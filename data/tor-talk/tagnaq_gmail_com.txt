
@_date: 2011-04-07 15:19:14
@_author: tagnaq 
@_subject: [tor-talk] Arm Release 1.4.2 
arm version 1.4.2.2 (released April 6, 2011)
typo in the manpage:
-v, --verion
              provides version information

@_date: 2011-04-08 16:03:20
@_author: tagnaq 
@_subject: [tor-talk] list archive files gziped twice? 
if I decompress one of the list archive files, for example:
I get gzip compressed data.
Did something go wrong when migrating the list or is there a particular
reason to compress these files twice?
(decompressing twice results in ASCII text files)

@_date: 2011-04-09 13:04:35
@_author: tagnaq 
@_subject: [tor-talk] Torbutton 1.3.2-alpha released 
Mike, thanks for your continued work on Torbutton!

@_date: 2011-04-09 13:17:13
@_author: tagnaq 
@_subject: [tor-talk] list archive files gziped twice? 
Indeed, downloading the file with firefox results in a different output
file when compared to the wget output file:
md5sum */*
5987e124389cc1cc156663f41d54d3cd  ff/2011-March.txt.gz
2598b636064e3884893a93268eb1fbdb  wget/2011-March.txt.gz
(reproducible not only on my host)

@_date: 2011-04-12 11:42:12
@_author: tagnaq 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
Will this new Tor Browser Bundle still offer the possibility to
configure it for "Transparent Torification"?
(traffic gets transparently redirected into Tor by a Tor router on the LAN)
added in TorButton 1.3.0-alpha:
 * new: Support for transparent proxies in settings
   (patch from Jacob Appelbaum and Kory Kirk)

@_date: 2011-04-13 15:30:00
@_author: tagnaq 
@_subject: [tor-talk] announcing releases 
just noticed (via [1], later via [2]) that 0.2.2.24-alpha was released.
I would find it valuable if relaeses would be announced at the same day
as they are available for download.
[1] [2] best regards,

@_date: 2011-04-16 22:10:38
@_author: tagnaq 
@_subject: [tor-talk] Torbutton: Resize windows to multiples of 50px during 
I run the test on  with Torbutton 1.2.5 and the
latest Tor Browser Bundle [1] (Torbutton 1.3.2-alpha).
The results in both cases show that the window resolution is not set to
multiples of 50px.
"Resize windows to multiples of 50px during Tor usage" was enabled in
both cases.
I verified the window size - the test result page shows correct values.
Can someone confirm this?
[1]

@_date: 2011-04-17 12:42:54
@_author: tagnaq 
@_subject: [tor-talk] Torbutton: Resize windows to multiples of 50px 
Compaired to a bunch of other websites [1] that do similar checks
ip-check.info seams to be the only one detecting the real screen/window
resolution. I guess [1] use JavaScript to get screen/window size and
ip-check.info doesn't.

@_date: 2011-04-17 16:36:51
@_author: tagnaq 
@_subject: [tor-talk] Torbutton: Resize windows to multiples of 50px 
Thanks for your reply.
Ok, Mike is aware of the issue:
best regards,

@_date: 2011-04-23 19:00:47
@_author: tagnaq 
@_subject: [tor-talk] Persistent XSS vulnerability in TorStatus 
Hash: SHA512
"TorStatus is a website display used to summarize metrics about the Tor
Network. It's a precursor to   The code
repository is at
 Example running sites are
 [...]"
Note: TorStatus is not a Tor Project product and is not maintained.

@_date: 2011-04-24 19:18:49
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
the original subject was
"reducing the negative anonymity impact for Tor node operators running
nodes at home" but then I thought it is a bit to long for a subject line :)
As a tor user you gain anonymity - as a Tor node operator you loose
I would call this a valid statement under certain circumstances.
The positive site effect of a dynamic IP address (lease <1d or even <1w)
is, that your IP is of less use to people trying to track you based on
your IP address.
If you run a Tor node at your home IP address you will loose the
positive side effect of a dynamic IP address and your IP layer anonymity
decreases to that of a static IP address because your node identity
links all your public IP addresses.
Actually it is even worse than being on a static IP address because an
IP address (alone) does not offer the same amount of certainty as
cryptographic ID's do (node fingerprint).
A tracker would have to wonder if IP address Y was assigned to the same
person if he/she sees it again after some months - there is no such
doubt if the IP hosts a Tor node.
For a Tor node operator (running a node at home) the server descriptor
archive becomes a data retention database, but the server descriptor
archive is not the problem.
This issue is even more relevant for Tor nodes running on mobile devices
(e.g. a laptop) If you are running a Tor node on your notebook you
should reset longterm keys and Nickname depending on your location.
Even the fact that you are running a tor node is sensitive information
because this reduces your anonymity set from on out of ~2^32 to one out
of 2^32 ;)
I submitted a Tor feature request to reduce the privacy impact for Tor
node operators running nodes at home:
best regards,
PS: I'm speaking only about non-exit nodes here because running an exit
at home and mixing your traffic with an exit is not a good idea[1].

@_date: 2011-04-25 01:16:06
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
[...] reduces your anonymity set from on out of ~2^32 to one out
of <2500.

@_date: 2011-04-25 02:24:07
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
I'll try to explain what I mean with an example:
Alice runs an non-exit Tor node at home. The Tor node at home is always
running. Her ISP assigns her a new IP address every day.
On 2011-01-29 Alice decides to create a new example.com account
(alice at example.com) using her home IP address - the same as her Tor node
is using [86.59.30.36] . (Alice is not using Tor for browsing the web
but she uses Torbutton in Transparent mode - I'm just mentioning this to
make clear that beside the IP address there is not much identifying
On 2011-03-13 (and several IP's) later Alice (now browsing with
[38.229.70.37]) wants another example.com account and again visits their
website. The Tor node is still running. example.com would like to know
if Alice did already create an account in the past.
example.com performs the following steps to answer its question:
1. IP address to Tor node fingerprint lookup
2. fetch all IP addresses that the Tor node (gathered in step 1) ever had
(one of the obtained records is: 2011-01-29 86.59.30.36)
3. look for matching IP addresses (comparing list gathered in step 2
with their own database)
MATCH: 2011-01-29 86.59.30.36 => created: alice at example.com
Now example.com will kindly ask Alice if she lost her password for
alice at example.com ;)
How would one implement such a "feature" if Alice was not running a Tor
node at her IP?
best regards,

@_date: 2011-04-25 10:26:29
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
The question was not "How do you fix this specific example".
One should see it at a higher level I used the example only to explain
what I meant.
I don't think that the Tor Project expects that every Tor node operator
routes his entire traffic through Tor to avoid this issue (this is not
even recommended or possible).
The question was:
because if you can implement this same "feature" if Alice was not
running a Tor node at her IP than this is not an issue Tor has to worry
If Alice is unlucky and has an unique (or near unique) screen resolution
in her ISPs network (AS) than you might fingerprint Alice also if she is
not running a Tor node at her IP address (fingerprinting based on a
combination of her screen resolution[1], installed fonts[2], STS
State[3], time[4], ISP/AS).
[1] [2] [3] [4] ...but Torbutton/TorBrowser will probably fix all these issues in the

@_date: 2011-04-25 12:59:31
@_author: tagnaq 
@_subject: [tor-talk] Persistent XSS vulnerability in TorStatus 
A search (grep) in the server descriptor archive starting with
2009-01-01 didn't show anything obviously nasty in the contact field -
so if a TorStatus site contained something nasty in that time period it
probably wasn't this vulnerability.
...but TorStatus is not properly html encoding everywhere where it should.
TorStatus sites usually do not require JavaScript.
The vulnerability reported in the original posting (a web application
not doing proper output encoding) has basically nothing to do with Tor
beside the fact that the web application does show Tor nodes information
and the way how an attacker delivers its payload to the website.
So your question boils down to:
Can one get compromised when browsing a website?
Yes, you can.
best regards,

@_date: 2011-04-25 14:24:00
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
So you are basically saying to Tor node operators running nodes at home:
Route *all* your traffic into Tor *regardless* of its content,
or dare using the Internet without Tor and handle the privacy effect
that running a Tor relay has on you yourself?
If that is the case then I'm astonished.
I guess you and Roger have different opinions on what to send over Tor
and what not [1].
[2] Do you disagree that rekeying ones in a while + a common node
descriptor would make it harder to link tor nodes to there past IP
addresses and reduce the privacy impact of running a Tor node at home?
best regards,
[1] [2]

@_date: 2011-04-25 15:44:45
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
I would say most or many nodes that are hosted at home are behind a NAT
router together with people. These people do not necessarily know about
the Tor node at their public IP address.
(even though they could easily find out)
If by 'limiting node data' you mean bandwidth throttling, this has no
influence on the issue.
The Tor server descriptor archive (metrics.tpo) is very useful to help
understand and improve the Tor network.
As a Tor user you probably know that one-hop proxies are weak by design.
I made a feature request. If the use of this feature actually improves
the situation of an node operator depends on how many other nodes are
using it on the same AS (and other things).

@_date: 2011-04-25 16:18:23
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
- Not all ISPs log assignments (yet) or are not even allowed to do so in
certain cases/legislations
- I doubt every ISP (that does store assignments) will give you all IPs
a certain subscriber ever had in the past by just demanding them without
having met certain legal requirements
..but beside that even running a Tor node at a static IP address reduces
your anonymity:

@_date: 2011-04-25 21:27:05
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
Following this logic no one should care about HTTP cookies, flash
cookies, ... because your ISP has a database with all your past IP
addresses (including timestamp) and gives them out to everyone who asks
for it anyway.

@_date: 2011-04-25 21:51:03
@_author: tagnaq 
@_subject: [tor-talk] Persistent XSS vulnerability in TorStatus 
Now I see what you mean. I think you are confusing the vulnerability in
TorStatus with the fact that Tor Exit Nodes might modify the traffic
that passes through them.
This has nothing to do with the vulnerably in TorStatus and is a totally
different issue.
Mike's Tor Exit scanner runs a lot of tests and I think it is likely
that an exit node messing with the traffic (injecting code) is detected.
After detection the exit node messing with the traffic will likely get
the badexit flag.

@_date: 2011-04-26 16:18:15
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
Even if you use Tor for *all* your traffic your node fingerprint will
generate a trace of your journeys in the descriptor archive if you run a
node on a mobile device (e.g. notebook) - and your tor node fingerprint
becomes high valuable information.
One might ask how can you get the node fingerprint of a certain person?
..what about using the ContactInfo field ;)  (one of may ways..)

@_date: 2011-04-28 16:41:17
@_author: tagnaq 
@_subject: [tor-talk] Better Privacy for Tor Node Operators 
Hi John,
thanks for your comment, you are making an important point here:
awareness. Is the Tor node operator aware about the side effects of
running a relay? Does the tor node operator know what implications
running a relay has?
The biggest problem here (IMHO) is that this issue (easier traceability)
affects also people that do not run a relay (people that probably do not
even know about Tor) - they are affected simply because they are at the
same Internet uplink as a Tor node.
With this thread (and other things that will take a bit longer) I'm
trying to improve the situation and awareness, and that is where I
disagree with you:
If I understand you correctly you are saying that there is no way to
improve the situation. I think there is a way to make it harder to
connect an internet uplink to a person and I would like to hear what you
think about it:
Imagine 50 nodes (or 20 or 10). All share the following:
- nickname (empty)
- contact (empty)
- tor version
- OS string (empty)
- ISP
- approximate internet uplink bandwidth
- ORPort
- DirPort
- exitpolicy
- key material is renewed before a new descriptor is published
in addition:
- the ISP forces IP renew at a certain interval (this is not imagination)
I think such a feature would make it harder to connect a person to his
internet uplink. What about you?
I'm not saying it will fix the problem but it would improve the
situation in my opinion.
(Unfortunately this feature request was denied.)
What makes me sad is that it is not even aknowledged that this might be
an issue at all[1].
best regards,
[1]

@_date: 2011-04-29 14:36:47
@_author: tagnaq 
@_subject: [tor-talk] fetching all server descriptors 
Hash: SHA512
if I understand it correctly metrics-db does not fetch all
descriptors[1] so the server-descriptor archives on metrics[2] does not
contain all descriptors.
If my assumption is correct:
Are there also archives that contain all descriptors? (referenced +
Does the directory-archive script[3] archive/fetch all descriptors?
"metrics-db fails to download non-referenced descriptors"
[2] [3]

@_date: 2011-02-21 23:59:44
@_author: tagnaq 
@_subject: [tor-talk] PDQVPN Tor Nodes - MyFamily 
Hi Andrew,
as my previous email remained unanswered I'm resending it, also CCing
tor-talk, so it may reach you this way in case my emails get flagged and
moved to the junk folder.
kind regards,

@_date: 2011-02-23 23:34:39
@_author: tagnaq 
@_subject: [tor-talk] Turning off all logging - how? 
I just tried the following:
Log notice file /dev/null
Works fine here (no logging at all)

@_date: 2011-02-23 23:45:36
@_author: tagnaq 
@_subject: [tor-talk] I wish to see one video on you tube 
I didn't know about that possibility yet to map addresses to exit countries.
As it doesn't work here (Tor complains about that torrc line at
startup), is this feature available in 0.2.1.x or is it only in 0.2.2.x?

@_date: 2011-02-28 20:39:35
@_author: tagnaq 
@_subject: [tor-talk] Is tor-announce still being used? 
I just received a email from that list today (new release). The archive
is empty because all lists were recently migrated.

@_date: 2011-02-13 00:32:55
@_author: tagnaq 
@_subject: Yet another UDP / DNS quiestion... 
Yes if you redirect DNS requests to Tor's DNSPort you should be safe
against DNS leaks.
I guess you are talking about a local setup without a "middlebox"
involved. If my assumption is correct you want to refer to the following
section in the document:
as far as I can see you copied parts of the iptables rules from the
"middlebox" setup from this section:
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-02-13 15:41:00
@_author: tagnaq 
@_subject: Yet another UDP / DNS quiestion... 
No it is not pointless because also if you do not use
AutomapHostsSuffixes in your config ".exit" and ".onion" are
AutomapHostsSuffixes per default.
The UDP rules in the LocalRedirectionThroughTor section:
redirect only UDP packets with destination port 53 (usually DNS
requests) to the DNSPort. All other outgoing UDP traffic is
blocked/rejected with the last rule:
iptables -A OUTPUT -j REJECT
The penultimate rule:
iptables -A OUTPUT -m owner --uid-owner $TOR_UID -j ACCEPT
would allow a program running with the $TOR_UID to send UDP traffic.
I will suggest to add -p tcp to that rule.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-02-13 15:51:56
@_author: tagnaq 
@_subject: Excluding exit nodes 
The config directive ChooseEntryExit should not be confused with
No you do not need to exclude them because your client will not use
nodes with the BadExit flag as an exit node anyway. The torstatus
website does not flag them, it just shows you that they have this flag
because the DirectoryAuthorities flagged these nodes as badexits.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-02-13 17:07:35
@_author: tagnaq 
@_subject: Excluding exit nodes 
(Coordination section)
General Design Document:
(chapter 6.3)
Note: This document is from 2004. Statements like "new nodes must be
approved by the directory server administrator before they are included"
are no longer valid.
Well this is currently a 'hot topic' and I refer you to the lengthy
thread 'Is "gatereloaded" a Bad Exit?'.
Short answer: you can not reliably detect passive sniffing.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-02-13 18:30:13
@_author: tagnaq 
@_subject: Yet another UDP / DNS quiestion... 
Why did you add -p udp here? Tor uses TCP.
This rule does not block UDP only, it rejects all traffic including UDP
(if a packets makes its way to the last line).
If this is your full iptables setup it doesn't make much sense to me.
You might have misunderstood my earlier reply.
But lets go one step back:
I'm wondering why one would want to setup DNSPort configuration without
I see two obvious use cases but neither matches yours:
scenario 1)
firefox+polipo+torbutton enabled
in such a setup there is no need for DNSPort + iptables if you are only
worried about firefox traffic
scenario 2)
you want to route all TCP traffic through Tor:
setup includes TransPort + DNSPort Setup (to prevent DNS leaking) +
iptables rules + Torbutton (transparent torification setting)
Could you describe your use case + thread model?
I wonder why your uid should be different everytime you reboot, but you
can also use the name of the user instead of the numerical value.
The word 'owner' after "-m" is _not_ a variable that needs to be
replaced. It is the match extension module name.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-02-21 23:59:44
@_author: tagnaq 
@_subject: [tor-talk] PDQVPN Tor Nodes - MyFamily 
Hi Andrew,
as my previous email remained unanswered I'm resending it, also CCing
tor-talk, so it may reach you this way in case my emails get flagged and
moved to the junk folder.
kind regards,
tor-talk mailing list
tor-talk at lists.torproject.org

@_date: 2011-07-08 16:37:31
@_author: tagnaq 
@_subject: [tor-talk] Torbutton 1.4.0 released 
Hash: SHA512
Torbutton 1.4.0 no longer displays the following info by default:
"Add-on update security checking is disabled. You may be
compromised by updates."
I haven't found anything regarding that in the changelog.
related question:

@_date: 2011-07-08 21:24:37
@_author: tagnaq 
@_subject: [tor-talk] Torbutton: 'Disable Updates During Tor' - Option 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Thanks for confirming this.
yes, the certificate is hardcoded - I tried an addon update doing a MITM
with my own root CA (manually installed)
result: update refused (good!)
hardcoding your *.tpo wildcard cert will also make other services safer
(check.tpo,  but it will require new releases when the cert

@_date: 2011-07-09 12:18:34
@_author: tagnaq 
@_subject: [tor-talk] Torbutton 1.4.0 released 
Hash: SHA512
found the changelog, thanks.
To me it seamed that updates were still disabled in Torbutton
1.3.3-alpha because the warning is still showing up in

@_date: 2011-07-10 14:30:48
@_author: tagnaq 
@_subject: [tor-talk] Vidalia documentation 
Hash: SHA512
I haven't found documentation for Vidalia besides
- - - - and the "Help" within the program
is there more?

@_date: 2011-07-10 21:14:32
@_author: tagnaq 
@_subject: [tor-talk] Vidalia documentation 
Hash: SHA512
I was looking for documentation regarding vidalia.conf
list of possible configuration options, their function and syntax
I probably overlooked it somewhere.

@_date: 2011-07-10 22:56:29
@_author: tagnaq 
@_subject: [tor-talk] Vidalia documentation 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Ok, do you have any raw estimate when it will be available?
(before or after 1 Sep 2011)
Thank you for this offer.

@_date: 2011-07-11 18:01:34
@_author: tagnaq 
@_subject: [tor-talk] Trac email interface 
Hash: SHA512
is there a way to file bugs at trac.tpo via email?

@_date: 2011-07-21 10:52:07
@_author: tagnaq 
@_subject: [tor-talk] "Firefox 4 Tor Browser Bundles" 
Hash: SHA512
Firefox 4 Tor Browser Bundles
Tor Browser Bundle (2.2.30-1)
    * Update Tor to 0.2.2.30-rc
    * Update Firefox to 5.0.1
Shouldn't TBBs containing Firefox 5 be named
"Firefox 5 Tor Browser Bundles"?

@_date: 2011-07-22 18:28:25
@_author: tagnaq 
@_subject: [tor-talk] Downloading Firefox add-ons trough Tor. Safe? 
Hash: SHA512
The versioncheck is performed over SSL, the download actually happens
over plain HTTP most of the times (depends on the addon) - but the
update is nontheless "safe" because the file hash is checked.
(incl. Mikes reply)
Th check for Mozilla's certificate is hardcoded therefore it is not
possible to do a MITM attack with a different certificate.

@_date: 2011-06-02 23:14:10
@_author: tagnaq 
@_subject: [tor-talk] SMTP & POP3 Email over Tor.. Anonymity breaking? 
Hash: SHA512
You can modify some of the header values using about:config,
depending on what exactly you want to achieve it maybe suitable for you
or not.
Local timezone (as seen by Thunderbird) can be modified by using the TZ
environment variable (without having to modify the OS timezone).
Thunderbird source code of v3.1.10:

@_date: 2011-06-03 00:45:04
@_author: tagnaq 
@_subject: [tor-talk] layer 2 separation: relay in a Host-only network 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
This is correct if you do not configure IP (addresses, routing).
If your Host OS acts as a router your relay running in a VM won't be
able to perform layer 2 attacks on your LAN as long as the VM can't
compromise the Host OS.

@_date: 2011-06-03 15:56:24
@_author: tagnaq 
@_subject: [tor-talk] SMTP & POP3 Email over Tor.. Anonymity breaking? 
Hash: SHA512
Also if these few settings seam to be what you wanted, please keep in
mind that they cover only the most obvious information leaks and there
might be a lot of other vectors that can be used to reduce your
anonymity set - after all it is "experimantal".

@_date: 2011-06-04 02:54:07
@_author: tagnaq 
@_subject: [tor-talk] How evil is TLS cert collection? 
Hash: SHA512
Someone running this (SSLObservatorySubmission) in a non-public network
(i.e. an internal corporate network) with Internet access will probably
disclose internal hostnames including IP addresses, if that is the case
I would identify this as an issue. What do you think about it?
btw: sorry for my late reply to this topic, but it was still 'unread'
till now on my side.

@_date: 2011-06-04 12:37:14
@_author: tagnaq 
@_subject: [tor-talk] How evil is TLS cert collection? 
Hash: SHA512
These two options will prevent disclosure in many scenarios but I don't
think it will avoid the problem in a common scenario (internal hosts use
a valid FQDN and a valid cert).
IP address and hostname (and cert.) of intranet-server1.example.com
using a valid certificate *.example.com will be published even if the
first two options in the "advanced options" are enabled. Is that correct?
In such scenarios I'm not worried about the certificate being submitted
but the hostname and IP address (domain and server_ip arguments).
I'm not sure if I understand "private DNS domains" correct.
"[x] Do not check/submit certificates for private DNS domains"
Are private DNS domains just non-existing TLDs? Something like

@_date: 2011-06-04 13:18:13
@_author: tagnaq 
@_subject: [tor-talk] How evil is TLS cert collection? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Well, if the EFF is able to ask the DNS regarding the hostname then the
submission to the EFF took already place :)

@_date: 2011-06-04 22:19:09
@_author: tagnaq 
@_subject: [tor-talk] How evil is TLS cert collection? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Yes, instead of asking the EFF to resolve a hostname an internal client
could just use Tor to get an "outside view" regarding a hostname.
This way hostnames don't have to go through a central point (EFF) for
the 'is this hostname private?' - check.

@_date: 2011-06-04 22:19:12
@_author: tagnaq 
@_subject: [tor-talk] How evil is TLS cert collection? 
Hash: SHA512
To make this example clearer:
The internal DNS resolves intranet-server1.example.com to a public IP
address (non RFC1918). The public DNS does not resolve this hostname
(split DNS).

@_date: 2011-06-05 00:34:42
@_author: tagnaq 
@_subject: [tor-talk] How evil is TLS cert collection? 
Hash: SHA512
Well, after all I guess we can acknowledge that there are scenarios
where information disclosures will happen.
To give users the possibility to contribute while preventing leaks for
specific domains they are concerned it would be great if the submission
addon would have a blacklist feature where one could say
never submit anything for  *.example.com.

@_date: 2011-06-07 17:08:49
@_author: tagnaq 
@_subject: [tor-talk] Tor 0.2.2.28-beta is out 
Hash: SHA512
0.2.2.28 is already in the repo [1] but I couldn't find the tar.gz.
Was it removed from [2] or was it not yet there?

@_date: 2011-06-09 18:08:05
@_author: tagnaq 
@_subject: [tor-talk] Identifying use of relay as an Entry node 
Hash: SHA512
If someone connecting to your ORPort isn't a relay in the consensus it
is probably a client or a bridge.
In rare cases it might even be a relay. (IP address in descriptor
differs with current outbound IP address)
If you run arm [1] on your guard node you probably see clients as
"[scrubbed]" entries.
[1]

@_date: 2011-06-09 18:47:24
@_author: tagnaq 
@_subject: [tor-talk] Directly vs. bridges 
Hash: SHA512
Bridge relays (or "bridges" for short) are Tor relays that aren't listed
in the main Tor directory. Since there is no complete public list of
them, even if your ISP is filtering connections to all the known Tor
relays, they probably won't be able to block all the bridges. If you
suspect your access to the Tor network is being blocked, you may want to
use the bridge feature of Tor.
If you use Vidalia the screenshots on the mentioned page will help you
determine if you use bridges, but in general: If you didn't explicitly
choose to use a bridge you connect to Tor directly.

@_date: 2011-06-10 18:54:46
@_author: tagnaq 
@_subject: [tor-talk] Firefox-update in Tor Browser Bundle? 
Hash: SHA512
There are Tor Browser Bundles containing Firefox 4

@_date: 2011-06-11 21:20:09
@_author: tagnaq 
@_subject: [tor-talk] browser bundles 
Hash: SHA512
Firefox 4 supports HTML5 and this means you can watch certain videos
even if you do not use flash ...for example on youtube. Currently you
have to opt-in for HTML5 videos but I think the developers (of TBB) are
working on settings to opt-in by default (seen in ticket on
Proxies such as polipo and privoxy were only a temporary workaround for
a firefox bug (hardcoded SOCKS timeout). The goal was to get rid of
these proxies.
TBB takes care of application-level privacy leaks such as User-Agent
Header and many other things.

@_date: 2011-06-13 16:07:07
@_author: tagnaq 
@_subject: [tor-talk] Torbutton: 'Disable Updates During Tor' - Option 
Hash: SHA512
Disable Updates During Tor (recommended)
Under Firefox 2, many extension authors did not update their extensions
from SSL-enabled websites. It is possible for malicious Tor nodes to
hijack these extensions and replace them with malicious ones, or add
malicious code to existing extensions. Since Firefox 3 now enforces
encrypted and/or authenticated updates, this setting is no longer as
important as it once was (though updates do leak information about which
extensions you have, it is fairly infrequent).
Note: The current Torbutton (1.3.3-alpha) doesn't display the
"(recommended)" next to this option.
I think it is better to not enable this option, meaning: you should make
updates - also - over Tor. I would like to hear your opinion if you
don't agree.
- - I assume requests to mozilla are encrypted + authenticated
- - I assume 3th-party extensions are update via mozilla server
- - update requests leak your version and used addons to mozilla but
mozilla shouldn't be able to connect that information with other
information about you. It is a problem if these versioncheck requests
would set a cookie that is transmitted while browsing mozilla sites.
- - enabling this option (disabling upates) will result in outdated
software which may contain security issues
- - updates my contain security issues too, but that is a question of
whether you trust that addon or not
- - Firefox 2 is not supported any more (for quite some time now)

@_date: 2011-06-13 16:36:13
@_author: tagnaq 
@_subject: [tor-talk] Torbutton: 'Disable Updates During Tor' - Option 
Hash: SHA512
Just adding this from the Design Document
Disable Updates During Tor
Option: extensions.torbutton.no_updates
This setting causes Torbutton to disable the four Firefox update
settings during Tor usage: extensions.update.enabled,
app.update.enabled, app.update.auto, and browser.search.update. These
prevent the browser from updating extensions, checking for Firefox
upgrades, and checking for search plugin updates while Tor is enabled.
This setting satisfies the Update Safety requirement.
The Update Safety requirement is:
The browser SHOULD NOT perform unauthenticated updates or upgrades via Tor.

@_date: 2011-06-15 23:12:12
@_author: tagnaq 
@_subject: [tor-talk] Does my ISP know I'm using Tor? 
Hash: SHA512
If you are unlucky and your ISP actually cares, he probably does it the
chinese way: Fetch as many bridges as possible to detect as many bridge
user as they can.
I think 'No.' is quite a strong wording here because it seams to imply
certainty. I'd like to add some uncertainty to it to rise awareness.
Awareness should help avoid dangerous situations or at least
detect/recognize them.
If you are unlucky and using an exit relay run by your ISP, this would
mean your ISP is in the position of seeing some of your traffic (by
correlation of input+output).
'some' because you won't use the same exit all the time.
How much 'some' actually is, is influenced by the bandwidth (and other
facts) of the ISP exit (if there is one).
Tor does not aim to protect against such a powerful adversary.

@_date: 2011-06-19 00:06:25
@_author: tagnaq 
@_subject: [tor-talk] ControlPort "read-only" access? 
Hash: SHA512
I'd like to give guys access to their Tor instance so they can view what
their current used relays are at the moment (vidalia map), without
giving them the possibility to actually issue commands that modify any
Looking through the manpage of Tor, I didn't spot something to do this.
Is this possible?

@_date: 2011-06-19 01:49:43
@_author: tagnaq 
@_subject: [tor-talk] ControlPort "read-only" access? 
Hash: SHA512
Is there a trac ticket for this feature request?

@_date: 2011-06-19 13:23:21
@_author: tagnaq 
@_subject: [tor-talk] nesting proxies 
Hash: SHA512
Depending on your OS / resources you could do the following to achieve
- - configure firefox to use the proxy that you want to use after the Tor
- - transparently route traffic into Tor (e.g. TransPort + iptables)
- - use Torbutton in Transparent Mode
(this setup would only use one proxy after Tor)

@_date: 2011-06-19 13:31:50
@_author: tagnaq 
@_subject: [tor-talk] nesting proxies 
Hash: SHA512
Manually setting a proxy (firefox settings) while using Torbutton might
be a problem/no go.
I didn't try the mentioned setup.

@_date: 2011-06-21 23:14:17
@_author: tagnaq 
@_subject: [tor-talk] How evil is TLS cert collection? 
Hash: SHA512
Yes, this is the scenario I was concerned about.
I would suggest the following:
- - user opts-in
- - addon performs check if host can resolve hostnames to IPs (possible?)
- - if it can't and the first adv. option isn't enabled, tell the user
that the addon will not do anything, but still give the user the
possibility to override this default check-and-disable procedure
the next question would be: is the addon doing periodic checks to see if
the situation changed?
Thank you for the inclusion of this feature.
Another feature request just came to my mind: (actually it became more
than just one)
[ ] do not submit the IP address (server_ip argument) for private DNS
(submits: '-2')
[ ] do not submit the IP address for the following private DNS domains
I see this useful in the following scenario:
The user is fine with submitting certificates that would fall into the [
] Check/submit certificates for private DNS domains
option, but doesn't want to disclose the internal IP addresses.
The new option is only available when the user enables the submission of
certificats for private DNS domains.
Or you submit -2 by default for private DNS domains (if he enabled the
submission for private DNS domains) and give the user the possibility to
further opt-in and say: "I'm fine with submitting the IP address for
private DNS domains" (this would probably be the better way from a
privacy point of view but will result in less people submitting that data)
I don't know if you find submissions with empty domain argument
valuable, but if you do, you could also consider adding an option like:
[ ] do not submit the hostname (domain argument) for private DNS domains.
[ ] do not submit the hostname for the following private DNS domains:
One might argue, the hostname is also included in the certificate (CN),
but this is not always the case (wilcard certificate).
Giving the users fine grained possibility about what they disclose might
result in more users willing to participate, but I totally agree to keep
them in an "expert section" because non-technical users might be
confused by these options.
These options give a "experts" the possibility to disclose more if they
are fine with that.

@_date: 2011-06-26 02:13:34
@_author: tagnaq 
@_subject: [tor-talk] Torbutton: 'Disable Updates During Tor' - Option 
Hash: SHA512
This assumption was and is wrong.
Disabling such insecure update paths makes sense.

@_date: 2011-06-26 13:40:02
@_author: tagnaq 
@_subject: [tor-talk] Torbutton: 'Disable Updates During Tor' - Option 
Hash: SHA512
I concluded that the addon process is insecure because the versioncheck
happens over HTTPS but the actual download of the new xpi file is over http.
This simple conclusion is wrong if one doesn't check the entire update
To download something over an insecure channel is fine as long as you
can check the file for modifications after the download.
The versioncheck mechanism provides the location of the new xpi file and
the SHA256 Hash over SSL to the browser:
 If firefox actually checks the SHA256 hash before installing the xpi it
should be reasonable safe (beside the information leaks).
Regarding SSL MITM: Mozilla seams to have a hardcoded check for the
certificate of the versioncheck host.[1]
What let Torbutton to the conclusion that the update mechanism is
insecure and therefore disabled by default?
(TBB: "Add-on update security checking is disabled. You may be
compromised by updates.")
Is 'compromised' meaning in this context: someone may install arbitrary
xpis or was it more the kind of "your anonymity gets compromised because
you disclose your addons incl. their versions"
I suppose thats a question for, Mike?
[1]

@_date: 2011-03-01 07:51:03
@_author: tagnaq 
@_subject: [tor-talk] Is tor-announce still being used? 
Updating or resubscribing the mailing list to gmane maybe a good idea?

@_date: 2011-03-20 13:31:17
@_author: tagnaq 
@_subject: [tor-talk] website: broken URL (roadmap) 
Originally send to Roger, but I guess he is busy..

@_date: 2011-05-04 16:41:52
@_author: tagnaq 
@_subject: [tor-talk] youtube with tor on wordpress 
When used with Firefox 4 or the alpha Tor Browser Bundles, it also
features support for youtube videos in HTML5, but you must currently
opt-in for youtube to provide you with HTML5 video as opposed to
flash:

@_date: 2011-05-13 22:25:25
@_author: tagnaq 
@_subject: [tor-talk] automatic updates? 
Hash: SHA512
automatic updates are an effective mechanism to reduce the window of
Is the Tor Project planing to go in that direction in cases where the
software is not managed by the OS package management?
best regards,

@_date: 2011-05-15 22:38:45
@_author: tagnaq 
@_subject: [tor-talk] "drop all vulnerable relays from the consensus" 
Hash: SHA512
"If someone publishes or demonstrates a code-exec exploit [...] we
should drop all vulnerable relays from the consensus" [1]
- - Does Tor provide Authority Directories with an easy way to reject/drop
relays from the consensus based on the platform string or is this only
possible based on FP or IP?
- - How will Directory Authorities determine if a relay is "vulnerable"?
(inspecting the platform string only)?
[1]

@_date: 2011-05-15 22:48:00
@_author: tagnaq 
@_subject: [tor-talk] detecting harmful relays 
Hash: SHA512
"Not reporting version is actively harmful" [1]
- - Is it possible to detect if someone is harming the Tor network in this
- - Are you already running such scanners or is there the Exit Scanner only?
[1]

@_date: 2011-05-27 17:10:47
@_author: tagnaq 
@_subject: [tor-talk] Securing a Relay - chroot 
Hash: SHA512
You do not mention the threats you worry about and assets you care about
(thread model + security requirements).
In [1] you mentioned "can monitor traffic" and Marsh gave you already
hints how to address this (VLAN, virtual host only networks) [2].
[1] [2] If you want specific answers you should pose specific questions.
"security for a relay" is quite general.

@_date: 2011-09-15 23:21:59
@_author: tagnaq 
@_subject: [tor-talk] Towards a Tor-safe Mozilla Thunderbird 
Hash: SHA512
I uploaded a document [1] to the Tor wiki. It is about application-level
privacy leaks in Thunderbird including proposed solutions. It would be
great to get some review/feedback - especially on the proposed solutions.
btw: I won't be able to reply in a timely manner in the next few days.
[1] Since the document was written, proposal 171 (stream separation) was
implemented/released in 0.2.3.3 [2] and new Thunderbird version were
released (but didn't address the problems yet).
To mitigate a certain problem (bugzilla: 684035) described in section
4.1.4.I recommend every Thunderbird user to set the following
preferences to true:
Related bugzilla tickets:
- - - - - - [2]

@_date: 2011-09-15 23:29:20
@_author: tagnaq 
@_subject: [tor-talk] Dutch CA issues fake *.torproject.org cert (among 
Hash: SHA512
A pity that  was not implemented at the time (even if the
likelihood to make any difference is only given if the user actually
toggled and is in disabled mode).

@_date: 2011-09-21 11:32:13
@_author: tagnaq 
@_subject: [tor-talk] Vidalia documentation 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Is the documentation already available somewhere?

@_date: 2011-09-22 13:30:44
@_author: tagnaq 
@_subject: [tor-talk] How to use Torbutton (1.4.3) in 'Transparent 
Hash: SHA512
when trying to change Torbuttons settings to use the Transparent
Torification Mode the final click on 'OK' does not do anything. It
doesn't close the window and the only way to exit is to click on 'Cancel'.
I suppose it as to do with the test that is performed to see if Firefox
really uses Tor.
Is someone successfully using Torbutton in 'Transparent Torification'  Mode?

@_date: 2012-08-21 22:25:48
@_author: tagnaq 
@_subject: [tor-talk] End-to-end correlation for fun and profit 
Hash: SHA512
I think karsten's graphs from  fit also well to this thread:
You might also be interested in this thread on tor-relays:

@_date: 2012-08-22 10:04:21
@_author: tagnaq 
@_subject: [tor-talk] End-to-end correlation for fun and profit 
Hash: SHA512
tor-relay-stats.py, renamed to compass.py might be useful too:

@_date: 2012-08-23 14:59:01
@_author: tagnaq 
@_subject: [tor-talk] [Advanced configuration troubleshooting] Exit node 
Hash: SHA512
[breaking the thread as it didn't seem to be related to Robin's]
you had a look at the advertised bandwidth fraction graphs?
(it dropped from 0.7% to under 0.2% around the 1th of August)
These relays (00Teh0Signul00, 00T3h0Signul00, 00Teh0S1gnul00)
currently do not have the stable flag.

@_date: 2012-08-23 23:08:08
@_author: tagnaq 
@_subject: [tor-talk] [Advanced configuration troubleshooting] Exit node 
Hash: SHA512
down till you see graphs with red, green, yellow and blue lines.

@_date: 2012-02-21 00:13:53
@_author: tagnaq 
@_subject: [tor-talk] tor debian repository for non x86 arch? (arm) 
Hash: SHA512
I used to install packages from the torproject debian repos
( )
but apparently they do not include packages for arm.
Is there a debian repo for arm somewhere?
(containing tor 0.2.3.x packages for debian stable)

@_date: 2012-02-21 19:11:36
@_author: tagnaq 
@_subject: [tor-talk] tor debian repository for non x86 arch? (arm) 
Hash: SHA512
Yes, I meant the architecture arm.
Would you consider building packages for arm if I would donate an arm

@_date: 2012-07-22 01:04:20
@_author: tagnaq 
@_subject: [tor-talk] General remarks when using mail clients over Tor (i.e. 
Hash: SHA512
I'd like to give some general information on what you might run into
when using mail clients over Tor, in fact this is not specific to
email but probably applies to other authenticated services that deploy
some kind of anti-account hijacking prevention systems. Whether this
stuff actually applies to you depends on your email provider.
- - Fetching mail via Tor might triggers automated intrusion prevention
systems because you come from 'unusual locations'.
These automated systems might temporarily block your account till you
login via webmail and confirm your password/secret question.
If this is the case on a gmail account you will get an email with the
subject: 'Suspicious sign in prevented'
This might happens when trying to fetch mails over Tor for the first
few times, at least the detection mechanism at gmail seems to be
adaptive and won't bother you continuously if you use constantly use
Tor to access you mail account.
Thunderbird might shows you a clear warning indicating that a login
was denied for that specific reason. I can't remember the exact
sentence anymore, but that was the case with a gmail account. (The
warning is not generated by Thunderbird itself but rather a displayed
message received from the mailserver.)
Make sure you know the answer to your secret question (or alternative
password recovery method). Unfortunately changing gmail's password
recovery options doesn't seem to work with TBB [1].
- - Another issue that I haven't seen often with gmail but you might run
into it with other freemail providers occurs when submitting emails to
the mailserver (sending). Depending on your mail provider and exit
node the mailserver might simply deny access or resets the connection.
This usually happens when using big exit relays (torservers seems to
work fine compared to CCC exit nodes). Hitting 'Use a New Identity'
might be a workaround [2]. Or you exclude exit nodes for which email
submission doesn't work, but in that case you should have a specific
tor instance just for mail because excluding the popular exit nodes
will affect your usability (speed) and privacy.
So when having troubles using Thunderbird with Tor keep in mind that
this might be the case because one of these issues arose.
Maybe we should start a wiki page to collect experience with different
[1] [2]

@_date: 2012-07-22 01:50:05
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy Not Allowing Connections to Servers 
Hash: SHA512
Can you be more specific? (mentioning exact settings, server, port,
connection security, ..)
Do you see the connection attempts in Vidalia's network map?
I suppose it is fixed now.
(it is a wiki page)

@_date: 2012-07-22 11:58:06
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy Not Allowing Connections to Servers 
Hash: SHA512
Good to hear that you were able to resolve your issue and it was not a
TorBirdy problem.
When you start the Tor Browser Bundle it starts the Socks listener on
a random TCP port (SocksPort auto). This is probably the reason why
you were not able to use tor in thunderbird because there was no open
Socks port where torbirdy expected it (9050).

@_date: 2012-07-22 13:47:03
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy with Tor? 
Hash: SHA512
TorBirdy is a Thunderbird extension that configures your Thunderbird
to use Tor, but it doesn't include Tor itself. TorBirdy expects that
you have Tor running on your localhost:
SocksPort 127.0.0.1:9050
http proxy: 127.0.01:8118
Thanks for your question, we will update/create end-user documentation
to make this requirements more clear.

@_date: 2012-07-24 00:26:11
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy - testing and feedback requested! 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Thank you for your feedback.
I'll write my follow-up answer directly to the trac entry.

@_date: 2012-03-10 15:08:30
@_author: tagnaq 
@_subject: [tor-talk] tor debian repository for non x86 arch? (arm) 
Hash: SHA512
looks like we are going to see ARM (arch) .deb packages sooner or later:

@_date: 2012-05-02 01:20:33
@_author: tagnaq 
@_subject: [tor-talk] Exitrelay performing SSL MITM on port 995 (Dr. Web 
Hash: SHA512
there is an exit relay performing SSL MITM on POP3S connections
(and probably others).
The relay seams to be using Dr. Web Netfilter (see att. [mail to big
att. removed]),
so the harm is probably not done intentionally.
Unfortunately I don't know which exit node I was using at the time.
I assume that Mike's exit scanner will detect this node sooner or later.
until then: do not ignore ssl warnings (not just now ;)

@_date: 2012-05-03 22:02:46
@_author: tagnaq 
@_subject: [tor-talk] Firefox security bug (proxy-bypass) in current TBBs 
Hash: SHA512
for the security advisory.
I'm quite surprised that you do not inform TBB users via "the usual
channel": via the default startpage in TBB (check.tpo) - even if there
are no new TBBs yet.

@_date: 2012-05-03 22:09:11
@_author: tagnaq 
@_subject: [tor-talk] Firefox security bug (proxy-bypass) in current TBBs 
Hash: SHA512
wouldn't it be better to remove the vulnerable TBB versions to prevent
people from actually downloading and using them?

@_date: 2012-05-03 22:54:09
@_author: tagnaq 
@_subject: [tor-talk] testing TBBs 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
After the last problem within a TBB release I signed up to tor-qa [1]
to help with testing and expected something like:
"hey we are about to release a new version x, download it here, please
send us your testresults and regression reports"
on that list everytime before a new release is published, but that
list was not used [2]
[1] [2] By 'signing up' do you mean, subscribe to  or how does the 'sign
up' process look like?
Where does one get the info that a new version is about to be released?
Where are pre-releases available for download?

@_date: 2012-05-07 20:40:10
@_author: tagnaq 
@_subject: [tor-talk] Towards a Torbutton for Thunderbird (torbutton-birdy) 
Hash: SHA512
Hi mix.tb,
I'm curious whether you did write the following line - especially the
word 'wrote' yourself or not?
The word 'wrote' shouldn't be there - at least not auto generated by
TB after installing the extension (language disclosure).

@_date: 2012-05-07 21:54:23
@_author: tagnaq 
@_subject: [tor-talk] Towards a Torbutton for Thunderbird (torbutton-birdy) 
Hash: SHA512
"Trying to hide we use Icedove seem unrealistic and/or impractical a
goal, at least to start with. Therefore, we'll ignore tagnaq's
suggestions whose single aim is that one."
Why do you think that I aimed for hiding the use of Thunderbird?
Hiding the fact that someone is using Thunderbird when he/she actually
is, was not my intention:
on page 3:
"Non-goals: hide the fact that we are using Thunderbird"
on page 21:
"As specified in section 2.3 the header information reduction
does not aim to hide the fact that Thunderbird is the used
Great! Thanks for explicitly mentioning this (I was about to ask you
if you are going to submit it for upstream inclusion ;)
I hope you are watching
It might be a good idea to submit/suggest it there?
I hope you enable mailnews.auto_config_ssl_only by default and hide
the disable button very well ;)
The basic idea is to get all issues that require code changes fixed
upstream so that we do not have to bother about builds.
Enabling privacy via an extension only gives you also a potentially
bigger user base (=bigger anonymity set => better anonymity).
..but as we saw with firefox/torbutton getting things done upstream is
not an easy and fast process.

@_date: 2012-05-08 21:09:07
@_author: tagnaq 
@_subject: [tor-talk] Towards a Torbutton for Thunderbird (torbutton-birdy) 
Hash: SHA512
thanks to you we are aware of this issue now.
You might be interested in this trac ticket - which mentions currently
known issues:

@_date: 2012-05-14 22:34:17
@_author: tagnaq 
@_subject: [tor-talk] any issue with TBB extensions auto updating? 
Hash: SHA512
You might be interested in this discussion:
short version: the exit sees what you are updating (http request) but
can't modify it without being detected.
regarding the prevention of SSL MITM (compromised CAs and the such)
during the update process, you might want to have a look at:
the future of key pinning via HTTP headers

@_date: 2012-05-15 08:43:12
@_author: tagnaq 
@_subject: [tor-talk] Towards a Torbutton for Thunderbird (torbutton-birdy) 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Mike Perry:
I voted for updates, analysis:

@_date: 2012-05-17 22:36:26
@_author: tagnaq 
@_subject: [tor-talk] Volunteer QA: The Price of Freedom is Eternal 
Hash: SHA512
Do you plan to create a mailing list for the 'interested people' that
are going to test pre-release builds?

@_date: 2012-05-18 00:10:21
@_author: tagnaq 
@_subject: [tor-talk] Technical Documentation for the TBB Update 
Hash: SHA512
the following trac entry might be helpful for you

@_date: 2012-05-27 17:43:15
@_author: tagnaq 
@_subject: [tor-talk] Torbutton-birdy version 0.0.2 
Hash: SHA512
Hi Tom,
I don't think that Sukhbir and Jake aim for an undetectable TorBirdy,
but as soon as another email client has also an extension like
TorBirdy and agrees on the same header field settings I guess it
wouldn't be easy to determine the client in use by looking at the
header. The MSA would very likely still have the "power" to determine
the client (version).
My thread model is described on page 6 of the following paper:
It depends on the mailserver settings but in almost all cases it
includes the connecting IP (the exit node's IP if you send your emails
through Tor). If you use gmail via webmail it does not include your
source IP in the outgoing email header.
As soon as you decide to modify the header to reduce certain leaks
your mail header is easily distinguishable. As soon as you introduce a
new header fingerprint it will always be more unique (at the
beginning) but someone has to start with a new one that leaks less
information even if your fingerprint is used by fewer people.
I'd consider it as important to have all torbirdy "stable" users in
one anonymity set as soon as there is a feature complete stable
version. I consider the current version as experimental.
typo: trsnafers
btw: Great talk at BH EU.

@_date: 2012-05-27 17:43:08
@_author: tagnaq 
@_subject: [tor-talk] Multiple Tor instances 
Hash: SHA512
It is certainly easier to link account A to account B if they always use
the same circuit,
but since tor version 0.2.3.3 you can achieve stream separation with one
single tor instance - no need to run multiple instances.
For more information see:
0.2.3.x manual page

@_date: 2012-05-27 19:01:30
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy version 0.0.2 
Hash: SHA512
Note: TorBirdy doesn't support a toggle model. There has been an
attack vector against the old Torbutton in Firefox where one was able
to detect the presence of Torbutton while it was off (IIRC).
If TorBirdy aims for a per-email-account enable/disable option within
one Thunderbird Instance/Profile this is an issue. E.g. you can
determine with sufficient likelihood that someone has TorBirdy
installed while he sends email from an email account for which he
doesn't have torbirdy enabled.
But as of now Thunderbird doesn't support per-email-account proxy
settings - AFAIK.

@_date: 2012-05-30 00:52:44
@_author: tagnaq 
@_subject: [tor-talk] email over Tor / anonymity sets vs. source IPs (was: 
Hash: SHA512
[new thread]
I'm glad you like it.
I see your point.
I exported it as html but it probably contains lots of metadata, which
would take some time for clean up.
I suppose it is less of an effort to open the pdf in a VM appropriate
for untrusted files.
...however if an html version is for some reasons very important for
you I'll reconsider it and add it to my todo list.
I do think that most SMTP servers / MLs include the entire SMTP path
and therefore it is very easy to separate Tor users based on their
source IP anyway. [I agree that it would be nice to have a more common
fingerprint but I do not think it is feasible without sacrificing a
lot on other aspects.] And after all this is only relevant if you
choose to trust your mail provider - which is considered an adversary
in my threat model.
(btw: anyway I finally filed I think that such an approach that requires the user to actively select
its language for every message is error prone. As soon as the sender
forgets to select the correct language or fails to choose the correct
language he is screwed.
I prefer something that doesn't depend on user interaction.
thank you for your feedback.

@_date: 2012-05-30 00:52:51
@_author: tagnaq 
@_subject: [tor-talk] email over Tor / anonymity sets vs. source IPs (was: 
Hash: SHA512
[new thread]
I'm glad you like it.
I see your point.
I exported it as html but it probably contains lots of metadata, which
would take some time for clean up.
I suppose it is less of an effort to open the pdf in a VM appropriate
for untrusted files.
...however if an html version is for some reasons very important for
you I'll reconsider it and add it to my todo list.
I do think that most SMTP servers / MLs include the entire SMTP path
and therefore it is very easy to separate Tor users based on their
source IP anyway. [I agree that it would be nice to have a more common
fingerprint but I do not think it is feasible without sacrificing a
lot on other aspects.] And after all this is only relevant if you
choose to trust your mail provider - which is considered an adversary
in my threat model.
(btw: anyway I finally filed I think that such an approach that requires the user to actively select
its language for every message is error prone. As soon as the sender
forgets to select the correct language or fails to choose the correct
language he is screwed.
I prefer something that doesn't depend on user interaction.
thank you for your feedback.

@_date: 2012-11-24 12:44:59
@_author: tagnaq 
@_subject: [tor-talk] upgrading procedure for TBB 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
I'm surprised to see this 'rm -rf' command in a recommendation. I
thought you recommend to just unpack the tar file to preserve bookmarks..
Has that alternative approach ('tar xzf' without prior 'rm -rf')
negative side effects?

@_date: 2012-11-24 12:44:50
@_author: tagnaq 
@_subject: [tor-talk] Tor 0.2.3.25 is out 
Hash: SHA512
great to see the first Tor 0.2.3 stable release!
Maybe we can reach the point where the line for 0.2.3 relays crosses
the line for 0.2.2 relays in the 'relays by version' - graph [1]
earlier with announcements via additional channels:
- - - - - - [1]

@_date: 2012-10-07 01:09:16
@_author: tagnaq 
@_subject: [tor-talk] Testing Documentation for TorBirdy 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
Hi antispam06,
thanks for your offer to test TorBirdy. What are you aiming for exactly?
a) Do you aim to test TorBirdy's features and ensure they are working
as they should (like regression tests before releasing new version)
b) Do you want to test a TorBirdy setup and find yet unknown leaks?
For (a) a detailed feature list with expected behaviour should be
enough for you to build test cases, such a list does not exist yet but
we will build it
if you want to go into the direction of (b) you might want to have a
look at bit.ly/qDZm7C (chapter 3.1 and 3.3) and analyze parts of
Thunderbird that were not in scope back then (for example the new chat
feature - which I really dislike to have in Thunderbird).
To cover (a) the following ticket has been created:

@_date: 2012-10-07 16:29:49
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy doesn't work with Gmail? 
Hash: SHA512
Could you have a look at:
and tell me if you see Tor connecting to your mailserver in Vidalia's
"Tor Network Map"?

@_date: 2012-10-07 21:48:37
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy GnuPG version curl-shim? 
Hash: SHA512
I suppose this is not a curl version that supports socks, Jake saw the
same [1].
For more background and test cases see:
[1]

@_date: 2013-04-02 20:48:32
@_author: tagnaq 
@_subject: [tor-talk] unable to create bitmessage forum account via Tor 
Hash: SHA512
Hi Jonathan,
(CC tor-talk)
thanks for your work on bitmessage.
I reviewed your papers and wanted to give you some feedback and
suggestions (problems we try to prevent in torbirdy [1]) in your forum
at [2] but I was unable to do so (forum thinks I'm a spamer [3]).
I didn't want to send my feedback via direct email because I wanted to
have an open discussion.
It would be great if you could allow me (and others) to create a forum
account via Tor.
btw: is there a bitmessage pseudo-mailing list about bitmessage?
(besides announce)
[1] [2] [3] "The user tagnaq with Email tagnaq at gmail.com (IP ) is
a Spam, please contact forum administrator."

@_date: 2013-08-14 14:48:07
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy question 
Hash: SHA512
Why would you want to change it there? (and not via the gui)
You have two possibilities:
1) add the following line to your torrc to get an additional SOCKSPort:
SOCKSPort 9150
2) Goto TorBirdy's Proxy Settings and choose 'Use custom proxy settings'
(this is what you did and I suppose it works)
We are aware of the "issue" and this will change in the future.

@_date: 2013-08-15 11:49:46
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy question 
Hash: SHA512
Well, that option is already there in Torbirdy's preferences.
What will probably change is the default SOCKSPort Torbirdy is trying
to connect out of the box.

@_date: 2013-07-05 20:26:01
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy doesn't work with Gmail? 
Hash: SHA512
In case you are trying to improve the system to prevent false
positives and need some feedback:
I still get 'Suspicious sign in prevented' emails (4 in the last
month) and was forced to change the password - but luckily I still
have access to my account.
Gmail blocked access when coming from ~8 different IP addresses - all
of which where tor relay IPs (verified via metrics.torproject.org).
I suppose you can see the IP addresses in my "account history" in case
you need them for debugging purposes.
If I should direct these emails to someone else let me know - thanks.

@_date: 2013-07-30 23:45:37
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy patches for Mozilla Thunderbird 
Hash: SHA512
I would suggest to work/discuss the harder part (date header) first.
Getting the message-id modification accepted might be easier but if
the date header remains, the message-id modification did not gain
anything (and vice versa: date header fix without msg-id fix doesn't
solve the problem either).
Before starting the discussion with Mozilla, I'd like to get some hard
facts by testing the no-date-header patch on a broad range of different
freemailers and MTAs run by ISPs having a significant market share
(this requires volunteers actually sending emails from their accounts
without date header).
If we run into MSA setups where emails without date header cause
problems (the MSA doesn't insert the date header for us) we have to
analyze this in detail. Ideally by contacting the operator. (Not an
easy task.)
One item on the task list, is it to make it easy for volunteers to
contribute test cases (send test emails without date header).
Volunteers should not be required to patch and recompile Thunderbird
to send test emails (a simple script would probably do the job).
My underlying assumption is:
As long as our patch breaks email (for some users) Mozilla will not
accept our patch (even if our patch does not change the default date
header at all - users would have to opt-in via TorBirdy).
So the first question I'd like to answer is:
Would our date patch break mail for some users?
(Currently we can answer this question for the main freemailers only.)
If so: How big is 'some'?
Why does it break?
1) create a script to send no-date-header test emails
2) set up a wiki page to collect test data
3) ask volunteers contribute

@_date: 2013-06-01 18:37:40
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy doesn't work with Gmail? 
Hash: SHA512
Hello Mike,
thank you for providing this information on this mailing list - really
I'm using Tor to fetch and send emails since quite some time but never
reached the point where I didn't get any 'Suspicious sign in
prevented' emails from google anymore.
I got used to it and occasionally verified if the IP address in
question was an exit node at the given time.
Yesterday google decided to lock my account (not the first time) even
though I used your described procedure (2) a while ago and hoped that
I should be fine now.
Did google revisit it's procedures or is this expected behaviour even
after following your described procedure (2) and with "relaxed
security checks"?
As several times before - I was able to unlock my account answering
the security question, but this is becoming a continuous burden.
kind regards,

@_date: 2013-06-07 13:42:34
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy doesn't work with Gmail? 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
I suppose it is a timing/delay issue since 50.7.228.92 is included in
the current version of
Generally speaking you can never say that a user that is coming from
an IP address that is *NOT* listed as an exit node is *NOT* coming
through Tor.
This is because Tor exit relays might use separate IP addresses on
inbound and outbound traffic.
The inbound address is announced and can be found in the consensus but
the outbound traffic (the one gmail.com will see) is not necessarily
the one that can be found in the consensus if a server is specifically
configured to do so or if he is behind a NAT.
So I would suggest to allow *ANY* IP address as soon as you know that
the actual user specifically opted-in to be a "Tor gmail user" (if the
user completed one of your two options described) - any other approach
will only mean trouble for Tor users on the long run.
thanks for bringing this up here!

@_date: 2013-09-02 19:48:59
@_author: tagnaq 
@_subject: [tor-talk] Email Clients and Tor 
Hash: SHA512
Depending on your threat model and use case simply routing program X
through tor might not what you actually want.
You used 'email client' in the plural form in the subject so I assume
you are also asking for other email clients?
You might want to use Thunderbird with Torbirdy?

@_date: 2013-09-09 12:15:44
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy doesn't work with Gmail? 
Hash: SHA512
We still get 'Suspicious sign in prevented' emails:
The following relay was used:
Note: The relay has no 'exit' flag (not fulfilling the minimum
requirements for that), but still allows exiting on certain ports.
Thank you for forwarding this email to the relevant people.
Would be great if they could share a timeline on when this issue will
 finally be fixed (if at all) - thanks!

@_date: 2013-09-09 17:33:47
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy doesn't work with Gmail? 
Hash: SHA512
I'd suggest the following:
Run an hourly job that gives you a list of tor relay IP addresses that
actually allow exit traffic to *your* services.
To achieve this you probably want to run a tor client to get an
authoritative consensus. Then you can parse that data to produce the
final IP address list for simple and fast offline lookups (simple IP
address comparision).
Exonerator is probably a good starting point that can be reused and
modified to your needs without a lot of effort.

@_date: 2013-09-09 19:25:06
@_author: tagnaq 
@_subject: [tor-talk] The reasoning behind the 'exit' flag definition 
Hash: SHA512
I'd like to understand why the exit flag is defined as it is.
The current definition can be found in the directory spec [1]:
"Exit" -- A router is called an 'Exit' iff it allows exits to at
   least two of the ports 80, 443, and 6667 and allows exits to at
   least one /8 address space.
I assume the exit flag was meant to be used by tor clients only [2]
because destination port 80/443 are probably amongst the most
frequently accessed services, but was than (mis)used to generate
(inaccurate) 'Tor exit IP address lists' (?).
This means that there is no way to tell if a relay actually allows
exiting (any) traffic simply by looking at relay flags. To actually
tell you would have to parse exit policies.
I think this is the main reason why people trying to handle the 'is a
tor user' - case are having a hard time.
Here are two examples why this negatively affects tor and non-tor users:
1) Non-Tor users are banned to access certain services when they share
their IP address with a non-exit relay. Admins start to block *all*
tor relay IP addresses (even non-exits) ones they realize that also
relays without 'exit' flag might allow exiting to their services.
2) I'm regularly banned from accessing my gmail account when using tor
because google blocks my access to its services if I'm appearing to
have a *non*-tor IP address [3] (this is the direct inversion of 1).
Which one of the following proposals would be more likely too be
accepted by the Tor Project (if any at all):
- - change the definition of the 'exit' flag to include all nodes that
allow *any* exiting traffic.
- - introduce a new flag that is set on all relays allowing *any* exit
traffic (leaving the current definition of the 'exit' flag unchanged)
As an alternative, better tools to create 'tor exit lists' as
suggested in [4] and [5], might also do the job. Is someone aware of a
tool that implements something like that already?
Something along the lines of:
./get-tor-exits [relay-IP] target-service-IP[/mask][:port],...
output: boolean if relay-IP is given,
if no relay IP was given: print a list of all relay IP addresses that
would allow accessing (any) service in the target IP (range).
(similar to what exonerator does already)

@_date: 2013-09-09 19:27:33
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy doesn't work with Gmail? 
Hash: SHA512
Correct, it wasn't a web-signin.
I started a thread for it here:

@_date: 2013-09-09 21:44:11
@_author: tagnaq 
@_subject: [tor-talk] The reasoning behind the 'exit' flag definition 
Hash: SHA512
I suppose that's how [1] is generated (Olaf in CC).
I would even suggest to remove it from the site if [1] is purely
generated based on the 'exit' flag.)
[1] Great. I think this should get them started - thanks.

@_date: 2013-09-10 06:18:38
@_author: tagnaq 
@_subject: [tor-talk] TorBirdy doesn't work with Gmail? 
Hash: SHA512
Yes, and I still believe this is the best option, because even with
the best possible 'tor exit IP list generator' - implementation you
will get false negatives [1].
[1]
