
@_date: 2014-01-02 11:36:48
@_author: tor@bitmessage.ch 
@_subject: [tor-talk] Harvard student used Tor to send bomb threats, 
This student did some really stupid things and in many ways is a "bad
example" of Tor use, but when Harvard students--even the ones who seem to
have come unhinged and clearly made reprehensible decisions--don't realize
that their university (or other institution's network administration)
probably can and does retain DHCP and/or other information, it's hard not
think that a significant user education and communication opportunity
exists for other Tor users.
I'm not defending this person or what they did in any way, but it does
seem like an example of why offerring more conspicuous, detailed warnings
and feedback to users could help prevent
activists/whistleblowers/journalists/people using Tor to do positive
things from being de-anonymized through similar means. Tor has made huge
strides in this respect (e.g. better update notifications in TBB) over the
past six months, but perhaps there are still some further improvements
that could be made.
In the spirit of Jake's 29c3 talk, I think we can decide as a community
not to brush off high-profile attacks against people using Tor with
arguments like "oh, it was an old Firefox vulnerability and some users
weren't running the latest available code" or "oh, obviously universities,
companies, and maybe ISPs retain enough data to make 'standard police
work' enough to de-anonymize someone using Tor." Instead of these kinds of
"not my department" arguments, we can *instead* conclude that at least in
some cases, making information more visible, accessible, and
understandable to users in more and different ways might still ultimately
be better for Tor users.
A community as innovative as this one can probably figure out ways to
present useful information to users in ways that don't interfere with
their autonomy, too. I realize that media portrayals--especially this past
year--have mischaracterized Tor and its community unfairly, but in
addition to making it clear whether Tor "still works" on technical
grounds, I think we can also choose to be constructive and up our game so
that especially for all the people using Tor who *aren't* jerks, Tor users
will have to be even more thoughtless in order to be de-anonymized through
similar means in the future.

@_date: 2014-01-03 00:24:06
@_author: tor@bitmessage.ch 
@_subject: [tor-talk] Harvard student used Tor to send bomb threats, 
I appreciate your perspective but still think the community may still be
better off--including those who take the time to RTFM--by taking a harm
reduction approach to the RTFM-related problems you've mentioned.
The incident seems to suggest that at least some people who we could
assume are capable of RTFM--and I heartily agree that this person is not a
good example of tor usage for a variety of reasons--appear not to be RTFM
for whatever reason. While I don't condone this user's choices, I hope
it's not controversial to suggest that this person probably now wishes he
had RTFM, or alternatively that the TBB's design had presented him with
more timely, relevant information as he was actually using Tor.
We may not feel sympathetic to this user's situation because of the
circumstances, but I hoped to point out that something similar could
plausibly happen to some *other* person using Tor for good that we
probably wouldn't want to experience the Syrian equivalent or the Chinese
equivalent of the consequences this person now faces.
We're all free to reiterate RTFM from our positions of relative privilege,
but I also think we should acknowledge that some users we should care
about don't or won't or can't always RTFM. Framing user education as an
important problem to solve or mitigate where possible seems like a more
constructive approach to me. Maybe we can't prevent all users from making
unwise choices, but to the extent we can help more of them, I still think
we should try.
So for the honest users out there who don't do reprehensible things but
may also sometimes not RTFM (e.g. because their internet access is
limited, or who live in constant fear of an oppressive regime, or who
can't afford time in the internet cafe to read all of the documentation),
I still hope this community will keep at it and continue to make it harder
for users to make mistakes without impinging on others' autonomy/freedom.

@_date: 2014-01-07 08:12:24
@_author: tor@bitmessage.ch 
@_subject: [tor-talk] Harvard student used Tor to send bomb threats, 
My point was that "this is not a technological issue" arguments sometimes
seem like "not my department" arguments. As a community, we have to decide
whether we exclusively care about the technology or whether we also care
about how easy it is for users to understand and make practical use of the
documentation that comes with it. Maybe it's not a technological issue in
the way you've framed it, but I still think it's an important issue and
hopefully something we can work toward addressing.
I think the offensive/defensive framing is mostly semantics. If you're a
pro-democracy activist in China or a blogger exercising free speech in
Syria, your government probably *does* consider your work an "offensive
operation". And while you're right that something like a blogging
platform's server probably won't be run by the Syrian government in most
hypothetical "user doing good things" scenarios, we have very good
evidence that a BlueCoat device *would be* run by the Syrian government
and that Syrian citizens are directly and personally connected to that
"entity". If BlueCoat's deep packet inspection (hypothetically) got better
at identifying users in Syria relying on pluggable transports and/or
bridges to access Tor, correlation attacks roughly analogous to what
happened to this Harvard student might be possible. If something like that
actually happened to you, you might not care as much about exactly how you
were de-anonymized as the simple fact that you WERE de-anonymized. You
might even wish that Tor's community had had a stronger spirit of mutual
aid and solidarity toward all of its users, and not merely the ones who
were "smart enough." And you might wish that smart people from Tor's
community hadn't brushed you off with "rtfm" and "this is not a
technological issue."
I wasn't trying to suggest that a lot of great people haven't been working
very hard on user education for a very long time, or that solid
documentation and research aren't already there. But wouldn't we all be
better off if users had a better understanding of exactly how and when
they were choosing to "roll the dice"? I was suggesting that maybe we can
aspire to do better in terms of how effectively users are informed of
important, complex information that they may not initially understand.
And I think it's really sad when people from our community suggest that
Harvard students just aren't smart enough to understand the documentation.
How smart should someone have to be, exactly, and how much time should
someone have to invest in understanding it? Would an MIT student have to
be de-anonymized in a similar fashion for us to conclude that we might be
able to do more on user education? An MIT-trained programmer? An
MIT-educated cryptography researcher? Would someone like Roger or Nick
themselves have to be de-anonymized in a similar fashion before we could
conclude that user education is something that could be done more
Where people go to school isn't a good predictor of whether people
understand technology, and it may never be possible to prevent everyone
from making mistakes while using Tor that they might regret. It's not the
easiest problem to solve, it may not have purely technical solutions, and
this student isn't a good example in a lot of ways.
But I still hope that we can try to do better helping the users we do want
to support--even the people who might not be "smart enough" right now.
