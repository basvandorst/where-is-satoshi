
@_date: 2014-12-24 00:05:41
@_author: Ben Tasker 
@_subject: [tor-talk] Possible upcoming attempts to disable the Tor network 
I'm far from an expert on Tor, but:
backup DirAuths servers only once the backup plan
to learn the locations of the backup DirAuths from > these public Gateways.
Assuming a software update isn't required to 'activate' these gateways in
the event of a compromise (and if it is, new DirAuths could just as easily
be pushed that way - as is the case now).
Whilst the code on the 'gateways' might be encrypted, will anything be
needed client side to handle the redirect? If so, what's to stop an
adversary from using the client codebase to develop something 'good enough'
to trigger a redirect to their malicious DirAuths.
I'm assuming you'd send a message signed with a specific key and have the
client verify it? What happens if the Gateways (which the client's
presumably know about) are also seized/compromised after the relevant keys
have been delivered to them?
In terms of a trust model, assuming the keys for the Gateways are
compromised (or a weakness in the implementation found giving the same
effect), presumably the response of the Gateways overrides the 10 DirAuths?
Potentially reducing the effort needed for an attack to 3 or 4 gateway
I'm not poking holes in your idea, it's more it's caught my interest and
raised a few questions in my mind.
10 Servers spread around different jurisdictions is still quite a challenge
to mount, though not impossible (though as I understand it, as it's
consensus based, they don't need all 10).
But given the widespread effect it would have, they'd have to be able to
support the argument that interfering with the routing of every Tor user
was reasonable in their stated goal - that'd probably carry in some
jurisdictions, but is unlikely to in others.
jurisdictions concerning warrant authorization, or eventually
I've no idea whether the operators of the DirAuth's have looked at this
(though I'd be surprised if some haven't) but looking at the processes used
(or ignored) in the relevant countries definitely seems like a worthwhile
effort to me.
On Tue, Dec 23, 2014 at 11:23 PM, Alexis Wattel

@_date: 2014-12-24 00:18:55
@_author: Ben Tasker 
@_subject: [tor-talk] How to prevent traffic relaying on an HS node... 
In torrc - where you've got a NickName, ORPort etc disabled, comment it out
and restart tor
As a side note, if you've got accounting disabled, you should probably
disable that too.

@_date: 2014-12-26 17:39:50
@_author: Ben Tasker 
@_subject: [tor-talk] Interview 
There was a tweet up (briefly, seems to have gone now) giving the mailing
list's address as the place to ask questions.
Still something of a common sense failure though.

@_date: 2015-04-06 20:44:32
@_author: Ben Tasker 
@_subject: [tor-talk] Hi! 
I think the point was that you've come onto the Tor mailing list and
essentially asked for dirt without asking about the other side of the coin.
I took it to mean that you think you've already got a good idea of what the
'good' uses might be, but it does come across as something of a loaded
question - especially as it's not impossible that there may be some 'good'
uses that you've not thought of.
Ben Tasker

@_date: 2015-04-07 07:39:17
@_author: Ben Tasker 
@_subject: [tor-talk] Hi! 
He didn't use the word only, but he did only ask about malicious uses - "Do
you guys mind if you tell
me some malicious uses with Tor?" - which doesn't exactly invite a balanced
conversation does it?
About specifically malicious uses? Probably nothing that he either won't
already have or that others aren't better qualified to talk about. I do
quite a lot with Tor, but I don't think any of it could be fairly labeled
as malicious.
The point I was trying to make (admittedly badly) was that asking
specifically about malicious uses on tor-talk is not particularly
constructive. The likelihood of a genuinely malicious actor popping up and
listing their behaviour is small.

@_date: 2015-04-30 16:12:03
@_author: Ben Tasker 
@_subject: [tor-talk] Full integration with bitcoin (suggestion / feature 
Never thought I'd see a suggestion of paid fast lanes on Tor, thought that
was largely limited to the dreams of greedy ISPs
You'd probably attract more exit operators if it were possible to be paid,
but I'm not sure it'd be a good idea overall.

@_date: 2015-12-16 10:14:15
@_author: Ben Tasker 
@_subject: [tor-talk] Ordering a .onion EV certificate from Digitcert 
The benefit of a publicly signed certificate over a snake-oil certificate
is obvious,
so I guess you're asking why a hidden service would want TLS?
There are a bunch of potential reasons an operator _might_ find it
one of which you've alluded to in that thread.
- E2E encryption if the HS' tor client is running on a different box to the
- Additional confirmation that you're talking to the hidden service you
expected to
- An additional layer of encryption if that provided by Tor is ever found
But as time goes by, there's an additional reason - availability of
Mozilla announced a while back that certain features were going to be gated
https availability - i.e. a HTTP only onion won't be able to benefit from
Personally, I think it's a bad idea, as (depending on the feature) it's
punishing the user for a decision taken by a website they have no control
over. But
it does mean in the future there may potentially be thinks a HS operator
want's to
take advantage of and can't.
the better
The problem is, letsencrypt doesn't help with a lot of the issues I see
coming from
the broken CA structure. Your personal data has less exposure (because
not giving it to them), but there's still no protection against a
CA issuing a certificate for your domain, for example.
Worse, because letsencrypt insist on that 90 day renewal, things that could
help defend
against that scenario (like key pinning) aren't really an option because
the windows
are too tight. There are ways around that (like not regenerating keys) but
it potentially
opens you up to other things.
Letsencrypt addresses some of the issues with the CA model, but IMO they've
managed to effectively worsen some of the issues I'm more concerned about.
On Tue, Dec 15, 2015 at 9:24 PM, Aymeric Vitte

@_date: 2015-02-01 23:24:58
@_author: Ben Tasker 
@_subject: [tor-talk] ISP CenturyLink Blocking Tor? 
Looking at their info page -
 -
it seems Century Link run what they call a Protection Program.
If they detect (what they consider to be) potentially malicious traffic,
the connection gets put in a walled garden to notify the end user.
Is the OP's friend using non-Century link DNS? Wondering if it could be as
simple as an over-enthusiastic detection policy triggering the walled
garden. I've no idea how Century Link achieve redirecting to the
notification page, but if they simply return the IP of one of their
servers, using external DNS servers could easily break that leading to the
impression that your internet has dropped out.
As others have said, rebooting the router would likely have acquired a new
IP, so effectively cancelling a block.

@_date: 2015-02-01 23:59:32
@_author: Ben Tasker 
@_subject: [tor-talk] ISP CenturyLink Blocking Tor? 
doesn't seem relevant to OP's friend, because tor and torrent clients are
As it has been known for some infections to establish a connection back to
their C&C via Tor, it's not inconceivable an ISP (or more likely,
who-ever's providing their kit) might apply a policy which could
(deliberately or otherwise) wind up blocking Tor. Whether Tor is malware
has no real bearing, what matters is whether it's traffic is perceived as
such by the ISP
I missed the part about the torrent client, though it sounds like the
behaviour was slightly different. In either case though, the OP's
description makes it sound like the external connection dropped in it's
entirety - for any kind of filtering/blocking that's massive overkill. If
you were being restricted to a walled garden, outside connectivity might
appear unavailable unless you were going to a whitelisted IP.
On my (UK) ISP, a reboot of the router pretty much guarantees a new IP,
though I have also been with providers where that wasn't the case.

@_date: 2015-02-02 17:03:40
@_author: Ben Tasker 
@_subject: [tor-talk] ISP CenturyLink Blocking Tor? 
Leeroy - I think what he meant was that if anyone can actually get through
to someone to talk to (and get a response) - as opposed to breaching a real
firewall and leaking staff details, at least that's the way I read it.

@_date: 2015-02-08 16:11:54
@_author: Ben Tasker 
@_subject: [tor-talk] When you forget to pay your Internet Bill, 
I'd say in this case, it's more a case of the ISP going quite light with
the form of blocking they put in place - they've implemented a means of
reminding you to pay your bill without breaking non HTTP applications.
If you were to continue to fail to pay your bill, it's highly unlikely that
Tor would get you past the blocks that would then be implemented.
That TWC decided to remind you in that way is definitely a good thing -
last time I was late (it was quite a while back) my ISP tried something
similar, but didn't put any thought into the fact that there are
applications that don't use port 80 and will break as a result of their
redirection strategy.

@_date: 2015-02-10 23:26:27
@_author: Ben Tasker 
@_subject: [tor-talk] TBB visited links color 
isn't the default purple?
I'm not sure if it's at all related to why TBB wasn''t changing the colour,
but a while back there was a bit of JS released used essentially tried to
map your browser history out by including a huge number of links and then
checking what colour they were -

@_date: 2015-02-26 00:35:00
@_author: Ben Tasker 
@_subject: [tor-talk] git: application level leaks and best practices? 
You can override this behaviour, but it's not particularly convenient to do:
git commit --date=2015-02-25T01:00:00+0000 -m "fixed it"
You could probably create an alias within git to save typing, though you'd
still have to get used to using your new alias. As far as I know, there
isn't a global option to force this behaviour (there is one to force git
log to use UTC, but that's not much help here)

@_date: 2015-01-11 18:48:58
@_author: Ben Tasker 
@_subject: [tor-talk] DNSSEC better protecting users? 
I would guess the idea is you may be able to tell the user is using tor2web
but not what they're accessing.
Because the domain name is sent in the clear as part of the SSL handshake
(the client Hello to be precise) it discloses what is being looked at.
The only way to avoid that is to use something that is only sent once the
handshake is complete - part of the request URI, the path or cookies -
though each has their issues.
It'd potentially mean rewriting responses (to make sure paths are relative)
but I'd be inclined to make the first section of the path identify the
service - example.com/foo.onion/index.html.
Just my 2p

@_date: 2015-01-23 15:01:41
@_author: Ben Tasker 
@_subject: [tor-talk] Deep Web Business Models 
Interesting reading, although I couldn't help but facepalm when seeing
someone involved in investment write the following
Well... yes.
One thing that he observes, and I definitely agree with, is that the
markets have shown that simply building a good reputation by serving your
customers well can lead to a lot of business. There's no need for
monitoring a customer's every move in order to try and predict their
desires - sell something people want, and have a track record of meeting
expectations and customers will come.
Longer term, it'll definitely be a good thing if something other than
arrests comes from outside scrutiny of the various marketplaces.

@_date: 2015-01-30 11:19:44
@_author: Ben Tasker 
@_subject: [tor-talk] Tor -> VPN Clarification 
VPN + Tor may also be useful if you're on a connection where you definitely
don't want your local ISP (or perhaps someone else on/with access to the
same network) to see that you're using Tor.
In this case, the ISP may not be a BT or a Verizon, but a hotel wireless
provider, employer, starbucks etc.
In that instance, the local ISP might also object to a VPN, of course, but
generally speaking a VPN (or an SSH tunnel) is generally seen as 'OK'.
What you're doing there, though, is shifting the trust you'd normally have
for your/an ISP to the VPN provider which may or may not prove wise in the
long run.

@_date: 2015-07-02 19:34:04
@_author: Ben Tasker 
@_subject: [tor-talk] Fighting human trafficking (on Tor and elsewhere) 
I wouldn't go quite that far, but scanning over I can see a few strange
comments in the notes
probably a lot
In POST's report to the UK Government they mentioned (I presume based on
metrics) that most didn't use Tor because they found it too slow. I'm not
in a position to know for sure, but my suspicion is that it's actually far
more prevalent on the clearnet.
Google scrapes far more of the deep web than some realise - if you can view
a HS through tor2web there's a reasonable chance that Google has crawled
it. All it takes is a single link (whether to a HS that links to your HS,
or a direct link).
Most of the other points are things that seem to have been rehashed over
and over - can't we protect legitimate users whilst defending against
illegitimate ones? etc.

@_date: 2015-06-07 11:58:35
@_author: Ben Tasker 
@_subject: [tor-talk] "Tor Browsers" on SourceForge 
Beware of SourceForge's recent behaviour (though they've promised not to do
it without consent again) -
- if something goes up on SF it needs to be maintained to avoid being
considered abandoned, and in the case of a few projects, wrapped in Adware
by Sourceforge themselves.
It's also potentially tricky getting projects removed once they're there -
If it was me, I'd create an official page, with no releases on it, but a
link to the correct location to get Tor from, Sourceforge is not what it
once was...

@_date: 2015-06-23 19:49:23
@_author: Ben Tasker 
@_subject: [tor-talk] do Cloudfare captchas ever work? 
partnerships with sites, to provide captcha services?
I think the suggestion is they'd provide captcha _solving_ services.
If you know where to look, you can find 'businesses' that provide just
those services - workers (or users) sat solving captcha after captcha so
that your scripts can go about their business unimpeded once you're able to
automatically solve the captchas you're presented with.

@_date: 2015-03-04 06:01:55
@_author: Ben Tasker 
@_subject: [tor-talk] Why corrupt government officials are strongly 
That is almost certainly true, there will be those who frown on Tor for a
variety of reasons
If true, that'd mean that some of Fox News' output is based on fact? Shaken
to my core :)
Seriously though, as others have pointed out, the Government has much
cheaper, much more effective ways of silencing opponents. Methods that are
used to great effect in many other countries.
I don't doubt that someone somewhere in an agency has probably looked at
whether advertising can be subverted, though I suspect it's far more likely
that they were interested in payload delivery and not attempts at mind

@_date: 2015-03-05 09:57:50
@_author: Ben Tasker 
@_subject: [tor-talk] Why corrupt government officials are strongly 
If you didn't believe it was 'make believe' then you might file reports,
even if it truly is make believe.
Being from the UK, I can safely say (at least in my case) that we're
subjected to Murdoch's 'output' but that does not necessarily mean we are
on board with him. I don't doubt that he, and his businesses, have a lot of
skeletons hidden in their cupboards (though whether that extends to some of
the things you assert is questionable).
You claim to have proof of this conspiracy, but have simply provided
conjecture based on the fact a number of sites (including Fox News) block
access from (certain) tor exit nodes. That some sites block tor users is
neither news or outright proof of a conspiracy. You may hold additional
'evidence' of what you claim, but what you've provided so far doesn't come
close IMO.

@_date: 2015-03-05 12:33:06
@_author: Ben Tasker 
@_subject: [tor-talk] Why corrupt government officials are strongly 
Because in the absence of evidence, it is just that - a conspiracy theory.
You're asserting that Fox and the Govt (or at least some of it's agencies)
are conspiring, but have provided no real no evidence to support it, hence
That they're all using the same method of communicating the block is
evident (they all return a 404 with the same 'reference' number). The
underlying software being used to generate their blocklist isn't something
that's immediately identifiable from the responses being returned.
In point of fact, foxnews appear to be blocking all tor exits (or I've been
very lucky in the exits I've selected) whilst senate.gov and usps.com
appear to discriminate between exits (some are blocked, others aren't).
That at the very least, suggests completely different policies (even if the
software affecting the block were to be the same).
There have been reports for quite some time of Fox blocking tor exits (see
for example
though I don't know when senate/usps started.
Aside from a similar error message, you've not provided anything to show a
'significant' connection between the three. It doesn't mean that there
isn't, but the point being made is that you haven't provided anything to
show that there is.
It's equally possible that both Fox and the US Govt have purchased 'bad
behaviour' blocking software from the same private company.

@_date: 2015-03-05 12:56:27
@_author: Ben Tasker 
@_subject: [tor-talk] Why corrupt government officials are strongly 
I appreciate there is strong feeling on both sides of that particular
debate, but I'm not entirely sure how you can view abortion as anywhere
near the same as rounding up people based on faith and executing them en
masse (to again use the German example). Abortion is it's own debate, and
personally I don't think it fits anywhere into the framing of genocide.

@_date: 2015-03-05 13:08:05
@_author: Ben Tasker 
@_subject: [tor-talk] Why corrupt government officials are strongly 
Whilst I agree with you, I think it's reasonable to say that a lot of
conspiracy theories wander into that bracket. You're correct though, in
that a 'theory' does require rationality.
Got a big grin from me. anyway

@_date: 2015-03-09 12:12:35
@_author: Ben Tasker 
@_subject: [tor-talk] Why corrupt government officials blah blah bleh blah 
I had removed myself from this conversation, but, having seen first-hand
the chilling effects of baseless screams of "defamation"
lawsuit if you keep it up.
Just to save you the filing fees - what Zenaan posted is not actionable
under defamation laws. He's mocked you, but has made no substantive claims
about your character. You cannot claim defamation when no references to
your character/behaviour have been made. "Condescending B.S." does not fall
within the realms of defamation (though a conversation starting that way
could wander into the correct territory I guess).
IANAL so I've no idea if calling you a tin-hatter would be actionable, but
I would hazard a guess that it doesn't meet the bar, and if it did you'd be
facing an uphill struggle.
As one way to defend against defamation is to prove the statements were an
honest opinion, the defendant(s) would need to convince the court that what
you're claiming falls within the realm of unfounded conspiracy. More so,
they'd have to do it based only on the 'evidence' you've provided in this
Nothing's certain when you're relying on a court to make a decision, but
given that the claimant's route to defeating such a defence is to show that
the defendant didn't actually hold that 'opinion' I'd say your odds of
success are low.
Some of the claims you've made against others elsewhere in the thread(s)
could potentially be actionable though, so depending on who you target, you
might find some interesting counter-claims.
Or, you know, if you're actually after a serious conversation, you could
have one, as long as you stop expecting everyone to interpret your
'evidence' in exactly the same way that you do.

@_date: 2015-03-09 12:27:26
@_author: Ben Tasker 
@_subject: [tor-talk] Tor as a network filter 
Depending on how you're getting traffic onto Tor (i.e. are you using the
SOCKS proxy or silently redirecting traffic to the relevant port) you may
be able to achieve something similar to what you're attempting using other
tools first.
For example, I have a VM running an MUA, it should only ever connect to
it's mailserver's over Tor. To enforce that, my router runs Tor and an
iptables rule ensures that all traffic from that VM leaves my network over
Tor (there are some other concerns with doing it this way, but they aren't
relevant for what I'm trying to say).
There's no technical reason I (or, you) couldn't add a rule to first push
that traffic through some sort of (semi)transparent proxy so that filtering
can be performed at application level.
There are a number of reason's you might not want to do it though:
- It complicates troubleshooting connection issues
- You've just inserted an extra listening point for an adversary to use
- If you're using a transparent solution and it breaks, you may find
yourself working without your extra level of 'protection'
- Depending on your solution, it may change your request signature (a lot
of work has gone into TBB to make all look the same, you don't want your
user-agent to suddenly becomes 'squid' for example)
In my setup, traffic transits my network in the clear (at least in a
metadata sense) before reaching Tor, there's no reason you necessarily need
to do that as you could set something similar up on a single box.
So whilst tor won't do application level filtering for you, you can insert
some filtering into the chain, as long as you weigh the risks (and I've
likely omitted some)

@_date: 2015-03-10 10:56:07
@_author: Ben Tasker 
@_subject: [tor-talk] (UK) Parliamentary advice on Tor 
Interesting reading  - the Parliamentary Office of Science and Technology
(POST) has published it's report on Tor and the (in)feasibility of blocking
anonymous access for users within the UK.
The document's a PDF, and the layout is questionable, but it's worth a read
if you have 5 minutes.
There are some interesting insights in there, from the perspective of what
LEA's see.
The overall summary though is - blocking anonymous access wholesale is not
an acceptable policy option in the UK, and would impact on non-criminal Tor
users. There _might_ be more appetite for legislating against Hidden
Services, but enforcing it would be technologically infeasible.

@_date: 2015-03-11 13:26:56
@_author: Ben Tasker 
@_subject: [tor-talk] Tor as a network filter 
in response to an out of the box product you can by[1], that running Tor on
a physical router is not so safe, though this is maybe where your iptables
rule comes in.
The advice given in that thread is correct - but it relates primarily to
Web browsing, and makes a few assumptions about user behaviour (wise
assumptions IMO though).
For the setup I described above, the traffic being carried is SMTP/IMAP so
I don't need to worry about tokens being exposed in quite the same way. I
can also guarantee that traffic from that VM will never leave my network
over anything but Tor (the edge firewall will drop it's traffic).
In theory, you could use an edge firewall to afford similar protection for
web browsing, though it would still leave a few risks, even assuming the
access device you were using was something that was only ever on that
network (i.e. a desktop not a laptop).
Similarly, if you were doing it all in one box (i.e. browser and Tor client
are all on the same system) you could, potentially achieve a similar
fail-safe environment, but it's by no means guaranteed.
Pushing to Tor at the network level helps against things like badly behaved
plugins that ignore proxy settings (though you shouldn't really be using
them anyway), but does carry it's own set of risks, some of which are well
described in that thread.
Because no specific config is needed at the browser, it allows you to use
your 'everyday' browser, so the cookies you pick up whilst browsing will be
sometimes be sent in the clear, and sometimes over Tor - that's obviously
Also, depending on your config, anything running on your machine will also
be routed over Tor.  If any of those send credentials that can be tied back
to you (e.g. credentials for a backup server in your name) then you've got
You _could_ try to work around it by selectively routing over Tor, but then
you've just opened a nice wide vector for information leakage.
With my mail VM, I have specific ports and destination IPs that it can talk
to. Everything else is denied, so it should be fairly safe, but it is
inherently inflexible.
you appear, ignoring the risk of standing out?  How would you interface
with the traffic?
It'd obviously depend on exactly what you were wanting to do, but as a
basic example, you could for example push HTTP traffic through a Squid
install first so that you can perform specific actions based on the HOST
header, or perhaps the content-type in the response (perhaps to block ads?).
If you're talking about doing it for an entire network, it'd also allow you
to cache specific resources.
All of the above could make your traffic stand out, of course, but it's
technically feasible. In effect, what you'd be doing is creating a proxy on
the network (transparent or otherwise) and configuring it to use Tor for
its upstream connection (though if you're doing it at the firewall level,
Squid would never see such a config).
You could achieve that with what I described above, whether or not it's a
good idea would depend largely on why you're using Tor - what are the
consequences if you make a mistake in the setup? If you're simply trying to
prevent your ISP from seeing where you're connecting to, it's potentially
less risky than if your activities might cause LEA(s) to kick down your
Using TBB with it's default settings is a fairly simplistic configuration,
and thanks to the developers behind it, there's not too much that should go
wrong on the average deployment.
Every additional step you insert introduces an opportunity for you to make
mistakes (even if that's as simple a not thinking of a specific type of
traffic), so you need to carefully design your setup and do a cost/benefit
on the changes.
I experiment with Tor quite a lot, and, on the average day a good
proportion of the traffic leaving my network via Tor is probably me testing
something 'harmless' to see if I can catch myself out. Once I'm happy that
a technique works, it'll get used for something I'm more sensitive about.
One thing I would say - you have to consider failure scenarios very
carefully. If Tor silently fails on your router, what will happen with new
connections? Will they fail (you probably want this) or will they be routed
out in the clear (leaving you non-the-wiser).
All that said - If I was doing something really sensitive, or with serious
real world implications, I'd be using the simplest solution possible (i.e.
TBB) to minimise the potential for mistakes on my part.
B Tasker

@_date: 2015-03-16 11:12:23
@_author: Ben Tasker 
@_subject: [tor-talk] Are webmail providers biased against Tor? 
You'll likely see the same thing from anything that the provider considers
to be an anonymous proxy - i.e. it'll affect Tor exits but isn't
necessarily Tor specific.
It's reasonably normal, if somewhat irritating

@_date: 2015-03-27 19:38:38
@_author: Ben Tasker 
@_subject: [tor-talk] Alternatives to Tor Browser? 
That was largely my impression too - the title of the article is
'Alternatives to Tor Browser' and asserts that Tor is broken, but then
proceeds to list examples of software that use Tor as an alternative. If
you don't like TBB then I suppose it might have some value, but the thrust
of the article doesn't really align with the statement they start by making.
I think the author probably doesn't entirely understand the technology in
use, or to some extent the threats - "The NSA has attempted to break the
Tor browser?s encryption and has been successful to a small extent".
Subgraph's site/description does make it look quite hopeful. Even if it
were available though, I'd also be dubious about it given the small
development team when compared to the alternatives.
On Fri, Mar 27, 2015 at 6:54 PM, Speak Freely

@_date: 2015-05-21 11:10:35
@_author: Ben Tasker 
@_subject: [tor-talk] Mailpile SMTorP [ref: nexgen P2P email] 
I've been using Mailpile for a while, I've a few criticisms of it, but they
can mostly be forgiven for the fact we're not at stable yet. There is some
base functionality missing (like being able to delete emails rather than
mark them as trashed), but it's definitely a project worth looking at - the
devs are pretty quick to respond to issues/questions and generally have a
pretty clear idea of where they're headed.
Have been meaning to play around with the SMTorP functionality since the
PoC made its way in, but haven't really found the time.

@_date: 2015-05-22 10:52:24
@_author: Ben Tasker 
@_subject: [tor-talk] Mailpile SMTorP [ref: nexgen P2P email] 
What procedure did you use to try and make the package? I'm running
Mailpile and definitely don't have node set up.
If you're building the dev version, one of it's requirement's is nose so
perhaps there's a typo kicking about?

@_date: 2015-05-22 12:59:11
@_author: Ben Tasker 
@_subject: [tor-talk] Mailpile SMTorP [ref: nexgen P2P email] 
Actually, having taken a look, I stand corrected. Although it started off
as just Python, Node has seeped it's way in a little bit (in terms of if
you're wanting to build from source).
They're using Grunt (by default) to process LESS files, which requires
node, you've also got bower (that should have jumped out at me in your
Your make all, of course, builds the JS and CSS, which uses Grunt and Bower.
As far as I can see, Node is only used for automating parts of the build,
which to be honest makes it worse in my view - requiring a completely
different tool chain just to build?
You *can* run Mailpile without having Node installed by using the pre-built
binaries, just install the dependencies, but that's placing an awful lot of
trust in the repo (and the devs themselves).
There was a slight off-topic tangent about "why not use node" here[1] in
2013 but around a year later Grunt was introduced in Oct 14[2] (hadn't
realised my build was quite so out of date....). Not going to dig any
So, basically, you have two options
- trust the devs never to fold to pressure and tamper with the binaries
- Use node to build your own from source
Sadly it looks that way, though I doubt it's likely to change, I've been
waiting for the 1.0 milestone to see whether the other issues I have with
it get addressed. Some, I know, have as the GH issues have been resolved,
so I'm being patient with the other bits :)
[1] - [2] -

@_date: 2015-11-04 19:33:46
@_author: Ben Tasker 
@_subject: [tor-talk] Fwd: [tor-relays] Tor Project slandered? 
Sadly I don't think it'll make much difference. As a franchise, NCIS has
been publicly criticised for it's portrayal of tech and "hacking" for years.
My favourite being the 4 handed, no talking CND -
Basically, they don't and haven't ever given a toss about whether something
they portray is accurate, realistic or even possible.
The claim that 97% happens on the darknet is awesome though, especially
with the UK govt publishing the draft IPB today

@_date: 2015-11-13 11:17:46
@_author: Ben Tasker 
@_subject: [tor-talk] Fwd: [tor-relays] Tor Project slandered? 
True. After all, it's not like nothing untoward happens on "the clearnet".
To be fair to Hollywood though, at least the average person *expects* them
to dramatise etc. Not sure how I missed it the first time round, but in my
book, this by the City of London Police rates far worse -

@_date: 2015-10-01 12:31:16
@_author: Ben Tasker 
@_subject: [tor-talk] Making TBB undetectable! 
But if one has one fingerprint (the default TBB) and the other an
'undetectable' one, then you can easily differentiate that they are two
different users. They both came from Tor exits, so you "know" they're TOR
users, but one user changing TBB's signature means they no longer appear as
close to identical as possible.
Used once, sure. But over time, it's likely going to get used more than
once, unless you're planning on inserting some sort of randomisation to try
and prevent that (by making some aspect different each session), but that
randomisation then becomes a potential means to identify users who are
using "UnidentifiableMode"
I don't _know_ but I suspect it's actually the opposite - thought has
previously been put into the feasibility and risk and it's been decided
that the current approach should be safer. Making something "Undetectable"
is very, very hard as your margin for error is 0 (because 0.01 gives
something that someone could use to make it identifiable). Making something
common so you can blend into the crowd makes it easier to avoid
(potentially) costly mistakes.
Remember that those who are _really_ interested in de-anonymising via
fingerprinting are _very_ good at finding means to differentiate between
requests, one tiny slip-up is all it would take to make your
"Unidentifiable" browser extremely identifiable. You'd then (potentially)
be the only client with fingerprint a, coming from a Tor exit.
Even if you didn't slip up, let's say you make your requests look almost
exactly like vanilla firefox. If you're the only user using that mode at a
given time, every request coming from an exit with your fingerprint is an
opportunity to correlate that traffic back to you. There's no immediate
proof that all that traffic is you, but volumes would be low enough that
you could then start examining requests with an aim to trying to prove it's
all one user.
Blending into the crowd is not without it's value.
On Thu, Oct 1, 2015 at 12:09 PM, behnaz Shirazi

@_date: 2015-10-01 19:18:48
@_author: Ben Tasker 
@_subject: [tor-talk] Making TBB undetectable! 
when usability is considered; the manual effort each session is undesirable
at the very least :)
The problem you have there, is what to randomize, and how to do it in such
a way that it does not itself become identifiable.
To use an example, think about when you run cover traffic (whether over Tor
or a VPN), the initial temptation is to have random levels of data
travelling over the link. The problem there being it's not a 'natural'
looking flow of data when you analyse it. So when you use the link, your
natural usage is identifiable in the analysis.
So you go for something more 'natural', but natural's hard to fake, so your
cover traffic has an identifiable set of patterns, meaning on analysis you
can discount it and still tell when the tunnel is being used for real
When we're talking about making the browser unidentifiable as TBB, the very
act of having something in the fingerprint that changes to prevent
correlation between sessions provides an avenue by which it can be
identified as TBB:
Let's say you override reported screen width so it lies, and then use TBB
to sign in to (sake of example) Facebook. Every time you start a new
session and sign in to Facebook, your screen size is going to be different.
That's *very* unusual. User's screen sizes will change from time to time
(because they're in a window rather than full-screen, or on a laptop
instead of a PC) but to be different every time?
What about if you're signed in to FB in one tab, and browsing news in
another. The news page has a Like button on it, and Facebook get a
completely different screen size reported. You might just have the news on
fullscreen, and FB windowed, but again, for it to happen every time is an
unusual pattern.
A bit of research would soon tell them you're using TBB even if they hadn't
thought to see if the traffic was coming from an exit node.
only if we resolve the traffic source; i.e., Tor exits.
That's quite an issue to solve though. Even if we assume that the IP's of
tor nodes weren't being published anymore, analysis of traffic patterns on
a busy site would likely soon let you work out the IP's of some exits.
Granted, you wouldn't immediately know whether those sources were Tor exits
or simply proxies being used by multiple users, but finding out wouldn't be
impossible. A determined adversary wanting to map out Tor exits could
simply initiate a lot of connections via Tor and keep a record of where the
other end (under their control) sees connections come from.
Not as accurate as downloading the relay list, but depending on your aims
you wouldn't need 100% coverage, so in the absence of the list it'd
probably do. It raises the cost of identifying Tor exits, but only so long
as the resulting list isn't then published (and kept up to date).
As others have said though, the aim isn't to hide that you're using Tor
from your destination, and successfully doing so would (IMO) be a pretty
non-trivial task

@_date: 2015-10-03 23:01:57
@_author: Ben Tasker 
@_subject: [tor-talk] Making TBB undetectable! 
But if you're doing something (in the adversary's eyes) that serious, it
probably doesn't matter whether they can tell you're using TBB or not.
Either way, they're going to look at ways to identify you. Being one of a
crowd of Tor users likely offers more protection against that than trying
to make it difficult to identify that you're using Tor.
The issue I have with the idea of private exits, is that not everyone can
use them. In other words, if you're using one, then you can be (however
loosely) associated with other users of that node. You all got
access/permission somehow, so you are now incredibly reliant on other users
not slipping up, and on the owner/operator not being traced.
If you've simply paid BTC for access, you then have to be very sure you've
not slipped up (simple examples: re-used a wallet, or funded one from fiat
Personally, I'd prefer a public exit, it's harder to associate users and
there's less room for making costly mistakes.
Those are a list of the requests we know are differentiators, it doesn't
mean that others won't be discovered, you'd need to gamble that anything
found is publicly disclosed when it's found, rather than kept quiet by an
adversary. What you're essentially asking for is a browser that behaves
like TBB (i.e. the various privacy protections) whilst pretending it
behaves like a Google Nexus (for example). It's not that it'd be impossible
to do, but one tiny mistake or oversight takes you straight back to being
finger-printable, and almost uniquely so if very few are using
Unidentifiable Mode.
Yes and no. You can't just run a list of add-ons off using Javascript,
however a fairly simple side-channel attack is to try and load images from
add-ons you care about detecting. If the add-on is installed and has
contentaccessible set (and your path is valid) then it'll load, if not,
it'll fail.
So, you can fairly easily poll for various add-ons. Not sure it'd affect
your add-on, but seemed worth mentioning.
How do you do this without breaking certain sites? For example, if my JS
configures absolute positioning based on screen-size (yes, it's a bad way
of doing things, and yes I've seen sites do it) then you reporting back a
600px screen is going to look terrible on a 1280.
You'd need to be very careful about where your private exit is located. If
it's in a datacentre, then no-one's going to mistake it for a cafe (for
example). An adversary with sufficient resources would also soon be able to
look at data-rates to and from your box, as well as sources - shouldn't
take them long to realise it's communicating with Tor relays.
True, the difference here being that you're talking about something that
would be happening on a much smaller scale, and attempting to closely
replicate 'normal' fingerprints. A tiny mistake would be enough to
differentiate you from the 'normal' traffic, as well as from the 'standard'
TBB profile.
To be clear - I meant it wasn't Tor's aim.
But not to hide that we're using Tor from the destination.
Making it correctly is not trivial, you have no room for mistakes,
otherwise you risk becoming more fingerprintable than vanilla TBB
Assuming we're talking about an unmodified TBB? I'd start by trying to
ascertain whether no-script is enabled. Working out whether HTTPS
Everywhere is enabled should be fairly trivial too. There are, of course,
plenty of people who run those in combination outside of TBB, but it's a
reasonable starting point for narrowing things down.
Someone who's suitably motivated will spend far more time and resources
looking at the minute differences in order to build a fingerprint.

@_date: 2015-10-06 20:57:53
@_author: Ben Tasker 
@_subject: [tor-talk] Tor Browser and my location 
Google will redirect you to a region specific version of Google based on
geo-location of your source IP. This the the IP of the Tor exit node you're
using, which is why it differs to your location.
If you set your homepage to  (append the query
string you want to use if desired) you should stay on the .com domain
On Tue, Oct 6, 2015 at 8:48 PM, Kit Carson McGuire

@_date: 2015-10-06 21:18:47
@_author: Ben Tasker 
@_subject: [tor-talk] Tor Browser and my location 
You'll want that to be  (note
the lack of trailing slash)
But, it looks like it strips the query string when it redirects you to
google.com though, so it may not be possible to keep the noj & gws_ssl.
On Tue, Oct 6, 2015 at 9:04 PM, Kit Carson McGuire

@_date: 2015-10-16 17:28:03
@_author: Ben Tasker 
@_subject: [tor-talk] Get Tor bridge via python code 
would need to support CAPTCHA-like (proof-of-humanity) functionality
The captcha on bridges.torproject.org isn't so much as proof of humanity,
as proof of humanity with absolutely impeccable eyesight. Either those
things are even harder to read than they appear, or cloudflare have given
someone at the Tor project stockholm syndrome with their own captchas.
On Fri, Oct 16, 2015 at 5:04 PM, Matthew Finkel

@_date: 2015-09-24 12:28:29
@_author: Ben Tasker 
@_subject: [tor-talk] Multiple IP's 
That would mean hitting the game servers from two different IP's, but
Bans/Notifications that im using 2 accounts
Which account you're using is an application level (based on authenticating
with the game servers), so there's no easy way around that (other than
actually using two different accounts). You've got to authenticate with the
remote server, so there's no way to make it think you're using a different
account without actually doing so.
Unless I'm misinterpreting the question?

@_date: 2016-04-02 16:55:49
@_author: Ben Tasker 
@_subject: [tor-talk] Tor and child pornography 
about a popular hidden service being attacked,
service due to "legal", e.g. traffic shaping attacks
Personally, I think you're making unfair assumptions there. If someone
comes on the list and says "I can't access abc.onion" then that email
address is publicly linked as being operated by a visitor to abc.onion. It
might be that the content of abc isn't all that objectionable, but isn't
legal wherever they're viewing from, it could also be that the person
simply doesn't want to be "publicly" associated with the content, again,
despite it being legal.
And yet the Parliamentary Technology Group recently noted in a report that
most paedophiles, in fact, do not use Tor because they find it too slow.
It's commonly stated that that kind of content exists on hidden services,
and it certainly does to some extent, but a haven? Hidden services aren't
exactly crawling with it, especially in comparison to things like Freenet.
See also the Reddit thread (sorry haven't got a link to hand) where a self
confessed child porn consumer talks about his experiences trying to find
new content on Hidden Services.
The research you refer to also had a number of concerns about methodology
and findings raised. Not least that the methodology they used would have
been positively affected if LE organisations were (as they almost certainly
do) regularly checking if known sites were still online
abuse? I do not think so.
Here, I agree with you. But I'm not sure I agree that that's what's
actually happening, at least not on a sizeable scale.

@_date: 2016-04-23 20:49:00
@_author: Ben Tasker 
@_subject: [tor-talk] Roger 
I think you've mis-attributed that quote. It was sent by Juan in response
to a mail from Roger

@_date: 2016-04-23 23:44:35
@_author: Ben Tasker 
@_subject: [tor-talk] 12.7 percent of the domains I visit are intercepted 
Keep in mind that Cloudflare is essentially a glorified bunch of reverse
proxies. Because Cloudflare terminates your TCP connection to abc.com,
they're in a position to set cookies _as_ abc.com. So I'd fully expect the
site name to be abc.com, though it's naughty of them. The browser won't
consider it thirdparty, because it isn't - it was set by abc.com. This does
seem to be the case (picking a site that uses cloudflare randomly from a
$ GET -Ssed   | grep Set-Co
Set-Cookie: __cfduid=dfcadd8517f9edb7f6fd202c7152da9861461451390;
expires=Sun, 23-Apr-17 22:43:10 GMT; path=/; domain=.absolutewealth.com;
What it does mean, though, is when you visit xyz.com, the browser won't
present the cookie set earlier by abc.com. So it's use in tracking across
domains is incredibly limited. Pretty useful for tracking return visits to
abc.com (and it's subdomains) though

@_date: 2016-04-25 00:13:31
@_author: Ben Tasker 
@_subject: [tor-talk] 12.7 percent of the domains I visit are intercepted 
implication / danger of one entity setting  cookies on multiple or 1000's
of  sites?
In theory it shouldn't be an issue, so long as they can't somehow tie the
multiple cookies together.
The problem being there are a wide range of fingerprinting techniques they
could use to do just that. On the flipside though, if they're willing to go
to those lengths then the cookie doesn't add a huge amount of value to
their operation. The potential risks, really, are more a product of one
party being the endpoint for so many sites.
CF claim that cookie is used only to indicate you got past security -
- which is _probably_ true.
If they were setting a third party cookie (e.g. with a domain of
nottrackingyou.cloudflare.com) it'd be a slightly different story, as
they'd then be able to track you across domains, based on that cookie.
data on cookies & IPa's to tracking companies or advertisers.
They sure do. Some go even further -  a little while back Verizon decided
to add a unique (to the subscriber) HTTP header to any outgoing (mobile
IIRC) requests so that their advertising buddies could easily track their
users and generate some revenue. Completely transparent to the user, unless
you happen to take a PCAP at the other end, or visit somewhere that
displays the request headers it received from you.
It had the particularly "pleasant" side-effect, that if you deleted
cookies, when the advertising platform next saw you, it'd set a new one,
pull the UID out of the injected header and link your new ID to the old one.
Selling individual (first-party) cookie details isn't particularly worth
while, even for a large site, as advertisers generally see more profit in
profiling your behaviour as far across the net as possible. IP's are in a
similar position, though I suspect they have some value if you're able to
show one user always visits your site from IP 1.1.1.1 - indicating they
either use a single proxy as a matter of course, or they've got a static IP
on their home connection (ker-ching, easy tracking)
do - just to take a peek, or it won't work right.  Maybe that's because the
cookies can be turned into cash?
That's definitely a driver for some. But, back in the day, most sites were
static and users interaction was largely limited to reading. A lot of sites
today run on content management systems, so will set (at least) a session
cookie in case you try to do something that would require a statefulness
(even if there's nothing like that enabled on the site....). There's also
(IMO) an aspect of laziness/stupidity - you can find sites where the
developer has decided that controlling the theme and page layout is best
done by setting a shedload of cookies and then reading them back with

@_date: 2016-08-08 12:18:35
@_author: Ben Tasker 
@_subject: [tor-talk] Am I successfully using Torsocks, SSH, 
If you're using Firefox, one thing you want to consider is DNS leakage.
If you go into about:config, see whether network.proxy.socks_remote_dns
exists. If not create it and set to True.
Without that, DNS won't use the tunnel. As you've got a VPN running it'll
likely egress from the VPN endpoint instead.
---> Internet.
How do you pay for the VPS? If it's in your name (or can be linked to you)
then all you're doing is preventing your local ISP from seeing what you're
connecting to (which might, of course, be your aim). You do, in effect,
have a fixed exit point though, so it's worth bearing in mind that in some
ways it makes you more identifiable from the point of view of services
you're connecting to.

@_date: 2016-08-08 16:41:33
@_author: Ben Tasker 
@_subject: [tor-talk] Am I successfully using Torsocks, SSH, 
arise with a VPN service.
Depends on a few things including whether the account can be linked to you
in some way. Also depends on whether the service keeps logs, and there's no
way to tell whether claims they don't are true.
Over time, I'd imagine always using the same endpoint (on services that let
you choose) probably does you some harm too, especially if there's anything
(like unusualish user-agent strings) that act as an otherwise weak
identifier, with that being accelerated if you often log into google,
facebook or anyone else with an interest in tracking you across the net

@_date: 2016-08-10 11:12:34
@_author: Ben Tasker 
@_subject: [tor-talk] Am I successfully using Torsocks, SSH, 
Wouldn't go so far as to use the word expertise ;)
You're using vanilla firefox, so if you haven't already, take a close look
at any plugins/addon's you've installed. Some are known to ignore Proxy
settings (flash being a primary example).
Conversely, look at whether you're using anything outside of Firefox that
might use Firefox's proxy settings without you realising (at least one of
the FOSS Java runtimes does this - I think it was OpenJDK but don't hold me
to that as I can't remember for sure) - if it's sending traffic out that
can be linked to you then you're now associated with the VPS. I'd be
inclined to set a packet capture running on the VPS, use your system
normally for a while and then review the capture to see whether anything
unexpected has gone out (it's unfinished, but this might help -
 )
The VPN means you also have a fixed entry point (if you think of it as an
additional hop), one you share with others (so there's a small risk in
getting caught up in a net meant for someone else), so you probably want to
check exactly what's going out over the VPN aside from your Tor traffic -
in part to check there's nothing directly attributable to you (though
you're connecting to the VPN directly, so they have your IP) - but also to
check there's nothing "related" to your Tor browsing (essentially an
extension of the check above).
I'm sure others with more experience will have input, but the network path
you've set up looks OK to me, so long as you're comfortable with the
ramifications of having a fixed exit point. Your biggest risk probably
comes from anything that might ignore the proxy settings, or from software
unexpectedly using the proxy, once you're linked to that VPS there's no
going back.
the IP. The ideal model would be: VPN -> Torsocks (on 127.0.0.1) -> SSH
(bound to port 33333) -> VPS -> Proxy (e.g. HTTP(S)) -> Internet.
Given that your stated aim is to avoid being blocked out of sites by coming
from exit node addresses, adding a proxy end might undermine that -
some proxies (at least) are blocked by various sites, and you'd also be
back to being exposed to some of the risks of having your traffic tampered
with by a third parties system.
However, if you really wanted to, one way would be to put Squid onto the
VPS with a transparent redirect, and then tell Squid to pass the traffic
onto whichever proxy (or pool of proxies) you wanted to use.

@_date: 2016-12-04 13:41:38
@_author: Ben Tasker 
@_subject: [tor-talk] Hacker and Tor (thank you) 
There's no more evidence that the OP is an Islamic terrorist than that he's
perhaps someone on the receiving end trying to identify someone who keeps
compromising his server. It's quite likely that neither's actually true.
And, even if it were true, on balance I think it's probably better for the
world if Islamic Terrorists did suddenly shift their focus from bombing to
hacking the kind of server you'd normally find running CPanel.
But, I agree, the way the question was phrased is somewhat questionable.
Yes, let's keep basic chemistry from kids in case they grow up to be
nut-jobs. Building a bomb is not difficult (though doing it without
accidentally triggering it is somewhat harder), and restricting information
that might lead one to learn how to do so means far more than taking down
"howto's", the entire chemistry curriculum needs to change, and there are a
number of household products we'll need to take off the shelves.
The point I'm trying to make, is restricting basic information "just in
case" doesn't work.
Every time some identifies a vulnerability and releases a PoC they're
providing arms that can be used against users that haven't updated yet. On
the other hand, without that PoC other similar projects can't look for
similar vulnerabilities in their own codebase without looking at the
commits that fixed the issue (which is exactly what the bad guys will do).
So the information's still available, we've just made it harder for the
issue to be fixed elsewhere.
Had someone piped up and said "actually, yesterday I found a way to have
CPanel de-anonymise you" the result would have been that someone looked to
see what weakness in the browser allowed it, and users (genuine or
otherwise) would all have been better off.
So yeah, don't directly give help for things you don't agree with, but
trying to outright shut down discussion is counter-productive. Especially
when the steps needed to maintain anonymity can be applied to a wide number
of legit use-cases.
It's worth noting, purely because I haven't seen it elsewhere. Using an
online browser leakage test is only indicative. If someone's privately
discovered a new way to achieve leakage, the leakage tests aren't going to
show it (at least until they become aware of the technique).
Seconded. HMA are a UK registered company, and with the IPA having just
received royal assent there's a good chance HMA are going to be forced to
log connections (and possibly worse). In principle, that's only an issue if
you come to the attention of law enforcement. In practice, there's a good
chance that the Government is going to apply it's usual skills to the IT
challenge and wind up leaking ICRs all over the place.

@_date: 2016-12-22 11:49:53
@_author: Ben Tasker 
@_subject: [tor-talk] Not comfortable with the new single-hop system 
insulting to users, we say the actual reality of the situation is that
people use TOR who arent computer experts and sane defaults are a needed
thing, to help keep people safe.
You mean the default where it's off, and you need to deliberately set TWO
different config variables in order to enable it? How is that not a sane
default position?
You mean if they deliberately enable settings that are clearly labelled as
reducing the anonymity of the hidden service?
out of programming since they made logging default on for OTR+Pidgin.
Except this isn't defaulted to on, and you'd have to screw up pretty
heavily to turn it on by accident.
Personally, I don't see an issue here that hasn't been addressed by devs
earlier in the thread
On Thu, Dec 22, 2016 at 11:21 AM, laurelai bailey

@_date: 2016-12-23 15:04:57
@_author: Ben Tasker 
@_subject: [tor-talk] [off-topic] linux firewall 
Depending on what options your kernel was compiled with, you may be able to
do this -
Otherwise there's Douane -  - no idea if it's any
good, or leopardflower
old /= broken
As Sebastian said, AFWall+ is just a front-end for iptables.

@_date: 2016-02-21 20:18:34
@_author: Ben Tasker 
@_subject: [tor-talk] Is it possible to use Tor without showing a Tor IP 
for using your real name and account?
Providers do exist that don't ask for details and accept payment via
Bitcoin - so it's not impossible to do in such a way that simply
threatening the provider won't be sufficient.
Personally, though, I think it's easy to underestimate/miss some of the
risks inherent in chaining connections like that. More does not always lead
to better privacy/security. If I was going to do it though, I think I'd
probably run a hidden service on the VPN VPS rather than wasting exit
On Sun, Feb 21, 2016 at 8:12 PM, Anders Andersson

@_date: 2016-01-15 19:36:24
@_author: Ben Tasker 
@_subject: [tor-talk] Escape NSA just to enter commercial surveillance? 
By using a proxy, you're placing trust in the proxy operator, both to have
configured things appropriately (I've seen some advertised as anonymous
where X-Forwarded-For has been left enabled, deliberately or otherwise) and
not to be actively malicious (i.e MiTM), or a honeypot run by another
entity you don't trust.
With the HS, you're trusting Tor. Advance as many theories about the US
Govts involvement as you like, but you're unlikely to convince me they'd
sacrifice the outwardly displayed principles to help Facebook.
No, but in Facebook's case you'd need to compromise the HS's private key
and obtain a publicly trusted TLS cert issued for that HS.
Not impossible, but certainly challenging.
Theoretically, someone could try and attack the dirauths or another part if
the infrastructure you hit before Facebook, but would it be worth risking
detection for Facebook?
In both setups, there's the risk FB themselves could try and implement
something to identify the user's location of course, but that's a different
kettle of fish.

@_date: 2016-01-17 13:50:58
@_author: Ben Tasker 
@_subject: [tor-talk] Multicast Onion Services for video-streaming? 
I don't have an answer on the multicast front, but I've been playing around
with Video delivery via onion recently - partly as an intensive way to test
delivery and partly to see how feasible it actually is.
The delivery infrastructure was/is a tiered caching heirachy, with each
tier having it's own HS
I'm not quite ready to write it all up yet, but as it partly ties into your
question figured I'd mention some of what I've observed so far.
HTTP Adaptive Streaming (HAS) works well using hidden services (I've
primarily been using HLS), subject to a couple of caveats.
- If the edge cache has to go upstream (to the midtier), it's incredibly
expensive and introduces substantial delay.
- There seems to be a risk of circuit collapse if a cache is taking too
many requests. If that cache happens to the midtier, then you're stuck
unless there are multiple caches in the midtier or the edge is also allowed
to go to the origin.
Caveat 1 can be offset by increasing the video segment length. 2 second
segments were nigh on unwatchable, whereas 10 second segments play pretty
I haven't checked in depth yet, but the acquisition times look about the
same for both, so it's possible the overhead is in establishing a circuit
rather than necessarily how quickly the bits can be delivered to the edge.
1080p video at 60 fps is do-able but highly unreliable (but then, it's the
same on the clearnet). Compression could help here.
480p works reliably. I've not got as far as 720 yet.
My theory on the bandwidth consumption side was that each edge device could
be capped at a certain throughput (say 100Mb/s for easy maths). A number of
new relays could then be added to contribute back the same (or more).
So, 6 edges, means adding 3 200Mb/s relays.
Alternatively as it's tiered, the edge knows nothing about the origin, so
you could conceivably have the edges also act as relays.
There's a bit of setup involved, but then even on the clearnet, delivering
video to a lot of clients requires a bit of infrastructure.
On 17 Jan 2016 12:08, "Fabio Pietrosanti (naif) - lists" <

@_date: 2016-06-06 13:36:29
@_author: Ben Tasker 
@_subject: [tor-talk] Any updates from Tor Project on ioerror? 
for the rule of law and the need to stay silent until "real proof and
evidence is provided".
Dunno about staying silent, but the creation of that website was a long,
long step over the line IMO.
A site in ioerros name containing multiple allegations with no evidence
provided, a somewhat malicious twitter link and no real re-course for an
easily found response. Nothing wrong with that whatsoever /s
But then, it ties into a bugbear I have with how various legal systems
handle this type of accusation. I 100% understand some alleged victims
might want to remain anonymous (in this and other cases). But given the
harm an allegation (even if unfounded) can wreak on it's own, the accused
should similarly be entitled to anonymity up until the point of conviction.
Other than that I don't like how the whole thing has been pursued (if
that's the right word), personally I'm making no judgement - it's not my
place and there's not nearly enough information available to know whether
there's any truth to it anyway. I'm also not particularly inclined to think
that any evidence should be publicly aired, outside of actual legal
FWIW, though, based on a quick read, I can easily see Nick Farr's story
boiling down to an incompatibility in personas/approaches rather than a
deliberate malicious campaign waged against him. Doesn't mean it was/wasn't
the case.

@_date: 2016-06-08 23:33:21
@_author: Ben Tasker 
@_subject: [tor-talk] Reddit user babalui1 claims that Roger Dingledine is 
Meh, wouldn't put any weight on anything being posted in /r/TOR at the
About 24 hours after "news" broke, a similar account (in the sense of being
brand-new with no other posts) posted the news that Jacob had committed
suicide as the result of the accusations. Post seems to have gone now

@_date: 2016-06-13 08:08:53
@_author: Ben Tasker 
@_subject: [tor-talk] 2 hop mode for people that only want to use Tor for 
Even aside from LEO's turning up, there's another issue with this. Any
service that blocks Tor exits will block your IP so you'll lose access to
pages you could normally access. Some sites don't limit themselves to
blocking exits, so even running a relay at home can have this effect.
As Ivan said, if someone takes an interest it's also possible to
distinguish which traffic originated from you and which came in from a
downstream relay, so it doesn't give quite the protection T F is
suggesting. Also, as Ivan said, it's a completely useless solution if the
aim is to circumvent downstream censorship
As well as the oft-quoted "there's no smoke without fire", or "there must
be something to it, or the case wouldn't have reached court"

@_date: 2016-03-07 23:30:04
@_author: Ben Tasker 
@_subject: [tor-talk] Transparent proxy question 
TCP channel?
Afaik, no. But you could configure the remote machine to transparently
proxy and then on your router configure interesting traffic to use that as
a gateway - I use Policy Based Routing to direct port 80 traffic to my
squid box and it works a charm.

@_date: 2016-03-14 13:16:29
@_author: Ben Tasker 
@_subject: [tor-talk] Torsocks plus ssh plus command line browser - does 
(not TBB).
There are potentially valid reasons for doing it this way, but is there a
reason you're not thinking of doing
ssh -D 8080 myvps
And then pointing (say) Firefox at the local socks port on 8080. (i.e. all
steps the same except C - so still routing to the VPS via Tor).
You'd want to make sure you could acquire the VPS anonymously, there's
little point in having Tor in between if the connection appears to
originate from a VPS registered in your name, with your card as the billing

@_date: 2016-03-14 16:52:57
@_author: Ben Tasker 
@_subject: [tor-talk] Torsocks plus ssh plus command line browser - does 
same time?
As before you're using Tsocks to route your SSH connection out over Tor.
Alternatively, if you've got TransPort running (in the example on 9050) you
can pass the following to SSH to achieve the same
    -o ProxyCommand="nc -X 5 -x localhost:9050 %h %p"
You'll also want to disable verification of the Host Key via DNS (to help
prevent leakage)
   -o VerifyHostKeyDNS=no -O CheckHostIP no
I have this set up in my ssh config file (~/.ssh/config) for various hosts
that run SSH as a hidden service, e.g.
    Host myOnion
      Hostname domain # This should be your .onion
      User user # Whatever username you connect with
      IdentityFile ~/.ssh/sshhs1.rsa
      ProxyCommand nc -X 5 -x localhost:9050 %h %p
      VerifyHostKeyDNS no
      CheckHostIP no
      IdentitiesOnly yes
As a slightly shameless plug, more here -
- including a few bits you might want to look at setting on the VPS itself
The -D flag tells SSH to enable Dynamic port forwarding. SSH will then
create it's own SOCKS proxy, and then torsocks will divert SSH out over
Tor's connection (personally I prefer the transparent mode I mentioned
If you wanted to forward a specific port to a specific host, you could
instead use -L, for example
    ssh -L 8080:example.com:443 myvps
Then when you visit  you'd get example.com (though
obviously the certificate validation would fail). I used 8080 there as 443
is a privileged port so you'd need to run your SSH command as root to bind
to it.
Incidentally, if you do decide to use Firefox, be aware that by default it
*doesn't* honour the Proxy configuration for DNS, so you'd get some
leakage. To resolve that, do the following
    about:config
    Create a new boolean called *network.proxy.socks_remote_dns* and set it
to True
Depending on what you're accessing and why, you'll want to keep your
"forwarded" browser seperate from your day-to-day clearnet browser.

@_date: 2016-05-04 09:46:03
@_author: Ben Tasker 
@_subject: [tor-talk] 'Refresh tor browser' - and then it wasn't one 
Is that the "Haven't seen you in a while" type message?
I've had a few problems with false positives triggering that in vanilla
firefox, to the extent I've now got a logout script that
removes ~/.mozilla/firefox/*/.parentlock (as the message is triggered based
on the mtime of that file). IMO that's probably un-needed functionality in

@_date: 2016-10-16 11:29:23
@_author: Ben Tasker 
@_subject: [tor-talk] Quote Line Prefixes in Linux Text Editors 
I may be remembering the wrong incident, but I thought the Engimail issue
was (arguably) a little less serious than that - it was sending certain
headers unencrypted, so whilst the content was still encrypted there was
additional metadata available for analysis. Not great for sure, but a
little lower on the scale than described (and if that bug were still
present, composing in a text editor still wouldn't help). Might be some
other bug though?
The claws thing was bug 2965 -
 -
when sending a mail, the unencrypted version was written to the Queue
folder (and written to the server via IMAP) before being encrypted and sent.
I recall seeing something similar and less MUA specific as well, again
relating to the fact that drafts were being saved to the server, can't
remember where I saw that but here's an OS X specific one -

@_date: 2016-10-24 13:27:32
@_author: Ben Tasker 
@_subject: [tor-talk] Tor and forward email to Spam folder. 
Gmail tends to add a header containing your client IP - X-Originating-Header
I've never looked to see whether any spam filters are set up to use it
though. If they were to, they'd see the IP of an exit node so might mark as
spam based on that.

@_date: 2016-10-24 13:57:00
@_author: Ben Tasker 
@_subject: [tor-talk] Tor and forward email to Spam folder. 
Send an email to another account you control (might work sending to
yourself, I've not tested).
Then in the receiving mail client choose "View original", "view headers"
 or similar. It'll probably be one of the lowermost headers

@_date: 2016-10-30 09:21:54
@_author: Ben Tasker 
@_subject: [tor-talk] Tor and forward email to Spam folder. 
You've snipped out more than half the headers, so obviously none of the
information's there.
If you're checking mail that's come via a list, the header won't be
included in the mail that the list sends onward (so you can't, for example,
walk over mails from tor-talk and grab people's IP).
Send your Yahoo account an email directly from your gmail account (using
the web interface) and then look at the headers. It should be there, though
taking a quick glance at Google's docs it looks like they sometimes don't
include it -  see also

@_date: 2016-10-30 13:21:02
@_author: Ben Tasker 
@_subject: [tor-talk] Tor and forward email to Spam folder. 
That's not strictly true.
Under various circumstances, when using webmail, google will add an
additional header - X-Originating-IP - which contains the IP of the client
(i.e. your browser) connected to the webmail interface.
Once upon a time, Hotmail used to do it to, though they moved to using a
hashed version (and X-EIP as the header IIRC).
You won't see the webmail client in "received from" headers though.

@_date: 2016-10-30 14:49:07
@_author: Ben Tasker 
@_subject: [tor-talk] Tor and forward email to Spam folder. 
So, it seems there are some differences which decide whether Google will
include the client IP when using the web interface.
If you're using an "Apps for domain" account, the X-originating-ip header
will be added *every* time, whether you use Webmail or the "Gmail" app on
If you're using a  address then it's not so consistent. I've not
tracked down exactly what the difference are, but it adds it some of the
Doesn't seem to be purely related to logging in from a new IP, could
perhaps be related to the "reputation" of the IP you're connecting from?
IPv4 vs IPv6 doesn't make a difference as far as I can see. Presumably they
only add it when they consider the connection is possibly a risk, otherwise
you'd never add it (or always add it).
So the fuller answer, I guess, is "perhaps"

@_date: 2016-09-12 13:54:49
@_author: Ben Tasker 
@_subject: [tor-talk] Anonymous SSH Hack. 
I'm not going to comment on the attack side of your post as, if nothing
else, this isn't really the forum, but the following is probably worth
noting in terms of potential leakage when SSH'ing over Tor.
You probably want to pass the following
     VerifyHostKeyDNS=no
Don't attempt to do lookups of the host's key fingerprint - those queries
will go out over your local connection
     CheckHostIP=no
Don't do a DNS lookup of the host, the Tor exit node's going to do that
anyway, and again, the queries will be observable by your ISP
     PubkeyAuthentication=no
Don't present any public keys which you might have configured the SSH
client to look for. They can be logged at the remote end
Instead of running connect, you can also use Netcat to pass traffic to Tor
    ProxyCommand="nc -X 5 -x localhost:9050 %h %p"
On Mon, Sep 12, 2016 at 1:29 PM, Andrzej Wysocki

@_date: 2016-09-12 15:56:53
@_author: Ben Tasker 
@_subject: [tor-talk] Anonymous SSH Hack. 
Yes, On a second look, I think you're probably right

@_date: 2017-08-10 08:50:10
@_author: Ben Tasker 
@_subject: [tor-talk] Motivations for certificate issues for onion services 
For me, this is a primary motivation in wanting a DV cert.
A number of my sites (for example  are
dual-homed between the WWW and Tor (it's also at
 ). I terminate the client's plain HTTP and
then use HTTPS for the backhaul to the webserver(s), which in principle
feels wrong....
Of greater concern to me, though, is it means there are various things that
I either can't do or are fairly risky to do. Even down to simple things
like adding HSTS headers to the site - if I miss stripping just one on the
torified end then bad things are going to happen. It also means I can't
mark cookies as secure only (not such an issue on the site above, but can
be an issue elsewhere).
For my own site, I don't need the anonymity (it's plastered with my name,
so, yeah), I *could* get an EV, the barrier there is the price - it's just
not (IMO) worth it, especially when you start talking about multiple
different sites. But, the "cost" I'm paying at the moment is increased
complexity in my config and back-end, increasing the risk of me having made
a mistake somewhere in there. And that's for a fairly simple (functionality
wise) site with an off-the-shelf CMS as the backend. It can easily get more
complex (further raising the risk).
As Alec alluded too, there's also a trade-off. Either your tor endpoint
talks to the backend via HTTP, or (as I do) you use HTTPS for that
backhaul, but then have to monkey about in the back-end to have it know
that although the connection appears to be HTTPS there's a whole host of
things that you cannot use.
This too, and as I understand it (unless things have changed), Firefox's
intention going forward is to increase the number of features that are
HTTPS only. Which isn't necessarily a bad thing, but it does mean that
useful features may increasingly become unavailable to hidden services. For
a multi-homed site, that's something of an issue because you then have to
decide whether to not use those features at all, or to further complicate
things by only using them on the non-Tor connections (and put up with user
complaints that X should be available via Tor too).
When you look at the acceptable steps for proving control of a domain, on
the clearnet, yeah. Simply putting a specific file in a specific place is
sufficient for validation nowadays, despite the relative ease of messing
with DNS and BGP for long enough to pass the 'test'. In comparison, having
to have the correct key seems like a much higher burden of proof.

@_date: 2017-08-30 15:07:37
@_author: Ben Tasker 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
That's not quite the claim he's making though. He seems to be claiming any
"legitimate" (in his eyes) service shouldn't mind sacrificing their own
anonymity by being linked to a clearnet identity and becoming a "verified"
onion to avoid the rolling rotation. He uses examples of some who've
already done that (by having an easily findable clearnet site - like
Facebook and DuckDuckGo) whilst sweeping other legitimate users under the
rug with a handwave of "they should be fine".
So his suggestion is portrayed as not sacrificing much, but actually
sacrifices quite a lot.
The comments are fairly telling as well, he notes that political dissidents
could just have a clearnet site in a "friendly" country to verify their
in the United States or Europe and have it point to the current unvalidated
name. Or they can just use a friend's Internet site (located in a friendly
country) for the validated onion name.
Which (IMO) kind of overlooks the additional risk it puts onto them. That
site may be in a country that respects freedom of speech (and so will stay
up), but there's now another potential vector for their unfriendly
government to link their writings back to their real life identity.

@_date: 2017-08-30 15:19:59
@_author: Ben Tasker 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
Succinctly put.
Yes, that'd be my reading of it.
The alternative is that you are free to speak/write, but no-one can ever
find you because your onion address will change every week, so any coverage
you might get of an issue will last, at most, a week.
Meanwhile, the drug-markets and other "vile" things he want to block will
carry on unabated because a subset of their users will put the effort in to
update a central resource weekly to note what the new address is. If that
user is an administrator, they could even sign the updates with a
predisclosed key to minimise the likelihood of you being lead to a fake by
a bad actor. So everyone else gets shot in the foot, while what he wants to
block only blinks briefly.

@_date: 2017-08-30 15:36:57
@_author: Ben Tasker 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
Yup, or, it's entirely successful in it's aim and none but the most
determined can use the markets. Which results in the alienated users now
buying back off the street, getting a lower quality product and putting
themselves in greater physical danger. Essentially reclaiming the hold that
cartels and the like have historically held over the street (not that it's
weakend much, but any reduction is still a good thing).
Intensely dumb is about right. There are a good number of examples around
the world now of a better way to approach it, but it's going to be a very
long time before sense kicks in sadly.

@_date: 2017-08-30 16:32:11
@_author: Ben Tasker 
@_subject: [tor-talk] Neal Krawetz's abcission proposal, 
Yup, sorry I used the term cartel there very, very loosely. The actual
cartels have just expanded their distribution methods to include the
markets (and why wouldn't they), as have any, err... local traders where
the opportunity allows. Not moved, just expanded (just as you might go to
the shops when you need something sooner than Amazon can get it to you,
you'd still see the guy on the corner from time to time).
What it has done though, is given people the opportunity to more easily
obtain drugs without having to wander to the dodgy guy on the corner (in
turn lowering the risk to themselves).
Oh, definitely. But you can't address violence in all areas at once, and
reducing it in one area (final distribution) inevitably means that some
will move upstream (due to increased demand, stemming from increased
convenience etc), and the violence that already existed upstream will
No, I think you've got the point mostly. I think you're slightly
overestimating the size of the smallest measures being sold on some of the
markets, though prices tend to be a little higher (generally because of
increased quality, but also because the market will bear it), but there's
still a huge market in the real world too - both people who are unable to
access the online markets, but also the opportunists (i.e. I fancy
something tonight). Those who've got and have had a life-controlling habit
for quite some time are fairly likely to fall into the former group, and
are probably also amongst the most vulnerable in terms of being ripped off
or subjected to violence (even if no-one could shop online).
I think you hit the nail on the head though, simply decriminalising it
isn't enough, as that leaves the manufacture and distribution in the hands
of criminals.
It needs to be legalised and regulated in order to start addressing the
issues that exist in the supply chain itself. Even then, as you say, it'd
need to be more or less world-wide to finally "win", but again you can't
address all the harm at once, so a few large countries would still be a
step in the right direction. Even then, there'll still be a black market
(see Cigarettes, Alcohol and Firearms for examples), but the leverage that
market is able to do will be greatly reduced. The criminal gangs will
probably move onto other "produce", and the next war will start. But in the
process we'll have stopped criminalising people who were simply
recreational users as well as making sure those who continue to use are at
least getting the substance they expect.

@_date: 2017-06-15 23:10:49
@_author: Ben Tasker 
@_subject: [tor-talk] Improved sharing of .onion links on Facebook! 
services which have opted in - helps visit the service's equivalent regular
Pity this wasn't a link to, or a reference to how to do so included. I'd
have no issue with opting some of my multi-homed sites into that, but I'm
not so bothered that I can be arsed to google around for information that
probably exists, if anywhere, on a single page.
suspect that they are making lists of people using TOR!
Quite possibly, but my experience has been they're not actually quite as
good at the tracking as they'd like to be. I had to test a foreign app for
work, which I signed into using my facebook account. Now, even when
completely signed out of Facebook, any link I follow to facebook will
result in the navigation elements being in a language from the other side
of the earth that I can't even begin to read.
I've still not quite worked out how they've tagged me as being from that
particular country, given that it even happens in incognito mode. I suspect
it's probably based on my IP though, as I've a static one at home, and if I
tproxy the same browser over tor it doesn't happen.
I don't use Facebook much, if at all, so it's more of an amusement on the
odd occasion I follow a link than an annoyance, but it does show how a
single action can throw even the most basic of their datasets right off.

@_date: 2017-06-16 15:15:15
@_author: Ben Tasker 
@_subject: [tor-talk] Improved sharing of .onion links on Facebook! 
That's correct.
However, there is a caveat here. Applications on your system can check your
MAC address and submit them (for example, Google Play's Music manager does
exactly this -
). So, if you're running the Facebook app on a tablet (for example) this
might be a concern, though at that point there's a whole host of other
identifiers the app could (and might) also grab to identify the hardware.
AFAIK, though, it's not possible to do it in Javascript (ignoring IE and
ActiveX calls) so it _shouldn't_ be a concern when hitting Facebook in a
Though you might still want to do it for the reasons related to it being a
public place.

@_date: 2017-03-17 15:15:07
@_author: Ben Tasker 
@_subject: [tor-talk] allow ssl-encapsulated connections to all tor 
I think Ural means the initial handshake when connecting to the entry node
is easily detectable and identifiable by a L7 firewall (which it is).
Though you could argue that if SSL is Layer 6 then Tor may also be too.

@_date: 2017-10-11 11:04:46
@_author: Ben Tasker 
@_subject: [tor-talk] Recent Tor Circuit Setup/Stability Issues? 
Quite possibly unrelated, but I've run up against this -
 - a couple of times
this week alone (it's a right shit for hidden services as well, because it
doesn't seem to impact already established circuits - so basic monitoring
doesn't report any issues).
On Wed, Oct 11, 2017 at 10:38 AM, Alec Muffett

@_date: 2017-09-07 21:47:24
@_author: Ben Tasker 
@_subject: [tor-talk] Tor bridges over ICMP or DNS 
In principle, yes. In practice, not so much. SSH to and from China can be
an absolute pain even for low traffic levels (like, for example, a standard
SSH session). Sometimes it's might be deliberate interference, but most of
the time it's a case of combining the headaches of TCP-over-TCP with a
massively busy (and underpowered for the traffic) system like the GFW.
Things like sshuttle ( help a bit (as
it addresses the TCP-over-TCP limitations) but it's still pretty bad
transiting the GFW (I do so pretty regularly).
It's worse than that, they also make heavy use of machine learning. So over
time the system realises that a lot of data seems to be going out over port
65532 (or whatever) to a specific subnet, so they start taking a much
closer look (and in some cases just start blocking/interfering

@_date: 2017-09-11 11:40:40
@_author: Ben Tasker 
@_subject: [tor-talk] Using unbound to resolve .onion domains 
Your config looks more or less exactly the same as mine (I allow tcp but
that's the only difference I can see).
If you do a dig from the unbound server to the BSD gateway do you get a
dig  protonirockerxow.onion
On Mon, Sep 11, 2017 at 10:45 AM, C. L. Martinez

@_date: 2017-09-11 12:56:36
@_author: Ben Tasker 
@_subject: [tor-talk] Using unbound to resolve .onion domains 
Ahh, your version of dig doesn't like that syntax and is trying to resolve
the resolver string.
Try this instead
dig  -p1053 protonirockerxow.onion
Basically I'm wondering if something's stopping the packets from reach the
tor resolver (pf maybe?) given that your netstat shows it is bound to all
interfaces (which'd be the normal mistake)
With various config options set (VirtualAddressNetwork, AutomapHostSuffixes
and AutomapHostsOnResolve) it should return an IP in a given range, which
you then route via the transparent router to reach the endpoint.
On Mon, Sep 11, 2017 at 11:24 AM, C. L. Martinez

@_date: 2017-09-11 16:32:58
@_author: Ben Tasker 
@_subject: [tor-talk] Using unbound to resolve .onion domains 
Did you restart unbound after the change to pf?
I had an issue in the past with Unbound blacklisting an upstream for
failing to respond (if you debug unbound it'll be logged as "chase to
blacklisted lame server"), from memory the default blacklist time is 900
Failing that, it's probably packet capture time to see whether the queries
are actually going out, and where to
On Mon, Sep 11, 2017 at 12:34 PM, C. L. Martinez

@_date: 2017-09-11 17:17:13
@_author: Ben Tasker 
@_subject: [tor-talk] Using unbound to resolve .onion domains (SOLVED) 
Ahhh, ok.
Good news! :D
Looks like Unbound have added .onion to the list of AS112 domains:
            *onion* *(RFC* *7686)*
                 Default content:
                 local-zone: "onion." static
                 local-data: "onion. 10800 IN NS localhost."
                 local-data: "onion. 10800 IN
                     SOA localhost. nobody.invalid. 1 3600 1200 604800 10800"
So yeah, without nodefault it won't let you forward queries for that TLD
and will just return an NXDOMAIN.
On Mon, Sep 11, 2017 at 1:09 PM, C. L. Martinez

@_date: 2018-12-06 09:24:54
@_author: Ben Tasker 
@_subject: [tor-talk] You Can Now Watch YouTube Videos with Onion Hidden 
One of the points made earlier though, is that this isn't entirely accurate.
If you're talking about security, there's still a SSL/TLS link between
invidious and Youtube over which your content must pass. The user has to
assume (and I *hope* it's true) that Invidious will properly verify the
cert that Youtube presents to ensure that there isn't a MiTM.
But, added to this, what you as the user are doing is inserting a third
party into the mix who's acting as a deliberate MiTM. Invidious could
(probably isn't, but has the ability) be injecting something nasty at any
point. That's no reflection on the intentions of the Invidious' operator,
they may simply get compromised by someone who sees them as a juicy target
- After all it seems unlikely that they've got the resources to put into
security that Google has.
So, whilst your initial connection has potentially gained some security (by
going over Tor), your security posture is weakened because you've inserted
a new potential attack vector, and just moved the point of origin for the
original one (the SSL/TLS connection) as well as also outsourcing the task
of verifying that TLS connection to a third party (who may very well be
ignoring invalid/expired certs for all you know at time of connection).
What you _have_ gained is some level of privacy. Youtube cannot see your
source IP, and neither can Invidious. But that's not the same thing as
increasing security - that's obviously ignoring any profiling that Youtube
still manage to do on you, though.
TL:DR - Security is weakened, Privacy is (potentially) strengthened

@_date: 2018-02-17 21:21:57
@_author: Ben Tasker 
@_subject: [tor-talk] Tor Talk Failing Authentication 
It's a commonly known issue with mailing lists
If you've got DKIM enabled on your domain example.com, when mailman (or
whatever) inserts headers the hash will no longer match.
If you've got SPF enabled on example.com then the mailing list server
almost certainly isn't included. When the receiving MTA checks the domain
in the from header those checks will fail.
There are ways around the DKIM issue. either stripping the sig completely
at the mailing list server (might cause more failures) or heavily
restricting the headers used in hashing at the sending MTA.
For the SPF side, not much you can do (assuming you don't want to add
various 3rd party controlled servers to your spf record). Only real answer
is for the list to send from its own domain, but then you start losing
useful functionality.
Does anyone know why Tor Talk entries are consistently flagged as failing
domain authentication, thereby as potentially spoofed?
Sent from [ProtonMail]( Swiss-based encrypted email.
tor-talk mailing list - tor-talk at lists.torproject.org
To unsubscribe or change other settings go to

@_date: 2018-01-05 09:59:23
@_author: Ben Tasker 
@_subject: [tor-talk] random onion non-reachability 
I've noticed similar with a group of services I've been experimenting with.
Each of those services is configured in Single-Hop mode
I initially assumed it related to this -
 - but haven't really
had much chance to dig into it much further as I've been busy with other
It's happened fairly frequently, but Tor's loglines aren't always the same.
Because I use a dedicated routing system to decide which address to send
you too, in the meantime I've just adjusted the routing status checks to
always force a new circuit (to increase the chances of detecting the
In all cases, restarting Tor on the Hidden Service helps.
The various loglines I've seen are:
Tor[3546]: I learned some more directory information, but not enough
to build a circuit: We're missing descriptors for some of our primary
entry guard
 Tor[5944]: Received http status code 404 ("Consensus is too old")
from server '149.56.157.119:9001' while fetching consensus directory
Tor[15520]: Giving up launching first hop of circuit to rendezvous
point [scrubbed] for service
I did also dump Tor into debug mode and repro the issue, but I won't paste
the output here as nothing stands out, and I can't be bothered to sit and
scrub stuff out of it unless it's likely to be helpful.
I've not actually noticed any instances of this in the last week or so, but
it may be that I've simply missed them (now that recovery is somewhat
automated). It might also be, though, that it coincided with a period where
a whole bunch of people were updating their relays  - I first started
seeing the issue after the update enabling next-gen hidden service names
(though, for reference, the affected services are all using 'legacy' names).
As far as I've been able to make out, It does appear to relate to
establishing new circuits - existing circuits continue to work just fine
(which meant all my routing status checks were initially passing, natch),
but if you try to create a new connection (forcing the HS to build a new
circuit out to the RP) it fails. But seemingly not for all attempts
(perhaps some get lucky and we're able to use partially cached information?)

@_date: 2018-01-05 13:30:01
@_author: Ben Tasker 
@_subject: [tor-talk] random onion non-reachability 
Cool. Updating is on my list, so hopefully things will improve once I get
that far.

@_date: 2018-01-29 12:55:36
@_author: Ben Tasker 
@_subject: [tor-talk] catastrophe: ip-api.com sees me 
Silly question, have you actually configured your other browsers to use
If you've just fired up Tor (or TBB) then those other browsers won't use it
by default, because they don't know anything about it. You'll first need to
either configure transparent interception, or tell the browser to use Tor's
socks port.

@_date: 2018-06-10 17:08:33
@_author: Ben Tasker 
@_subject: [tor-talk] Digital IDs needed to end 'mob rule' online, 
brought in to end online anoymity that permits "mob rule" and lawlessness
 online, the securit
The problem is, intelligent or not, they do sometimes achieve gains.
Sometimes through attrition by repeatedly repeatimg the same rubbish,
sometimes quietly in the background (see Theresa May's hostile environment).
So however patently stupid, this stuff still has to be addressed head on.
It's not the first time it (and similar) has been mooted in the UK (and not
just by Tory governments). The risk is they'll find support somewhere for
some half-cocked idea that fails to achieve it's objective but screws the
rest of us in the process (see Identity Verification for accessing porn).
As I see it, there are two complimentary ways to fight it.
Firstly, explain (again) why it's a stupid and flawed idea.
Second, keep building and supporting systems that help protect privacy and
anonymity online. That means running more tor relays as well as developing
new privacy friendly services etc. Essentially, make sure there are
alternatives that cannot be affected by whatever half-baked implementation
they try to foist on us.
The first should help erode any support they might claim to have, but the
second is important and carries benefits either way.

@_date: 2018-09-22 15:28:19
@_author: Ben Tasker 
@_subject: [tor-talk] Deploying Alt-Svc on your own website. Hello? 
Which part are you struggling with?
The following is assuming you've got a site -  - that's
accessible at 1234.onion.
Configure your nginx server block (or apache config) for  to
include an Alt-Svc header to advertise the onion:
 Alt-Svc: h2="1234.onion:443"; ma=3600; persist=1
(The Ma there tells the browser to remember this for an hour).
In Nginx config that would be
add_header Alt-Svc 'h2="1234.onion:443"; ma=3600; persist=1';
In Apache with mod_headers that *should* be
Header set Alt-Svc 'h2="1234.onion:443"; ma=3600; persist=1';
So far so easy. The next bit is a little less obvious though.
You need to configure your onion server block to respond on port 443 _and_
to handle your clearnet host header (and serve a publicly trusted
certificate matching that name). Alt-Svc tells the browser to use the
alternate address as a trusted origin for the service it's connecting to,
so it'll connect to 1234.onion and request You can, of course, continue to also serve your onion over port 80 as well
 if you wish for direct visitors (as you still can't trivially get a cert
for an onion name).
HTH - hopefully I haven't missed anything

@_date: 2018-09-22 16:39:03
@_author: Ben Tasker 
@_subject: [tor-talk] Deploying Alt-Svc on your own website. Hello? 
It has to go to HTTPS because the cert served by the new origin is used as
a mechanism to authenticate that it is actually authorised to act as an
origin. The primary aim being to ensure that if I (somehow) manage to
inject an Alt-Svc header into your responses, I cannot simply redirect
users via my service _unless_ I can also obtain a valid certificate for
your original name.
traffic is already authenticated and encrypted, it only adds useless
See above. Without HTTPS the onion service is authenticated as being that
onion service, but is absolutely not authorised as an authorised origin for
 It's not an oversight, it's a deliberate rational design
decision to help prevent various attacks that would otherwise be possible.
I've not checked Browser support for downgrading to 1.1, but the Alt-Svc
header expects a RFC7301 ALPN name - so the name here would be http/1.1.
However, you also need to percent encode (RFC 7838 section 3), so it'd be
I should add - depending on the browser you *may* find you need to only
inject the header when the user is coming from a Tor exit. Otherwise direct
clearnet users might try and connect out.
It *shouldn't* happen (the RFC makes it very clear that alt services are
optional, and should be used when the alt origin becomes available - "the
client SHOULD use that alternative service for all requests to the
associated origin as soon as it is available"). But as with anything, plan
for the dumbest user-agent you could possibly imagine.

@_date: 2019-04-03 15:03:08
@_author: Ben Tasker 
@_subject: [tor-talk] Is there a way to use internet in a sandbox 
No, one time recordable is fine (preferable, even).
When the system boots from the disk, it loads the OS into memory, so things
like your browser cache files are written into memory (and so lost when the
DIMMs lose charge).  If you want persistence then most live CDs will allow
you to provide a writeable media (normally a USB drive) for that purpose,
but then you get back into the risks associated with having writeable media
It can just as easily as the same ISO running off the USB could. If you
need that level of security, then you're going to want to remove the
harddrive from the system.
Alternatively make sure whatever system you've got installed on the
harddrive is using software Full Disk Encryption. At which point the ISO
cannot read any data from it, and write attempts will (at most) corrupt
your filesystem.

@_date: 2019-03-24 22:51:27
@_author: Ben Tasker 
@_subject: [tor-talk] Is there a way to use internet in a sandbox 
Most browsers actually already do exactly this and run tabs inside a
If you wanted to restrict that further, you could look at chrooting or
using docker. Or take it a step further and use a full blown VM (whether
that's KVM or something like Virtualbox).
But don't, please, follow the suggestion of using root for routine
non-internet tasks. You should use privileged accounts only when you
actually require that level of privilege. Also keep in mind that while
malware running as an unpriviliged user cannot (generally) hose the system,
it can still steal/corrupt whatever data that user has access to. Unless
this is a shared system, you probably care more about that data than the OS
files themselves.

@_date: 2019-03-26 23:21:52
@_author: Ben Tasker 
@_subject: [tor-talk] Is there a way to use internet in a sandbox 
Nothing is 100% safe, but by instituting isolation you'll have raised the
For "something" to escape your internet VM would require some kind of
hypervisor exploit. Technically there is the potential for rowhammer style
attacks from within that VM, but for the forseeable future that'd likely
mean a pretty targeted attack.
Basically it all depends on your threat model. Some prefer to boot tails
from read only media on a system with no disks, others don't need that
level so are willing to sacrifice a little security in the name of
There's a lot more to opsec than just the browser you're running too.
That said, you specifically mentioned concerns about malware, so a simple
VM could well be enough for you (or even a multi-vm setup like Qubes to
reduce the risk of data leaks). You could also have a disconnected VM for
"offline" stuff, but it'd probably be overkill for most people.

@_date: 2019-03-27 17:11:50
@_author: Ben Tasker 
@_subject: [tor-talk] tor project website change 
Just my 10p here. Most pages are concise to a fault, in my opinion. My 4k
monitor is mostly filled with dead space on most pages, which doesn't feel
to welcoming to me.
To be honest it doesn't feel that much better on my phone either, though
the use of space is better.
I'm inclined to agree that too many options is a bad thing, but I feel the
new design has gone too far the other way:
- Why isn't there a prominent link to the source?
- Why are the icons at the top used for download? At a glance it looks like
you're listing out the supported platforms, it's only when you hover over
them you realise they link to the downloads (it's a long page, so
reasonable IMO for someone to assume the downloads are further down. If you
reach the "Download Tor Browser" button at the bottom in your hunt, it's
just  a link back to the page you're on)
- Why's there a screenshot of the top half of tor browser?
- Why is there a section linking out to how to verify signatures when the
download page doesn't appear to contain links to the signatures?
My opinion? What's now the Tor site should have been a brand new site
dedicated to the browser. 90% of the work I do with tor does not involve
TBB at all, it's tor itself I'm interested in. That, obviously, will skew
my perspective of the site.
Sorry to sound so negative, I don't doubt a lot of effort and planning has
gone in, and personal preferences aside (I don't like this fad of long
pages with masses of dead space) it's a very nice site for Tor Browser
Bundle. But I go to torproject for more than that.

@_date: 2020-03-06 15:10:55
@_author: Ben Tasker 
@_subject: [tor-talk] Mozilla's DNS over HTTPS does not complement Tor 
The canary domain will only disable DoH if you've been defaulted into using
If you've actively turned it on, or set network.trr.mode to 3 then the
canary will not disable it.
On Fri, Mar 6, 2020 at 2:58 PM Nathaniel Suchy <

@_date: 2020-03-09 10:32:00
@_author: Ben Tasker 
@_subject: [tor-talk] Mozilla's DNS over HTTPS does not complement Tor 
Several places, but the main user/admin facing doc is probably this one -
these in place that would be disabled if DoH were used for domain name
resolution. Checking for this signaling will be implemented in Firefox when
DoH is enabled by default for users. This will first happen for users in
the United States in the Fall of 2019. If a user has chosen to manually
enable DoH, the signal from the network will be ignored and the users
preference will be honored.
On Mon, Mar 9, 2020 at 10:21 AM Nathaniel Suchy <
