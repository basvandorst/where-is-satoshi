
@_date: 2012-04-28 14:53:16
@_author: George Kadianakis 
@_subject: [tor-talk] Blocked HTTPS 
I'm afraid that using a generic proxy _and_ obfsproxy at the same time
is not possible at the moment.
There is a ticket in the bug tracker to track the progress of fixing
this issue [0] and there is also a proposal with the changes to be
made [1]. Unfortunately, the implementation of the proposal hasn't
started yet.
[0]: [1]:

@_date: 2012-12-17 16:50:27
@_author: George Kadianakis 
@_subject: [tor-talk] Pluggable Transports metrics? 
Sure. However, much of the work in pluggable transport metrics is
currently under development and not ready for end-users.
I will answer the general pluggable transport questions and leave the
flashproxy stuff for David.
Obfsbridges running 0.2.4x report their transports to BridgeDB. To get
the statistic you are looking for, fetch the sanitized bridge
descriptors and count the ones that support pluggable transports.
For example:
$ curl  > bridges
$ grep transport bridges
This is not currently possible.  (and  is the bridge-side
ticket that needs to be implemented for this. I will do the coding
soon (either this month or in January), and we will probably release
some experimental bridge-side bundles for end-user testing.
Another related ticket is

@_date: 2013-08-14 12:53:49
@_author: George Kadianakis 
@_subject: [tor-talk] obfsproxy failure: obfs3 
Hi lee,
it seems like you are using an old version of obfsproxy which does not
support obfs3. obfsproxy was recently rewritten in Python and that's
the version you want to use (the version you are currently using is
written in C). That is, you are currently using obfsproxy-0.1.4 but
you should be using obfsproxy-0.2.1.
As seen in  you can find
obfsproxy-0.2.1-3 through wheezy-backports. Or you can install it
manually using

@_date: 2013-08-15 15:25:41
@_author: George Kadianakis 
@_subject: [tor-talk] Flattor: A practical crowdfunded Flattr-like incentive 
==tldr (Too Long, Didn't Read)
Where will Tor's bandwidth come from in 20 years? Will solo volunteers
still exist, or will all the bandwidth come from Tor-friendly
Tor incentive schemes are interesting. There are many proposed schemes
but their crypto needs to be reviewed and lots of code/spec needs to
be written before they can be deployed.
This document describes the idea of a Flattr-like crowdfunding model
for tor relays.
==Intro (skip if you know why Tor incentive schemes might be useful)
One of the goals of Tor is to increase its reach and get tens of
millions of Tor users. This makes sense from an anonymity point of
view, since an increase on the number of users is also an increase on
Tor's anonymity set.
One of the problems of scaling Tor to tens of millions of users is
that Tor's bandwidth capacity is finite. The current total relay
bandwidth is about 4GB/s [0], and it's donated by kind volunteers and
various organizations [1]. As the number of users increases, Tor's
bandwidth must also increase.
Lately the bandwidth coming out of Tor-friendly organizations (like
torservers.net, universities, etc.) seems to increase. Currently,
there is 50% chance of exiting from an org-controlled exit node, as
can be seen in slide 30 of        If this trend continues, Tor might end up looking like the Bitcoin
network -- where a number of organizations (mining pools) drive the
network. Unfortunately, in contrast with the coin minting of Bitcoin,
there is no incentives for organizations to contribute to the Tor
At the moment, organizations and solo volunteers pay out of their own
pocket (or accept donations) to maintain their Tor relays. There must
be ways to help reimburse their costs.
==Incentive schemes (feel free to skip if you know this stuff)
Incentive schemes for anonymous networks have been extensively
researched and there are multiple papers for systems that apply
specifically to Tor [2].
Most of those systems require to modify the code of the Tor network,
to be able to give "contribution tokens" to relay operators. Then
those tokens can be exchanged to get "premium Tor service" or other
These systems have a few issues that make them hard to implement and
a) Baking anything inside Tor is a lengthy procedure. Secure designs
   and code must be written, time must pass for the new code to be
   deployed and used by the majority of the network, etc.
b) These schemes might cause anonymity issues, since the set of people
   who have "contribution tokens" is smaller than the set of Tor
   users. The proposed incentive schemes try to fix these issues; for
   example, LIRA solves it by creating a lottery system (yes, on top
   of Tor) that rewards "contribution tokens" to random relays.
c) Alternative currencies, like "contribution tokens", are not easy to
   get right. Baking them inside the Tor network is not a trivial task
While these proposed "complex" schemes might be The Right Thing for
the long-term, we might be able to create an incentive scheme based on
already existing technologies; like the bandwidth authorities and
==Flattor: A simple incentive scheme
Flattor is (fictional) software (or a website) that given a Bitcoin
wallet and a number of Bitcoins that the user is willing to spend,
splits those Bitcoins in chunks and sends them to contributing relay
The idea assumes that there is some way to find the Bitcoin address of
relay operators. There is no standard way to do so, but operators who
are interested in getting reimbursed can put their address in the
Contact field of their relay.
Flattor uses the bandwidth estimations of Tor to find the contribution
factor of each relay. We will assume that these estimates are
accurate, since the security of Tor depends on them anyway.
As a simplified example, if the Tor network has 4 relays with
bandwidth contribution 0.05, 0.05, 0.3 and 0.6 respectively, and the
user is willing to spend 1 bitcoin, Flattor will send 0.05, 0.05, 0.3
and 0.6 bitcoins to each relay operator respectively.
Of course, this gets more complicated as the number of relays
increases, or when only a subset of the relays have a registered
bitcoin address, etc.
==Why this might be a good idea
It's simple to implement and easy to understand, it doesn't require
any Tor code to be written and it can even be started as an unofficial
Furthermore, it doesn't cause anonymity issues, there are no
middlemen, and it doesn't centralize bandwidth to a single relay
==Why this might be a bad idea
(This concern is based on a discussion with gmaxwell.)
Incentivising Tor relay operators with money is not a good way to run
an anonymity network
Currently, (we want to believe that) the Tor network is run by a bunch
of cypherpunks that are contributing bandwidth because they believe in
the Cause.
If relay operators start getting money for their bandwidth, we might
end up with relay operators that are just in for the money. It might
then be easier for a three-letter org to persuade those relay
operators to snoop on their users (by giving them double the money
they are currently getting).
While I agree that this concern is legitimate, I would say that it's
pretty far off at the moment: I doubt that anything like Flattor will
ever generate a considerable income for anyone. Still, it's something
that we should have in mind.
(Furthermore, since the Bitcoin blockchain is public you can see how
much money each relay operator has gotten so far. Maybe there should
be some kind of limit on the number of money each operator should get
per time period.)
==Final thoughts
There are many details that must be sorted out before Flattr can be
implemented. There are also multiple improvements that can be applied
on top of the simple model described above. Also, there are ethical
issues that spawn up when real money is given to relay operators.
My plan was to expand on all these issues in this paragraph, but it
seems like I've already spent too many hours writing this document.
I'm not planning to implement this system before I hear some opinions
from other people. To be honest, I'm not even sure if such an
incentive scheme is a good idea, but posting bad ideas to mailing
lists is what the Internet is for, right?
[0]: [1]: [2]:           (see section 'VI. RELATED WORK' of the LIRA paper)

@_date: 2013-08-18 12:26:22
@_author: George Kadianakis 
@_subject: [tor-talk] Flattor: A practical crowdfunded Flattr-like 
Adrelanos said:
FWIW the idea was that you use the relay bandwidth weights (included
in the consensus) to get the overall contribution of each relay.
The bandwidth weights are calculated by the bandwidth authorities (and
the security of the Tor network depends on them).

@_date: 2013-08-28 19:59:03
@_author: George Kadianakis 
@_subject: [tor-talk] Risks of using custom .onion addresses 
Aug 2013 05:46:58 -0700")
with the current Hidden Service protocol, your onion address is leaked
to a small number of Tor relays -- specifically, your onion address is
leaked to the HSDirs that host and serve the descriptor of your Hidden
Service (That's 6 HSDirs per time period and they rotate every some
If your threat model includes those HSDirs being malicious (which
should probably be the case), then I would advise you to not do stuff
like homeaddressxxxxx.onion.
For what it's worth, there has recently been some discussion on
plugging that leak. You can find more information in:

@_date: 2013-06-27 13:21:42
@_author: George Kadianakis 
@_subject: [tor-talk] Research paper "The Parrot is Dead: Observing 
That paper made me even more doubtful that we can emulate a popular
implementation of a non-trivial protocol without actually using the
implementation itself.
To this end, I started thinking of pluggable transports that actually
use a popular implementation of the protocol they are trying to
For example, in the case of HTTP, we could use a browser on the
client-side and an HTTP server on the server-side.  [0] was
created to discuss such a pluggable transport. More research and ideas
are needed before we start specifying and implementing the transport
PS: Sorry if I screwed up the threading. I'm not subscribed and
mailing lists are so hard!
[0]:

@_date: 2013-10-07 00:47:54
@_author: George Kadianakis 
@_subject: [tor-talk] ScrambleSuit is ready for testing: help needed! 
Tested on a Linux system and it worked fine (managed to connect to
bridge and build a circuit)!

@_date: 2014-08-12 11:32:22
@_author: George Kadianakis 
@_subject: [tor-talk] About bandwidth weights selection 
If it's a Guard+Exit, it will multiply the bandwidth weight with Wgd:
Wgd - Weight for Guard+Exit-flagged nodes in the guard Position

@_date: 2014-08-12 13:10:17
@_author: George Kadianakis 
@_subject: [tor-talk] About bandwidth weights selection 
Tor will consider any node with the Guard flag during guard selection
(this also includes Guard+Exit nodes). As you noticed, it will apply
different weights to nodes with the Guard flag and to nodes with the
Guard+Exit flag.
Please read the "Guard nodes" section of path-spec.txt:

@_date: 2014-08-18 12:54:57
@_author: George Kadianakis 
@_subject: [tor-talk] Scaling Tor 
Hidden Services have trouble scaling.
We've been thinking how to build availability in them by allowing
multiple nodes behind a single HS. There are many threads about this
in [tor-dev].
A good starting point is:
along with the threads it references in the beginning.

@_date: 2014-02-12 15:10:30
@_author: George Kadianakis 
@_subject: [tor-talk] Obfsproxy on Raspberry Pi 
I was just wondering, which version of Tor are you using?
If you are using a version older than 0.2.5.1, then scramblesuit will
not work properly. Please upgrade to tor-0.2.5.1 if you can, by using
the latest git master. :)

@_date: 2014-01-29 17:05:42
@_author: George Kadianakis 
@_subject: [tor-talk] Improved HS key management 
FWIW I started a thread in tor-dev about this:
Would like to hear your comments if you have any :)

@_date: 2014-01-30 17:55:48
@_author: George Kadianakis 
@_subject: [tor-talk] Pluggable transports for other projects... 
Greetings Shadowman,
I admit that the documentation resources on how to integrate PTs on
your project are not particularly good. This is mainly because not
many projects had expressed interest in the past and we had more
urgent things to do. Recently a few projects have asked us for help on
integrating PTs into their system. This is a good sign but it also
means that we should improve our documentation. A related trac ticket
is For starters, I suggest you read
 .
This will give you an idea of how Tor uses pluggable transports. That
document can be vastly improved and I plan to do it "soon". Till then,
patches are more than welcome (I especially need to add some sections
and structure to that document, since it doesn't have a nice flow.)
Now, let me give you a small description of how Tor manages its
pluggable transports. It will not be ultra robust, but it might help
you understand what's going on:
Client side:
0) The user is supposed to use the torrc configuration file to inform
   Tor about bridges, their pluggable transports and their
   IP:port. This happens using the Bridge and ClientTransportPlugin
   torrc directives (see the man page, the pt-spec or the source
   code).
1) Tor now knows which bridges the user wants to connect to and which
   pluggable transports it needs to use. It gets the filepath of the
   pluggable transports from the ClientTransportPlugin line and gets
   ready to start them up.
   Before starting the PT, Tor needs to prepare some managerial
   information that the PT needs to know. For example, the directory
   that the PT should use if it needs to store permanent state, which
   transports the PT application should initialize (if it supports
   more than one transport) etc. To do so, Tor sets up the TOR_PT_*
   environment variables accordingly. You can find more info about
   those in the pt-spec.txt.
   After Tor prepares the environment variables, it fires up the PT
   (using execve() or whatever).
2) The PT application now parses the environment variables and
   initializes the PTs that Tor asked it to use. Each PT starts up a
   SOCKS listener that Tor is supposed to connect to. After the
   initialization has been done, the PT sends a 'CMETHOD' line to
   stdout that informs Tor of the IP:port that the PT SOCKS listener
   is listening on, the SOCKS version that it uses etc. You can read
   more about CMETHOD lines in pt-spec.
   We've developed helper libraries that manage this step for you,
   check out pyptlib, goptlib and liballium [0]. For example, you
   might want to skim over this:
   3) Tor now knows which SOCKS listener it should connect to for each
   PT. When Tor wants to connect to a bridge that uses a PT, it does a
   SOCKS CONNECT request to the appropriate SOCKS listener and asks it
   to CONNECT to the destination (the destination should of course be
   the server-side PT IP:port).
   In case the PT requires further parameters for each connection
   (e.g. if the server-side PT protocol requires a shared-secret) the
   SOCKS handshake is (ab)used to transfer those parameters to the
   PT. Currently we are using the username/password fields of the
   SOCKS handshake to transfer those parameters, but we are not very
   happy about this. For more info see:
   4) When the PT receives a CONNECT request to its SOCKS listener, it
   connects to the destination and starts relaying traffic between Tor
   and the destination. Specifically, everytime the PT receives
   application-layer traffic from Tor, it obfuscates it appropriately,
   and relays it to the destination.
That's how the client side works. Now let's look at the server (bridge) side.
Server side:
0) The bridge operator is supposed to use the torrc configuration file
   to inform Tor about the PTs it wants to support in her bridge. This
   happens using the ServerTransportPlugin torrc directive (again see
   the man page, the pt-spec or the source code).
1) Tor, again, prepares the environment variables that need to be
   passed to the PT and spawns it.
   In the server-side there is even more information that Tor needs to
   pass to the PT. Take a look at the server-only TOR_PT_* environment
   variables in pt-spec.txt. For example, Tor needs to instruct the PT
   to bind on a specific IP:port, so that the PT listener stays in the
   same place even after Tor reboots (Tor saves the IP:port in its
   state file).
2) The PT, again, parses the environment variables, fires up its
   listeners and informs Tor of its IP:port using SMETHOD lines in
   stdout.
   The pyptlib/goptlib/liballium libraries help with this step too.
3) When the PT receives traffic from a client, it deobfuscates it and
   passes it to Tor.
   In the server side, the PT uses a special protocol to communicate
   with Tor. It's called the "Extended ORPort" protocol and its
   basically a round of metadata transfer before the actual
   application-layer traffic are forwarded to Tor. This metadata
   includes the actual IP address of the client and the name of the PT
   used. We use this information to keep statistics about the clients
   that each bridge sees.
   The Extended ORPort protocol is specified here:
         Ignore the TransportControlPort part of proposal 196, as that's not
   implemented. Also, don't ask me why this stuff are not in
   pt-spec.txt because I don't know; we should fix this.
   For the extended OR port, you may also want to look at
   some existing source code:
      So... this is how PTs work with Tor. Parts of it work like this
because we wanted PTs to work transparently; so that the end user
doesn't need to care at all about how PTs work and why they work like
If you don't need all of this, you might enjoy the simpler "external
mode" functionality of PTs, as is specified in pt-spec.txt.
I already wrote a bit too much and I'm not really sure what you are
actually interested in so I'll shut up and wait for any questions you
might have.
Also, feel free to drop by  at the OFTC IRC network for a more
synchronous communication experience. We also have biweekly PT
meetings in IRC every second Friday. Tomorrow is one of those Fridays
and we are going to gather there at 17:00 UTC. Feel free to join.
(BTW, I've been meaning to write a "How to integrate PTs with your
project" document for a while. I'll probably reuse parts of this post
when I do so.)
[0]:

@_date: 2014-07-11 16:20:43
@_author: George Kadianakis 
@_subject: [tor-talk] How to add Obfs3 Bridges to Network Settings? 
Just adding the bridges to the "Enter Custom Bridges" textbox and
proceeding is all that is needed.
OTOH, if you use the "Connect with provided bridges (obfs3
recommended)" option, Tor will use some hardcoded bridges that might
or might not work in your jurisdiction.

@_date: 2014-06-15 13:17:33
@_author: George Kadianakis 
@_subject: [tor-talk] On recent and upcoming developments in the PT universe 
Hello friends,
this is a brief post on recent and upcoming developments in the PT
What has happened:
  TBB 3.6:
     As many of you know, the TBB team recently started releasing TBB-3.6
     with built-in PT support. This is great and has taken PT usage to new
     levels [0]. Maaad props to the TBB team for all their work.
     Please try the TBB-3.6 bundles here:
          TBB-3.6 includes obfs3 and FTE by default. All of them seem to work
     fine. If the built-in bridges are blocked for you (this is the case at
     least in China), try getting some more bridges from
      (which also got renovated recently).
  obfs2 deprecation:
     We are in the process of deprecating the obfs2 pluggable transport [1].
     This is because China blocks it using active probing, and because
     obfs3 is stictly better than obfs2. obfs3 can also be blocked using
     active probing, but China hasn't implemented this yet. The new
     upcoming line of PTs (like scramblesuit and obfs4) should be able
     to defend better more effectively against active probing.
  Proxy support in PTs:
     Yawning Angel et al. recently implemented proxy support within
     PTs. This means that TBB-3.6 obfsproxy can now connect to an
     outgoing proxy using the Socks5Proxy torrc option [2]. This will soon
     also be the case for FTE etc.
What will happen:
  obfs4 and scramblesuit:
     Remember ScrambleSuit [3]? We are thinking of *not* deploying it after all...
     ScrambleSuit is great, but during the past two months Yawning has
     been developing a new transport called 'obfs4' [4]. obfs4 is like
     ScrambleSuit (wrt features/threat model), but it's faster and
     autofixes some of the open issues with scramblesuit (  ...).
     Since scramblesuit has not been entirely deployed yet, we thought
     that it would be a good idea to deploy obfs4 instead, and keep
     scramblesuit around as an emergency PT.
  Meek:
     Meek is an exciting new transport by David Fifield. You can read
     all about it here:      It's basically a transport that (ab)uses Firefox to do SSL in a way
     that makes it look like Firefox but underneath it's actually Tor
     data. Very sneaky, and because it uses third-party services (like
     Google Appspot, Akamai, etc.) as proxies, the user does not need to
     input a bridge. Meek just works bridgeless and automgically.
     Help us by testing the latest bundles that David made here:
       PTs and IPv6:
     PTs are not very good at IPv6 yet. We identified some of the open
     issues and created tickets for them. Hopefully we will fix them too:
       : No IPv6 support when suggesting a bindaddr to a PT
       Multiple ServerTransportListenAddr entries should be allowed per transport.
        Publish transports that bind on IPv6 addresses [0]: [1]: [2]: [3]: [4]:

@_date: 2014-06-24 17:27:10
@_author: George Kadianakis 
@_subject: [tor-talk] Meek bridges request 
yes, I'm afraid there is a bug in this functionality:
we will try to fix it soon.
sorry for that.

@_date: 2014-05-03 11:10:58
@_author: George Kadianakis 
@_subject: [tor-talk] Orbot v14 alpha: obfsclient, Tor 0.2.5.3-alpha 
Great news! Thanks!
BTW, how are obfs3 bridges supposed to be used?
I installed Orbot-v14.0.0-ALPHA-2a.apk and checked the Preferences
menu. There used to be an option called 'Obfuscated Bridges' that it's
not there anymore. I assumed that I just have to specify a bridge, and
then prefix it with the transport name, like you do in the torrc.
So I clicked on 'Bridges' and then inserted 'obfs3 :' (with
my own  and ) and started up Orbot. Unfortunately, I think
that it didn't work very well. In the logs I got:
Adding bridge: obfs3 :
Setting conf: SOCKSPort=127.0.0.1:9050
WARN: Controller gave us config lines that didn't validate: If you setUseBridges, you must specify at least one bridge.
Starting polipo process
and then Orbot bootstrapped directly, without using my bridge :/
I'm not sure exactly why my bridge was not set in Tor. Maybe I'm not
supposed to specify my obfsbridge using the 'Bridges' dialog?
PS: I think the move from the 'Obfuscated Bridges' box is a good
    idea. IIRC, the 'Obfuscated Bridges' box assumed that the bridge
    is obfs2, without even mentioning it to the user, which is not
    good now that we have more pluggable transport around.

@_date: 2014-05-03 20:29:02
@_author: George Kadianakis 
@_subject: [tor-talk] Orbot v14 alpha: obfsclient, Tor 0.2.5.3-alpha 
Hm, I just tried that bridge again (without adding a fingerprint), and
now I'm getting the usual PT error:
"We were supposed to connect to bridge ':' using pluggable
transport 'obfs3', but we can't find a pluggable transport proxy
supporting 'obfs2'. ..."
I'm not sure why I'm getting this today instead of the error I was
getting yesterday [0]. I don't remember rebooting or changing
In any case, this new message usually means that obfsproxy crashed
early: before being configured to be a Pluggable Transport. The same
should be true for obfsclient too. Could it be a permission issue?
For example, have you asked obfsclient to log to somewhere? Does it
have permission to do so? (I vaguely remember Yawning telling me that
obfsclient logs by default in the PT state directory, which is inside
the DataDirectory of Tor).
Is there a way to dump the torrc that Orbot is using, to see if it's
well formatted? That would help in debugging.
Yeah, that might be a bad idea for some threat models.
Making the current behavior an option might make sense for some other
threat models.
Very very nice :)
Looking forward to this!
[0]: WARN: Controller gave us config lines that didn't validate: If you setUseBridges, you must specify at least one bridge.

@_date: 2014-05-03 21:18:28
@_author: George Kadianakis 
@_subject: [tor-talk] Orbot v14 alpha: obfsclient, Tor 0.2.5.3-alpha 
We played a bit with Yawning on this.
Are we sure that the ClientTransportPlugin is even set at all?
Because looking at
it seems that it depends on the boolean PREF_BRIDGES_OBFUSCATED which
apparently is never set since commit 147b57af4.
This seems to agree with my experience since I'm getting the log
message "Using standard bridges" which is on the 'else' codepath.
Or maybe we are missing something.

@_date: 2014-05-04 10:18:38
@_author: George Kadianakis 
@_subject: [tor-talk] Orbot v14 alpha: obfsclient, Tor 0.2.5.3-alpha 
BTW, I'd suggest to parse the Bridge lines to figure out if PTs are
used and only then insert a ClientTransportPlugin line (in contrast,
to always adding a ClientTransportPlugin line). That's to avoid issues
like You can check if a Bridge line uses PTs, by checking if its second
element is a C-identifier as the pt-spec.txt suggests. An IP:PORT is
not a C-identifier because of the colon.

@_date: 2014-05-05 16:44:30
@_author: George Kadianakis 
@_subject: [tor-talk] Orbot v14 alpha: obfsclient, Tor 0.2.5.3-alpha 
Works fine in my device using an obfs3 bridge!
Thanks for the rapid fix!

@_date: 2014-05-28 16:27:48
@_author: George Kadianakis 
@_subject: [tor-talk] Setting up an IPv6-supporting obfs3 bridge? 
I think you are right that this is a bug.
I opened  ( to track this issue.

@_date: 2014-09-28 20:06:55
@_author: George Kadianakis 
@_subject: [tor-talk] Hidden Services - how to implement something like 
(Dmitry Alexandrov's message of "Sun, 28 Sep 2014 09:42:49 +0400")
It's not so easy (to implement something like Round Robin DNS for
HSes). It requires complicated protocol modifications.
 (and all its link)
as well its subsequent posts
if you are interested in this problem.

@_date: 2015-02-13 16:15:24
@_author: George Kadianakis 
@_subject: [tor-talk] Funded search engine for onionspace? 
Ah, exciting!
The use of a custom google search is an interesting idea. I also like
the motto and the logo! (although search engine logos are supposed to
be colorful right?)
Some comments:
- How does the custom google search thing works? Where does it get its
  index? You expose all the tor2web onions on your sitemap, so google
  crawls them and generates an index?
  I'm a bit concerned that clients connect directly to Google. Can
  this be avoided and still keep the custom google search functionality?
- I don't like that the default link is through onion.city. This means
  that onion.city watches *both* the search query *and* the content of
  the communication. That's crazy.
  It's especially crazy if you allow your clients to submit HTTP forms
  over onion.city, since it basically means that onion.city gets to
  see *all* the usernames and passwords. I bet there are many people
  out there who don't really get the tor2web threat model, and it's
  nasty to read their passwords.
  There are various ways to solve or semi-solve this problem. My
  preference is to *always* default to the onion link (and maybe also
  have an option for a tor2web alternative). Combined with a nice
  guide on how to download Tor, this might help user education and IMO
  it's the responsible thing to do.
- How do you crawl for more onions?
- It really needs HTTPS!
- Are you planning to also index non-HTTP services?
- Serving onion.city as a hidden service would be nice.
- Curious on the funding model here. Will there be ads?
Thanks and best of luck with your project!

@_date: 2015-03-02 00:44:06
@_author: George Kadianakis 
@_subject: [tor-talk] Obfsproxy: Multiple ServerTransportListenAddr lines 
(megabrutal message of "Sun, 1 Mar 2015 21:43:22 +0100")
I think ticket  might be related to what you want.  It's still
open. As a start, the wanted behavior should be specified and we
should update the PT spec accordingly.

@_date: 2015-03-04 18:16:56
@_author: George Kadianakis 
@_subject: [tor-talk] Funded search engine for onionspace? 
Hello Virgil,
I have received mails from a few people who are feeling bad about the
disallowed.html list of onioncity. Some of them are afraid that it
might list their private hidden service, just because an inexperienced
user accidentally tried to access it over tor2web.
I find their concern very valid, and I also don't see much benefit
from publishing the list anyway. I think removing the list might be
the responsible thing to do here.

@_date: 2015-03-05 11:27:08
@_author: George Kadianakis 
@_subject: [tor-talk] Funded search engine for onionspace? 
I understand but don't really agree with your point. Mainly because I
can't think of a single positive thing that can happen because of this
public list.
FWIW, none of the above will actually help against a non-experienced
user that uses tor2web to connect to an onion by mistake. Even with HS
authorization or HTTP auth, the onion will forever be imprinted on
that public list.
OpSec would help, but it actually relies on the human factor.

@_date: 2015-03-11 17:40:34
@_author: George Kadianakis 
@_subject: [tor-talk] Load Balancing/High Availability Hidden Services 
An application-layer load balancer like HAProxy might be able to help you.
Unfortunately, there is not something equivalent to DNS Round Robin
for hidden services yet. There are some ideas on how to do this on the
Introduction Point-layer, but a proposal still needs to be written. For
further reading:

@_date: 2015-03-13 12:02:49
@_author: George Kadianakis 
@_subject: [tor-talk] Load Balancing/High Availability Hidden Services 
Interesting approach.
I especially like the fact that it doesn't need little-t-tor
modifications to work, which means that we can experiment with it and
if its UX and threat model works out for people we can even change
little-t-tor to improve it.
The main problem I see is that all parts of the system will be racing
each other constantly. A harmful race condition I can see, is this one:
a) Management server is about to make a new superdescriptor.
   Management server polls HSDirs for descriptors and
   waits till it receives them.
b) At the same time as (a), one of the HS nodes abandons an
   introduction point (because it expired or because it went down),
   and publishes a new descriptor with a new intro point.
c) The management server is done forming the superdescriptor and
   publishes it. The management server was not aware of event (b) and
   hence the superdescriptor includes the old introduction point of
   that node, which means that clients who pick that IP will fail.
I think that this is not catastrophic failure because a client will
move on to the next intro point in the list.
It's also worth noting that in this system, availability is enforced
by having the client try the next introduction point. That is if an HS
node is down, introductions to it will fail and the client will only
be successful when she moves to the intro point of an active HS
node. Hence, we should ensure that clients don't spend 5 mins before
moving to the next intro point, or don't abandon connecting after
failing to connect to two bad intro points.
Other race conditions here, involve the management server missing
descriptors from certain HS nodes and publishing incomplete
descriptors, or not publishing anything till all HS node descriptors
have been retrieved. We should make sure that the management server
polls often enough that these problems are minimized.
On security now, it's worth having in mind that HSDir servers and HS
clients can now monitor presense of HS nodes, by looking at the
content of superdescriptors. Also, it will probably be easy to learn
whether an HS is scaleable and approximately how many nodes it has,
just by looking at the number of IPs.
BTW, why do you say that "a hidden service operator could set up a Tor
relay and a hidden service on each of their load-balancing nodes"? Why
do we need a Tor relay in this case?
Thanks for the idea.
Looking forward to see what happens with this!

@_date: 2016-12-20 16:03:40
@_author: George Kadianakis 
@_subject: [tor-talk] Massive Bandwidth Onion Services 
Seems like a reasonable request. Doesn't make sense to refuse to start
up hidden services with a legitimate number of intro points. I added a
positive comment to  which was courteously opened by David.
BTW and to slightly diverge the topic, I really like this experiment and
its blazing fast results, but I still get a weird feeling when I see
that to start functioning it requires 432 descriptors uploaded to the
HSDir system (72 daemons * 6 descriptors). To be clear, I think this is
fine for an innovative experiment like this, but it's not a setup that
everyone on the network should replicate. I guess to improve the
situation here, we would need some sort of "onionbalance complex mode"
where instead of uploading the intermediary descriptors to the HSDir
system, we upload them to an internal master onionbalance node which
does the intro point multiplexing.
Best of luck with your experiment :]

@_date: 2016-01-27 13:52:03
@_author: George Kadianakis 
@_subject: [tor-talk] New hidden service operators mailing list: [tor-onions] 
we would like to inform you of [tor-onions], a new mailing list that we just
launched: The idea is that it will become a place to discuss anything about operating and
administrating hidden services. We figured that with all these websites and
organizations setting up hidden services lately it would be nice if there was a
place for them to ask questions and get feedback on how to set up their
infrastructure in the best way, and also for us to keep them informed of the
newest developments in hidden services.  For example, it's a fine venue for
hidden service operators to ask questions about setting up hidden services at
scale, or embedding them in applications and the mobile, or figuring out why
your hidden service authentication does not work.
It is strictly a technical mailing list in the sense that discussing the
content of hidden services is considered out of scope.
You can think of it as [tor-relays] but for hidden service operators instead of
relay operators.

@_date: 2016-03-01 01:35:05
@_author: George Kadianakis 
@_subject: [tor-talk] large increase in .onion domains 
Potentially systems using Multi-Party Computation, or maybe approaches similar
to PrivEx. For example see:
                I think there is also a sequel paper to PrivEx  but can't find it right now.
If you skim the 2015 archives of [tor-dev] you can find various discussions and
attacks on potential systems.

@_date: 2017-12-04 12:41:31
@_author: George Kadianakis 
@_subject: [tor-talk] Is there a limit to how many .onion addresses I can 
Hello Fabio,
actually that's not really true. There is a limit of 10 _intro point
circuits_ launched _per service_ every 300 seconds.
The reason you are seeing these logs is probably because you are
starting WAY TOO MANY onion services, whose circuits overload your
guard, and your guard starts failing circuits, and hence you need to
keep on building introduction circuits and hence you reach the limit...
You probably have messages like this as well:
"Your Guard riuriu ($0AD5DC3C47CAD362E5682F7FBD5E2E28B2D49899) is failing more circuits than usual. Most likely this means the Tor network is overloaded.     Success counts are 115/165. Use counts are 62/62. 119 circuits completed, 0 were unusable, 4 collapsed, and 16 timed out. For reference, your timeout cutoff is 60 seconds."
I'm not sure but also it doesn't matter. 2880 onion services are way too
many for a single host, and as you can see your guard simply cannot handle it.
I'd suggest you find a better way to do this (e.g. subdomains) instead
of launching thousands of onion services on a single host.
If you are too launch thousands of onions on a single host, you/we need
to find a solution to avoid the host building tens of thousands of
circuits through your guard, since that's definitely unsustainable and

@_date: 2017-06-24 17:37:27
@_author: George Kadianakis 
@_subject: [tor-talk] Do onion services have forward secrecy? 
yes, hidden service circuits are end-to-end encrypted between the HS and
the client. It works like this:
The hidden service sends its ephemeral DH keys to the client using the
INTRODUCE1 cell, and the client sends its own ephemeral DH keys in the
RENDEZVOUS1 cell; both parties then use those keys to establish the
end-to-end shared secret that secures the session.
To answer your question: If the HS or the client get compromised _after_
the session has ended (and the ephemeral DH keys have been wiped), the
adversary must not be able to decrypt the exchanged data, even if all
the between hops get pwned as well.

@_date: 2017-03-03 20:29:22
@_author: George Kadianakis 
@_subject: [tor-talk] State of bad relays (March 2017) 
Hello list,
in this email we will present you the current state of bad relays on the Tor network.
It should be no surprise that the Tor network is under constant attack. As part
of critical Internet infrastructure, people have been attacking our network in
various ways and for multiple reasons. Some people do it for research purposes,
others to satisfy their curiosity whereas others have flat out malicious intent.
Two common Tor network abuses are:
a) Bad exit nodes sniffing and messing around with client traffic.
b) Bad HSDir nodes. The hidden service hash ring is a particularly juicy
   target, since participating relays get to see the addresses of onion
   services when they publish their descriptors.
Both of those attacks require the adversary to setup relays on the network, and
this gives us a chance to catch and block them.
Our elite bad relay hunting team has been chasing down those bad actors and
blocking them from the network. Over the years, we've discovered hundreds of
evil relays that have been attacking the network. Here is a graph that shows
the volume of bad relays we've found over time:
   The bottom part of the graph shows relays caught participating in exit node
attacks (see (a) above). And the top part of the graph shows relays that have
been conducting HSDir-related attacks (see (b) above) or other miscellaneous
As you can see there is quite a number of relays participating in HSDir-related
attacks and finding them has been time consuming. However, the good news is
that these HSDir attacks will be addressed completely and forever when we roll
out Next Generation Hidden Services:
    With Next Gen Hidden Services, HSDir relays won't be able to learn the
address of onion services anymore, because their descriptors will be
completely encrypted.
Anyway, this was an email to brief you up on our efforts of detecting bad
actors on the network and to let you know that we've got your back.
And don't forget to send your warmest thanks to the 1337 members of our bad
relay hunting team if you ever see them around the network :)
Have a good day!

@_date: 2017-03-14 17:28:39
@_author: George Kadianakis 
@_subject: [tor-talk] Possible solution to next-gen onion services UX 
as Jonathan said this has been proposed and done before, and
unfortunately it did not get very far.
Personally, I think this might be an improvement over the current
situation, but far from the solution to the UX problem.
The whole idea has various social/technical problems as well:
- Who maintains the list of  ->  mappings?
- How do we ensure the correctness and authenticity of the list?
  Validating http -> https changes is not super hard, but validating
   to  mappings is harder.
- Having addons rewrite your URLs is not polite. Going from http to
  https is one thing, but rewritting the whole URL is a different
  thing. Users will get confused and paranoid.
- What happens if we learn that a mapping was wrong/evil? How do we push
  and validate updates? I'm not sure if HTTPS everywhere can/should do
  this over the network right now.
The list of issues above is not complete, and it doesn't mean that the
idea is useless at all. I just think that more thinking needs to happen.
Personally, I think launching such a project as a third-party effort is
a fine thing to do. If people like it and use it then that's fine, and
perhaps a community can be built and flourish around the tool. After
all, I2P has been using hosts files to do human-memorable names for ages
and even tho the idea is flawed in nature, it seems to work fine for
people without problems.
And there is also the alternative approach which is that HTTPS
everywhere could define its own pseudo-tld (e.g. .scallion), and then it
could do arbitrary mappings of  -> .
That's a more complete solution but it brings even more security/social issues.
FWIW, all these things have been discussed with the HTTPS everywhere
people over the years, but it's unclear whether the team has the
firepower and energy to handle such a task, or whether it's worth it at
As an alternative here is a more general and abstract approach to
solving the UX problem: Have a good day!

@_date: 2017-11-14 14:03:13
@_author: George Kadianakis 
@_subject: [tor-talk] Layer-7 DoS Attack Against WWW Tor Hidden Service 
There is no such functionality right now I'm afraid. People have been
wanting some sort of functionality like that for a while:
        but we haven't had time to develop/design something.
One cheap solution would be to use some sort of CAPTCHA or use onionbalance :S
Some sort of concept like ticket  might be a good start for this,
but we still don't have a precise design: We are all quite overwhelmed with v3 onions bugfixing right now, so
these projects are on a lower priority for now, and any help from the
community would be appreciated ;)

@_date: 2017-11-15 14:26:36
@_author: George Kadianakis 
@_subject: [tor-talk] Layer-7 DoS Attack Against WWW Tor Hidden Service 
Thanks for this information bob1983. I opened ticket  to handle
the generic issue of DoS attacks, and also opened  to investigate
the I2P feature you mentioned. Hopefully we can find some time to work
on this, or it might give the community a place to design stuff.
I'm also wondering how the I2P community is using that feature. I have
asked some I2P friends and waiting for answers.

@_date: 2017-11-17 13:33:18
@_author: George Kadianakis 
@_subject: [tor-talk] Is there a limit to how many .onion addresses I can 
Hello cyberpotato,
I suggest you *carefully* consider your threat model before creating 500
unique hidden services. The network is not gonna collapse if you do so,
but it's not something that should be done casually by lots of people
because it will definitelly stress out the network.
Please consider that onion services support *stealth client
authorization* which basically provide this functionality (different HS
for each user), and it's currently capped at 16 users max. So please be
cautious if you plan to pass that limit. Also check out this article:
         Specifically, each hidden service puts the following burden on the
network even when idle:
              - 3 long-term introduction circuits per HS
              - 6 descriptors uploaded per HS (this becomes 12 for hsv3)
With so many descriptor uploads and circuits you might even end up
overloading your guard node, which might impact your reachability

@_date: 2017-10-25 14:47:20
@_author: George Kadianakis 
@_subject: [tor-talk] Need a stable .onion address hosted by the Tor 
Hm. That's not really true. An onion service should work regardless of
where it's hosted and that's the whole point (to provide
location-anonymity). If you had to use a different onion address based
on where it's hosted, then better stick to good ol' regular TCP/IP
"Latency problems, AS problems and circuit congestion" should not be
influenced too much by where the onion service is hosted. After all, you
have a 6 hop circuit to the onion service regardless of where it's
hosted, and that big circuit is probably the source of any issues.

@_date: 2018-04-16 14:37:00
@_author: George Kadianakis 
@_subject: [tor-talk] V3 censorship ? 
Thanks for the report, Hikki! It's really valuable for us to receive
such reports from HSv3 operators given that the system is so new and
there are undiscovered bugs we should fix.
Personally, I doubt this is a censorship attack by an adversary since
it's even harder to censor v3 onions than v2 onions. Of course, we can
never be sure.
If I were to bet, I would bet that it's some sort of bug on the v3
codebase, that perhaps could be triggering when it's getting used by
many people (hence why it appears when you make it
public). Unfortunately, there is no way to really know what's going on
except if we see some tor logs.
Please let us know if you'd be willing to send us some (sanitized) logs
of your tor process. If you don't want to do that, perhaps you could
check your log files to see if there are any really obvious log lines
there that could point out the problem, and let us know about them.
Thanks for the report again! v3 onions are still early in their
lifetime, so there will be various bugs to fix until they can reach the
stability of the older v2 onions!
Cheers! :)

@_date: 2018-12-18 14:40:17
@_author: George Kadianakis 
@_subject: [tor-talk] circpathbias.c : Your Guard vs The Guard 
Agreed that this is confusing (as can also be seen by this email
thread). I opened a trac ticket where people can brainstorm and
hopefully submit patches for this issue:

@_date: 2018-01-05 14:57:58
@_author: George Kadianakis 
@_subject: [tor-talk] random onion non-reachability 
Yes, that's precisely  and can be very bad for the reachability of
onion services. There has been lots of work on improving the situation on 0.3.2, so I'd recommend you try the latest tor-0.3.2
version and see whether things improve.

@_date: 2018-11-12 18:27:26
@_author: George Kadianakis 
@_subject: [tor-talk] onion balance needed by default 
Yes, I agree that onionbalance is an essential tool for onion service operators.
We have looked into how to make that possible for v3s but it doesn't
seem to be a trivial project:           For what it's worth, we've been applying for onion-service related
funding as an organization so that we have more resources to support
third-party tools like onionbalance.
Other than that, we've been ultra busy bugfixing v3s and in general
supporting them, that does not allow us much time into improving
onionbalance given the current state of our resources.
Hope this was useful! :)

@_date: 2018-10-24 16:11:28
@_author: George Kadianakis 
@_subject: [tor-talk] derive onion v3 key from mnemonic seed phrase? 
I think that should be possible reading
 .
I don't think there is anything that stops us from taking the generated
onion private key, splitting it up as specified, and assigning a
mnemonic to it. You could imagine a third-party tool that just reads the
privkey file and outputs the mnemonic, or reads the mnemonic and
generates a privkey file.
Not sure if this belongs to the upstream Tor code, but I guess it if it
gains enough popularity something can be arranged ;)

@_date: 2019-12-10 15:19:14
@_author: George Kadianakis 
@_subject: [tor-talk] Onioncat and Tor Hidden Services V3 
Hello there,
I appreciate your excitement about onioncat and sympathize with your
frustration about support going away.
I'd like to find a way to keep on supporting this use case but these
things are not easy. They are actually quite hard:
A v2 descriptor cannot be signed by a v3 key, because a v2 descriptors
needs an RSA signature and v3 keys are ed25519.
This means that v2a would be a brand new descriptor type, which means
tons of engineering work (but we already knew that because the lookup
algorithm below is also tons of work).
At that point it doesn't make sense to call it v2a, you can just call it
OnionCatDescriptor. OnionCatDescriptor is a document that can be fetched
and verified using the entropy available in an IPv6 onioncat address and
somehow redirects you to a v3 descriptor.
I know I said that this is tons of work, but everything is tons of work
in this life, so if you want to proceed with this project, the next step
would be to write a proper Tor proposal on how this would work, then
post it in this list and let the fun begin.
As a final note and as my personal opinion, I don't think onioncat
support is gonna stop v2 deprecation. v2 addresses are 80-bit and can be
literally brute-forced and impersonated with the current human
technology, so their deprecation is already too late.

@_date: 2019-05-20 17:55:14
@_author: George Kadianakis 
@_subject: [tor-talk] Hidden service persistent connections 
What kind of attacks are you worried about? I don't see any serious
threats for onion service clients when it comes to long lasting connections.

@_date: 2020-02-06 12:33:39
@_author: George Kadianakis 
@_subject: [tor-talk] Call for alpha testing onionbalance for v3 onions 
Hello list,
I'm glad to announce that onionbalance for v3 onions is now ready for
preliminary testing.
Please see for more details, and don't hesitate to ask questions.
I'm looking forward to your testing!
Thanks a lot!

@_date: 2020-01-23 13:50:16
@_author: George Kadianakis 
@_subject: [tor-talk] Ports required for Tor and hidden services 
Tor hidden services are Tor clients and hence you don't need to forward
any ports for them to work. They punch through NAT because they work by
only doing outgoing connections.

@_date: 2020-03-03 14:54:21
@_author: George Kadianakis 
@_subject: [tor-talk] .onion alt-svc issues? 
[CCing Mahrud in case he can still reproduce the issue.]

@_date: 2020-03-03 18:14:06
@_author: George Kadianakis 
@_subject: [tor-talk] Call for alpha testing onionbalance for v3 onions 
Hello again,
you can now find a better guide for setting up OnionBalance V3 here:
    I'm currently working on packages and CI.
Let me know if you find any bugs or issues :)
