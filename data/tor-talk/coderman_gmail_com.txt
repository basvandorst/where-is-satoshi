
@_date: 2004-12-09 09:42:31
@_author: Martin Peck 
@_subject: Privacy KNOPPIX 3.7 
i've created a first rough cut of a knoppix distribution with tor,
privoxy and squid all configured to run at startup.  The configuration
for these apps is created dynamically on /ramdisk/home/* and if you
have a USB storage pen drive you can save any customizations to
this is a work in progress, but it should be usable.
a screenshot is available here:
the torrents may be a bit slow as there are currently only a few seeders.
feedback welcome.  i'll have un updated version that fixes a number of
the to-do items in a few weeks.

@_date: 2005-05-27 06:28:05
@_author: coderman 
@_subject: volunteer to do php patch for wikipedia? 
Hi Adam, this looks very good!  One feature I thought would be useful
is a test entry that would accept an IP and tell you which ipblock (if
any) matches it.  This would really only be useful if a given ipblock
set contained a large number of distinct IPs/CIDR's.
Would that be useful?  I look forward to playing with this new feature
set once you have a patch available!  (perhaps I can help with some
coding / bug fixes at that point...)
Best regards,
    Martin

@_date: 2006-12-27 15:11:29
@_author: coderman 
@_subject: MyFamily issues 
that is a digest and not a nickname.  try the human friendly nickname
you assigned to the node in question instead

@_date: 2006-02-22 07:35:41
@_author: coderman 
@_subject: [michael.holstein@csuohio.edu: Re: Anonymity questions] 
tor does not apply to an NSA threat model; your low latency mix/onion
== p0wn3d by NSA, sorry.
from the FAQ they say as much: [6.7
 ]
"As mentioned above, it is possible for an observer who can view large
portions of the Internet (called a 'global adversary') to be able to
correlate timings of all traffic entering and exiting the tor network,
and thus link arbitrary users. Tor does not defend against such a
threat model."
that said, i think IPsec is a great idea in as many places as possible
assuming your key distribution/exchange is well implemented.

@_date: 2006-06-22 00:46:05
@_author: coderman 
@_subject: Tor Leaking 
and transparently proxy DNS to plug leaks and make .onion & .exit work
as expected.
i'll have some technical detail as well as a mastering tools / scripts
for this purpose in the next day or so (linux specific).   long
overdue, but better late than never...
i like this method of using Tor best myself since it either gets
resolved and rerouted through Tor or it is dropped.  there is never
any questions about weird ports / apps / DNS leaks, aside from the
large and pressing concerns of application leakage above the transport
best regards,

@_date: 2006-06-22 00:54:58
@_author: coderman 
@_subject: Tor,security and web-usability - Sorry, now readable with line-breaks... 
the impact is impressive and useful with the right classification for
http into Squid[transparent]->Privoxy->Tor, all other tcp into Tor,
and transparent DNS through dns-proxy-tor.
many thanks to whoever for making the *-proxy-tor tools available.
you can sniff the outgoing traffic and literally it is all Tor if you
drop ICMP and other unnecessary protocols.  this is my preferred
method of using Tor now...

@_date: 2006-06-29 04:58:39
@_author: coderman 
@_subject: Help with privoxy on Virtual Privacy Machine 
according to  you should be
able to grab this shared lib from knoppix.  be sure to include sym
links for various versions to the library and run ldconfig once copied
to destination.

@_date: 2006-06-29 04:58:39
@_author: coderman 
@_subject: Help with privoxy on Virtual Privacy Machine 
according to  you should be
able to grab this shared lib from knoppix.  be sure to include sym
links for various versions to the library and run ldconfig once copied
to destination.

@_date: 2006-05-31 16:19:39
@_author: coderman 
@_subject: internet browsing privacy appliance with tor and privoxy 
we've got a proof of concept build of an internet privacy appliance
for windows users available via torrent at:
there are some known issues / deficiencies in this release:
- DNS leaks due to transparent proxy. transparent DNS proxy when in
anonymous mode is in progress (using tor-resolve and a python DNS
- http traffic is identified by outgoing port (80, 8080, etc) rather
than traffic type. L7 matching is also in the works.
- https (SSL/TLS) traffic and most other types is passed through and
not proxied.
- this runtime has not been hardened against malicious peers on the
same internal network and chroot's and other techniques are not yet
- if you are behind a restrictive firewall the update check may take a
long time to time out.
- if you are running a restrictive firewall locally the SMB share with
the install script may not be accessible.
- some types of CGI GET requests appear to be mishandled by privoxy or squid.
we're trying to work out logistics for torrent seeding before
distributing the build tools to remaster your own vmware installers
and customize the privacy appliance.  we're working on fixing known
issues and anticipate a new build in the next week or so.
how it works in a nutshell:
- start the vmware instance with 128M ram and 200M disk (image is 38M
- a public SMB share is provided with a Run.BAT install script
- script installs a MS PPTP VPN connection to forward all traffic
through the appliance
- privacy (privoxy) and anonymity (tor) is enabled by default.  you
can select privacy only for a faster browsing experience with ads and
popups filtered.
a note on auto updates:
remove the /etc/janus directory to prevent the automatic update check.
 we intend to use this to deploy security critical patches, filtering
updates to privoxy, and other maintenance.  you can apply these
changes by hand or disable them completely as desired.
we may be intermittently available in  on irc.oftc.net for any
additional questions or comments in real-time.
checksums for these files:
MD5: B2 7B 51 C1 09 32 E1 05 73 3A A1 72 3F F3 B6 EC
294CE5C3 C9FD4088 4B6DE7D1 E69251F5 45E4A495 4AAD1023 C22E752E D3389E36
10A1FA1F 2C7B6700 EE804318 CE2BBF55 9258E199 A6DE81B3 D76B1F9D 4B4C6FA0
MD5: 5B E9 28 91 A3 76 BD AA 7B E7 43 41 1F CF 30 26
1F29137A F86FCECA 1E396962 325F651C AB60EE4C 22571743 C143A986 4A4A35D8
A0911E0E 08A43B6B 44933929 B2A09B85 F6F60969 60046BF1 A3207548 528846CF

@_date: 2006-11-19 16:56:51
@_author: coderman 
@_subject: tor privoxy squid 
try the following:
squid: make sure these elements are in your squid.conf
httpd_accel_port 3128
httpd_accel_host virtual
httpd_accel_with_proxy on
httpd_accel_uses_host_header on
cache_peer      localhost       parent  8118    7       no-query default
header_access Via deny all
header_access From deny all
forwarded_for off
privoxy: note that the cache_peer in squid config refers to SOCKS
proxy in privoxy config.
listen-address  127.0.0.1:8118
forward-socks4a         /       127.0.0.1:9050  .
tor: note that 9050 is the SOCKS proxy port for Tor.
INTF=eth1 # internal network interface
ONTF=eth0 # external default route / public interface
$IPTABLES -A FORWARD -i $INTIF -o $EXTIF -p tcp -m state --state
ESTABLISHED,RELATED -j ACCEPT
$IPTABLES -t nat -A PREROUTING -i $INTIF -p tcp --dport 80 -j REDIRECT --to 3128
note that you'll want additional firewall / filter rules, and also
that DNS leaks may be present.  you will have to transparently proxy
DNS via dns-proxy-tor or equivalent to avoid this, and the following
filter rules can be used for transparent DNS proxy:
$IPTABLES -t nat -A PREROUTING -i $INTIF -p udp --dport 53 -j REDIRECT
--to 65533
where 65533 is where dns-proxy-tor is listening.

@_date: 2006-11-26 23:25:24
@_author: coderman 
@_subject: Traces left by Torpark, and other security discussion (was Re: TorPark) 
the exact keys may vary from win98/2k/xp, as they often do.  (are you
using a fixed list of keys to look for, or is there a more in depth
search for particular key names/values?  a static list will be
system restore, regsafe, and any number of other snapshot or backup
tools for the windows registry would make this ineffective.  not to
mention remnants on disk but outside the file system view, though such
recovery does take special skill.
do you mean adding your own CA cert, or just blindly accepting the
cert presented upon the first connect to the https server?  or
something else?
why the focus on automatic updates?  [we thought we'd need these at
one point, but really, it opened up more problems than it solved.
additional care before releases has proved sufficient]
wiping swap is difficult in such a situation, and i'd be more
concerned about document fragments and other information than the
network signatures. (network signatures at least are gone once you
exit, but sensitive data on disk can live for arbitrary periods of
a hard problem, i'd be interested in any potential resolutions you
discover.  encrypting the swap is really the "right way" to solve
this, but again, requires administrator.
best regards,

@_date: 2006-11-27 02:03:44
@_author: coderman 
@_subject: Traces left by Torpark, and other security discussion (was Re: TorPark) 
i am referring to the developers of janusvm, NOT Tor, since this
paragraph is confusing.
the first few versions included an update check that used a hard coded
hostname in /etc/hosts (to prevent DNS latency/DoS) to retrieve via
http a file that contained an sha256 digest associated with the
current release or update.
each build included an sha256 id associated with the current version.
if the version stored on the vm file system at boot and the version
obtained online were different this was assumed to indicate a new
release was available.
a gpg public key used for signing updates was also bundled with the vm
image, and the update process would obtain two more files $id.tgz and
$id.tgz.asc which contained the patch and its signature, respectively.
the $id.tgz was digested and if the sha256 sum of the downloaded
update did not match the sum obtained in the current.id http request,
the update aborted with prejudice.
if the digests matched, gpg was then used to verify the $id.tgz.asc
signature associated with the downloaded update.  if this failed, also
if all validations passed, the update was applied to the vm file
system and the init process continued to start as expected, but now
with the updates applied.
in short, we thought this might be needed to push critical updates or
config changes for Tor or other applications / utils on the vm.  it
turned out this kind of urgent / critical update was never needed, and
various organizations who started blocking our update server IP
address ended up causing longer startup times due to the http timeout
required before continuing past the update check.
not to mention the scalability concerns of doing this for anything
more than a small number of clients.
best regards,

@_date: 2006-11-30 10:28:47
@_author: coderman 
@_subject: Relakks 
let me make this really clear:
Relakks and other single hop proxies are trivial to observe for an
adversary correlating traffic.  Such services make it MUCH EASIER, not
harder, for governments to watch.  they also introduce a single point
of failure and require full trust in this third party.
Tor is slower than Relakks because it provides stronger anonymity,
which is a feature, not a bug.
best regards,

@_date: 2006-11-30 13:24:39
@_author: coderman 
@_subject: Relakks 
sure, privacy via an encrypted link is better than plaintext.  but
that's different from anonymity, which is what i was referring to.
straight forward correlation via traffic analysis to determine source
and destination is easier than "eventually" in such a situation.
it's easier than you assert.  monitoring the swedish ISP is not
necessary, and changing IP's doesn't gain you much, if anything.
more difficult != anonymous.
Tor does not defend against a global eavesdropper like the NSA.
this is not to say Relakks is worthless, but it does not offer strong
anonymity like Tor provides.
best regards,

@_date: 2006-11-01 08:12:08
@_author: coderman 
@_subject: "Practical onion hacking: finding the real address of Tor clients" 
the narus advantage is hardware/programmable classifiers, ala snort on
fpga, which allows deep inspection across numerous (linearly scalable)
OC12/OC48 peering points.  rules also scale linearly, with anywhere
from 500 to thousands per classifier proc.
this is all about scale, and since we are discussing taps on the
backbones, scale is paramount.  but for small ISP's, corp it staff
you're right...
the problem with narus run by $TLA is that it functions as global
adversary, which is explicitly outside Tor's threat model.  this may
or may not mean they are watching.  (and there are certainly some
$TLA's who are using packet latency fingerprinting with active
manipulation of packet timing up stream to link clients to particular
exit traffic)
zero knowledge mixes defend against this threat, but you lose the
(relatively) low latency of onion like routing in Tor.  [exercise for
the researchers: would traffic padding with a DTLS Tor ala reliable
multicast at fixed bandwidth limits keep the low latency but provide
the anonymity of a stronger mix?]
best regards,

@_date: 2006-10-05 17:35:59
@_author: coderman 
@_subject: First results of analysis 
or just behaving when you were looking?  ;)
if i were a rogue exit node i'd make sure that i leave all explicitly
routed *.exit requests alone and only MITM the rest :)
most of the exits running proxies are probably doing so with honest
intent, a caching proxy for example, and not actively logging /
attacking traffic.
[ commodore64 which is running a squid proxy on all port 80 it is
exiting is probably doing so for caching purposes:
 ]
the malicious exits seem to be rare (that is, the explicit attempts to
capture login / pass or route to phishing / spoofed sites).
a banking URL or web mail service would be a better test case for
these types of attacks.
it's been many weeks since i've seen an exit explicitly attacking
traffic to get account info.  so not a big problem to date... [and
that exit is long gone - someone said they were doing it as a warning
what you _really_ want is a reliable reputation metric for Tor nodes,
which is actually a very hard problem to do well without opening up
other attacks / vulnerabilities for the network as a whole.
- random pages will miss the targeted attacks on things like webmail
or banking sites.
- you may want to avoid checking with .exit so you don't tip off the
rogue nodes you are making a test request.
- comparing "wrong" results without lots of false positives is hard,
as most site changes are legitimate (rolling ad content, news or other
notices, etc).
some kind of automated testing for rogue exits would be useful though.

@_date: 2006-10-12 18:00:33
@_author: coderman 
@_subject: Tor-compatible secure email systems 
something like freenigma?
you have to trust them with your keys, but at least provides some
protection for the scenario you describe.

@_date: 2006-10-20 15:31:22
@_author: coderman 
@_subject: "Practical onion hacking: finding the real address of Tor clients" 
i'm fond of the transparent proxy router approach we've used to try
and fail safe for most protocols (at least with respect to the DNS
leaks and covert TCP connections via Java/Flash/etc).[1]
this doesn't do much for identifiers in the data stream (although
privoxy/squid do scrub the transparent HTTP which is visible), and
probably won't until significant effort is employed for
protocol/application specific content filtering proxies.  until then,
user beware...
it would be nice to have a detailed proxy checker available that looks
at these Java/Flash/RealPlayer/etc holes.  right now there are a
handful of common http proxy checkers but these look for headers and
IP at best.
does such a thing exist?  i would be willing to host (although i
suspect others would have done so already were a tool available).
1.  uses a pptp vpn connection to force a
default route through the virtual machine providing transparent TCP
and DNS proxy through Tor.  this defeats all of the covert TCP
connection attacks designed to circumvent browser/application level
SOCKS/HTTP proxy settings, but does not address identifying data
within the TCP streams. [people have been asking about non-Win
support, and this will be forthcoming in the next few months via
openvpn for *bsd/linux/solaris/mac]

@_date: 2006-10-24 11:45:36
@_author: coderman 
@_subject: "Practical onion hacking: finding the real address of Tor clients" 
as you mentioned further down, the presence of your node in the
directory will do more to "invite attacks" than an open port 80 i
you can configure other ports, but 80/443 are recommended precisely
because most firewalls let web traffic pass (and thus these clients
behind restrictive firewalls can still use Tor).
your OS is usually displayed in the directory as well.  for example:
[Linux i686]
like any network software there are a number of things you can do to
address security concerns.  Tor has a good security record, but
certainly isn't perfect.  you might check
 for details but
you appear to be familiar with the usual tricks.
i like this approach, with the client serving VPN connections (PPTP,
OpenVPN) that force a default route through it and Tor for any users
on the same internal network.  it does not make much sense to run a
server and lots of clients behind the same IP if you can just share
use of the server.
when a user wants to be anonymous, they activate the privacy vpn, and
no IP leakage (even javascript, flash, etc) occurs.  when they are
finished, just disconnect.
see for more info.
you could even use a virtual machine for the tor server.  there is
some rough detail to do this with janusvm in the "Alternative
Solutions" mentioned here:
this feels like a straw man.  there are valid security bones to pick
with Tor but capable and motivated developers are behind it.  would
more support / community be helpful?  absolutely.  but size alone is
less useful a metric than you think...
one last comment:
an additional reason to run a server which i haven't seen listed in
this thread is hidden services.  while not a compelling feature, they
are useful for some purposes.
best regards,

@_date: 2006-10-25 01:47:19
@_author: coderman 
@_subject: Silly question... 
this looks like:
- Tor was started with an old directory
- thought it could create circuits
- attempts to connect out (your new firefox?) failed because directory
info was actually stale
- got updated directory
- working fine now?
i assume it was your 2.0 firefox using torbutton.  is anything else
configured to use Tor as a socks proxy?
best regards,
if Tor did think an out of date directory (cached?) was suitable for
building circuits, shouldn't it defer until it has obtained a current

@_date: 2006-10-25 08:36:41
@_author: coderman 
@_subject: Silly question... 
you mean servers?  there are more than one and the likelihood of them
all failing / partitioning at once is really low.

@_date: 2006-10-26 13:11:53
@_author: coderman 
@_subject: "Practical onion hacking: finding the real address of Tor clients" 
this is correct.  i experience much better availability/performance
with hidden services on a server.  though it was a while ago that i
compared, and this would be worth revisiting in detail.
best regards,

@_date: 2006-10-03 15:45:53
@_author: coderman 
@_subject: transparent DNS proxy for tor resolution [was: Confused about Tor settings] 
you may want to look at janusvm (  ) which
uses a PPTP VPN tunnel to force a default route which does transparent
DNS proxy through dns-proxy-tor on a virtual machine to plug the DNS
leak.  [note that you may need to alter your DNS settings if your
local gateway is also the nameserver - see docs for details]
i don't know that this capacity could be integrated any further into
tor in a cross-platform / effective manner.  the mapaddress capability
is a good abstraction point for this in my opinion. [that is, building
a full DNS resolver into tor would be complex and there exist easy
ways to integrate mapaddres to your host resolution]
best regards,

@_date: 2006-10-03 16:38:56
@_author: coderman 
@_subject: forcing tor to build a new circuit [was: tor and its speed] 
tor supports a control command: "signal newnym"
      NEWNYM    -- Switch to clean circuits, so new application requests
                   don't share any circuits with old ones.
   The server responds with "250 OK" if the signal is recognized (or simply
   closes the socket if it was asked to close immediately), or "552
the following utilities (among other tools) can talk to the tor control port:
[these may or may not be included in a binary distribution under
various locations]
best regards,

@_date: 2007-08-10 18:41:11
@_author: coderman 
@_subject: Warning to NoReply.org DEB Package Users 
there are some configurations that don't allow saving the config.
they are still vulnerable.
you can set config options live, and they will take effect.  these are
ephemeral changes, but still effective.
that will work fine.
best regards,

@_date: 2007-08-11 20:37:06
@_author: coderman 
@_subject: Question about the vulnerability 
great; you're now protected against this type of attack. (but may have
some risk for other types...)
ideally you would have some kind of authentication associated with the
control port.  note that the way Tor behaves even without
authentication configured will protect you if you are using a recent
version like 0.2.0.4-alpha.
if you want to configure authentication you can do so, however, this
may break vidalia (?).  either the HashedControlPassword or
CookieAuthentication method can be used.
if you use "CookieAuthentication 1" in the config, a
control_auth_cookie file will be created in your DataDirectory.  the
contents of this file is needed for authentication.
you can create a hashed control password via "tor --hash-password
password" and set the resulting digest in the HashedControlPassword
best regards,

@_date: 2007-08-12 22:52:57
@_author: coderman 
@_subject: Directory issues 
have you tried deleting your torrc config, and using no config, or the
default torrc?
that page appears to be quite out of date.  i see current descriptors
for this router published:
TulenianFreeSpeech $E7C779651CBA12075EC6C29C07616636744AEA59
2007-08-13 04:48:47 UTC
you appeared to have restarted on 2007-08-13, 2007-08-10, 2007-08-08,
and 2007-08-05 with successful descriptors published each time.
the "not enough to build a circuit" is concerning.  let us know if a
new torrc fixes the problem or if it persists.
best regards,

@_date: 2007-08-13 01:10:01
@_author: coderman 
@_subject: Directory issues 
your descriptors are published regularly as well.
is it possible both of you are experiencing clock skew / incorrect system times?
best regards,

@_date: 2007-08-14 17:15:07
@_author: coderman 
@_subject: contradicting log entries regarding ExcludeNodes 
the digest is public, and you can obtain it via cached-* files in your
Tor data directory, a public Tor status site, or other methods.
the key(s) from which the digest is derived should never be disclosed.
note that many routers may share the same nickname, like "Unnamed", so
you should use a combination of nickname+ip address to identify the
digest you want.
best regards,

@_date: 2007-08-16 06:34:08
@_author: coderman 
@_subject: Privoxy usage? 
privoxy filters visible HTTP traffic configured to pass through it.
privoxy cannot "see" into encrypted streams like the VPN you describe;
it would not be useful in that situation.
what may be useful is the transparent TCP proxy support in Tor for
ensuring the VPN connections are going through Tor. (VPN software
being difficult to SOCKS'ify so to speak)
best regards,

@_date: 2007-08-16 06:50:06
@_author: coderman 
@_subject: Privoxy usage? 
also, janusvm.peertech.org provides transparent proxy through a
virtual machine. (you'd need to configure routing through the vm if
the PPTP method conflicted with your VPN setup; email off list if
best regards,

@_date: 2007-08-18 12:40:31
@_author: coderman 
@_subject: Privoxy usage? 
that's not good advice.  tcp to 443 and other uses in general are
quite acceptable.  (ok, i do favor AH/ESP or UDP, but TCP is still
quite usable and useful)
i've used openvpn tcp over tor.  it works just as you expect other
application layer protocols over tcp to work.  what's your grudge
against tcp over tcp?
with Tor your tcp endpoint is terminating quite close, in this case on
the same host stack or one host over.  you don't lose or timeout
packets over a single hop (unless you've got a blaster infected client
on your LAN :)
please back up these arguments with some kind of facts, since you're
misunderstanding the usual nature of TCP applications using Tor here.
the performance hit for TCP over TCP in Tor land is the latency and
bandwidth associated with onion routing, not nested TCP transport.
best regards,

@_date: 2007-08-18 15:41:27
@_author: coderman 
@_subject: Privoxy usage? 
indeed.  i need more coffee before getting into technical protocol
discussions. (i was misreading part of this thread...)
right, there can be a hit here.  enough that maybe interest in the UDP
transport proposal could get some attention? :)
however, this is a much bigger hit for lossy links, rather than latent
links.  TCP VPN over WiFi is much more problematic than TCP VPN over
Tor in my experience.  i've also had success tweaking the TCP VPN
layer (disable nagle for example, and i recall someone using cork to
benefit too).
the Tor UDP proposal is here:
 ,
DTLS is more mature now than it was at time of writing, but this still
has unresolved issues.
best regards,

@_date: 2007-08-18 15:54:57
@_author: coderman 
@_subject: Privoxy usage? 
i forgot to add:
LongLivedPorts and NEWNYM are your friends.

@_date: 2007-08-21 02:54:37
@_author: coderman 
@_subject: Server node stalls on unsuccessful socks listener change 
yup, same experience here.
this would be a nice issue to fix.  haven't looked into it further.
kiiled my 25790692 second uptime.  oh well, needed to upgrade anyway
best regards,

@_date: 2007-08-04 00:15:09
@_author: coderman 
@_subject: Directory information no longer up-to-date; access blocked? 
"Isn't Defcon _fun_, kids?"
appears to be those pesky hackers causing trouble.  you shouldn't
encounter problems of this type anymore if you're running a recent
version (0.1.2.16 or 0.2.0.4-alpha).  the directory
best regards,

@_date: 2007-08-21 15:42:48
@_author: coderman 
@_subject: Server node stalls on unsuccessful socks listener change 
i lied!
looking back over this i did not set a ORListenAddress.  when i
changed this and tried to reload the config the server died.
i don't know if this is related to the socks listener address change
issue, but it sounds similar.  i tried reproducing the socks problem
but it worked fine with 0.2.0.4-alpha (that is, it correctly closed
the old port, and created a new one bound to the new address)
i tried the ORListenAddress change and the following occurred:
Aug 21 15:41:28.773 [notice] Received reload signal (hup). Reloading config.
Aug 21 15:41:28.774 [notice] Closing no-longer-configured OR listener
on 0.0.0.0:9001
Aug 21 15:41:28.774 [notice] Opening OR listener on 127.0.0.1:9001
Aug 21 15:41:28.774 [warn] Could not bind to 127.0.0.1:9001: Address
already in use. Is Tor already running?
Aug 21 15:41:28.774 [warn] Failed to parse/validate config: Failed to
bind one of the listener ports.
Aug 21 15:41:28.774 [err] Reading config failed--see warnings above.
For usage, try -h.
Aug 21 15:41:28.774 [warn] Restart failed (config error?). Exiting.
(in the original case i was rebinding to a public IP; the loopback is
just for test, but the same behavior was encountered.)
hope that clarifies things.
best regards,

@_date: 2007-08-21 16:24:14
@_author: coderman 
@_subject: Server node stalls on unsuccessful socks listener change 
this appears to be a linux'ism and applies only when going from an
unspecified bind (0.0.0.0) to a specified bind to an address on the
host.  changing specified bind addresses works as expected.
i'm not sure what the correct workaround is for this; i can't seem to
find any good documentation on this behavior and how to avoid it.
SO_REUSEADDR is getting set but apparently behaves "weirdly" on
sockets with unspecified binds.
perhaps some on list has dealt with this before...
best regards,

@_date: 2007-08-24 17:59:26
@_author: coderman 
@_subject: Server node stalls on unsuccessful socks listener change 
two issues here, one that i completely overlooked (thanks tup!)
the linux'ism described above may or may not be a problem.  there is a
bigger issue affecting all platforms first:
when reloading the config (ala SIGHUP or control port), the Tor
process tries to apply the various settings in an "undoable" fashion,
such that if the configuration fails, it reverts to its previous
state.  that is, set_options tries options_act_reversible which calls
retry_all_listeners which calls retry_listeners for each type with a
replaced_conns passed.
this results in behavior where a listening socket bound to 0.0.0.0 is
open at the same time tor tries to bind to a specified address, like
127.0.0.1, which obviously fails.  this doesn't cause a problem when
you start with a specified address because multiple specified
addresses can be bound to the same port since Tor is using
question for the Tor devs:
two possible ways to resolve this:
1. check for a change from unspecified to specified address in any of
the settings and disallow it.  (this should generate a warning in the
options_transition_allowed() checks)
2. modify retry_listeners so that when a listen port is previously
bound to 0.0.0.0 it does the following:
a. close the existing port immediately, instead of adding it to the
replace queue.
b. add this 0.0.0.0:port to an "undo" list in case subsequent changes fail.
c. bind to the new address:port and return success, or
d. close the attempted socket which caused a failed bind, and re-open
the previous 0.0.0.0:port socket so undo behavior is preserved.
i'd really like to be able to modify a running instance to change from
unspecified to specified binds without a restart.  this bit me once
already, and i think it is worth pursuing unless too complicated to
last caveat: the linux'ism still may be a problem.  the apparent
workaround for this is a small delay before rebinding.  the fix above
would at least correct the behavior on most platforms, leaving loonix
to be dealt with if needed.
best regards,

@_date: 2007-08-04 04:25:49
@_author: coderman 
@_subject: critical security vulnaribility fixed in Tor 0.1.2.16 
you're wrong.  upgrade to the latest version (0.1.2.16 or
0.2.0.4-alpha) to avoid this type of attack.
best regards,

@_date: 2007-08-04 04:28:39
@_author: coderman 
@_subject: tor servers communicating to wrong ports 
is this TCP or UDP?  (DNS)
59k and above are ephemeral ports usually associated with a local
client type connection to a remote public ip/port.
best regards,

@_date: 2007-08-04 05:04:22
@_author: coderman 
@_subject: critical security vulnaribility fixed in Tor 0.1.2.16 
port 9051 is usually bound to localhost (127.0.0.1).  a firewall
(usually) protects against external connections.  applications /
utilities bound to localhost can access other ports bound to this
best regards,

@_date: 2007-08-04 05:08:44
@_author: coderman 
@_subject: tor servers communicating to wrong ports 
i'd be curious to know if you uncover additional details (packet
dump?) to determine the nature of these connections.  it may be that
you are attempting connections to potential external servers for
reachability verification or something else of this nature.
best regards,
(is there anything in the logs to indicate the nature of these
requests as well?)

@_date: 2007-08-04 05:48:32
@_author: coderman 
@_subject: critical security vulnaribility fixed in Tor 0.1.2.16 
what do you mean directly?  your firewall protects against remote
connections, but direct connections can be made from localhost.
best regards,

@_date: 2007-12-02 12:10:43
@_author: coderman 
@_subject: Reducing java leakage in windows 
the last time i looked into this (over a year ago) the socks proxy
settings, either 4 or 5, still did name lookup external to the proxy
(not 4a nor 5 with names).  this means the same DNS resolution tricks
to leak your IP will work, even if the simpler "open a TCP sock to
eve" does not.
i think HD Moore's revealer used this as one of the tricks, so it
might be worth checking against that with an updated
deployment.properties to confirm.
if you really want to use java you should use it behind a transparent Tor proxy.
best regards,

@_date: 2007-12-19 15:00:38
@_author: coderman 
@_subject: Snail Mail Onion Routing 
what you want is a zero knowledge mix, not a "snail mail onion routing
protocol".  :)
see  for lots of zero knowledge
mixing ("mix") info...
this is off topic for Tor, as such mixes are not low latency.
however, they are the appropriate for the design you seek and most of
the open questions you pose are answered in various papers on the
best regards,

@_date: 2007-12-02 14:43:26
@_author: coderman 
@_subject: storage privacy (was: Nice quiet, private, anonymous life??) 
apologies in advance for veering this far off topic...
use full disk encryption, even the latest ubuntu supports this.
destroy the disk keys and you've got platters full of entropy.
anything else is just a bad idea.
see the Tor Operational Security wiki page for more not bad ideas:
best regards,

@_date: 2007-12-26 07:07:51
@_author: coderman 
@_subject: Running on embedded hardware 
can you provide the rest of the configure string for tor?
this is usually an openssl crypto or other optimization using an
instruction that is not supported by the processor.
did you build openssl yourself too, or use the openwrt trunk package?

@_date: 2007-12-26 07:43:34
@_author: coderman 
@_subject: Running on embedded hardware 
i believe you need to pass at least --target= and maybe --host and --build.
also, openssl in opnewrt appears to be configured with "no-threads",
if you still encounter weirdness, can you try adding:
--disable-threads to the Tor configure and see if this makes a

@_date: 2007-12-02 15:12:32
@_author: coderman 
@_subject: Win32 / netsh 
hi chris,
this works the opposite way you'd need it to for the behavior you seek.
it is indeed for inbound connection relay only.
note that even if this could redirect outbound connections, you'd
still need to proxy DNS requests to avoid compromising your anonymity
through name resolution.
best regards,

@_date: 2007-12-02 15:12:32
@_author: coderman 
@_subject: Win32 / netsh 
hi chris,
this works the opposite way you'd need it to for the behavior you seek.
it is indeed for inbound connection relay only.
note that even if this could redirect outbound connections, you'd
still need to proxy DNS requests to avoid compromising your anonymity
through name resolution.
best regards,

@_date: 2007-12-02 15:18:03
@_author: coderman 
@_subject: javaprogram using tor 
you can also use the system and/or user level deployment properties
file to set the SOCKS proxy settings:
this is correct.  the only way to do this securely is via transparent Tor proxy.
(it may be possible to implement your own lookups through Tor via JNDI
naming service hooks, but this would require a significant effort and
still leave you vulnerable to third party jars and such...)
best regards,

@_date: 2007-12-02 15:20:55
@_author: coderman 
@_subject: javaprogram using tor 
my understanding is that doing DNS resolution via tsocks is spotty at
best since it forces the resolver library to use TCP which may not be
reliable.  it is better to have the application use socks 4a, socks 5
with names, or perhaps a transparent Tor proxy.
best regards,

@_date: 2007-12-05 16:28:18
@_author: coderman 
@_subject: storage privacy (was: Nice quiet, private, anonymous life??) 
despite the rudeness of some of this thread, it really is difficult to
properly clear / purge data from a modern hard disk using a magnetic
field.  we do this at work, and the device is a large box with loud
fans.  you must wear heat resistant glove(s) to hold the hard drive
over the unit for 60+ seconds.  it gets quite hot (see inductive
smelting, etc).
arranging such a unit inside a case would be difficult, dangerous, and
probably not as effective as you think.
see this is why full disk encryption is preferable.  it is much quicker
and safer to securely purge or destroy the disk keys (small) than the
whole disk itself (large, time consuming).
there are many ways to configure authentication/authorization for
encrypted disk access, including multi-factor passphrase, token, even
biometric.  maybe you leave the keys on disk for headless boot and
only want the ability to securely wipe them if needed.
last note, the loop-aes module support key scrubbing in memory, so
that even ram cannot be inspected for usable disk encryption keys that
could remain after power down. (some other volume encryption methods
may also support this, however, loop-aes is the only one i've used
that does so.)
best regards,

@_date: 2007-02-19 13:55:51
@_author: coderman 
@_subject: Security concerning Tor, BitTorrent and Firewall 
Tor will not punch holes (as of yet).  however, it is common for the
official bittorrent client and utorrent (iirc) to use UPnP to speak to
the router and open ports.  if this is going on, it's likely that your
Tor'ification left this hole open, so to speak.
this class of problem (applications bypassing proxy settings and/or or
using non-TCP protocols to communicate) is one reason i am fond of a
transparent proxy approach to Tor rather than cumbersome and
potentially error prone application specific configurations for all
desired tasks.
ditto the previous comments about torrents on Tor; it's not really
useful and is detrimental to performance as a whole.

@_date: 2007-02-19 14:08:05
@_author: coderman 
@_subject: Security concerning Tor, BitTorrent and Firewall 
zeroconf fortunately doesn't do the UPnP port forwarding stuff.
filtering multicast is an easy way to halt zeroconf discovery if
desired anyway...

@_date: 2007-02-04 20:31:00
@_author: coderman 
@_subject: Really strange interface behavior 
let me guess, eth1 is default route, and if you look at outgoing Tor
packets the source address is correctly "216.9.65.50".
you can maybe fix via iproute2 and policy based routing (may also need
netfilter hooks).
best regards,

@_date: 2007-02-04 20:31:00
@_author: coderman 
@_subject: Really strange interface behavior 
let me guess, eth1 is default route, and if you look at outgoing Tor
packets the source address is correctly "216.9.65.50".
you can maybe fix via iproute2 and policy based routing (may also need
netfilter hooks).
best regards,

@_date: 2007-02-27 11:01:11
@_author: coderman 
@_subject: building pages with tor in mind 
consider the drive-by pharming style attack:
malicious javascript connects to your router, and if using defaults,
can open up an external telnet management service, change your DNS
server, basically leverage your router for any number of secondary

@_date: 2007-02-27 11:01:11
@_author: coderman 
@_subject: building pages with tor in mind 
consider the drive-by pharming style attack:
malicious javascript connects to your router, and if using defaults,
can open up an external telnet management service, change your DNS
server, basically leverage your router for any number of secondary

@_date: 2007-02-27 11:08:42
@_author: coderman 
@_subject: Newbie's questions 
this is actually more complicated to answer; namely implementation
specific in the context of an active attacker.  consider an AES cache
timing attack which can recover AES secrets remotely over the network
with modest effort:
there are similar side channels (exploiting pipelining, L1/L2 cache
latency, and other CPU capabilities) against public key and symmetric
cipher implementations in software.
while not a dire threat this is something to consider in your threat
model and one reason i am a big fan of hardware cipher implementations
like VIA Padlock.

@_date: 2007-02-04 20:42:48
@_author: coderman 
@_subject: Really strange interface behavior 
for the sake of completeness:
gw1 = 216.9.65.1
gw2 = 216.9.100.1
ip route add default via 216.9.65.1 dev eth0 tab 1
ip route add default via 216.9.100.1 dev eth1 tab 2
ip rule add from 216.9.65.50/32 tab 1 priority 500
ip rule add from 216.9.100.100/32 tab 2 priority 501
ip route flush cache
may do the trick.  (if you've got the same default router IP for both,
then use it instead of two distinct as shown above).
good luck,

@_date: 2007-02-04 20:42:48
@_author: coderman 
@_subject: Really strange interface behavior 
for the sake of completeness:
gw1 = 216.9.65.1
gw2 = 216.9.100.1
ip route add default via 216.9.65.1 dev eth0 tab 1
ip route add default via 216.9.100.1 dev eth1 tab 2
ip rule add from 216.9.65.50/32 tab 1 priority 500
ip rule add from 216.9.100.100/32 tab 2 priority 501
ip route flush cache
may do the trick.  (if you've got the same default router IP for both,
then use it instead of two distinct as shown above).
good luck,

@_date: 2007-07-15 18:11:38
@_author: coderman 
@_subject: constrained socket buffers patch 
i've updated the previous patches once again:
- provide a warning when DirPort is set and this option is enabled.
providing cached directory entries exacerbates the TCP buffer resource
- corrected format to 80 lines.
thanks to those who have helped with testing!  this appears to
mitigate the problem to varying degrees.  i am still interested in
feedback for win32 WSAENOBUFS behavior. (still trying to build a win32
tor.exe for those who may want to test it.)
best regards,

@_date: 2007-07-20 14:55:03
@_author: coderman 
@_subject: constrained socket buffers patch 
it's important to note that while the constrained buffers patch will
limit the maximum size of the window, it does not do the inverse.
it is very common to have small TCP windows at start and yet still
have 64KB buffers allocated to the socket resource itself in kernel
land...  (so think of this like setting a ceiling on window, rather
than fixing it to a specific value at start)

@_date: 2007-07-23 10:53:47
@_author: coderman 
@_subject: directory server change 
tor26 $847B1F850344D7876491A54892F904934E4EB85D 2007-07-23 04:34:19 86.59.21.38
perhaps not referenced by name, but still a DA.

@_date: 2007-07-24 16:27:03
@_author: coderman 
@_subject: PHP's CURL & Tor integration hangin 
is this connect timeout, dns resolve timeout, transfer timeout, etc?
you're not doing anything obnoxious, are you? :)
that sounds like a curl/php problem.
it is up to Tor?  Tor will timeout a failed connect attempt at 120 or
180 seconds(?), but if you've got a connection, and the server doesn't
close it, and you never time it out, sure, it could hang open for
you need to fix the curl part to timeout transfers as well as connect/dns.
best regards,

@_date: 2007-07-25 16:36:09
@_author: coderman 
@_subject: PHP's CURL & Tor integration hangi 
this is veering a bit off topic, but the following should work:
php -f chk_tor.php 2>&1 | mailx -s "my script output" root at localhost
if you don't have mailx, mail should work too.
best regards,

@_date: 2007-07-09 11:01:09
@_author: coderman 
@_subject: running tor on a vserver 
another possibility is cranking down the xmit/recv buffers for the TCP
sockets Tor is using.  this would be a patch to the connection.c stuff
to set a sockopt, like:
int bufmax = 4 * 1024;  /* min 2048, usually 16-32k */
setsockopt(sock, SOL_SOCKET, SO_SNDBUF, &bufmax, sizeof(bufmax));
setsockopt(sock, SOL_SOCKET, SO_RCVBUF, &bufmax, sizeof(bufmax));
this would allow you to create enough connections without consuming
over your virtual server limit (at the expense of some performance
penalty for smaller buffers.  this probably won't cause a lot of
problem since Tor uses libevent for handling socket i/o...)
best regards,

@_date: 2007-07-10 13:33:59
@_author: coderman 
@_subject: running tor on a vserver 
will do.  i'll post the patch tonight.
a possibly more intuitive name: "ConstrainedSockets 1"   (or something
to indicate xmit/recv buffer limiting?)

@_date: 2007-07-11 14:54:16
@_author: coderman 
@_subject: constrained socket buffers patch 
hi Andrew, all,
attached is the constrained sockets patch.  apologies for the delay;
still have DSL problems at home.
to enable this feature set:
ConstrainedSockets 1
in your configuration.  this will limit the recv and xmit buffers
associated with TCP sockets to the default 4096 bytes.  you can also
alter the default explicitly via:
ConstrainedSockSize 2048
the value must be between 2048 and 262144 in 1024 byte increments.
attempting to set an invalid value should produce an error at start.
see the (patched) man page for additional details.
to patch:
cd tor-0.1.2.14
patch -p1 < ../tor-constrained-sockets.patch
then build as usual (vary per your reqs):
./configure --prefix=/usr --sysconfdir=/etc && make && make install
let me know if this appears to work!  you may try adjusting the
buffers down as low as 2048 if you still get problems at 4096,
however, i don't think this is likely.
best regards,

@_date: 2007-07-13 02:59:36
@_author: coderman 
@_subject: constrained socket buffers patch 
this is a good idea.  16k might be even better if it worked reliably
(the usual default is 32 to 64k).
i've updated the patch to provide better documentation on this option
in the man page and set the default to 8k per your suggestion.[0]
one last note: this should work on win32 sockets and may help reduce
the windows buffer problem. [1]
any feedback testing this patch on vservers or win32 is appreciated.
best regards,
0. updated constrained socket buffers patches:
    md5:ff2432af49e3348e12de61a795b10840
  sha1:8a18a8a1b2dc872fff03d7611773f615b3382d28
  ---
    md5:b53e37863612110e764769b84f527609
  sha1:7e990582ea0a240bd54b3ba7ea97ede72a592856
1. "Windows Buffer Problems (WSAENOBUFS)"

@_date: 2007-06-02 17:21:35
@_author: coderman 
@_subject: [ANNOUNCE] Updated JanusVM and JanusVMLive 
A new version of JanusVM is available:
 - Upgraded Tor to version 0.1.2.14 which includes new DA addresses.
 - Added "New Circuit" menu option for manually requesting a new exit.
MD5: 7c9e38959ab61672a72ec019787cebc5
SHA1: 6af939b2ca28e967f6db50e1b1246f4e86f72905
SHA256: 72ef9fc56d8f43e6aa5211ce79adfe2e2d1c49b0165bec672f27add3aa672443
A variant of JanusVM called "JanusVM Live" is also available.  This
boots from read-only CDROM ISO image and keeps all state in memory.
The included JanusVMLive.vmx for VMWare locks all VM pages in memory
so that no runtime information is paged out to swap. [0]
MD5: 715fb7c0d7ae8863265cd1e3019f29eb
SHA1: 9a4a4f488500187c6f8cf5874298d0f9542c3727
SHA256: 61568d5224b65cafd599bdb2c484042d3a0622ebcc0dbffe1d531e9aac6e26d2
The janusvm.iso included in the Live release ZIP should work with
other virtual machines, like  and possibly
qemu.  Feedback is appreciated, as we have not verified the networking
capabilities of these other vm's to ensure compatibility with JanusVM
VPN and transparent proxy support.
0. DISCLAIMER on the VMWare page locking:
To our knowledge, this option only works using Windows host OSes.
We have only done a preliminary evaluation of VMWare's page locking
mechanism. While it appears to work as described, this is in no way a
thorough evaluation.  Also note that applications on the host OS using
JanusVM may keep data on disk and in swap / page cache.
The VMWare options used to enforce memory resident operation are:
sched.mem.pshare.enable = "FALSE"
prefvmx.useRecommendedLockedMemSize = "TRUE"
prefvmx.minVmMemPct = "100"
mainMem.partialLazySave = "FALSE"
mainMem.partialLazyRestore = "FALSE"
mainMem.useNamedFile = "FALSE"
Any feedback on the efficacy of this configuration is also appreciated.

@_date: 2007-06-18 12:59:09
@_author: coderman 
@_subject: Strange behaviour of Tor 0.2.0.2 Alpha & vidalia 0.0.12 
i don't know about the other issues but usually bandwidth in the
config is specified in kB/s not kb/s.

@_date: 2007-06-21 11:21:23
@_author: coderman 
@_subject: [ANNOUNCE] ROCKate Tor LiveCD V0.4.0.0 
you may want to consider loop-aes instead. [0]  i'll try to avoid a
flame war here, but dm-crypt/luks has some deficiencies [1] which may
or may not be of concern.  if you do use dm-crypt/luks, make sure you
have a recent version. (pref. 2.6.20+).
truecrypt is free and open, and pretty decent, particularly if you
want win32 support.
best regards,
0. key management is usually more difficult for loop-aes and the keys
(multi-v3) are also larger.  that said, the key schedule and key
scrubbing in loop-aes are preferable to the others IMHO.
1. cryptoloop, dm-crypt, bestcrypt, truecrypt, and loop-aes  - Why
cryptoloop should not be used.

@_date: 2007-06-21 11:33:05
@_author: coderman 
@_subject: Remote Vulnerability in Firefox Extensions 
the problem exists when non https is used for updates. any plugins
getting updates via http port 80 would be vulnerable.
i haven't tested the various plugins myself.  a sniffer should tell
you quickly if updates are performed insecurely, though you may need
trial and error to determine which one is making the requests if it
isn't obvious in the data.
this would be a good subject to document on the wiki if you pursue it :)
best regards,

@_date: 2007-06-21 11:55:46
@_author: coderman 
@_subject: [ANNOUNCE] ROCKate Tor LiveCD V0.4.0.0 
right.  but this means more work for you (to manage loop-aes keys) as
luks makes things simple(r) already. :)
all of the statements are current for the most part. the author
updated relevant sections to name versions where the watermarking /
plain-text attack issues were fixed in truecrypt / dm-crypt.
dm-crypt still exposes more information than is desired during partial
block updates. (change the last bit in a loop-aes 512byte block and
you get a new block.  dm-crypt just updates the last cipher block
sized portion at the end of the 512 block - 16 bytes)
overall, any of them are a pretty good choice.  the crypto will be the
last thing an adversary tries to attack here, so your key management
and user clue will be the crux.
key scrubbing and robust key schedule (less data is encrypted per key
than the others) for loop-aes multi-v3 may provide a useful benefit
depending on your needs...
best regards,

@_date: 2007-06-21 14:03:14
@_author: coderman 
@_subject: [ANNOUNCE] ROCKate Tor LiveCD V0.4.0.0 
i like this better.  you get more entropy in your disk encryption
keys, and you can optionally store the disk keys on a separate device,
like USB fob.
[ i like the Sony MicroVaults:
 ]
you shouldn't need to do this for luks, since it stores cipher info in
the partition header.
for loop-aes i prefer to attempt to mount as AES256 and fall back to
AES128 if mount fails. (or vice versa, depending on defaults.)  since
loop-aes doesn't indicate anything about format or encryption type on
the volume, you have to manage this meta data elsewhere, and fail
this is always useful, especially when trying to recover a corrupted
file system on an encrypted volume. :)
what about saving changes later?  require re-auth and remount?
intended usage and environment is a better description.  if the LiveCD
is used for a client only, no long term identity keys stored, than any
of the above should be fine.  (this sounds like what you envision near
if the LiveCD is intended for running a long lived Tor server with
router keys on the encrypted drive then loop-aes with key scrubbing,
disk keys on an external USB device, and key management in a minimal
un-networked pre-boot environment [0] would be my preference.  a
million other factors to consider, particularly application
vulnerabilities and physical security, but at least that would put
storage privacy toward the bottom of the risk list.
hope that helps,
0. pre-boot auth:
i like to use a small initrd to do this with a kernel configured
without networking and other unnecessary device support.  pivot_root,
kexec, and exec init work well in this context...

@_date: 2007-06-25 08:53:41
@_author: coderman 
@_subject: Tor Traffic Problems 
hi Andrew,
please note that 150KBytes/sec == 1.2Mbits/sec.
if you convert your bandwidth values accordingly you should see better behavior.
best regards,

@_date: 2007-06-25 08:57:29
@_author: coderman 
@_subject: stuff making it around the exit policy? 
hi Whysyn,
this is a connection to another router, not an exit:
router AscendedDaniel 131.215.166.198 6882 ...
best regards,

@_date: 2007-03-09 02:53:48
@_author: coderman 
@_subject: Security Focus story 
repeat after me: it's "Tor", _NOT_ "TOR"  :)
 i have a policy that law breakers will leave evidence
in logs and set the "evil bit" on all packets! [0][1]
if it does get close to that bad over in EU, don't run Tor nodes in
data centers.  once those canaries have died begin to worry about that
DSL exit...
0. "i have a policy..."
   1. RFC 3514 - The Security Flag in the IPv4 Header

@_date: 2007-03-13 19:11:25
@_author: coderman 
@_subject: server status 'offline' 
certainly plausible.  there are known issues with the TCP stack in
windows. (or, more correctly, in the manner in which Tor currently
interfaces with the host TCP stack in windows [0])
it will run better. just how much depends on a number of factors. may
solve your problem, may not...
XP Pro or perhaps a virtual machine running bsd/linux running Tor
would both be an improvement.  i'd be interested to know which, if
any, of these suggestions resolves your problem.
best regards,
0. Windows Buffer Problems

@_date: 2007-03-07 02:41:54
@_author: coderman 
@_subject: Building tracking system to nab Tor pedophiles 
the depths of just how badly security in general sucks well captured.
at least some areas of the technology landscape are showing signs of
improvement.  bitfrost and mac(with parrallels?).
otherwise, the capriciousness of users encouraged by the inherent
architectural vulnerabilities sold in mass quantity by vendors more
concerned with profit and appearance than customer vulnerabilities
ensures lots of targets...
  i need a drink...   *g*
ah, at least this can be worked on in a straightforward fashion.
(unlike transnational market forces with lots of momentum :)
and even various combinations of the above for additional
compartmentalization without excessive overhead.  some relevant links:
(btw: if anyone has some bandwidth they would like to donate for
janusvm dev torrents please email me so i can contact you for early

@_date: 2007-05-18 13:46:34
@_author: coderman 
@_subject: nighteffect.us gone 
hi Joe,
something happen with an employer?  or just lack of support?
i'd like a copy of the code if that's ok.
thanks again for all your efforts; i know that they are unappreciated
and unnoticed most of the time, but they do make a difference and
there are many who appreciate it quietly...
best regards,
    martin peck

@_date: 2007-05-18 13:50:34
@_author: coderman 
@_subject: a solution on the horizon to counteract detecting temperature through clock skew (on Tor Hidden Services)? 
i've wondered about using a frequent ntpdate to reduce skew, and if
that is not sufficient, what about a modified client that uses
adjtime() or settimeofday() with random offsets (+/- within some
tolerance) to gently randomize on a few minute schedule?
is there a public tool to analyze clock skew like that mentioned in
the attacks to determine if such workarounds are effective?
best regards,

@_date: 2007-05-18 14:04:58
@_author: coderman 
@_subject: tor plus openssl hardware? 
seems to work great, but i've only used it as a client.
as Nick mentioned, Tor can handle engines in openssl with the config
option.  if you have a C7 with PHE and MONTMULT i've got a temporary
patch here:
that includes RSA/DSA acceleration via the new bn_mont_mult extension
backported from 0.9.9 and includes the above patches.  use at your own
you will need a kernel that recognizes the phe_en instruction for the
config to work:
grep flags /proc/cpuinfo
flags           : [...] rng rng_en ace ace_en ace2 ace2_en phe phe_en pmm pmm_en
and simply patch against 0.9.8e and configure via:
./config --prefix=/usr --openssldir=/etc/ssl threads shared
you'll probably need to manually copy the .so*'s into
include the patches with so versioning so various debian like systems
won't complain when dynamic linking to these new libs.
BIG WARNING: these binaries are using asm optimized montgomery
multiplication, not as engine, but as platform native optimizations.
this means they will absolutely die on any non-montmult enabled
processor.  C7 only, sorry.
the speed up is impressive:
1.5Ghz C7 with patched openssl speed test:
SHA-1 throughput 268,405.03kB/sec with 8k blocks
SHA2-256 throughput 263,643.08kB/sec with 8k blocks
AES-128-CBC throughput 1,029,006.84kB/sec with 8k blocks
AES-256-CBC throughput 779,103.35kB/sec with 8k blocks
[ montmult accel via openssl 0.9.9 bn_mont_mult via-mont.pl asm optimization ]
rsa 1024 394.1 sign/sec, 8710.6 verify/sec
rsa 2048 84.0 sign/sec, 2973.4 verify/sec
rsa 4096 14.2 sign/sec, 866.8 verify/sec
dsa 1024 1024.0 sign/sec, 852.5 verify/sec
dsa 2048 349.2 sign/sec, 294.6 verify/sec
[ to gather your own stats invoke "openssl speed" ]
best regards,

@_date: 2007-05-18 14:04:58
@_author: coderman 
@_subject: tor plus openssl hardware? 
seems to work great, but i've only used it as a client.
as Nick mentioned, Tor can handle engines in openssl with the config
option.  if you have a C7 with PHE and MONTMULT i've got a temporary
patch here:
that includes RSA/DSA acceleration via the new bn_mont_mult extension
backported from 0.9.9 and includes the above patches.  use at your own
you will need a kernel that recognizes the phe_en instruction for the
config to work:
grep flags /proc/cpuinfo
flags           : [...] rng rng_en ace ace_en ace2 ace2_en phe phe_en pmm pmm_en
and simply patch against 0.9.8e and configure via:
./config --prefix=/usr --openssldir=/etc/ssl threads shared
you'll probably need to manually copy the .so*'s into
include the patches with so versioning so various debian like systems
won't complain when dynamic linking to these new libs.
BIG WARNING: these binaries are using asm optimized montgomery
multiplication, not as engine, but as platform native optimizations.
this means they will absolutely die on any non-montmult enabled
processor.  C7 only, sorry.
the speed up is impressive:
1.5Ghz C7 with patched openssl speed test:
SHA-1 throughput 268,405.03kB/sec with 8k blocks
SHA2-256 throughput 263,643.08kB/sec with 8k blocks
AES-128-CBC throughput 1,029,006.84kB/sec with 8k blocks
AES-256-CBC throughput 779,103.35kB/sec with 8k blocks
[ montmult accel via openssl 0.9.9 bn_mont_mult via-mont.pl asm optimization ]
rsa 1024 394.1 sign/sec, 8710.6 verify/sec
rsa 2048 84.0 sign/sec, 2973.4 verify/sec
rsa 4096 14.2 sign/sec, 866.8 verify/sec
dsa 1024 1024.0 sign/sec, 852.5 verify/sec
dsa 2048 349.2 sign/sec, 294.6 verify/sec
[ to gather your own stats invoke "openssl speed" ]
best regards,

@_date: 2007-05-18 17:12:46
@_author: coderman 
@_subject: No JavaScript, No Google Navigation 
I haven't tried Google with NoScript, but it seems the latest
"Universal Search" interface upgrade just made it much less friendly:
"If you disable JavaScript in your browser, you'll notice that the
recently updated Google.com doesn't have too many navigational links
anymore. That's because the menu from the top left corner is written
entirely in JavaScript."
has anyone noticed additional features now inaccessible without Java
Script capabilities?
best regards,

@_date: 2007-05-28 03:36:05
@_author: coderman 
@_subject: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
hi Steven; an enjoyable read.  thank you!
i am curious about a few aspects.
you state "an assumption that the global passive adversary is
unrealistic".  is this really true in anonymity research circles?  it
seems the evidence to the contrary is well supported.  i do prefer the
"those who are the target of such adversaries have larger problems
than anonymous Internet access" statement instead.  :)
i am also curious if you had considered lower layer propinquity of
physical paths.  critical infrastructure research has shown how even
seemingly disparate and redundant paths are often inhabiting common
right of way and facilities.  is the assumption that inspection at
OC/WDM layers is too cumbersome/expensive for all but the previously
mentioned TLA/$gov adversaries?
given the surprises looking at network topology from an IX rather than
AS level, i'd expect a similar revelation when viewing from an optical
carrier vantage point.
sadly, the information useful for such study has become a subject of
heated and irrational censorship post 9/11.  i'll stop this tangent
early before i delve into a heated rant about critical infrastructure
and terrorism madness... *g*
best regards,

@_date: 2007-05-28 03:47:22
@_author: coderman 
@_subject: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
one more comment that ties into your mention PCIe bus limitations.
previous research on monitoring high speeds links has shown FPGA
devices well suited for header and deep packet inspect at line rates
up to 10GigE for hundreds of snort style  filter rules. this approach
scales in a linear fashion.
i'll try to find some of the papers on this subject; i don't have them
on hand.  coincidentally, many of those involved in such projects seem
to get sucked into the proprietary/classified commercial and
government sectors. *grin*
it's turtles, all the way down...

@_date: 2007-05-28 04:23:51
@_author: coderman 
@_subject: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
thanks for the clarification.  i tend to forget that the "passive
adversary" applies to all network communication, not just internet
links across isp's, countries, and oceans...
ah, agreed; i was unaware of such a myth, and the thought of someone
trying to inspect 10GigE with a workstation and wireshark is comical.
thanks again for these efforts.
best regards,

@_date: 2007-05-29 09:33:42
@_author: coderman 
@_subject: [OT - interface bandwidth] was: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
veering off topic here, but the vast majority of 10GigE devices have
hardware TCP offload support, which is how OS stacks can push toward
the line limits.  without offload support the checksum and tcp
protocol overhead vastly reduces throughput and taxes the processor.
so inspecting packets at line rates, even simple header matching,
becomes problematic.  if you look at devices designed to do this kind
of inspection on 10GigE and equivalent links (cloudshield, narus, etc)
they all use either custom ASIC's or FPGA's to offload matching.
best regards,

@_date: 2007-05-30 00:00:40
@_author: coderman 
@_subject: Remote Vulnerability in Firefox Extensions 
it would be trivial for a rogue exit to use this technique.  public
wifi users should also take note.
check your firefox extensions!
A vulnerability exists in the upgrade mechanism used by a number of
high profile Firefox extensions. These include Google Toolbar, Google
Browser Sync, Yahoo Toolbar, Del.icio.us Extension, Facebook Toolbar,
AOL Toolbar, Ask.com Toolbar, LinkedIn Browser Toolbar, Netcraft
Anti-Phishing Toolbar, PhishTank SiteChecker and a number of others,
mainly commercial extensions...
Users are vulnerable and are at risk of an attacker silently
installing malicious software on their computers. This possibility
exists whenever the user cannot trust their domain name server (DNS)
or network connection. Examples of this include public wireless
networks, and users connected to compromised home routers.
best regards,

@_date: 2007-05-30 01:36:55
@_author: coderman 
@_subject: SIGNAL NEWNYM and firefox browser settings 
if you are having problems with SIGNAL NEWNYM having no effect it may
be firefox browser settings that are keeping a cached tcp session to
the target host (and/or proxy).
verify that the following are disabled in "about:config"
network.http.keep-alive = FALSE
network.http.max-persistent-connections-per-proxy = 0
network.http.max-persistent-connections-per-server = 0
pipelining is OK.  it does not matter if the following are on or off:
it is suggested that these be enabled for better performance.
best regards,

@_date: 2007-05-30 10:44:59
@_author: coderman 
@_subject: Bandwith donation for some days ? 
if there is anyone with a VIA C7 system they could use there i would
love to assist with a padlock accelerated openssl/Tor node.  i do not
have a link where i can test myself, and this would be a useful
opportunity to see how much crypto offload improves throughput.
i've listed raw openssl stats in a previous message to this list,
along with a link to a patch that combines the MONTMULT acceleration
for RSA/DSA with the patches for AES/SHA offload via padlock dynamic
[my expectation is that zlib compression of traffic will become the
new bottle neck, as crypto overhead drops off.  i am very interested
to see a real world test though...]
best regards,

@_date: 2007-09-10 18:16:37
@_author: coderman 
@_subject: a changing network security landscape is difficult for even the biggest tech companies to wrestle with 
five weeks after presenting the dangers at BlackHat, Google, eBay,
MySpace, Yahoo, Microsoft and a slew of others are still unable to
resolve the problem. [0]
the spreading popularity of wireless data networks may do more for
protecting Tor users against malicious exit nodes than any other
efforts in progress.  perhaps big names pushing the HTTPS message will
help inform and protect users who seem to give little heed to the
prominent and oft repeated instructions to ensure encryption is used
over Tor when privacy of content, in addition to location, is needed.
it's been interesting to watch 10 years of wireless data network
deployments evolve from high dollar corporate manufacturing domains
into a myriad of applications, from free community wifi to city wide
metro networks, business offices and hotels saturated with access and
even truck stops offering high speed connectivity.  the first FHSS
deployments i was involved in that long ago gave no thought to
security; an unencrypted, open link to the corporate intranet
communicating with ERP databases literally driving the entire
enterprise wasn't even a blip on the radar.  when a radio costs $2000
and an access point multiples of that, the risk was low even though
the security was non-existant.
now the inverse is true, and perhaps the tide will shift to adapt to
the new realities that have brought long known weaknesses to the
forefront of the discussion.  Google, as much as we all loathe their
data retention policies, appears to be doing the most in this regard.
hopefully the others will take notice and users themselves will change
behavior as these subjects become ever more visible. [1]
next time someone gives Tor heat for the perceived risks of an
untrusted network i'll point to the nearest access point and ask why
web 2.0 doesn't get it's share of scrutiny for the same tough
problems. :)
best regards,
0. Web sites may transmit authentication tokens unencrypted
      ... still no progress, with the companies in question dragging their feet...
1. World's biggest websites no match for decade-old web bug
 US CERT warned that Google, eBay, MySpace, Yahoo, and Microsoft were
vulnerable, but that list is nowhere near exhaustive. Just about any
banking website, online social network or other electronic forum that
transmits certain types of security cookies is also susceptible.
Indeed, awareness of this man-in-the-middle vulnerability is by no
means new. For more than a decade people have known that
authentication cookies could be manipulated, but somehow it took the
folks at Errata Security to make a presentation at Black Hat to remind
the world that the risks continue.
But you'd think the collective brainpower and considerable
pursestrings at the world's most elite tech companies would by now
have found a way to tackle a problem that leaves attackers free to
rifle through their users' most intimate details. It begs the
question: is this problem unsolvable or are these guys simply
uninterested in figuring it out?
If you're waiting for a fix, we recommend you pack a very large lunch.
And beyond that, where possible you might switch to Google, which has
already gone a long way to closing the hole.
As the only web-based email service we know of that offers a
start-to-finish SSL session, the service is among the most resilient
to cookie hijacking. Unfortunately, Gmail doesn't enable persistent
SSL by default, and has done little to educate its users about its

@_date: 2007-09-11 11:53:14
@_author: coderman 
@_subject: How can I know my IP address geted by the website? 
ok, there is no easier way than to request your public IP from some
public service.  the reason for this is that there are a number of
exit nodes that exit traffic from a different IP than their OR port
listens on.

@_date: 2007-09-11 11:54:11
@_author: coderman 
@_subject: How can I know my IP address geted by the website? 
this will provide the IP address the OR port for that node listens on.
 this is frequently not the same as the IP the traffic exits from when
using that node.

@_date: 2007-09-11 23:55:28
@_author: coderman 
@_subject: How can I know my IP address geted by the website? 
you need to listen to asynchronous circuit and stream events.
this will still give you incorrect information for over 100 exit nodes
that exit traffic from a different IP address than the OR port listens
what you want to do requires a check with an external service to
correctly identify the public IP.  there is no other way around it...

@_date: 2007-09-12 04:03:37
@_author: coderman 
@_subject: How can I know my IP address geted by the website? 
correct.  you would need to verify the exit IP for every exit node in
the active (built + streams attached) circuit list.  this verification
requires an external host as described above.  (some such services
provide a cross reference between the node fingerprint and/or public
IP and the exit IP).
best regards,

@_date: 2007-09-13 15:44:41
@_author: coderman 
@_subject: end-to-end encryption question 
please read a bit more about the Tor design and implementation.  it is
trivial to know if a client is trying to reach a directory authorities
or nodes caching directory information based on the router info
you still need to bootstrap them into the network to be able to create
circuits this way.  see AllDirActionsPrivate and some of the new
bridge features recently developed.
best regards,

@_date: 2007-09-13 23:39:17
@_author: coderman 
@_subject: a changing network security landscape is difficult for even the biggest tech companies to wrestle with 
vulnerable against a MITM that can request / inject an HTTP page,
frame, or item to the site.  this would expose the auth cookie and
allow hijacking of the account.
for solely passive monitoring, as long as everything is HTTPS it will
be protected. (for example, gmail via https)
yes.  then if a MITM tries to request a non encrypted resource of any
type, the cookie will not be sent with that request, protected the
authenticated session.
if they do this, you're back to square one.  a dirty hack i've been
using is to configure adblock to block all http:// requests to a site
that i access via https.  if an attacker tries to inject a link to a
resource that is not SSL protected it gets blocked.
most sites are like this, and simply don't support encryption for the
full duration of a session (limiting encryption to only log in for
yup.  these sites are irrevocably broken.
best regards,

@_date: 2007-09-04 11:50:49
@_author: coderman 
@_subject: Directory server errors: can't connect 
if you've put the TunnelDirConns options in your config as directed
above your routers should be updated privately from now on.
if UAE starts more aggressive blocking, you may need to consider using
the new bridge features in the latest versions of Tor.
best regards,

@_date: 2007-09-06 10:49:59
@_author: coderman 
@_subject: Odd tor spam 
if you manage to stop the storm trojan i'll be impressed. :)

@_date: 2007-09-01 01:45:45
@_author: coderman 
@_subject: Warning about the TOR exit node "snailitper" 
very probably.  (this happens from time to time, and is one of the
reasons Snakes on a Tor and other such tools/scanners exist :)
oops!  usable security is still nearly non existent these days, hard
to fault her too much...
it's also hard on certificate revocation lists.  but i digress...
IE should only be used with Tor in a transparent proxy configuration
(like JanusVM).  otherwise, the integration of various non-proxied
services with browser / document handlers in win32 API leaves you
vulnerable to side channels.
this may be elaborated on further in the future...
best regards,

@_date: 2007-09-10 06:55:25
@_author: coderman 
@_subject: =?WINDOWS-1252?Q?Tor_at_heart_of_embassy_passwords_leak;_"ToR_isn=92t?= =?WINDOWS-1252?Q?_the_problem,_just_use_it_for_what_it=92s_made_for."?= 
[std disclaimer: i am not speaking on behalf of the Tor project nor
any developers or employees of it.  i know Roger likes to avoid even
the appearance of such relationships with rogue third parties so i'll
void such notions up front *g* ]
Dan Egerstad published some more details about the source of his
embassy password list:
anonymouse pointed this out back on sep. 1st and also seems to imply
that some kind of active MITM against SSL/TLS was used:
(ok, mea culpa. if i'm going to use a pseudonym to post i should
really use Tor to do it *grin*.  the reason i claimed he was also
performing an active MITM is that i've seen this done from at least a
few exit nodes against encrypted mail protocols with forged
certificate CN and other elements.  i assumed at the time the list was
published it was Dan running these exits, but it may well be others
and he was solely sniffing plain-text credentials.  perhaps he will
clarify with a bit more detail :)  some additional comments at end of
this msg [0].
Dan correctly states in bold that "ToR (sic) isn't the problem, just
use it for what it's made for.".  this highlights the complexities and
subtleties of implementing Tor properly at both an application layer
and network layer; the details are complicated and carelessness will
get you into trouble, sometimes a lot of it...  (more to come on this
subject later this month)
one thing i don't agree with is the concern about some of the node
operators. "Criminals, hackers and Governments are running nodes,
there is really no reason you should trust an apparently honest
looking node more than one hosted by a government or a hacker group.
the strength of Tor's privacy comes from the decentralized nature of
node contributors; restricting the ability to contribute only
diminishes the scope of this decentralization, thus weakening your
privacy.  (not to mention suspicions fabricated against other nodes in
such an environment are useful methods to further weaken it against a
determined adversary.  recall the damage of just "some guy in IRC" as
Nick outlined so succinctly :)
expecting privacy of your traffic exiting a given node is an entirely
different matter however, and hopefully this incident and the others
like it that have occurred before (and no doubt will occur again) show
that private information (authentication credentials, personally
identifying details, etc) must never be sent in plain-text, no
exceptions.  public wireless networks are in a very similar situation
and the majority of users there are just as careless.  this will be a
painful lesson, again and again, for those who continue to ignore the
one last interesting tidbit posted on the 6th:
Our site got shut down and we stood there not knowing why, couldn't
get any information from anyone. You aren't going to like the answer
we just dug up.
* American law enforcement officials requested DEranged Security to be
taken down *
Woho, we pissed the US of! But why? Millions of people have already
read the story and tens of thousands have those passwords.
this is indeed interesting as Dan stated that the list of passwords,
even those not disclosed, did not involve any US Gov embassies or
state side facilities.  i don't remember where this comment was made,
perhaps in the comments now lost.  Dan, if you're reading this, please
correct me as needed :)
best regards,
0. more tangential commentary
0.a. the active MITM fun:
i won't say how exactly i was sure Tor was involved in the password
disclosures, but suffice it to say that just the destinations
themselves are indicative to someone paying attention, even without
watching exit traffic.  (and maybe origins too :)
as for the SSL/TLS MITM, i've seen this from some exits, and this is a
well known issue.  (even at defcon 13 one of the feds "spotted" was
exposed because his blackberry or other email client was not handling
forged certificates correctly and failed back to an insecure mode of
operation during an active MITM over the wireless there.  he was
assured by his tech staff that he would be safe because "SSL is being
used".  oops!)
refer to active protocol-version rollback attacks and social
engineering tricks used to break SSL/TLS privacy for more details.
so Dan, if this wasn't you after all, my apologies.
0.b. node reputation and automated detection of malicious activity:
it would be nice to extend torflow and/or snakes on a Tor to perform
SSL/TLS certificate checks for various protocols like https, imap-ssl,
etc.  these tools (and the scanner running on peertech) can detect
malicious DNS and web page hi jinx fairly quickly.  the remaining
protocols, however, are probably not getting looked at by anyone.
likewise, such tools once available would be a great fit for the
voting / node reputation proposals in the works.  marking these nodes
as bad exits quickly would help contain the impact of such rogue
nodes, even if strong privacy is implemented (since an active SSL/TLS
MITM would at least produce a denial of service in a good
0.c. pissing off 'The Powers That Be' (tm) and "not winning any friends", etc
 "Directly to the people in the security industry out there
to clarify some stuff. There is no exploit to publish, no vendor to
contact. This have been told about before with no reactions.
Publishing it yet one more time wouldn't have changed crap. Even after
publishing a full disclosure list like we did, it was first thought of
like BS and done nothing about."
you have to cede some credit to this argument, despite the fact that
such a method undoubtedly pisses people off in the process.  a
favorite comparison of security and dentistry is useful to put this
into context; it may be uncomfortable and painful, but just like those
vegetables mom makes you eat it's good for you in the long run:
the proof-of-concept Tor attack this summer is a similar learning
experience, even if not the wisest idea to implement.  the Tor
developers had a patched version ready within HOURS (not days, and
certainly not weeks/months like many vendors) after it hit.
this highlights the ability of the Tor team to react swiftly and
effectively to counter even the most malicious 0day that drops out of
no where.  (hopefully a very rare event not to been seen again for a
long while :)
additionally, the nature of the flaw associated with this event was
known years ago (though we weren't aware of the research at the time
either :), and a question about the security of the Tor control port
specifically was posted to this list about a year ago without much
consideration.  full disclosure can be useful to "encourage" prompt
attention to weaknesses that expose clients/users to risks that may
otherwise be deemed insignificant, not exploitable, or simply "too
much trouble/cost/time/bad-pr to fix".
0.d. on security in general:
or, "it's the attackers who determine the effectiveness of security in a system"
Peter Gutmann made an excellent point about the nature of assessing
the effectiveness of security mechanisms implemented in a given system
in a thread about the economics of security:
 at metzdowd.com/msg07940.html
We already have really, really good metrics for this.  It's called the
commercial malware industry (blatant ad: see my Defcon talk from last week for
examples of exploit sales and pricing models).  To find out how secure
something is, look at how much exploits for it are selling for on the black
... it could be argued that the best
real-world metric that we have for security comes from the attackers, not the
(Incidentally, this powerful real-world metric is telling us that the
existing browser security model is indistinguishable from placebo :-).
this is exactly the reason why the janusvm developers are always
trying to attack our own software and implementation to probe for
weaknesses that may have been overlooked and verify the assumptions of
our threat model and capability of attackers against it.  this is
called "red teaming" and the government and industry have found it
indispensable for decades.
(we're failing in some other important areas though, particularly
documentation to clearly define our threat model and implementation in
detailed specifications, as well as sources and processes related to
development of it. I promise Roger, this is being worked on, it is
just a lot of work and we're very distracted with day to day
responsibilities like onerous day jobs, meat-space drama, and the
various other time sinks that slow our progress toward this goal.
many thanks to those who have donated to janusvm; we appreciate it, it
has helped us directly, and will make good on getting it documented
and more transparently developed.)
"PS: Data and hard drive on each node is destroyed and I forgot
everything somehow"
lol !
... i understand this sentiment completely.  :P
best regards,

@_date: 2007-09-10 09:49:08
@_author: coderman 
@_subject: =?WINDOWS-1252?Q?Re:_Tor_at_heart_of_embassy_passwords_leak;_"ToR_isn?= =?WINDOWS-1252?Q?=92t_the_problem,_just_use_it_for_what_it=92s_made_for."?= 
the main difference is that your ISP (unless it is a wireless one)
will rarely expose you to active man in the middle attacks.  this does
make certain types of attacks possible that cannot be implemented in a
fully passive manner.
best regards,

@_date: 2007-09-10 11:16:54
@_author: coderman 
@_subject: How can I know my IP address geted by the website? 
i'm not sure what you mean by "control commands".  you can possibly
use the scripted interfaces or exit data from peertech. [0]
the Tor DNSEL may also be useful for this purpose:
best regards,
0. tor port 80 exit checks
the client info page with headers, etc.:
  or
wget -qO - exit information lists:
fields are nickname, fingerprint, exit IP, uptime (sec), bandwidth (kB/s)

@_date: 2007-09-10 11:16:54
@_author: coderman 
@_subject: How can I know my IP address geted by the website? 
i'm not sure what you mean by "control commands".  you can possibly
use the scripted interfaces or exit data from peertech. [0]
the Tor DNSEL may also be useful for this purpose:
best regards,
0. tor port 80 exit checks
the client info page with headers, etc.:
  or
wget -qO - exit information lists:
fields are nickname, fingerprint, exit IP, uptime (sec), bandwidth (kB/s)

@_date: 2007-09-10 11:26:22
@_author: coderman 
@_subject: =?WINDOWS-1252?Q?Re:_Tor_at_heart_of_embassy_passwords_leak;_"ToR_isn?= =?WINDOWS-1252?Q?=92t_the_problem,_just_use_it_for_what_it=92s_made_for."?= 
fair enough; i'll suggest that the vast majority of ISP's don't have
the equipment or skill to implement these kinds of MITM attacks.  (can
you imagine trying to play eve against arbitrary customer traffic on
an OC12+ link?  that cisco switch isn't going to cut it...)
they are out to make a profit, and spending non-trivial amounts of
money for something that can only negatively impact the customer
experience is a total loss.  (note that even CALEA had to sweeten the
deal for carriers just for passive eavesdropping capability which is
trivial compared to complex layer MITM attacks)
i'd love to know more about any such ISP implemented MITM
"investigative techniques" that may have been used; i've never heard
of such, but perhaps they are simply uncommon and rarely publicized.
best regards,

@_date: 2007-09-10 11:41:46
@_author: coderman 
@_subject: =?WINDOWS-1252?Q?Re:_Tor_at_heart_of_embassy_passwords_leak;_"ToR_isn?= =?WINDOWS-1252?Q?=92t_the_problem,_just_use_it_for_what_it=92s_made_for."?= 
agreed; i suppose the difference depends on the desired result.  if
you want to snag passwords it only takes once, and the temporal nature
of Tor exit streams is no problem.
if you want visibility into the entirety of communication from a peer
the rolling exits are a problem.
best regards,

@_date: 2007-09-10 11:46:56
@_author: coderman 
@_subject: =?WINDOWS-1252?Q?Re:_Tor_at_heart_of_embassy_passwords_leak;_"ToR_isn?= =?WINDOWS-1252?Q?=92t_the_problem,_just_use_it_for_what_it=92s_made_for."?= 
er, that should be mallory, not eve :P
(regarding the equipment required to do MITM on high bandwidth links,
i wonder if any of the enterprise network policy enforcement equipment
that is becoming increasingly popular could achieve this.)
best regards,

@_date: 2008-04-05 19:49:46
@_author: coderman 
@_subject: clock jump in 0.2.0.23-rc, too 
i'm curious to know if your configure script is perhaps doing
something wonky; can you determine if there are changes in the link
flags, config.h, or -D defines between these two versions that
configure may be generating?
in particular, i'm curious if something in a failed configure setup is
causing your tor_gettimeofday wrapper to use ftime() instead of
best regards,

@_date: 2008-04-05 19:49:46
@_author: coderman 
@_subject: clock jump in 0.2.0.23-rc, too 
i'm curious to know if your configure script is perhaps doing
something wonky; can you determine if there are changes in the link
flags, config.h, or -D defines between these two versions that
configure may be generating?
in particular, i'm curious if something in a failed configure setup is
causing your tor_gettimeofday wrapper to use ftime() instead of
best regards,

@_date: 2008-08-14 14:26:30
@_author: coderman 
@_subject: No torrc in xBBrowser 
instructions for building the browser bundle are at:

@_date: 2008-08-22 20:22:08
@_author: coderman 
@_subject: AVG + TOR = BARF 
that really is the crux; email passes through so many possible hops,
usually unecrypted (and even when the payload itself is encrypted,
subject and other headers are not).
i don't understand how/why many people think email can be private.  it
fails silently and frequently; truly good end to end and inter-MTA
authenticated and private email is a usability and configuration
use off the record [0] or something equivalent for private
conversations!  you get clear indication of state (private/not
private) and it was designed for end to end privacy.
(just my personal opinion :)
FDE is an excellent suggestion though, and something everyone should enjoy.
best regards,
0. Off-the-Record Messaging

@_date: 2008-08-25 09:46:28
@_author: coderman 
@_subject: [Fwd: [Fwd: Not getting copied my posts to or-talk]] 
this is a feature of google mail / gmail.  it collapses conversations
into distinct messages; since you sent the message, it sees no reason
to deliver it back to yourself.
you can find the message in your outbound mail folder, and confirm it
was received via the external mail list archives, if needed.
best regards,

@_date: 2008-08-09 12:47:32
@_author: coderman 
@_subject: Gmail/SSL 
an update of note: Gmail now supports an account option to enforce the
secure only bit on session cookies and keeps your entire gmail session
on SSL.  this makes attacks like Mike Perry's active side jacking
impossible, as the session cookie is no longer sent in the clear when
http:// non-SSL links are injected into browser content.
to enable this feature:
- at top of page select "Settings"
- scroll to bottom of section for "Browser connection:" preference
- select "Always use https"
this will pass the Secure / secureonly option when settings the GX=...
session cookie used to identify your authenticated session.  this
cookie will then never be sent over plain-text connections, protecting
you from passive / active side jacking attacks.
be sure to use a somewhat modern browser that supports secure only
cookies.  you can also verify correct operation with the "Live HTTP
Headers" plugin for Firefox.
best regards,

@_date: 2008-12-11 12:57:49
@_author: coderman 
@_subject: problem while trying to fetch 0.2.1.8-alpha 
is it possible you have an old openssl cacerts package without the
newer ev signing and root ca's?
(you can tell wget to use an explicit trusted ca cert file if necessary)
 openssl s_client -connect  -showcerts
indicate anything unusual during session negotiation?
best regards,

@_date: 2008-12-11 12:57:49
@_author: coderman 
@_subject: problem while trying to fetch 0.2.1.8-alpha 
is it possible you have an old openssl cacerts package without the
newer ev signing and root ca's?
(you can tell wget to use an explicit trusted ca cert file if necessary)
 openssl s_client -connect  -showcerts
indicate anything unusual during session negotiation?
best regards,

@_date: 2008-12-18 22:35:16
@_author: coderman 
@_subject: System Proxyfier for Windows: WideCap 
by default nothing is proxied and the user interface requires
individual applications to be selected for proxy.  as Kyle mentioned
this is insufficient protection for Tor users since various Windows
services may access network resources outside application proxy
if WideCap were to default all applications proxied that would be more useful.
this is the model of operation for the early work done on Tor in a VM
for Windows:
  please heed the warnings about the alpha state of this software :)
there are actually two issues (or more?) for non-server Windows
running Tor.  the usual problem Tor encounters is not related to the
number of concurrent attempts but to kernel non-paged memory resources
consumed to exhaustion when lots of active non-overlapped-I/O sockets
are in use.  details here:
the concurrent connection attempt limit is easier to fix, although
messing with system files is generally not advised!
best regards,

@_date: 2008-12-19 14:40:16
@_author: coderman 
@_subject: Windows buffer problems 
this is a little odd.  there is a different option useful for virtual
servers (and seems to help with the WSAENOBUFS too) called
ConstrainedSockets.  this will use setsockopt()  to limit the size of
send and receive buffers associated with each socket.  the
ConstrainedSockSize parameter can lower or increase from the default
constrained size.
i wonder if the person reporting that behavior allowed TCP windows to
scale above 1M so constraining them to 1M limit helped (but still
seems high).
i don't think this is quite as common, and is reported as an error
distinct from the too many concurrent pending and buffer exhaustion
dropping the time wait state is a good idea.  i have to do this for
other connect heavy applications in a different setting to keep within
global kernel limits for max open files.  by default this is usually
around 4 minutes.  that's a long time to tie up scarce kernel buffer
resources and/or file descriptors.  i don't know how useful this would
be for Tor servers; a good experiment for someone to try perhaps! :)
best regards,

@_date: 2008-12-21 22:59:09
@_author: coderman 
@_subject: problem while trying to fetch 0.2.1.8-alpha 
yup, that appears to be it.  (looking at the certs you got).
nothing nefarious, aside from another random root added to your circle
of trust :)
you can download via:
you want:
verify things look good:
openssl s_client -CAfile Equifax_Secure_Global_eBusiness_CA-1.cer
-connect  -showcerts
    Verify return code: 0 (ok)
and to use this with wget:
 wget --ca-certificate=Equifax_Secure_Global_eBusiness_CA-1.cer
best regards,

@_date: 2008-12-23 14:00:49
@_author: coderman 
@_subject: Perfect MITM attack with valid SSL Certs 
this is why i am fond of the petname toolbar to identify server
certificates using local trust information rather than assuming any
cert signed by any of the dozens of random CA's bundled with Firefox
is legit:
  for other applications that use system or application CA certificate
stores you've got fewer options.  if you're really concerned you can
extract the few roots you trust into a new certificate store and tell
the app in question to validate against those CA's only.
supposedly extended validation certs will restore trust in the PKI
hierarchy, but i'm not holding my breath...  *grin*
best regards,

@_date: 2008-12-29 10:53:58
@_author: coderman 
@_subject: User tor issue 
you'll need to set HardwareAccel 1 like you mentioned.  then you should see
"Initializing OpenSSL engine support." followed by the engine used for
various cipher primitives. (RSA,DH,AES,etc...)
best regards,

@_date: 2008-12-29 11:19:29
@_author: coderman 
@_subject: User tor issue 
you are correct; my apologies.
by the time tor_tls_init invokes crypto_global_init it should have
been initialized correctly based on the config option as you describe.
are you not seeing the hardware accel log entries at all?  or is this
a question about the (potentially misleading) call from tor_tls_init?
btw, if you want to force OpenSSL hardware acceleration without
requiring application intervention see:
best regards,

@_date: 2008-12-30 07:54:28
@_author: coderman 
@_subject: User tor issue 
yes, you're fine.  just a note: the no-rng is a good sign - you are
expected to use an entropy daemon that does fips sanity checks on
garbage.  (usually called rngd)
best regards,

@_date: 2008-12-30 10:08:26
@_author: coderman 
@_subject: User tor issue 
another suggestion: you could try openssl 0.9.9 (devel) with the
montgomery multiplier acceleration to speed up some of the rsa/dsa
openssl engine padlock
(padlock) VIA PadLock: RNG (not used) ACE2 PHE(8192) PMM
PHE is the sha1 padlock hash engine
PMM is the MONTMULT accel
best regards,
.. any further discussion down this tangent should probably be taken
off list for brevity.  let me know directly if you're still having
trouble with the hardware throughput.

@_date: 2008-12-31 10:55:36
@_author: coderman 
@_subject: problem while trying to fetch 0.2.1.8-alpha 
ah the joys of PKI.  Tor has been changing certs.  new roots are
 and "Entrust Secure Server
CA" is the one you want.
i believe the check.torproject.org and blog.torproject.org will be
changing soon as well.
best regards,

@_date: 2008-02-13 03:49:32
@_author: coderman 
@_subject: threaded Tor utilization / dtls work 
this paper and patch for a multi-threaded cipher suite for ssh/scp on
multi-core servers is very effective:
in regards to the proposed udp / dtls proposal, many of the same
tricks apply to udp (socket buffer tuning, thread pools and event
based socket handling (SEDA), etc.)
is a new revision of the dtls proposal required before the datagram
transport work is started? particularly reliable delivery via airhook
or equivalent for existing TCP stream support?
best regards,

@_date: 2008-01-09 08:15:14
@_author: coderman 
@_subject: 24C3: Current events in Tor development 
hi Roger,
this looks like an interesting talk; i wish i could have seen it in
person.  some comments...
is there any research / observations to support this claim?  i'm
curious.  (i think Tor will always be "slow" compared to direct
traffic.  this is a feature, not a bug, and exists independent of any
particular transport protocols...)
i wish i could add a prerequisite before this item: "Implement
datagram based transport" :)  commodity routers even now have problems
with NAPT table entries for busy Tor / other network apps.  a UDP
transport would open up effective new NAT busting abilities and bypass
some of the windows / weak router NAT table conn tracking issues that
make scaling the existing TCP implementation difficult.  i know the
DTLS proposal hasn't seen any attention lately.  is this potentially
going to resume sometime, or is an entirely new proposal needed?  (the
UDP section mentions more research / hacking, maybe even both? :)
best regards,

@_date: 2008-01-09 10:34:00
@_author: coderman 
@_subject: 24C3: Current events in Tor development 
things i would add to a revised DTLS proposal in my copious free time:
- preserve TCP support while converting all traffic to DTLS; use
airhook [0] like library for transparent TCP, SOCKS, and reliable Tor
messaging (signalling channel).
- use a virtual machine implementation to avoid timer resolution and
event dispatch latency in win32, in addition to traffic shaping (pf or
tc) on the VM for outgoing DTLS control and transport traffic.  UDP,
TCP and name resolution could then be supported transparently to the
user/host os while running on a fast event based unix implementation
in vm.  traffic shaping is going to be critical to keeping latency low
(buffers on broadband CPE devices can incur up to 1-2 seconds of
latency when send queue is maxed out...)
- UDP NAPT busting, including symmetric and full cone UDP NAPT
detection and assisted simultaneous open.  UPnP would of course be
just as useful for UDP port assignment as for TCP...
- the TCP support could be kept in place for bridge nodes, as DTLS Tor
will stick out like a sore thumb on a network.  the "Web HTTPS"
looking sessions to bridges would be useful when UDP/DTLS is blocked.
0. Airhook - Reliable, efficient transmission control for networks that suck.
   * this is likely to be useful in a Tor DTLS environment, as it is for
wireless, because most TCP stacks are going to treat the intermittent
lag / packet loss of the multiple DTLS hops as "congestion", leading
to poor throughput.  this is similar to the situation with wireless
where temporary congestion or 802.11 timeouts are treated as
"congested network" by most TCP stacks, rather than just "less than
ideal wireless network".

@_date: 2008-01-12 23:09:54
@_author: coderman 
@_subject: RemoteControl dev trouble (510 Unrecognized command) 
try carriage return, then linefeed: "\r\n".
best regards,

@_date: 2008-01-30 16:09:52
@_author: coderman 
@_subject: Hypothetical: Totalitarian regimes & virtual servers abroad? 
reputation in decentralized systems is hard, and the best protection
is a solid implementation that resists attacks from rogue exits (which
will always occur to some degree).

@_date: 2008-01-02 14:41:16
@_author: coderman 
@_subject: Your computer is too slow to handle this many creation requests! 
compression (zlib) is the Tor bottleneck on a 1.5Ghz C7.  crypto
throughput with patched openssl (dynamic padlock engine) is:
SHA-1 throughput 268,405.03kB/sec with 8k blocks
SHA2-256 throughput 263,643.08kB/sec with 8k blocks
AES-128-CBC throughput 1,029,006.84kB/sec with 8k blocks  -> yes, 8Gbs of AES!
AES-256-CBC throughput 779,103.35kB/sec with 8k blocks
[ montmult accel via openssl 0.9.9 bn_mont_mult via-mont.pl asm optimization ]
rsa 1024 394.1 sign/sec, 8710.6 verify/sec
rsa 2048 84.0 sign/sec, 2973.4 verify/sec
rsa 4096 14.2 sign/sec, 866.8 verify/sec
dsa 1024 1024.0 sign/sec, 852.5 verify/sec
dsa 2048 349.2 sign/sec, 294.6 verify/sec
hardware entropy throughput is 50kB/sec to 8+MB/sec depending on
XSTORE instruction and user space entropy daemon configuration.
best regards,

@_date: 2008-07-14 11:03:03
@_author: coderman 
@_subject: Exit node connection statistics 
this is why use of SSL/TLS over Tor is so strongly encouraged.
the strongest argument is not for the privacy of those who exit your
node, but your own personal liability for knowing what exits your
node.  see the Tor Legal FAQ:
Should I snoop on the plaintext that exits through my Tor relay?
No. You may be technically capable of modifying the Tor source code or
installing additional software to monitor or log plaintext that exits
your node. However, Tor relay operators in the U.S. can create legal
and possibly even criminal liability for themselves under state or
federal wiretap laws if they affirmatively monitor, log, or disclose
Tor users' communications, while non-U.S. operators may be subject to
similar laws. Do not examine the contents of anyone's communications
without first talking to a lawyer.
best regards,

@_date: 2008-06-10 21:44:39
@_author: coderman 
@_subject: How are hackers breaking Tor and trojan users? 
this is a pretty strong statement and unsupported for any more complex
attack against a host.  to claim immunity from 0day is to ignore the
(less likely) use of multiple exploits against a virtual machine
environment for escalation of compromise of the guest up to full
control of the host. [0] [1] [2] [3] [4] [5] [6] [7] [8]
that is not to downplay the benefits of a vm model with isolated
network stack; this provides a clear improvement in terms of defense
in depth and reducing attack surface available to attackers (to use
against you).
unfortunately, without fundamental and sweeping changes in the way
software is designed, implemented and used the 0day is here to stay,
no matter who you are...
best regards,
NOTE: i'm picking on vmware to prove a point (and because they're such
an easy target!) but the lesson applies to all virtual machines or
hyper visor implementations crafted by human brains...
0. 1. 2. 3. 4. 5. 6. 7. 8. [ ... no need to continue beating this dead horse ... ]

@_date: 2008-06-02 00:48:45
@_author: coderman 
@_subject: relay tidbits... 
how do you determine?
that is the crux, and since you cannot do so, you open yourself to
legal liability and target a subset of the legitimate users as well.
this is not to say that better education of users about authenticity
and privacy over Tor is not needed, but that exit sniffing is a risky
and less effective way to do so.
best regards,

@_date: 2008-06-11 19:22:49
@_author: coderman 
@_subject: How are hackers breaking Tor and trojan users? 
that is a standard HTTP post and thus sends HTTP request headers
before the textarea form payload.
what Robert indicated is that he thinks it is highly unlikely that you
could use a browser to connect and send AUTHENTICATE before anything
else, like the request headers.
the challenge / response handshake he suggested is an interesting
option for authenticating to the control port; it would indeed
eliminate any blind injection attacks, while still making it trivial
to use the control port legitimately.
best regards,

@_date: 2008-06-02 17:48:36
@_author: coderman 
@_subject: relay tidbits... 
see proposal 129: rejecting plaintext ports:
this would be quite useful, and help Tor fail safe when a user is not
sophisticated enough to understand how their use of Tor might
compromise the privacy of accounts they access.
sure, why not?
best regards,

@_date: 2008-06-02 17:52:42
@_author: coderman 
@_subject: relay tidbits... 
note that this is implemented in Tor (no longer a proposal), however,
the harder part is exposing this information to the user in a
meaningful way.
i don't know how or if vidalia, portable Tor, tork, xB browser, and
other such bundles make use of these new warnings, but at least the
ability to provide some feedback about potentially unsafe usage

@_date: 2008-06-04 11:52:29
@_author: coderman 
@_subject: OpenSolaris? 
i'm confused.  you want to run a node on Solaris on EC2 to achieve
higher throughput?
this is not likely to work as well as you expect, as the current
implementation of Tor has a hard time utilizing multiple processors
for the bottleneck crypto operations.  a grid computer with multiple
virtual cores is likely to have the same issues with load
you will most likely be limited by the crypto power of a single
virtual core, regardless of how many are configured.
i'd be interested to hear how this experiment goes, if you do try it.
for better performance, you might consider using hardware crypto
offload to improve throughput.  this is known to work to well, and
some crypto acceleration is effective enough that the
compression/decompression is now the bottleneck for a Tor router.
there are a number of such add in cards and even some CPU's with
crypto acceleration built in (VIA padlock).
best regards,

@_date: 2008-06-01 13:19:05
@_author: coderman 
@_subject: multiple connections to ORPort from one IP address 
multiple clients (multiple Tor instances) behind the same NAT at a
school, for example.  or multiple clients someone is testing behind
their DSL router.  etc, etc.
i'm assuming you are excluding TIME_WAIT and other expiring socket states...

@_date: 2008-03-03 15:02:52
@_author: coderman 
@_subject: Defeat Exit Node Sniffing? 
On Mon, Mar 3, 2008 at 2:08 AM, Marco Bonetti
with a rogue exit node you also need to be aware of intentional
injection of   since google does not bind authenticated
session cookies to ssl only (secure only flag) you need to mitigate
this yourself.  otherwise, a single  will expose
your session cookie and permit session hijacking.
i've done this via one of two ways, and there are certainly many ways
to skin this cat:
1. use adblock or proxy filter to explicitly block all plain text
http:// requests to google.com domains.
2. use proxy to mangle the cookie settings for the authenticated login
to force secure only before it is sent to the browser.
the former breaks lots of google services that are not available via
https, the latter is a pain in the  to configure.
best regards,

@_date: 2008-03-03 22:50:12
@_author: coderman 
@_subject: I am at my wits end, I cant register for account at digg.com using tor 
you won't be able edit wikipedia articles via Tor either (probably),
and other sites may behave differently if they detect you're coming
from a Tor exit.
this is either a feature or a bug, depending on your viewpoint.
in either case, Tor is working correctly.

@_date: 2008-03-03 22:50:12
@_author: coderman 
@_subject: I am at my wits end, I cant register for account at digg.com using tor 
you won't be able edit wikipedia articles via Tor either (probably),
and other sites may behave differently if they detect you're coming
from a Tor exit.
this is either a feature or a bug, depending on your viewpoint.
in either case, Tor is working correctly.

@_date: 2008-03-05 16:58:35
@_author: coderman 
@_subject: Defeat Exit Node Sniffing? 
the modification (secure only = true) must be made with every updated
expiration / set cookie received, otherwise a session refresh / save
will save without the secure only option enforced.
it might be easiest to extend the existing modify headers extension to
alter incoming cookie parameters...  (and if you find out, document in
the wiki :)

@_date: 2008-03-10 17:37:43
@_author: coderman 
@_subject: Gmail/SSL 
managing this on your end transparently makes it impossible to
exploit.  you enforce policy of ssl/tls only, always, regardless of
how they may have implemented sessions and authentication on their
end.  (at worst, they break their service rendering it unusable
securely [DoS], rather than leaking your private information
agreed, though exit polices for these ports are not as plentiful...
best regards,

@_date: 2008-03-10 17:47:14
@_author: coderman 
@_subject: Gmail/SSL 
i am referring solely to the auth cookie management here; host and
browser vulnerabilities that bypass SSL/TLS protections are an
entirely different problem...
regarding the modification of cookie parameters via browser plugin,
"Modify Headers" [0] might be a close fit needing only a few tweaks to
implement secure only.
0.

@_date: 2008-03-10 19:29:12
@_author: coderman 
@_subject: Gmail/SSL 
my last comments (to myself :) on this subject for site devs or cookie mungers:
IE since v6 SP1 and firefox 3.x support a 'httponly' cookie option to
prevent scripting access to leak sessions auth.  most web scripting /
libraries already provide this option when sending cookies to the
regarding transparent proxy of SSL/TLS to enforce safe cookie
settings, you have to use a MITM proxy ala webwasher ssl scanner [0].
best regards,
0. Webwasher SSL Scanner
   the PKI hijinx required to implement this securely and transparently
is why i called this a pain in the a ss, even if it is the most
effective way to enforce secure only policy.

@_date: 2008-05-05 09:53:41
@_author: coderman 
@_subject: List of exit nodes wanted 
use the Tor DNSEL implementation.  it is up to date and easy to integrate:
there are code snippets for using the reverse dns lookups in PHP and PERL.
best regards,

@_date: 2008-05-05 09:53:41
@_author: coderman 
@_subject: List of exit nodes wanted 
use the Tor DNSEL implementation.  it is up to date and easy to integrate:
there are code snippets for using the reverse dns lookups in PHP and PERL.
best regards,

@_date: 2008-05-05 10:39:29
@_author: coderman 
@_subject: List of exit nodes wanted 
note that this still entails the other problems mentioned above: nodes
which exit from a different IP address than they listen on for OR
traffic will be a false negative.  nodes that do not provide exit to
the poster's server will be a false positive.
the Tor DNSEL is the correct solution to the problem described in the
original post.
(but thank you for the exit node list links; that's a useful service
for other reasons...)
best regards,

@_date: 2008-05-26 11:33:21
@_author: coderman 
@_subject: security of systems using Tor < 0.2.0.26 [was: JanusVM ...] 
from   Second, all Tor clients and servers running 0.2.0.x should upgrade to
  0.2.0.26...
JanusVM from Oct is running v0.2.0.8-alpha.  wait for an update...

@_date: 2008-05-29 12:52:28
@_author: coderman 
@_subject: de-Tor-iorate Anonymity 
Is this a known or currently unknown weakness/vulnerability?
via: de-Tor-iorate Anonymity
Nathan Evans
Ph.D Student, University of Denver
Christian Grothoff
Feel safe and comfortable browsing the Internet with impunity because
you are using Tor? Feel safe no more! We present an attack on the Tor
network that means that the bad guys could find out where you are
going on the Internet while using Tor. This presentation goes over the
design decisions that have made this attack possible, as well as show
results from a Tor network that reveals the paths that data travels
when using Tor. This method can make using the Tor network no more
secure than using a simple open web proxy. We go over the attack in
detail, as well as possible solutions for future versions of Tor.
also, there is a talk on "Generic, Decentralized, Unstoppable
Anonymity: The Phantom Protocol" which sounds a little used car
salesman like..
is this similar to crowds, tarzan, morphmix, or also unknown at this time?

@_date: 2008-11-11 23:59:41
@_author: coderman 
@_subject: Ping: Kyle Williams: TorVM 
... xeromail is xerobank, right?
is this topletz incognito?

@_date: 2008-11-12 00:18:45
@_author: coderman 
@_subject: Ping: Kyle Williams: TorVM 
sorry.  my apologies to yourself and Steve.  (if he's reading :)
given that Tor in a VM is a work in progress not ready for common use
it is difficult to discuss differences.  i'd say the essential
difference is that the Tor VM work is all open source without a
dependency on VMWare or other closed source virtualization products.
aside from that, you'll probably have to wait a while longer until a
functional release is available for a good comparison.
best regards,

@_date: 2008-11-12 00:39:46
@_author: coderman 
@_subject: Kudos on memory usage in 0.2.X 
along with the 0.2.1.x memory improvements you may want to experiment
with the ConstrainedSockets option.  there has been reported success
using this feature on virtual private servers where kernel and/or
system memory is limited more than usual.  you can read more about
this option in the man page for Tor.
best regards,

@_date: 2008-11-22 13:09:35
@_author: coderman 
@_subject: swap and live CD 
this isn't much of a problem if you use encrypted swap with an
ephemeral / one time key. power off the host (and wait for DRAM to
drain :) and you should be in good shape.
if data remanence attacks are in your threat model you've probably got
bigger concerns about porting your OS around random hardware though.
regarding using the USB for full OS/swap: the duty cycle of flash
memory is significantly less than disk platters. if you can make use
of disk swap safely it would probably be useful to do so.  booting
from read only ISO media also provides some integrity benefit.
(8.10 supports LVM+LUKS which can provide the encrypted swap without
the key management headaches eCryptfs avoids.  and both take advantage
of hardware crypto acceleration in kernel so those with VIA padlock
cores and other crypto offload won't even notice the overhead!)
my $0.02
best regards,

@_date: 2008-11-23 01:09:50
@_author: coderman 
@_subject: tor-0.2.0.32 doesn't compile on Solaris? 
did you specify an architecture when invoking the configure script?
the config.log would be helpful but should probably go in a flyspray
report if needed.
best regards,

@_date: 2008-10-18 15:23:17
@_author: coderman 
@_subject: Tor 0.2.1.6-alpha is out 
it looks like the way to fix this is add a configure check for "flock"
and fall back on fcntl when not present.  for example:
src/common/compat.c: line 508
 HAVE_FCNTL_H
  struct flock fl;
  fl.l_type   = F_WRLCK;
  fl.l_whence = SEEK_SET;
  fl.l_start  = 0;
  fl.l_len    = 0;
  fl.l_pid    = getpid();
  if (fcntl(fd, F_SETLK, &fl) < 0) {
  if (flock(fd, LOCK_EX|(blocking ? 0 : LOCK_NB)) < 0) {
unlock is similar, except you set fl.l_type   = F_UNLCK;
this is a bit of a patch, and unfortunately not many Tor developers /
supporters use Solaris.  it would be nice to have a fix for this,
perhaps if you would be willing to test some patches i could take a
stab at initial support for the fcntl changes.
best regards,

@_date: 2008-09-15 16:11:20
@_author: coderman 
@_subject: Proposed student project 
On Mon, Sep 15, 2008 at 12:17 PM, Kyle Williams
i have been able to run a middle node with 32M guest VM (8M free below
32M limit in OS) for days.  dir cache and exit will increase this, as
does the amount of traffic.
i know some people have used quite a bit less for client only on
routers with 8-16M, and others who need a lot more memory for their
high traffic nodes.  sorry i don't have more quantified results; your
mileage will vary :)
best regards,

@_date: 2008-09-29 17:13:12
@_author: coderman 
@_subject: Force exitnode oddness 
you actually need a proxy that supports the .exit syntax scrubbing,
like privoxy with appropriate rules, in order to use .exit syntax for
a virtual host domain to work properly.  otherwise, the host header
(and possibly other values, like cookie domain) will be incorrect.
best regards,

@_date: 2008-09-10 14:30:17
@_author: coderman 
@_subject: peculiar server "bandwidth" posted by server "mnl" and possible new type of attack 
i'd be curious to compare number of packets with the observed
bandwidth; how much of that 10% is TCP/IP protocol headers that aren't
visible to Tor's bandwidth accounting (which looks at bytes read/write
at socket level).
best regards,

@_date: 2009-04-22 14:13:03
@_author: coderman 
@_subject: How to deal with OS hibernation 
while this is not a problem for clients (they won't be sending traffic
while OS is hibernating) it does cause interruption for others using
your relay as a bridge or exit.
when you terminate and/or OS hibernate any circuits with your relay in
them will fail.  if you are not a guard or stable exit the impact of
this might be minimal in practice.
best regards,

@_date: 2009-08-02 16:12:21
@_author: coderman 
@_subject: Issue creating a private tor network 
i assume you've read the FAQ entry, and you might find an earlier
thread on the subject informative.
best regards,

@_date: 2009-08-02 16:12:21
@_author: coderman 
@_subject: Issue creating a private tor network 
i assume you've read the FAQ entry, and you might find an earlier
thread on the subject informative.
best regards,

@_date: 2009-08-12 22:42:07
@_author: coderman 
@_subject: windows tor 
hi Peter,
there are various reasons for the design decision chosen; a kernel
driver would certainly be useful for non-ethernet Windows clients who
want a transparent Tor proxy.
the advantages of a VM hosting Tor and performing the transparent
redirection is that the Windows TCP/IP stack is bypassed entirely,
avoiding issues with non-paged pool socket buffer resources and many
socket file descriptors/handles.
it is also simpler to write and maintain a Qemu based transparent Tor
proxy virtual machine using existing WinPCAP features for the bridged
network mode and having Windows route through this VM. a kernel driver
to do this would require an intermediate layer driver with hooks into
all of the various L3/L4 protocols and winsock2 / firewall
capabilities (to do securely / properly).
long term it would be great to have a well supported intermediate
layer transparent Tor proxy interface that works on win2k through
win7, however, this is simply too much an effort for the limited
resources available. if you're willing to help with such an effort
that would be great but it sounds like you're already overloaded.
in any case, this solves just one part of the Tor puzzle. you really
do need Firefox and Torbutton to use Tor properly. see
 for all the details. a
transparent proxy mode may protect against IP disclosure side channels
but there are still many other privacy risks worth protecting against.
best regards,

@_date: 2009-08-20 05:07:02
@_author: coderman 
@_subject: Tor/Iptables Question 
try adding:
iptables -A INPUT -p tcp -m state --state ESTABLISHED -j ACCEPT
otherwise that last one is killing all incoming TCP packets.
best regards,

@_date: 2009-08-20 18:27:48
@_author: coderman 
@_subject: More Secure Tor Browsing Through A Virtual Machine in Ubuntu 
hi Curious,
entropy in virtual machines can be a serious problem. (see "Cloud
computing needs more chaos"). this can be mitigated by passing entropy
into the VM and keeping seed state persisted on virtual disk between
runtime instances. further improvement would entail an entropy daemon
like rngd inside the guest VM receiving entropy from the host.
Tor VM does persist the /dev/random seed state on virtual disk and
also hashes the kernel command line passed to the VM for mixing into
guest entropy pool. this has less entropy than would be desired,
i have created a new flyspray to improve this further:
best regards,

@_date: 2009-08-30 15:14:23
@_author: coderman 
@_subject: OpenSSL dynamic hardware engines in 0.2.2.1-alpha 
The new 0.2.2.1-alpha release includes support for dynamic crypto
offload engines in OpenSSL. Two new config options are added to the
existing HardwareAccel boolean:
HardwareAccel 0|1 : If non-zero, try to use built-in (static) crypto
hardware acceleration when available. (Default: 0)
AccelName NAME : When using OpenSSL hardware crypto acceleration
attempt to load the dynamic engine of this name. This must be used for
any dynamic hardware engine. Names can be verified with the openssl
engine command.
AccelDir DIR : Specify this option if using dynamic hardware
acceleration and the engine implementation library resides somewhere
other than the OpenSSL default.
In most cases OpenSSL will know where to find its dynamic engine
shared library files and only "AccelName" needs to be set.
For example, to enable the padlock engine add:
HardwareAccel 1
AccelName padlock
to your torrc.
If the engine is successfully loaded you should see confirmation in
the notices.log similar to:
Aug 30 15:04:17.844 [notice] Tor 0.2.2.1-alpha (git-1092fdca53ec0110)
opening new log file.
Aug 30 15:04:17.864 [notice] Parsing GEOIP file.
Aug 30 15:04:18.374 [notice] Using OpenSSL engine VIA PadLock: RNG
(not used) ACE2 PHE(8192) PMM  [padlock] for SHA1
Aug 30 15:04:18.374 [notice] Using OpenSSL engine VIA PadLock: RNG
(not used) ACE2 PHE(8192) PMM  [padlock] for AES
Best regards,

@_date: 2009-08-04 08:03:14
@_author: coderman 
@_subject: Which proxy to use? 
exit notation as used this way is a deprecated feature. it will be
removed at some point. you really want the controller to direct an
exit for you, if you need it, rather than some mangled domain names
implying the choice.
what are you trying to do, exactly?
best regards,

@_date: 2009-08-07 17:54:56
@_author: coderman 
@_subject: Libevent errors with running Tor on a virtual server 
then you've got a problem. you may not be able to run a useful relay
in this situation. can you contact your hosting provider and see if
they'll make an exception?
you must fix the 1024 ulimit first. once that is resolved, you may run
into the socket buffer issue next and have to set ConstrainedSockets.
best regards,

@_date: 2009-08-08 18:35:31
@_author: coderman 
@_subject: Libevent errors with running Tor on a virtual server 
you are already causing some problems; if someone tries to extend a
circuit or exit a stream through your relay when this happens it will
fail, wasting effort / causing intermittent issues. (they will try
again somewhere else, and succeed, most likely)
well, you don't need to mention Tor specifically. any network
intensive application may need more than 1024 descriptors.
good luck!
best regards,

@_date: 2009-02-12 19:31:58
@_author: coderman 
@_subject: Tor speed 
latency is also an important component to measure.  especially when
content, like html pages, contains many nested elements or links which
require additional connections to other sites.  the latencies are
additive and some elements of an HTML document are not rendered until
a sufficient number of bytes / linked entities are loaded.
best regards,

@_date: 2009-02-16 23:03:02
@_author: coderman 
@_subject: Geoip information 
the service works, you can verify yourself by making a request to
one thing i have seen is that because this is using port 1443 it can
be hit or miss to find a decent exit for requesting all of the desired
information.  your vidalia log should indicate what is going on in
more detail.
best regards,

@_date: 2009-02-16 23:03:02
@_author: coderman 
@_subject: Geoip information 
the service works, you can verify yourself by making a request to
one thing i have seen is that because this is using port 1443 it can
be hit or miss to find a decent exit for requesting all of the desired
information.  your vidalia log should indicate what is going on in
more detail.
best regards,

@_date: 2009-02-17 21:17:03
@_author: coderman 
@_subject: Geoip information 
try debug, i should have mentioned this before.  it will be
exceptionally noisy though :/
good! did you see it actually CONNECT ok before closing? or was the
close a "gave up" or "no exit available" close?
(may have to watch closely)
depending on how out of date your cached information is, there may be
hundreds and hundreds of IP's to get info for.  while the request to
the geoip service does try to ask about many IPs at a time, it will
still break a huge amount into reasonable chunks, and thus multiple
GOOD responses are needed to successfully connected requests for some
router details to get geo coordinates.
we should be talking about the same thing.

@_date: 2009-02-18 15:10:11
@_author: coderman 
@_subject: Geoip information 
the behavior you describe is exactly as if whatever Vidalia's thinks
is the data directory does not exist.  this could be file system
corruption, an accidental deletion, permissions.  the best suggestion
is to reinstall, so that the installer creates and populates the
Vidalia data directories correctly.  debug level logging should point
out the cause, but you may have to dig for it among all the other
best regards,

@_date: 2009-02-23 11:09:14
@_author: coderman 
@_subject: aes performance 
i think you mean buffers (or at least multiples of 16 byte blocks);
and yes the 4096 byte or larger buffers would be nice to get the most
of the "rep" style XCRYPT instruction chaining.
it is also worthwhile to accelerate the public key ops with MONTMULT
on the padlock core.  there is assembly optimized code for this in
openssl 0.9.9 (work in progress).
the bottleneck for Tor on these CPU's becomes the libz
compression/decompression overhead with padlock enabled.
best regards,

@_date: 2009-02-23 11:19:42
@_author: coderman 
@_subject: Avoiding HTTPS pitfalls [was: Re: Moxie Marlinspike] 
agreed. i always recommend two things when using HTTPS over Tor:
- install the petname toolbar.  this will also notify you if some
rogue CA is suddenly signing the google.com certs, for example, not
just that encryption isn't used.
- save bookmarks to sites that support HTTPS only (secure cookies)
with the https:// secure URL. (no insecure transition).
a plugin to enforce secure cookies and https only operation for some
domains would be useful.  i don't know of any that do this kind of
thing yet...
best regards,

@_date: 2009-02-23 11:28:54
@_author: coderman 
@_subject: Tor on virtual servers [was: Re: Suspended..] 
note that because a Virtual private server is usually sharing kernel
networking resources with other vservers you're likely to encounter
limits of some kind that will cause problems.
see: and the ConstrainedSockets option and kernel tuning parameters, if
available to you.
best regards,

@_date: 2009-02-23 12:19:07
@_author: coderman 
@_subject: Avoiding HTTPS pitfalls [was: Re: Moxie Marlinspike] 
Tyler's suggestion is a good one.  if you want the certs themselves
authenticated you get to manage them yourself too.  remove all CA's by
nuking libnssckbi.so and only add back those you've authenticated and
sadly, this is beyond the skills of most people. the PKI cartel lives
another day... :P
best regards,

@_date: 2009-02-23 12:37:12
@_author: coderman 
@_subject: aes performance 
On Mon, Feb 23, 2009 at 12:29 PM, Arjan
it would be interesting to see how roles (middle, exit, directory
cache) affect the crypto overhead.  i suspect you're right, that a
middle only would opt toward the traffic it is most effective at (lots
of AES, fewer pubkey ops, fewer compressed payloads).
i have no if this would make a significant impact, or get you past
other CPU limits for network saturation.  would be a fun experiment
for someone with the bandwidth/lab setting and some C7 cores... :)
best regards,

@_date: 2009-02-23 12:40:54
@_author: coderman 
@_subject: Avoiding HTTPS pitfalls [was: Re: Moxie Marlinspike] 
from "Which Firefox extensions should I avoid using? ... NoScript: using
NoScript can actually disable protections that Torbutton itself
provides via Javascript, yet still allow malicious exit nodes to
compromise your anonymity via the default whitelist..."
as an aside, i found a plugin that could do everything above, but only
if the sites themselves send you a ForceHTTPS cookie securely:
the design paper does a good job of explaining why this is all more
complicated than you might think...
best regards,

@_date: 2009-01-13 19:14:06
@_author: coderman 
@_subject: Testing the Tor Vidalia bundle with Thandy updater support 
Two packages for Windows are now available for testing the new Thandy
updater code for maintaining current versions of Tor in the Vidalia
bundle.  These are test only releases and should not be used for
anything important; feedback on the package installation and ease of
use is solicited.
The first package is the usual bundle installer with all necessary
programs included.  The second is a network based installer that uses
Thandy to download the most up to date versions of the bundle packages
at install time. Note that if you want to test the update process for
Tor 0.2.1.9 to 0.2.1.10 you will need to install the bundle package;
the network installer will always install the latest version.
Instructions for testing the packages:
  My thanks in advance for help testing these packages; I can be reached
at this address for any question or comments.
Best regards,
also, some additional detail about the MSI based packages and update
process is here:

@_date: 2009-01-13 20:38:34
@_author: coderman 
@_subject: cannot compile 0.2.1.10-alpha 
how did you invoke configure?
what version of mingw?

@_date: 2009-01-14 22:55:44
@_author: coderman 
@_subject: tor-browser bundle on XP 
the "no route to host" can be caused by many things, and may not be
impacting the ability for Tor to function.
can you try running vidalia with notice or info loglevel to see if a
failure is reported?
  vidalia.exe -loglevel notice -logfile log.txt
(don't send a full log to the list of course :)
i would also be curious if the MSI based installer bundle works better
when installed as unprivileged user:
  best regards,

@_date: 2009-01-21 11:51:10
@_author: coderman 
@_subject: problem while trying to fetch 0.2.1.8-alpha 
i tend to use PEM; DER won't work with many wget installations.
wget --ca-certificate=entrust_ssl_ca.cer should work fine.
best regards,

@_date: 2009-01-01 19:01:02
@_author: coderman 
@_subject: Jailed/sandboxed/chrooted applications 
situations vary but my personal preference is for distinct virtual
machines to run groups of applications and Tor separately.  the main
benefit this provides is stronger isolation from arbitrary execution
and other exploits as well as providing a virtual network address that
does not provide any hints about the topology or configuration of your
internal LAN / Internet connection.
being able to configure Tor'ified applications in freebsd jails would
be useful though; i've only tried to do that (owner match) with
iptables on linux though...
best regards,

@_date: 2009-07-08 18:29:22
@_author: coderman 
@_subject: Running a Tor Server as a Tax Deduction? 
i had the best luck positioning Tor relay contribution as a way to
support the Sarbanes-Oxley Act whistleblower retaliation provision
with my last employer. but even that was a stretch...
best regards,

@_date: 2009-07-13 15:51:41
@_author: coderman 
@_subject: Hidden Service Weirdness 
this is wordpress sucking. it tries to be helpful and always
explicitly list non-80 ports in complete URI's.
you can try running on port 80 in the VM (and --redir tcp:80::80),
setup apache mod_rewrite, or get wordpress to quit sucking.
(there might be a more effective method, but i don't like wordpress,
so have no idea what it might be.)
good luck,

@_date: 2009-07-25 04:23:09
@_author: coderman 
@_subject: Hidden Service Weirdness 
unfortunately you must run qemu as root to bind to privileged ports
like 80, which negates some of the protections you're hoping to
the best solution would be correct behavior from wordpress. perhaps
someone in that community has encountered this situation and knows
what configuration or code changes are required.
best regards,

@_date: 2009-07-25 20:18:52
@_author: coderman 
@_subject: New option DirPortFrontPage 
difficult to have a DirPort open otherwise :)
someone else can speak to the realworld load added better than i,
however if you're running a server behind a NAT you may have to
contend with another forwarded port and additional strain on your
connection tracking resources.
DirPortFrontPage FILENAME
When this option is set, it takes an HTML file and publishes it as "/" on
the DirPort. Now relay operators can provide a disclaimer without needing
to set up a separate webserver. There's a sample disclaimer in
best regards,

@_date: 2009-07-07 22:03:03
@_author: coderman 
@_subject: Question: Hidden Services, Virtual Machines, and iptables 
in such a configuration i prefer to use two virtual machines.
one vm has host-only networking to serve hidden service content.
second vm hosts Tor router with hidden service pointed at vm host.
host uses iptables redirect and/or tcp proxy to connect hidden service
connections from Tor VM to hidden service VM port at host-only
(there are variations on this theme...)
best regards,

@_date: 2009-07-07 23:22:54
@_author: coderman 
@_subject: Question: Hidden Services, Virtual Machines, and iptables 
iptables owner match (by process uid) is simpler, both LAMP and Tor in
a single VM. restrict outbound for LAMP user processes.
lightweight appliance type virtual machines can be light on resource
consumption even with many running concurrently. the LAMP stack will
be the most resource intensive part.
best regards,

@_date: 2009-03-08 19:56:57
@_author: coderman 
@_subject: Clock problems 
this sounds like the expected behavior of ntpd issuing adjtime() calls
to slowly bring your clock skew down to current time.  this can take
hours depending on how large of an adjustment is needed.
is the computer off for a longer period of time than usual when such
behavior occurs?
from OSX adjtime man page:
Adjtime() makes small adjustments to the system time, as returned by
gettimeofday(2), advancing or retarding it by the time specified by
the timeval delta.  If delta is negative, the clock is slowed down by
incrementing it more slowly than normal until the correction is
complete.  If delta is positive, a larger increment than normal is
used.  The skew used to perform the correction is generally a fraction
of one percent.  Thus, the time is always a monotonically increasing
also, ntpd / ntpdate may also perform similar incremental adjustment themselves:
[ntpd|ntpdate may] step the time using settimeofday(2) if the offset
is greater than +-128 ms.  Note that, if the offset is much greater
than +-128 ms in this case, it can take a long time (hours) to slew
the clock to the correct value.  During this time, the host should not
be used to synchronize clients.
best regards,

@_date: 2009-03-09 13:25:22
@_author: coderman 
@_subject: Clock problems 
you could check /var/log/system.log for things like:
Mar  9 01:24:55 imac ntpd[3721]: time reset -0.173970 s
Mar  9 01:49:24 imac ntpd[3721]: time reset +0.168392 s
(also bzcat /var/log/system.log.*.bz2 | grep ntpd)
if ntpd is quiet, you've got something else affecting the clock jumps...
best regards,

@_date: 2009-05-16 15:14:06
@_author: coderman 
@_subject: Iptables configuration for a transparent proxy for a single user 
make sure control port is disabled or properly authenticated;
otherwise a good setup.
an improvement is white listing Tor process with direct access and all
other traffic is transparently re-routed through Tor. this protects
against attacks where embedded content or network filesystem based
URIs are used to initiate requests through a kernel subsystem or other
process not associated with the anonymous Tor network user. (this is a
relevant issue on Windows, less so unix like systems)
best regards,

@_date: 2009-10-27 17:38:32
@_author: coderman 
@_subject: Anyone running Tor on routing/switching hardware ? 
yes in that network hardware often provides hardware accelerated
crypto primitives that can be utilized by Tor to accelerate the CPU
bound aspects of relaying a large amount of traffic.
no since hardware acceleration is poorly supported in OpenSSL let
alone via direct offload in Tor itself. the latter is necessary to
truly take advance of hardware acceleration for large chunks of CTR
mode or Montgomery multiplication given shortcomings in the OpenSSL
API's used by Tor.
if you have a hardware entropy device and a good userspace entropy
daemon / mixer this is always useful to Tor and OpenSSL in general.
this is manged outside of Tor or OpenSSL by administrator however.
as for particular hardware acceleration support the archives of this
list provide some details.
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2009-10-17 03:26:05
@_author: coderman 
@_subject: hardware acceleration available for Tor ? On FreeBSD ? 
speeding up OpenSSL derived CTR mode with hardware acceleration is
useful. (the HardwareAccel and EngineName options above)
speeding up Tor with native hardware acceleration and chained /
repetitive CTR offload is a much bigger win. as an example the VIA
Padlock engine can do a few score MBytes/sec aes 128 with small/single
block sizes like those used when HardwareAccel is on and EngineName
padlock set. if you could utilize the maximum 16KByte rep instruction
mode directly goes well over a gigabyte / second. this is also why the
native Solaris API CTR mode gives much better performance than the
OpenSSL engine acceleration.
speeding up OpenSSL pubkey ops also helps. as of OpenSSL 0.9.9 and
1.0.x you can build OpenSSL with padlock MONTMULT acceleration. still
no dynamic engine support for pubkey ops iirc...
there will be some benefit as Tor wraps a CTR mode around
(accelerated) OpenSSL ECB mode. the problem is that this method is
limited to single blocks per call, rather than long buffers optimized
for crypto offload.
you may also get SHA acceleration. the notices log should say, for example:
[info] crypto_global_init(): Initializing OpenSSL engine support.
[info] crypto_global_init(): Initializing dynamic OpenSSL engine
"padlock" acceleration support.
[info] crypto_global_init(): Loaded dynamic OpenSSL engine "padlock".
[info] crypto_global_init(): Loaded OpenSSL hardware acceleration
engine, setting default ciphers.
[info] Using default implementation for RSA
[info] Using default implementation for DH
[info] Using default implementation for RAND
[notice] Using OpenSSL engine VIA PadLock: RNG (not used) ACE2
PHE(8192) PMM  [padlock] for SHA1
[info] Using default implementation for 3DES
[notice] Using OpenSSL engine VIA PadLock: RNG (not used) ACE2
PHE(8192) PMM  [padlock] for AES
not necessarily, per above :)
it would also be nice to have these routines native for other engines,
like padlock. however this is not a small amount of effort and no one
with time and skill has shown an interest yet. (Tor buffer allocation
alignment to 16K, inline padlock instr. calls in REP mode, and other
changes required.)
there are kernel cryptographic facilities including asm optimized and
hardware accelerated crypto primitives. these are usually not utilized
from userspace directly. there are PKCS specs for communicating with
offload devices in a concise manner, and libs of various types to
speak this to myraid hardware. perhaps a longer discussion should be
taken off list...
the T2 is core acceleration and thus higher throughput for most
purposes. the 6000 is useful as a hardened private key store service
for your less trusted OS and software to cooperate with.
Tor would need to be updated to take advantage of the new CTR mode in
the OpenSSL API calls, but then the same HardwareAccel (and AccelName)
options would provide a significant improvement over the previous
acceleration mode.
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2009-09-01 21:49:50
@_author: coderman 
@_subject: Gmail 
someone should set up a gmail invite spooler on a hidden service. many
gmail users probably have 100 or so invites sitting around...
(invites do not need to be delivered to valid addresses; you can check
your sent folder for the invite code with a bogus dest.)
best regards,

@_date: 2010-08-23 10:56:53
@_author: coderman 
@_subject: Tor + SELinux sandbox = leak proof without VM overhead? 
not a silver bullet, but tends to fail safer.
the "costs" include:
- elevated privs for accelerated virtualization / para-virtualization.
Tor by default does not require such.
- additional resource consumption. isolated os, network stacks, and
applications require additional memory and CPU.
- only solve part of the problem; you still need Torbutton and other
application level protections, even if direct proxy-bypass type
disclosures of endpoint or identity are mitigated.
ideally this model would apply across the entire user experience, see qubes:
 developing and maintaining a robust RSBAC policy is non-trivial. that
said, these are complementary techniques. a strong RSBAC model around
and within virtual machine based isolation provides additional defense
against application errors, vm break-outs, etc.
it doesn't help that a lot of the good SELinux policy development /
management tools are closed source / proprietary.  it's not the only
game in town...
there's RSBAC bypass just like vm break-out; anyone claiming
infallibility is smoking something or selling you lies...
absolutely! you could submit a series of policies for various Tor
modes of operation and solicit feedback / commit to contrib.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-08-23 11:40:14
@_author: coderman 
@_subject: https proxy [was polipo] 
- because by default applications trust either a large, promiscuous
set of certificate authorities, or even worse, use the operating
system supplied list of trusted authorities.
- because by default applications do not or cannot utilize mitigating
measures like perspective based certificate retrieval and consensus
from varying endpoints or sources.
- because by default applications may not support robust cipher suites
or handle some aspects of protocol or session negotiation poorly /
incorrectly / insecurely.
- because by default applications don't support a persistent, mobile
store of trusted server certificates built up over time, which a proxy
could provide (Tahoe LAFS / encrypted $cloud storage for your
certificate store available wherever you need it.)
- lots of additional reasons...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-08-24 12:24:05
@_author: coderman 
@_subject: How to Run High Capacity Tor Relays 
typically in /etc/security/limits.conf. i like to append:
*               soft    nofile          4096
*               hard    nofile          65535
but on big servers use .25mm as hard limit. (Tor not this fd hungry,
64k is fine)
you probably want to save in /etc/sysctl.conf , then sysctl -p
^- these are important and useful
^- that's a little aggressive, better to set FIN timeout lower. i like
5000 to 65535 ephemeral port range
^- i like a fin timeout of 3-4 seconds on a busy server, otherwise
you've got lots of resources tied up in sockets waiting to die...  Tor
not quite so volatile as some services, so perhaps 30 is fine.
^- who uses keepalive? :)
^- best to just disable conntrack altogether if you can. -J NOTRACK in
the raw table as appropriate.
you're going to each up lots of memory with a decent nf|ip_conntrack_max
( check /proc/sys/net/ipv4/netfilter/ip_conntrack_max , etc )
some dupes in here?
^- BAD! this should not be enabled by default unless you're actually
routing specifically to guest vm's or between interfaces or something.
if you enable forwarding by default, someone may use you to relay some
malicious traffic.
were these cut and paste errors?  remember to disable forwarding
first, before tuning other parameters, as changing this value will
reset some others back to defaults. (!!)
^- not usually worth the overhead?
^- note that you need to be precise with your routing metrics and such
for multi-homed with rp_filter enabled. also, this costs resources,
and if you can avoid it, do so.
^- don't know if these are too useful either. i prefer to limit ICMP
beyond this. (perhaps related to forwarding defaults above.) Ex:
echo "1" > /proc/sys/net/ipv4/icmp_echo_ignore_broadcasts
echo "1" > /proc/sys/net/ipv4/icmp_echo_ignore_all
echo "0" > /proc/sys/net/ipv4/conf/all/accept_redirects
echo "1" > /proc/sys/net/ipv4/icmp_ignore_bogus_error_responses
i'd love to see an sca6000 accelerated node.  been working with these
recently but unfortunately they're allocated for other work...
(most of the other crypto hw is going to be bus / implementation
limited to less than what a beefy 64bit modern server can provide, so
of little utility in this context.)
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-08-29 15:14:26
@_author: coderman 
@_subject: Tor + SELinux sandbox = leak proof without VM overhead? 
the loading / configuring of kernel module part is one elevated task.
route table changes / altering iptables rules and chains*, many other
such things require elevated privileges.
there are often host facilities to permit specific use of valid
settings, and rsbac constraints, lots of other mitigation
if you give up acceleration and do full softmmu / user only and
constrained device emulation you can still have a guest / least
privilege virtual machine, but the overhead is significant.
fortunately fast virtio devices are become common across both
userspace only and accelerated virtual machine implementations.
i also like livecd as you mention, and qubes on live fedora is a nice
setup, perhaps coupled with HTTPS-Fuse on-demand pre-caching file
system overlays... many many different combinations and techniques to
complement and fit a particular need. the limiting factor is time to
explore them all and their relative
* i call this out specifically because you need extend beyond the
basic VirtualBox / Qemu / VMWare settings associated with the common
bridge, nat, host-only network devices and implement host level
routing protections; otherwise you're exposed to a number of potential
side channel and other attacks listed in the FAQ and elsewhere.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-08-29 15:23:45
@_author: coderman 
@_subject: Tor + SELinux sandbox = leak proof without VM overhead? 
one last note, these are all complementary techniques. the SELinux
effort early on was applied to VMWare virtual machine rules per
instance on virtual disks and across network devices. improving the
usability of such a configuration by deploying via livecd images
supporting a wide range of hardware would also be a clear improvement
for many users.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-08-01 21:20:47
@_author: coderman 
@_subject: Padding again Was: Practical web-site-specific traffic analyses 
perhaps DLP with SFQ and datagram transport. could even add endpoint
mobility / multi-path for resilience. (it sounds so easy ;)
practical can be surprisingly forgiving if the protections are compelling.
 you could build it and find out...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-12-23 14:33:57
@_author: coderman 
@_subject: Tor VM stalled at 25% 
where in the world did you find a tor_vm.iso ? "latest" is years
deprecated at this point unless you've built it yourself or got it
from someone who has.
if you're using a '2009 image you're too far out of date for current network.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-12-23 14:59:32
@_author: coderman 
@_subject: Tor VM stalled at 25% 
not all, but at least one.  why not use the standard Bundle in an
Ubuntu or other VM?
the transparent VM model is experimental and complicated; if you're
not comfortable building and deploying it yourself the supported
bundle distributions and modes of use are much more recommended.
there are also third party distributions like Janus VM if you're
evaluating all your options...
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-12-23 15:29:02
@_author: coderman 
@_subject: Tor VM stalled at 25% 
there are still a large number of risks to your anonymity when using
things like Java, Flash, arbitrary applications with Tor, even in a
fully transparently Tor'ified VM configuration.
local DNS resolver IP disclosures and side channels, chained exploits
(accelerated VM interfaces are very risky but oh so performant...),
many, many other considerations and risks.
you need to carefully consider your risks for using such things, hence
my recommendation for the stock bundle without those risky things
unless you really know what you're doing or the risks are
exceptionally low.
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-19 17:32:15
@_author: coderman 
@_subject: Searching for "good" ISPs 
Tor is a decentralized architecture. why use Tor in your centralized
(even if distributed) network?
based on your description a one or two hop VPN service would fit the
needs of your customers and design nicely. attempting to use Tor in
such a configuration would only mislead your users about the potential
privacy and security that could be afforded.
perhaps i have misunderstood the nature of your "hosted Tor service".
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-11 12:05:36
@_author: coderman 
@_subject: TOR Blocked at Universities 
can you elaborate on that?
are these apparent attacks coming _from_ the Tor exits or are Tor
clients being used to circumvent network policy, etc?
do bridges work or is this identifying Tor client signature to filter?
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-02-11 12:05:36
@_author: coderman 
@_subject: TOR Blocked at Universities 
can you elaborate on that?
are these apparent attacks coming _from_ the Tor exits or are Tor
clients being used to circumvent network policy, etc?
do bridges work or is this identifying Tor client signature to filter?
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-01-14 15:55:52
@_author: coderman 
@_subject: Google in China 
weaponized 0days in IE leveraged for this assault are a disturbing escalation.
the targets of their interest imply relevance to Tor now or in the near future.
Google funding/developing large scale decentralized anonymity and
circumvention technologies would be a welcome retort against the
coming constraints in .cn and elsewhere.
interesting times!
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-01-14 17:57:58
@_author: coderman 
@_subject: Google in China 
right. hence "would be nice" as a qualifier. in any case, it is
interesting that these attacks on their lawful intercept functions
occurred "just days after hosting a closed-door symposium on
circumventing censorship"
perhaps not in this manner exactly, however they have helped Tor.
Summer of code and the secure Thandy updater funding just two
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-01-27 13:30:52
@_author: coderman 
@_subject: browser fingerprinting - panopticlick 
EFF has an interesting tool available:
  technical details at
an interesting look at exactly how distinguishable your default
browser configuration may be...
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-01-28 15:27:14
@_author: coderman 
@_subject: browser fingerprinting - panopticlick 
it would be nice if the tool could distinguish between persistent
uniqueness and ephemeral / transient settings like those employed by
Torbutton and other privacy proxies (which randomize some aspects of
the request and/or headers).
this is not a trivial task though...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-04 14:46:12
@_author: coderman 
@_subject: why not TORVM for linux? 
it is not maintained. this applies to all Tor VM unless you've patched
and built a current version for yourself / others.
the controller is built for a windows environment. you'll have to
customize the invocation and configuration for Linux based systems.
there is no support for hardware assisted / para-virtualization by
default, due to instability and elevated permissions. for best
performance you'll have to configure the KQEMU or KVM acceleration
support yourself with the appropriate KVM and/or virtio device
more reasons too numerous to list here. moving Tor VM from a (dated)
research beta to production ready is a non-trivial effort for which
there does not seem to be much interest.
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-29 17:22:59
@_author: coderman 
@_subject: US Seeks Access to More Internet Data Without Court Order 
money/time, lack of hardware acceleration, certificate management,
cross-browser or historical client compatibility, nullification of
in-line/transparent caching infrastructure, probably lots more
i agree with your sentiment for the most part.
traffic confirmation is pretty easy. as for active attacks both near
and far end via this route, that's a different question. it does
happen, but if you're in that kind of spotlight Tor use is the least
of your worries :P
hah; sadly i lack the discipline to be "expert" in this subject.
you've seen the anobib, right?
in general i agree that at the level of scrutiny being discussed here
you're either off the radar in the Tor crowd or screwed totally and
entirely via all of the other weaker links in your protections. and
that's generously assuming your threat model is sufficient and
they don't give out NSL's for just any whim or fancy after all...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-29 17:34:05
@_author: coderman 
@_subject: Flash Cookies and Tor. 
we all have our vices...
this will quit surprising you as you begin paying attention.
nope, as long as you NEVER, EVER, NOT EVEN ONCE have Flash enabled
while using Tor. or anything with privs (extensions, other plug-ins)
that have access to the local store, or other situations where remote
disclosure of local file content may occur.
an easier consideration, are you consistent about always using a
recent and signature verified release of the browser bundle?
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-29 17:36:28
@_author: coderman 
@_subject: Flash Cookies and Tor. 
having looked at the download page i see the Linux bundle is at 1.0.9
and beta, while the usual is 1.3.9. these may be totally incomparable
sequences but the above advice is more apropos Windows users (the
majority) than yourself...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-04 15:17:08
@_author: coderman 
@_subject: The State of the DNS and Tor Union (also: a DNS UDP - >TCP shim) 
great info!  my comments below...
a better wording:
"... ultimately, any application that uses DNS or UDP may compromise
your anonymity."
best intentions fail in the face of an attacker in most circumstances.
Java can be configured to use explicit resolver endpoints regardless
of suggested default proxy or other configuration.  raw UDP sockets
via third party plug-ins are worst case.
note that even with transparent proxy configuration and DNS port you
are at risk if the attacker can direct explicit DNS requests to a
local resolver (over link-local route, not default gateway). this type
of attack affects all VPN or transparent proxy configurations that do
not use a /29 point-to-point router path.
to add insult to injury, many commercial Linux based routers like
ActionTek and D-Link use dproxy-nexgen resolvers accessible at
link-local 192.168.1.1. a reverse lookup of the gateway itself
provides not just the internal address but also the public IP and
hostname from ISP. there are other caching resolvers used in captive
wifi portals and other locations with same behavior.
not really hard in any sense of the word.  :(
PERL, but that doesn't detract from the awesome that is Tup.
sadly, we are not currently temporally propinquitous with Tup.
the other trade-off with this approach is that is behaves very poorly
with some applications that expect name resolution to fail on
un-reachability (like .onion or .exit) rather than in-determinate
connection establishment.
that is, your application may resolve a random site or hidden service
immediately and attempt to connect, but this attempt (via transparent
transport access) may hang indefinitely for minutes before success or
failure.  some prefer to have more explicit control over these
resolution timers and timeouts.
coming soon: the best of all worlds would combine:
- virtualaddrnetwork based immediate resolve and map
- dnsport transparent resolve through Tor
- ttdnsd based tunneled TCP DNS from exit
- host based interception and/or filtering mechanisms against side
channels around the above
until then you're exposing yourself to specific attacks and providing
poor end user experience in other situations.
a discussion of negative caching might be useful. some people
encounter situations where they get a positive responsive from an
explicit request but host based resolver facilities still return not
found. see also host based caches like nscd.
not really. this is the exception rather than the rule, or even common case.  :(
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-31 01:16:40
@_author: coderman 
@_subject: Practical web-site-specific traffic analyses 
i've heard QA and security departments complain that it's extremely
hard to get web developers to do things!
there's a parable about a creek full of excrement and no paddles ...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-04 15:19:20
@_author: coderman 
@_subject: The State of the DNS and Tor Union (also: a DNS UDP - >TCP shim) 
apologies; that should read: "/31 point-to-point router path."
i've been dealing with service provider annoyances too much lately.. :)
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-05 15:07:11
@_author: coderman 
@_subject: The State of the DNS and Tor Union (also: a DNS UDP - >TCP shim) 
i should mention that the Tor Browser Bundle when used as directed has
been and continues to be most resilient to these attacks. while this
is a very limited environment (no plug-ins, flash, java, etc.) these
limitations are a feature ensuring your protection.
when you start using arbitrary applications or plug-ins with Tor or
any other anonymity service you open yourself up to great risk as
described here for DNS, not to mention other side channels avenues
using TCP directly.
best regards,
(hi pedants!)
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-05 21:20:09
@_author: coderman 
@_subject: The State of the DNS and Tor Union (also: a DNS UDP - >TCP shim) 
to manually test:
1. route -n or equiv to find default gateway (running dproxy-nexgen or
equiv. DNS proxy / resolver)
(for remainder of this sequence 192.168.1.1 is assumed to be router
and dproxy host)
2. dig  192.168.1.1
3. observe the ISP provided hostname in answer
4. dig  5. observe public IP endpoint address in answer
not sure how many routers run this kind of stuff, but they number in
the millions.
(cheap Linux routers, Wifi captive portals, etc.)
as for Java test case, i can dig up the applet code from ages back, if
i've got it. i recall another avenue via
sun.net.spi.nameservice.provider and
there is also a mechanism via JNI to use _res.options global to reset
DNS bindings, and open up other attacks. (although if you've got JNI
access these are all less interesting approaches.)
consider the case of a link local resolver like above, or any DNS
server on the LAN for public routed requests.  you don't need
arbitrary execution; i agree that's game over in any case.
yeah, not to be confused with the dsocks python version. i'll find a
copy and forward it on.  i know it's around here somewhere...
right, i usually don't like this behavior. but sometimes it is very
handy, particularly when applications cache negative responses for too
long, or aggressive DNS rebinding attack prevention makes a resolution
last much longer than you'd like. (in which case, in is better to be
stuck to a binding against 10.x or other virtualnetwork addr that can
reconnect on the TCP side rather than having an old public DNS mapping
that persists beyond TTL, etc.)
this is all a bit technical, and i agree that the above is the lesser
desired behavior.
i'm thinking of the Windows DNS cache behavior. it probably should be
considered a bug :)
agreed. the issue is when you've got a link-local resolver accessible,
and a mechanism to perform DNS queries against it. in such a case, the
host configuration of 127.0.0.1 is simply ignored, and an explicit
local resolver is queried.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-07-06 00:55:59
@_author: coderman 
@_subject: The State of the DNS and Tor Union (also: a DNS UDP - >TCP shim) 
this is the only copy i have on hand. i believe there is an updated
version in bsd ports archive (no longer in current mirrors).
best regards,

@_date: 2010-07-06 00:57:23
@_author: coderman 
@_subject: The State of the DNS and Tor Union (also: a DNS UDP - >TCP shim) 
# dns-proxy-tor
# This script has been dedicated to the public domain.
# See LICENSE file included with this distribution for the dedication.
use strict;
use warnings;
our $VERSION = '0.0.6';
  package Log;
  use strict;
  use warnings;
  use constant INFO   => 0;
  use constant DEBUG  => 1;
  my  = qw/INFO DEBUG/;
  my  = qw/level handle/;
  our %Log = (level => 1);
  our $Err;
  sub _self {
    my $class = __PACKAGE__;
    no strict 'refs';
    return \%$class;
  }
  sub init {
    my $self = shift->_self;
    %$self =     if (not $self->{handle} and not open $self->{handle}, '>>', $self->{file}) {
      $Err = "Can't open log file $self->{file}: $!\n";
      return;
    }
    select( (select($self->{handle}), $| = 1)[0] );
    return 1;
  }
  sub close {
    my $self = shift->_self;
    close $self->{handle};
  }
  for my $attribute ( {
    no strict 'refs';
    *$attribute = sub {
      use strict 'refs';
      my $self = shift->_self;
      $self->{$attribute} = shift if       return $self->{$attribute};
    };
  }
  for my $level ( {
    no strict 'refs';
    *{lc $level} = sub {
      my $self = shift->_self;
      return unless $self->{level} >= &$level;
      use strict 'refs';
      my $fh = $self->{handle};
      printf $fh     };
  }
  1;
  package DNS::Session;
  use strict;
  use warnings;
  use Socket;
  use constant SERVFAIL => 0x8102;
  use constant NOERROR  => 0x8100;
  use constant TYPE_A   => 1;
  use constant CLASS_IN => 1;
  use constant NAME_PTR => 0xc00c;
  sub new {
    my $class = shift;
    my $self = {
      sessions     => {},
      last_timeout => time,
          };
    bless $self, $class;
  }
  sub add_request {
    my ($self, $dns_request) =     Log->debug("Adding session for %s\n", $dns_request->domain);
    push  $self->{sessions}{lc $dns_request->domain} }, $dns_request;
  }
  sub _pack_name {
    join( '', map chr(length).$_, split /\./, $_[1] )."\0";
  }
  sub _pack_response {
    my ($self, $id, $flags, $req_type, $domain, $addr) =     my ($qd, $an, $ns, $ar) = (1, 0, 0, 0);
    my $answer;
    if ($addr) {
      $an = 1;
      $answer = pack('n3Nn', NAME_PTR, TYPE_A, CLASS_IN, 0, 4).inet_aton($addr);
    }
    # header
    my $response = pack 'n6', $id, $flags, $qd, $an, $ns, $ar;
    # question
    $response .= $self->_pack_name($domain).pack('n2', $req_type, CLASS_IN);
    # answer
    $response .= $answer if $an;
    return $response;
  }
  sub exists {
    my ($self, $domain) =     return exists $self->{sessions}{lc $domain};
  }
  sub flush {
    my $self = shift;
    $self->send_response($_ => 0)
      for keys %{ $self->{sessions} };
  }
  sub send_response {
    my ($self, $domain, $addr) =     if (not $self->exists($domain)) {
      Log->debug("Session not found for $domain\n");
      return;
    }
    my $requests = $self->{sessions}{lc $domain};
    my $flags = $addr ne '0' ? NOERROR : SERVFAIL;
    undef $addr if $addr eq '0';
    while (my $request = shift  {
      if (defined $addr) {
        Log->info("Resolved %s => %s, sent to %s:%s\n", $domain, $addr,
          $request->remote_addr, $request->remote_port);
      } else {
        Log->info("Failed to resolve %s, sent to %s:%s\n", $domain,
          $request->remote_addr, $request->remote_port);
      }
      my $response = $self->_pack_response(
        $request->id,
        $flags,
        $request->type,
        $request->domain,
        $addr
      );
      send $self->{handle}, $response, 0, $request->remote_sa;
    }
    delete $self->{sessions}{lc $domain};
  }
  sub timeout {
    my $self = shift;
    my $limit = time - $self->{timeout};
    return if $limit < $self->{last_timeout};
    for (keys %{ $self->{sessions} }) {
      delete $self->{sessions}{$_}
        if $self->{sessions}{$_}[0]->time < $limit;
    }
    $self->{last_timeout} = time;
  }
  sub handle {
    my $self = shift;
    $self->{handle} = shift if     return $self->{handle};
  }
  1;
  package DNS::Request;
  use strict;
  use warnings;
  use Socket;
  use constant INVALID        => 0;
  use constant FORMERR        => 0x8101;
  use constant SERVFAIL       => 0x8102;
  use constant TYPE_A         => 1;
  use constant TYPE_AAAA      => 0x1c;
  use constant CLASS_IN       => 1;
  use constant MAX_LABEL_LEN  => 63;
  use constant MAX_DOMAIN_LEN => 255;
  sub receive {
    my ($class, $handle) =     my $remote_sa = recv $handle, my $query, 512, 0;
    return unless defined $remote_sa;
    my $self = {
      query     => $query,
      remote_sa => $remote_sa,
      time      => time
    };
    bless $self, $class;
  }
  sub _unpack_name {
    my ($self, $pos) =     return if length $self->{query} < $pos + 2;
    my     while (my $len = ord substr $self->{query}, $pos, 1) {
      return if ($len & 0xc0) == 0xc0 or length $self->{query} < $pos+$len+2;
      push  substr $self->{query}, ++$pos, $len;
      $pos += $len;
    }
    return $pos + 1,   }
  sub remote_addr {
    my $self = shift;
    my (undef, $remote_addr) = sockaddr_in $self->{remote_sa};
    return inet_ntoa $remote_addr;
  }
  sub remote_port {
    my $self = shift;
    (sockaddr_in $self->{remote_sa})[0];
  }
  sub parse {
    my $self = shift;
    Log->info("Received datagram from %s:%s\n",
      $self->remote_addr, $self->remote_port);
    if (length $self->{query} < 19) {
      Log->info("Dropping invalid packet from %s:%s\n",
        $self->remote_addr, $self->remote_port);
      $self->{error} = INVALID;
      return;
    }
    my ($id, $flags, $qd, $an, $ns, $ar) = unpack 'n6', $self->{query};
    my $pos = 12;
    Log->info("id=0x%04x flags=0x%04x qd=0x%04x an=0x%04x ".
               "ns=0x%04x ar=0x%04x\n", $id, $flags, $qd, $an, $ns, $ar);
    unless ($qd == 1
            and $an == 0 and $ns == 0 and $ar == 0) {
      Log->info("Server failure (unsupported) to %s:%s\n",
        $self->remote_addr, $self->remote_port);
      $self->{error} = SERVFAIL;
      return;
    }
    my     ($pos,  = $self->_unpack_name($pos);
    unless ($pos and length $self->{query} >= $pos + 4) {
      Log->info("Format error (invalid name or length) to %s:%s\n",
        $self->remote_addr, $self->remote_port);
      $self->{error} = FORMERR;
      return;
    }
    my ($type, $class) = unpack 'n2', substr $self->{query}, $pos, 4;
    $pos += 4;
#    unless ($type == TYPE_A) {
# || $type == TYPE_AAAA and $class == CLASS_IN) {
#      Log->info("Server failure (unsupported type/class) to %s:%s\n",
#        $self->remote_addr, $self->remote_port);
#      $self->{error} = SERVFAIL;
#      return;
#    }
    my $domain_len = 0;
    for my $label ( {
      my $label_len = length $label;
      $domain_len += 1 + $label_len;
      unless ($label_len <= MAX_LABEL_LEN and
              $domain_len <= MAX_DOMAIN_LEN and
              # labels can only start with a letter, but we need
              # to allow numbers for .onion names
              $label =~ /(\A[[:alnum:]](?:[[:alnum:]\-]*[[:alnum:]])?\z)/) {
        Log->info("Format error (invalid label/domain) to %s:%s\n",
          $self->remote_addr, $self->remote_port);
        $self->{error} = FORMERR;
        return;
      }
      $label = $1;
    }
    my $domain = join '.',     %$self = (%$self, id => $id, type => $type, domain => $domain);
    return 1;
  }
  sub send_error {
    my ($self, $handle) =     return if $self->{error} == INVALID;
    my $response = substr($self->{query}, 0, 2).pack('n', $self->{error}).
                   substr($self->{query}, 4);
    send $handle, $response, 0, $self->{remote_sa};
  }
  sub remote_sa { $_[0]->{remote_sa} }
  sub id        { $_[0]->{id}        }
  sub domain    { $_[0]->{domain}    }
  sub type      { $_[0]->{type}      }
  sub time      { $_[0]->{time}      }
  1;
  package Connection;
  use strict;
  use warnings;
  use Socket;
  use Fcntl;
  my $Tcp_proto = getprotobyname 'tcp';
  sub connect {
    my ($self, $timeout) =     eval {
      local $SIG{ALRM} = sub { die "Connection timed out\n" };
      alarm $timeout;
      socket $self->{handle}, AF_INET, SOCK_STREAM, $Tcp_proto
        or die "socket() failed: $!\n";
      select( (select($self->{handle}), $| = 1)[0] );
      connect $self->{handle}, $self->{sockaddr}
        or die "connect() failed: $!\n";
    };
    alarm 0;
    close $self->{handle} if $
    return not $
  }
  sub _set_nonblocking {
    my $self = shift;
    my $flags = fcntl $self->{handle}, F_GETFL, 0
      or die "fcntl() failed: $!\n";
    fcntl $self->{handle}, F_SETFL, $flags | O_NONBLOCK
      or die "fcntl() failed: $!\n";
  }
  1;
  package Tor::Control;
  use base 'Connection';
  use strict;
  use warnings;
  use Socket qw/:DEFAULT :crlf/;
  use Errno 'EWOULDBLOCK';
  use constant BUF_SIZE       => 8192;
  use constant TIMEOUT        => 300;
  sub new {
    my $class = shift;
    my $self = {
      read_buf     => "\0" x BUF_SIZE,
      write_buf    => "\0" x BUF_SIZE,
      read_pos     => 0,
      write_pos    => 0,
      disconnected => 1,
          };
    bless $self, $class;
  }
  sub _read_auth_cookie {
    my $self = shift;
    my $cookie_file = "$self->{data_directory}/control_auth_cookie";
    if (open my $cookie_handle, '<', $cookie_file) {
      local $/;
      my $cookie = <$cookie_handle>;
      $self->{secret} = unpack 'H*', $cookie;
    } else {
      Log->info("Can't open $cookie_file: $!\n");
    }
  }
  sub _authenticate {
    my $self = shift;
    local $/ = CRLF;
    $self->_read_auth_cookie if $self->{data_directory};
    syswrite $self->{handle}, 'AUTHENTICATE '.$self->{secret}.CRLF
      or die "syswrite() failed: $!\n";
    defined( my $response = readline $self->{handle} )
      or die "readline() failed: $!\n";
    chomp $response;
    $response eq '250 OK'
      or die "Authentication failed\n";
  }
  sub connect {
    my $self = shift;
    my $timeout = 5;
    for (;;) {
      eval {
        $self->SUPER::connect($timeout) or die $
        local $SIG{ALRM} = sub { die "Authentication timed out\n" };
        alarm $timeout;
        $self->_authenticate;
        $self->_set_nonblocking if $^O ne 'MSWin32';
      };
      alarm 0;
      if ($ {
        Log->info("$ to Tor failed. Retrying...\n");
        close $self->{handle};
        sleep $timeout;
        last if $self->{terminate}->();
      } else {
        Log->info("Connected to Tor\n");
        $self->{disconnected} = 0;
        last;
      }
    }
    $self->{read_pos} = $self->{write_pos} = 0;
  }
  sub add_mapaddress_to_buf {
    my ($self, $domain) =     my $command = 'MAPADDRESS 0.0.0.0='.$domain.CRLF;
    my $len = length $command;
    if ($self->{write_pos} + $len < BUF_SIZE) {
      Log->debug("Adding mapaddress to buffer for $domain\n");
      substr $self->{write_buf}, $self->{write_pos}, $len, $command;
      $self->{write_pos} += $len;
    } else {
      Log->info("Write buffer full. Dropping packet.\n");
    }
  }
  sub _readline {
    my $self = shift;
    my $index = index substr($self->{read_buf}, 0, $self->{read_pos}), CRLF;
    return if $index == -1;
    my $len = $index + length CRLF;
    my $line = substr $self->{read_buf}, 0, $len;
    if ($len == $self->{read_pos}) {
      $self->{read_pos} = 0;
    } else {
      substr $self->{read_buf}, 0, $self->{read_pos} - $len,
        substr $self->{read_buf}, $len, $self->{read_pos} - $len;
      $self->{read_pos} -= $len;
    }
    return $line;
  }
  sub _read_mapaddress_response {
    my $self = shift;
    local $/ = CRLF;
    while (defined( my $line = $self->_readline )) {
      chomp $line;
      my ($code, $ret) = split / /, $line;
      next unless defined $code and $code eq '250';
      my ($addr, $domain) = split /=/, $ret;
      $self->{dns_session}->send_response($domain => $addr);
    }
  }
  sub read {
    my $self = shift;
    Log->debug("Handling read from Tor control port\n");
    my $bytes = sysread $self->{handle}, $self->{read_buf},
                        BUF_SIZE - $self->{read_pos}, $self->{read_pos};
    if ($bytes) {
      $self->{read_pos} += $bytes;
      $self->_read_mapaddress_response;
    } elsif (defined $bytes && $bytes == 0 or $! != EWOULDBLOCK) {
      Log->info("Tor closed control connection\n");
      $self->{dns_session}->flush;
      $self->{disconnected} = 1;
    }
  }
  sub write {
    my $self = shift;
    Log->debug("Handling write to Tor control port\n");
    my $bytes = syswrite $self->{handle},$self->{write_buf},$self->{write_pos};
    if (defined $bytes) {
      if ($bytes == $self->{write_pos}) {
        $self->{write_pos} = 0;
      } else {
        substr $self->{write_buf}, 0, $self->{write_pos} - $bytes,
          substr $self->{write_buf}, $bytes, $self->{write_pos} - $bytes;
        $self->{write_pos} -= $bytes;
      }
    } elsif ($! != EWOULDBLOCK) {
      Log->info("syswrite() error: $!\n");
      $self->{dns_session}->flush;
      $self->{disconnected} = 1;
    }
  }
  sub can_write    { $_[0]->{write_pos} > 0 }
  sub handle       { $_[0]->{handle}       }
  sub disconnected { $_[0]->{disconnected} }
  1;
  package Socks::Resolve;
  use base 'Connection';
  use strict;
  use warnings;
  use Socket;
  use Errno 'EWOULDBLOCK';
  sub _add_request_to_buf {
    my $self = shift;
    Log->debug("Adding SOCKS resolve request to buffer\n");
    $self->{write_buf} = "\4\xf0\0\0\0\0\0\1\0$self->{domain}\0";
  }
  sub connect {
    my $class = shift;
    my $self = {
      handle   => undef,
      read_buf => '',
      time     => time,
          };
    bless $self, $class;
    my $timeout = 1;
    eval {
      # blocking connect shouldn't be a problem when tor is on loopback
      $self->SUPER::connect($timeout) or die $
      $self->_set_nonblocking if $^O ne 'MSWin32';
    };
    if ($ {
      Log->info("$ connection failed, dropping request\n");
      close $self->{handle};
      return;
    }
    $self->_add_request_to_buf;
    return $self;
  }
  sub _fail {
    my $self = shift;
    Log->info("SOCKS resolve failed for $self->{domain}\n");
    $self->{dns_session}->send_response($self->{domain} => 0);
    $self->{disconnected} = 1;
  }
  sub read {
    my $self = shift;
    Log->debug("Handling read from Tor SOCKS port\n");
    my $bytes = sysread $self->{handle}, my $buf, 8 - length $self->{read_buf};
    if (not defined $bytes) {
      $self->_fail if $! != EWOULDBLOCK;
      return;
    }
    $self->{read_buf} .= $buf;
    if (length $self->{read_buf} < 8) {
      $self->_fail if $bytes == 0;
      return;
    }
    my ($ver, $res, $port) = unpack 'CCn', $self->{read_buf};
    my $addr = substr $self->{read_buf}, 4, 4;
    if ($res != 90) {
      $self->_fail;
      return;
    }
    $self->{dns_session}->send_response($self->{domain} => inet_ntoa($addr));
    $self->{disconnected} = 1;
  }
  sub write {
    my $self = shift;
    Log->debug("Handling write to Tor SOCKS port\n");
    if (defined( my $bytes = syswrite $self->{handle}, $self->{write_buf} )) {
      substr $self->{write_buf}, 0, $bytes, '';
      delete $self->{write_buf} if length $self->{write_buf} == 0;
    } else {
      $self->_fail if $! != EWOULDBLOCK;
    }
  }
  sub can_read     { not exists $_[0]->{write_buf} }
  sub time         { $_[0]->{time}         }
  sub handle       { $_[0]->{handle}       }
  sub disconnected { $_[0]->{disconnected} }
  1;
  package DNS::Server;
  use strict;
  use warnings;
  use Socket;
  use POSIX;
  use Getopt::Std;
  use IO::Poll qw/POLLIN POLLOUT POLLERR POLLHUP/;
  use constant TIMEOUT => 300;
  my $Tcp_proto = getprotobyname 'tcp';
  sub new {
    my $class = shift;
    my $self = {  };
    bless $self, $class;
  }
  sub _fail {
    my $self = shift;
    print <_fail("Invalid user:group\n")
      unless $user and $group;
    defined( $self->{uid} = getpwnam $user )
      or $self->_fail("getpwnam($user) failed\n");
    defined( $self->{gid} = getgrnam $group )
      or $self->_fail("getgrnam($group) failed\n");
  }
  sub _sockaddr {
    my ($self, $port, $addr) =     return if $addr !~ /\A(?:\d+\.){3}\d+\z/;
    eval { sockaddr_in $port, pack 'C4', split /\./, $addr };
  }
  sub _open_tor_control {
    my $self = shift;
    $self->{tor_control} = Tor::Control->new(
      sockaddr       => $self->{tor_control_sa},
      dns_session    => $self->{dns_session},
      data_directory => $self->{data_directory} || undef,
      secret         => $self->{secret},
      terminate      => $self->{terminate}
    );
    my ($level, $handle) = (Log->level, Log->handle);
    Log->level(Log::DEBUG); Log->handle(*STDERR);
    $self->{tor_control}->connect;
    Log->level($level); Log->handle($handle);
  }
  sub _test_socks {
    my $self = shift;
    socket my $socks_test, AF_INET, SOCK_STREAM, $Tcp_proto
      or $self->_fail("socket() failed: $!\n");
    connect $socks_test, $self->{socks_sa}
      or $self->_fail("Connection failed to Tor SOCKS port\n");
    close $socks_test;
  }
  sub _bind {
    my $self = shift;
    socket $self->{handle}, AF_INET, SOCK_DGRAM, scalar getprotobyname 'udp'
      or $self->_fail("socket() failed: $!\n");
    setsockopt $self->{handle}, SOL_SOCKET, SO_REUSEADDR, 1
      or $self->_fail("setsockopt(SO_REUSEADDR) failed: $!\n");
    bind $self->{handle}, $self->{bind_sa}
      or $self->_fail("bind() failed: $!\n");
    $self->{dns_session} = DNS::Session->new(
      handle  => $self->{handle},
      timeout => TIMEOUT
    );
  }
  sub _daemonize {
    my $self = shift;
    defined( fork and exit )
      or $self->_fail("Can't fork: $!\n");
    POSIX::setsid
      or $self->_fail("setsid(): Can't create a new session: $!\n");
    chdir '/';
    umask 0;
    open $_, '+<', '/dev/null'
      or $self->_fail("Can't reopen $_ to /dev/null: $!")
        for *STDIN, *STDOUT, *STDERR;
  }
  sub _write_pid_file {
    my $self = shift;
    my $pid_handle = $self->{pid_handle};
    print $pid_handle $$;
    close $self->{pid_handle};
  }
  sub _chroot {
    my $self = shift;
    chroot $self->{chroot} and chdir '/'
      or $self->_fail("Can't chroot to $self->{chroot}: $!\n");
  }
  sub _drop_privileges {
    my $self = shift;
    $) = "$self->{gid} $self->{gid}";
    $( = $self->{gid};
    $> = $self->{uid};
    $< = $self->{uid};
    $self->_fail("Can't drop privileges to $self->{uid}:$self->{gid}: $!\n")
      if $) ne "$self->{gid} $self->{gid}" or $( != $self->{gid} or
         $> != $self->{uid} or $< != $self->{uid};
  }
  sub parse_options {
    my $self = shift;
    getopts 'b:t:s:u:p:c:v:k:w:l:f', \my %opt;
    defined $opt{$_} or $self->_fail
      for qw/b t/;
    $self->_fail("Can't set both cookie and password\n")
      if $opt{k} and $opt{w};
    $self->_fail("Can't set log file without log level\n")
      if $opt{l} and not $opt{v};
    $self->_fail("Must be run as root to chroot\n")
      if $opt{c} and $> != 0;
    $self->_fail("Must be run as root to drop privileges\n")
      if $opt{u} and $> != 0;
    my ($bind_addr, $bind_port) = split /:/, $opt{b};
    my ($tor_ctrl_addr, $tor_ctrl_port) = split /:/, $opt{t};
    defined $_ or $self->_fail
      for $bind_addr, $bind_port, $tor_ctrl_addr, $tor_ctrl_port;
    if ($bind_addr eq 'any') {
      $bind_addr = inet_ntoa INADDR_ANY;
    } elsif ($bind_addr eq 'lo') {
      $bind_addr = inet_ntoa INADDR_LOOPBACK;
    }
    $self->{bind_sa} = $self->_sockaddr($bind_port, $bind_addr)
      or $self->_fail("Invalid bind address or port\n");
    $self->{tor_control_sa} = $self->_sockaddr($tor_ctrl_port, $tor_ctrl_addr)
      or $self->_fail("Invalid Tor control address or port\n");
    if ($opt{s}) {
      my ($socks_addr, $socks_port) = split /:/, $opt{s};
      defined $_ or $self->_fail
        for $socks_addr, $socks_port;
      $self->{socks_sa} = $self->_sockaddr($socks_port, $socks_addr);
    }
    if ($opt{v}) {
      $opt{v} =~ /\A([1-2])\z/
        or $self->_fail("Log levels 1-2 are valid\n");
      my $log_level = (Log::INFO, Log::DEBUG)[$1 - 1];
      if ($opt{l}) {
        Log->init(level => $log_level, file => $opt{l})
          or $self->_fail($Log::Err);
      } else {
        Log->init(level => $log_level, handle => *STDERR);
      }
    }
    open $self->{pid_handle}, '>', $opt{p}
 $!\n")
        if $opt{p};
    $self->_set_ugid($opt{u}) if $opt{u};
    $self->{secret} = '';
    if ($opt{k}) {
      $self->{data_directory} = $opt{k};
    } elsif ($opt{w}) {
      $self->{secret} = unpack 'H*', $opt{w};
    }
    $self->{chroot} = $opt{c} if $opt{c};
    $self->{foreground} = 1 if $opt{f};
  }
  sub _dns_request_handler {
    my $self = shift;
    my $dns_request = receive DNS::Request $self->{handle} or return;
    if (not $dns_request->parse) {
      $dns_request->send_error($self->{handle});
      return;
    }
    if (not $self->{dns_session}->exists($dns_request->domain)) {
      if ($self->{socks_sa} and $dns_request->domain !~ /\.(?:exit|onion)\z/) {
        my $socks_resolve = Socks::Resolve->connect(
          sockaddr    => $self->{socks_sa},
          dns_session => $self->{dns_session},
          domain      => $dns_request->domain
        ) or return;
        $self->{poll}->mask($socks_resolve->handle => POLLOUT);
        $self->{socks_resolve}{$socks_resolve->handle} = $socks_resolve;
      } else {
        $self->{tor_control}->add_mapaddress_to_buf($dns_request->domain);
        $self->{poll}->mask($self->{tor_control}->handle => POLLIN | POLLOUT);
      }
    }
    $self->{dns_session}->add_request($dns_request);
  }
  sub _tor_control_handler {
    my ($self, $handle, $event) =     if ($event == POLLIN) {
      $self->{tor_control}->read;
    } else {
      $self->{tor_control}->write;
    }
    if ($self->{tor_control}->disconnected) {
      $self->{poll}->remove($handle);
      $self->{tor_control}->connect;
    }
    $self->{poll}->mask($handle => POLLIN)
      unless $self->{tor_control}->can_write;
  }
  sub _socks_resolve_handler {
    my ($self, $handle, $event) =     if ($event == POLLIN) {
      $self->{socks_resolve}{$handle}->read;
    } else {
      $self->{socks_resolve}{$handle}->write;
    }
    if ($self->{socks_resolve}{$handle}->disconnected) {
      $self->{poll}->remove($handle);
      delete $self->{socks_resolve}{$handle};
    } elsif ($self->{socks_resolve}{$handle}->can_read) {
      $self->{poll}->mask($handle => POLLIN);
    }
  }
  sub _timeout {
    my $self = shift;
    my $limit = time - TIMEOUT;
    return unless $self->{last_timeout} < $limit;
    $self->{dns_session}->timeout;
    for (keys %{ $self->{socks_resolve} }) {
      if ($self->{socks_resolve}{$_}{time} < $limit) {
        $self->{poll}->remove($self->{socks_resolve}{$_}->handle);
        delete $self->{socks_resolve}{$_};
      }
    }
    $self->{last_timeout} = time;
  }
  sub _event_loop {
    my $self = shift;
    $self->{poll} = IO::Poll->new;
    $self->{poll}->mask($_ => POLLIN)
      for $self->{handle}, $self->{tor_control}->handle;
    $self->{last_timeout} = time;
    for (;;) {
      $self->{poll}->poll;
      last if $self->{terminate}->();
      for my $h ($self->{poll}->handles(POLLIN | POLLERR | POLLHUP)) {
        if ($h eq $self->{handle}) {
          $self->_dns_request_handler;
        } elsif ($h eq $self->{tor_control}->handle) {
          $self->_tor_control_handler($h, POLLIN);
        } else {
          $self->_socks_resolve_handler($h, POLLIN);
        }
      }
      for my $h ($self->{poll}->handles(POLLOUT)) {
        if ($h eq $self->{tor_control}->handle) {
          $self->_tor_control_handler($h, POLLOUT);
        } else {
          $self->_socks_resolve_handler($h, POLLOUT);
        }
      }
      $self->_timeout;
    }
    delete $self->{poll};
    delete $self->{socks_resolve};
    $self->{dns_session}->flush;
  }
  sub _cleanup {
    my $self = shift;
    delete $self->{dns_session};
    delete $self->{tor_control};
    close $self->{handle}        if $self->{handle};
    Log->close                   if Log->handle;
  }
  sub DESTROY {
    my $self = shift;
    $self->_cleanup;
  }
  sub serve {
    my $self = shift;
    local %SIG;
    $SIG{PIPE} = 'IGNORE';
    my $terminate = 0;
    $SIG{INT} = $SIG{TERM} = $SIG{HUP} = sub { $terminate = 1 };
    $self->{terminate} = sub { $terminate };
    $self->_bind;
    $self->_open_tor_control;
    if ($self->{terminate}->()) {
      $self->_cleanup;
      return;
    }
    $self->_test_socks        if $self->{socks_sa};
    $self->_daemonize         unless $self->{foreground} or $^O eq 'MSWin32';
    $self->_write_pid_file    if $self->{pid_handle};
    $self->_chroot            if $self->{chroot};
    $self->_drop_privileges   if $self->{uid};
    $self->_event_loop;
    $self->_cleanup;
  }
  1;
my $server = DNS::Server->new;
=head1 NAME
B - A DNS server for plugging DNS leaks when using Tor
=head1 SYNOPSIS
B B<-b> I:I
              B<-t> I:I
              [B<-s> I:I]
              [B<-u> I:I] [B<-c> I]
              [B<-p> I] [B<-k> I] [B<-w> I]
              [B<-f>] [B<-v> I] [B<-l> I]
=head1 DESCRIPTION
B is a DNS server that instructs B to map a domain name to
a fake IP address, then responds with that fake address. Subsequently, B
will send connections intended for the fake address to the mapped domain name
instead. Actual domain names, C<.onion> names, and C<.node.exit> names work
using this method.
I must be specified in your I before B will listen on
the port needed for communication with B.
If you want B to answer queries over a network rather than just
over the loopback interface, you'll need to set I in your
I to C<10.192.0.0/10> or C<172.16.0.0/12>. This is necessary because by
default, B supplies fake addresses in the network 127.192.0.0/10, which
properly configured machines will route to the loopback interface.
Use the B<-s> option to resolve domain names with B's SOCKS resolve
extension instead of the C controller command. You must use this
option if you want applications to resolve names through B, but make their
actual connections directly. Even when the B<-s> option is specified,
C<.node.exit> and C<.onion> names will still be resolved with C.
=head1 OPTIONS
B<-b> I:I
        Bind the proxy to I and I. I can be
        either an IP address, C for the loopback
        interface, or C for all interfaces. If you
        are forwarding connections to B
        with pf or iptables rules, this should be
        C or C. Otherwise, it should
        be C or C. Binding to port 53
        requires root privileges.
B<-t> I:I
        Send C B controller commands to B
        on I and I. I must be an IP
        address. When B is listening on the loopback
        interface, this should be C<127.0.0.1:9051>.
B<-s> I:I
        Send SOCKS resolve requests to B on I and
        I. I must be an IP address. When B
        is listening on the loopback interface, this
        should be C<127.0.0.1:9050>.
B<-u> I:I
        Drop privileges to those of I and I. Only
        available when run as a privileged user.
B<-p> I
        Write PID to I.
B<-c> I
        Change root directory to I. Specify B<-u>
        also to make this irreversible. Only available
        when run as a privileged user.
B<-f>      Run in the foreground.
B<-v> I
        Output log messages at I. Available levels
        are 1 and 2. Level 2 is more verbose than level 1.
        Messages will be sent to stderr unless B<-l> is set.
B<-l> I
        Write log messages to I.
B<-k> I
        Authenticate to the B control port with the
        C file located in B's
        data directory, I. Add
        I to your I to
        enable this form of authentication. Cookie
        authentication doesn't work in B 0.1.1.20
        and earlier. Typically, B should
        be run as the same user B runs as to
        access I. If running in a chroot,
        I should be accessible both inside
        and outside the chroot from the same path.
B<-w> I
        Authenticate to the B control port with
        I. To enable this form of
        authentication, generate a hashed password with
        C<< tor --hash-password  >>, then place
        the hashed password in your I as the
        I.
=head1 SEE ALSO
B, L, L, L, L,
=head1 COPYRIGHT
B has been dedicated to the public domain. It has no
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-03-27 14:01:00
@_author: coderman 
@_subject: Tor Browser Bundle for GNU/Linux 1.0.0 Released 
certlock add-on would be useful too... even better if seeded with
perspectives like validated cert details for the popular targets, like
those you listed above.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-11-20 18:47:23
@_author: coderman 
@_subject: Bitcoin And The Electronic Frontier Foundation 
the latest i5 / i7 with AES-NI can accelerate ... AES.
the SPARC T2/T3 can accelerate:
- AES (ECB, CBC, CTR, CCM, CGM, CFB modes)
- RSA, DSA, DH
- Elliptic Curve (ECDH, ECDSA, including key generation)
- MD5, SHA1, SHA256, SHA384, SHA512
- Hardware entropy source
not much of a comparison, really.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-11-20 21:05:19
@_author: coderman 
@_subject: Bitcoin And The Electronic Frontier Foundation 
a T3 would be a great platform for a Tor relay, were someone to code
support for it.
fermi still pwns bitcoin...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-11-20 21:14:02
@_author: coderman 
@_subject: Bitcoin And The Electronic Frontier Foundation 
SETI at home is a cooperative effort. if they were to code their client
such that everybody was chewing on the same chunk of datum, that would
be wasted effort. (read: waste)
having any software miners active when GPU miners are active is wasted
effort. for integrity sake, bitcoin should disable all software
miners, and explain to users that trying to mine via software is "a
waste of your time and power".
last but not least, this discussion has clearly drifted way off topic.
why not take it to cypherpunks or cryptography list (if not bitcoin
if Tor starts using bitcoin for priority routing we can revive this thread..  ;)
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-11-16 10:27:57
@_author: coderman 
@_subject: Bitcoin And The Electronic Frontier Foundation 
On Tue, Nov 16, 2010 at 7:00 AM, TheGravitator
AES-NI is pretty slick. now if only we could get RSA/DSA/DH on die... :)
[the benchmarks in question show 875MB/s AES256 on PhenomII X6 1090T @
3.8Ghz as the closest competitor to the 11,000MB/s on i7-980X w/
AES-NI instruction at less clock.]
i haven't had a processor to test with; has any Tor user had luck with
openssl-aesni patches against 1.0.0?
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-11-17 15:49:14
@_author: coderman 
@_subject: Scalability and fairness [was: P2P over Tor [was: Anomos - anonBT]] 
there's always a catch. ;)
Tor would become something else, perhaps UDP Tor.
there has been more written on that subject than i can do justice
here.  i'm fond of DTLS signalling for encapsulated IPsec telescopes
with SFQ and DLP transport for multi-homed SCTP endpoints, but that is
just one of many possibilities.
a grand unified datagram Tor spec has yet to be written...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-11-17 17:27:17
@_author: coderman 
@_subject: Scalability and fairness [was: P2P over Tor [was: Anomos - anonBT]] 
mea culpa; i shall curb my reply-all enthusiasm!
grarpamp: i'll follow this up with links for  various UDP Tor papers
and discussions. i've got a bunch of bookmarks somewhere...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-10-24 20:28:21
@_author: coderman 
@_subject: TCP stack attack? 
long of it short: given the spectrum of OS level remote ring0 exploits
in network device and protocol attack surface, there is a potential
risk here. given all of the other risks [0][1], this is probably the
least of your many concerns...
best regards,
0. if I were to rank broad category,
a. application level arbitrary execution or side channel attack. so
many, so frequent to reify and persist, so easy to leverage for full
privileged arbitrary execution, so many additional clauses to add but
omitted for brevity. (remote w/ priv. escalation, direct remote
root/ring0, local escalation, vm break-out, many others)
b. Tor deployment weaknesses as commonly built, distributed, and used
on various platforms, primarily Windows, Mac and various Linux and
Unix like systems to a lesser extent for everyone but node operators.
(ex. Unauthenticated control port access with cross protocol vector -
implementation / deployment vulnerability)
c. Tor usability or correctness deficiencies including the application
layer (ex. Firefox with Tor Button Extension - application usability,
Transparent Virtualized Privacy Router - configuration correctness: IP
and DNS side channel elimination)
d. everything else, including mundane issues like not using trojaned
hardware out to exotic risk models with chained professional
multi-0day targeted efforts or state agency actors. but not the risks
that exist outside your threat model, or the un-identifiable and
un-conjecturable unknown risks we can't predict or reason about. :/
i mentioned the "Threat Model", right? because this entire topic of
conversation requires the presumptive act of you having pointed out
the threat model you are assumed to be operating under and that we are
both discussing. :)
1.  remote ring0 do happen, c.f. CORE-2007-0219: OpenBSD's IPv6 mbufs
remote kernel buffer overflow. fortunately these are rare, extremely
valuable (likely to be exposed once propagating), and relatively
infrequent compared to most other operating system vulnerability
stuxnet is a good example of the exotic end of this spectrum; unless
"you" yourself are a very well funded or state level actor you're
pretty much fucked/ entirely and inevitably fucked.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-10-24 20:38:11
@_author: coderman 
@_subject: TCP stack attack? 
Forgot to link to the announce in question; it is worthy of a read if
only to emphasize why any claim of immunity from a broad class of
threats with blanket assurance is a strong claim best made after
thorough and extensive effort to prove it to yourself via technical
applied testing and measurement.
"OpenBSD's IPv6 mbufs remote kernel buffer overflow"
2007-02-20: First notification sent by Core.
2007-02-20: Acknowledgement of first notification received from the
OpenBSD team.
2007-02-26: OpenBSD team communicates that the issue is specific to
OpenBSD. OpenBSD no longer uses the term "vulnerability" when
referring to bugs that lead to a remote denial of service attack, as
opposed to bugs that lead to remote control of vulnerable systems...
2007-03-05: Core develops proof of concept code that demonstrates
remote code execution in the kernel context by exploiting the mbuf
2007-03-05: OpenBSD team notified of PoC availability.
2007-03-07: OpenBSD team commits fix to OpenBSD 4.0 and 3.9 source
tree branches and releases a "reliability fix" notice on the project's
The OpenBSD kernel contains a memory corruption vulnerability in the
code that handles IPv6 packets. Exploitation of this vulnerability can
result in:
1) Remote execution of arbitrary code at the kernel level on the
vulnerable systems (complete system compromise), or;
2) Remote denial of service attacks against vulnerable systems (system
crash due to a kernel panic)
The issue can be triggered by sending a specially crafted IPv6
fragmented packet.
OpenBSD systems using default installations are vulnerable because the
default pre-compiled kernel binary (GENERIC) has IPv6 enabled and
OpenBSD's firewall does not filter inbound IPv6 packets in its default
However, in order to exploit a vulnerable system an attacker needs to
be able to inject fragmented IPv6 packets on the target system's local
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-10-24 21:32:28
@_author: coderman 
@_subject: DNS with Tor (compared to VPNs). 
the reverse is not true, however. there are numerous side channels
around host default nameserver entries set by VPN software or yourself
manually (explicit resolver IP passed to host libs, or custom UDP DNS
queries, or caching proxy query reflection, or. etc.
"am I leaking DNS?" turns out to be a complicated question...
this is one reason why Tor Button or other privacy minded extensions
and configurations explicitly disable bad plug-ins and mime types;
this is useful for VPN users in general who want leakage resistant DNS
privacy through their VPN provider DNS nameservers rather than ISP
again, more complicated than it seems; devil in the technical details
according to your uses and threats...
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-10-27 12:00:57
@_author: coderman 
@_subject: Hints and Tips for Whistleblowers - their comments on Tor and SSL 
client certificates, although fortunately these are difficult to
leverage surreptitiously...
this is definitely the riskiest aspect and why https is awesome when
used correctly. sadly, most https sites don't use https correctly.
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-09-24 20:30:43
@_author: coderman 
@_subject: The best way to run a hidden service: one or two computers? 
you'll likely need to have the interface down before changing mac:
sudo ifconfig eth1 down
sudo ifconfig eth1 hw ether sudo ifconfig eth1 up / or dhclient / or pump / or ...
however, if an attacker has access to read this locally they've
already compromised you to a degree that random mac affords no
(remember mac only visible on link-local or host)
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-09-26 21:16:12
@_author: coderman 
@_subject: The best way to run a hidden service: one or two computers? 
yup.  for the very few situations it is not true, you've designed a
virtual network and client environment with this class of information
leakage covered (read: you know what you're doing and what you're
defending against :)
yes. this is one reason why Torbutton is great regardless of other
protections. the list of plug-ins exposing dangerous interfaces /
attack surface is about as long as the list of plug-ins for FFox,
Chrome only has a prayer as live browser instance (which it does well
by the way!).
IE, Opera, Safari, most are hopeless.
yup, and/or upstream router details sufficient to geo locate you,
expose public IP endpoint, etc. (like the "how i met your girlfriend"
attacks, many others...)
yes. :)
yes. :P
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-09-27 05:04:42
@_author: coderman 
@_subject: The best way to run a hidden service: one or two computers? 
usually, yes. extended device statistics / mib, diagnostic cmds,
hardware manufacturer, or third party driver/stack components, or any
other numerous ways have been demonstrated to obtain serial nos,
device mac (regardless of sw/host change), and other sensitive
this is why arbitrary plug-ins are so dangerous and a restricted
browser necessary.
service affecting, but works every time...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2010-09-01 15:52:23
@_author: coderman 
@_subject: How to Run High Capacity Tor Relays 
if you're running a high capacity relay you likely don't need hw
acceleration because:
a. you're on a fast server with relatively modern processor to get
into the high capacity game. assembly optimized crypto is pretty fast
on these systems.
b. the compression, buffer management, and other aspects of Tor are
just as significant as the crypto specific parts on such a server.
c. the crypto hw needed to be effective is expensive, at least a
grand, or inside specialized server processors you're unlikely to have
in your dedicated / leased server hardware.
this is not to say it isn't useful. it's useful in all kinds of ways
ranging from efficiency improvements, side channel attack resistance,
to entropy sources for strong session key / nonce generation.
however, i doubt hardware crypto will prove useful for anyone in the
top tier of relay capacity to drastically improve their throughput or
efficiency overall given the current architecture of Tor itself.
and, as mentioned, there have been a number of threads on the subject,
and widely expanded OpenSSL engine support added since last year for
those interested in experimenting with hw acceleration.
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-08-26 15:54:24
@_author: coderman 
@_subject: [tor-talk] virtual private servers for Tor? 
Xen, VMWare work best in bridged mode; alas most providers don't
configure them this way.
OpenVZ is worthless from a networking standpoint and Virtuozzo only
somewhat better.
you'll want to peruse the wiki for vserver tuning tricks...

@_date: 2011-08-27 12:12:37
@_author: coderman 
@_subject: [tor-talk] virtual private servers for Tor? 
there's a huge volume of history spanning years of research on this
subject in both this mailing list, the wiki, the old-wiki, and trac
tickets.  i speak from experience, and if you're curious the details
are there.
i agree it would be nice to have a singular set of pros / cons in
detail. perhaps you could aggregate and compile it? ;)
concurrent number of open sockets. ip stack tuning parameters. other
technical constraints that make networking on these "light overhead"
container systems unworkable. the very design trade offs they make to
support larger numbers of contains per host directly reduce the
networking performance and capacity of any singular container/vm.
you must have at least X resources to participate in the Tor network
as a router.  these crippled systems don't cut it.
vserver is the best of the low overhead bunch. depending on how they
are provisioned, you've got access to the networking parameters needed
and can scale out enough sockets to be workable.
also, it would be helpful to describe how you are running your node.
the following directly affect network resource consumption and can
make or break a relay on these constrained systems:
- middle only or exit?
- serving directory or not?
- serving hidden svc descriptors or not?
- received the guard flag or not?
- using bandwidth or socket constraints in config or not?

@_date: 2011-08-27 12:29:59
@_author: coderman 
@_subject: [tor-talk] virtual private servers for Tor? 
note that design trade-offs in favor of speed also reduce the security
alone should not be only consideration.
as to the question which work well or poorly as Tor routers, too many
factors for a simple yes or no. on a spectrum of best to worst try
this ranking, with the usual caveats of how context dependent views
with the added caveat that many low end virtuozzo, openvz, uml hosting
are too constrained to run a useful relay.

@_date: 2011-12-04 11:24:32
@_author: coderman 
@_subject: [tor-talk] Running tails headless ... virtualbox ... 
use xvfb (X virtual framebuffer) as the display environment. you can
then even run VNC or remote desktop to this display, if you want a
tails GUI, otherwise shell in as usual.

@_date: 2011-12-27 16:35:22
@_author: coderman 
@_subject: [tor-talk] Tor transparent proxy implementation on Windows 
it is not as simple, but you could create the equivalent facilities on
Windows. torvm is deprecated (an out of date proof of concept?) but
this statement would be worth updating for someone with access to that
to clarify, to implement the desired owner / application based port,
and protocol filtering, you would likely need to implement a shim with
NDIS intermediate and filter driver interfaces as well as the newer
WFP features if available to do what is needed on the intended XP
through 7 systems. this also implies driver signing and the scrutiny /
hurdles that involves for modern Windows 32 and 64bit kernels.
if you only target windows 7 the built in filter facilities, while not
equivalent on command line basis, are probably suitable. and WFP
certainly is!
this is a longer discussion, for someone interested. broken out to map
the various old intermediate APIs and support, to the newer filter
interfaces and advanced command line capabilities need to do full host
transparent proxying without a guest or aliased interface (inline),
and in tandom with one or more guest VMs to isolate Tor or its
accompanying components.
transparent proxying to the host itself is technically different
enough to matter between WFP and NDIS. that is, there is more to this
than just intercept/forward, nor just port filtering or redirect.
while there are features to do this on WFP (and to a lesser extent
with NDIS) the command line capability and full host transparent proxy
are still tricky (and worth breaking out into detail as mentioned
above, if someone is interested.)
presume that this is in context of relying on poor socket style
interfaces in Windows networking instead of high performance I/O
completion ports and async networking.
at the time of writing, Tor did not take full advantage of async I/O
on Windows due to libevent limitations in the 1.x series. libevent 2.x
has much improved Windows support.
that would be ideal, but still much more work. Tor VM used existing
WinPCAP and Tap32/64 drivers, there was zero kernel side driver
development to make use of the existing transparent proxy facilities
in linux.
yes. see above. Tor VM is nearly 3 years out of date at this point...

@_date: 2011-12-28 22:13:43
@_author: coderman 
@_subject: [tor-talk] Tor transparent proxy implementation on Windows 
it would be useful for many reasons, including:
- fail-safe configuration by enforcing Tor or nothing behavior.
- high performance interface to VM networking (virtio capable).
- robust QoS on client traffic by application, user or protocol.
- native transparent proxy support without VMs of course.
agreed. i'd be happy to assist with this effort as a technical
resource, but i cannot be a significant developer.
this was integrated into the Tor VM for the WinPCAP and Tap32 driver
builds via MSVC command line and WDK/DDK tools. the build
configuration is annoying, but straightforward _as long as the tools
are free_.
a wildcard for sure. you're going to pay for the driver testing &
signature anyway, so there is no way to escape some tithe to Microsoft
when going the native driver route. given this fact, additional
licenses for a DDK/WDK may not be onerous.
i hadn't considered these difficulties much, but support requirements
would indeed be unique and perhaps significant. i've seen more than a
few VPN and Firewall solutions on windows conflict badly with other
intermediate and filter drivers.
it would be nice to formally deprecate XP. at Vista and above things
become less stratified.
we could find out, dig up tech details, and document on the wiki. :)
sure, link them here. i can take a stab at a wiki page and will
include these resources as part of the discussion.
best regards,

@_date: 2011-02-08 02:38:22
@_author: coderman 
@_subject: Bridging from Bootcamp??? 
check your firewall. usually this is the windows or $antivirus
firewall blocking UPnP and/or the listening Tor socket.
(you can try just disabling the firewall to confirm/deny, and then
continue on to the various help sites for configuring allow rules for
Tor bridge, relay, UPnP requests, etc.)
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-02-05 00:56:20
@_author: coderman 
@_subject: Tor raid [was: "cease and desist" from my vps provider...] 
this is interesting.
just to clarify: you had traffic of interest from a dedicated server
in a data center running Tor, yet the raid and confiscation targeted
hardware at your home?
(while leaving the data center server untouched?)
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-02-07 15:15:59
@_author: coderman 
@_subject: Tor raid [was: "cease and desist" from my vps provider...] 
only if you purchase said services under your real name/accounts or
without sufficient indirection.
defense in depth++
but that is tangential discussion not for this list...
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-01-11 12:21:13
@_author: coderman 
@_subject: BHDC11 - De-anonymizing Live CDs through Physical Memory Analysis 
does anyone know more about the methods to be discussed by Andrew Case
next week?
the memory analysis of Tor seems interesting.
(do Tor Live CDs need a new kexec target for memtest sweeps / ram
zeroisation? :)
Traditional digital forensics encompasses the examination of data from
an offline or ?dead? source such as a disk image. Since the filesystem
is intact on these images, a number of forensics techniques are
available for analysis such as file and metadata examination,
timelining, deleted file recovery, indexing, and searching. Live CDs
present a large problem for this forensics model though as they run
solely in RAM and do not interact with the local disk. This removes
the ability to perform an orderly examination since the filesystem is
no longer readily available and putting random pages of data into
context can be very difficult for in-depth investigations. In order to
solve this problem, we present a number of techniques that allow for
complete recovery of a live CD?s in-memory filesystem and partial
recovery of its previously deleted contents. We also present memory
analysis of the popular Tor application as it is used by a number of
live CDs in an attempt to keep network communications encrypted and
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-01-12 04:06:05
@_author: coderman 
@_subject: BHDC11 - De-anonymizing Live CDs through Physical Memory Analysis 
likely so. however, more than just wipe at shutdown is useful.
explicit ordered zeroisation is handy. (starting with keys and key
schedules, working cipher state, then on to user data, before
completing a full pass or three. this takes a smart kexec or other ham
fisted - still worth the effort.)
synchronous wipe on shutdown in foreground with progress indication. i
argue this necessity on usability basis.
experimental methods like key and state storage in CPU cache lines may
hold promise.
physical rendition of your solid state memory via self-powered
capacitive discharge initiated by big red panic button! (ok, not
really. you get the picture :)
yes, i've seen the sleep 10 magic smem trick, and this is one reason
why pre-empting the entire runtime to execute a wipe is useful - there
are no locked devices or blocking operations contending for resources
with the wipe procedure itself.
in any case, this begs the question of best practice in solid state
remanence avoidance.  it would make a good FAQ entry, perhaps...
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-01-12 13:02:03
@_author: coderman 
@_subject: Tor relay on vserver exeeding numtcpsock 
550 is ridiculous. it should be at least 4096, more if they are accomodating.
you may or may not find the ConstrainedSocksSize option useful as well.
good luck!  you may want to update the good / bad ISP entry with your
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-01-12 12:56:37
@_author: coderman 
@_subject: BHDC11 - De-anonymizing Live CDs through Physical Memory Analysis 
right.  there are trade-off's with the kexec approach, mainly that
you're bypassing most normal shutdown.
i don't care, as long as dirty pages are written before mem is trashed...
the kernel key management facilities do make it easy, although you
also need to consider userspace like OpenSSL keys and cipher state.
kudos sir!
nope, that's the method. it is ghetto, for sure, but unless you've got
a real HSM that's as good as you'll get.
and as mentioned, cache line key storage is only effective if the
entire key, including any expanded key schedules, is kept in cache.
this is another performance hit, unless you've got AES-NI on die or
other acceleration.
anyway, not really practical yet. and likely never will be.
best regards,
To unsubscribe, send an e-mail to majordomo at torproject.org with
unsubscribe or-talk    in the body.

@_date: 2011-06-28 20:36:02
@_author: coderman 
@_subject: [tor-talk] Access blocked by Baracuda Content filter 
have you tried using bridges?
please report back if bridges do not work.

@_date: 2011-03-20 19:21:43
@_author: coderman 
@_subject: [tor-talk] How evil is TLS cert collection? 
if EFF was presented with a national security letter or other legal
demand under seal demanding the existence of a given certificate not
be exposed, would they be bound to not present a MITM alert for that
(said another way, could this potentially be a false sense of
security, if all trust for anomaly notification was placed in the EFF

@_date: 2011-05-28 22:47:55
@_author: coderman 
@_subject: [tor-talk] Tor Webmail 
spoof user agent. vi ~/.kde/config/kio_httprc
be happy.

@_date: 2011-05-28 22:50:12
@_author: coderman 
@_subject: [tor-talk] Tor Webmail 
or ~/.kde/share/config/kio_httprc
(if you've been using this for 10 years, not sure what ver. you're on ;)

@_date: 2011-11-07 21:29:12
@_author: coderman 
@_subject: [tor-talk] Tor and AES-NI acceleration , and Tor profiling 
this notice does indicate you are successfully using the dynamic aes-ni engine.
public key operations and zlib still dominate processing. however, you
are getting not only 3x-10x+ performance improvement in AES ops, but
also avoiding nearly all side channel attacks against AES!
it would be useful to be able to toggle this engine on and off at run
time without a restart of Tor to measure actual performance comparison
of a running node with and without AES-NI acceleration.
best regards,

@_date: 2011-11-08 20:47:32
@_author: coderman 
@_subject: [tor-talk] Tor and AES-NI acceleration , and Tor profiling 
apologies, this is a general statement of my previous profiling which
assumed dir port enabled, hs dir, and exit status.
the profile attached looks more like a non-exit, no dir port, no hsdir
setup. (entry/middle only?)
this deserves a longer treatment i'll try to address soon...

@_date: 2011-11-18 13:44:07
@_author: coderman 
@_subject: [tor-talk] Tor and AES-NI acceleration , and Tor profiling 
hi Moritz, were you able to gather updated stats now that additional
flags are present?
i am very curious about the performance profiles you've observed; they
are unusual :)
best regards,

@_date: 2011-11-18 14:03:18
@_author: coderman 
@_subject: [tor-talk] Tor and AES-NI acceleration , and Tor profiling 
my understanding is that HiFn supports only symmetric and digest
acceleration (w/ hw entropy). [0] the only public key accelerated
devices i've used are montmult in VIA Padlock enabled cores (too slow
for fast relay) and SCA6000 devices (too expensive for a relay?)
the padlock montmult uses the "padlock" engine and the sca6000 is
utilized via the "pkcs11" engine.
still waiting for ssl-shader to be released, it could be promising. [1]
for AES acceleration it's hard to beat Intel's native instruction set
for it.  Tor could of course make better use of these interfaces to
improve performance as Nick pointed out earlier.
backdoor != sidechannel  ;P
0. the HiFn

@_date: 2011-11-18 14:05:27
@_author: coderman 
@_subject: [tor-talk] Tor and AES-NI acceleration , and Tor profiling 
0. the HiFN DS 100, DS 250, and DS 255 only do symmetric that i can see.
1.

@_date: 2011-11-28 11:39:40
@_author: coderman 
@_subject: [tor-talk] Tor and AES-NI acceleration , and Tor profiling 
the latter looks more like what i expected:
samples  %           symbol name
930011   12.9268   bn_mul_mont
831935   11.5636   sha1_block_data_order
470510    6.5399   libc-2.13.so
297219    4.1312   nf_conntrack
217209    3.0191   libz.so.1.2.3.4
171688    2.3864   aesni_ecb_encrypt
171151    2.3789   aesni_cbc_encrypt
114169    1.5869   e1000e
111509    1.5499   aes_crypt_inplace
GPU support for montmult, sha1, and gzip would be a nice complement to
your AES-NI capacity.

@_date: 2011-10-04 22:02:18
@_author: coderman 
@_subject: [tor-talk] Qubes TorVM (and more fun :) 
Relevant to a few threads lately:
"Today, I would like to showcase some of the cool things that one can
do with the Qubes networking infrastructure, ... the use of multiple
Net VMs for creating isolated networks, the use of a Proxy VM for
creating a transparent Tor Proxy VM, as well as [more fun]"
TAILS + Qubes would be awesome, and more than a little work.

@_date: 2011-09-08 10:18:20
@_author: coderman 
@_subject: [tor-talk] Hardware accel by default 
nice! glad to know this is working as expected with other dynamic engines.
some engines are actually slower than host optimized code.
hw accel is experimental, and by default all providers in an engine
are used. aesni is specific (aes only) but something like pkcs11 could
use acceleration where not intended (montmult accel is fast but aes is
slow, for example).
if an engine is loaded (device present) and fails there is no graceful
fallback, this could leave Tor broken in a way that is hard to
diagnose via logs or traces. by explicitly enabling this, you are
assumed to know what you're doing.
probably other reasons i've overlooked...

@_date: 2011-09-22 19:53:51
@_author: coderman 
@_subject: [tor-talk] using TOR without any browser 
unfortunately you'd have to build it yourself. if you can do this a
linux or bsd computer acting as a transparent Tor proxy can route
everything from your ethernet card over Tor (or drop/filter it.)
may even be a tiny linux router with dual ethernet ports for a
transparent inline portable Tor proxy appliance powered by USB
(gumstix, now defunct yoggie, etc.)
be warned: not only is this technically difficult, but the risks using
an entire system in transparent Tor mode are difficult to identify and
address. Browser Bundle Firefox and Torbutton extension is recommended
for a reason!
see also

@_date: 2012-04-18 00:07:11
@_author: coderman 
@_subject: [tor-talk] wget - secure? 
1. using environment variables correctly
2. using command line parameters correctly
set http_proxy but not HTTPS_PROXY or ALL_PROXY with recursive? maybe oops.
all generalizations are false ;)
in other words, user beware.

@_date: 2012-08-10 20:19:01
@_author: coderman 
@_subject: [tor-talk] Attack against Tor: Statistic Manipulation Attack 
i thought this might be a person contributing to an incendiary topic...
now i'm convinced this adrelanos is a bot :)

@_date: 2012-08-10 20:27:58
@_author: coderman 
@_subject: [tor-talk] effect of Tor exit IP addresses listed on a few 
this is why you see aggressive use of "new" exits by various parties
who are interested using in Tor exits before they get listed. they
write their own controllers for the purpose even...
as for impact, the majority of complaints i've seen are from
individuals who run an exit from their home and have trouble accessing
email, other services once identified as a Tor exit.  most hosting
providers don't seem to care if your IP gets listed, only if you're
sending abusive traffic from it that is reported to them.

@_date: 2012-08-10 20:36:12
@_author: coderman 
@_subject: [tor-talk] simple example in ruby 
behind transparent Tor proxy (see FAQ :)
s = TCPSocket.new 'ypr7i2smxhcjalla.onion', 80
s.puts "string"
while line = s.gets
  puts line         # this is your answer(s)
if you want to speak to Tor SOCKS port directly, and use name
resolution correctly, that's a longer answer... and this is not the
right forum to ask.

@_date: 2012-08-10 20:52:13
@_author: coderman 
@_subject: [tor-talk] Bug Remains: OpenSSL library does not load unless 
this gentleperson appears confused by static vs. dynamic linking.
not every application does it the same!

@_date: 2012-08-10 23:40:36
@_author: coderman 
@_subject: [tor-talk] Tor as ecommerce platform 
you're mostly wrong, unless they are incredibly stupid. however recent
monitoring has tried to close the gap and correlate transaction origin
with IP origin, to fuzzy degree.
see also  ,
 and their "taint analysis"
feature... unless washed through the bitcoin laundry ;)
the oldest tricks are the best tricks!

@_date: 2012-01-28 11:13:20
@_author: coderman 
@_subject: [tor-talk] Bad performance in private tor network 
how many clients are you using to test with? at least a hundred?

@_date: 2012-07-15 21:10:10
@_author: coderman 
@_subject: [tor-talk] hidden services 2.0 brainstorming 
Tor does not use third party CAs like verisign, thawte, etc.
the directory authorities are your CA equivalents, and consensus
protects against singular MITM like that applied to rogue CA

@_date: 2012-07-15 21:16:29
@_author: coderman 
@_subject: [tor-talk] CA cert MITM vulnerability in Tor? (Was: hidden 
the null byte implementation failure does not apply to Tor. the rogue
CA attack does not apply to Tor.
correct; a rogue CA cert could be leveraged for a MitM attack at a
malicious exit. this is outside the Tor threat model.

@_date: 2012-06-23 22:04:45
@_author: coderman 
@_subject: [tor-talk] Roger's status report, May 2012 
sounds interesting!
are these devs and researchers that already know about each other,
 or is this part call for participation?
any papers, wikis, git repos, or other resources expected this summer?
this is disappointing. i hope it is a transient situation...
the blog has more search engine visibility, open commentary;
announcing entry on the dev list with a link not a bad idea either.
  and when does anonbib get links to reviews? ;)

@_date: 2012-03-03 12:00:03
@_author: coderman 
@_subject: [tor-talk] Obtain real IP behind Tor transparent proxy; 
Transparent Proxy
this is prone to failure as you mention and easily compromised by
anything not honoring proxy settings. (which can be as trivial as a
crafted file path on windows)
same as above. anything "Torified" via per application or per user
settings are vulnerable to these side steps, to a lesser or greater
degree depending on operating system, configured services, etc.
this is not true. you also need to prevent any local subnet
communication is this mode to be fully protected. there are multiple
ways to bounce/reflect an attack off the local network to directly
obtain real public IP or leak origin to attacker.
this is why the old Tor VM docs explicitly stated "A robust
transparent Tor proxy implementation requires careful configuration of
the routing and filtering of traffic on both the host and guest OS
instances. Unfortunately Windows does not support /31 style
point-to-point links so a two host address /30 subnet is used."
depends on how you setup networking to funnel traffic to these
transparent redirect ports.

@_date: 2012-03-03 12:12:53
@_author: coderman 
@_subject: [tor-talk] Risk with transparent proxy mode [was Re:Operating 
these are significant if you are mixing tor and non-tor access on the
same system. much of this is covered in the thread, and the particular
risks are very specific to context and nature of use, as discussed.
yes. there are still poor and better ways to configure transparent proxy.
this is not true; you must also prevent all local subnet access when
in this mode. this may entail removing IPv6 interfaces, changing the
default route to a /31 or /30 path, etc.
otherwise there are attacks which reflect or bounce traffic on the
local network to obtain public IP address or leak endpoint to an

@_date: 2012-03-03 21:01:45
@_author: coderman 
@_subject: [tor-talk] Risk with transparent proxy mode [was Re:Operating 
some operating systems (Windows) do not support /31 host-to-host
interface configurations. in which case, a /29 two host subnet
achieves the same result (forcing all remote traffic through default
gateway, transparent proxy port in Tor in this case.
the setup looks fine from a cursory check, but i would need to give it
a run to know.  the concern with local network access is primarily at
the client. an insecure configuration would look like:
client(physical)  eth0 192.168.1.100
localrouter(physical) via eth0 at 192.168.1.1
virtual torbox at 168.16.1.1 via eth1/tun0 (virtual device) and client
using 168.16.1.100
virtual torbox outgoing bridged to eth0 using 192.168.1.102 using second device.
in this case, even if client was routing all internet access through
168.16.1.1 virtual torbox, it could still be compelled to send TCP or
UDP traffic to the 192.168.1.1 and other hosts on the network. such
reflection off internal hosts can compromise your anonymity.
cross over / isolated LAN is the key part here. if you share same LAN
between client and internal network, hosts within that internal
network can be leveraged to leak.
the transparent proxy ports (TCP and DNS) work great in Tor. it is the
routing configuration between the client and these ports which is of

@_date: 2012-03-06 15:58:10
@_author: coderman 
@_subject: [tor-talk] How to contribute / takeover a sub project? 
not quite; some differences that drove the original Tor VM effort:
- you rely on closed source virtualization (Tor VM builds modified
Qemu from source)
- you don't support windows robustly (e.g. the /29 discussion,
simplified install/run)
that said, you do have many additional useful features in TorBOX.
there seem to be different audiences here. Tor VM was explicitly
targeted for windows and ease of use (no technical know how required).
it didn't quite get there, but calling TorBOX equivalent is a bit
what would be the purpose?
make TorBOX easy to use on windows. then it could provide what the Tor
VM experiment failed to do.
(Do you just prefer the name?)

@_date: 2012-03-06 23:02:22
@_author: coderman 
@_subject: [tor-talk] How to contribute / takeover a sub project? 
note that Tor VM is not on that page. ("taking over" Tor VM would not
grant you a spot ;)
for a redistributable installer / portable app you'd need to build
virtualbox from source with different visible content. otherwise, it
may finally be suitable. (only other question is if the signed drivers
for windows can be redistributed with a custom build of vbox itself.
kernel acceleration is useful, this was a major pain point with Qemu!)
yes; it would be better to have a controller / wrapper around existing
VirtualBox so that it could be launched in a robust mode of operation
automatically, so there is no need for manual steps the user may not
perform correctly.
for redistribution, you may need to make some slight changes for
builds but nothing like a fork.
there are a lot; was reviewing
 too :)
they're pretty different. if there are aspects of Tor VM that would be
useful in TorBOX the license is permissive and owned by The Tor
Project, Inc. (excluding the third party components it is based of off
like openwrt, etc. of course)
the only parts that seem relevant may be the controller for windows or
the openwrt builds for the Tor-Gateway.ova like functionality.
TAILS is likely another great resource, although i know much less
about that system.
best regards,

@_date: 2012-03-10 20:21:04
@_author: coderman 
@_subject: [tor-talk] Tor and HTTPS graphic 
as amused as i am by our favorite dumpster diver, this does bring to
mind the need for datagram transport with multiplexed paths and
stochastic mixing.
a lot of infrastructure to build; call it Tor 2.0:
combine LEDBAT edge management[0] with SCTP multi-homed[1] endpoints
over ORCHID overlay[2] provided by IPsec telescopes[3] with reliable
multicast gradients[4] and stochastic fair queuing[5] and you've got
something resistant to passive and active attacks, including traffic
build the meanest machine learning system and throw it at it, the pure
theory a little unwieldy...
have fun!
0. 1. 2. 3. 4. 5.

@_date: 2012-03-13 19:31:34
@_author: coderman 
@_subject: [tor-talk] Tor and HTTPS graphic 
my last comment for this sad, confused tangent of a thread;
  it has been accosted via conjecture with too much frequency *grin*
SCTP for congestion control of transparent proxy TCP/UDP traffic.
local classification of traffic allocates by protocol / use fairness
instead of aggregate tcp fairness. like bittorrent or aria2 parallel
traffic treated as distinct low priority unit of traffic, deferring to
higher priority low latency web traffic and messaging.
multi-homing / multi-path endpoints in SCTP would maintain concurrent
connection with distinct endpoints, avoiding predecessor, timing,
denial of service attacks present in reliable, ordered, single stream
edges would be screwed as you mention, unless they were full fledged
participants consistently. using a UDP based transport with LEDBAT or
other technique to keep broadband upstream unsaturated and unclogged
(no deep queues), allowing all broadband endpoints the ability to
contribute to a large shared network.
ORCHID IPv6 addressing with IPsec tunnels is intended to re-use
existing work, including well tested auth+privacy with datagram
padding in IPsec. SCTP+TLS would fit over top of IPv6 ORCHID endpoints
(using IPsec SAs) to transport signalling/keying and encapsulated
client traffic. part of this would also include lowest priority (lossy
reliable) SRMP type delivery of useful, less immediate information to
nodes. to some extent the ORCHID addresses could be thought of as
hidden service names and also circuit endpoints for a given IPsec
this set of:
a. critical signalling and keying traffic
b. high priority, interactive web traffic and messaging
c. lower priority bulk traffic, downloads, streaming media
d. best effort, latent bulk caching and exchange
are the classful shaping groups ordered inside of opaque SFQ outbound
queues at various improved/concurrent stratified dependent link
padding paths of IPsec telescopes carrying intermediate
hop(signalling) and bearer traffic.
combining better prioritization of traffic and consistent consumption
of traffic (deferring low priority packets and using opportunistic
caching strategies for network information respectively) obtains the
best performance out of the SFQ DLP paths with the lowest latency for
priority traffic.
still, so many details left as exercise for the reader ;)
sort of, for only parts; if you want a portable user space
implementation (or port) it's all custom. the joys of wild conjecture
include absurd timelines and technical effort for free...
rump is about as close as i've seen: this is not the least of "how to deploy a thing like this" concerns.
there is also no backward compatibility or slow transition from an
existing Tor network to something using UDP encapsulated IPsec
telescopes (even if TCP can be transparently proxied over SCTP over

@_date: 2012-05-11 16:43:43
@_author: coderman 
@_subject: [tor-talk] tor/netfilter: packets without uid 
if the application closes a socket there are time wait states that
retain the socket ip:port endpoint in kernel land without an
associated application user ID.
try disabling time wait to confirm. if it is indeed sockets locally
closed but still receiving (and ACK'ing) you may get a little extra
bandwidth dropping them (remote re-sends until timeout) but it
shouldn't affect functionality.

@_date: 2012-05-11 16:59:46
@_author: coderman 
@_subject: [tor-talk] Setting up redirection to TORs transparent proxy 
connection tracking (conntrack) works on new streams; when the SYN
(connect) is redirected, the conntrack behavior in iptables does the
you can read an overview here if curious:

@_date: 2012-05-11 20:09:07
@_author: coderman 
@_subject: [tor-talk] tor/netfilter: packets without uid 
some would call it a kernel "feature" to conserve memory space already
wasted on TIME_WAIT.  not everything is designed around your
particular use case. (it is not uncommon to find systems with 32k to
100k's of connections in time wait state at high throughout. a few
more bytes each adds up!)
this is the better option, and fails safe.
it's been years and still transparent proxy modes are black magic. one
day we'll figure this out, right?

@_date: 2012-05-11 22:05:14
@_author: coderman 
@_subject: [tor-talk] tor/netfilter: packets without uid 
actually not straight forward. depending on kernel, first try:
  echo 1 > /proc/sys/net/ipv4/tcp_rfc1337
some other settings to aggressively prune lingering kernel states:
  echo 2 > /proc/sys/net/ipv4/tcp_fin_timeout (or 1)
  echo 0 > /proc/sys/net/ipv4/tcp_orphan_retries
you can set these in sysctl.conf if you want to persist...

@_date: 2012-05-11 22:14:45
@_author: coderman 
@_subject: [tor-talk] tor/netfilter: packets without uid 
not the right option; this is different, and to avoid an issue with time wait.
the feature i'm thinking of is time-wait negotiation, which can be
tweaked to always put this state on the peer (or fail if not
last time i messed with this is was kernel build tweaks; probably too
much for most tastes ;)
regarding the match rules, why are you whitelisting a firefox
instances? a robust setup is everything transparently routed, except
for Tor PID, and only this PID. kernel originated traffic and all
other application originated traffic is thus routed properly without
bypass, assuming Tor itself is not vulnerable.

@_date: 2012-09-20 07:31:22
@_author: coderman 
@_subject: [tor-talk] Apps which uses outgoing fixed IP-Adrs:AnyPort, 
the fundamental limitation here is windows networking circa XP (any SP).
the easy answer is: run a transparent proxy Tor VM like Tails or a
custom ramdisk with a VM implementation that supports bridged mode.
route through it, but only selectively, via iptables, route through
Tor transparently.
more complicated than this, but you've probably got the picture. use
modern Windows[0] or other OS.
0. as of win7, svr2008 you can use advanced firewall settings to
accomplish what you describe.

@_date: 2013-08-09 00:39:03
@_author: coderman 
@_subject: [tor-talk] Secure email with limited usable metadata 
another one decides email is inherently insecure:
  Silent Mail has thus always been something of a quandary for us. Email
that uses standard Internet protocols cannot have the same security
guarantees that real-time communications has. There are far too many
leaks of information and metadata intrinsically in the email protocols
themselves. Email as we know it with SMTP, POP3, and IMAP cannot be
use other tools and protocols for private communication!  here's to
hoping TorMail stays dormant...

@_date: 2013-08-10 15:50:42
@_author: coderman 
@_subject: [tor-talk] Secure email with limited usable metadata 
this is the kind of messaging i would use - leaving all the
complexities and drawbacks of traditional email behind.
and StealthMonger: while the theory and design of latest generation
anonymous remailers are suitable for secure mail, the practical
realities render them unusable.
effort on real-time protocols that can defend against traffic
analysis, or other non-email systems like pond would be better spent.

@_date: 2013-08-18 17:20:54
@_author: coderman 
@_subject: [tor-talk] Tor Mail Gateway (was: Re: Replacement for Tormail) 
sounds better than average,
this only makes sense on the client protocols, of course. (since you
can't enforce behavior on intermediate paths of delivery. did i
mention that email sucks in many ways like this? ;)
if you discover a usable way to make client certificates, including
key management / re-keying usable, then by all means use this better
authentication mechanism!
i still don't like this idea, but think you're approaching it as best
possible. good luck!

@_date: 2013-12-14 06:14:27
@_author: coderman 
@_subject: [tor-talk] Help testing patch on SandyBridge/IvyBridge? Force 
this is logged as trac ticket:
  FreeBSD project announced RDRAND not to be used directly, with OpenSSL
following guidance.[0][1][2]
  you are using a Tor built against openssl-1.0.1-beta1 through openssl-1.0.1e
  you have set HardwareAccel 1
  you should implement one of the remedies below!
help coderman test mitigation patch:
      if on Sandy Bridge, Ivy Bridge, other Intel CPU with RDRAND.
OTHER mitigation:
- re-build your OpenSSL with OPENSSL_NO_RDRAND defined
- re-build your Tor with DISABLE_ENGINES defined
- update to latest git openssl or cherry pick commit: "Don't use
rdrand engine as default unless explicitly requested." - Dr. Stephen
best regards,
0. "FreeBSD Developer Summit: Security Working Group, /dev/random"
  1. "Surreptitiously Tampering with Computer Chips"
  2. "How does the NSA break SSL? ... Weak random number generators"

@_date: 2013-12-14 10:07:29
@_author: coderman 
@_subject: [tor-talk] Help testing patch on SandyBridge/IvyBridge? Force 
i am not speaking for Tor devs nor Tor project - the cautious should
wait for a review and merge.
many thanks to rl1987! the patches have been updated and verified.
anyone running a relay on openssl 1.0.x with HardwareAccel 1 and
seeing this line in their notices.log:
"[notice] Using OpenSSL engine Intel RDRAND engine [rdrand] for RAND"
should** apply the apropos patch above and let me know if it doesn't
a successful mitigation will look like this:
[warn] OpenSSL is using RDRAND by default. Attempting to force disable.
 ...
[notice] Using default implementation for RAND
**last but not least, please do run a userspace entropy collector like
haveged, dakarand, etc.  also be sure you're on a recent kernel that
is using RDRAND in a conservative / robust manner.[0]
best regards,
0. "void extract_buf(struct entropy_store *r, __u8 *out)"
  good use of RDRAND is:
1. mixed into a hash across the pool, not XOR'd against output,
2. mix the mix back into pool (prevent backtrack attacks)
3. atomically extract portion of pool and mix
4. fold final extracted output in half for conservative operation

@_date: 2013-12-17 14:31:04
@_author: coderman 
@_subject: [tor-talk] What about GnuPG's --hidden-recipient option as 
you're probably not able to make use of this option effectively.
but if you could, i would use:
  --throw-keyids

@_date: 2013-12-18 09:23:43
@_author: coderman 
@_subject: [tor-talk] Help testing patch on SandyBridge/IvyBridge? Force 
thanks Nick!  i have been poking at a "badengine" version of the
rdrand module since you asked for a trace two days ago.
(also to be able to confirm/deny the environment variable CPU flag
tricks works as other option)
i also appreciate the explanation of where first call for entropy is
encountered in circuit builds, which is another scenario i didn't
i don't know when OpenSSL expects to deliver an update; this is really
the best fix.
this code could also use some cleanup for newer versions, which i'll
keep as a separate patch. (e.g. ENGINE_register_all_complete() is
called by ENGINE_load_builtin_engines() in later revisions, and no
longer needed in Tor's engine setup)
thanks again, and lesson learned :)
best regards,

@_date: 2013-02-03 12:03:33
@_author: coderman 
@_subject: [tor-talk] TOR Fone - p2p secure and anonymous VoIP tool 
Jacob is not great at C++, apparently.
(there is nothing wrong with C++ used properly and done well... except
the lack of an ABI; you win some you lose some ;)
on a more on-topic note i do not expect to see usable VoIP over Tor
until datagram transport(s) are implemented.  i'd love to be proved

@_date: 2013-02-03 12:23:13
@_author: coderman 
@_subject: [tor-talk] TOR Fone - p2p secure and anonymous VoIP tool 
"push-to-talk" with procedure words over zrtp would be applicable. use
FEC to accommodate reasonable loss over datagram Tor.
both Whisper Systems and Guardian Project are working on PTT
capabilities, iirc.
last but not least, the codec makes no difference until larger issues
are worked out, for those arguing about OPUS vs. G729a/729.1 vs Speex,
etc. in practice the G729 implementations in cSipSimple (over ZRTP)
seem to be best, but this is most likely the other implementations
sucking. i have high hopes for a better OPUS codec...
best regards,

@_date: 2013-02-03 15:07:22
@_author: coderman 
@_subject: [tor-talk] TOR Fone - p2p secure and anonymous VoIP tool 
On Sun, Feb 3, 2013 at 12:46 PM, Fabio Pietrosanti (naif)
presence and connection signaling is a problem too; also requiring
customization / enhancements to the signalling and transport layers
around these mechanisms, in addition to the voice transport and
implementations details you mention above (which also apply to
multi-media, were you to extend the ZRTP / Tor'ified streams to video
and extended media).
large static jitter buffers also need more help, as a Tor circuit has
a much larger total delay in addition to jitter variance. smarter
dynamic jitter buffers, noise cancelation / silence optimization /
other expensive processing options are useful and applicable, as
anything running a Tor client has plenty of processing power for voice
of any complexity.
regarding the directory and signalling, i would love to test:
- petname or distributed directory (namecoin) for people to hidden
server address(es)
- custom Tor controller to establish and advertise multiple hidden
service endpoints concurrently via different rendz.
- custom SIP/signalling extensions to advertise and register via
ordered hidden svz addresses (maybe just transparent DNS with multiple
peers in RRs?)
- long-lived-ports modified for circuit availability, consistency over
absolute duration?
with the transport and voice processing improvements discussed above.
PTT is orthogonal to the transport question, perhaps limited to some
context like group / conference / broadcast idioms. i agree it may not
be necessary.
best regards,

@_date: 2013-02-24 14:07:42
@_author: coderman 
@_subject: [tor-talk] [qubes-devel] please look at Comparison of Whonix, 
Qubes is built with security in mind and a clear intent to minimize
attacks surface. this is akin to the proactive defense grsecurity and
a hardened distro provides against a generic distribution.
compare the opposite approach of VMWare or VirtualBox which focus on
features and low level accelerations (kernel driver for network,
graphics, USB, acceleration, other extensions) without thought to the
added risk these less then hardened components expose the host
operating systems and other guests to.
for example, but not limited to, networking passive and active attacks
on physical and virtual endpoints, local and host privilege
escalations, driver level privilege escalations, and many other
serious vulnerabilities Qubes prevents outright by design and explicit
all of these protections require zeroization to be performed before
physical access; an interesting HCI design detail itself...
  (at DEF CON there are the usual hack the software attack challenges,
and non computing seal and lock based physical attack challenges, but
i have not yet seen a hack the running system cold boot attack
challenge - perhaps because a real attack would likely be destructive
to some or most of the hardware to be tested.  i'd still be game for
mobile and workstation challenges if anyone else is interested :)

@_date: 2013-01-17 08:19:14
@_author: coderman 
@_subject: [tor-talk] Leave Your Cellphone at Home 
baseband exploits can tamper with airplane/flight mode. it is designed
to prevent transmission, however, the radio can still receive.
get a faraday bag/case instead...

@_date: 2013-07-01 22:10:38
@_author: coderman 
@_subject: [tor-talk] Secure email with limited usable metadata 
my contempt for email should be evident by provider; ...  ;)
  [OTR, ZRTP, others preferable many years now]
yet in all seriousness the complexities are many and some difficult
problems (hidden svc to public network delivery with any confidence,
end-user key management that is usable _and_ secure by default,
sufficiently inter-operable without undue vulnerability or exposure,
protocol aware mail message identifying information scrubbing modes,
proper SSL/TLS cipher suites with PFS and wide client side support,
ssl/tls session expiry and zeroisation, many others) have frustrating
trade offs for all parties.
regarding a well thought out specification: something written in
chef[0] or saltstack[1] which i could launch and test myself would be
excellent. suggestions accepted in form of git diffs and pull
alas, my order of copious free time is in the mail and it may be
difficult to find someone excited to tackle this;
 i wager Jake would prefer numerous other agonies instead!
0. 1.

@_date: 2013-07-01 22:18:06
@_author: coderman 
@_subject: [tor-talk] Secure email with limited usable metadata 
you should assume this number will always approach anything greater
than zero; and how do you handle a reduction? axe clients without
better option: end-to-end only, usable privacy that is secure by
default - the only mode is secure.  then you can publish "lawful
intercepts" of ciphertext without risk to any users.**
if you're forced to cooperate with active malware explotation of
customers through assisted MitM via your services it is time to pull
the plug and announce while you find a sane jurisdiction. the active
exploitation and run time key recovery route is plan B for some
entities which have lawful intercept charters...
** this is a "Hard Problem" (TM). *grin*

@_date: 2013-07-02 08:26:14
@_author: coderman 
@_subject: [tor-talk] Secure email with limited usable metadata 
you say this like there's an inexhaustible supply of dedicated
individuals / volunteers able to administer a business entity /
incorporation each with enough autonomy and self sufficiency to avoid
conspiracy charges ... ;)
i am skeptical this can scale in any meaningful sense; still better
than nothing?
the joy of email is that you defer hard problems like unlinkability,
psuedonymity, anonymity to lower layers where possible.  i agree that
"pen register" and other metadata is just as critical to privacy as
content - perhaps more so given the lack of constraints around access
to "pen register" metadata.
did i mention this is a hard problem?
"Due to circumstances outside our control we are no longer able to
provide customers with quality service. Effective immediately.

@_date: 2013-07-05 14:24:45
@_author: coderman 
@_subject: [tor-talk] TorWall - experimental transparent Tor proxy for 
can you explain more about the following signer of the pre-built driver?
who maintains updates to the built driver when security or other
source updates are available?
NEW: As of version 1.0.4 the WinDivert.sys driver distributed in the
above binary packages is signed by Nemea Mjukvaruutveckling (Nemea
Software Development). Software projects can now use this driver
without the need to acquire a valid kernel-mode code-signing
certificate. We thank Nemea for their support.
NOTE: In order to user WinDivert, please ensure that:
You sign (or test-sign) the WinDivert.sys driver. Note that this step
is no longer required for the WinDivert.sys driver distributed in the
above binary packages. Commercial WinDivert users may still wish to
sign the driver with their own company's certificate.
You use the 32-bit WinDivert.sys for 32-bit Windows, and the 64-bit
WinDivert.sys for 64-bit windows.
You are running with Administrator privileges.
best regards,

@_date: 2013-07-06 00:30:08
@_author: coderman 
@_subject: [tor-talk] TorWall - experimental transparent Tor proxy for 
ok. thanks :)
this look pretty decent; i am curious if you've considered two areas
(perhaps in docs i've not yet read),
 a) system or non-user context activity. e.g. program accessing remote
WebDAV over HTTPS as file sytem while system user and context provides
the WebDAV communication and mounts. is there a way to associate
requesting process or user, or must all system communication be
treated opaquely / en masse?
 b) kernel resource consumption impact, if any. does a lot of traffic
through the diversion consume significantly more non paged pool, or is
the overhead negligible under load?
yes, sys drivers and WDK dev are fun...
there are other ways to load, but not recommended! *grin*

@_date: 2013-07-10 19:00:56
@_author: coderman 
@_subject: [tor-talk] Network diversity [was: Should I warn against Tor?] 
you're likely thinking of Sean Gorman's dissertation:
"Networks, complexity, and security: the role of public policy in
critical infrastructure protection"
 path diversity at the physical layer would be useful to consider, and
you could do this without the fine grained location and capacity
details that makes the above critical infrastructure vulnerabilities
less a concern.
detailed and specific plats/maps akin to what Sean aggregated and
analyzed get you unwelcome scrutiny ;)
c.f. cable landing sites in US:
  see also:
            and telegeography's submarine cable map:

@_date: 2013-07-10 19:17:50
@_author: coderman 
@_subject: [tor-talk] Network diversity [was: Should I warn against Tor?] 
regarding questions about:
the lower images are the facilities at the landing site, the upper
images the termination / peering point a few score miles down fiber.
the secondary power and cooling infrastructure for the new facilities
indicate the scope of additional equipment applied at a landing site
previously served by much more modest footprint.

@_date: 2013-06-21 11:52:33
@_author: coderman 
@_subject: [tor-talk] Research paper "The Parrot is Dead: Observing 
i'm interested in Blanu's "dust", which will be presented at DEF CON:
"Defeating Internet Censorship with Dust, the Polymorphic Protocol Engine"
is there any technical information about dust ahead of presentation?

@_date: 2013-06-21 13:43:44
@_author: coderman 
@_subject: [tor-talk] Research paper "The Parrot is Dead: Observing 
Thanks Moritz!
The paper
has a link to what I was looking for:

@_date: 2013-11-18 04:42:09
@_author: coderman 
@_subject: [tor-talk] A great way for you to help Tor: track down recent 
six months of news[0] added to
let's see if your conjecture regarding getting the list onto the web
page is correct ;)
best regards,
0. "Tor Articles: June to November 2013"
note that this is an abridged, biased, selective subset of news, blog,
and web content matching Tor filters. it would be useful to have
additional parties review the whole set for inclusion of overlooked or
oppressed reports.  i'll post link to the full archive on the trac
ticket once available.

@_date: 2013-11-21 11:15:11
@_author: coderman 
@_subject: [tor-talk] The New Threat: Targeted Internet Traffic 
active attacks, of various types, are also clearly possible.  the
impact of these varied, but possibly significant.
i recommend all relay ops sign up for cyclops alerts for suspicious
BGP behavior on their netblocks:
it's a bit noisy, but useful.
best regards,

@_date: 2013-10-03 05:59:11
@_author: coderman 
@_subject: [tor-talk] suppression of Guardian story on Tor in Snowden 
" Stop suppressing the story on Tor."
 "  The Guardian is sitting on a story about Tor -
I'll do one better:  refused to show us the story/docs."
this begs two questions:
1. is this story pending polish and expected to be published at some point
in the near future? [alan rusbridger says Tor story not suppressed?]
2. if this story truly is suppressed / killed, is it because of undue, over
broad US/UK government pressure, or is it because the story included
detailed technical aspects of how Tor is monitored[0] in the context of
international counter-terrorism and other "data sharing"?
who else or what organizations might be able to compel some guidance in the
case of reality of 0. by technical details of Tor analysis, this may cover capabilities such
as, traffic confirmation via active interruption of client networks, or
protocol attacks leveraging  relays under their control for circuit
manipulation, or even widespread circuit linking via prevalent points of
privileged access to backbone links and internet facilities monitored by
the intelligence community.

@_date: 2013-10-04 09:35:39
@_author: coderman 
@_subject: [tor-talk] suppression of Guardian story on Tor in Snowden 
not quite how it turned out; see
  "Tor Stinks" means you're doing it right;
 good job Tor devs :)
two interesting parts:
 - GCHQ runs Tor nodes under NEWTONS CRADLE. do they run fast exits
too? (some or all of this capacity in Amazon AWS?)
 - an entire category of "feeling lucky" collection where "Dumb Users
(EPICFAIL)" cross the streams...
best regards,

@_date: 2013-10-04 09:50:14
@_author: coderman 
@_subject: [tor-talk] Guardian Tor article - better endpoint and 
"p7 Tor Project and friends Recent Activity"
""" Tails: ... Adds Severe CNE misery to the equation ...
  """
good news everybody; defense is depth is effective and practical!
this has been a subject of discussion on the Qubes devel list as well,
in the content of Whonix, Tails and other Tor packagings.
     qubes devel threads of interest:
"Qubes + Whonix"
  "QuebesOS - Secure Against Spying?"
  "Disposable VM versus local forensics?"
  best regards,

@_date: 2013-10-04 16:33:09
@_author: coderman 
@_subject: [tor-talk] Deterministic Builds Part Two: Technical Details 
Mike Perry has just posted the second half of his reproducible builds effort:
"Deterministic Builds Part Two: Technical Details - This is the second
post in a two-part series on the build security improvements in the
Tor Browser Bundle 3.0 release cycle."

@_date: 2013-10-05 15:09:23
@_author: coderman 
@_subject: [tor-talk] [tor-relays] NSA v TOR Guardian article 
this is only for destinations, E.g. using a copied, stolen, or
impersonated Google certificate when clients are accesing Google sites
over HTTPS.
and by copied i mean certificate handed over per court order,
and by stolen i mean BULLRUN pilfered certs,
and by impersonated i mean a validating cert that was fraudulently
issued. (Comodo, DigiNotar, etc.)

@_date: 2013-10-08 19:10:29
@_author: coderman 
@_subject: [tor-talk] McAfee 
McAfee is doing lots of drugs.  all other details yet to be confirmed...
  [keep it weird! like my favorite machines...]

@_date: 2013-10-08 19:46:43
@_author: coderman 
@_subject: [tor-talk] McAfee 
less flippantly,
if you want D-Central today, check out  (why do they not have HTTPS?)

@_date: 2013-10-25 15:16:41
@_author: coderman 
@_subject: [tor-talk] tor available for the iphone 5? 
also  which required jailbreak / Cydia and provide a Tor toggle via
Wireless Network Proxy profile and settings toggle on/off.
i was able to install 0.2.3.25-6 via Cydia as of today.
i much prefer this approach to the per-app thread-hack sub-tor method
used by Onion Browser, however, it does require jailbreak.
(you're jailbreaking your iOS devices for privacy purposes already, right? ;)
best regards,

@_date: 2013-10-25 15:28:06
@_author: coderman 
@_subject: [tor-talk] tor available for the iphone 5? 
if anyone has tried the Apple Configurator system to enforce a global
proxy setting i'd love to hear about it.  this would be a further
improvement on the configuration discussed above, and apply to all
networks not just the WiFi profiles with a proxy setting associated.
best regards,

@_date: 2013-09-23 13:14:17
@_author: coderman 
@_subject: [tor-talk] Tor companies 
in addition "The Tor Project, Inc." there appears to be related:
"Tor Solutions Corporation" - Tor Solutions Corporation in Walpole, MA
is a private company categorized under Website Design Services. Our
records show it was established in and incorporated in Massachusetts.
"Tor Solutions Group" - unknown.
what are these entities used for?
see also:

@_date: 2013-09-23 15:19:21
@_author: coderman 
@_subject: [tor-talk] Tor companies 
if someone was impersonating "Tor Project" to solicit funds and enjoy
revenue that would be of concern.
thanks for the prompt responses!
best regards,

@_date: 2014-04-05 21:30:25
@_author: coderman 
@_subject: [tor-talk] How safe is smartphones today? 
as long as you assume the 3G link is as trustworthy as your
neighborhood open wifi, you're fine.
i can tell you that i've had malware sent down a 3G pipe to a tethered
target just as you might except on any other hostile network.
incidentally, this tethered mode is how i prefer to communicate:
1. a front-end sacrificial/signalling device to indicate a threat
level and carry traffic. (hotspot puck, 3G phone, CPE router, etc.)
2. a packet inspecting host to passively monitor for anomalies and
respond to emergencies. (emergency zeroisation+filtering)
3. the actual communicating device containing keys and terminating
sessions. further hardened by defense in depth.
for any decent attacker, mobile platforms are just fucked.  sorry!
this is true until you can implement an entire isolated SDR stack;
even opaque wifi blobs are fail.
 [i've stated my preference for various software defined radio setups
before, omitted.]
it's fine to route traffic over such a device as long as you assume
the attacker is also watching and able to inject into your traffic
over said gateway :)
this means you run Tor on a different device, not the phone itself.
last but not least, regarding the "Mission Impossible: Hardening
Android for Security and Privacy"
 i have found the following techniques useful in the past against
advanced attackers:
0.) rootkit Android kernel to trap and notify|block syscall use by
user-id and process-id.  anomalous calls by a privileged processes or
users is a great signal of compromise.
1.) monkey patch Android API in every dalvik runtime for specific
calls of interests that should not be granted. this caught the
"Android Master key" vuln in practice as an updated app was behaving
way out of permission and expected profile.
2.) deploy camouflage guacamole to feign vulnerability to various
techniques and then use exploit attempts to signal presence of an
adversary of identified capabilities.
doing the above on a reference Nexus 7 platform left as exercise for
the reader, *grin*
best regards,

@_date: 2014-04-05 23:33:54
@_author: coderman 
@_subject: [tor-talk] Linux kernel transproxy packet leak (w/ repro case + 
this is where defense in depth at the multiple-virtual machine /
routing layer fails safe in ways that a single / monolithic Tor setup
cannot, when applied with care.
what i mean by "applied with care" is that forwarding through Tor only
is the default.  Anything unexpected / unsupported gets the bit
bucket.  the best target is actually TARPIT, not DROP, but that's
another discussion...
[this advice to default drop and isolate at routing level applies to
Tails, Whonix, Qubes TorVM, and whoever else allows a transparent
proxy model, IMHO]
best regards,

@_date: 2014-04-06 21:01:54
@_author: coderman 
@_subject: [tor-talk] How safe is smartphones today? 
i have intended to go over the ath9k-htc sources, thanks for bringing this up!
of all the wifi chipsets, i do like the atheros lines the best...
especially with virtual station/ap/device support!

@_date: 2014-04-18 20:25:49
@_author: coderman 
@_subject: [tor-talk] [liberationtech] Programming language for anonymity 
is this an implementation of existing research, or experimentation
with novel architectures?  tell us more :)
use modern C++ with testing discipline.
 , but what about this traffic analysis resistant anonymity network,
low latency too?
  *grin*
best regards,

@_date: 2014-04-18 20:29:34
@_author: coderman 
@_subject: [tor-talk] Programming language for anonymity network 
old C: int*
modern C++: std::vector move constructor
[ everything old is new again? ...]

@_date: 2014-04-20 21:36:12
@_author: coderman 
@_subject: [tor-talk] [liberationtech] Programming language for anonymity 
also relevant:
   which gets kudos for also mentioning the benefits of modern C++ in
respect to unit tests.
to summarize the goals for your C++ implementation:
 - reads with clarity like a high level language
 - performs with efficiency like a low level language
 - tests with coverage across whole codebase regardless of language.
full disclosure: i am a completely not biased party in this
declaration of absolute truth.
 *cough*
best regards,

@_date: 2014-08-03 14:11:56
@_author: coderman 
@_subject: [tor-talk] carml: tasty treats from your Tor 
thank you meejah! this is awesome useful :)
best regards,

@_date: 2014-12-06 16:32:51
@_author: coderman 
@_subject: [tor-talk] compare and contrast 
"This fictional example is constructed to convey some similarities to
parts of reporting in the public knowledge base."
"Fictional Input Document"
With a link to an actual example,
   where the source document, "'Peeling back the layers with Egotistical
Giraffe" is referenced.
hope that clears things up.  best regards,

@_date: 2014-12-06 16:39:47
@_author: coderman 
@_subject: [tor-talk] NSA and other codewords 
other useful resources for _non-fictional_ codenames / projects,
a good write up putting these pieces in context,
  best regards,

@_date: 2014-12-07 02:27:44
@_author: coderman 
@_subject: [tor-talk] NSA TAO Exploit of Whonix Qubes - EGOTISTICALSHALLOT 
thanks for pointing out the thread. there are more questions there, as
you ask below.
Patrick worked it out; i am indeed the same.
(apologies for the typo; this document was in flux hours before the
deadline to submit. Qubes should have been Qubes OS as well.)
i am the author, and as stated, there are two examples of information
in the document. one about programs/projects that _do_ exist, meaning
the information is fully supported multiple times in the "public
knowledge base".
and this alternate example which is similar, but fictional, and thus
results in only partial support in the public knowledge base.
this "public knowledge base" and BigSun system is a much longer
discussion. i originally started on this work back in spring for a
different purpose; see cypherpunks "datamine the Snowden files"
discussion. the application to redaction and evaluating claims of
sensitivity evolved later, and specifically to assist Diane with her
Whonix on Qubes OS represents defense in depth unlike any other
system. as such, it is a likely target, like Tails and the Tor Browser
before it.
being a likely target, it made a good candidate for description of a
fictitious exploit for the purposes of this partial support example.
a better example would be to compare a classified document with a
unique attack, and never leaked, against the public knowledge base.
this would demonstrate only partial support because it contains
information that has not been made public.  for obvious reasons, the
alternative of constructing a fictitious example to demonstrate
partial support was used.
some other comments from that thread:
"The mentioned creation date of 2014 also looks accurate as far as
matching when your Whonix group started working with the Qubes group
to co-develop your software together."
the specific date was chosen because of the affidavit being this year.
if Whonix Qubes OS had started in 2013, i would still have used 2014
in the example.
"Maybe this Martin Peck, software engineer, is just a fan or user of
Whonix and Qubes and was being creative by dreaming up this
EGOTISTICALSHALLOT exploit?"
i am a fan of many things, but as described above, this example was
chosen for being a good candidate to demonstrate partial support in
the public knowledge base.
best regards,

@_date: 2014-12-07 03:38:56
@_author: coderman 
@_subject: [tor-talk] NSA TAO Exploit of Whonix Qubes - EGOTISTICALSHALLOT 
exploits are developed at all levels of the system. from attacking
applications, to subverting operating system updates and package
management, down to compromising random number generator instructions.
some of these techniques are more complicated than others. some may
involve active triggers vs. always affecting all users. some may
require a window of opportunity, while others can be launched at any
time. and so on...
would compromising Debian upstream be easier?  probably, but it would
also be more visible.
this is two concerns:
1) if built packages can be verified independently. (reproducible builds)
2) if packages are distributed to users securely. (signatures on pkgs, etc.)
you need to cover both, of course. but they only address part of the
problem.  a vulnerable application that is reproducibly built, and
properly signed, and verified before installation, is still
how do you securely distribute sources to be built?  a source based
distribution has different trade-offs, rather than being immune to
you can of course build any of these from source. (all of them open source).
some vulnerabilities are specific to a single build or architecture,
some are specific to configuration, some are specific to opportune
timing or position, and so on.
which route is chosen, backdoor or exploit, varies by situation, and
of course, the visibility of either varies quite a bit too.
if there's one thing we've learned the last few years, it is that all
avenues are pursued. backdoors and exploits both, and at all levels,
from operating system to end user applications.
best regards,

@_date: 2014-12-07 04:53:20
@_author: coderman 
@_subject: [tor-talk] Qubes? debian? binary? reproducible? (was: 
if the source is available, how likely is it to be reviewed?
(to play devil's advocate, if heartbleed was found via protocol
fuzzing, then a rogue binary just as likely to be identified - the key
variable is "scrutiny", whether as source code review or protocol
testing of built application)
finding backdoors or vulnerabilities a problem for every
implementation, open source or not.  source based or not. reproducible
builds or not.
it's hard to not get depressed at the current state of technology and
software. we must do everything better!
"Not really" - do you mean they are not separate? or that everyone
should do  correctly, and get  for free?
(i agree that  is better)
this comes up in many circles, "why fix Y when we can't even do X well?"
as stated again, we should be doing everything better. but if you fix
the easy vulns, the hard ones all of the sudden become focus.
as an example, it used to be you could ignore active
monkey-in-the-middle threats in most situations, because they were
difficult and rare.  with the advent of wireless networks,
sophisticated tools, and easy access MitM became not-uncommon.
why talk about it?  so we can fix what is broken. (easily broken, or not)
(assuming we haven't drowned in sorrowed muted by string drunk first ;)
i was speaking more to signatures and key distribution that validating
digests. where did you get the list of hashes? who was it signed by?
would you know if private keys were stolen and your list was a
forgery? etc.
i like gentoo, yet i see why others have a preference for pre-built as well.
the most usable source based distribution still needs to be built, and
that is both time consuming and resource intensive, comparatively.
again, different set of trade-offs. (we should do everything better!)
you emerge from a stage1 boostrap as well, don't you?  per Ken
Thompson, and "On trusting trust", this rabbit hole goes quite deep.
as for treating any distribution as "being secure" who is saying that?
certainly not me.
they are all vulnerable, to varying degrees.  we need to do everything better!
question everything!  (the sources, the default configurations, the
distribution, ...)
because, as i like to say in this thread, we need to do everything better.
best regards,
P.S. this topic is getting pretty off-topic. perhaps general
discussion on software insecurity could continue in depth elsewhere if
you wish.

@_date: 2014-12-07 10:15:31
@_author: coderman 
@_subject: [tor-talk] Qubes? debian? binary? reproducible? (was: 
see openwrt, for one common example.
we claim  is solved, yet evilgrade has hundreds of vectors.  again,
we should be doing both.
i am not rejecting prioritization,  nor trying to defocus with a big
basket. what i am saying is that risk is a very context dependent,
multi-faceted thing.
looking at one aspect, reproducible builds or package management, is a
narrow misleading perspective.  as mentioned before, a vulnerable
application built reproducibly and distributed securely is still
which is the bigger risk? binary packages or vulnerable applications?
it depends!
(and we should do better on both fronts :)
not "fixed", but made more difficult. how well do all signers manage
their keys? would they know if a signing key was stolen? how would you
part of the benefit of reproducible builds is a consensus of digests
from multiple parties. this is different assurance than a signed
source package, which you build yourself.
and again, which reduces risk the most is very context dependent.
(and we should do both :)
you understand that the Debian openssl flaw was a patch against
upstream, rather than a rogue binary, right?
who reads gentoo patch sets?
again, risk is complicated. and we should fix both problems.
(complicated distribution patches, as well as dependence on binary
packages without independent validation (reproducible builds, etc))
i agree with you 100% here!
(and i also hated my use flag magic, and overrides, and wondering what
in portage shifted under my feet such that builds which used to work,
no longer after updating some other component, etc.)
i like Guix; binary pre-builts for the impatient. source based
rebuilds for the conservative.
it's not that simple, though many threats do take path of least
resistance. some times stealth is more important than easy. other
times zero-persistence (memory resident only) methods are desirable,
despite being more complicated.
as i've said before, risk is a complicated thing, and which threat
matters most to you is context dependent.  in industry jargon, "what's
you threat model?"
we need to solve for many.
i disagree that building from scratch is safe. it may be less risky
than binary packages in some situations, but that is the most you can
claim in broad strokes.
priority  fix what is broken.
(unfortunately, it seems almost everything is broken :)
what you don't mention here is IOMMU isolation between domains in a
Qubes OS system. your Gentoo hardened, running one vulnerable app,
leading to one vulnerable device, is a class break, as you could call
it. full compromise.
a vulnerable throw-away App VM doesn't get to compromise devices in
other domains, nor persist across instances.
finally, this is an example - created for sake of demonstration. why
does TAO do what they do? they have offensive addition is my best
[ see could i have used a Gentoo hardened Tor user for the example? sure. my
apologies if my choice in this matter has annoyed you!
Qubes OS is based on Centos, while Whonix is based on Debian. Whonix +
Qubes OS a chimera, and perhaps one day you'll have a usable Gentoo
Hardened App VM template for various other paranoid purposes, too.
best regards,

@_date: 2014-12-07 10:30:38
@_author: coderman 
@_subject: [tor-talk] Qubes? debian? binary? reproducible? (was: 
that should read: Qubes OS is based on Fedora.  ETOOTIRED.
sorry Carlo, i will have to continue this thread tomorrow if you feel
inclined.  brain at empty...

@_date: 2014-07-03 04:35:09
@_author: coderman 
@_subject: [tor-talk] XKeyscore-Quellcode: more english details requested 
request for more (english speaking) details on QUELLCODE part of XKeyScore(XKS)
specifically subsequent tasking associated with selected anonyms...

@_date: 2014-07-03 08:36:33
@_author: coderman 
@_subject: [tor-talk] Fwd: according to leaked XKeyScore source NSA marks 
i presume you mean as below:
  (more a translation than additional QUELLCODE info though ;)
Donate for the Cryptome archive of files from June 1996 to the present
3 July 2014
NSA Hacks TOR in Germany, Calls Users Extremists
Original German: German named an extremist targeted by U.S. intelligence from the NSA
Published: 07.03.2014 05:00 clock
The NSA peeks specifically from German that deal with encryption on
the Internet. This emerges from a secret source, the NDR and WDR
exists. NSA victim can thus be identified by name. One of them is a
student from Erlangen.
By Lena Kampf, Jacob Appelbaum and John Goetz, NDR
[Images omitted.]
It is one of the most sensitive secrets of the NSA, the engine of the
global monitoring machine: the source code of the XKeyscore program,
the most comprehensive Aussp?hprogramm of U.S. foreign intelligence.
NDR and WDR have excerpts of the source code. Parts of the collection
infrastructure ie, so-called software rules that define the
intelligence, what or who they want to investigate.
There are only a few numbers and characters to string together the
programmer. But when the program executes XKeyscore these rules, get
people and their data in their sights. The connections from computers
to the Internet are identified and stored in a database type. The
users are quasi marked. It is the dragnet of the 21st century.
Download the video file
Users of the Tor network aim of penetration
In the present source is about the spying infrastructure and the users
of the Tor network. Tor stands for "the onion router" - a program in
which Internet traffic, such as a query to a search engine, is passed
through various servers and lie encryption layers like an onion to
make the request. Thus, the origin of the request, so obscures the IP
address. The IP address is like a mailing address and reveals among
other things, the location of the computer.
There are about 5,000 Tor servers worldwide which are operated by
volunteers. It is an anonymizing infrastructure, which is often used,
especially in countries where it is dangerous to abandon the regime,
which websites you visited or where they retrieve. In Iran and Syria,
for example. Tor is used by journalists, human rights activists and
lawyers worldwide.
Popular German IP addresses in Fort Meade
The reporting of the "Guardian" on PowerPoint presentations from the
Snowden archive has shown in the past year that the Tor network the
NSA is a particular thorn in the side. The top-secret documents and
the first time published the source code show that the NSA is making
significant efforts to deanonymisieren users of the Tor network.
Search of the NDR and WDR show: German IP addresses are defined in the
source code of the NSA as a unique destination.
The IP 212 212 245 170 leads to a gray, factory-like building, whose
high walls are fenced with barbed wire. "On the Tower" is the street
in an industrial area near N?rnberg. There is a computer center with
Mietservern in long shelves. They all look the same. But one is spied
on by the NSA. Sebastian Hahn, a student and employee of the computer
science department in Erlangen has rented this server.
The program goal: TOR a thorn in the NSA.
Momentous commitment to the Internet community
In his spare time he is involved in the Tor network, as well as one of
the authors of this paper. The gate community trusts Sebastian Hahn
especially: He may run one of nine so-called "Directory Authorities".
On his server is a list, in which all Tor servers are listed. Users
who connect to the Tor network, automatically access to one of the
nine "Directory Authorities" to download the latest list. Hundreds of
thousands of hits a day there are at Sebastian Hahn.
All of these accesses are marked by the NSA and land according to
research by the NDR and WDR then in a special NSA database. In the
source code appeared even the name of the server on tap: "Gabelmoo"
had called him cock predecessor, Frankish for "fork man," as the
Bamberger call a Poseidon statue lovingly.
"This is shocking," says Hahn. Because: "The connection data of
millions of people are listed every day." Sebastian Hahn found next to
"Gabelmoo" all other names of "Directory Authorities" in Berlin, the
Netherlands, Austria, Sweden and the USA. They are also target of the
Second notably known NSA victims
Although he is only a means to an end for the NSA - finally, the
intelligence want to filter on its server who uses the Tor network -
Hahn feels violated his privacy. Because he wanted to do something
good, he random "in the focus of the intelligence agencies," he says,
visibly shocked. He is now probably after German Chancellor Angela
Merkel, the second known by name German surveillance victims of
American intelligence.
The lawyer specializing in IT law, Thomas Stadler, sees a "suspicion
of intelligence agents work". The Attorney General expressed only in
general terms: you examine all instructions. On request, the NSA
shares only generally, we consider strictly to the law: "privacy and
civil liberties always be considered in the computer monitor."
What you want to anonymize is deanonymized
Ironically, it is in accordance with the special rules that NDR and
WDR present, so just people with the desire for anonymity that are the
target of the NSA. In the eyes of the Secret Service: extremists. This
is not rhetoric, no journalistic escalation. The term is even in the
Comment column of the source text, quoted by programmers of the NSA.
Extremists? The opposite is the case, as the search point. The German
victims are politically to find not at the outer edge. Extreme they
are alone on one point: They are concerned about the security of their
data. And that's what makes them suspect in the eyes of the U.S.
Secret Service.
How quickly do you become a "Extremist"
"Tails" is an operating system that uses the Tor network to post on
the Internet any traces, but nothing saves the user on the computer
from which it is, for example, on a USB stick, booted.
Darko Medic, 18, short brown hair, sitting in front of his laptop. He
is "Tails" and "USB" in the mask its search engine. What Darko not
know: He's just so also landed in a database of the NSA. Marked as one
of the extremists, they seek the secret service so diligently.
Limitless espionage
How the NSA spying friends and enemies and the consequences of that.
Because what the rules of the source code also revealed: The NSA
observed on a large scale search queries worldwide - also in Germany.
Just the simple search for encryption software, such as "Tails" is
enough to get into the grid of the NSA. The connection of the request
with search engines makes suspicious. His search for "Tails" opens a
door, access to Darko and his world. Once in the database, any inquiry
from Darko can be accessed selectively. Darko is under observation.
This Darko has traveled in the computer-AG so he learns how to protect
themselves from the spying by the NSA. "I do not think anyone is
reading my e-mails," he says.
His seatmate has opened the website of the Tor project. His connection
to the site is now marked and stored in a database. For the entire Web
page of the Tor project is under observation. Everyone who visits
them, like the Neuk?lln students ends with a marker.
The NSA peeks specifically from people who deal with encryption on the Internet.
It's not just about metadata
In addition, it can be shown beyond reasonable doubt through the
source code for the first time, that the NSA is not only so-called
metadata, ie connection data reads. According programming command,
e-mails used to connect to the Tor network, then the contents of the
so-called e-mail body, analyzed and stored. The relevant quote from
the source code reads: "email_body ('
c + + extractors"
William Binney, 70, was technical director of the NSA until he left in
2001 because the machines he invented, were directed against its own
people. Today he is testifying before the NSA Untersuchungssauschuss.
In an interview with NDR and WDR, he explains why the secret service
have calculated it apart to users of the Tor network: "There shall be
no free, anonymous rooms give," he says. "They want to know everything
about everyone."
Only a few are excluded: Registered in the source code, the NDR and
WDR exists, is the differentiation between the partner countries of
the United States, the so-called "Five Eyes", in New Zealand,
Australia, Britain and Canada, and other countries. Compounds that are
made from the "Five Eyes" countries on the Tor website, according to
the present rule should not be marked. From all other countries,
however, already. Without exception.
More on the topic tonight at Panorama, 21.45 clock in the First

@_date: 2014-07-03 09:06:19
@_author: coderman 
@_subject: [tor-talk] Fwd: according to leaked XKeyScore source NSA marks 
detailed technical info via J. Appelbaum, A. Gibson, J. Goetz, V.
Kabisch, L. Kampf, L. Ryge
The investigation discloses the following:
Two servers in Germany - in Berlin and Nuremberg - are under
surveillance by the NSA.
Merely searching the web for the privacy-enhancing software tools
outlined in the XKeyscore rules causes the NSA to mark and track the
IP address of the person doing the search. Not only are German privacy
software users tracked, but the source code shows that privacy
software users worldwide are tracked by the NSA.
Among the NSA's targets is the Tor network funded primarily by the US
government to aid democracy advocates in authoritarian states.
 The XKeyscore rules reveal that the NSA tracks all connections to a
server that hosts part of an anonymous email service at the MIT
Computer Science and Artificial Intelligence Laboratory (CSAIL) in
Cambridge, Massachusetts. It also records details about visits to a
popular internet journal for Linux operating system users called "the
Linux Journal - the Original Magazine of the Linux Community", and
calls it an "extremist forum".
Three authors of this investigation have personal and professional
ties to the Tor Project, an American company mentioned within the
following investigation. Jacob Appelbaum is a paid employee of the Tor
Project, Aaron Gibson is a paid contractor for the Tor Project, and
Leif Ryge is a volunteer contributor to various Tor-related software
projects. Their research in this story is wholly independent from the
Tor Project and does not reflect the views of the Tor Project in any
way. During the course of the investigation, it was further discovered
that an additional computer system run by Jacob Appelbaum for his
volunteer work with helping to run part of the Tor network was
targeted by the NSA. Moreover, all members of this team are Tor users
and appear to be have been targets of the mass surveillance described
in the investigation.
It is a small server that looks like any of the other dozens in the
same row. It is in a large room devoted to computers and computer
storage, just like every other room in this industrial park building
on Am Tower Street just outside the city of Nuremberg. That the grey
building is surrounded by barbed wire seems to indicate that the
servers' provider is working hard to secure their customers' data.
Yet despite these efforts, one of the servers is targeted by the NSA.
The IP address 212.212.245.170 is explicitly specified in the rules of
the powerful and invasive spy software program XKeyscore. The code is
published here exclusively for the first time.
After a year of NSA revelations based on documents that focus on
program names and high-level Powerpoint presentations, NDR and WDR are
revealing NSA source code that shows how these programs function and
how they are implemented in Germany and around the world.
Months of investigation by the German public television broadcasters
NDR and WDR, drawing on exclusive access to top secret NSA source
code, interviews with former NSA employees, and the review of secret
documents of the German government reveal that not only is the server
in Nuremberg under observation by the NSA, but so is virtually anyone
who has taken an interest in several well-known privacy software
The NSA program XKeyscore is a collection and analysis tool and "a
computer network exploitation system", as described in an NSA
presentation. It is one of the agency?s most ambitious programs
devoted to gathering "nearly everything a user does on the internet."
The source code contains several rules that enable agents using
XKeyscore to surveil privacy-conscious internet users around the
world. The rules published here are specifically directed at the
infrastructure and the users of the Tor Network, the Tails operating
system, and other privacy-related software.
Tor, also known as The Onion Router, is a network of several thousand
volunteer-operated servers, or nodes, that work in concert to conceal
Tor users' IP addresses and thus keep them anonymous while online.
Tails is a privacy-focused GNU/Linux-based operating system that runs
entirely from an external storage device such as a USB stick or CD. It
comes with Tor and other privacy tools pre-installed and configured,
and each time it reboots it automatically wipes everything that is not
saved on an encrypted persistent storage medium.
Normally a user's online traffic - such as emails, instant messages,
searches, or visits to websites - can be attributed to the IP address
assigned to them by their internet service provider. When a user goes
online over the Tor Network, their connections are relayed through a
number of Tor nodes using another layer of encryption between each
server such that the first server cannot see where the last server is
located and vice-versa.
Tor is used by private individuals who want to conceal their online
activity, human rights activists in oppressive regimes such as China
and Iran, journalists who want to protect their sources, and even by
the U.S. Drug Enforcement Agency in their efforts to infiltrate
criminal groups without revealing their identity. The Tor Project is a
non-profit charity based in Massachusetts and is primarily funded by
government agencies. Thus it is ironic that the Tor Network has become
such a high-priority target in the NSA's worldwide surveillance
As revealed by the British newspaper The Guardian, there have been
repeated efforts to crack the Tor Network and de-anonymize its users.
The top secret presentations published in October last year show that
Tor is anathema to the NSA. In one presentation, agents refer to the
network as "the king of high-secure, low-latency internet anonymity".
Another is titled "Tor Stinks". Despite the snide remarks, the agents
admit, "We will never be able to de-anonymize all Tor users all the
The former NSA director General Keith Alexander stated that all those
communicating with encryption will be regarded as terror suspects and
will be monitored and stored as a method of prevention, as quoted by
the Frankfurter Allgemeine Zeitung in August last year. The top secret
source code published here indicates that the NSA is making a
concerted effort to combat any and all anonymous spaces that remain on
the internet. Merely visiting privacy-related websites is enough for a
user's IP address to be logged into an NSA database.
An examination of the XKeyscore rules published here goes beyond the
slide presentation and provides a window into the actual instructions
given to NSA computers. The code was deployed recently and former NSA
employees and experts are convinced that the same code or similar code
is still in use today. The XKeyscore rules include elements known as
"appids", "fingerprints", and "microplugins".  Each connection a user
makes online - to a search engine, for example - can be assigned a
single appid and any number of fingerprints.
Appids are unique identifiers for a connection in XKeyscore. Appid
rules have weights assigned to them.  When multiple appids match a
given connection, the one with the highest weight is chosen.
Microplugins may contain software written in general-purpose
programming languages, such as C++, which can extract and store
specific types of data. The rules specifically target the Tor
Project's email and web infrastructure, as well as servers operated by
key volunteers in Germany, the United States, Sweden, Austria, and the
Netherlands. Beyond being ethically questionable, the attacks on Tor
also raise legal concerns.  The IP addresses of Tor servers in the
United States are amongst the targets, which could violate the fourth
amendment of the US constitution.
The German attorney Thomas Stadler, who specializes in IT law,
commented: "The fact that a German citizen is specifically traced by
the NSA, in my opinion, justifies the reasonable suspicion of the NSA
carrying out secret service activities in Germany. For this reason,
the German Federal Public Prosecutor should look into this matter and
initiate preliminary proceedings."
One of NSA's German targets is 212.212.245.170.  The string of numbers
is an IP address assigned to Sebastian Hahn, a computer science
student at the University of Erlangen. Hahn operates the server out of
a grey high-security building a few kilometers from where he lives.
Hahn, 28 years old and sporting a red beard, volunteers for the Tor
Project in his free time. He is especially trusted by the Tor
community, as his server is not just a node, it is a so-called
Directory Authority. There are nine of these worldwide, and they are
central to the Tor Network, as they contain an index of all Tor nodes.
A user's traffic is automatically directed to one of the directory
authorities to download the newest list of Tor relays generated each
Quellcode NSA  "anonymizer/tor/node/authority" fingerprint.
Hahn's predecessor named the server Gabelmoo, or Fork Man, the
nickname of a local statue of Poseidon. After a look at the NSA source
code, Hahn quickly found his server's name listed in the XKeyscore
rules. "Yes, I recognize the IP address of my Tor server called
'gabelmoo'." he said. "Millions of people use it to stay safe online,
and by watching the server and collecting metadata about its users,
those people are put at risk." The rule shown to Hahn, published
below, has a fingerprint called 'anonymizer/tor/node/authority'. The
fingerprint targets users who connect to Gabelmoo and other Tor
Directory Authority servers. In Germany, the Tor Directory Authorities
like Gabelmoo that are specifically targeted by XKeyscore rules are in
Berlin and Nuremberg. Additional targets are located in Austria,
Sweden, the United States, and the Netherlands.
Quellcode NSA  Fragments of XKeyscore rules targetting Tor directory
The expression below performs essentially the same function, but it
specifies the Tor directory authorities located in Five Eyes countries
(Australia, Canada, New Zealand, the United Kingdom and the United
States) separately from those in other countries. As the comment
explains, the "goal is to find potential Tor clients connecting to the
Tor directory servers."
Another rule catalogs users connecting to known Tor relays. This is
not difficult, because the addresses of all normal Tor relays are
published by the directory authorities so that the Tor software on
users' computers can select its own path through the network. In
addition to the public relays, connections characterized as Tor based
on protocol identifiers are also cataloged.
Not only Metadata
Internet service providers in countries with strong censorship such as
China and Iran frequently block connections to known Tor relays. To
avoid this blocking, The Tor Project maintains a list of non-public
relays called "bridges" to allow users to avoid this type of blocking.
Bridges are run by volunteers and they share the details with the Tor
Project to help censored users reach the internet.
Quellcode NSA  Microplugin which extracts bridge addresses from the
full text of Tor Project emails.
Users can request a bridge address via email or on the web. The
following fingerprints show two ways that XKeyscore attempts to track
Tor bridge users. First, the fingerprint "anonymizer/tor/bridge/tls"
records connections to the bridges.torproject.org server. Second, in
order obtain the actual bridge addresses for the purpose of tracking
connections to them in the future, the "microplugin" fingerprint
called "anonymizer/tor/bridge/email" extracts data from the body of
the emails that the Tor Project sends to its users.
This code demonstrates the ease with which an XKeyscore rule can
analyze the full content of intercepted connections. The fingerprint
first checks every message using the "email_address" function to see
if the message is to or from "bridges at torproject.org". Next, if the
address matched, it uses the "email_body" function to search the full
content of the email for a particular piece of text - in this case,
" If the "email_body" function finds
what it is looking for, it passes the full email text to a C++ program
which extracts the bridge addresses and stores them in a database.
Quellcode NSA  Fingerprint to identify visitors to the Tor Project website.
The full content of the email must already be intercepted before this
code can analyze it. XKeyscore also keeps track of people who are not
using Tor, but who are merely visiting The Tor Project's website
( as this rule demonstrates:
Quellcode NSA  Rules targeting people viewing the Tails or Linux
Journal websites, or performing Tails-related web searches.
It is interesting to note that this rule specifically avoids
fingerprinting users believed to be located in Five Eyes countries,
while other rules make no such distinction. For instance, the
following fingerprint targets users visiting the Tails and Linux
Journal websites, or performing certain web searches related to Tails,
and makes no distinction about the country of the user.
The comment in the  source code above describes Tails as "a comsec
mechanism advocated by extremists on extremist forums". In actuality,
the software is used by journalists, human rights activists, and
hundreds of thousands of ordinary people who merely wish to protect
their privacy.
The rules related to Tails clearly demonstrate how easily web searches
and website visits can be spied on by XKeyscore. On June 25, 2014, the
United States Supreme Court noted how sensitive this type of
information is in their Riley v. California decision against
warrantless searches of mobile phones: "An Internet search and
browsing history [...] could reveal an individual?s private interests
or concerns - perhaps a search for certain symptoms of disease,
coupled with frequent visits to WebMD."
Quellcode NSA  C++ program which searches "raw traffic" for .onion addresses.
In addition to anonymous internet access, Tor also provides a
mechanism for hosting anonymous internet services called "Hidden
Services". These sites' URLs contain a domain name in the
pseudo-top-level-domain ".onion" which is only accessible using Tor.
The code shown below finds and catalogs URLs for these sites which
XKeyscore sees in "raw traffic", creating a unique fingerprint for
each onion address. Each .onion address found in raw traffic is
extracted and stored in an NSA database:
Quellcode NSA  "anonymizer/mailer/mixminion" appid matching all
connections to 128.31.0.34.
There are also rules that target users of numerous other
privacy-focused internet services, including HotSpotShield, FreeNet,
Centurian, FreeProxies.org, MegaProxy, privacy.li and an anonymous
email service called MixMinion as well as its predecessor MixMaster.
The appid rule for MixMinion is extremely broad as it matches all
traffic to or from the IP address 128.31.0.34, a server located on the
MIT campus.
That server is operated by the Tor Project's leader Roger Dingledine,
an MIT alumnus. The machine at this IP address provides many services
besides MixMinion, and it is also one of the above-mentioned Tor
directory authorities. Dingledine said "That computer hosts many
websites, ranging from open source gaming libraries to the Privacy
Enhancing Technologies Symposium website."
Sebastian Hahn, the Tor volunteer who runs Gabelmoo, was stunned to
learn that his hobby could interest the NSA: "This shows that Tor is
working well enough that Tor has become a target for the intelligence
services. For me this means that I will definitely go ahead with the
When asked for a reaction to the findings, the Tor Project's Roger
Dingledine stated the following: "We've been thinking of state
surveillance for years because of our work in places where journalists
are threatened. Tor's anonymity is based on distributed trust, so
observing traffic at one place in the Tor network, even a directory
authority, isn't enough to break it. Tor has gone mainstream in the
past few years, and its wide diversity of users - from civic-minded
individuals and ordinary consumers to activists, law enforcement, and
companies - is part of its security. Just learning that somebody
visited the Tor or Tails website doesn't tell you whether that person
is a journalist source, someone concerned that her Internet Service
Provider will learn about her health conditions, or just someone irked
that cat videos are blocked in her location. Trying to make a list of
Tor's millions of daily users certainly counts as wide scale
collection. Their attack on the bridge address distribution service
shows their "collect all the things" mentality - it's worth
emphasizing that we designed bridges for users in countries like China
and Iran, and here we are finding out about attacks by our own
country. Does reading the contents of those mails violate the wiretap
act? Now I understand how the Google engineers felt when they learned
about the attacks on their infrastructure.?
NDR and WDR wanted to know from the NSA how it justified attacking a
service funded by the U.S. government, under what legal authority Tor
Network users are monitored, and whether the German government has any
knowledge of the targeting of servers in Germany. Instead of adressing
the questions repeatedly posed to them, the NSA provided the following
statement: "In carrying out its mission, NSA collects only what it is
authorized by law to collect for valid foreign intelligence purposes -
regardless of the technical means used by foreign intelligence
targets. The communications of people who are not foreign intelligence
targets are of no use to the agency. In January, President Obama
issued U.S. Presidential Policy Directive 28, which affirms that all
persons - regardless of nationality - have legitimate privacy
interests in the handling of their personal information, and that
privacy and civil liberties shall be integral considerations in the
planning of U.S. signals intelligence activities. The president's
directive also makes clear that the United States does not collect
signals intelligence for the purpose of suppressing or burdening
criticism or dissent, or for disadvantaging persons based on their
ethnicity, race, gender, sexual orientation, or religion. XKeyscore is
an analytic tool that is used as a part of NSA's lawful foreign
signals intelligence collection system. Such tools have stringent
oversight and compliance mechanisms built in at several levels. The
use of XKeyscore allows the agency to help defend the nation and
protect U.S. and allied troops abroad. All of NSA's operations are
conducted in strict accordance with the rule of law, including the
President's new directive."
However, the research contradicts the United States' promise to
Germany that German citizens are not surveiled without suspicion.
Using Tor in Germany does not justify targeting someone, the German
attorney Thomas Stadler states: "Tor users do not breach any laws, it
is absolutely legitimate to act anonymously on the internet. There are
many good reasons to remain anonymous."
What is deep packet inspection?
Deep Packet Inspection, or DPI, refers to the class of technology
which examines the content of data packets as they travel across a
network. A packet is the fundamental unit of transfer in packet
switched networks like the internet. While DPI is commonly used by
organizations to monitor their own networks, its use on public
networks for censorship and surveillance has been widely condemned by
privacy advocates and the United States government alike.
In 2012, the head of the U.S. Delegation to the World Conference on
International Telecommunications, U.S. Ambassador Terry Kramer, said
?some companies have used deep packet inspection technologies to not
look at aggregate customer information, traffic information, et
cetera, but to look at individual customer information. So looking at
individuals and what sites they?re on and how much capacity they?re
using, et cetera, as you can imagine, we?re very much opposed to that
because we feel that?s a violation of people?s privacy and gets into,
obviously, censorship, et cetera?.
Despite its public political condemnations of invasive DPI use, the
United States "Intelligence Community" and its "Five Eyes" partners
(Australia, Canada, New Zealand, and the United Kingdom) operate
massive internet-scale DPI systems themselves, including XKeyscore.
The use of XKeyscore is not limited to these partners, however. The
software has been shared with the German BND and BfV, as well as the
Swedish FRA, amongst others.
Active vs Passive
XKeyscore and the systems that feed it are considered "passive",
meaning that they silently listen but do not transmit anything on the
networks that they are targeting. However, through a process known as
"tipping", data from these programs can trigger other systems which
perform "active" attacks.
Quantum is a family of such programs, including Quantuminsert,
Quantumhand, Quantumtheory, Quantumbot, and Quantumcopper, which are
used for offensive computer intrusion. Turmoil, Quantum, and other
components of the Turbulence architecture are running at so-called
"defensive sites" including the Ramstein Air Force base in Germany,
Yokota Air Force base in Japan, and numerous military and non-military
locations within the United States.
Both Turmoil and XKeyscore feed selected data to real-time "tipping"
programs, such as Trafficthief, which can both alert NSA analysts when
their targets are communicating and trigger other software programs.
Selected data is "promoted" from the local XKeyscore data store to the
NSA's so-called "corporate repositories" for long term storage,
analysis and exploitation.
In 2013, the British newspaper The Guardian revealed that by 2008 more
than 150 internet surveillance facilities around the world were
running the XKeyscore Deep Packet Inspection software. All of the
internet traffic observed by XKeyscore, both metadata and full
content, is analyzed and stored temporarily at the collection sites
for periods ranging from days to weeks, while selected data is
forwarded on to other locations for long-term storage.
The storage, indexing, and querying functions are performed at or near
the collection sites because the volume of data being collected is too
large to forward everything back to facilities in other countries.
Analysts working from various locations around the world may search
specific XKeyscore sites, or send their queries to a collection of
XKeyscore provides a modular architecture in which tens of thousands
of small computer programs, or rules, written in XKeyscore's
specialized programming languages called Genesis and XKScript as well
as general-purpose languages such as C++ and Python, are run against
all traffic to categorize it and extract data. This indexing of the
"full take" allows analysts to query the temporary storage stored at
the XKeyscore site, effectively sifting through already pilfered
communications which occurred before they had deemed them interesting
for a specific reason.
XKeyscore can be fed by several different programs, including
Wealthycluster and Turmoil. These programs "sessionize" the data,
which means that individual connections, such as a request for a web
page, are reconstructed from the stream of intercepted packets.
Locations where the NSA runs XKeyscore include Special Source
Operations (SSO) sites, typically found at or near major
telecommunication providers' infrastructure; Special Collection
Service (SCS) sites, usually located inside diplomatic facilities like
embassies and consulates; and FORNSAT sites where satellite
communications are intercepted. All of these types of sites are known
to exist in Germany.
Other "Five Eyes" partners also operate XKeyscore installations. The
United Kingdom's Tempora program runs the largest instance of
XKeyscore. Both the software itself and limited access to NSA
databases have been shared with so-called "3rd party" partners
including Germany. The German foreign intelligence agency BND and the
domestic intelligence agency BfV are testing the Software.

@_date: 2014-07-03 13:12:10
@_author: coderman 
@_subject: [tor-talk] according to leaked XKeyScore source NSA marks all 
this says to me "we used to directly implement linking processes at
print "... hiddenservice/address" but now we have improved our
infrastructure of XKS workflow to abstract plugin interfaces of which
this functionality is now implemented as "... plugin/onion".
directories and authorities being of interest is interesting ;)
best regards,

@_date: 2014-07-06 19:11:45
@_author: coderman 
@_subject: [tor-talk] XKeyScore code authenticity - genuine [was: messing with 
the theme of messing with XKeyScore is amusing[0], but more to the
point i was asked to respond to some concerns of authenticity made in
a different post:
"Validating XKeyScore code"
i'm trying to keep this feedback technical, as i don't like much of
Graham's reasoning. (i do however approve of his use of "Great Man" in
the Voldemort sense, in reference to Cowboy Alexander[1])
his claim that "we believe the code partly fake and that it came from
the Snowden treasure trove." should be ammended:
"we believe the code deprecated, and that it came from the Snowden archives"
first segment of summary, by point:
# Point 1)
"The signatures are old (2011 to 2012), so it fits within the Snowden
timeframe, and is unlikely to be a recent leak."
 - agreed.
# Point 2)
"The code is weird, as if they are snippets combined from training
manuals rather than operational code. That would mean it is ?fake?."
 - false; the code is valid and deprecated (can be used as example)
rather than false. the technical detail. as a programmer, i know that
a regexp rule like:
extractors: {{
    bridges[] =
  }}
is both written by a novice regexp'er, and also took them a bit of
time. more than they'd spend on an example.
for another example,
for (size_t i=0; i < bridges.size(); ++i) {
        std::string address = bridges[i][0] + ":" + bridges[i][1];
        DB[SCHEMA_OLD]["tor_bridge"] = address;
        DB.apply();
        DB[SCHEMA_NEW]["tor_ip"] = bridges[i][0];
        DB[SCHEMA_NEW]["tor_port_or"] = bridges[i][1];
        DB[SCHEMA_NEW]["tor_flags"] = FLAGS;
        DB.apply();
      }
why two commits here to backend changes? as a programmer i understand
why this is done, but as a purely fictitious example the double commit
is pointless noise.
# Point 3)
"The story makes claims about the source that are verifiably false,
leading us to believe that they may have falsified the origin of this
source code."
 - false
how does limited misunderstanding arcane technicalities invalidate the entirety?
 if this were true, Robert Graham would be a complete imbecile, rather
than  technically competent and occasionally wrong.
# Point 4)
"The code is so domain specific that it probably is, in some fashion,
related to real XKeyScore code ? if fake, it's not completely so."
 - false. as stated above, these rules are deprecated rather than
fictitiously constructed. (and perhaps referenced in training
materials for utilizing the particular language engines demonstrated)
as explained above, and i will go into more detail later (i wager i
have more big data experience and DPI experience than Mr. Graham the
DPI expert does in this domain alone[2] ;)
last but not least, this speaks to the need for greater technical
expertise to be applied to the leaked archives.  if anything, the
nature of domain specific details discussed here show that not just
generalists, but an army of specialists, will ultimately be needed to
properly parse and protect based upon the archives as yet revealed.
best regards,
0.  "" for those with "Jam Eschelon Day" nostalgia ;)
  ^- see whole thread from "messing with XKeyScore"
1. "The character assassination of Keith Alexander"
 '... People have criticized calling him a "great man". I'm quoting
the Harry Potter movie here people, where the guy who sells
Harry's[sic] wand points out that Voldermort was a great wizard,[sic]
a great and terrible wizard'
   2. "XKeyScore: it's not attacking Tor"
 '... I am an expert in deep packet inspection (DPI). I've written a
system vaguely similar to this XKeyScore system here: (ferret). I find
the conclusions in this story completely unwarranted, though the
technical information cited by this story is pretty good. I suggest
future stories about the NSA's deep packet inspection actually consult
with engineers who've written DPI code before making wild claims.'

@_date: 2014-07-06 19:30:01
@_author: coderman 
@_subject: [tor-talk] XKeyScore code authenticity - genuine [was: messing 
i should have clarified this statement.  this is code someone wrote to
get a job done.  they are pulling bridge addresses out of text (email
bodies?) and getting a job done.
this is fine code and similar to what you'd see in any production environment.
this is not what a regexp guru would use to show their ability to
tightly match with sparse efficiency.
it is also not so simple that a non-PCRE fluent person would use it as
a fictitious example.
to be clear: all signs point to this being real code a person wrote to
get a job done - parse out bridge addresses from text.  the signs
point toward this code being legitimate depricated code, even if not
currently useful.
the code do not point toward this being a non-fictitious example, and
it seems Robert even alludes to as much with.
 "One interesting thing to note about the port number is that it
captures the first non-digit character after the number as well. This
is obvious[sic] a bug, but since it's usually whitespace, one that
doesn't impact the system."
 - implying he believes this is a legitimate rule, and also not
written by an expert.
best regards,

@_date: 2014-07-06 19:33:11
@_author: coderman 
@_subject: [tor-talk] XKeyScore code authenticity - genuine [was: messing 
i meant "non-functional, fictitious example" of course.  and with
that, i will leave my further comments to a later, more sober date...
 airport security, here i come!
best regards,

@_date: 2014-07-11 08:34:10
@_author: coderman 
@_subject: [tor-talk] [liberationtech] data mine the snowden files [was: 
it's the cryptome archives as of last month[0]. it is also 23G large,
hence the many onions and a aria2c hint.
curious to see what throughput some get; in theory it could be pretty
fast... no torrent yet as torrent is less private.
best regards,
0. "data mine the snowden files ..."

@_date: 2014-07-11 10:13:16
@_author: coderman 
@_subject: [tor-talk] [liberationtech] data mine the snowden files [was: 
JYA has been serving the public good on a shoestring for years with no
thanks but the occasional griefing by feds and hosting provider.
if any of this is useful, help him continue doing it!
see best regards,

@_date: 2014-07-11 22:19:20
@_author: coderman 
@_subject: [tor-talk] [liberationtech] data mine the snowden files [was: 
added example privoxy config as http_proxy to Tor, add sig note for Update 13.
 no further updates on list; contact direct if issues encountered.
best regards,

@_date: 2014-06-25 15:53:50
@_author: coderman 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
from this you draw too many unsupported conclusions.
freedom to communicate is very different from freedom of consequences
for your actions.  if you are posting material incriminating yourself
harming another, do you think the evidence is solely digital and
"good old fashioned police work" identifies criminals harming others
effectively, and outside the scope of "private network communication".
the markets you allude to, drug trade and sex crimes, perhaps a less
appropriate measure - consider cyber crime where information trade
alone is the offense, and you've got a better metric for the privacy
protections of illicit infotrade across digital networks.
last but not least, to the extent that these sites distributing
deplorable content (rape of earth humans) represented a failure in
enforcement, it seems logical that a vigilante response would develop.
these may have significant impact on availability, yet say more about
the general insecurity of software systems and digital networks more
than anything specific about Tor's privacy protections.
flawed assumptions, invalid premises. i disagree entirely!
best regards,

@_date: 2014-06-25 23:00:36
@_author: coderman 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
i am only aware of one Tor vulnerability that led to compromised
hidden services of affected instances, back in 2007.
also not a government or LE leveraged vuln.
the original argument is based on faulty assumptions.
best regards,

@_date: 2014-06-26 09:25:47
@_author: coderman 
@_subject: [tor-talk] Secure Hidden Service (was: Re: ... Illegal Activity 
i never use apache, php, perl. i use custom built nginx against custom
built dependencies to front custom python/c++ web services.
these hidden services have never been compromised, but they're also
not designed like most web services. (i have used bounties in the past
to attract scrutiny, but to be fair "never been compromised" is also a
pretty poor metric for security or privacy. this is more a sanity
i've seen vulnerabilities in configuration, where insecure options
enabled by default allow local execution and privilege escalation.
i've seen vulnerabilities in implementation, where poor coding implies
errors around authorization or authentication.
i've seen vulnerabilities in database communication, where failure to
sanitize inputs leads to complete compromise.
the list goes on, and on, ...
building secure systems is hard.  Tor is pretty hard, but the things
people run across it much less so; double for hidden services.
trying to remain anonymous while hosting an average site on a hidden
service?  this is difficult.
trying to remain anonymous while posting and chatting and otherwise
practicing horrible opsec?  this is near impossible.
last but not least, the entire premise of this thread is around
blatant, public illegal behavior brazenly displayed being
discover-able through search and publication - the sites that practice
good privacy aren't spamming their links everywhere.  by definition,
the original survey is collecting only the worst run sites.
too much thought wasted on this thread already.
best regards,

@_date: 2014-06-26 14:38:33
@_author: coderman 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
all of these; assuming discovery of hidden sites remains consistently
authoritative of all resources (the presumption of fewer hidden
services leading to flawed hypothesis, ...)
to be clear: i disagree with the measurements, just as much as i
disagree with the conclusions drawn from them.
and yet here too, a limited metric.
indeed.  until then, i can only provide subjective experience as well.
for what's it's worth, my experience is to the contrary. in network
hostile environments Tor is increasingly the only effective technology
i can use to remain in robust communication.
best regards,

@_date: 2014-06-27 13:41:40
@_author: coderman 
@_subject: [tor-talk] hardware acceleration OK or not? 
the only reason you may have wanted to not enabled hardware
acceleration was fixed last year. (openssl was inadvertently forcing
use of a single entropy source (RDRAND) when default engines enabled
in a specific first Tor run sequence. (see
 )
there used to be some engines that were slower than optimized CPU asm
variants, but i don't believe these are in use any more.
please enable this option, especially if you've got a recent VIA or
Intel processor.
best regards,

@_date: 2014-06-27 13:48:27
@_author: coderman 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
this is amusing! explain to me where i've said Tor resists traffic analysis? :)
my point is that Tor is harder than the software you're using over it.
web browsers, instant messaging clients, web services and poorly
implemented applications.
why do you need traffic analysis when trivial attacks work just as well?
citation needed.  all signs point to insider threat (you know, rats)
this may be true ;)
we could have a long discussion on this subject, but not apropos to this list...
best regards,
TL;DR:  Tor is not the weak spot in your privacy.  OPSEC, application
attack surface, pervasive information insecurity - these are all going
to betray you before some fundamental vulnerability in Tor protocol.

@_date: 2014-06-27 14:32:13
@_author: coderman 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
last but not least, passive confirmation attacks are passe; the best
attacks active.
"From a Trickle to a Flood: Active Attacks on Several Mix Types"

@_date: 2014-06-28 20:53:35
@_author: coderman 
@_subject: [tor-talk] hardware acceleration OK or not? 
it makes a difference for high performance relays. client don't notice
unless you're on mobile or embedded.
in theory you're also closing a few side channels ... ;)
if you are not crashing, i would leave it enabled.
best regards,

@_date: 2014-06-29 16:14:18
@_author: coderman 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
"pointing out obvious flaws" - as in, "it's so easy to protect against
traffic analysis!  just make one end invisible!"
in the interest of adding even a minuscule bit of signal back to this
discussion, let's get technical.
1) compute the cost of global traffic analysis.  we have big data mark
to put a ball park on it, but the point is: the cost is non zero and
non trivial.
2) compare to other mechanisms of compromise, whether through remote
exploitation, technical surveillance, surreptitious physical access,
3) compare to possible *well researched/designed* solutions against
traffic analysis.
the math appears to be  is expensive on already maximized
intelligence community budgets.  possible?  of course.  actually
applied?  not so clear.[0]
re  it is cheaper in every sense, to pwn the application layer and
end point directly. this is well documented by years of industry
experience, and more recently through covert budget details leaked.
finally,  this is fucking hard! to point a fine point on it.  if
you've designed and implemented a low latency traffic analysis
resistant anonymity protocol with great usability and modest
requirements please post here with the info; i for one would love to
see how you solved a few of the hard details involved. ;)
best regards,
0. i have more to say, but also en route to Paris.  'till then,

@_date: 2014-06-29 16:19:23
@_author: coderman 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
specifically UPSTREAM model collection at backbone peering points.
consider both landing points and internet exchanges - you are alluding
to total traffic analysis here, not piecemeal efforts like prior
localized IX opportunistically applied to long-lived streams...
it would be interesting to compare the cost of small scale
opportunistic IX vs. total global analysis, though. (if you're feeling

@_date: 2014-06-29 23:15:52
@_author: coderman 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
this is just one part of a series of costs; how much raw DPI capacity
(it is finite)? how much memory/storage for backtrace to some hours
window? 30day window? how much engineering time (earth human hours) to
implement the collection, classification, and analysis of all flows in
daily time? in near-real-time (<60sec)? how is accuracy beyond doubt
identified? how much does additional accuracy in shorter time cost?
you trivialize too much; over and under estimate.  justify the costs
you quantify in detail - what you throw around above betrays a lack of
understanding of the constraints of collection at global scale.
as i keep restating another way, no matter how many times you call it a cop out:
  if global traffic analysis against Tor is expensive, the ability to
pwn every endpoint with rare exception so cared about, using Tor or
not, is cheaper - your reasonable adversary will do that!
 ... more value for less money.
(this is perhaps one of the more interesting details to emerge across
the Snowden leaks - the technical constraints and evolution of the
offensive platform (TAO) and the scale (SSO/GAO) of the technical
processes (QUANTUM*/TURB*|TURM*) applied and where the most resources
are applied year over year.)
last but not least, please note that i am in Paris for the drinking
chocolate.  ;)

@_date: 2014-06-29 23:28:41
@_author: coderman 
@_subject: [tor-talk] High-latency hidden services (was: Re: Secure Hidden 
i know that one mechanism i have used to some limited success is
fronting a nginx proxy in front of multiple back-end hidden services
as actual sources.
this leaves an ephemeral instance (similar to ram only relays) with a
different traffic profile more like your average relay. (it has more
symmetric bandwidth no matter how lopsided the end point recv vs. xmit
is tilted which betrays most direct hidden service serving, or client
only links)
that is to say:
  front-onion -> nginx -> 3x-?x many onion HTTP keep-alive with
heart-beat if no request in last 30sec
it is slower, and less efficient, but also seems to be more robust.
  (putting multiple onions on the front end to avoid hotspots and
transient unavailability another question more apropos availability
than unlinkability...)
i'd love to see someone do some research on this subject they could
make public, hint hint! ;)
this would be quite interesting as a method to pursue further, but
also as you mention, still a far cry from strong traffic analysis
resistance. (distinct from social graph discovery resistance)
best regards,

@_date: 2014-06-29 23:34:00
@_author: coderman 
@_subject: [tor-talk] Illegal Activity As A Metric of Tor Security and 
i have a follow up:
  "The Case Against Earth Humans Communicating: Conspiracy to Crimes,
Communicating Crimes, Communication as Crime - END IT ALL!"
the all caps at end denotes seriousness.
a simple procedure with focused ionizing radiation and i can fix this
for you.  (who needs more than the reptile brain? not you criminal
earth humans!)
best regards,
    earth humans in your best interest, incorporated.

@_date: 2014-05-06 13:42:36
@_author: coderman 
@_subject: [tor-talk] Publishing Dangerous Data and Opinions 
nice! usually legal threats and intimidation indicate a good story,
but this must be juicy!
 Valar morghulis
no single guide, but many relevant subjects to study:
- metadata in documents (EXIF, headers, etc.) can betray you.
- a collection of facts or data can identify you (e.g. limited access
== limited suspects)
- the expert guidance itself can identify you (stylometry)
- hosted services can point toward you (you seem to assume a hidden
service will be uncovered, so anonymous hosting of a hidden service
appears requisite; procuring hosting anonymously another long
- third parties are liabilities, the more entities you interact with
en route to disclosure, the more potentially identifying information
you leak along the way.
i can publish for you.  my herd of trained attack goats have thwarted
many a foe!
best regards,

@_date: 2014-11-01 12:42:41
@_author: coderman 
@_subject: [tor-talk] Cloak Tor Router 
first question, did you contact Tor Project Inc. about this for their
input? (if yes, what was their take on your aims?)
the majority of these repositories are forks of existing public
projects, but not clearly so. (e.g. cloak-routing is a selection of
specific OpenWRT packages, eschalot, etc.)
what do you think of branching from upstream repositories, and keeping
your changes in a manner that upstream would be encouraged to
i have more feedback on code itself, but this is foremost to mention.
i approve of open hardware approach very much :)
perhaps useful to identify what is open (like PCB) and what is not (Atheros)
obviously this is not difficult, but it is also more complicated than
just "some sensible rules". e.g.
 and
iptables -A OUTPUT -m conntrack --ctstate INVALID -j DROP and all the
other intricacies...
it would also be great if you could introduce some per-device unique
entropy seed, obtained from a strong hardware based random number
generator. (how better to signal your interest in utmost privacy, even
if practical benefit is less concrete? :)
the concept of a portable Tor proxy hardware router that fits in your
pocket is great, in my not so unbiased opinion :)
what technical people will frown on is the way the device is presented
to users, and if users are placed into risk by technical errors.
that's fine; i believe it is possible to make a device that is
transparently usable that also doesn't put users at needless risk, if
that is what you are getting at.
the suggestions others have made that i second:
- block accidental Tor over Tor setups.
- provide a Tor Browser on the supported platforms with TOR_TRANSPROXY=1
- provide automated builds, so that users can keep their device up to
date easily, or use a built-in mechanism to obtain and install the
latest easily.
in general, some guidelines that me as a technical person would like to see:
- the device should fail safe, rather than fail open: if i
accidentally connect my friend's windows XP laptop to your device, it
should block rather than allow all by default.
- support robust stream isolation, beyond what may be default. perhaps
IsolateDestAddr and IsolateByClientAddr on TransPort (this does not
yet exist, but you could code it to the benefit of all Transparent
proxy consumers :)
regarding your other information:
from your kickstarter, "We commit to establish and operate new exit
nodes, to ensure that we are pulling our weight. Tor is currently at
approx 2000 users per exit node. For every 1000 devices we ship, we
will establish a new dedicated exit node. "
why the focus on number of exit nodes, instead of contributed exit
capacity?  you're measuring the wrong thing here.
i have more feedback, but your responses to these questions will help
me determine how much time i can contribute to an evaluation.
best regards,

@_date: 2014-11-02 00:47:40
@_author: coderman 
@_subject: [tor-talk] Cloak Tor Router 
ok. and thanks for running a relay and exit!
this is true; i see you have tried to be accommodating.  more on this later,
please let them upgrade digests on packages then too! :)
indeed. perhaps better one day, how much are Intel's foundry services?
ah, we can dream...
agreed. the "initialized and always kept on Tor" mode of operation is
useful for products like these, preferably also bought in cash!
even a simple one time, "You are about to route your traffic over the
Tor network. Turn off your torrents and don't upgrade poorly written
the zero guidance to unsuspecting is what i am most concerned about;
even basic captive portal warning would be a benefit.
i have more to say on this, as there are crude and more friendly ways
to do this.  it is not the end of the world if it happens, either.
just extra slow and inefficient :)
agreed. another topic deserving of a full discussion.  so queued,
thanks again, i appreciate your in depth responses!
best regards,

@_date: 2014-11-02 19:42:02
@_author: coderman 
@_subject: [tor-talk] Cloak Tor Router 
there is also the clients behind NAT issue for stream isolation,
  e.g. clients[1-N...] -> WiFi Router -> Cloak -> ISP -.
it would be useful to document the list of these concerns somewhere,
perhaps on the Transparent Proxy wiki page. (i can do this later, if
anon doesn't beat me to it :)
as for lightweight builds, you may find the tor ramdisk effort
useful*, and at runtime, kernel tuning (e.g.
desired ConstrainedSockSize.  this would only be necessary if memory
pressure truly is very tight.
64M is enough for Tor as client and hidden service or two, but will
have trouble with some pluggable transports and won't be a useful
relay.  the GeoIP database for friendly grouping by country can be
problematic as well, and may require some selective vfs pressure.
more later,
best regards,

@_date: 2014-11-02 22:18:37
@_author: coderman 
@_subject: [tor-talk] Cloak Tor Router 
if each client has a a distinct address (not behind NAT) this works
fine.  ideally there would be a way to force this behavior on each
connection so that clients behind NAT get stream isolation even for
connections to the same destinations.
as for which options your build supports, that's a good question.  i'm
not sure best to determine from a given Tor binary what options it
supports based on version and build configuration...  (maybe someone
on list knows off hand?  i can check later :)
best regards,

@_date: 2014-11-03 00:01:37
@_author: coderman 
@_subject: [tor-talk] Cloak Tor Router 
agreed.  i mention this because the way i usually use transparent
proxy mode is as mentioned above:  a local wifi router connected to
transparent Tor proxy connected to ISP.
in this situation, all the clients are behind the NAT WiFi router,
which complicated isolation.
if you _are_ the WiFi access point, as you intend to be, then there is
no NAT, and you avoid this issue.  (perhaps note to end-user: best to
connect clients directly to Cloak, rather than a router to Cloak :)
thank you for your prompt responses and attention to these details!
best regards,

@_date: 2014-11-03 11:12:49
@_author: coderman 
@_subject: [tor-talk] Krypton Anonymous: A Chromium Tor Browser 
cool :)
do you use any stream isolation per tab behavior? (perhaps via the
SOCKSPort isolation options?)
i will take a look further, with feedback, as time permits.  good stuff!
best regards,

@_date: 2014-11-05 15:32:26
@_author: coderman 
@_subject: [tor-talk] Platform diversity in Tor network [was: OpenBSD 
kudos, whoever you are!
(i love this flavor more than most :)
best regards,

@_date: 2014-11-06 05:41:09
@_author: coderman 
@_subject: [tor-talk] Cloak Tor Router 
in the past i have used OUI prefix lists to avoid known bad behavior.
(this doesn't work if a device is spoofing MAC of course, but in that
case they are probably savvy :)
a few hundred prefixes to opt-in safe (captive unless masked avoid),
 half that to fail open on occasion (default no captive unless known usable)
the timeout behavior, perhaps you could detect "brain-dead re-attempt
repeat" behavior for this duration, and then let through instead.
this came up in past discussions about a device that is simply
connected but idle, not yet seen by human.  and a device that is
headless dumb, like your media player.
more feedback when i have time.
thanks again for the open discussion!
best regards,

@_date: 2014-11-09 02:04:59
@_author: coderman 
@_subject: [tor-talk] insufficient hidden service performance is potential 
thanks for the transparency, nachash! i am putting this conversation
on tor-talk, since my replies are more noise and less dev, and the
details seem to be around Tor use and configuration.
the pcap dumps would have been most useful, as the access logs only
identify state transitions. these types of attacks likely utilized
many concurrent requests (perhaps just sending a few bytes of the
request string at once, bit by bit, until a request is complete)
performance analysis and tuning of internet sytems is difficult, and
even more so in this context!  (and performance in anonymity systems
is easily reversed for de-anonymizing DoS)
Andrea's distribution shows this type of behavior, as i would expect it:
e.g. send small bits to keep connection active and not closed by
server side client send timeouts, then around 900-1000 chars call it
good and finalize the request.
this may be application of slowloris type DoS to "encourage" HS
operator to use a vulnerable path, or confirm via side channel. (you
stated your web server bound to localhost, so the obvious ones you
avoided at least :)
of all the virtualization environments, i dislike OpenVZ the most. i
dislike all virtual hosting, however, so don't assume this is a vote
for Docker ;)
pay the extra for dedi on bare metal!
ok, maybe a dedi not an option if you're that tight for cash... :/
i find this amusing! my only suggestion is that you incorporate his nickname,
 Keith "Cowboy" Alexander
yup. hence slappy fights over the HSDir descriptor publishing is going
to be effective for who knows how long...
this was an international effort, so perhaps just one hand not talking
to the other, is the only conclusion to be drawn.
thanks for this, while not as useful as PCAPs with headers, it is still useful!
how would you know what covert heat looks like?
don't plea out!
P.S. public key?
best regards,

@_date: 2014-11-09 02:52:35
@_author: coderman 
@_subject: [tor-talk] insufficient hidden service performance is potential 
your ConstrainedSockets experiments are exactly what i would expect to
see if this technique were used, since reducing socket buffers would
allow you to have more concurrent connections open (and thus thwart a
DoS at lower limits).
note that the next level of breakage might show up at file descriptor
limits in processes like Tor or your Nginx server.  ulimits tuning
also suggested. (i like to use 32-64k as soft limit for all processes
on a server by default, and 0.25mm for front-end proxies running
Nginx/HAProxy or related services.)
last but not least, if you are pushing to extreme levels of
concurrence, be sure to disable CONNTRACK in iptables/xtables.
(or use an OS that has better performance with filtering
infrastructure, per the platform diversity thread active here the last
few days)
best regards,

@_date: 2014-11-09 02:59:24
@_author: coderman 
@_subject: [tor-talk] Operation Onymous against hidden services, 
if you crash Tor, it won't necessarily use more of its backup guards.
this attack would have to be combined with other network level (MitM)
tampering to manipulate route selection like that, as i currently
understand the situation.
with your "DDoSing all known hidden-service guard relays" perhaps you
allude to this, but note that all you'd need to do is interfere with
the hidden service path to those guards to be effective. (RST
injection) rather than a carpet bombing of all guards HS uses.
best regards.

@_date: 2014-11-09 03:31:28
@_author: coderman 
@_subject: [tor-talk] Operation Onymous against hidden services, 
i'm going to laugh if the "technological breakthrough" is a DoS
slowing Tor enough you restart it. then they watch to see who (serving
up the appropriate amount of more traffic out than in) just restarted
all signs point to modified slowloris with a limited set of suspects.
best regards,
  coder 'cointelpro' man

@_date: 2014-11-09 04:11:27
@_author: coderman 
@_subject: [tor-talk] Cloak Tor Router 
perhaps it would be useful to break this project into two parts,
 a. client or bridge only portable router (pocket sized)
 b. dedicated Tor router/relay machine for fixed use.
perhaps c. could be "common requirements for ALL Tor routers" which
apply to both types of use above.
i would be willing to help work on these requirements and concerns, if
the  page is
the right place to do it...
best regards,

@_date: 2014-11-09 05:31:47
@_author: coderman 
@_subject: [tor-talk] insufficient hidden service performance is potential 
someone asked, "then why the names and ..?"
if i was implementing this attack, i would want the attacked to assume
it was a mis-configured bot. this looks like a mis-configured bot.
only by watching established connections, and the rate of client
request data sent over them, would you be able to identify this type
of malicious attack was taking place.
morals of this story:
- never assume a crash or DoS is innocuous on the Tor network.
- always get packet captures to diagnose trouble! (not just request logs)
- "the old tricks, still the best tricks..."
- and DON'T record traffic on a relay or exit! this is likely to harm
others while you attempt to be proactive. the last thing Tor needs is
relays and exits breaking the very privacy it is intended to provide
best regards,

@_date: 2014-11-09 06:00:22
@_author: coderman 
@_subject: [tor-talk] Operation Onymous against hidden services, 
or was it RELAY_EARLY?
 you could also use the attack above as "parallel construction" for
mining the never-released-probably-a-poisoned-tree research done
here i will quit speculating, as either of these two techniques, or
others, would be sufficient.
best regards,

@_date: 2014-11-09 08:48:35
@_author: coderman 
@_subject: [tor-talk] Tor Blog: "Thoughts and Concerns about Operation Onymous" 
Griffin, Matt, Adam, Roger, David, George, Karen, and Jake worked on a
wonderful write up of all the questions and concerns regarding this
thank you!
the performance link to doc/TUNING shows it could use much help.
currently this is minimal, focused on file descriptor limits. more
tuning guidance is needed!
there is a good thread a few years past on tor-relays,
, which could provide instruction for additional knobs to turn for a
solid relay or client under load.
best regards,

@_date: 2014-11-05 15:32:26
@_author: coderman 
@_subject: [tor-talk] [tor-relays] Platform diversity in Tor network 
kudos, whoever you are!
(i love this flavor more than most :)
best regards,
tor-relays mailing list
tor-relays at lists.torproject.org

@_date: 2014-11-09 13:50:09
@_author: coderman 
@_subject: [tor-talk] insufficient hidden service performance is potential 
if you'd like to help test, the existing PyLoris implementation does
not handle hidden services well, instead uses host DNS to lookup and
then connect to IP address.
i have modified a Tor HS PyLoris and updated the HS 100 connections
ticket with a copy:
  best regards,

@_date: 2014-11-14 12:55:52
@_author: coderman 
@_subject: [tor-talk] Defense against DDoS Attacks in Tor 
i assume you looked over  as well.
DoS are all "successful", by some measure.
ordered by hardness, consider:
 0. application level, like slowloris or computational DoS. [ see
torhs-pyloris-nov9.tgz on  ]
 1. hidden services in general, roles like HSDir or Rendz., high
connection rates, stream isolation impacts. [ see list at
for enumeration of many known attacks ]
2. protocol issues, circuit extension attacks, shared gateways
manipulation, predecessor attacks, etc.
3. high capacity relay performance issues, tuning, clogging, etc.
messing with the fast relays most difficult. from there, considerably
easier to deny service. a hard problem.  good luck! :)
( most don't even try to fix 0 or 1 at all... )
best regards,

@_date: 2014-11-14 13:04:30
@_author: coderman 
@_subject: [tor-talk] Tor router requirements / best practices [was: Cloak Tor 
prior testing on similar hardware shows them at the bottom of the
relay capacity pool.  the trend the last few years has been toward
faster relays, rather than more relays, because of other pressures in
the Tor directory consensus.
it appears anonymous contributors have edited which would be useful to integrate back into a Tor wiki page like
 including
any feedback you, or any other contributors, may have to provide.
the main points are provided by arma and mike in these threads:
  mike:   arma: I was thinking something like:
- Many people keep wanting to build a magic anonymity box. And it's
really appealing to not have to change your behavior or your
application settings, and just magically get anonymity, so I can
understand why the idea keeps popping up.
- Unfortunately, if you just route all your traffic through Tor,
you're only solving half the problem: all the application-level issues
remain. First this is a problem when you use your Chrome over Tor and
then wonder how websites are able to recognize you anyway (remember
all the protections that Tor Browser adds over vanilla Firefox). And
second, as you say in your post here, it's a problem because of all the
chatter that comes from background applications, update attempts, printer
notifications, and so on that most systems do by default these days.
- To be fair, some expert users may still get a benefit from Torifying
their traffic. For example, if they've already set up a firewall to
block everything they don't want talking, and now they want to use
an application that's hard to configure a proxy for. Or if they have
thought deeply about their threat model and they don't want a lot of
the anonymity properties that Tor aims to offer. But that user is very
far from the target audience for these magic anonymity boxes.
- The best design we've been able to come up with is one that forces you
to be using Tor on your side, and only allows your traffic through if it's
coming from Tor. Making it use a proxy, or maybe even better a Tor bridge,
that's running on the router seems a fine way to do this limiting. And we
could also imagine running a captive portal website on the router that
intercepts outgoing port 80 requests and teaches you what you need to
do to use this network connection safely. Perhaps it has a local copy
of Tor Browser for you (but how does the user know it's the real Tor
Browser?), or perhaps it lets you reach so you can fetch it yourself.
- This approach sure isn't as usable as the magic anonymity box. What a
great research area! But be aware that people have been thinking about
this issue for several years now, and don't get fooled by solutions
that brush all the above details under the rug....
best regards,

@_date: 2014-11-14 13:12:15
@_author: coderman 
@_subject: [tor-talk] Tor router requirements / best practices [was: Cloak 
that was quoting arma (Roger) per
and of course, how could i leave out PORTAL :
  best regards,

@_date: 2014-11-28 18:25:37
@_author: coderman 
@_subject: [tor-talk] latest generation traffic confirmation attacks 
a multi-path wide socket datagram based stochastically re-ordered and
shaped transport overlay with optimized dependent link padding would
keep such a coding recoverable confirmation in the dark, indefinitely.
[citation needed]

@_date: 2014-10-03 04:25:07
@_author: coderman 
@_subject: [tor-talk] Hidden Services - Access control. 
re: HiddenServiceAuthorizeClient
this assumes you will never encounter an adversary relay (hsdir)
intending to enumerate addresses.  a useful feature, but the intent is
not to hide existence of hidden service addresses.
best regards,

@_date: 2014-10-03 07:23:22
@_author: coderman 
@_subject: [tor-talk] Hidden Services - Access control. 
this is not correct; think of SocksPort as a way for clients to use
the Tor program to access the Tor network; like TransPort and DNSPort.
this does not affect reachability of the hidden services you are
serving with your Tor instance.
seems so.  the reason i mention PKI is a defense in depth
configuration where Tor access to hidden services are in a domain
distinct from services where key material for authentication and
privacy are used.  Tor == network layer, TLS == application layer,
each in their own restricted runtime.
to each their threat models...
best regards,

@_date: 2014-10-03 08:09:37
@_author: coderman 
@_subject: [tor-talk] Hidden Services - Access control. 
by clients i typically mean Tor Browser, users behind Transparent Tor
Proxy, etc.
by hidden service i mean entries in Tor config that map hidden service
addresses to hidden services.
said another way,
clients access Tor via SocksPort, or TransPort, or ...
Tor routes connections to hidden services as per configuration.
these are different things; and SocksPort is not needed to "serve
hidden services"
if this doesn't make sense, perhaps someone with better explanatory
powers can assist...
best regards,

@_date: 2014-10-05 15:58:10
@_author: coderman 
@_subject: [tor-talk] Hidden Services - how to implement something like 
i can describe how to build it; as this is not conforming DNS
protocol.  perhaps one day re-distributable, or secondary sourced...
this configuration is specifically to avoid hotspots with singular
onion hostnames, of any sort. currently this is brittle if you are
this configuration is specifically oriented around transparent Tor
proxy use, with AutoMapHostsOnResolve and a private address space
routed when internal names resolve.
this configuration is specifically designed to co-operate with other
services, like i2p eep sites on different ranges, and ORCHID mappings
into IPv6.
use mostly stock namecoind - you may want to use a "mod" to monitor
.bit resolutions for current status, and trigger updates as needed;
multi-onion names are simply published under alias: and the list is
priority ordered onions.
the resolution is performed by a modified powerdns authoritative and
local caching resolver pair. see the authoritative is used to implement a .hidden alias that provides
the mapping across .onion (or other) addresses which are then cached
via the local resolver, also configured in /etc/resolv.conf as the
only resolver. (12.0.0.1:53)
the authoritative pipe-backend like backend does the work. (i use
shared memory mapped pages)
when a request .hidden (e.g. peertech.hidden arrives, the
resolver back-end queries local bitcoind for alias:. the local DNSPort
is queried for each onion in the alias list in parallel, if not cached
[see addendum],
the list of ordered [see adendum] addresses is returned as DNS RR with
modest / adaptive expiry to the requester.
the client, assuming transparent routable path, then connects any IPv4
or IPv6 capable client to endpoint as desired. this also works for TCP
multi-path with some additional tweaks ;)
best regards,

@_date: 2014-10-05 16:07:19
@_author: coderman 
@_subject: [tor-talk] How does Tor help abuse victims? 
not sure i can see through the twisted as expected,
but absolutely speaking, i would gladly trade "tor stalking" [do you
mean trolling?] to most other stalking, particularly the stalking
enabled when an aggrieved party can opportunistically leverage
location against me for significant and physical, other harm.
some things just must exist, privacy of communication and other basic
human rights included.
best regards,

@_date: 2014-10-07 15:20:49
@_author: coderman 
@_subject: [tor-talk] Revocable Anonymity is Anonymity like Clipper Chip 
Kane/Ksec]
"Revocable Anonymity" is a farce and distraction; Skipjack Clipper
Clip[0] equivalent in every sense to the non-starter of "key escrow"
and "government / lawful access mandated backdoors".
all backdoors, no matter how well intentioned, lead straight to hell.[1]
best regards,
0. "The Clipper chip was a chipset that was developed and promoted by
the United States National Security Agency as an encryption device,
with a built-in backdoor, intended to be adopted by telecommunications
companies for voice transmission."
 -  1. "The Athens Affair - How some extremely smart hackers pulled off
the most audacious cell-network break-in ever"
 -

@_date: 2014-10-30 20:25:37
@_author: coderman 
@_subject: [tor-talk] hidden service performance [was: Questions about crypto 
Nick has commented on them before on tor-dev, among other places.
some additional hidden service performance links:
"Hidden Services are in a peculiar situation. While they see a loyal
fan-base, there are no dedicated Tor developers to take care of them."
 - "[tor-dev] Hidden Service Scaling"
 - "[tor-talk] Hidden Services - how to implement something like Round Robin DNS?"
 - "Rumors that hidden services have trouble scaling to 100 concurrent connections"
 - best regards,

@_date: 2014-09-12 03:28:51
@_author: coderman 
@_subject: [tor-talk] Tor in popular culture, 
it's Tor, btw :)
i believe this is next great source of both support and funding -
integrating a compelling and authentic narrative into creative
production with a slice of residuals applied to long bets and other
far horizon research best supported by such endowments and other "no
strings attached" funding.
Tor has a problem right now in that many efforts are tied to specific
sponsor deliverables. if a sponsor doesn't want to cover the cost, and
the volunteer expertise is not immediately and continuously available,
the effort stalls.  Few big sponsors also incur other planning and
renewal concerns.
this is not to say that sponsors and specific deliverables are a
failure - the opposite!  there is a great benefit to specific funds
for specific goals, and many of the usability and connectivity
improvements have been made through these efforts.
however, long bets and complicated research are another story. i think
Roger may consider datagram Tor research and development toxic; the
short term efforts burning out devs, the research leading to more
questions than answers, and the desire to put one's hand again into
the fire diminishing.
i'd love to see creative efforts underscore positive narratives around
privacy in general, and Tor specifically.
i'd love to have no strings attached funding flowing into the project
for whatever non-profit appropriate endeavors they choose, including
experimental efforts with little near term benefit.
i'd love to see more inspiring and positive portrayals of Tor and
privacy in popular culture, reaching those who have never considered
what privacy means to them and how they may one day depend on it in
dire need.
i believe Tor Project Inc. would be receptive to this, however it
would need to be presented as a whole package ready to sign on dotted
lines. their time better spent on actually building privacy enhancing
technologies rather than creative distractions...
best regards,

@_date: 2014-09-12 19:10:12
@_author: coderman 
@_subject: [tor-talk] Someone is crawling TorHS Directories: Honeypot 
fun; this appears to be an intermittent pastime of some for near a decade now...
i would call these honeytokens, however, as it is the name you are
concerned about, not the services running at that onion. e.g. "...
configured honeytoken hidden service addresses known only to myself
and the chosen HSDir for that address." you shouldn't assume HSDir is private in any case; and if enumeration
is truly a concern, fast flux onions is a thing.  these are location
hidden, not existence hidden :)
best regards,

@_date: 2014-09-30 15:22:47
@_author: coderman 
@_subject: [tor-talk] Hidden Services - Access control. 
you cannot hide the existence of the *.onion, as these are "location
hidden" not "existence hidden".
you can use various methods to restrict access, my favorite being PKI
with client certificates - if you are not an authorized client your
socket is disconnected before reaching application service layers.
simple HTTP auth leaks too much for my taste.  and of course,
variations of single packet authentication to access...
best regards,

@_date: 2014-09-30 15:28:54
@_author: coderman 
@_subject: [tor-talk] Hidden Services - how to implement something like 
i have been using modified local resolvers and web clients with
namecoin for this purpose.  c.f.:
peertech.bit expires in 5618 blocks
Raw value: '{tor:j5ivfpymes6h2kg4.onion,info:peertech hidden
as one experiment.  it will indeed be convenient once "out of the box"
support for Tor/I2P is provided...
best regards,

@_date: 2015-04-05 22:19:17
@_author: coderman 
@_subject: [tor-talk] Tor Summer of Privacy 
as an individual doing things independently, you are shielded from NSL
silent screwing.
if you are trying to run a business, this becomes a concern.
however as an individual you are more vulnerable to "display of power"
pressures, with less resources to resist them.
the only reliable advice i can see is to speak up rather than suffer in silence.
this example bothers me because Ladar put himself in position of
having the ability to get at the keys of users. this is a bad place to
be, as demonstrated by NSLs and lucre. Very different than writing
open source for any to use.
the earth humans are pretty atrocious, it is true. they're also pretty
awesome :)
a mixed bag...
it's Tor, and
we can discuss more applicable metrics, like fast to respond to and
release fixes for serious security issues.  they're working hard to
address funding diversity, that long sore subject. etc. etc.
best regards,

@_date: 2015-04-17 05:03:19
@_author: coderman 
@_subject: [tor-talk] [tor-dev] Porting Tor Browser to the BSDs 
as an attacker, i love claims of bullet proof and NSA proof and military grade!
regardless of other hubris, there is demonstrable benefit for security
through isolation; both as front-tier container technique and
fail-safe backstop to other forefront application level failures.
best regards,

@_date: 2015-04-28 19:52:28
@_author: coderman 
@_subject: [tor-talk] hiddden service on openwrt 
8mb flash, 32mb ram is probably the lower bound for a useful Tor
client / hs host device. remember to omit geoip from the tor pkg :)
i would state this as: never use these devices as relay.
 and only as bridge if not already running hidden svc,
  and not more than a few distinct onions per device.
a longer hidden service performance discussion spans:
"Hidden Services are in a peculiar situation. While they see a loyal
fan-base, there are no dedicated Tor developers to take care of them."
 - "[tor-dev] Hidden Service Scaling"
 - "[tor-talk] Hidden Services - how to implement something like Round Robin DNS?"
 - "Rumors that hidden services have trouble scaling to 100 concurrent connections"
 -   finally, consider:
Increase NumEntryGuards to 3 or 5
 and Increase MaxClientCircuitsPending 300
you'll want to squeeze the best reduction across toolchain (uClibc
opts) and application (for example, ConstrainedSockets opts) even
system tuning (ulimits, /proc). some of this is on the Torouter page:
 the rest on
the list archives...
in general terms, there is not a good set of measurements for Tor
client/hs serv performance. most performance attention focuses on
relays or crypto primitives.
i'd like to run common Tor client/hs-serv benchmarks across a variety
of platforms. in particular the i.MX53 and i.MX6 line as step up
compute wise from these units. e.g.
 for a nice i.MX53 device.
best regards,

@_date: 2015-08-07 13:10:49
@_author: coderman 
@_subject: [tor-talk] pdf with tor 
you could call that rube goldberg a "conversion tool", but really it
was an object lesson. ;)
speaking of PDFs,
  "The vulnerability comes from the interaction of the mechanism that
enforces JavaScript context separation (the ?same origin policy?) and
Firefox?s PDF Viewer... The exploit leaves no trace it has been run on
the local machine."
- best regards,

@_date: 2015-08-11 16:32:49
@_author: coderman 
@_subject: [tor-talk] (no subject) 
it would be useful, particularly on systems with native acceleration
of supported crypto primitives.
correct. in particular, making the Tor internals efficiently
multi-threaded is difficult due to the particulars of crypto and Tor
network I/O in the implementation.
i thought i had a list of Trac tickets to the gist of this matter,
  alas i cannot find them. perhaps someone else has a convenient collection?
this also came up in context of using CUDA or OpenCL to accelerate
network crypto via CPU offload to GPU.
the good news is that it is maybe less hard now, than it was some
years ago, to make this transition to well threaded internals in Tor.
maybe soon, even closer yet. and as you mention, patches welcome since
the best fix is code under test :)
best regards,

@_date: 2015-08-11 16:42:37
@_author: coderman 
@_subject: [tor-talk] Crowdsourcing Tor Guides 
resources i find myself suggesting to others:
Surveillance Self Defense Guides and Briefings
 - Library Freedom Project  presentations:
 -  - Tom's Tor review is too technical per your audience, but also excellent :)
 best regards,

@_date: 2015-08-11 16:46:20
@_author: coderman 
@_subject: [tor-talk] Crowdsourcing Tor Guides 
i think it also is worth pointing out:
 using Tor in odd ways outside the supported Tor Browser configuration
is not recommended. (like transparent Tor routers, or different
browsers with Tor proxy setup)
as with the PDF.js viewer, which has flaws, you don't want to just
"Use Acrobat Reader" instead, which would be even worse!
in short:
  if there is not a guide for using X with Tor, it might be because X
is horrible. :)
best regards,

@_date: 2015-08-15 08:38:22
@_author: coderman 
@_subject: [tor-talk] multithreading 
which covers the lay of the land.
last summer a GSoC project:
  making steps in the direction.
see also Trac tickets:
- - -  best regards,

@_date: 2015-12-02 17:32:22
@_author: coderman 
@_subject: [tor-talk] Attention tor-talk ,what happened,?? 
this is a mystery to us all!
this has been aggregated into a handful of tickets for multi-threading support.
the collective defect identification efforts in real-time have moved
to channel we still kill bugs. live. for your gratutious pleasure!
i hear rumor of a relaychat777jqcz.onion soon; sounds lucky :P
perhaps you're trying to make it harder than it need be? ...
best regards,

@_date: 2015-12-02 17:36:31
@_author: coderman 
@_subject: [tor-talk] twitter tor block redux 
they seem to regularly attempt a "tie all accouns to secondary
identifiers" phase.
i dodged this lock-out having previously associated a hotspot puck SMS
with a Tor-only twitter account.
perhaps pre-paid is sufficiently tied-in to avoid the automated mechanisms...
it was always, and will always be, total bullshit from Twitter.
question is if they get enough flak to cut the crap...
best regards,

@_date: 2015-12-06 03:02:15
@_author: coderman 
@_subject: [tor-talk] How does one remove the NSA Virus off the BIOS Chip 
you say "find out, copy all" like it's so easy, *grin*
here's some fun for you:
 $ sha256sum taobios-v2.tar.bz2
interesting details in both samples!
( L2 is config only PDoS via UEFI BIOS :)
best regards,

@_date: 2015-12-10 13:19:26
@_author: coderman 
@_subject: [tor-talk] single entity running >36% exit probability with 5 
thank you to everyone for acting transparently and conservatively in
this situation.
has a trac ticket been created for this issue?
best regards.

@_date: 2015-12-29 17:15:29
@_author: coderman 
@_subject: [tor-talk] Hello I have a few question about tor network 
Tom also provided a handy redirect to latest,
     :)

@_date: 2015-01-03 04:34:25
@_author: coderman 
@_subject: [tor-talk] HardwareAccel: Current proper use??? 
you could submit a patch ;)
in OpenSSL land, there are two types of crypto offload / hw engines:
 built-in (static), and dynamically loaded (dynamic).
the "HardwareAccel 1" option says to enable the built-in / static
engines.  you may have a patched OpenSSL that will automatically try
dynamic engines without explicitly attempting to load them by name (as
libengine.so dlopen'ed implementations).
in some versions of OpenSSL, you will need to enable HardwareAccel
(but not use a dynamic engine - aesni is built-in / static).
you will need to consult the distribution of OpenSSL you are using to
be sure - it varies by version and pkg maintainers.
leave HardwareAccel 1, but do not bother with a dynamic named engine opt.

@_date: 2015-01-19 10:37:06
@_author: coderman 
@_subject: [tor-talk] force apt-get & yum updates through tor? - don't use 
don't use polipo, it has trouble with very large downloads.
better to use a different type of proxy like privoxy or torsocks or
python socks wrapper or transparent Tor gateway or ...
in a different benchmark, (fy2014 corpus of cryptome and other)
 best performance is aria2c with 18 concurrent connections across 9
onions / 3 servers.
  you can configure package downloads from mirrors this way, too.
[ usually, don't need to dial these this aggressive, just resume after
failure and confirm digests once retrieved. ]
best regards,

@_date: 2015-07-08 01:43:16
@_author: coderman 
@_subject: [tor-talk] Regarding the Hacking Team leak and the "TOR 
there are at least three common ways:
1. using an evil proxy, as directed above. they install a rogue CA so
they can sign for any SSL/TLS required.  this works for hidden
services, because their proxy strips ssl, then forwards to hidden
service. e.g. 2. using memory scraping - they don't appear to do this, but other
exploit kit does. if your browser is rendering pages and accepting
input, it does so on the local machine, and inspecting local machine
memory gets at these bits before encryption (before network I/O)
3. using key exfiltration, so that encrypted streams captured on the
network can be decrypted later. note that exfiltration key material is
very small, easy to hide. and then gets you access to all the
plain-text. call this the  method.
best regards,

@_date: 2015-07-09 00:42:56
@_author: coderman 
@_subject: [tor-talk] app -> socks5-openvpn -> socks5-tor ? 
this would be useful; i recall a http-proxy/socks-proxy front-end to
OpenVPN but can't seem to find it. it did not create a tun/tap device
on host.
will try again later, but in interim, would love a current copy if
found. good luck!
 best regards,

@_date: 2015-07-10 12:09:47
@_author: coderman 
@_subject: [tor-talk] pdf with tor 
WhonixQubes with DeepLang semantic barriers between isolated temporal
processing pipelines.
you obtain the PDF inside a transient isolated VM via scrutinized path
through upstream Tor and Firewall VMs.
next hand-off to normalized representation VM instance, which produces
each page as a well formed bitmap no compression no metadata graphical
then, each probably innocuous page image is paired to yet another
temporal VM to convert page into semantic description in ascii text,
english language.
finally, a semantic reconstruction VM uses the natural language
descriptions from above to re-construct a page for your viewing
pleasure as intended, now without risk of malicious surreiptitious
constructs...  perhaps with a puppyslug or two. :P
best regards,

@_date: 2015-07-12 21:32:40
@_author: coderman 
@_subject: [tor-talk] pdf with tor 
Yuri, the fact of the matter is:  both formats are unsafe!
 please see if you are engaged in high risk activities,
 either format is sufficient to screw you.
best regards,

@_date: 2015-07-22 16:10:17
@_author: coderman 
@_subject: [tor-talk] USB Sticks for Tails -> CCCamp 
USB fit in your pocket; more like DVD-RW perhaps, too.
best regards,

@_date: 2015-07-25 15:00:35
@_author: coderman 
@_subject: [tor-talk] Attention Jail afficionados 
minijail better than real jail, see:
 "a tiny, custom launcher that handles namespacing, control groups,
forked from documentation is anyone using minijail on a distribution other than Arch Linux
without building a new kernel and libcommoncap?  reply on list as this
would be useful reference point.
next question is how you're running Tor in minijail :)
[ if SocksPort, SocksSocket, DNSPort, etc. ... ]
   best regards,

@_date: 2015-06-04 10:13:15
@_author: coderman 
@_subject: [tor-talk] Fwd: Qubes Project gets OTF funding to integrate Whonix, 
congratulations! glad to see Qubes & Whonix work continue...
Hash: SHA1
Here is some great news:
In other news: Qubes Canary  has been published yesterday:

@_date: 2015-06-18 13:45:31
@_author: coderman 
@_subject: [tor-talk] Matryoshka: Are TOR holes intentional? 
this is where multi-path transports, which resist attacks against
traditional in-order or stream oriented transports - inherently
encumbered by serial datagram sequence. sadly, such transports also
require user space stacks and significant complexity. [see past
threads on multi-homed, multi-path SCTP w/ DTLS/IPsec telescopes, as
just one possible shape of could be...]
future ideas, plausible or no,
 Matryoshka does not solve even the known problems, let alone beat Tor
at the privacy game.
... fun subjects for exploratory development, perhaps when Tor Project
gets a research endowment. :P
best regards,

@_date: 2015-06-18 13:48:33
@_author: coderman 
@_subject: [tor-talk] Matryoshka: Are TOR holes intentional? 
i should have mentioned that stochastic shaping is required along with
the multi-homed, multi-path transports. otherwise you risk carrying
covert channel in jitter forward...
that should suffice for your anonymity bibliography and mailing list
search set. :)

@_date: 2015-03-01 20:03:31
@_author: coderman 
@_subject: [tor-talk] How can I let tor use the local dns settings instead 
using your own DNS settings would be a "side channel" and "IP leak/disclosure".
Tor cares about your DNS if configured as relay, in order to respond
to lookups on behalf of clients like yourself.
as a client, you must always resolve hosts through Tor, or connect by
name, otherwise you circumvent the protection it provides.

@_date: 2015-03-07 17:33:34
@_author: coderman 
@_subject: [tor-talk] FOIPA adventures 
first responsive one to complete:
"A search of the INTERPOL Washington indices produced 87 responsive
pages regarding the Tor Project. We have reviewed the pages and are
releasing 3 pages with partial redactions pursuant to Title 5, United
States Code, Section 552 and of the FOIA."
i'm not going to challenge the exception, but if anyone else cares to,
see the case above.
best regards,
P.S. originally i had included Tor devs on these requests, with an
offer like the one below. it turns out most of them have tried these
FOIPA requests before, and got the run-around or simple Glommar
responses. rather than demonstrate an ability for selective insanity,
i am carrying on with this muckrock experiment solo.
finally, i have come to the position that i like muckrock, and anyone
else who wants embargoes during requests should sign up a professional
account and support their good work!
 I have a HUGE favor to ask of you!
  and it involves multiple iterations of annoying paperwork.  :/
   [there are probably other reasons this is the worst request ever...]
 Should you kindly agree to participate, you will mail multiple copies
 of identification documents to various agencies. You will _not_ need to
 pay any fees. I will reimburse you for shipping with tracking number
 (prefer USPS priority with tracking  Requests are hidden / embargoed
 until approved for public release - you will review them before public.
 This is in support of a project I describe below, using public records,
 and inspired by Aaron's fearless advocacy for transparency.
 I hope you consider participating!
 - martin

@_date: 2015-03-17 15:20:42
@_author: coderman 
@_subject: [tor-talk] RAPTOR: Routing Attacks on Privacy in Tor 
i use cyclops to monitor BGP routes of interest. it would be
interesting to automate monitoring of routes for routers in consensus
automatically via script rather than fixed configuration through
cyclops UI. if anyone is aware of such a tool, i'd like to know about it :)

@_date: 2015-03-25 19:21:32
@_author: coderman 
@_subject: [tor-talk] Pocan & Massie Introduce Legislation to Repeal 
i want proposals to de-fund entire classes of offensive operations
that contribute nothing to security, only detriment to all privacy.
it's telling that even token gestures, and make no mistake - the CDR
db debacle was a show - were scuttled out of (misguided) principle.
miles away from touching even mundane recommendations...
technology out-pacing tort and policy for sure!

@_date: 2015-05-02 21:29:01
@_author: coderman 
@_subject: [tor-talk] Meeting Snowden in Princeton 
all technology is entrapment ;)
another quote i appreciated,
"Usability is critical. Lots of good crypto never got widely adopted
as it was too hard to use; think of PGP. On the other hand, Tails is
horrifically vulnerable to traditional endpoint attacks, but you can
give it as a package to journalists to use so they won?t make so many
mistakes. ... Engineers who design stuff for whistleblowers and
journalists must be really thoughtful and careful if they want to
ensure their users won?t die when they screw up. The goal should be
that no single error should be fatal, and so long as their failures
aren?t compounded the users will stay alive."
i posted on tor-dev about defense in depth for Tor Browser using a Tor
router device:
  my only contention is that the allowance for targeted attacks yields
too much to the adversary. the targeted SIGINT attacks of today will
be the opportunistic blackhat attacks of tomorrow. and so on,
best regards,
P.S. there's another point to be made about funding secure software
and product development.

@_date: 2015-05-02 21:39:22
@_author: coderman 
@_subject: [tor-talk] Meeting Snowden in Princeton 
the claim was not that Tor is immune to flaws. the point is that it
works. it is not systematically broken, otherwise Snowden would have
been neutralized early into tentative discussions with Laura, et. al.
it's also important to note that Tor was only part of Snowden's opsec,
which is a verbose tangent elided here.
citation needed. disclosure was delegated to reporters, as Snowden
himself collected details  that have demonstrated impact on US
interests, given only the reporting to date.
what Tor Project and EFF decisions have you felt abdicated to the government?
i have seen only positive efforts to diversify funding, advocate for
privacy, and support other organizations with interests that align
toward team-EarthHuman, and not team-NSA...
best regards,

@_date: 2015-05-02 22:32:16
@_author: coderman 
@_subject: [tor-talk] Meeting Snowden in Princeton 
funding. check. (a hard problem for anybody!)
mostly funding, disagreements over earth humans being decent to each other?
disagreements over earth humans being decent to each other?
earth humans being decent to each other? this is controversial?
you are misrepresenting and you know it.
as one still perma-moderated on full-disclosure, i am sympathetic to
heated discourse against long ignored or under served ills of infosec.
i may regret many words, later,
 yet how are these the fault of anyone but myself?
NSA, FBI, CIA and other privacy antagonists use Tor. i may not like
it, but i don't fault Tor Project for it either.
do you have any legitimate disaffections?

@_date: 2015-05-03 02:02:44
@_author: coderman 
@_subject: [tor-talk] Meeting Snowden in Princeton 
what part of "Will never compromise Tor" do you not understand?
educating law enforcement does not equate to capitulating to calls for
backdoors or weaknesses.
when the control port flaw was disclosed, a patch was committed within
8 hours - while Tor people were on the road at a security conference.
this is a record turn-around for any defect i have been involved with.
in terms of technical measures for security, Tor has a great track
record - even compared to projects with ten times their resources.
Tor _is_ the most effective model deployed. there are a great many
ideas about making it even better, and i don't see how Tor being
popular precludes making it better.
take a look at the datagram Tor related research to see just how
difficult / complicated some of these problems are.
 (userspace stacks, congestion controls, padding and reordering, etc... )
pro-active security posture, prompt resolutions to serious security
issues, attentive to new research and actively engaged with
educational and professional organizations.
any of these aspects speak well of Tor itself and the Tor Project around it.
perhaps disagreement based in technical merit should have been
requested. do you have any?
best regards,

@_date: 2015-05-03 17:32:00
@_author: coderman 
@_subject: [tor-talk] Meeting Snowden in Princeton 
hey Juan,
i'm turning over a new leaf and responding to your feedback with
promptness and detail. [0]
open source code in the open means heavy handed attempts to backdoor
or weaken are visible, and prone to discovery in the future. if you
have a diverse, engaged community of security conscious developers,
the odds of finding such a thing quickly is good, and you're also
going to find the oversights and bugs just as risky to security and
how do you trust the developers themselves? that's a hard question i
have no good answer for. i went to the Paris dev conference last
summer to get first hand view of environment around Tor devs, and meet
digital entities face to face... nation state security services
definitely interested, but seemingly effective without resorting to
exotic narco cartel threats in your vivid imagination.
notice that Tor browser builds are reproducible, and now (some) signed
by hardware token. these are all parts of building trust in the
software that gets distributed and executed by others.
how do you trust, along specific angles, the OPSEC, integrity(verity),
vigilance of a given developer? i don't have answers. one fun
anecdote, however, is trial by DEF CON, back in the day before it sold
out wholesale. not recommended, even then! :P
i trust serqet345qt265xp.onion more gmail, that's for sure. (gmail
nicely expresses my contempt for email, however.)
as for anything else, it's back to trusting trust and where do you
draw the line.  open development cannot force independent, competent
review of code and architecture - a highly demanded service in
industry and elsewhere.
are you contesting the appropriateness of any cooperation with law
enforcement what so ever?
or that education is really some nefarious secret collusion to screw Tor users?
please elaborate on the bla. thank you!
best regards,

@_date: 2015-05-06 03:18:13
@_author: coderman 
@_subject: [tor-talk] German University signs up 24 tor relays 
"Dodgson, Dodgson, we've got Dodgson here!"
 ... in other words, relays are inherently public.
more importantly, this is an opportunity for researchers to show good
faith by being forthcoming about the purpose and impact of their
efforts. if it is careful research, vetted by legal council and
supported by the institution, such heads up is reasonable.
if you're not aware of ethical considerations, working for the
[REDACTED], or using Tor exit traffic as unwitting guinea pigs,
  then your silence is suspect, and relays in such scenario deserving
of even more scrutiny.
my $0.02

@_date: 2015-05-08 19:21:29
@_author: coderman 
@_subject: [tor-talk] Friendly LAN bridge -- bad idea? 
there are also stream isolation concerns, see options
 IsolateClientAddr, IsolateSOCKSAuth, IsolateClientProtocol,
IsolateDestPort, IsolateDestAddr, etc.
better to have each client run their own Tor, and a router / gateway
which can tell Tor Launcher a specific bridge or PT for Tor network

@_date: 2015-05-26 12:41:07
@_author: coderman 
@_subject: [tor-talk] Hidden Service Scaling Summer of Privacy Project 
speaking for two,
- file distribution
- "web services", etherpad, ethersheet, webdav
- XMPP
- IRC
- overlay network (tun/tap)
file distribution and chat.
fragility; zooko's triangle. (see also namecoin and onion name service
experiments for bootstrap)
it would be nice to speak of hidden service establishment rates across
distinct number of onions, rather than a simple frequency counter.
specifically, high establishment rates over many onions is the most
performance intensive use case unless under attack of any myriad
conversely, if in a constrained environment like old computer or small
device, using only a couple onions, for light traffic is advised.
one word: blowback.
 [ maybe  ? gotta make lemonade, sweet sweet lemonade ]
in the 50G mirror experiment, even while under volatile network
conditions, this technique - using many concurrently active onions -
worked well and kept throughput and availability consistently robust.
bigsun dist uses 9 onions across three physical hosts, for reference.
 useful.
 useful.
both,  useful.
this should be a trac, wiki, or doc? :P
best regards,

@_date: 2015-05-27 11:20:44
@_author: coderman 
@_subject: [tor-talk] isolating multiple server requests 
ok, this is "stream isolation" and supported, as you discuss.
you can expire out oldest, but i don't think you'll find this a
problem in practice.
right; this is a big hammer - more than just isolation, although it
can be used to enforce isolation forward.
you can use stem to manually control / cull circuits and streams, too.
a back-up plan, perhaps.
right - you'd need to look at actual circuits via control port to know
for certain in all circumstances.
right; also trade-off's involved.
some Tor control port consumers restrict to only a few necessary
commands - thus eliminating the truly ugly and trivial attacks against
your anonymity using the control port against you.
stem is a nice python interface to do what you want. it is adding
complexity, but implemented thoughtfully the benefit would outweigh
see also options:
IsolateClientAddr, IsolateSOCKSAuth, IsolateClientProtocol,
IsolateDestPort, IsolateDestAddr, etc.
note that potentially only on by default are: IsolateClientAddr,
there is also a trac,
  Support Isolation by SCM_CREDENTIALS / SCM_CREDS for AF_UNIX
endpoints -  which may be relevant to
best regards,

@_date: 2015-10-31 17:17:12
@_author: coderman 
@_subject: [tor-talk] Diaspora, 
from Twitter
FATAL FLAW.
don't worry, it's not just you. i can't stand half measures!
(3/4 measures, with a plan to 4/4 are ok, though...)
i enjoy a silent room to myself for a quiet read, too. sometimes.
[ reading alone in silence is not quite a social activity, however. ]
half measures are fatal.
these two dominant modes boil down to one "anonymous" and one not.
where pseudonyms are now equivalent to TOTAL ANONYMITY in popular
headspace... for shame!
i dream of a space where the outcasts suddenly congregate in privacy
and comfort.
will they come, if it can be built?

@_date: 2015-11-12 02:24:36
@_author: coderman 
@_subject: [tor-talk] Did the FBI Pay a University to Attack Tor Users? 
conflating issues; let's pick apart,
can you stop evil relays from ever participating?
 No. however the design of Tor takes this into account through guard
selection, circuit building, consensus decisions, see
can you stop enough evil relays from routinely be selected in circuits
such that correlation like this is impossible?
 Probably! this is where better relay checking techniques (beyond the
usual exit checks) could help. Note that troubleshooting for tor-relay
community would be advantaged by more robust checks as well.
can you stop evil relays from using 0day attacks against users?
 No; 0day has, does, and will continue to happen. this is why defense
in depth is important - you don't know if you might one day fall into
a window of vulnerability to the wrong attacker and end up without
Tor's privacy protections.
yes, and this is annoying.
 see LizardSquad attempted Tor DoS.
this kind of crap sybil does not affect the anonymity of clients however!
this is the challenge. when an attacker is motivated, patient, well
funded, and exercising utmost stealth, it is very difficult to
distinguish their behavior from others in the world wide Tor relay
best regards,

@_date: 2015-11-21 04:10:05
@_author: coderman 
@_subject: [tor-talk] How does one remove the NSA Virus off the BIOS Chip 
it will be persistent but latent.
  e.g. after a time period of "unable to successfully implant in OS"
    it will quit trying. or maybe not! unknown unknowns, etc.
or maybe not! large variance between paid proprietary LE only exploit kit
 and truly exceptional nation state intelligence and exploitation techniques.
you should use the BIOS adventures below to find out.
 [the TAO-related Snowden leak details are informative]
mobile implants are observed "geofenced" by tower or stringray. by
activity of other apps. by network traffic. by time of day, ... this
is a long list :)
your router(s) are trash, now. (maybe you can directly flash, like
BIOS adventures below?)
capture is good first step, and if not in this instance perhaps the next.
capture is always useful! (via independent and not networked device)
you can open up and search for BIOS flash chip. if you're lucky it
will be a 3.3V SPI flash chip in 4 or 8MByte (they often measure in
bits, too, don't ask me why).
you can use a rPi to do it, even!
  that last is an SPI chip in my pair of ASUS B43J laptops - it is nice
to have a pair, saving the good one, in case something like this
happens. the stealthy stuff will betray power consumption and forensic
flash image digest values (sha256 of specific flash regions)
remember to adjust configuration parameters for SPI support if using the rPi.
i highly recommend the Shikra as well, however, it requires postal CUSTOMS. :)
 this is just the start, of course, but enough to give tells...
best regards,

@_date: 2015-10-05 16:00:36
@_author: coderman 
@_subject: [tor-talk] pidgin and tor 
the primary problem with Pidgin is libpurple [
 ] and a more appropriate mitigation
would be Qubes isolation, perhaps Whonix-Qubes on new 3.0. :)
as indicated in the thread, there are not any good alternatives.
xmpp-client and irssi-xmpp-otr, others quite weird usability wise.
   [old schoolers may disagree *grin*]
best regards,

@_date: 2015-10-08 19:53:02
@_author: coderman 
@_subject: [tor-talk] pidgin and tor 
"security vs. usability", as ever...
consider the Tor Browser PDF exploit that accessed $HOME for keys and other.
if Tor Browser (and Pidgin) are isolated from each other, this $HOME
type attack of reduced risk.
one example.
do you not see the benefit in isolating applications at risk of rogue
remote execution?
i agree it is not the only security measure, nor the most important.
but it is useful, and that is why i mention it. more useful would be
using a secure client, but, again, usability.
i disagree with this approach. make the secure usable. don't force
users to adapt to "secure".
so, you're going to design and implement a usable, secure chat and presence?
actually, i saw this Kickstarter the other day...  ;P
best regards,

@_date: 2015-10-11 17:36:22
@_author: coderman 
@_subject: [tor-talk] Question 
it would be fun to compare different Tor configurations:
 - Tor Browser
 - TAILS
 - Whonix / Whonix-Qubes
 - Qubes-TorVM
 - TransProxy [
 ]
have fun!

@_date: 2015-10-12 18:23:19
@_author: coderman 
@_subject: [tor-talk] pidgin and tor 
i appreciate education in all forms :)
i should have been more clear.
specifically, The vulnerability does not enable the execution of arbitrary code but
the exploit was able to inject a JavaScript payload into the local
file context. This allowed it to search for and upload potentially
sensitive local files.
The files it was looking for were surprisingly developer focused for
an exploit launched on a general audience news site, though of course
we don?t know where else the malicious ad might have been deployed. On
Windows the exploit looked for subversion, s3browser, and Filezilla
configurations files, .purple and Psi+ account information, and site
configuration files from eight different popular FTP clients. On Linux
the exploit goes after the usual global configuration files like
looks for .bash_history, .mysql_history, .pgsql_history, .ssh
configuration files and keys, configuration files for remina,
Filezilla, and Psi+, text files with ?pass? and ?access? in the names,
and any shell scripts. Mac users are not targeted by this particular
exploit but would not be immune should someone create a different
payload. [Update: we?ve now seen variants that do have a Mac section,
looking for much the same kinds of files as on Linux.]
usability is not just convenience. but i see why you conflate the two.
i'd rather have langsec, for sure!
let's discuss cost... one much closer (near-term practical) than the other!
awaiting your next treatise on the quantification of attack surface
using appropriate cohort analysis of similar risk pools.
best regards,

@_date: 2015-10-12 18:30:35
@_author: coderman 
@_subject: [tor-talk] Question 
there are also significant numbers of browser hardening and
configuration tuning for privacy, beyond just plugins and the Tor
this is the fun part!
(seeing how diff. plugins, browser capabilities affect the ability to
"de-anonymize" you, or affect your privacy)
you track current? ;)
TransProxy does indeed provide different results, depending on client
behind the proxy.
"Using a Tor circuit and exit" is sometimes synonymous with "Perfectly
and uniquely identified". E.g. doing it wrong. Also part of the fun!
it is indeed changed; the subtle differences the height of fun and
enjoyable learning.
best regards,

@_date: 2015-10-12 18:33:57
@_author: coderman 
@_subject: [tor-talk] Tor 
Private communications for all earth humans!
as noble an aim today as it was then. and forever a basic human right.
best regards,

@_date: 2015-10-12 18:43:41
@_author: coderman 
@_subject: [tor-talk] Mulihomed flag for nodes (from Re: why are some exit 
at times it is desirable to avoid the usual "knee-jerk" responses, however.
there is a trick, which is to monitor the consensus. any new relay
identity, or new IP associated with an existing entity.
on event of a new relay or IP, attempt an exit check.
if the exit is not currently in the listed DNSRBL, use it as quickly
as possible as "new-not-yet-blacklisted"
note that there are plenty already using this technique, and you must
race the horde, depending. (the people reading this in some search
engine cache surely spammers looking to maximize their abuse of the
Tor network. ;)
you may like my theory of the whole world going hidden service, soon
enough. since the public internet is all DEF CON wireless, whether you
admit it to yourself or not. *grin*
i'd like you to tell us more about these negative relay experiences.
i don't doubt them. but i find your misguided understanding of and
pre-occupation with only Tor's detriments interesting.
this quantified risk analysis at your disposal sounds quite useful.
looking forward to details!
you don't understand why this isn't practical. but that's ok.
totally different from AS for OR endpoint.
you're a considerate and careful Internet citizen, thank you!
multi-homed flag must die in a fire. don't even consider it!
best regards,

@_date: 2015-10-12 18:49:54
@_author: coderman 
@_subject: [tor-talk] Mulihomed flag for nodes (from Re: why are some exit 
note that multiple listen addrs for a relay (multi-homing) would be
fine in consensus. this "multi-homed exit behavior" flag is a farce,
best regards,

@_date: 2015-10-12 22:52:24
@_author: coderman 
@_subject: [tor-talk] Tor 
this is what's called an ancillary benefit.
 "teachable moments"

@_date: 2015-10-29 13:31:07
@_author: coderman 
@_subject: [tor-talk] A little more hostility towards Tor from Twitter 
yes. i am using an account only ever accessed via onion.
 [  ]

@_date: 2015-10-29 13:33:20
@_author: coderman 
@_subject: [tor-talk] A little more hostility towards Tor from Twitter 
i can't speak to "Real Names" policy, or verification requirements. it
seems you can be singled out for verification by any number of
feedback or automatic selection mechanisms...
best regards,

@_date: 2016-02-01 13:20:01
@_author: coderman 
@_subject: [tor-talk] Scripted installer of Tor and more being worked on 
please allow a single default jail.local to be used in one or any Tor
service port configurations, including hidden service port
then also allow each distinct configuration (IP:port, unix_domain,
etc) of any Tor service configuration to be blocked individually.
the latter is very useful for power users / multiple onion service
operators who use service isolation intentionally to mitigate concerns
of directed attacks, denial of service, or related risks.
(there might be a better way than a sane default, with optional
per-endpoint limits; that's my favorite approach to this question for
best regards,

@_date: 2016-02-04 18:17:17
@_author: coderman 
@_subject: [tor-talk] Using SDR 
where i have wanted SDR most is for wide area digital broadcast of Tor
consensus, for example, along with extended descriptor information,
perhaps over DVB-T bands adopted for the purpose (like the Sweedish
in terms of observability, it may actually be worse to use SDR links
unless they also provide strong authenticity and privacy guarantees at
the physical layer - WirelessWarrior discusses this in talks and
an interesting idea, even if not near-term practical :)
best regards,

@_date: 2016-02-06 04:22:57
@_author: coderman 
@_subject: [tor-talk] Using SDR 
this assumes you're keeping it under constant supervision, of course :P
one of my favorite tricks, but rather rude in spectrum,
 is setting high power amplifier to maximum. DF tends to see this
signal arriving from all around...  *grin*
this introduces it's own trade-offs, of course.
free space optics rides again!!  :P
right, UWB is the solution here with privacy and authenticity at the
physical layer (not above MAC, or other deferred placement in stack)
if you're building LPI, you don't give a fuck about the FCC (compliance).
 by definition, if they've found you, you fucked up!
it is now possible for a professional's budget to accodomate the SDR
equipment necessary to do this type of phase sync'ed active beam
forming MIMO transmission, and not all methods require the training
phase. in fact, omission of this (by out of band training, in a sense)
in a method of "keying" phased delivery of UWB MIMO in a way more
likely to achieve LPI.
synthetic aperature millimeter wave vision systems are also pushing
along this boundary, for cross-pollination of suitable phased sync'ed
UWB MIMO signal processing.
i could go on, if you're curious, but perhaps on another list? :)
best regards,

@_date: 2016-02-14 05:17:25
@_author: coderman 
@_subject: [tor-talk] [guardian-dev] orplug, 
with VPN approach you don't get to control traffic outside routed
range, or before VPN activates, or fail-safe if it drops
un-expectedly, or ...
it's better than nothing, for some less sensitive uses.
note that a tor enforcing gateway approach is preferable to
transparent proxy, security wise. e.g. corridor. i haven't seen this
applied to Android env, which might be interesting safety buffer
around Orweb&Orbot.
best regards,

@_date: 2016-02-22 06:43:47
@_author: coderman 
@_subject: [tor-talk] Large spike in .onion addresses - port scan? 
they're able to enumerate the onions which land on their node(s) per
O(1) mapping in HSDir participants. e.g. "get lucky"
see also: "Hidden Services Need Some Love"
 - best regards,

@_date: 2016-02-26 03:08:44
@_author: coderman 
@_subject: [tor-talk] FPGA Tor Relay 
more machines to saturate a gig link.
 in theory, future Tor will handle 10GigE at speed on single host :)
compression is the other area FPGA offload could assist with Tor as
is. more important is to make Tor concurrent(well threaded), then
focus on the exotic offloads...
aha, the thread need stated! carry on,
there used to be someone keeping track of the current node capacity
king pin. i don't recall what a saturated gigabit needed in terms of
best regards,

@_date: 2016-01-12 15:48:45
@_author: coderman 
@_subject: [tor-talk] Help me secure my setup 
this becomes particularly bad if the attacker has a way to trigger a
crash remotely  (like file descriptor exhaustion or conntrack
placing you in attack position next to them just a simple matter of patience...
just save state!  if not on the router, then an encrypted volume which
requires your intervention or ambient authority to activate.
best regards,

@_date: 2016-01-18 10:15:43
@_author: coderman 
@_subject: [tor-talk] transparent tor routers 
a recurrent theme. past discussion threads:
1. "[tor-dev] design for a Tor router without anonymity compromises"
  2. "[tor-relays] Anonbox Project - Mike Perry"
  3. "[tor-relays] Anonbox Project - Roger Dingledine"
  4. "[tor-talk] Cloak Tor Router"
  i still prefer the "Tor enforcing privacy router" approach instead.
then the router can act as a fail-safe for Tor instances running on
the client.
any other design will be misunderstood, to the detriment of (some)
users. instead of easy, why not correct? :)
best regards,

@_date: 2016-01-20 12:54:43
@_author: coderman 
@_subject: [tor-talk] Scripted installer of Tor and more being worked on 
interesting; thank you!
i did not see a way for general preferance of control socket, socks
socket, etc, over IP:Port in configs. this would be useful, but also
need graceful fallback as older Tor versions do not support socket
type for some services...  [codespelunking continues]
best regards,

@_date: 2016-01-31 14:42:47
@_author: coderman 
@_subject: [tor-talk] Scripted installer of Tor and more being worked on 
you're not going to find much "professional software developer" uptake
in your effort.
the professionals feel "configuration management" is the domain of
actual programming languages, like Python, or domain specific
constructs like cfEngine. they'll frown on your expedient bash swiss
army knife.
that said, i love bash for some specific niche circumstances. a
statically linked bash interpreter, coupled to a static busy box (or
one in the same) is indispensable at time when nothing else will do.
those times happen, even today! :)
let the haters hate, and best of luck to you Michael,

@_date: 2016-03-19 04:02:53
@_author: coderman 
@_subject: [tor-talk] Traffic shaping attack 
yes; it's a traffic confirmation attack, and by interrupting the flow
you confirm that the endpoints in question are involved in that flow.
best regards,

@_date: 2016-03-21 07:27:01
@_author: coderman 
@_subject: [tor-talk] Traffic shaping attack 
the problem with high traffic sites is a local confirmation attack.
E.g. your colo line is really active! and on a short list of suspects
above large traffic threshold.
an outage of your local link for 3-5 min leads to confirmation across
10,000 probe sessions, circuit extension attempts, and connect
attempts, all confirming yes indeed suspect hidden service suddenly
out of reach. [ is this sufficient *proof* for $context? who knows,
but you get the picture...]
at least now the feds can't pretend to be the technicians servicing
your outage under cover, anymore... ;)
attacks attempting to confirm a solitary client connecting to a peer
(e.g. very low degree node) are at different risk than those highly
centralized, very active services experience.
good luck to you! and please share insights and experience :)
best regards,
