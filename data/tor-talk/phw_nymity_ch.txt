
@_date: 2014-04-10 14:49:57
@_author: Philipp Winter 
@_subject: [tor-talk] Pogoplug: is safe enough against NSA? 
I had a look at the system and reported a number of problems to the developers.
That was about a month ago.  Unfortunately, I cannot give any details at this
point but I will post a full analysis once the problems are fixed.  In the
meanwhile, I would not use the Safeplug.

@_date: 2014-12-22 13:35:49
@_author: Philipp Winter 
@_subject: [tor-talk] Anonbib November papers without papers 
You are referring to the WPES and CCS papers.  The reason for that is
that WPES and CCS are conferences whose papers are published by the
academic publisher ACM.  ACM is one of the worst offenders in open
access.  You can only read their research papers after paying quite a
bit of money.  For people who are not affiliated with a university, it's
typically too expensive to obtain more than a few research papers.
That said, many researchers are nice enough to put their papers online
by themselves so that others can read them for free.  Somebody just has
to search for these papers and then add the pdf files to anonbib.

@_date: 2014-02-10 11:29:10
@_author: Philipp Winter 
@_subject: [tor-talk] IMAPS login errors 
Real MitM attacks typically don't cause "password incorrect" error messages.
Incidentally, there are two exit relays whose IMAPS traffic is modified by
"security" software:
The former uses a Fortinet device whereas the latter uses an antivirus scanner.

@_date: 2014-02-18 18:51:37
@_author: Philipp Winter 
@_subject: [tor-talk] torproject.org censorship detection using RIPE atlas? 
That's quite exciting -- thanks for sharing the data!
The probes might be using OpenDNS as their DNS resolver.  OpenDNS can block
website categories such as "proxy/anonymiser" which happens to contain
torproject.org.  When resolving a blocked domain, you are being redirected to
an OpenDNS page explaining what happened.  Every now and then, there are exit
relays which have the same problem.

@_date: 2014-07-02 16:26:25
@_author: Philipp Winter 
@_subject: [tor-talk] About Bandwidth rate, burst and observed. 
Atlas makes use of Onionoo as its backend and the semantics behind these
fields can be found in Onionoo's documentation:
In particular, you are interested in the fields are "bandwidth_rate",
"bandwidth_burst", "observed_bandwidth", and "advertised_bandwidth".

@_date: 2014-07-07 13:34:11
@_author: Philipp Winter 
@_subject: [tor-talk] What are the PPTOR relays? 
Tor's MyFamily option is used to announce that a set of relays is run by
the same operator.  Sometimes, relay operators fail to configure the
option which could explain what you witnessed.
At first glance, it looks like the PPTOR family correctly set the
MyFamily option (using fingerprints and nicknames).  See for example:
Among these relays, do you know which ones were part of your circuit?

@_date: 2014-07-10 11:42:16
@_author: Philipp Winter 
@_subject: [tor-talk] Atlas 
Atlas heavily depends on JavaScript and does not even have an active
maintainer, so the chance of seeing that is rather low.
There is also Globe [0] but it requires JavaScript, too.
[0]

@_date: 2014-07-30 20:08:56
@_author: Philipp Winter 
@_subject: [tor-talk] 'How to report bad relays' (blog entry) 
It depends on what's going on.  If we are dealing with bad
configuration, we tend to contact the operator before assigning the
BadExit flag.
If the relay is malicious, we flag it immediately.  Generally, malicious
relays do not have contact information because the operators have no
interest in contributing to the network.  However, a few days ago, we
had a relay which ran HTTPS MitM attacks against bitcoin trading sites.
We assigned the BadExit flag and then contacted the relay operator.  It
turned out that the relay was fine but a server in the same data center
as the relay was compromised and poisoned the ARP cache of all other
servers in the same LAN in order to break into their HTTPS.
No, the "every other day or week" was referring to the BadExit flag.
Note that BadExit does not make a relay disappear -- that's only the
case when the AuthDirReject option is used which happens "every other
month".  A BadExit flag only prevents clients from using the relay as
exit relay.  Such a relay continues to be part of the consensus and can
be selected for other hops.
That's a good question and a controversial topic.  Personally, I'd like
to see more transparency too but it's a sensitive trade-off.  By making
the process more and more public, we also make it easier for attackers
to adapt their behaviour and become harder to spot.
Rejected relays are not part of the consensus but relays which were
assigned the BadExit flag are.  Just Ctrl+F for "BadExit" on that page.

@_date: 2014-07-30 20:27:41
@_author: Philipp Winter 
@_subject: [tor-talk] Why make bad-relays a closed mailing list? 
Sorry, I must have missed that email.  First of all, thanks for your
feedback and for putting so much thought into this!
I think we need to distinguish between the report and the discussion.
Ultimately, a report that is acted upon *cannot* remain secret.  As soon
as a relay gets the BadExit flag, the operator can figure out that they
got caught.  As a result, I believe that the mere fact that a relay was
blocked (via BadExit or reject) can be published.  There is an ongoing
discussion if we should do that.
The discussion of observed malicious behaviour, however, can give the
attacker a lot of knowledge which they can exploit in order to evade
detection in the future.  Consider, for example, an HTTPS MitM attack
which targets a small number of web sites.  If somebody reports only one
of these targets, the attacker can spawn a new relay after discovery and
simply reduce the set of targeted sites in order to remain under the
radar.  This seems to be an uphill battle and it's difficult to have
full transparency without giving dedicated adversaries a big advantage.

@_date: 2014-07-31 16:12:33
@_author: Philipp Winter 
@_subject: [tor-talk] Why make bad-relays a closed mailing list? 
Yes, it is generally not a problem to publish a security bug which has
already been fixed.  In fact, it is encouraged because it spreads
knowledge and awareness.
Our situation is a slightly different one, though.  By publishing the
discussion about a relay (even if it has already been disabled), we are
harming future endeavours: As long as we keep using the same method to
check malicious relays, revealing this very method would "spoil it"
until we switch to a different one.  That's not quite the case with
security bugs.  If we had plenty of resources, scanning modules, and
methods, the story would be different but unfortunately that's not the
One good example is documented in a recent research paper [0].  Section
5.2 describes how we chased a group of related malicious exit relays
over several months.  At some point the attackers began to sample MitM
attempts and target web sites.  Publishing our actions would probably
have helped the attackers substantially.
I think in addition to publishing *which* relays were disabled, it would
also be safe to publish *why* they were disabled.  We could add a short
sentence along the lines of "running HTTPS MitM" or "running sslstrip".
Damian mentioned that in the other thread.
[0]

@_date: 2014-07-31 17:15:28
@_author: Philipp Winter 
@_subject: [tor-talk] Why make bad-relays a closed mailing list? 
It's not just about HTTP.  We've also seen attacks targeting SSH, SMTP,
IMAP, FTP, and XMPP.  While SSH's trust-on-first-use works reasonably
well and MitM attacks tend to be ineffective, XMPP is a different story
with at least one major client having had issues with authentication.

@_date: 2014-06-27 11:42:10
@_author: Philipp Winter 
@_subject: [tor-talk] Bad Exit Nodes. 
We recently did some work on that:
Long story short: Active attacks such as sslstripping are easy to detect
because they modify network traffic.  Passive attacks such as traffic sniffing
is more difficult to detect but you can catch sniffers if they later decide to
log in with sniffed credentials.
"Bad" typically means either malicious or misconfigured.  Some relays were
assigned the BadExit flag because their DNS resolver blocks domain categories
such as pornography or proxy/anonymiser.  BadExiting a relay is a last resort
and sending an email to the exit relay operator is typically enough to fix the
The relay iiioooeee has the BadExit flag because it is located in Iran.  Here's
the discussion leading to that:
The HKT relays are not malicious but seem to be subject to the Great Firewall's
DNS poisoning.  While that won't hurt you, it can be quite annoying when trying
to connect to web sites which are blocked in China.
HKT02 is not marked as bad yet because it is not clear if it's a good idea to
block all relays which sometimes return broken DNS records.  Many exit relays
use crappy resolvers and blocking all of them might be worse for the Tor
network than being redirected to unexpected web sites every now and then.

@_date: 2014-03-12 15:58:01
@_author: Philipp Winter 
@_subject: [tor-talk] TLS/SSL SMTP MitM 
Given that you used SSL SMTP, I assume your connection went to port 465?
I probed all ~400 currently available exit relays which allow exiting to port
465 but could not spot any MitM attacks yet.

@_date: 2014-03-24 15:09:55
@_author: Philipp Winter 
@_subject: [tor-talk] Fail to test scramblesuit. 
Note that you no longer need to use this custom obfsproxy branch.  The official
repository [0] now also contains ScrambleSuit.
We recently had to do some server maintenance.  The bridge should now be back
online.  You can get additional ScrambleSuit bridges from BridgeDB [1] but the
service is a little bit unreliable at this point.
[0] [1]

@_date: 2014-11-15 19:05:23
@_author: Philipp Winter 
@_subject: [tor-talk] "Hidden Services" vs "Onion services" 
The term "onion service" could supersede "hidden service" and an "onion
site" could simply be a web server set up as onion service.

@_date: 2014-11-16 18:28:22
@_author: Philipp Winter 
@_subject: [tor-talk] Simulators available for Tor Network 
It's not a simulator but you might still be interested in ExperimenTor:

@_date: 2014-10-13 14:45:14
@_author: Philipp Winter 
@_subject: [tor-talk] Double-checking a couple questions about node churn 
I'm late to the party but the following might also be helpful:
 Section 5.7.
 Section IV.A.
Interestingly, there is a non-trivial number of relays (identified by
fingerprint) which can only be seen in one consensus, i.e., they are
only part of the network for one hour.

@_date: 2015-04-05 17:55:16
@_author: Philipp Winter 
@_subject: [tor-talk] DNS hijacking 
What is the "real" IP address?  All exit relays that are currently
online resolve your domain to 185.53.179.29.
Also, your site seems to include Google AdSense code -- when fetched
over Tor as well as when fetched directly.

@_date: 2015-04-23 00:34:20
@_author: Philipp Winter 
@_subject: [tor-talk] SIGAINT email service targeted by 70 bad exit nodes 
While these relays account for 6% of the total number of exit relays,
they only sum up to 2.7% of exit probability, which is what really
Almost all of them were younger than one month and they seem to have
joined the network in small batches.  I uploaded Onionoo's
JSON-formatted relay descriptors, so everybody can have a look:
For example, to find out when all relays joined the network, run:
  grep -h first_seen * | sort

@_date: 2015-04-23 22:47:23
@_author: Philipp Winter 
@_subject: [tor-talk] SIGAINT email service targeted by 70 bad exit nodes 
Yes, I remember your list.  Thanks a lot for sharing it, it's really
The relays that are in your, but not in my list indeed look quite
similar to the rest.  They don't have a BadExit flag because nobody has
caught them doing something nasty yet.

@_date: 2015-04-27 20:43:02
@_author: Philipp Winter 
@_subject: [tor-talk] SIGAINT email service targeted by 70 bad exit nodes 
I'm not sure, unfortunately.
We don't really have any requirements.  Every case is different and
judged individually.
Maybe somebody started a Tor relay after breaking into them?
Not yet, but I hope to get to it later today.  It's certainly odd that
all these relays were in only a few data centers.

@_date: 2015-04-30 15:09:23
@_author: Philipp Winter 
@_subject: [tor-talk] What is being detected to alert upon? 
Here's how the Great Firewall does it:
And here are some thoughts on TLS handshake signatures that can be used
to fingerprint traffic:

@_date: 2015-04-30 15:13:46
@_author: Philipp Winter 
@_subject: [tor-talk] What is being detected to alert upon? 
That's probably not very effective because the Tor network has quite a
bit of churn, which would lead to plenty of false positives and false
negatives.  You would have to update this list pretty much hourly.

@_date: 2015-12-16 13:23:31
@_author: Philipp Winter 
@_subject: [tor-talk] Tor Historical Consensus Analytic 
The contact field is part of a relay's server descriptor, not of the
A while ago, I mirrored all consensuses and server descriptors from
Collector.  I just grepped the data for contact info strings that
contain ".it".  I found 385 matches, which I'll send you off-list.

@_date: 2015-01-12 23:40:10
@_author: Philipp Winter 
@_subject: [tor-talk] Using obfsproxy with OpenVPN 
What is the exact command you are trying to run?
Here's a working example of a server run in external mode:

@_date: 2015-01-21 11:06:01
@_author: Philipp Winter 
@_subject: [tor-talk] Which PTs shall we prioritize for inclusion in Tails? 
You shouldn't prioritise ScrambleSuit because it's superseded by obfs4.

@_date: 2015-07-28 14:20:44
@_author: Philipp Winter 
@_subject: [tor-talk] tor not running 
Last year, Andrew Lewman analysed the log files of his website mirror
to answer that question:
His number seems surprisingly high, but the analysis should be taken
with a grain of salt.  For example, users who find their way to a mirror
(instead of using the official web site) might be more technical, and as
a result more likely to verify downloads.  Also, the analysis did not
weed out bots and other noise.

@_date: 2015-06-04 10:52:01
@_author: Philipp Winter 
@_subject: [tor-talk] Recorded Future webinar on sniffing exit nodes 
I tried to attend this, but their website required you to have Java
installed, which I didn't have.
Did anyone watch this and can provide a summary?

@_date: 2015-06-05 11:10:45
@_author: Philipp Winter 
@_subject: [tor-talk] DocTor's 'Possible Sybil Attack' (2015-06-03) report 
I agree that it needs improvement.  In theory, we already have a public
repository for blacklisting relays:
In practice, nobody has had time yet to put all existing rules in the
new repository.  Also, it's called "authdirbadexit" and it would be
great if AuthDirReject and AuthDirInvalid rules could be published as
I attached a list of fingerprints that were rejected by the directory
authorities around May 20.  All these relays were HSDirs and actively
scanned hidden services they were responsible for.

@_date: 2015-06-05 11:21:54
@_author: Philipp Winter 
@_subject: [tor-talk] DocTor's 'Possible Sybil Attack' (2015-06-03) report 
Apparently the mailing list won't let me.  Here's a URL:

@_date: 2015-06-05 18:47:29
@_author: Philipp Winter 
@_subject: [tor-talk] DocTor's 'Possible Sybil Attack' (2015-06-03) report 
The relay list I put online?  By fingerprint.
It means port scans, as far as I know.  Maybe Donncha can elaborate
since he worked on this.

@_date: 2015-06-27 13:18:24
@_author: Philipp Winter 
@_subject: [tor-talk] A month with BADONIONS 
The relay wasn't blacklisted and disappeared on its own.
Chloe is right in saying that the BadExit process could work better.
Similar to so many other projects, there are not enough people to keep
up with all the work.  The little resources we have we tend to spend on
more serious attacks.  That is not to say that traffic sniffing is
harmless, but we are forced to prioritise.

@_date: 2015-05-20 16:30:09
@_author: Philipp Winter 
@_subject: [tor-talk] google meek server returns 403 error to Iranian IPs ! 
There is also meek-azure and meek-amazon, but they might have the same
issue with sanctions.  You might be better off with the obfs4 pluggable

@_date: 2015-05-20 17:10:04
@_author: Philipp Winter 
@_subject: [tor-talk] reverse enumeration attacks on bridges (re: 100-foot 
If the hostile relay has no Guard flag, it shouldn't receive direct
connections from clients.  If it does have the Guard flag, it could port
scan the previous hop to see if it has an open (OR) port.  (Active
probing-resistant bridges would leave some uncertainty, though.)
Some more details about this attack are in Section III.D of:

@_date: 2015-11-29 19:31:52
@_author: Philipp Winter 
@_subject: [tor-talk] TOR and Obfsproxy packet size 
The difference is caused by the protocol headers that are wrapped around
Tor cells; IP, TCP, and TLS.
How did you run your test?  543 sounds like the TCP segment length and
not like the length of the IP packet.
Also, obfsproxy is just a framework.  Which obfuscation protocol did you
run?  Obfs3?
First, Tor has static-length and variable-length cells, so it's not
entirely fixed.  Second, what actually ends up on the wire isn't only up
to the tor client.  It depends on TCP, which tries to fill the link MTU
if there's enough data in the send buffer.
You should read the peer-reviewed version of this paper instead:

@_date: 2016-01-14 12:51:31
@_author: Philipp Winter 
@_subject: [tor-talk] Escape NSA just to enter commercial surveillance? 
Logging in to Facebook over Tor reveals your identity, but not your
location.  Facebook still does not know if you are logging in from
Angola or Indonesia.  Also, Facebook doesn't get to learn your operating
system or your browsing history.
Privacy tools must be policy-agnostic to experience widespread adoption.
And widespread adoption is what Tor needs to guarantee better anonymity.
As you point out, it is important to remind people of the dangers of
using Facebook.  However, it should be up to the user to decide if she
wants to use Facebook or not.

@_date: 2016-07-18 11:49:22
@_author: Philipp Winter 
@_subject: [tor-talk] Which Dns? 
I assume this is for a Tor relay?
If you plan to run an exit relay, you should avoid third party
resolvers.  Google currently gets to see ~35% of all DNS requests coming
out of the Tor network.  We shouldn't hand any organisation such data on
a silver plate.
If you don't want to use your ISP's resolver, I recommend setting up
your own, local DNS resolver such as unbound.  Recent versions of
unbound implement qname minimisation, which is a great feature for exit
relays as it minimises the exposure to some network-level adversaries.
Quoting Peter's quick guide [1] on setting up unbound:
[1]

@_date: 2016-06-07 17:02:43
@_author: Philipp Winter 
@_subject: [tor-talk] The Aqua design (was: A possible solution to traffic 
The Aqua design goes in that direction.  It is a traffic
analysis-resistant anonymity system for BitTorrent:
It handles traffic at the network edges differently than the core, to
achieve low-latency resistance to traffic analysis.  At the edges, it
dynamically groups clients with similar usage patterns together to
provide k-anonymity.  The network core consists of nodes that exchange
constant-rate traffic that is padded when necessary.
However, Aqua cannot protect against long-term intersection attacks and
the authors haven't really thought about incentives for joining the
network; I could see the network only being used for illegal file
sharing, making it an attractive target for blocking with low collateral

@_date: 2016-06-22 18:36:57
@_author: Philipp Winter 
@_subject: [tor-talk] Latest Research Trends in Tor Security 
In general, have a look at AnonBib: Here are three important topics off the top of my head:
- Tor is an overlay network, which brings with it a number of problems.
  Recently, folks have been working on ways to move anonymity networks
  to lower layers in the network stack.  That includes systems such as
  LAP (Security and Privacy 2012), Dovetail (PETS 2014), and HORNET (CCS
  2015).
- A lot of work went into making Tor more resistant to censorship.  All
  relevant papers are on: - Some folks have tried to come up with better path selection algorithms
  for Tor, e.g., algorithms that have an understanding of Internet
  topology.  That includes:
  * "AS-awareness in Tor path selection" by Edman and Syverson
  * "LASTor: A Low-Latency AS-Aware Tor Clien" by Akhoondi et al.
  * "Measuring and Mitigating AS-level Adversaries Against Tor" by
    Nithyanand et al.
Depending on what exactly you mean by security (e.g., crypto,
end-to-end correlation, website fingerprinting, ...), there are more
sub-fields to look into.

@_date: 2016-03-30 11:01:51
@_author: Philipp Winter 
@_subject: [tor-talk] CloudFlare blog post 
My blog comment is still awaiting moderation, so I'll post it here too:
I don't see any mention of a client-side PoW scheme in the draft, which
may be good because it seems difficult to discourage attackers
sufficiently while not inconveniencing users too much.  See also:
I am also skeptical about the sentence "Based on data across the
CloudFlare network, 94% of requests that we see across the Tor network
are per se malicious."  I would really like to hear about the method you
used to get to that number and what, exactly, you classify as
"malicious."  For example, for how long did you observe requests coming
out of the network? After all, you justify the use of CAPTCHAs with this
high number, so it would be great if we could all verify the problem.
I also wonder how effective your CAPTCHAs really are.  Deep learning
techniques suggest that bots are about to become just as good, or even
better, at solving CAPTCHAs than people.  Therefore, I wonder if a long
term solution should also center around the question if the distinction
between people and machines is still meaningful.
Still, thanks for trying to improve the situation.

@_date: 2016-10-14 11:09:44
@_author: Philipp Winter 
@_subject: [tor-talk] Tor DNS Deanonymization 
I am one of the authors.  While the attack is very precise in our
simulations, it only works in a specific situation.  On the complexity
spectrum, the attack is in between website fingerprinting (the attacker
observes or is your guard relay) and end-to-end correlation (the
attacker sees both ends).
In our setting, the attacker must observe traffic to your guard (or be
your guard) *and* your DNS requests.  That's easier than end-to-end
correlation because, depending on an exit relay's setup, DNS requests
can traverse quite a lot of autonomous systems, which benefits
network-level adversaries.  Summing up, your neighbour will have a hard
time mounting the attack, but not necessarily your government.
There are two ways to mitigate the issue.  First, we need better
defences against website fingerprinting, so an attacker learns less by
observing the connection to your guard relay.  Second, we need to
improve the DNS setup of exit relays.  I would like to see less relays
use Google's resolver, and we need to move towards encrypted DNS.

@_date: 2016-10-18 10:39:59
@_author: Philipp Winter 
@_subject: [tor-talk] Tor DNS Deanonymization 
Generally, the longer exit relays cache domains, the less precise the
attack.  The trade-off is illustrated in Figure 10b in our paper [0].
At the moment, exit relays cache domains for only 60 seconds [1],
regardless of the domain's TTL.  If that bug is fixed, the attack
becomes a bit harder to mount.  It can become even harder if exit relays
were to cache each domain for, say, 10 minutes or more.
[0] [1]

@_date: 2017-02-15 12:10:05
@_author: Philipp Winter 
@_subject: [tor-talk] What is preventing Bridge Enumeration? 
That is indeed a problem.  Section III.D of the following paper talks
about the issue in greater detail:

@_date: 2017-07-19 13:36:54
@_author: Philipp Winter 
@_subject: [tor-talk] Anecdotical experience of SSH MITM 
I could confirm the issue.  The relay will no longer be part of the
network consensus once enough directory authorities updated their
config -- hopefully in a couple of hours.
In the future, please send such reports to our bad-relays@ mailing list
to make sure that they are seen by the right people:

@_date: 2017-07-19 16:02:57
@_author: Philipp Winter 
@_subject: [tor-talk] Systematically finding bad relays (was: Anecdotical 
Yes, the blog post I linked to contains some more information.  We are
using tools such as exitmap [1] to systematically scan the network for
attacks such as DNS poisoning, SSL stripping, HTTPS MitM, and XMPP MitM,
just to name a few.  We are always looking for more ideas on what to
scan for, so let us know if you have any!
[1]

@_date: 2017-07-19 18:30:23
@_author: Philipp Winter 
@_subject: [tor-talk] Systematically finding bad relays (was: Anecdotical 
The Tor Project maintains a second repository with more modules.
Unfortunately this repository is private because we are in an uphill
battle that is already difficult -- without our adversaries being able
to see what we scan for.  Here's some more information on that:
Modules for that would be great.  If only there were more volunteers
working on these issues!
The module "patchingCheck" (in src/modules/) does this for an executable
that's hosted on live.sysinternals.com.  Or were you thinking of
something else?

@_date: 2017-07-23 12:51:29
@_author: Philipp Winter 
@_subject: [tor-talk] Tor Router 
That was probably NetAidKit: Note that devices like that are notoriously difficult to get right.  The
last attempt I'm aware of was the Safeplug and it had severe security

@_date: 2017-10-27 17:06:18
@_author: Philipp Winter 
@_subject: [tor-talk] Perceived safety of Tor Browser and onion services 
This is the third part of our preliminary analysis of how Tor users
interact with onion services [0].  In this part, we look at the
subjective feeling of safety that people experience when using Tor
Browser and onion services, respectively.
Question 6.6 in our survey asked:
We deliberately did not define "safe," to leave the interpretation up to
our participants.  Here's the breakdown:
                  Safer  Less safe  Neutral
    ---------------------------------------
    Experts      72.24%      6.31%   21.45%
    Non-experts  58.48%     10.71%   30.80%
Experts [1] tend to feel safer on onion services than non-experts [2].
One explanation is that experts' understanding of the underlying
technology gives them more confidence in identifying and fighting off
phishing attacks etc.  Besides, experts may be less influenced by media
reports that focus on the shadier aspects of the "Dark Web."
Another issue is that non-technical users often don't distinguish
between more nuanced aspects of anonymity.  Some of our interview
participants expressed that there's no point in logging in to services
over Tor because "if I log in they know who I am."  Concepts such as
location anonymity, self-authenticating names, and end-to-end encryption
elude them.
The next question in our survey asked our participants to explain their
choice.  Here are the most prevalent themes:
- The underlying technology of onion services (self-authenticating
  names, end-to-end encryption) overwhelmingly made our participants
  feel safe.  People expect a clear improvement in security compared
  to the use of normal websites.
- Orthogonal to the technology, many participants voiced concern about
  illegal, sketchy, and questionable content on onion services.  The
  term "wild west" was used occasionally.  Phishing sites, honeypots,
  and compromised onion sites were also a concern.
- The lack of advertising companies on onion services was mentioned as a
  good thing by several participants.
- A handful of participants complained that it is difficult to know if
  you ended up at the right onion site or a phishing site.
Now let's look at Tor Browser.  Question 6.4 asked:
                  Safer  Less safe  Neutral
    ---------------------------------------
    Experts      86.16%      5.97%    7.86%
    Non-experts  83.33%      5.26%   11.40%
Interestingly, the difference between both demographics is significantly
smaller here, presumably in part because Tor Browser is widely seen as a
content-agnostic tool while onion services are frequently associated
with the content that they are perceived to host.
Again, the next question asked our participants to explain their choice.
Here are the most prevalent themes:
- Non-experts lack the ability to evaluate or understand Tor's
  design which is why they defer to expert opinion, their gut feeling,
  or the trust they have in Tor developers.  The Tor Project is
  perceived to focus more on privacy and security than any other browser
  vendor, which many participants appreciated.  Also, its transparency
  further contributes to the trust people have.
- Most of the security criticism focused not on Tor Browser but on the
  underlying Firefox code base.  Many participants were unhappy with the
  exploit mitigation techniques, lack of sandboxing, and the complex
  code base.  Chrome was sometimes brought up as the golden standard for
  browser security.
- Malicious exit relays were a concern for a handful of participants.
- A couple of participants feel safer when using Tor Browser but are
  concerned that their use of Tor makes them stick out and turn into a
  target for government agencies.
- Some participants weren't sure if their Tor setup works properly.
  This is a common theme that we also noticed in our interviews.
  Non-technical users want visual feedback that shows that their network
  traffic comes out "somewhere else."
The above was joint work with my colleagues Marshini Chetty, Annie
Edmundson, Nick Feamster, and Laura M. Roberts.
[0] [1] Participants who stated that they are either "highly knowledgeable"
    or an "expert" in Internet security.
[2] Participants who stated that they have either "no knowledge," are
    "mildly knowledgeable," or "moderately knowledgable" in Internet
    security.
