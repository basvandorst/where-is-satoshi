
@_date: 2005-11-10 11:45:45
@_author: cyphrpunk 
@_subject: Hacker strikes through student's router 
What if we had a Tor network where exit node operators made Tor-money,
and Tor-money was necessary to use the network? Or perhaps, Tor-money
at least gave you priority in using the network, so all those P2P
traders wouldn't slow you down so much? Maybe exit node operators
could even sell their Tor-money for real cash, to potential Tor users.
People tend to have two contradictory views about proposals like this.
One is that such a Tor network would never work, because people would
prefer to use the free one. The other is that free Tor networks will
never work, because no one will take the heat to run an exit node.
The point is that this proposal cuts the knot and creates a
self-sustaining Tor-style network, one which rewards people who take
the risk of running exit nodes, just as in Anthony's example about
WiFi hotspots.
One technical problem is verifying that a particular exit node is
legit, so that its operator can get his Tor-bucks. It might be enough
to put Tor-money in the packet so that the last node receives it, but
then he could skim the cash without performing the service of letting
the packets go out. Still, this would be easily detected and users
could blacklist exit nodes which didn't perform, so it might be
Obviously an ecash-integrated Tor network is an ambitious project, but
it is something to think about if Tor starts running into problems
with people not wanting to run exit nodes.

@_date: 2005-11-11 17:44:49
@_author: cyphrpunk 
@_subject: Hacker strikes through student's router 
You might look at hashcash.org or rpow.net which both use ideas like
this. Hashcash is based on hash collisions of n bits, such that it
takes about 2^n tries to generate an n-bit hashcash token. The rpow
system came out last year and was supposed to let people exchange
hashcash for ecash via a centralized server, but I'm not sure of its
current status.
To make this more concrete, when you set up a Tor circuit the
originator would "pay" the exit node using hashcash. Then you'd want
to have the exit node re-use those hashcash tokens for its own Tor
activities, or sell them on some kind of market to other Tor users.
One thing to think about is how expensive this should be, in terms of
CPU time. If you make it too cheap, hashcash that just takes a few
seconds to generate, then it's not much of a reward for exit node
operators. If you make it too costly then it becomes a burden to using
the system, for people who don't run exit nodes.
A unique feature of anonymity systems is that usage is a public good:
the more the system is used, the better the anonymity. More users
means a bigger crowd to hide within. You don't want to tune the system
to make it so expensive that no one can afford to use it. At the same
time, a pseudo-financial incentive could motivate people to donate
resources to the project. It would be interesting to see some
experiments along these lines.

@_date: 2005-11-03 15:06:37
@_author: cyphrpunk 
@_subject: Wikipedia and Tor - a solution in the works? 
Or even money! The mechanism by which the server makes new tokens hard
to get would be up to the server operator. The point is that it is
supposed to be bad if you lose one, you can't just get another.
(or even harder)
Right, so here's the problem. Wikipedia, every other wiki, and every
blog site, must change their software to recognize tokens as an
alternative to IP addresses. This solution still requires the net to
rewrite itself to accommodate Tor.
My solution goes in the other direction. I propose a server which will
let the net work the way it does now, filtering by IP, while still
letting anonymous Tor users not be blocked due to the misbehavior of
others. We centralize the token-to-IP mapping in one server which is
token-aware and don't require every web service on the net to be
rewritten. It's a much better solution.

@_date: 2005-11-09 16:04:44
@_author: cyphrpunk 
@_subject: Hacker strikes through student's router 
A gunshot rings out from a man's house and a passer-by falls to the
ground. But when the authorities come to arrest him, they find that he
didn't fire the gun! It was aimed out the window but hooked up to the
Internet. Anyone online could aim and fire the gun. Who is at fault?
The point of this parable is that you can't escape responsibility
simply by delegating it.
Tor can be justified, but it must be done by balancing the good
against bad that it offers. You can't just sit back and rely on
absolute principles that anonymity is good and that it justifies any
evil side effects. Everything is a balancing act. If society decides
that the kind of anonymity offered by Tor causes more harm than good,
it will not exist.
I would point to my earlier suggestion to use something like the "nym"
software to limit the amount of damage that any particular bad actor
could cause. An anonymous gateway can allow only authorized users to
go through without knowing who anyone is, but still be able to
blacklist those who misbehave. This could be an enhancement to Tor
which would allow socially good uses of anonymity to continue freely
while providing a mechanism to limit bad uses. Rather than rejecting
this approach out of hand on philosophical grounds, the Tor community
should seriously consider the need to coexist with a larger society
and to find ways to make Tor more beneficial and less harmful.

@_date: 2005-10-01 15:27:32
@_author: cyphrpunk 
@_subject: nym-0.2 released (fwd) 
All these degrees of indirection look good on paper but are
problematic in practice. Each link in this chain has to trust all the
others. Whether the token server issues tokens freely, or the CA
issues certificates freely, or the gateway proxy creates client
identifiers freely, any of these can destroy the security properties
of the system. Hence it makes sense for all of them to be run by a
single entity. There can of course be multiple independent such
pseudonym services, each with its own policies.
In particular it is not clear that the use of a CA and a client
certificate buys you anything. Why not skip that step and allow the
gateway proxy simply to use tokens as user identifiers? Misbehaving
users get their tokens blacklisted.
There are two problems with providing client identifiers to Wikipedia.
The first is as discussed elsewhere, that making persistent pseudonyms
such as client identifiers (rather than pure certifications of
complaint-freeness) available to end services like Wikipedia hurts
privacy and is vulnerable to future exposure due to the lack of
forward secrecy. The second is that the necessary changes to the
Wikipedia software are probably more extensive than they might sound.
Wikipedia tags each ("anonymous") edit with the IP address from which
it came. This information is displayed on the history page and is used
widely throughout the site. Changing Wikipedia to use some other kind
of identifier is likely to have far-reaching ramifications. Unless you
can provide this "client idenfier" as a sort of virtual IP (fits in 32
bits) which you don't mind being displayed everywhere on the site (see
objection 1), it is going to be expensive to implement on the wiki
The simpler solution is to have the gateway proxy not be a hidden
service but to be a public service on the net which has its own exit
IP addresses. It would be a sort of "virtual ISP" which helps
anonymous users to gain the rights and privileges of the identified,
including putting their reputations at risk if they misbehave. This
solution works out of the box for Wikipedia and other wikis, for blog
comments, and for any other HTTP service which is subject to abuse by
anonymous users. I suggest that you adapt your software to this usage
model, which is more general and probably easier to implement.

@_date: 2005-10-02 09:12:18
@_author: cyphrpunk 
@_subject: nym-0.2 released (fwd) 
A few comments on the implementation details of
1. Limting token requests by IP doesn't work in today's internet. Most
customers have dynamic IPs. Either they won't be able to get tokens,
because someone else has already gotten one using their temporary IP,
or they will be able to get multiple ones by rotating among available
IPs. It may seem that IP filtering is expedient for demo purposes, but
actually that is not true, as it prevents interested parties from
trying out your server more than once, such as to do experimental
hacking on the token-requesting code.
I suggest a proof of work system a la hashcash. You don't have to use
that directly, just require the token request to be accompanied by a
value whose sha1 hash starts with say 32 bits of zeros (and record
those to avoid reuse).
2. The token reuse detection in signcert.cgi is flawed. Leading zeros
can be added to r which will cause it to miss the saved value in the
database, while still producing the same rbinary value and so allowing
a token to be reused arbitrarily many times.
3. signer.cgi attempts to test that the value being signed is > 2^512.
This test is ineffective because the client is blinding his values. He
can get a signature on, say, the value 2, and you can't stop him.
4. Your token construction, sign(sha1(r)), is weak. sha1(r) is only
160 bits which could allow a smooth-value attack. This involves
getting signatures on all the small primes up to some limit k, then
looking for an r such that sha1(r) factors over those small primes
(i.e. is k-smooth). For k = 2^14 this requires getting less than 2000
signatures on small primes, and then approximately one in 2^40 160-bit
values will be smooth. With a few thousand more signatures the work
value drops even lower.
A simple solution is to do slightly more complex padding. For example,
concatenate sha1(0||r) || sha1(1||r) || sha1(2||r) || ... until it is
the size of the modulus. Such values will have essentially zero
probability of being smooth and so the attack does not work.

@_date: 2005-10-02 19:03:26
@_author: cyphrpunk 
@_subject: nym-0.2 released (fwd) 
That makes sense, although it does add some complexity for the end
user, having to figure out how to get his certificate into his
browser. Adam Langley's suggestion to cut and paste the token into a
login field at the gateway proxy would be simpler for the user. The
proxy could then set the token in a browser cookie which would make it
available on every access.
My suggestion was even simpler. The mere fact that a connection was
allowed through by the gateway proxy implicitly certifies that it is
complaint-free. There is no need for client identifiers. Rather, the
proxy would keep a table of which outgoing IPs at which times mapped
to which tokens. The proxy would handle a complaint by invalidating
the token that was used at the time the problem occurred. This is
simpler than your client identifier, provides more user privacy, and
should work out of the box with Wikipedia, which must use a similar
complaint resolution mechanism with ISPs that dynamically assign IPs
to users.

@_date: 2005-10-29 21:57:34
@_author: cyphrpunk 
@_subject: Wikipedia and Tor - a solution in the works? 
I agree with this concept, but I think you are focusing too narrowly
on Wikipedia.  The general case is:
trusted user -> tor cloud -> authentication server -> whatever
The point is, as Jimmy Wales notes, what constitutes abuse is not that
different for Wikipedia than for other wikis, for blog spam, for email
spam, and for many other services on the net. An authentication server
that only allows trusted users through is a generally useful
I am working on software to provide this service. It is slow going due
to the complexity, but I will hopefully have something working in a
few weeks. Here is a brief description.
The authentication server can be thought of as a proxy which only
serves a set of "customers in good standing". Like a Tor exit server,
it applies its own policies to filter outbound connections to whatever
the server operator thinks is appropriate. However the main point of
the proxy server is to accept anonymous connections outbound from Tor
(or any similar anonymity service), to verify that they are associated
with good customers, and to pass them on. In this way, anonymous users
can still access sites that block Tor exit nodes and those of other
anonymity services.
Although connections through the authentication server are anonymous,
cryptography is used to associate each connection with a unique
identifier. If the authentication server gets a report back of bad
behavior by one of its customers, the identifier in use at the time of
the abuse can be put on a blacklist. More crypto allows each user to
prove that he is not on the blacklist, while still retaining his
anonymity. Keeping the multiple uses of the authentication server
unlinkable provides an important element of privacy. Otherwise the
authentication server could build up profiles about the places which
each nym likes to visit, and possibly correlate that with the use of
various pseudonyms on the net.
The result is that the authentication server is something like an
"anonymous ISP" in terms of having a set of customers that go through
the server, and being responsible for cancelling the accounts of
customers who misbehave. Because it is responsive to complaints from
services on the net, the authentication server should be able to avoid
being blocked and can maintain the ability for good customers to
continue to be first class users of the net even while being
The details are beyond the scope of this note, but the idea is similar
to the mechanism used by Jason Holt in his nym software. Users would
register for the service via some mechanism that makes it expensive.
Perhaps this involves using their real names and/or email addresses,
or maybe it could even cost money. On this basis they get what is
essentially a blind signature, although the technology is not based on
Chaum. They can then show this signature anonymously and unlinkably to
other showings (this is where it goes beyond Chaum). At the same time
they commit to their signed value and are able to prove that their
commitment is different from any of those on the blacklist.
Running the authentication server will take a certain amount of
commitment on the part of the operator. He must respond to complaints
fairly and expeditiously, and maintain the blacklist. He needs to set
his policies for exit connections, and for how to make it expensive to
create new accounts. It would nevertheless be a highly useful service
for anonymous users and would therefore increase the spread of

@_date: 2005-10-04 11:35:43
@_author: cyphrpunk 
@_subject: Hooking nym to wikipedia 
This is a good summary of the issues. With regard to turning client
certs on and off: from many years of experience with anonymous and
pseudonymous communication, the big usability problem is remembering
which mode you are in - whether you are identified or anonymous. This
relates to the technical problem of preventing data from one mode from
leaking over into the other.
The best solution is to use separate logins for the two modes. This
prevents any technical leakage such as cookies or certificates.
Separate desktop pictures and browser skins can be selected to provide
constant cues about the mode. Using this method it would not be
necessary to be asked on every certificate usage, so that problem with
certs would not arise.
(As far as the Chinese dissident using net cafes, if they are using
Tor at all it might be via a USB token like the one (formerly?)
available from virtualprivacymachine.com. The browser on the token can
be configured to hold the cert, making it portable.)
Network eavesdropping should not be a major issue for a pseudonym
server. Attackers would have little to gain for all their work. The
user is accessing the server via Tor so their anonymity is still
Any solution which waits for Wikimedia to make changes to their
software will probably be long in coming. When Jimmy Wales was asked
whether their software could allow logins for "trusted" users from
otherwise blocked IPs, he didn't have any idea. The technical people
are apparently in a separate part of the organization. Even if Jimmy
endorsed an idea for changing Wikipedia, he would have to sell it to
the technical guys, who would then have to implement and test it in
their Wiki code base, then it would have to be deployed in Wikipedia
(which is after all their flagship product and one which they would
want to be sure not to break).
Even once this happened, the problem is only solved for that one case
(possibly also for other users of the Wiki code base). What about
blogs or other web services that may decide to block Tor? It would be
better to have a solution which does not require customization of the
web service software. That approach tries to make the Tor tail wag the
Internet dog.
The alternative of running a pseudonym based web proxy that only lets
"good" users pass through will avoid the need to customize web
services on an individual basis, at the expense of requiring a
pseudonym quality administrator who cancels nyms that misbehave. For
forward secrecy, this service would expunge its records of which nyms
had been active, after a day or two (long enough to make sure no
complaints are going to come back).
As far as the Unlinkable Serial Transactions proposal, the gist of it
is to issue a new blinded token whenever one is used. That's a clever
idea but it is not adequate for this situtation, because abuse
information is not available until after the fact. By the time a
complaint arises the miscreant will have long ago received his new
blinded token and the service will have no way to stop him from
continuing to use it.
I could envision a complicated system whereby someone could use a
token on Monday to access the net, then on Wednesday they would become
eligible to exchange that token for a new one, provided that it had
not been black-listed due to complaints in the interim. This adds
considerable complexity, including the need to supply people with
multiple initial tokens so that they could do multiple net accesses
while waiting for their tokens to be eligible for exchange; the risk
that exchange would often be followed immediately by use of the new
token, harming unlinkability; the difficulty in fully black-listing a
user who has multiple independent tokens, when each act of abuse
essentially just takes one of his tokens away from him. Overall this
would be too cumbersome and problematic to use for this purpose.
Providing forward secrecy by having the nym-based web proxy erase its
records every two days is certainly less secure than doing it by
cryptographic means, but at the same time it is more secure than
trusting every web service out there to take similar actions to
protect its clients. Until a clean and unemcumbered technological
approach is available, this looks like a reasonable compromise.

@_date: 2005-10-08 14:31:48
@_author: cyphrpunk 
@_subject: Wikipedia proposal 
You haven't defined what "wp" means at this point. At first I thought
it meant "web proxy" but actually in this context it is probably
wikipedia. Presumably the readers on wikipedia-l won't suffer this
There doesn't seem to have been any response so far to your
suggestion. The problems of Tor users are outside the interests of
mainstream wikipedia developers. This is part of why I prefer a system
such as I suggested earlier, a web proxy which only lets complaint
free nyms go through. This would not require any changes at all to
wikipedia (at the expense of requiring a nym administrator to handle
Even if you manage to change the wikipedia code to use a client cert
identifier in place of remote IP under some circumstances, you will
still have to convince them to incorporate your patches. It's not
clear that adding this support will be a high enough priority for them
that they will be willing to do so, as evidenced by their lack of
interest in your idea.

@_date: 2005-09-27 17:25:07
@_author: cypherpunk 
@_subject: Hello directly from Jimbo at Wikipedia 
As an occasional Tor and Wikipedia user, let me add a couple of points.
First, in case it is not obvious, the problem with the present system
is that Tor users can no longer edit on Wikipedia. I have done so in
the past, in what I like to think is a constructive manner, but cannot
do so since this summer. I have valid although perhaps unpopular
contributions to make, and not only is my freedom to express myself
limited, the quality of the material on Wikipedia suffers due to the
absence of my perspective. The status quo is not acceptable and we
should work to find a solution.
Looking at the proposals for authentication servers and such, I see a
major issue which is not being addressed. That is, how does the web
server distinguish "authenticated" Tor users from unathenticated ones?
If this is via a complicated protocol, there is no point as the
servers won't use it.
The hard truth is this: the distinction must be done on the basis of
IP address. That is, there must be a separate set of Tor exit nodes
which are only for authenticated users.
This does not necessarily mean building complex authentication
protocols into the Tor network, and having two classes of traffic
flowing around. It could be that this authenticated Tor is a separate
network. It only lets users in who are authenticated, and owns a
specific set of IP addresses which servers can whitelist. The regular
Tor exit nodes can be blacklisted as they are now.
The technical problem is then, how to achieve as much anonymity as
possible in the authenticated network, while still providing the abuse
prevention services which Wikipedia and other servers will require in
order to whitelist the nodes.
What does Wikipedia need? What is the minimum level of service they
require? Presumably, it is similar to what they can get via ISPs, who
also map many users to a fixed set of IP addresses. Wikipedia can
complain to the ISP, and it will get back in some form to that user.
Of course, Wikipedia does not know the details of how their complaint
is handled. Is the user kicked off, banned temporarily, or merely
given a stern warning? What matters to them is that, generally, users
that they complain about don't keep coming back. Their complaints are
effective, at least much or most of the time. This is the level of
response which an authenticated Tor network would have to provide.
The problem with this functionality from Tor's perspective is that
unlike an ISP, Tor does not have knowledge of the mapping from users
to IP addresses. Given a complaint that a certain IP was misused at a
certain time, Tor has no information about which user to penalize.
To solve the problem we would need to use some cryptographic
mechanism. Let authenticated users gain credentials via some
expensive, slow process. Let them embed the credentials in their
messages such that they are revealed in some blinded form to the exit
node. Let the exit nodes remember the credentials which were used at
different times. When valid complaints arrive, let the exit nodes
blacklist the credential which was in use at that time. This stops the
There could be many such authenticated-Tor subnetworks. Each could
have its own credential servers, its own abuse policies, and its own
set of exit IP addresses. They would be like anonymous ISPs, from the
POV of web server operators like Wikipedia. Those which are
effectively able to suppress abuse will avoid blacklists and their
users will be able to successfully use web based services.

@_date: 2005-09-29 16:44:37
@_author: cyphrpunk 
@_subject: [roy@rant-central.com: Re: [arma@mit.edu: Re: Wikipedia & Tor]] 
One of the problems with the idea of a pseudonym service
distinguishing between "good" and 'bad" users is that it has no way on
its own of telling the difference. The service manages pseudonyms,
which are intended to be used out on the web in some way. But the
service can't tell if people are playing nicely or not.
The only way this could happen is if the service receives
*complaints*. This is the only feedback mechanism possible. I gather
that Tor does in fact send out complaints about people who misbehave.
Perhaps blog services do so as well.
One problem is that these complaints generally don't arrive in real
time. It takes time for a human being to notice that some vandalism
has occured and register a complaint. If the pseudonym service is
going to be able to respond, it has to know which pseudonym was active
at the time the bad actions occured.
Jimmy Wales very accurately describes the problem with pseudonyms at
the web-server level. If Wikipedia or blog comments require the use of
pseudonyms, these can be linked after the fact. I am very sensitive to
this problem myself.
The implied solution is that the pseudonym service would maintain the
pseudonyms, but would not reveal them to the web service. Rather, it
would only provide a certificate that the pseudonym is currently in
good standing, i.e. it has not received (too many) complaints.
This implies that the pseudonym service must maintain a record of
recently used pseudonyms, and have some way of mapping them to what
the web services (which issue the complaints, services like Wikipedia)
would have seen. This mapping might be by IP address, or if Wikipedia
and other services are willing to do more, it could perhaps be an
opaque identifier which the pseudonym service provided at the time the
web service (Wikipedia) asked whether this pseudonym was a "good guy"
or not.
As a specific example, the pseudonym service might have replied, to a
query from Wikipedia, "Yes, this user is a good guy, and the sequence
number of this reply is  Then later if abuse occured,
Wikipedia (or the blog service, or other victim of vandalism) comes
back and said "we had a problem with the user who was certified with
sequence number  The pseudonym server would map this back to
the pseudonym in use at that time, and invalidate the pseudonym (or at
least give it a bad mark, with enough such marks killing the nym).
The main problems with this solution are first, it requires
considerable manual work on the part of the pseudonym server, similar
to the work necessary at an ISP to resolve complaints about users. It
could be a full time job. And second, it requires custom software at
Wikipedia and other web services that might be willing to work to
implement such a solution.
The second problem could be alleviated by the use of a related
service, a web proxy that is only for "good" pseudonyms. The web proxy
would provide transparent pass-through similar to anonymizer.com, but
only for users who were able to provide the kind of certification
described above, from the pseudonym server. In this way, the outgoing
IP addresses belonging to the web proxy would be "good" from the POV
of Wikipedia and other web services. Those services could continue to
use IP blocking as one of their main tools for handling misuse,
treating the web proxy service as being like an ISP. The web proxy
service could be bundled with the pseudonym service, or they could
exist independently.

@_date: 2005-09-29 17:07:44
@_author: cyphrpunk 
@_subject: Pseudonymity for tor: nym-0.1 (fwd) 
This idea sounds promising. Just issuing the pseudonyms, and even
making them expensive, is only half the job though. The other half is
using them to provide some kind of consequence to bad behavior. This
is much harder to define and may require human decision-making to
judge whether a particular complaint is valid or not.
There may be a superior technical solution than blind signatures. The
problem with them is that all uses of the pseudonym are linkable.
While that can be helpful in a way, for example distinguishing between
old and new pseudonyms to make old ones more valuable, it also hurts
privacy. There is no "forward secrecy", so if a nym's identity is
discovered, that discloses all his previous activities.
A newer technology allows pseudonyms to be used unlinkably, while
still allowing them to be blacklisted in the event of a complaint.
This would stop future usage of a nym without revealing previous uses.
There may be patent limitations, however. More information will be
provided when available.

@_date: 2005-09-30 11:35:29
@_author: cyphrpunk 
@_subject: Hello directly from Jimbo at Wikipedia 
Do you presently have the ability in Wikipedia to allow specific users
to come in via otherwise-blocked IP addresses? I would be happy to
make a cash donation to Wikipedia in exchange for my user account
being able to edit via Tor. Is your software set up to allow that?

@_date: 2006-01-03 20:03:38
@_author: cyphrpunk 
@_subject: Voting for nym 
I would see a proxy as being, from Wikipedia's point of view, like an
ISP. It would be like aol.com or, more analogously, momandpopisp.com,
some ISP with a number of users. If one misbehaves at Wikipedia they
probably don't block the whole ISP. That would be an unfriendly action
that would give them a bad reputation. Instead they probably make an
effort to contact someone at the ISP responsible for abuse and tell
them about the user who caused trouble, letting the ISP block him.
Only if an ISP were persistently unresponsive to abuse complaints
would they be justified in blocking the entire ISP, and I imagine that
this is exactly what they do.
If so, the need is for the anonymous proxy to be able to provide the
same level of service. I have outlined in previous messages how it
could do so, using similar technology to Jason's nym server. It would
hand out usage tokens, one to a customer, and black list tokens which
commit abuse.
BTW Jimmy Wales himself suffered some embarrassment a few weeks ago
when it came out that he had edited his own Wikipedia entry (an action
that is frowned upon) to change it and make himself look better and
more important. If only he had been able to use Tor to create a nym
account he could have avoided all this trouble. Setting himself up as
the sole founder of Wikipedia and removing the name of that other
fellow who had been given credit could have been done without making
Jimmy look bad. So I think we definitely have a friend on the inside,
we just need to get him involved in pushing for this.
