
@_date: 2013-10-07 10:58:41
@_author: str4d 
@_subject: [tor-talk] Freenet and hidden services 
Hash: SHA512
I consider Tahoe-LAFS to be the (current) best solution for this. It
provides a distributed data store, which can be used for hosting (with
a Javascript "web server"). I know Tahoe works with Tor via SOCKS but
I don't personally know of any active networks. Tahoe has been used in
I2P as a distributed data store for a long time, and there are several
"deepsites" hosted in it. We are actively working to make Tahoe
integrate better with Tor/I2P.
Zooko recently posted a *much* better summary of this:

@_date: 2013-09-04 01:16:48
@_author: str4d 
@_subject: [tor-talk] Email Clients and Tor 
Hash: SHA512
When it comes to email clients, DNS leaks and proxy bypassing are not
the only concern. Email headers are a potent source of exposed private
information, and are generally much less configurable by the end user
- - and easily overlooked by less experienced users.
The operator of mail.i2p/i2pmail.org (the email system inside I2P)
compiled a list of popular email clients and compared them in the
areas of anonymity and privacy protection. I don't know how current it
is, but it does provide a good overview of how different clients
expose different information within the email itself before the client
even touches the network:
Incidentally, by postman's ratings, (Sylpheed) Claws comes out on top :)
(For those without I2P I have pasted the page contents to
 - postman doesn't allow access to his
site via I2P inproxies)

@_date: 2013-09-18 04:53:38
@_author: str4d 
@_subject: [tor-talk] Help with getting a good automated sign up script 
Hash: SHA512
What you are setting up is identical to postman's mail.i2p/i2pmail.org
service in I2P (which I am using right now). See
 for details ( via an
I2P inproxy).
I only mention this here because postman's mail system has been
running since 2004, so he could be a useful source of info for you.
And I think that having the operators of two similar mail systems
talking with each other would be beneficial to the development of
these systems :)

@_date: 2014-12-15 12:42:55
@_author: str4d 
@_subject: [tor-talk] phantom protocol 
Hash: SHA512
As far as the design goes, it is most similar to I2P's protocol. I
have only read (most of) the original whitepaper[0] so far, and AFAICT
at a high level it is almost identical to I2P, except for a few
specific points (e.g. using IPv4 for identifying anonymizing paths,
and bidirectional circuit-switched tunnels).
It is an interesting protocol. I am reviewing the whitepapers, and
intend to publish a comparison page on the I2P website[1] once I have
a good understanding of the differences.
[0] [1]

@_date: 2014-07-03 05:47:27
@_author: str4d 
@_subject: [tor-talk] High-latency hidden services (was: Re: Secure Hidden 
Hash: SHA512
A few from the I2P sphere:
Syndie [0] - distributed forum system that can sync data from various
sources at any desired interval.
I2P-Bote [1] - distributed encrypted email. Can be configured so that
emails are stored via relays which delay before passing on packets, so
the "visible" store of an encrypted email packet in the DHT can occur
hours after it was sent and the original Bote node disconnected.
[0] [1]

@_date: 2014-07-05 00:16:36
@_author: str4d 
@_subject: [tor-talk] BlackHat2014: Deanonymize Tor for $3000 
Hash: SHA512
"Exits" in I2P are technically different from exits in Tor, though at
the user level they appear the same. An I2P exit would be equivalent
to configuring a Tor hidden service as a proxy to the clearnet. Thus a
comparison is not completely straightforward.
(Since Tor is actually designed to provide clearnet access, and has
much better exit infrastructure, we usually recommend using it
alongside I2P. And for users that don't want to manually configure a
browser to handle both, we package Orchid (Java Tor client) as an I2P

@_date: 2014-07-11 01:41:09
@_author: str4d 
@_subject: [tor-talk] Can NAT traversal be Tor's killer feature? 
Hash: SHA512
OnionCat [0] provides this functionality via a layer 3 VPN. It works
with Tor Hidden Services (ocat) and I2P tunnels (gcat [1]), by
calculating a unique IPv6 address from the hidden service ID or I2P
Destination. This has the advantage that you can give an IPv6 address
to an application and it will resolve correctly anywhere.
OnionCat is not as user-friendly as I think you would like, primarily
because it requires that the Tor HS or I2P tunnel is already set up.
But further integration could be done (certainly with I2P, because all
tunnels automatically have a Destination).
One downside to this method is that there is a possibility of address
collisions. I am not familiar with the particular algorithm OnionCat
uses to map IPv6 addresses to .onions, but in the I2P case at least,
the IPv6 address space is not large enough to hold all possible I2P
B32 addresses (which are 52 characters long). The Tor proposal for
next-gen HSs outlines a format for new .onions that is nearly
identical to I2P B32s, and will have the same problem.
The solution that I2P is considering for this is to remove the
requirement for a global IPv6 <-> .b32.i2p mapping, and instead use a
local ephemeral mapping on a virtual interface combined with a local
DNS resolver. This would enable backwards compatibility for
applications that support hostnames.
As an aside, most of the applications that you mention generally use
UDP packets, which Tor does not yet support (AFAIK). I2P does support
[0] does this, but doesn't worry about privacy.]

@_date: 2014-11-05 20:56:33
@_author: str4d 
@_subject: [tor-talk] Twitter account lockouts for Tor users 
Hash: SHA512
I use Polly on my laptop with no lock-out yet. I do regularly get
"Unable to connect to Twitter" error messages, from the exit node my
circuit has switched to being blocked by Twitter (I assume).

@_date: 2014-09-04 04:39:00
@_author: str4d 
@_subject: [tor-talk] 
=?utf-8?q?014?=
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512
It should be mentioned that I2P was also upgraded to the latest
version, which fixes the disclosed vulnerability. Disabling I2P by
default was done to reduce the potential attack surface; I2P itself is
no longer vulnerable to that attack.

@_date: 2015-04-26 12:34:06
@_author: str4d 
@_subject: [tor-talk] SIGAINT email service targeted by 70 bad exit nodes 
Hash: SHA512
I compared your list (71 FPs) with my list (55 FPs) from
This makes for an interesting counter-example: if the MyFamily
declaration was used as reason for setting BadExit on related exits, a
malicious adversary could set their MyFamily to the same as a good
exit cluster, and then intentionally behave badly, in order to get the
good cluster flagged as BadExit.
My point is, the MyFamily declaration is completely unauthenticated,
and cannot be relied upon for anything more than providing contact
information. There is a newer iteration being discussed that would
prevent relays from joining families without permission, but then a
malicious exit provider would have even less motivation to set it up.
ml and it does not actually hurt their malicious activities because

@_date: 2015-02-26 20:55:56
@_author: str4d 
@_subject: [tor-talk] git: application level leaks and best practices? 
Hash: SHA512
There is if you use bash (or a similar shell environment):
alias git='TZ=UTC git'
If you only want to force UTC for occasional commands then just add
"TZ=UTC" in front of the command, but I personally prefer redefining
the git command like above, to prevent accidentally forgetting.

@_date: 2015-07-24 00:59:35
@_author: str4d 
@_subject: [tor-talk] HORNET onion routing design 
Hash: SHA512
According to tor-talk is for "all discussion about theory, design, and development
of Onion Routing". So I think it is fine here :)
I've read it, and it's quite neat. The paper has a few bugs in the
Evaluation section that made its results a bit harder to follow in
places, but I assume these will be caught and fixed in a v2.
AFAICT, the two primary reasons for this are:
* Stateless data transmission (as they say on the box) - the routing
info is replicated in every data packet, removing the need for local
lookups. This increases the data packet header size (7 hops requires
344 bytes for HORNET, c/f 80 bytes for Tor and 20 bytes for I2P), but
massively reduces memory load (Tor stores at least 376 bytes per
circuit, requiring almost 20GB of memory for a load level of 5 million
new sessions per second).
* No replay detection - packet replay is ignored within the lifetime
of a session. They suggest that adversaries would be deterred by the
risk of being detected by volunteers/organizations/ASs, but the
detection process is going to add additional processing time and
therefore compromise throughput (c/f I2P uses a bloom filter to detect
packet replays, and this is the primary limiting factor on
participating throughput).
Only as far as recommending that the routing participants be actual
hardware routers, because this is easily possible with a stateless
protocol. HORNET doesn't specify how a path from source to destination
would be determined, but merely assumes that such a path can be found.
It should therefore be possible to implement a HORNET-based routing
overlay using server-side software instead of network hardware,
similar to Tor and I2P. Such a scheme would however not be as
efficient as one based on deployed network hardware.

@_date: 2015-07-24 01:52:54
@_author: str4d 
@_subject: [tor-talk] HORNET onion routing design 
Hash: SHA512
Erm, that should be 5 million new sessions per *minute* :P

@_date: 2015-07-25 00:21:08
@_author: str4d 
@_subject: [tor-talk] HORNET onion routing design 
Hash: SHA512
In this design, I would say the major problems are wasting network
resources, and forcing router rotation. There is no way to "cancel" a
session other than to let it time out. This means that an attacker can
replay packets as rapidly as they want in order to overwhelm the
participating routers, effectively DoSing the remote peer (as well as
anyone else whose sessions are going through those routers).
The participating routers can't do anything, because they are
stateless and the packets they are processing *are* valid. The remote
peer *can* detect the replays, but they can't tell the participating
routers about it. All that the remote peer can do is drop all packets
from that session, select new participants and switch to a new session
- - which increases the probability of selecting the adversary's
malicious routers. Perhaps the selection process can be constructed to
minimize the danger, but that is outside the scope of HORNET's design.

@_date: 2015-07-25 12:30:46
@_author: str4d 
@_subject: [tor-talk] HORNET onion routing design 
Hash: SHA512
If you store the FS locally and have a route identifier, then
essentially you have an I2P tunnel (ignoring differences in the
specifics of the way symmetric onion encryption is handled). Routers
sending the extra 344 bytes _is_ what makes this better for the type
of large-scale network they are proposing - without the stored state
(and associated memory usage and lookup), packet processing is much
But in a real implementation, some kind of replay resistance would be
necessary (probably based on the nonce field in the CHDR), and this
would significantly affect the observed maximum throughput of
93.5Gb/s. Still, I expect it would remain faster than networks that do
store state.

@_date: 2015-05-05 11:49:25
@_author: str4d 
@_subject: [tor-talk] Meeting Snowden in Princeton 
Hash: SHA512
As with everything, it's a question of balance. Tor errs on the side
of centralization, which enables it to easily detect bandwidth dumping
and block arbitrary routers with quick turnaround, but that is a lot
of power in the hands of a (trusted) few. It also does nothing against
e.g. carefully-planned slow Sybil attacks.
The original I2P devs *did* consider Sybil resistance while designing
the network, and did include scope in the network architecture for
e.g. HashCash-like mechanisms, but ultimately decided to take the
decentralized route, and designed the network on the assumption that
no router is trusted. As for detecting and inhibiting Sybil attacks:
it is still possible to detect bandwidth dumping (one example I recall
was a research group starting up a bunch of routers), and we do have
the ability to block routers, but only via router upgrades. So yes, it
is certainly more difficult right now to impede Sybils on I2P. But
there is more focus on making the attacks that Sybil enables harder to
carry out (because a Sybil on its own is not an attack), as well as
general network growth to make obtaining a large enough network
fraction more difficult (we estimate there are currently around 25,000
I2P routers).

@_date: 2015-05-18 23:47:23
@_author: str4d 
@_subject: [tor-talk] Making a Site Available as both a Hidden Service and 
Hash: SHA512
If the patch to give each inbound circuit its own temporary "IP
address" [0] were ever to be committed, then you could potentially use
off-the-shelf protections to protect HSs. However, the local addresses
are only ever temporarily unique, because they are derived from the
circuit ID; the protection application would need to be carefully
configured so that its timeouts matched the expected durations for
which a circuit ID is expected to be unique.
Bidirectionally-authenticated circuits (like I2P's tunnels) are
certainly a better way to enable protections like these, but
off-the-shelf applications won't work with them. I2P "solves" this by
implementing the protection itself, including some general rate
limiting features in server tunnels that drop connections before the
webserver ever sees them. It also includes a unique local address per
client feature like [0] for use with off-the-shelf applications, but
this is open to collisions (because the client hash space does not fit
into the IPv4 or IPv6 localhost address space).
[0]

@_date: 2015-05-27 23:51:23
@_author: str4d 
@_subject: [tor-talk] CloudFlare one site, multiple domains problem 
Hash: SHA512
I have encountered this problem regularly, e.g. with HackerOne. The
problem is that CloudFlare does not recognize the common session
across the distinct domains, assumes that the requests to example.org
are different to those from example.com, and returns a CAPTCHA. But
you can't solve a CAPTCHA for an image URL loaded inside a page >_>
If you were actually requesting example.org, you would see the CAPTCHA
page. But because the Tor Browser Bundle uses a new circuit per domain
name (in the tab's URL bar), you can't just open example.org in a new
tab, solve the CAPTCHA, and then reload example.com, because the
example.org CAPTCHA is associated with a different Tor circuit.
I have notified the websites I have had this problem with, as well as
CloudFlare, but until they provide some way for server operators to
"link" domains together, so a request from an IP to example.com (that
has had a CAPTCHA solved) followed by a request from that IP to
example.org is recognized as the same session, then there isn't much
that can be done.
A possible workaround would be for Tor Browser to include an option
that allows users to "open all CAPTCHAs on this page". It could look
for all unique domains within a page, and open a tab (or pop-up
window) for each through the same circuit. That would allow users to
authenticate that site's Tor circuit with CloudFlare for all domains
the site uses. But this would probably need to be repeated each time
the circuit changes (like the CAPTCHAs already need to be).

@_date: 2015-10-03 10:55:31
@_author: str4d 
@_subject: [tor-talk] Accessing Cloudflare sites on TBB 
Hash: SHA512
What is a step they can take right now for improving Tor user experience
A third is the cross-domain problem. Even if the user answers a
CAPTCHA for a site, if the site uses another domain for static
content, that content never loads. Specifically, the static content
requests themselves return a separate CAPTCHA. Since these can never
be answered in that tab, the real content can never be fetched. The
user can't e.g. open an image URL in a new tab and solve the CAPTCHA
there, because TBB by default opens a new circuit, so CloudFlare sees
it as a separate "session".
At best, the site looks rubbish. At worst, it can make the site
unusable (if it requires JS).
Ideally, CloudFlare should be more intelligent about cross-domain
content. Site admins should be able to list expected cross-links
between their CloudFlare-controlled domains. If a request comes in on
spamalot.com and shortly after multiple requests come in on
slstatic.com, it should mark those as the same session, somehow
(whether by adding a query parameter or header to the static requests,
or being more intelligent on the server side).

@_date: 2016-01-14 17:31:45
@_author: str4d 
@_subject: [tor-talk] Escape NSA just to enter commercial surveillance? 
Hash: SHA512
Tor is not for anonymization. At least, not in the pervasive sense
that you mean it. All Tor provides is location anonymity (of the
client or server); the applications on top have to also be designed
for anonymity (and the user educated, etc etc) to attempt to get close
to full anonymization. So yes, in that sense using Facebook over Tor
is pointless, because Facebook requires that you be logged in with a
"real name".
But sometimes, location anonymity is all you need. What if you are in
a country where Facebook is banned? Facebook's HS will enable you to
reach it (using bridges or PTs if necessary). What if you are a public
figure and need to go into hiding to protect yourself? A Tor client
will enable you to communicate publicly over Facebook without
revealing your location (modulo JavaScript issues).
Not everyone's adversary is the NSA.
