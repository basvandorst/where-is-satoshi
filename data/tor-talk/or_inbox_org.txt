
@_date: 2005-12-14 07:12:10
@_author: Anthony DiPierro 
@_subject: Google 403 error pages 
Does the web API work?  If so, you can always use that.
Anyway, I think the 403 page has more to do with Google not wanting
people bulk-scraping its site.  Letting exit nodes make unlimited
requests would defeat its crude protection against that, and in a way
where the violators couldn't even be easily traced.
Yeah, they could establish some sort of scheme where you prove your
identity to Google and then get a cookie or login or something to get
past the IP check, but c'mon, the cost would be too high for such a
few people.

@_date: 2005-12-14 18:13:03
@_author: Anthony DiPierro 
@_subject: Almost on-topic news article -- Wikipedia, Jimmy Wales, and anonymity! 
The funny thing is, they keep calling the Wikipedia vandal
"anonymous".  But he wasn't at all anonymous, he ultimately admitted
to what he did after someone tracked him down to his business and it
was inevitable that his identity was going to be made known.
Wales agrees with the interviewer that he thinks "it's important to
allow contributors and site administrators to remain anonymous".  But
you can't be anonymous when your IP address is broadcast to the world.

@_date: 2005-12-16 11:10:14
@_author: Anthony DiPierro 
@_subject: Google 403 error pages 
I figure someone has just been running a bot through Tor, hitting
Google.  Google throttles the number of requests an IP can make over a
certain time period, to stop bots that do this.  Running the bot
through Tor is a good way to get around that throttle, for a while,
but then you wind up screwing everyone else.
Yeah, I've switched to scroogle too.  I didn't mention it, because I
figured whoever is running that bot might be listening to this mailing
list, and maybe scroogle will block Tor (or Google will block
Scroogle) next.
Anyway, one of the reasons Scroogle isn't usually blocked is because
they've written software to automatically distribute their requests to
come from multiple IPs and to go to multiple different sites on the
Google end.  The different Google sites distributed throughout the
world apparently don't coordinate the throttling mechanism.  All of
this is described on the scroogle site.
If Google decides to get more intelligent with their blocking it
wouldn't be hard to block the scroogle site.  But as long as scroogle
stays relatively low key that probably won't happen.

@_date: 2005-12-25 07:16:34
@_author: Anthony DiPierro 
@_subject: Wikipedia & Tor & ... moderators? 
It should be noted that many countries do not allow their citizens to
release copyrighted works into the public domain.  And, in fact, most
of these same countries don't allow their citizens to waive their
right to attribution.
So if you're going to do this, you're better off attributing the
content to the people who wrote it.

@_date: 2005-12-31 07:08:11
@_author: Anthony DiPierro 
@_subject: public archive? 
FWIW, I haven't *yet* received any spam to the email address I use for
this list.  It is possible that someone could have subscribed to the
list and then set up a bot to collect addresses directly, though -
that would be problematic even if the list was public.
Anyway, gmail allows you to set up multiple email addresses if you
have a service to forward to your gmail account.  Unfortunately last
time I checked they *do* broadcast your real gmail account address to
anyone receiving those emails, but you can set up the service to trash
emails coming directly to that address.  It might be a solution for
you, at least if you don't mind your mailing list traffic and other
non-sensitive traffic being sent to a different place from the stuff
you don't trust Google employees with.
And plus you get archive searching built in (at least for the time
you've been subscribed to the list).
I know, it's a pain in the ass to do all this just to get subscribed
to a mailing list.  Personally, I hate email - I think it's a horribly
designed technology that unfortunately a lot of people insist on using
anyway.  Posting to or-talk just happens to be one of those things
that you can't do any other way.

@_date: 2005-12-31 10:56:01
@_author: Anthony DiPierro 
@_subject: Way off topic talk about email 
If it hurts, I'm doing it wrong?  Maybe you can point me to a perfect
spam filter, because I haven't yet found one.
Your list of "features" essentially defined email, as one was that it
"creates multiple redundant realtime-searchable archives at each
user's end (mailboxes)".  If you eliminate that "feature" there are
plenty of alternatives, and I don't really see it as a useful feature,
more of a horribly inefficient implementation.  Some of the other
features I'm not even sure I agree about.  Email supports
authentication and encryption?  Only in the sense that you can easily
build authentication and encryption on top of any digital distribution
If I had the opportunity to post replies to this mailing list using a
web form instead of email I'd definitely use it.  Creating a gmail
account to subscribe to mailing lists is the next best thing.
I guess it's true that no one is *forcing* me to use email.  But
without an email address I can't access my bank's online banking, or
pay my student loans through the web, or post to or-talk, or subscribe
to slashdot, or receive paypal payments, or a whole host of other
things.  That doesn't really make sense to me.  In fact, using the
listserver does) makes about as much sense as using an IP address.

@_date: 2005-12-31 15:45:16
@_author: Anthony DiPierro 
@_subject: Way off topic talk about email 
Considering that you can easily attach a spam filter to a blog, I
don't see how that could possibly be the case.
I'd be interested in what spam filter you use.  I think I'd go through
the trouble of setting it up if I could drop my spam to "almost none"
(of course I get thousands of spam messages a day pre-filters so maybe
it wouldn't work as well for me).
Well there's always archive.org...  Besides, the fact that some
alternatives to email don't back anything up doesn't mean that none of
them back anything up.  You don't have to have a distributed P2P
filestore to make daily backups and distribute them to 3 or 4 backup
locations.  Backing up every post to every mailing list on the
computer of every single subscriber is excessively wasteful.
Of course it matters how it's implemented.  Disk space costs money.
C'mon, what percentage of email users do you think use authentication
and encryption?  The rest of the world hasn't adopted it, not yet.
Some day maybe I'll have the time and energy to write such an
interface (or more likely to pay someone else to write it for me).  In
the mean time my gmail hackaround is good enough.
See above.  I have enough things to do in life to the point where it's
not worth it for me to spend the time administering my own email
server.  I've played with that stuff in the past but I don't have time
for it right now.
I should be able to do a lot of things without an email address. Doesn't mean I can.  Both of the banks I use require me to tell them
my email address, and I can't use a throwaway account because then
anyone else who gets access to that account could steal my password.
Authentication of what?  There are people with multiple email
addresses.  There are email addresses which are used by multiple
people.  There are people with no email address at all. Email-delivered one-time tokens don't authenticate much of anything,
and those examples I gave aren't one-time things anyway.  I really
don't see what this type of "authentication" works well at.
Sounds to me like it's trivial for a spammer to spam the list anyway. That's what I'd refer to as a rather useless security mechanism.
Turing tests through email?  That's about the dumbest idea I've ever
heard (yeah yeah, I'm being hyperbolic).  Seriously though, who wants
to sit and wait for a bounce before they can post a message?
Signed email is more reasonable, I could see a system built around
that being better from an authentication standpoint (it'd probably
have to rely on other forms of authentication other than just the
current webs of trust, though).  It still wouldn't satify those of us
who don't feel like giving out our email address in the first place,

@_date: 2005-12-01 23:28:46
@_author: Anthony DiPierro 
@_subject: Voting for nym 
I've added a few of the concerns that I already brought up on the
mailing list.  I'm more enthusiastic about
 . That is a proposal to allow certain IPs to be blocked for users that
aren't logged in, but to allow edits by users that are logged in.  In
my mind it is long overdue, and nearly everyone who voted in the straw
poll agrees that it is a good idea.
Of course, maybe the two could be combined.  One of the major
questions with the blocking policy proposal is what hurdles (if any)
to use for new account creation.  It wouldn't be very effective to
allow logged in users to edit through blocked IP addresses if vandals
could just keep creating accounts.  Well, one answer would be to not
allow new account creation through anonymized IPs at all, but instead
use nym to create the new account.
Nym would simply be one method to get an account.  Other ways could
include providing and verifying your email address, getting sponsored
by another user, or simply using a non-anonymized IP address to create
the account.  Once you created the account (using nym or through
whatever means), then you would just log in to the site using your
Wikipedia account and wouldn't be blocked simply because you were
using a Tor IP address.

@_date: 2005-11-11 06:57:05
@_author: Anthony DiPierro 
@_subject: Hacker strikes through student's router 
In case you're wondering, like I was, "Agoric comes from agora, the
Greek word for marketplace. The programs and computers in these
systems become buyers and sellers of resources, much like a real-life
marketplace. Buyers compete against one another for scarce resources
and try to get the best price they can, while sellers attempt to
maximize their profit." Anyway, I think the real difficulty here would be in implementing some
sort of marketplace without having a significant effect on anonymity. I'm sure there are ways to do it, but it doesn't seem to me to be a
trivial problem at all.  One advantage though is that in Tor the exit
nodes themselves make essentially no attempt at being anonymous.  This
is important, because it means they can be trusted to some extent
based on their track record.
One idea I've played with in my head for a different type of network,
but which could apply to Tor too, is using processing power as the
base unit.  Someone would set up a bunch of public/private keypairs or
md5 hashes or some other sort of one-way function (destroying the
answers which you'd have to trust them to do), and you'd have to crack
them in order to get a token.  Different tokens would have different
values depending on how widespread they were, because the same exit
node wouldn't accept the same token twice, and as time goes on the
tokens would get easier and easier to crack, so you'd have to have
progressively harder to crack values to sustain this over time.  Using
public/private keypairs of varying strengths would have the advantage
that you could prove that you possess a token without actually giving
up that token, but I'm not sure exactly what the use of that would be.
So, to get a high priority packet through the system you crack a key
and present it as a token to an exit node (using a key that isn't
already in the possession of that exit node).  Yes, it'd be a crude
system, among other things because the token wouldn't be transferred,
it'd be copied, but it'd probably work "good enough", if for nothing
else than to bootstrap some more elaborate system.  Cracking keys is
also a waste of resources, so a better system should probably be
developed over time.  But better systems seem to always rely on some
sort of central authority - this system has no central authority (as
long as you trust that the person who initially created the keys threw
them away, anyway).  Maybe this is where the ability to prove you have
a public/private keypair without giving it away would come into place,
those who could prove a high level of trust could create a
pseudonymous identity and implement one of many alternate currency
I think this system would be fairly anonymous.  But it would give a
bit of a paper trail to those attacking the anonymity of Tor.

@_date: 2005-11-11 08:03:02
@_author: Anthony DiPierro 
@_subject: Hacker strikes through student's router 
Something along those lines could probably work.  A really simple
implementation of giving top priority to servers might lead to a few
bad people running exit nodes ruining things for everyone, but that
can probably be solved.
You'd probably lose a bit of anonymity, but you'd still be able to
hide your IP address from the end servers, which is one of the main
features of Tor anyway.  For other situations you could always go
through the slower low-priority route.

@_date: 2005-11-14 06:15:02
@_author: Anthony DiPierro 
@_subject: Offtopic - when to use BitTorrent (was Torpark Mirroring) 
Isn't anything which has mirrors a good candidate for BitTorrent? BitTorrent essentially just decreases the cost of being a mirror.
(I guess BitTorrent doesn't handle a site with lots of small files
well yet, but for a site with just a few large files I'd say there's
not really a time *not* to use it.)

@_date: 2005-11-14 11:10:57
@_author: Anthony DiPierro 
@_subject: Offtopic - when to use BitTorrent (was Torpark Mirroring) 
You can offer something through bittorrent and the web, though.  And
finding people to seed is as easy as finding people to offer mirrors,
in fact, I'd say that bittorrent is easier to run than alternative
mirroring systems.
I believe new versions of bittorrent even allow you to use http
seeding, so you don't have to set up any seeds at all.  Just throttle
the http server down to a level where your resource usage is
acceptable.  I'm not sure how widespread this feature is though, and I
might be misunderstanding it.
I dunno, in my opinion once you've gotten to the point where it's
worth the trouble to set up mirrors, you might as well set up
bittorrent as well.

@_date: 2005-11-17 17:03:51
@_author: Anthony DiPierro 
@_subject: Marketing Tor (Was Re: For those using Tor with windows) 
Certainly if you're reselling it directly, without adding anything of
value yourself.  Of course, if people don't want to allow reselling,
then they should restrict the service to those who agree not to
I think this is inevitable anyway, at least without a partial
redesign.  Something as simple as balancing the load so that peer
nodes which contribute the most get priority through your nodes would
probably solve that problem to a large extent (think tit-for-tat).
If you don't want people using your resources without giving anything
back, don't let them.

@_date: 2005-11-20 08:33:38
@_author: Anthony DiPierro 
@_subject: Challenges paper and other tools 
I'll definitely take a look at this, but I'd really like to start
experimenting with Tor.  Is there an easy way to say (for example), I
want to run A as my exit node, then go through B, then exit through C,
pass this all to an app, and then do it?  I've looked at the protocol
and I'm starting to understand it, but there seem to be a lot of parts
and I'm kind of looking for a package which implements those parts
So, is there a hello world Tor client?

@_date: 2005-11-25 15:25:04
@_author: Anthony DiPierro 
@_subject: ATTN: for-profit Tor operators 
Actually I would say if anything the opposite is true.  By being an
operator itself, the EFF has standing to be involved in the cases
themselves, rather than simply providing free legal support to someone
else.  Then again, I suppose the EFF could argue that it *was* an
operator, and that it wants to continue being an operator after the
legal issues are settled.
All that said, I'm not sure there is much threat by copyright law
(including the DMCA) in being a Tor operator.  About the only time I
could see it coming into play is if you're supporting a hidden service
which has copyright infringments on it.  Then, if you've registered as
an ISP under the DMCA, you might have to disable access to that hidden
service (assuming this is possible - I figure it must be possible to
at least disable it for whoever is doing the DNS resolution).  If
you're not registered as an ISP under the DMCA, well, then you don't
get the protections of the DMCA.  The CDA might still kick in, but
it'd probably be a good idea to register under the DMCA anyway.
The CDA might also be useful for protection under non-copyright laws
including libel.
The EFF has done a lot of things that I consider to be a waste,
actually.  The Felton case, for example, was pretty obviously going to
be thrown out for a lack of standing.  That whole case was a big waste
of time and money (to quote the judge, "the defendants having said
we're not going to sue you, the plaintiffs decided apparently to
catalyze this action by bringing a suit themselves"), and it was
enough to turn me off from giving the EFF any financial support for a
while.  The way I saw it the EFF was creating strawman arguments
against the DMCA, and in some ways I think they've actually done more
harm than good, making people paranoid over interpretations of the
DMCA which simply haven't panned out in the courts.  It's been years
since that whole mess, though, and maybe it's time to give the EFF
another chance.  I agree that the DMCA is bad, but I think the ACLU
has made better challenges to it Constitutionally (of course, they've
been losing too, but I feel they have better arguments).

@_date: 2005-11-25 18:01:07
@_author: Anthony DiPierro 
@_subject: ATTN: for-profit Tor operators 
Well, read below for more explanation, but I really don't even know
what it means for "a DMCA notice against a Tor node" to "make it to
Frankly, I think you are basing this on a misconception as to what the
DMCA is, one which in my opinion has been propagated in part by the
EFF (though Slashdot and some other techie media companies can be
blamed for a lot of it too).
The DMCA (specifically, the OCILLA) provides a defense against certain
types of copyright infringement.  Before the DMCA and the CDA, there
was a good chance an ISP could lose a lawsuit for direct and/or
contributory and/or vicarious copyright infringement simply for being
an ISP.  The DMCA (OCILLA) came in and gave ISPs a positive defense,
*if* they follow certain rules.
Yes, there are other parts of the DMCA other than OCILLA.  There are
parts about circumvention of copyright protections, and there are
parts giving certain subpoena powers which otherwise wouldn't be
available (this part is technically part of OCILLA, I believe).  Some
parts are bad (in my opinion), and some of them might even be
unconstiutional (especially the subpoena powers), but the parts that
are relevant to Tor (again, in my opinion) are a good thing.
One relevant case to look at is RIAA vs. Verizon.  See
As for your "belief that a 'service provider' should be a legal
definition in the DMCA itself", I believe this is actually the case,
but having not registered for myself or any other entities, I can't
say for sure.
Depends on why you get the takedown notice.  As I alluded to, the only
place I can see them being useful is in the case of a hidden service,
in which case you should probably do whatever you can to
"expeditiously disable access to the work".  Otherwise (although you
could argue even in the case of a hidden service), the information is
just passing through the ISPs network (something the DMCA calls
"transitory network communications"), and "there are no takedown
provisions", "even if it is infringing and they know it"
 Should you then throw them in the trash otherwise?  Well, it might be
smarter to send back a letter explaining why the takedown notice is
not applicable.  You might even want to cite RIAA vs. Verizon which
says "any notice to an ISP concerning its activity as a mere conduit
does not satisfy the condition of ? 512(c)(3)(A)(iii) and is therefore
So, I actually misspoke when I said "If you're not registered as an
ISP under the DMCA, well, then you don't get the protections of the
DMCA."  You still do get some of the protections, such as the ones for
"transitory network communications".  Maybe this is all you need. It'd be nice if someone with more knowledge of OCILLA (and the Tor
protocol) would clarify.
A lot of people misunderstand "DMCA takedown notices", thinking that
they are used for violations of the DMCA.  But more often the
infringement involved is regular old copyright infringement.  The
takedown notice provides the ISP with "actual knowledge" of the
infrinement, and therefore the ISP no longer has "safe harbor" under
OCILLA to defend against a copyright infringement case.  Even that
doesn't mean they are necessarily guilty of anything, though.  To
quote Wikipedia again, "Even if a removal is found not to be
'expeditious' within the meaning of the law and the so-called 'safe
harbor' under the DMCA is lost, in many cases the ISP may still be
protected" (for example, under the CDA, another bad law with some good
provisions in it).

@_date: 2005-11-28 14:58:14
@_author: Anthony DiPierro 
@_subject: ATTN: for-profit Tor operators 
Thanks for the info and the correction.  I was aware that I was
oversimplifying, but perhaps I was oversimplifying a bit too much :).

@_date: 2005-11-29 09:38:48
@_author: Anthony DiPierro 
@_subject: use of routing information in anti-fraud mechanisms 
Hmm, when I read this I assumed you were just connecting from some
high fraud country, though now that I think about it, it could be
both.  Maybe your billing address is in Cambridge, MA and you're
connecting from a completely different country which has an extremely
high fraud rate.
If so, I can see why they'd block you.  Sure, they might lose one
sale, but they'll probably save much more in stopped fraud.
If enough people really want to hide their location from their payment
service (and I'm not sure why you'd want to do this, since they
already *know* your location), then I'm sure there are other payment
services which will pop up to fill this market.  Credit cards are
notoriously very insecure payment methods.  Part of how they make up
for this is by producing so called "false positives" (one time I had
my credit card declined at a gas station because I was travelling 200
miles twice a week and it triggered their fraud detection; a simple
call to my credit card company telling them about this situation
resolved it).  Simply accepting that anyone who knows a 16 digit
number is who they say they are, even in the face of evidence pointing
strongly to the contrary, is not a very good business practice.

@_date: 2005-11-29 12:01:48
@_author: Anthony DiPierro 
@_subject: use of routing information in anti-fraud mechanisms 
If you're going to go visit (for example) Nigeria and you plan on
using your credit card, you should probably let your credit card
company know first.  This is true whether you're planning on making
purchases online or offline.

@_date: 2005-11-29 14:49:26
@_author: Anthony DiPierro 
@_subject: use of routing information in anti-fraud mechanisms 
Yeah, pretty much.  If you ran your phone calls through some sort of
jamming device which gave fake caller id info, and then called Dominos
to order a pizza for delivery, I wouldn't be surprised if they had
some problems placing your order.
Of course, one major difference is that over the telephone you
generally have the option to speak to an actual person who can
override things.  And caller-ID blocking is available and more popular
than Tor (not to mention that calls can still be traced by the phone
company unless you've somehow hacked the network or gone through a
redirection service).

@_date: 2005-11-01 12:15:33
@_author: Anthony DiPierro 
@_subject: Wikipedia and Tor - a solution in the works? 
It's historical more than anything. Publishing first and asking questions
later was what made Wikipedia so successful. Nowadays that might be
obsolete, but there would be a lot of backlash from some of the regulars to
take it away.
 I think it'd just be enough to identify edits by anonymous Tor users under
a single account. There's no advantage to having the specific IP, and it'd
be easier to police edits if all edits made anonymously through Tor were
lumped under a single account. It'd also increase the anonymity slightly,
though that's just a side effect.
 Sure, you could screen the edits too, but that'd be a bit of extra work on
the coding side, would bother a number of users, and wouldn't have much
benefit. I guess it'd lessen the incentive to vandalize, but not very much.
 Anthony

@_date: 2005-11-08 22:14:31
@_author: Anthony DiPierro 
@_subject: Hacker strikes through student's router 
How hard would it be to run a Tor exit node which accepts GET requests but
not POST requests? Or, possibly, POST requests could simply be passed on to
another Tor exit node? Would it be ethical to do this? You'd have to examine
the traffic to see if it was a GET or a POST, but you wouldn't have to store

@_date: 2005-11-09 08:42:44
@_author: Anthony DiPierro 
@_subject: Hacker strikes through student's router 
Maybe we should look into implementing RFC 3514 filtering based on the
"evil bit". As an advantage that works at the same layer as Tor. :)
 Seriously though, this is kind of the response I expected. I'd be a bit
nervous about putting up a server which allowed unfiltered port 80 traffic,
as far as getting in trouble with my ISP. I'm sure a lot of people feel the
same way, too. Even just allowing GET requests would take load off the other
exit nodes, but apparently this isn't really possible with the
implementation of Tor.
 Anyway, I guess filtering by IP address would be the safest way to go
there, and would still potentially draw a bit of traffic if you include some
popular services. Of course the best scenario would be to just get enough
people using Tor that the ISPs can't complain without losing lots of
customers, but that right now is just wishful thinking. :)
 Anthony

@_date: 2005-11-10 06:30:25
@_author: Anthony DiPierro 
@_subject: Hacker strikes through student's router 
Well, Tor is more accessible to more people. Tor lets you use your own
software, not whatever happens to be loaded on the public computer (answer
to 2 and 3 anyway). And the difficulty of tracking people using Tor is much
higher than tracking people using these other providers, because at least
the other providers give you a location. Along those same lines, the
examples you give are more limited. You could easily set up a bot to use all
Tor nodes at once. It'd be a lot harder to do that with all wifi hotspots,
or internet cafes, or public libraries.
On top of all that, there are probably protections put in place at most of
these places. Firewalls and proxies, with every access being logged in case
there's a problem. And finally, to the degree that these methods don't
provide this type of accountability, they probably do find themselves being
threatened with lawsuits.
I agree with cyphrpunk for the most part. In the end Tor is going to be
widely accepted to the extent that the good outweighs the harm. To say it's
just like cyber cafes, or wifi hotspots, or public libraries, or selling
hammers - none of these are very good analogies. Of course hooking up a gun
to the internet isn't any better, but somewhere between the two lies my view
of the situation. (Actually, both the hammer and the gun analogy miss the
point that Tor just allows you to do something most users can already do,
more anonymously.)

@_date: 2005-11-10 06:50:07
@_author: Anthony DiPierro 
@_subject: Launching Attacks via TOR Re: Hacker strikes through student's router 
Do you really think it doesn't matter? In the real world, I think it matters
a lot. Garage doors and houses aren't that hard to break into even when
things are locked. As someone else pointed out in an earlier discussion,
people lock doors while there's a big glass window sitting right next to it.
The reason they can do that is accountability. If you break into someone's
house, there's a good chance you're going to get caught.
That said, I think you've got to treat the internet entirely differently. If
someone invents the invisibility cloak, you can be sure that home security
systems are going to change drastically. For those who refuse to change,
should they blame the person who created or sold the invisibility cloak?
Certainly not unless they had some specific reason to believe the cloak was
going to be used for a crime. Besides, it's much easier to protect yourself
from criminals on the internet. Things on the internet are locked by
default. If you don't plug in that ethernet cable, you don't have to worry
at all. Any access to your computer systems is provided by you. I guess
that's the idea behind the garage door analogy. If all houses were
completely impenetrable except for the doors you create then the idea of
invisibility cloaks wouldn't be nearly as scary.
Anyway, on the internet it's already extremely difficult to track down the
identities of many who aren't using Tor. Tor just brings that anonymity to
the average law abiding citizen instead of reserving it for the criminals
who have access to arrays of zombie computers or whatever.

@_date: 2005-11-10 07:40:43
@_author: Anthony DiPierro 
@_subject: Hacker strikes through student's router 
I agree with this. There are differences, some of which I've pointed out,
and some of which you've pointed out. But they are close, and I agree that
if you should be *allowed* to run a wifi hotspot you should be *allowed* to
run a Tor node.
Of course, that said, you should probably get permission from your ISP
before you run a wifi hotspot. And it's perfectly reasonable for a
university to ban students from setting up free/open wifi hotspots. And
those who run open wifi hotspots probably have to deal with abuse complaints
on a regular basis.
One of the reasons companies go through all this is because they think
(reasonably in most circumstances) that they can profit from it. If only we
could figure out how to really spread anonymous e-money. Then we could
really start spreading Tor.

@_date: 2005-10-29 14:42:36
@_author: Anthony DiPierro 
@_subject: Wikipedia and Tor - a solution in the works? 
Jimmy Wales proposed what he described as a "simple solution to the problem
of Tor users being unable to edit Wikipedia." Here it is:
"trusted user -> tor cloud -> authentication server -> trusted tor cloud ->
"untrusted user -> tor cloud -> authentication server -> untrusted tor cloud
-> no wikipedia"
David Benfell responded "So they want us to do their authentication for
them. Wrong answer." I think this points out exactly the problem with Mr.
Wales' proposal, but it's perhaps not clear to everyone why.
First, let me try to understand exactly what it is Mr. Wales is proposing.
Someone, presumably someone not affiliated directly with Wikipedia, is
supposed to run an "authentication server". Presumably this authentication
server will establish pseudonymous accounts with some mechanism for
authentication (for simplicity let's say username/password). Some mechanism
will be used to tie edits made to Wikipedia to the account username, and
upon complaints coming from Wikipedia that account will be disabled. Now,
since the authentication server must not know the true identity of the
trusted user (since that would completely destroy the anonymity), there
needs to be a way for an untrusted user to become a trusted user. But to
limit abuse where a single person creates many accounts, some mechanism must
be implemented at the authentication server to throttle the creation of new
pseudonymous accounts.
Let me now explain why the "trusted tor cloud" would be very difficult to
implement, as well as why it is essentially useless. The difference between
a "trusted user" and an "untrusted user" is specific to the application.
What Wikipedia considers bad behavior does not coincide with what someone
else might consider bad behavior. While there might be some actions which
are fairly universally accepted as bad behavior, it is likely that Wikipedia
will not accept merely limiting these behaviors. What I'm saying in essense,
is that the "authentication server" would have to be geared specifically to
Wikipedia. For this reason, the trusted tor cloud would likely be very
small, and it would be quite simple to determine the location of the
authentication server. So you might as well remove the "trusted tor cloud"
completely, and simply have the authentication server connect directly to
So now, we have "trusted user -> tor cloud -> authentication server ->
wikipedia". The Tor cloud between the authentication server and Wikipedia
was difficult to implement and essentially useless, so we dropped it.
Instead the authentication server connects directly to Wikipedia using a
single IP address. This could be implemented without too much work on the
part of Wikipedia, they'd essentially only have to agree not to ban the IP
address of the authentication server (at least not for a very long period of
time), and to send information about any bad behavior to that server. In
theory you could even run it as a Tor hidden service, increasing the
anonymity (especially since Wikipedia doesn't offer https).
If Wikipedia would agree to this, it wouldn't be too hard to set up. But it
would make the most sense for Wikipedia to run the authentication server
itself! Wikipedia already has pseudonymous accounts set up, after all.
To be clear, for those who aren't familiar with the way Wikipedia implements
blocking, users, even users that have established accounts on Wikipedia for
years, cannot edit Wikipedia if the IP address they are using is blocked
(even admins are blocked from editing, though they are able to remove the IP
block). There is a proposal on Wikipedia to correct this, at
 . Almost
everyone supports it, the only real question is what mechanism to use to
throttle/limit the creation of new accounts. It seems to me that this is a
good implementation of "trusted user -> tor cloud -> authentication server
-> wikipedia", where the authentication server is run by Wikipedia itself.
What would be a good additional feature would be for Wikipedia to offer a
Tor hidden service to use to connect to Wikipedia. This is especially true
since Wikipedia passwords are passed in plaintext over http and thus could
be snooped by an exit node.

@_date: 2005-10-31 07:15:52
@_author: Anthony DiPierro 
@_subject: Wikipedia and Tor - a solution in the works? 
I don't really see how nym provides the security that was talked about by
Mr. Wales, with the authentication server and the trusted cloud. It is
really an entirely different solution. But more importantly, nym, as I
understand it, doesn't provide the same security as using the IP address
directly. Nym doesn't provide you with a token showing that have a unique IP
address, it provides you with a token showing that - at some point in the
past - you had a unique IP address.
I'm not sure when, if ever, tokens and certificates are supposed to expire,
but between expirations if you happen to be using an IP address which was
used by someone else to obtain a token (or, furthermore, if you simply have
lost the certificate you obtained for yourself), then you can't obtain a
token, and therefore can't obtian a certificate. Furthermore, it would be
rather trivial for anyone on an account which uses dynamic IP addresses to
build up a huge assortment of valid certificates, which could be used later
if one of them becomes invalid, and in fact such selfish behavior would
inherently destroy the system, as major ISPs would have a scarce supply of
tokens available.
Finally, the anonymity only increases as more people use the system (and in
fact would be completely unacceptable for anything but the most trivial of
protections without a significant number of users), and usability decreases
as more people use the system (for the reasons above).
I'm not even going to even get into what would happen if someone manages to
spoof IP addresses to the token server. This is arguably a problem with
Wikipedia's current system anyway, though on a more temporary basis. Same
thing with IPv6.
if wikipedia is unhappy with a user, it bans that user's token (with
Effectively banning the IP address *forever*. Yes, you could add an
expiration on the certificate to allow someone to obtain a new token after a
certain period of time, but the shorter you make the period of time, the
less the anonymity you're providing (and the less useful the block).

@_date: 2005-10-31 08:48:23
@_author: Anthony DiPierro 
@_subject: Wikipedia and Tor - a solution in the works? 
Security is not binary. I put a (slightly) higher level of trust in the ISPs
between myself and Wikipedia than I put in some random person running a Tor
exit node. Only slightly, though. The reality is that it's not that huge of
a deal if someone finds out my Wikipedia password. In fact, in some ways
it's a feature in that I can repudiate any edit made using my account.
If the server uses https for password authentication (as is used on
I was under the impression that a man-in-the-middle attack would require
obtaining a certificate signed by one of the default certificate agencies
with the same domain name as the destination server. Now every once in a
while bugs will pop up which might trick a browser into not properly making
this check, but that's a bug in implementation not a bug in the design.
I should also note that any Tor exit node can perform a man-in-the-middle
attack in addition to just sniffing passwords.
So, in essence, the problem here is not just something you find with
Unless you happen to check the javascript source every time you type in your
password, this would still be subject to a man-in-the-middle attack. Using
client certificates which are distributed using a pre-established secure
channel would probably be the best security, but installation is not that
user-friendly and roaming is difficult (of course, you might say that it's a
security risk to use Wikipedia from a coffee shop in the first place, but I
think you're overvaluing the importance of absolute security on a site that
anyone can edit).
Using this javascript hashing scheme has one drawback in that it requires
the unencrypted password to be stored in the database. This isn't a drawback
if you look at security in a binary way, because someone who has access to
modify the server could get the unencrypted password anyway, but it would
make it somewhat easier especially for someone who only has access to the

@_date: 2005-10-31 10:19:01
@_author: Anthony DiPierro 
@_subject: Wikipedia and Tor - a solution in the works? 
Well, you see security as binary, I don't. I look at the chances that
something is going to happen, and by increasing the number of people who can
break the security from a relatively small number (I happen to live in the
same city as the Wikipedia servers) to potentially anyone in the world, I
see that as a negative thing. Apparently you don't.
 Yes, it's possible that someone could steal the private key of the service
who couldn't otherwise steal the information directly. And that same person
might happen to be able to mount a man-in-the-middle attack. But I think the
chances of that are relatively slim compared to the chances of them simply
attacking the service directly.
 You've simply changed the password from one to another. This might be
useful if the original password was was used on multiple sites, but
otherwise it's rather useless, because the original password is no longer
needed to access the site, only the hashed password (and some client-side
tweaks to the javascript).
i have yet to encounter a competent authentication system which does not
 You don't seem to understand how a man-in-the-middle attack works. In this
type of attack the data going from the server to the man-in-the-middle is
different from that going from the man-in-the-middle to the client. The
man-in-the-middle would simply turn off the hashing of the password in the
javascript presented to the client. They'd then get a copy of the original
plaintext password and could use that to generate the hashed password to
access the site by emulating the javascript presented to them from the
 Yes, performing a man-in-the-middle attack over SSL is difficult. But
that's why simply providing the password over that SSL connection is usually
acceptable. All the fancy hashing amounts to essentially no security against
any type of attack. This presumes of course that users don't use the same
password for multiple sites, and that they use passwords that are difficult
to guess. But if they don't, that's their problem.

@_date: 2006-04-28 07:39:02
@_author: Anthony DiPierro 
@_subject: Is three hops enough? (was Re: Tor client over a SOCKS proxy, and Tor client running through another Tor Circuit) 
The way I picture it it would basically be equivalent to adding extra
hops.  I remember reading this is possible to hack into the standard
tor software, but I believe it requires a recompile and not just a
config file tweak.
Anyway, it is my understanding that the current default implementation
uses three hops.  Now am I correct that that includes the exit node? Does it also include the entry node which is generally on the same
If so, it seems that in the current default implementation only one
compromised node, the middle node (working with the destination site),
is needed to significantly impact your anonymity.  The IP address of
the exit node is generally recorded in web logs along with the time
and date.  So if the middle node records the incoming and outgoing
node IP addresses, that can then be matched up with the web logs.  If
someone is using three hops the way I described it above, then the
incoming IP address would be the address of the tor user, right? Sure, you'd have a little bit of plausible deniability, as there's no
proof your system was set up this way, but that's it.
Now hopefully I'm just wrong about what constitutes three hops (or
that the default setting is three hops).  Or maybe I'm missing
something as to why this type of attack isn't possible.
One thing seems almost certain, adding hops does increase the security
against a compromised node attack.

@_date: 2006-04-28 08:17:11
@_author: Anthony DiPierro 
@_subject: Is three hops enough? (was Re: Tor client over a SOCKS proxy, and Tor client running through another Tor Circuit) 
OK, thanks for the correction.  So the standard implementation (using
privoxy and firefox, for instance), would be:
firefox (local) -> privoxy (local) -> tor client (local) -> tor 1
(remote) -> tor 2 (remote) -> tor 3 (remote, exit node) -> webserver?
Well, it's a matter of what type of odds are acceptable to you.  If
1/100th of circuits are compromised, I'd consider that too high.  Now
under the diagram I drew above, that'd require about 1/10 of the nodes
to be compromised.  If you add in another hop, then 1/10th of the
nodes being compromised would mean only 1/1000th of circuits were
Or am I calculating something wrong?

@_date: 2006-04-28 11:47:07
@_author: Anthony DiPierro 
@_subject: Is three hops enough? (was Re: Tor client over a SOCKS proxy, and Tor client running through another Tor Circuit) 
The way I understand it, an attacker would need to compromise all the
nodes except for the exit node (and the start node, of course) - *not*
that they need to compromise any two nodes in the chain.
If there is an attack that can be made, for example, over a 9 hop
chain where an attacker only has two nodes compromised, I'm not sure
what it is.  I suppose there could be some sort of timing attack, one
that can't be easily mitigated by cover traffic.  Maybe that's what
I'm missing.

@_date: 2006-04-28 12:28:37
@_author: Anthony DiPierro 
@_subject: Is three hops enough? (was Re: Tor client over a SOCKS proxy, and Tor client running through another Tor Circuit) 
I'm going to have to delve deeper into the design and other docs.  I
thought I understood what was going on to some extent, but the more I
think about it the more questions I have.
Thanks for bearing with me and my semi-newbie questions.

@_date: 2006-04-28 12:51:35
@_author: Anthony DiPierro 
@_subject: Is three hops enough? (was Re: Tor client over a SOCKS proxy, and Tor client running through another Tor Circuit) 
Well, if it only takes 2 compromised nodes in a circuit to compromise
that circuit, then Tor isn't really useful for anything other than
keeping your IP address out of server logs.  That's fine, as that's
all I use Tor for anyway, and it works well for that limited purpose. I just thought there was more potential.
Anyway, as I've said in my other post, I need to delve a lot deeper
into the design information.  I should probably build my own client
while I'm at it - to really understand what's going on.
Thanks for your help and information.

@_date: 2006-08-21 13:04:13
@_author: Anthony DiPierro 
@_subject: Exit Node sniffing solution...an idea... 
It's not just defeating geolocation.  It's about not having your IP
address tied to your identity (at least, not without collusion with
your ISP).
I suppose renting a shell account somewhere and using SSH redirection,
only when identifying yourself and for no other purpose, would solve
approximately the same purpose.  But that's a lot more complicated
(and a little more expensive) than just using Tor and making sure you
clear your cookies before logging in and after logging out of any
services where your identity is revealed.
Plus you'd have to have a different SSH account for every single
pseudonym you use.

@_date: 2006-02-11 07:44:47
@_author: Anthony DiPierro 
@_subject: [declan@well.com: [Politech] Lawsuit challenges law targeting Internet "annoyances" [fs]] 
Wow, that's one of the most ridiculous laws I've ever heard of.  It's
actually a law I used to joke about when people talked about
legislating spam.  What's next, I used to say, a law against trolling
on [insert name of forum here]?
Hopefully the courts will refuse to acknowledge such a blatantly
unconstitutional law.  I've pretty much given up on the sanity of the
United States Congress, but the Supreme Court seems to still have a
little bit left.
Interestingly, the law refers to "interstate or foreign
communications" and not "interstate or foreign commerce", which means
in addition to the First Amendment it's probably in violation of the
Anyway, the even scarier section in terms of Tor is "(2) knowingly
permits any telecommunications facility under his control to be used
for any activity prohibited by paragraph (1) with the intent that it
be used for such activity".  Now "knowingly" and "with the intent" are
rather high hurdles to reach, but it is one step closer to outlawing
Tor altogether.
Anyone got any suggestions on where to move to?

@_date: 2006-01-17 06:19:13
@_author: Anthony DiPierro 
@_subject: You think you can hide your ip? 
I'm assuming what is being done is that java is being used to connect
back to the site - this will reveal the IP address because java
doesn't go through the proxy.
I looked really quickly, and there doesn't seem to be an easy way to
disable just this one java feature (to make TCP connections) without
disabling java completely (at least not on firefox, there *might* be a
way to do it on IE which has differing java security levels, but I
didn't really look into it because I don't really use IE with tor).
Another option would be some sort of restrictive firewall.  There is
software for Unix and Windows that can restrict the ability to make
connections on a program by program basis.  Limit connections only to
Tor and you know you won't make any leaks (this could be turned on and
off when switching Tor on and off).
Personally I have java on my firefox browser turned off, party for
security reasons and partly for performance reasons.  I've found it
really doesn't affect many sites that I use.  For those few sites it
does affect, I use IE.  Now that I think about it there is likely a
firefox extension which can easily turn java on and off (maybe even on
a site-by-site whitelist basis), though until Interactive Brokers
decides to support something other than IE (or someone else offers $1
stock trades) I'm kind of stuck.
I'm curious, what are the favorite sites you have which insist on
java?  The only one I really go to more than rarely is Yahoo Games,
and it's pretty obvious why they need java.  Now if only there were
enough sites which don't require javascript...

@_date: 2006-06-04 08:32:10
@_author: Anthony DiPierro 
@_subject: FW: [Full-disclosure] Tool Release - Tor Blocker 
I can't wait until IPv6 finally becomes widespread.
On another note, Tor is big and getting bigger.  Plus there are a
number of Tor nodes that are on dynamic IPs.  Blocking them all is
going to become more and more painful.

@_date: 2006-05-15 18:30:22
@_author: Anthony DiPierro 
@_subject: Some legal trouble with TOR in France 
OK, that covers the defendant, but what if the person in question is
not a defendant?
Unfortunately, the First Amendment does not seem to apply to
questioning by a court (or Congress, for that matter).  The Fifth
Amendment protects you from being a witness against yourself, but it
doesn't protect you from being a witness against someone else.

@_date: 2006-05-15 20:37:43
@_author: Anthony DiPierro 
@_subject: Some legal trouble with TOR in France + 
There's always the possibility of letting each exit node decide for
itself what subjective judgement to make.  And in fact that's what is
being done.  Some exit nodes allow port 25, some don't.  Some allow
6667, others don't.  Some exit nodes only allow port 80.  You can
likewise filter by IP address.
The only real problem is that it's not feasible to effectively filter
out the type of traffic you don't want (especially in a way which can
be described in an exit policy).
Remember that by default Tor *does* censor.  Port 25 is blocked by
default.  Why is this?

@_date: 2006-05-16 06:42:21
@_author: Anthony DiPierro 
@_subject: Some legal trouble with TOR in France + 
I don't think it is.  It's not that hard, after all, for a government
entity which can spy on your connection and the endpoint connection to
correlate the two using traffic analysis.
Tor is useful for plenty of legal things.  If there were a way for
each exit node to filter out any traffic which was illegal in its
jurisdiction, Tor would still be useful.  This is not at all feasible
right now, though.
Large backbone routers aren't equivalent to exit nodes.  They'd be
more equivalent to middle nodes.
Unless you're using a secure connection (https, ssh, etc.) you should
always worry that you might not be actually connecting to the site you
think you are.  Sure, you could take away RedirectExit (I'm not
actually up on the useful purpose of it), but that'd only take it away
from people playing by the rules.

@_date: 2006-05-16 19:59:47
@_author: Anthony DiPierro 
@_subject: Some legal trouble with TOR in France 
And we do this by censoring a blacklist?
I don't have a problem with the police coming up with a "blacklist".
I don't even have a problem with people following it.  But the way I
see it Tor is about privacy, not censorship.
Personally I have more of a problem with going to jail than not being
able to convince institutions to sponsor my computing/bandwidth
expenses.  I don't think I'm alone, either.  If people could run an
exit node and still avoid getting mixed up with the law by
implementing a particular blacklist, I think the number of exit nodes
would go up dramatically.
But, as I've said in most of my replies to these threads, I don't
think such a solution is currently feasible.  Actually what would be
more feasible is a whitelist.  Maybe some exit nodes could provide a
list of the most popular exit IP addresses.

@_date: 2006-05-16 21:13:11
@_author: Anthony DiPierro 
@_subject: TOR on Academic networks (problem) 
What'd be preferable to both of those, but even harder to implement,
would be to route that traffic (or even all traffic) through a
transparent proxy with an IP outside the /16.
'Course if you're going to do that, you might as well just be a middleman node.

@_date: 2006-05-17 15:39:19
@_author: Anthony DiPierro 
@_subject: TOR on Academic networks (problem) 
That's a good solution for the long run, and I'm sure if you provide
the patches it'll get implemented quite quickly.
In the mean time, if I were running a directory server (and I'm not),
I wouldn't allow you in the directory if I knew your exit policy
wasn't valid.  Sure, it might not negatively affect many people, but
the alternatives, to take you out of the directory or to add *:80 to
your reject list, would negatively affect no people.

@_date: 2006-05-21 19:29:54
@_author: Anthony DiPierro 
@_subject: "User.Actions" Template 
I thought a browser was supposed to warn you of this "mixed content"
situation (an http site with https images, for instance), but checking
Firefox apparently it doesn't!
Anyway, it seems like the only proper solution here is to not use
privoxy at all, this way https and http both present exactly the same
header information.  But this of course means taking all the
identifying information out of your browser - easier said than done.

@_date: 2006-05-24 07:28:37
@_author: Anthony DiPierro 
@_subject: Aren't exit node names supposed to be unique? 
It would seem to me that exit node names should be unique, in part in
order for ExcludeNodes to work.  But a recent download of the list
showed the following (just the two relevant lines):
US godzilla                3635 B/s 68.42.126.128   MICHIGAN-3
          22   53   80  110    -  143  443 5190 6667
NO godzilla               25600 B/s 80.203.228.236  NEXTGENTEL-NO
          22   53   80  110    -  143  443 5190 6667
Does this mean that these two nodes have the same owner/key/etc?  Or
is it a bug?  Or maybe something else?

@_date: 2006-05-24 07:56:51
@_author: Anthony DiPierro 
@_subject: Aren't exit node names supposed to be unique? 
Thanks for the info.  It looks like that perl script on serifos needs
to be updated, since nicknames aren't unique.  Specifically, the
desc.pl takes a query where the variable "q" is set to the nickname of
the router.
Now I guess I should look into accessing this information more
directly instead of scraping someone else's tor script output :)

@_date: 2006-05-24 18:57:49
@_author: Anthony DiPierro 
@_subject: Aren't exit node names supposed to be unique? 
works too.  Cool.
And Geoff, thanks for the response.

@_date: 2006-05-13 19:15:55
@_author: Anthony DiPierro 
@_subject: Some legal trouble with TOR in France 
If I understand things correctly then the name of the node should be
told to someone who can permanently take it out of the directory
servers.  Is this possible/necessary?  Or does everyone have to add an

@_date: 2006-09-20 17:00:10
@_author: Anthony DiPierro 
@_subject: Using Gmail (with Tor) is a bad idea 
If you use  to login, then you will remain
using https after you log in.  If you use  to
login, you won't.  This is covered in one of gmail's FAQs.
(Incidently, it also seems to work to go to  and
then change the "continue=http" to "continue=https" in the url).
Is this the solution, or is the issue something different?

@_date: 2006-09-20 17:51:44
@_author: Anthony DiPierro 
@_subject: Using Gmail (with Tor) is a bad idea 
OK, so if you're careful, and enter through you're fine, as long as you don't go to *any* http site before you
clear your cookies.
But if you log in to gmail, even through https, then you go to a an
http site (like  for example), then your session
can be stolen.
Assuming this can't be turned off, the only real workaround I think
would work is to disable the http proxy.  This might be realistic, you
could switch between three proxy settings, one for normal browsing,
one just for gmail/tor (which would send http requests to a proxy at a
nonexistant IP address), and one for normal tor browsing.  These three
settings could be managed through SwitchProxy, which would
automatically clear cookies between each one.
For those gmail diehards (like me) who want to hide their IP address
from gmail (not a bad idea), it might be a reasonable workaround.
And considering how many sites, including financial sites, are happy
to send you a new password by email, getting your gmail session stolen
could be really horrible.

@_date: 2006-09-21 11:57:58
@_author: Anthony DiPierro 
@_subject: Using Gmail (with Tor) is a bad idea 
I haven't really found any (gratis) clients I like that well, not that
I've done a very thorough search.  Gmail's filtering does kind of
suck, though.

@_date: 2007-01-27 18:06:35
@_author: Anthony DiPierro 
@_subject: more letters from the feds 
If *nobody* is willing to run an exit server the performance drops to
zero (at least for all but hidden services).
That brings up an idea, though.  Are there certain common perfectly
legitimate things that exit nodes are being used for, that maybe some
hidden services could be set up to take the load off?  For instance,
one could set up a hidden service to search Google or to read
Wikipedia, things which aren't going to attract any negative
attention, but which would take the load off an exit server.
Or what about a hidden service for reading web pages in general?
Something which doesn't support POST (or maybe even GET), so is much
less likely to be used abusively.  Is this feasible?

@_date: 2007-01-28 14:12:43
@_author: Anthony DiPierro 
@_subject: more letters from the feds 
Hidden services don't require exit nodes, so if exit nodes are the
bottleneck, then moving traffic from exit nodes to middleman nodes
will improve the entire network.
As for "if a hidden service does the job of an exit node you might as
well consider it as one", I'm not really sure what that means.  What
if a hidden service does *some* of the jobs of an exit node?  Do you
count it as part of one?
The risk is the same for the same services, but there's no requirement
for a hidden service to, for instance, forward POST requests, which I
would think greatly reduces the risk.  If one runs an exit node,
they're agreeing to forward all requests, not just GET requests or GET
requests without any parameters, and not even just HTTP traffic (as
was pointed out, any traffic can go over port 80).

@_date: 2007-01-28 14:23:14
@_author: Anthony DiPierro 
@_subject: more letters from the feds 
A port 80 only exit node is possible.  This isn't the same as an exit
node which can only be used for reading web pages).
Yes, exactly.  What you could do, though, is run a hidden service
which provides anonymous "HTTP GET-only" web access, and you wouldn't
have to break any protocols or cause anyone to get mad.  *IF* that
hidden service became popular, it could potentially take a lot of load
off the exit servers.
Anyway, just an idea I was throwing out there.  The big questions are
1) is there enough traffic which consists only of browsing websites to
make it worth it, and 2) are there enough people willing to run "HTTP
GET-only" hidden services to make it worth it?  Personally I'd answer
a resounding "yes" to question 1 in that I use Tor primarily for "HTTP
GET", but as I'm currently on a relatively slow EVDO connection I
couldn't answer "yes" to question 2.

@_date: 2007-09-11 07:03:51
@_author: Anthony DiPierro 
@_subject: Filtering traffic from your node - for exit points 
The only problem I have with the latter is that blocking beyond IP
and/or port blocking is not handled by the directories.

@_date: 2007-09-11 07:11:31
@_author: Anthony DiPierro 
@_subject: Filtering traffic from your node - for exit points 
Or run an exit node which exits only to itself, then run a filtering
proxy service which is reachable through that exit node.
If enough people did that, we could build a separately directory of
such services, and anyone using it would take load off the exit nodes
(and maybe get a faster browsing experience to boot?).
The Tor developers rightly don't want to put application layer
filtering into Tor itself, but that doesn't mean you can't build an
HTTP proxying service *on top of* Tor.

@_date: 2007-09-11 12:43:16
@_author: Anthony DiPierro 
@_subject: Filtering traffic from your node - for exit points 
Not that I know of.  I basically came up with it myself.

@_date: 2007-09-11 13:37:16
@_author: Anthony DiPierro 
@_subject: Filtering traffic from your node - for exit points 
I thought this was handled by "exit enclaves".  See
Well, yeah, this would handle the "directory server" mechanism
completely outside of Tor.  You'd have to specifically set up privoxy
to connect to those filtering proxy services through tor.

@_date: 2007-09-22 15:51:07
@_author: Anthony DiPierro 
@_subject: Load Balancing 
Why does new circuit creation use up so much CPU?  Are you spawning a
new thread for each circuit, or something?  If so, maybe there's a way
to be more efficient instead?
I know, I know, I shouldn't complain if I'm not going to offer code.
So don't consider this a complaint, just a question.
