
@_date: 2007-04-20 18:41:43
@_author: Mike Perry 
@_subject: Using a Proxy with Tor 
Thus spake Tarek Tag (ttag at ironkey.com):
Yes, you need to set both. HttpProxy only proxies directory traffic.
HttpsProxy proxies Tor node traffic. Also, if your proxy only allows
connections to limited ports, you must specify FascistFirewall and
FirewallPorts for those ports, or the more recent (and slightly more
complicated) ReachableAddresses config.
Regretably the proxy behavior with Tor is not all that good. For
example, if for some reason the proxy is unreachable, it fails
silently and reverts to non-proxied connections. If the proxy refuses
to allow you to connect to a particular IP/port (for example, if you
do not specify FascistFirewall), it prints out a warn, and then
reconnects without using the proxy.

@_date: 2007-04-23 01:56:22
@_author: Mike Perry 
@_subject: Using a Proxy with Tor 
Thus spake Roger Dingledine (arma at mit.edu):
The above was what I noticed while briefly testing SETCONF HttpsProxy
via the control port for different proxies, some unreachable, some
that gave me 403 errors. It seemed that after the proxy failed once,
it was ignored. Sometimes it failed silently and then was ignored.
I suppose I could have been doing something strange accidentally. Or
maybe the control port setting wasn't properly being propagated. I can
retest sometime next week if you need me to.

@_date: 2007-08-20 21:00:55
@_author: Mike Perry 
@_subject: Linux Tor node prioritization script 
So I've posted this script before, but that was over a year ago,
probably should re-announce it.
I've created a Linux 'tc'-based tor prioritization script, ideal for
running Tor nodes on Linux machines that have multiple IPs with
non-Tor traffic on them that you would like to take priority over Tor
traffic. Using this script, it is possible to set a minimum guaranteed
bandwidth for your Tor node, and to allow it to take up all unused
bandwidth up to another maximum value you specify. I use it on a few
different types of links, and it is very nice. You can allow Tor to
take up essentially an entire link, but still have that link usable
for ssh, web, etc. I don't even feel the impact of Tor traffic on
nodes that use this script.
It is in svn at and soon to be in the various source tarballs.

@_date: 2007-08-01 21:47:45
@_author: Mike Perry 
@_subject: Torbutton 1.1.6-alpha 
Thus spake Kees Vonk (keesvonk at gmail.com):
Is this bug reproducible? Does it happen every time for this website
even after successive restarts of the browser? I am having
difficulties reproducing this...
At a glance, I would suspect NoScript may be the culprit. If you
disable that thing, does the issue persist?

@_date: 2007-12-10 14:25:41
@_author: Mike Perry 
@_subject: torbutton webpage comments 
Thus spake Eric H. Jung (eric.jung at yahoo.com):
My apologies. The statement has been corrected.
Yeah, unfortunately despite Mozilla's impressively extensive work
making almost every browser behavior into scriptable, contractable
components, most Firefox APIs suffer from a particularly annoying
aspect of braindamage: They almost never provide the context of the
browser window, tab, and/or DOMWindow that they are happening in. As
I'm sure you're aware, you have to bend over backwards in all sorts of
weird ways to get this sort of info without falling prey to various
race conditions and window focus issues (for example, almost all of
the mozilla documentation gives example code to get the currently
FOCUSED navigator window, calling it the "most recent window", but
this is not the actual one that just performed whatever network IO or
action caused your API hook/callback to be called).. My guess is your problems arise from this issue being the case with
nsIProtocolProxyFilter, right?  My suggestion would be recording this
context from somewhere that recieves the event first and making a
cache. Torbutton does this with its content-window-mapper:
That component may be helpful for you to use as a starting point to
map DOMWindows to tabbrowsers, but you probably need another layer for
URLs themselves.  Probably you want to go with a dummy
nsIContentPolicy that gets the window for a URL fetch (see
for how torbutton does this), then use the torbutton window mapper to
map this to a tabbrowser, then use your own custom component to map
that URL to that tabbrowser..
If you are real lucky, your nsIContentPolicy will always be called
before your nsIProtocolProxyFilter, and thus your URL->tabbrowser
mapper will always have the correct (and most recent/current)
tabbrowser, which you would then use to look up the appropriate proxy
in your filter based on the tabbrowser's contentWindow.top.location
URL instead of the one handed to nsIProtocolProxyFilter.applyFilter.
If you are no so lucky wrt to the ordering of those two interface
calls, perhaps the doc loader service can provide you with similar
context information that you can cache, but its unclear if this will
give you ALL url evens like the content policy will:
The page has been updated. Again, sorry for spreading any
misinformation. I hope we can work together to provide users with as
many secure and easy to use privacy-enhancing options as possible.
Please feel free to borrow any Torbutton source code to help improve
FoxyProxy. I will be posting a design document within a week or so
that should help you more easily navigate all the crazy hacks I have
done to deal with the various idiosyncrasies of Firefox component
behavior and context wrt privacy and safe Tor usage.

@_date: 2007-12-10 15:13:52
@_author: Mike Perry 
@_subject: torbutton webpage comments 
Thus spake Mike Perry (mikeperry at fscked.org):
Oh, I should probably also mention that of course this approach has
its own fun race conditions that need to be addressed. For example,
say you trust washingtonpost.com but not foxnews.com, but both source
an ad from doubleclick.net. There is then a race between which tab
fetches the URL, potentially transmitting cookies for both.
You can try to fix this with some kind of priority system, where tor
windows always cause their URLs to replace old entries in the cache
but lower priority fetches cannot expire the entries placed by Tor or
corporate security proxies.
I still have no idea how you would handle the cookie jars per tab,
cache per tab, history attributes per tab, user agent per tab, and
many of the other security features the Torbutton dev provides
though... You might be able to handle cookies and user agent per tab
by manually creating the headers yourself a-la refspoof (which uses
nsIHttpChannel and nsIRequestObserver I believe)..

@_date: 2007-12-18 18:16:04
@_author: Mike Perry 
@_subject: Firefox extension "SafeCache"? Thoughts? 
Thus spake jeffery statin (jeffstatin at yahoo.com):
The alpha version of Torbutton (
should clear your browser cache on Tor toggle. However, SafeCache may
still be helpful to have if you are not the type to toggle Tor very
often or restart your browser (since it isolates the cache on a per
domain basis). It should work fine with Torbutton, but I have not
tested it. Please let me know if you notice any bugs.

@_date: 2007-07-18 01:31:00
@_author: Mike Perry 
@_subject: Torbutton 1.1.5-alpha 
Torbutton 1.1.5 has been released at The changes are small, but significant:
 * bugfix: Reset shutdown option if user wants to manually manage cookies
 * misc: Add code to detect date hooking failures to zero in on Bug  * new: Pref to disable "DOM Storage" during Tor usage
Bug  is a potentially nasty issue where in some cases the
Date/timezone hooks aren't properly applied. The 1.1.5 code should pop
up an alert now when this is the case. The alert will say either
"False [win/doc] hooking. Please report bug+website!" or "Error,
double js-hook". Please report either of these ocurrances plus the
website plus what else you may have been doing either here or in the
In the meantime, you should be safe from timezone disclosure so long
as those alerts are not present, but please be vigilant.
There also is an uncomfirmed bug that in some cases cookies may not be
cleared during Tor toggle (and probably only when you are using
certain options also). Please keep an eye out for this one.
P.S. Thanks go to Steve Topletz of Xerobank for the DOM Storage tip.

@_date: 2007-07-18 19:43:34
@_author: Mike Perry 
@_subject: On the performance scalability of Tor 
Thus spake Robert Hogan (robert at roberthogan.net):
(Excellent observations Steven. I think you're spot-on. I've long
suspected this sort of behavior also. The converse is why I always
argue to make Tor more efficient to get more users. Also, I think
first Tor needs to fix balancing issues before more nodes can even
really support more users to begin with).
Well, also, the bandwidth of Tor fetches can vary considerably, and in
a balanced network this shouldn't be the case.  Currently, the middle
of the network is overloaded due to guard bug  and exit clipping.
I published a brief study of this in December, though at that point I
did not yet know the cause.
The 35-45% tier nodes are much more unreliable than the upper AND
lower bandwidths. Note that the guard node cutoff is about 50% by
I think this plus the exit issue are one of the reasons why Tor
bandwidth performance is irregular. Another major other reason being path
selection issues: like crossing the atlantic ocean 4 times to retrieve
some document.
The problem is the round trip time to create the TCP connection. A
client has to tell the exit to create the TCP connections somehow.
RELAY_EXTEND is the way this is done. I believe clients can and do
send multiple RELAY_EXTENDs in a row, so it's not like its a
chattyness issue.. Sending multiple requests in a row is effectively
the same as sending a single request with a bunch of "please connect"
requests stacked in it, from a networking standpoint. You just have to
wait for the requests to cross n oceans and 3 queues on the way out,
and on the way back. So long as you are not waiting for them to be
sent one at a time, you are going about as fast as you can go.
So, pipeling may or may not help this aspect, at least. So long as the
circuit is reused, it probably is not terribly significant as to
whether there is a single RELAY_EXTEND that will set up a pipelined
HTTP request, or a bunch of RELAY_EXTENDs issued in parallel for a
bunch of HTTP requests. What probably matters more is how many
concurrent proxy requests your browser is willing to issue.
Concurrency is main way to mitigate request/response latency..
But, that being said, the one case where pipelining WILL help more
than just multiple HTTP requests is if you have a high latency between
your exit and your TCP destination. High latency makes TCP slow start
a real bottleneck for short-lived connections like HTTP. So if you
exit out of germany to fetch documents in the US, you will spend most
of your time waiting for TCPs congestion windows to grow up to fill
the BDP of their links.  If you use pipelining, one TCP connection and
thus only one TCP slow start is incurred for these fetches. So that
can be a huge bonus for cross-oceanic webpage downloads.
P.S. Yes, I do know way too much about this sort of thing. :)

@_date: 2007-07-18 19:52:14
@_author: Mike Perry 
@_subject: On the performance scalability of Tor 
Thus spake Mike Perry (mikeperry at fscked.org):
Sorry, I'm a moron. I meant to say RELAY_BEGIN. Also, Roger/Nick,
please correct me if these can't be issued concurrently.

@_date: 2007-07-18 21:25:23
@_author: Mike Perry 
@_subject: On the performance scalability of Tor 
Thus spake Roger Dingledine (arma at mit.edu):
Yeah, cause it's not like optimizing high latency networks and chatty
protocols for speed is my day job or anything. Probably should wait
for the expert to weigh in to really be sure ;)

@_date: 2007-07-22 21:16:18
@_author: Mike Perry 
@_subject: Tor takes too much RAM 
Thus spake Roger Dingledine (arma at mit.edu):
I have done this, and have been running 0.1.1.26 for about a couple
weeks weeks. It appears to be leaking at about the same rate as
0.1.2.14 did.
Since this problem suddenly showed up, yet 0.1.1.26 has been out for
ages, perhaps it is a client problem? There is that issue where
clients can send too many SENDMEs and fill up server buffers.. Maybe
there is a SENDME leak?

@_date: 2007-07-30 17:20:37
@_author: Mike Perry 
@_subject: Torbutton 1.1.6-alpha 
30 Jul 2007
  * bugfix: Fix an exception that may have messed up cookie/cache clearing
    if you allowed Tor to write history URLs (possibly kills bug   * bugfix: Use only sub-browsers for tagging. Could fix some Date
    hooking misses (possibly kills bug   * misc: Clean up annoying false positives with date hooking checks
I've been running this version for a week or so now, and I have not
seen any alerts about missing Javascript hooking. It is possible the
bug has been fixed by those other fixes, plus I cut down on the false
positives for those alerts.
As always, please keep an eye on Torbutton to make sure it is actually
properly blocking plugins, always properly clearing/isolating
cookies+cache, disabling javascript for pages loaded in an opposite
Tor state, and blocking CSS popups for the same.

@_date: 2007-07-09 02:16:55
@_author: Mike Perry 
@_subject: New Torbutton (1.1.4-alpha) 
As some of you know, I've been working on a security-enhanced version
of Torbutton to handle all sorts of anonymity vulnerabilities present
in a standard Firefox configuration (see the big fat warning on
 - the goal is to make all that
text irrelevant). I will be presenting this plugin as a part of my
talk "Securing the Tor Network" for Black Hat and Defcon.
The goal of the extension is to make it possible to use modern
websites via Tor without the risk of something reducing your anonymity
set or bypassing proxy settings.
The major features are:  * Disabling plugins while Tor is enabled
 * Isolating dynamic content to the Tor state at document load
 * Cookie jars/cookie clearing
 * Cache management
 * History Management
 * User agent spoofing
 * Timezone spoofing
The extension itself, and more information on the individual
features/options are available at the horrifyingly stoic homepage:
Currently, only FireFox 2.0 is supported. Kind-hearted souls are
sought to help port to Seamonkey and Thunderbird.
Feedback, suggestions, and comments are welcome. Especially if someone
could point out what I'm doing wrong with the OpenSearch Google search
plugin installations (which are somewhat unrelated, but I figured were
worth putting up there, since a major usability complaint is "Why do I
get the damn German/Chinese/etc Google with Tor?").

@_date: 2007-07-10 15:04:29
@_author: Mike Perry 
@_subject: New Torbutton (1.1.4-alpha) 
Thus spake Roger Dingledine (arma at mit.edu):
This is a good question. For any non-XUL binary plugins, there is no
hope. For the stuff that is implemented as javascript, we have a
prayer of it obeying proxy settings, but it can also randomly disable
those as it sees fit. Other extensions can also send unique
identifiers at inconvenient times (stumbleupon and other such website
recommenders come to mind).
So these types of warnings should remain, sadly. But the gauntlet of
recommended plugins and such can be removed at least. I would say we
can do away with warnings 2 and 3, assuming people will use the
defaults of Torbutton and heed the relevant warnings it has in its
own documentation when changing them.
Well the bugs are marked as fixed.. Not sure of their backport status
though. The web development community loves to bitch about them, so
hopefully firefox will backport into 2.0.0.5 or something. I probably
will add the tooltips anyways, so we have the strings there and
translated to create a help page if the fixes are never backported.
Javascript is never going away, might as well get used to it. :) It's a
shame that particular javascript is broken though. Perhaps it is a
mimetype issue or something. Hopefully I or somebody can figure out wtf is going on so people can install the search plugins easily. I know
they are a huge convenience bonus for me.
Unless you think I should explain to the Windows users how to manually
download and copy xml files into their firefox install directory, so
they don't have to use javascript? ;)
Should it automagically switch to "Let me manage my own Private Data
Settings"? I cannot overemphasize how dangerous this setting is though.  If you
preserve any non-tor cookies during tor usage, these cookies can be
fetched by exit nodes, even if you were not visiting that website at
the time. This allows them to do things like download your entire gmail,
yahoo, or whatever inbox behind your back without your knowledge, from
a SINGLE Tor-based visit OF ANY WEBSITE.
Of course, the same thing can happen at your local coffee shop. But
how many local coffee shops are run by an ad-hoc collection of
thousands of semi-anonymous hackers? :)

@_date: 2007-07-10 15:22:35
@_author: Mike Perry 
@_subject: New Torbutton (1.1.4-alpha) 
Thus spake kara.ml at arcor.de (kara.ml at arcor.de):
I run these two. No conflicts so far.
I briefly tested this. It seems to play nice. I would advise against
setting a different user agent during Tor usage though, because of
anonymity set reduction. Torbutton already masks your user agent to a
popular recent windows firefox build (and does a better job of it
These two are superceded/assimilated by Torbutton in one form or another.
Might be useful for Non-Tor usage, but Tor usage will have all
plugins disabled. Would be interesting to know if flashblock can
somehow re-enable it, but I doubt it.
No idea. I don't really like this thing. Also note that Tor nodes can
inject script from the default whitelist, so it doesn't really protect
you there.
Hopefully this functionality will be assimilated into Torbutton.
Actually, are you aware of sites that their "Forge" functionality
still breaks? That is what I was considering implementing for all
sites with Torbutton. Looks relatively benign.
Dunno about these guys. Please report any issues.

@_date: 2007-07-11 01:49:45
@_author: Mike Perry 
@_subject: New Torbutton (1.1.4-alpha) 
Thus spake Ryan Wagner (starshadow10101 at gmail.com):
This is tied in with the history writing setting. The idea was that if
you are OK with tor writing out these things, then you are ok with it
saving your history and vice-versa. However, this idea may be slightly flawed since you could be concerned
about history disclosure attacks from regular websites you visit.. So
maybe it should be a seperate option..

@_date: 2007-07-11 01:55:13
@_author: Mike Perry 
@_subject: New Torbutton (1.1.4-alpha) 
Thus spake Jens Kubieziel (maillist at kubieziel.de):
Is there a good reason behind this wish? The cache can store unique
identifiers almost as easily as cookies can.. Though at least it is
not used for authentication, I suppose.
Is this just not a concern for you, or is ther another extension you
prefer to use?

@_date: 2007-07-11 02:10:36
@_author: Mike Perry 
@_subject: New Torbutton (1.1.4-alpha) 
Thus spake Robert Hogan (robert at roberthogan.net):
Actually, this is possible a few different ways.. You can create your
own protocol handlers, but it might not be necessary. Torbutton
already listens to the LocationChange event.. It may be possible just
to look to see if the new location has a .onion/ in it, and enable tor
if so. But this probably should be pondered for a while.. Changing tor
state automatically makes me a little nervous, even if it is only in
the "Tor Enabled" direction..
And creating a new protocol prefix for onion sites seems a little
sketchy also.. All sorts of compatibility issues are probably hiding
in there (not just the obvious problem of adoption).

@_date: 2007-07-12 15:34:49
@_author: Mike Perry 
@_subject: New Torbutton (1.1.4-alpha) 
Thus spake Jens Kubieziel (maillist at kubieziel.de):
But why? I can actually create a lot more options if you just want
choices. There are a couple things torbutton just does automatically
(like making sure you never query google's safesearch for every url on
the fly), and some actions (like the web history+form history+login
history option) come bundled together as a single option.
Torbutton is already bordering on an obscene number of nobs.. There is
room for this one, I guess.. But if I do this, and split the history
options out into seperate settings, we're talking about at least 10
more options (6 more history, 1 more cache.. plus at least 3-4 more
others if you want *everything* to be an option). That is getting a
little ridiculous, and I'm running out of space for nobs. Is all this
really needed?

@_date: 2007-06-14 15:39:43
@_author: Mike Perry 
@_subject: What will happen to Tor after the new German data retention law takes effect? 
Thus spake Freemor (freemor at yahoo.ca):
Code moves faster than law. No need to panic, or speculate on
technical solutions before a law is even passed. If the powers that be
are this intent on exemplifying their stupidity and pointlessly
wasting their resources on excuses to justify flawed totalitarianism
instead of addressing real problems, we should let them. We will have
plenty of time to adapt once the law is passed.
Right now, the proper avenue is well-articulated political opposition.
On a technical perspective we should be lazy with this one. It will
work to our advantage. Plus, I can't believe such measures don't run
against basic human rights and constitutional protections revolving
around search & seizure and presumed innocence. But I am constantly
surprised by the williness of my own country to shred the spirit if
not the letter of its own constitution as soon as technology comes
into consideration.. and even before that point.

@_date: 2007-06-14 18:36:42
@_author: Mike Perry 
@_subject: Cisco firewall filtering Tor? 
Hey Jay!
Thus spake Jay Goodman Tamboli (jay at tamboli.cx):
If you are running Tor 0.1.2.x or later, you can add "ControlPort
9051" to your .torrc, and telnet localhost 9051. You can then do SETEVENTS EXTENDED CIRC ORCONN
to get some info that is sometimes not reported in logs, in a
well-formed format. You can also try jacking up your log to debug
level. It then should dump a bunch of info about TLS connections
there, but that is harder to sift through.
Might also be a good idea to kill tor, fire up wireshark
( start a network capture, start tor, and let it
try to make some circuits for a bit. Then save the capture, and post
it and the control port info and possibly logs somewhere so we can
look at the results.
I believe at some point, tor changed its TLS certificate format to be
less-torlike.. But maybe this is only in SVN and not widely deployed
at the tor nodes. Roger or Nick will need to answer this question most
If they are doing content-based filtering like this, it is likely they
are also blocking directory connections too..

@_date: 2007-05-30 02:46:20
@_author: Mike Perry 
@_subject: Sampled Traffic Analysis by Internet-Exchange-Level Adversaries 
Thus spake Paul Syverson (syverson at itd.nrl.navy.mil):
Actually, I'm going to disagree slightly because I don't feel like
sleeping yet :). It would take far less resources to passively tap the
traffic and filter out say Tor IPs and do analysis on just that data
offline. Trying to actively do that filter in-path PLUS arbitrarily
delay (ie queue in memory) that traffic in real time, all without
signficantly affecting pass-through traffic seems like it would be a
lot more expensive.
Also, not to mention there is a limited number of bits that can be
reliably encoded in this manner, and the purturbations of padding that
shares the same TLS connection will lower this effectiveness. The
adversary needs enough bits to get through to be able to track all the
parties it is interested in. If padding is in place, it will have to
spend considerable effort in redundancy to make sure that the
timestamp remains present in the exit stream.. Which again means more
queueing and more expense. Of course, it also means more expense on the part of the anonymity
network in wasted bandwidth.. If padding slows down the network to the
point where users start to leave, other, more dangerous effects take
Finally, going on what has been disclosed so far in the EFF v AT&T case,
it would seem that global adversary-style mass surveilance is in fact
ocurring passively, out of path. At least the illegal domestic stuff,
anyways. I suppose it's anyone's guess what they do when it's less
blatantly illegal.. Maybe Echelon is the reason my bbc is so slow! :)

@_date: 2007-11-14 11:44:39
@_author: Mike Perry 
@_subject: 20090101 
Thus spake Smuggler (smuggler at kryptohippie.com):
Actually, out of curiosity do your lawyers believe that
upstream/backbone/IX ISPs will also be required to log (and to log the
same type of data)? That would seem to be a lot of data.. Not to
mention that upstream ISPs will not have customer information for IP
addresses. It would seem to me that Tor nodes are much more similar to
backbone routers than consumer ISPs.

@_date: 2007-11-14 11:59:43
@_author: Mike Perry 
@_subject: 20090101 
Thus spake Smuggler (smuggler at kryptohippie.com):
Oh, and I'm also wondering about redundancy. If I run a Tor node in
Germany is it the case that I have to log, AND my ISP has to log, AND
their colo provider has to log, AND the upstream ISP has to log, AND the
IX has to log all the same data? Is there any division of
responsibility? Or will there be like 5-10 copies of the same
connection data floating around everywhere?

@_date: 2007-11-27 12:12:23
@_author: Mike Perry 
@_subject: Another host in China which use persistant cookie to track Tor users 
Thus spake phobos at rootme.org (phobos at rootme.org):
If anyone wants to play with it, 'svn co
 or pull down
You start it up by running metatroller.py, and then soat.pl. The rough
edges are with respect to how the perl script depends on tsocks, wget
md5sum and a couple other 3rd party utilities. Metatroller.py is what
handles the node selection by acting as a metacontroller. One of these
days I'm planning on rewriting soat.pl to be soat.py, but I'm
currently occupied with Torbutton.

@_date: 2007-10-25 16:18:27
@_author: Mike Perry 
@_subject: Firefox IPv6 Anonymity bypass 
Thus spake Nick 'Zaf' Clifford (zaf at nrc.co.nz):
Nice. Thanks for reporting this, I will add it to the next reelease of
the dev torbutton. One thing concerns me though: Since this setting is under network.dns,
does this mean it disables using IPv6 only for DNS replies? Did you
verify this actually works to block numerical IPv6 links as well?

@_date: 2007-10-26 12:02:11
@_author: Mike Perry 
@_subject: Firefox IPv6 Anonymity bypass 
Thus spake Arrakis (arrakistor at gmail.com):
Heh, what's happened in 2007 then? Does this document still exist? A
couple of google searches fail to turn it up.
Does this in fact block ipv6 if no DNS is involved and image links are
numerical only? I am living in the dark ages of ipv4. Can someone who
has ipv6 verify this for us? From reading:
it looks like this setting is not enough by itself.
Do we know exactly what this does? It seems somewhat vague and
undocumented. Do we know any extensions it breaks?

@_date: 2007-10-02 00:06:39
@_author: Mike Perry 
@_subject: Torbutton 1.1.8-alpha (Usability improvements) 
This is the 1.1.8 alpha release of the Torbutton Firefox extension. It
features significant usability and compatibility enhancements. However,
it is still alpha software, so it may have some rough edges. If you
notice issues or have usability complaints, now is the time to speak up
while things are still easy to change. Please be specific. I have made a good effort to anticipate common usability complaints for
this release from the feedback I have so far received, but I am not
omniscient. Eventually, this Torbutton will be backported to the stable
Tor release, so if you do not speak up soon, you will be perpetually
suffering in silence and will be stuck uninstalling the extension every
time you upgrade Tor (and leaving yourself vulnerable to numerous
anonymity-compromising vulnerabilities in the process).
See  for more information.
Changes in 1.1.8
  * bugfix: bug 510: Decouple cookie clearing from Clear Private Data     settings
  * bugfix: bug 474: Decouple password+form saving from history writing
  * bugfix: bug 460: Rework handling of hooking based on global     events+window lookup
  * bugfix: Hooking fixes for pages with nested frames/iframes
  * bugfix: Cookies are now properly synced before storing into a jar
  * misc: Tightened up the alerts a bit more for the javascript hooking
  * misc: Changed defaults to be less intrusive to non-tor usage
  * new: Added options to start in Tor and reload cookies after browser crash
  * new: Added ability to have both Tor and Non-Tor cookie jars
MD5: 39ce0dc3f6b20f79042aad2397baafb4

@_date: 2007-10-02 10:24:06
@_author: Mike Perry 
@_subject: Torbutton 1.1.8-alpha (Usability improvements) 
Thus spake jeffery statin (jeffstatin at yahoo.com):
The combination of "hook dangerous javascript" and "isolate dynamic
content" make javascript safe, modulo browser exploits. The main
problems with javascript revolve around the ability to get timezone+OS
info, and to install event handlers/timers to load content after you
toggle Tor. These two issues are handled by those options
For some Java plugin+OS combos, the "Disable Plugins during Tor Usage"
is also required.  claims that they
are able to get Firefox 2.0 to call java functions from javascript.
When I tested with the Sun JRE 5.0 on Windows, this was only possible
up to and including Firefox 1.5, but not Firefox 2.0.  However it
appears that the new Sun JRE 6.0 has "fixed" this problem, and again
allows you full access to Java from javascript. Brilliant work,
impressive even for a company that has managed to give the same
product 5 different version numbers at the same time.
Note that allowing plugins is a lot more dangerous than just Java
anyways, so you should not have this setting unchecked for normal
usage unless you have some other type of upstream Tor-only firewall.
This is logistically difficult. The easier route is to add a New Nym
option to torbutton itself, and have it somehow communicate to either
vidalia or the control port directly. Allegedly raw TCP is possible
from privileged Firefox javascript, but it is likely less than pretty.
I will look into it to see if it is technically possible before the
1.2 stable release. Usability complications also arise though. If the user says they want
to keep their Tor cookies in a jar (or left alone entirely), should
new nym still clear them? I think so, esp since cookies can be
injected and stolen by exit nodes (even many https ones). But other
people may disagree.  Some people really like cookies. I wouldn't
expect those people to also like Tor, but I'm sure they're out there.

@_date: 2007-10-02 14:52:44
@_author: Mike Perry 
@_subject: Torbutton 1.1.8-alpha (Usability improvements) 
Thus spake MB (mangoblues at gmail.com):
Hrmm, unlikely. Most of the stuff the new Torbutton does is very
tightly coupled to Firefox 2.0 behavior and recently created
"unfrozen" interfaces and events. Even just supporting
Mozilla/Seamonkey properly would probably require a lot of rewriting,
and a lot of luck wrt specific behaviors being the same, or even being
However, the one good thing we have going for us is that I would think
email clients would be much more careful about running random
code/plugins that are sent to them. If the thunderbird folks are
actually careful about what they allow html email to do, it should be
fine to continue running the standard Torbutton, and we probably
should create a seperate stripped down "Thunderbutton" extension or
something like this specifically for thunderbird (ie something not too
much different than torbutton 1.0.4).
What sort of security does thunderbird employ for html mail by
default? Does it allow html mail to run javascript, post forms to
random websites, run java applets, and/or arbitrary plugins (flash,
quicktime, etc)? If it allows any of these things, 1.0.4 may not be

@_date: 2007-10-03 01:29:44
@_author: Mike Perry 
@_subject: Advanced traffic shaping with iptables? 
Thus spake Marco Bonetti (marco.bonetti at slackware.it):
Wow, nice work! I didn't see this option. Completely didn't expect it
to exist either.
Actually, my iptables manpage only says that pid, sid and command
matching are broken on SMP.  Perhaps UID is actually safe?

@_date: 2007-10-03 09:29:51
@_author: Mike Perry 
@_subject: Torbutton 1.1.8-alpha (Usability improvements) 
Thus spake Michael_google gmail_Gersten (keybounce at gmail.com):
So what does this mean to you with respect to cookie clearing? Should
a newnym signal always clear cookies? Should it sometimes clear
cookies? Should its behavior be tied to an existing torbutton cookie
preference? I'm still of the mind it's kind of silly to put it in
torbutton if it doesn't clear cache+cookies...
Gmail and many other sites are still vulnerable.

@_date: 2007-09-11 13:26:19
@_author: Mike Perry 
@_subject: EU Censorship: "Web search for bomb recipes should be blocked" 
Thus spake Dave Page (grimoire at cultofperf.org.uk):
Hrmm. With this, and the talk of half-baked squid exit filtering,
might it be time for a CensoredExit flag (which would do something
like allow clients to avoid it for port 80 exits, or a user-defined
port list)?
I am routinely censored by China..  Last week they didn't like me
shopping for some O'Reilly books on oreilly.com about 802.11
networking and continually closed my connection... (The symptom for
this filtering is a series of "Connection: closed" privoxy messages,
which comes from the Great Firewall's RST spoofing method of
More and more these filters are going to interfere with real research
people are trying to do via Tor about human rights issues,
state-sanctioned terrorism, state-funded paramilitary, genocide past
and present, obscure technology, "criminal skills", etc. Allowing them
to hinder Tor user experience randomly is a poor property for a
censorship-resistant network to have.
The major problem I see with such a flag is that some defintions
of it may end up causing it to apply to pretty much every exit node..
Is it possible for us to draw the line somewhere? Maybe just base it
on user reporting of excessive inconvenience, with some blanket
applications for known egregiously offending countries?

@_date: 2007-09-21 01:06:53
@_author: Mike Perry 
@_subject: Torbutton 1.1.7 Released 
The 1.1.7 alpha release of the security-enhanced Tor Firefox extension
is out. Changes in this version:
  * bugfix: bug 495: couple of memory leaks found and fixed by arno
  * bugfix: bug 497: uninstall exception found and fixed by arno
  * bugfix: bug 460: No more alerts should happen. But does that mean
    its fixed? Outlook not so good...
  * bugfix: bugs 461+489: verbosity+macos logging issues resolved
  * bugfix: if javascript is disabled, the hooking code no longer complains
  * misc: Update spoofed Firefox version to 2.0.0.6
  * new: "Restore Defaults" button added to the preferences window
Please report bugs at Enjoy!

@_date: 2007-09-23 13:08:40
@_author: Mike Perry 
@_subject: Warning TorButton 1.1.7-alfa 
Thus spake force44 at Safe-mail.net (force44 at Safe-mail.net):
Thanks for the bug report. Even though it is a bit immaturely
delivered with lots of whining instead of actual helpful content, I
will do my best to fix the issues you have encountered.
This is a bug. It will be fixed in 1.1.8. Thanks for reporting!
In the meantime, the workaround is to go into the Torbutton
preferences, go to the "Shutdown" tab, and click "Allow me to manage
my own Private Data Settings."
Is it possible for you to give me a list of websites torbutton breaks?
or describe how it breaks then? It works for me and I have recieved no
reports of breakage so far from others.
You can hate on me all day long, but the fact of the matter is that
every other Firefox extension combo (including self management up to
the point of a Tor-only firewall) leaves you vulnerable to numerous
attacks to reveal your IP address and other location infromation. So
people can either help me fix Torbutton so it is usable for them, or
they can choose to remain vulnerable.
You may want to read over  to see
what sort of things you are vulnerable to without torbutton. If that
documentation is unclear, again, please notify me.

@_date: 2007-09-23 13:17:02
@_author: Mike Perry 
@_subject: Warning TorButton 1.1.7-alfa 
Thus spake Scott Bennett (bennett at cs.niu.edu):
Can you give me a list of websites torbutton breaks for you? And how
does it break them? Toggling torbutton will kill javascript in
websites that are currently open, but you want that, unless you like
random javascript timers going off and sending your real IP to
SwitchProxy should be usable with Torbutton. If you configure your Tor
proxy settings as one of the proxies, Torbutton should detect when it
is enabled and turn on its security features for you without your
needing to actually hit the torbutton itself. If it does not, it is a
bug. Please report it.
Again, Torbutton protects against numerous web exploits that can
reveal your IP address when you use vanilla proxy changers. Please
read over  before you go
recommending insecure solutions to people, or simply hate on Torbutton
without providing any bug reports to the maintainer as to why.

@_date: 2007-09-01 06:50:03
@_author: Mike Perry 
@_subject: Want a faster Tor? Upgrade, inform others 
For those of you who are not subscribed to or-announce and/or have
friends who use Tor, the latest Tor stable should provide significant
performance/capacity increase once most clients upgrade. According to
my measurements with TorFlow, there should be roughly four times as
much capacity once the network rebalances. In addition, many users should experience noticable improvement in
performance just based on the fact that we are choosing guards in proportion to their bandwidth and expiring guards that were
selected with the buggy uniform algorithm.
Also, once the network is balanced, we can begin to investigate both
reliability scanning options and Johannes Renner can finish his
Master's Thesis on performance enhanced path selection. :)

@_date: 2008-04-02 10:09:59
@_author: Mike Perry 
@_subject: [GSoC] Torflow question. 
Thus spake Wojciech Walczak (wojtek.gminick.walczak at gmail.com):
As Sebastian stated, there are already a lot of apps for the exit
scanner. If you would like to work with Torflow, there are a lot less
apps for the node scanner (item  on the volunteer page):
You may want to have a look at the scanning bits of my defcon
talk/slides for more info on the arms race we face for these types of
scanners to ideas to help make writing the proposal easier:
and you should also look at the template we made for GSoC apps:
Alternatively, you could try to pick any other project from that
volunteer page that has a zero or low app count to increase your
chances of being selected.

@_date: 2008-04-02 10:09:59
@_author: Mike Perry 
@_subject: [GSoC] Torflow question. 
Thus spake Wojciech Walczak (wojtek.gminick.walczak at gmail.com):
As Sebastian stated, there are already a lot of apps for the exit
scanner. If you would like to work with Torflow, there are a lot less
apps for the node scanner (item  on the volunteer page):
You may want to have a look at the scanning bits of my defcon
talk/slides for more info on the arms race we face for these types of
scanners to ideas to help make writing the proposal easier:
and you should also look at the template we made for GSoC apps:
Alternatively, you could try to pick any other project from that
volunteer page that has a zero or low app count to increase your
chances of being selected.

@_date: 2008-04-19 21:05:23
@_author: Mike Perry 
@_subject: Firefox sends your uptime 
Thus spake .FUF (fuf at itdefence.ru):
Incidentally, this was filed as Firefox Bug  They have a fix
in the 3.0 branch. I requested backport into FF2.0.

@_date: 2008-04-19 22:30:48
@_author: Mike Perry 
@_subject: Torbutton 1.1.18-alpha released 
The 18th alpha release of the Torbutton development series has just been released. The release features fixes for issues with gmail,
yahoo, and livejournal, and also fixes issues with the Clear Private
Data feature.
The release can be found at: There is potentially one more feature I would like to get in before
declaring 1.2.0rc1, and that is ssl certificate separation:
It looks like it should be possible, but if it turns out to be
impossible or extremely hairy, I may just drop it for 1.2.0.
Also, see for a list of Firefox bugs still impacting Torbutton security.
Here is the complete changelog:
  17 Apr 2008
  * bugfix: Fix Gmail exceptions involving window.navigator that made Gmail
    unusable after recent updates by Google.
  * bugfix: Fix an exception in the content policy that may have prevented
    some AJAX page elements from loading.
  * bugfix: Fix regression on cross-state favicon leak introduced in 1.1.17
  * bugfix: Fix to make clear private data work again by fixing up history
    hooking (may also help FF3 compatibility).
  * bugfix: Fix Yahoo email account creation (broken due to Date.valueOf()
    weirdness).
  * bugfix: Fix to allow plugins if the user unchecks the plugin blocking
    preference
  * bugfix: Fix bug 638: eliminate cross-state history popup on session
    restore
  * bugfix: Only resize windows on document load. Hopefully this will make
    the resizing code less annoying, and drift less.
  * bugfix: Fix Object.prototype extensions involving the Date object
    (observed on LiveJournal)
  * bugfix: Fix javascript debugger compatibility issues involving source
    window display and other functionality.
  * misc: Prevent blocked popups from opening blank, unusable windows
  * misc: Updated firefox version to 2.0.0.14
  * new: New translations for French, Russian, Farsi, Italian, and Spanish.

@_date: 2008-04-22 21:20:32
@_author: Mike Perry 
@_subject: Torbutton 1.1.18-alpha released 
Thus spake scar (scar at drigon.com):
Yes, this is fine. The lack of the dropdown history in 1.1.17 was a
bug. The real test is to check if visited links show up in different
colors on pages when Tor is enabled. That should not happen.

@_date: 2008-01-31 21:00:18
@_author: Mike Perry 
@_subject: Tor slow no matter what I do. 
Thus spake phobos at rootme.org (phobos at rootme.org):
Actually, it /is/ likely that one setting here is actually doing
something.. "CircuitBuildTimeout 5" may have a survival of the fittest
style effect. If you tweak the circuit setup down to only 5 seconds,
only those servers who have ~1 second latency or less are going to be
able be members of your circuit, so you effectively will be weeding
out slow and congested nodes from your paths.
Of course, there are anonymity implications here.. You are ultimately
reducing the set of routers you are using, but on the other hand, you
are automatically avoiding overloaded nodes, which technically is good
for load balancing.. I'd be interested to hear Roger, Nick and Paul weigh in on this idea.
Are there good reasons to keep circuits alive that have nodes in them
so overloaded that it can take them up to a minute to build a circuit?

@_date: 2008-02-15 13:38:58
@_author: Mike Perry 
@_subject: Maybe Firfox isn't the best choice for privacy? 
Thus spake kazaam (kazaam at oleco.net):
A few comments on this. First off, the fact that window sizes factor
into a hash means as soon as you resize your window 1 pixel, they get
a completely new identifier, uncorrelated to the previous one. So this
is a trivial identifier to modify on your own if you are aware of it,
or even to change accidentally.
But otherwise, I agree it is pretty interesting work, and Torbutton
1.1.14 will address many of these items, including a couple of modes
of operation for masking window size, and protection against revealing
extension installation during Tor. The ability to use chome urls to
determine true user agent, extension presence, and platform
information was brought to our attention courtesy of Gregory
Fleischer about a month ago. Unfortunately, fixes for his issues and
the window size spoofing code didn't make it into the 1.1.13 release
because of the more serious javascript and plugin issues recently
descovered in Firefox that that release had to work around.

@_date: 2008-02-23 16:49:32
@_author: Mike Perry 
@_subject: Maybe Firfox isn't the best choice for privacy? 
Thus spake misc (misc at mail333.com):
Not to my knowledge. Adblock Plus has support to hide extension
presence, but I believe extensions have to programmatically request it
from an Adblock service. Torbutton 1.1.14 should be out early next
week, and will address these issues.

@_date: 2008-02-24 19:33:38
@_author: Mike Perry 
@_subject: Torbutton 1.1.14-alpha released 
Torbutton 1.1.14-alpha has been released at
 This release primarily features several mechanisms to mitigate browser
fingerprinting. This includes chrome/extension presence disclosure,
resolution information, Tor port probing, and user agent and locale
spoofing fixes.
Here is the complete ChangeLog for 1.1.14:
  * bugfix: set general.useragent.locale if user wants to spoof an English
    browser. This handles navigator.locale
  * bugfix: Mask navigator.buildID. Reported by Greg Fleischer
  * Initial Firefox 3 work. Functionality still broken due to FF Bug 413682
  * bug 580: Resize preferences window to fit in 640x480 displays
  * new: Spoof window.screen to mask desktop resolution and resize the
    browser to multiples of 50px while tor is enabled.
  * new: Block content window access to chrome urls if Tor is enabled,
    and hide Torbutton if Tor is disabled. Thanks to Greg Fleischer for
    reporting the chrome disclosure issues
  * new: Added option to close all opened tabs on a Tor toggle. Useful
    for general convenience and also as a backup protection against
    Bug 409737.
  * new: Add Tor ports to the list of banned ports for Firefox. Should
    prevent http-ping based fingerprinting attacks.
  * new: Finally add support for automatic updates.

@_date: 2008-02-26 01:12:11
@_author: Mike Perry 
@_subject: Torbutton 1.1.14-alpha released 
Thus spake Vlad SATtva Miller (sattva at pgpru.com):
This is actually how Firefox extensions operate. There is NO support
for actually installing an extension over https (at least under
Firefox 2). The best you can do is retreive the SHA1 sum via
javascript over https, and then download the extension over http and
check the sha1 afterwords. Of course, if you disable javascript, you
made your extension install+update process insecure. Funny how that
all works out, isn't it?

@_date: 2008-02-26 02:27:16
@_author: Mike Perry 
@_subject: Torbutton 1.1.15-alpha released 
Torbutton 1.1.15-alpha has been released at
 Those of you who installed
Torbutton 1.1.14 should also be able to fetch the latest version
now by simply clicking Find Updates in the addons window.
This release features a number of fixes for bugs discovered by Gregory
Fleischer. Greg discovered a way to unmask the Javascript hooks for
window.screen, window.history, window.Date and window.navigator. It is
technically possible to use an unmasked window.history object in
combination with an exploit for Firefox Bug 409737 to write Javascript
that waits for Tor to be disabled to connect to a site via your IP.
The Date unmasking unfortunately has not been fixed due to
idiosyncrasies with the way the Date class is implemented in the
Firefox Javascript interpreter. This means it is possible for a
malicious website or exit node to determine your timezone if they
perform Greg's attack to unmask the original Date implementation from
behind the hooks. It appears that the only way to fix this issue is to implement a
fix for either Firefox Bug 392274 or 419598.
Here is the complete ChangeLog for 1.1.15:
 * bugfix: Fix hook unmasking of window.screen, window.history,
   and window.navigator discovered by Greg Fleischer. window.Date    unmasking is still unfixed. window.history unmasking represents
   potential IP disclosure due to Firefox Bug 409737.
 * bugfix: Fix view-source extension disclosure bug found by Greg    Fleischer.
 * bugfix: Fix javascript and about links. Found by Greg Fleischer.
 * new: Attempt to prevent window sizes from drifting during resize.

@_date: 2008-02-03 13:46:29
@_author: Mike Perry 
@_subject: Torbutton 1.1.13-alpha released 
Version 1.1.13 of the development series of the Torbutton Firefox
Extension has been released at This release features a couple of important security fixes to work
around two Firefox bugs. Firefox bug 409737 allows pages to still
execute some javascript after Tor has been toggled, and Firefox bug
401296 allows plugins to be loaded via direct links and
Here is the complete changelog:
 * bugfix: Implement workarounds to disable Javascript network access    for Firefox Bug 409737
 * bugfix: Improved plugin-disabling workarounds for Firefox Bug
   401296  * misc: Set network.protocol-handler.warn-external.* to warn on
   external app handlers during Tor usage
 * misc: Disable browser.safebrowsing.enabled during Tor usage since
   it retrieves some information in plaintext.
 * misc: Disable browser.send_pings.
 * misc: Block Javascript back/forward manipulation if Tor is enabled
 * new: Option to clear HTTP auth on Tor toggle

@_date: 2008-07-05 16:49:41
@_author: Mike Perry 
@_subject: Torbutton 1.2.0RC4 Error 
Thus spake Matthieu Dalissier (mdal at gmx.ch):
Fixed as Bug 734. This will be out in 1.2.0rc5.

@_date: 2008-07-05 16:52:47
@_author: Mike Perry 
@_subject: Torbutton 1.2.0RC4 Error 
Thus spake Kyle Williams (kyle.kwilliams at gmail.com):
Err no, sorry. Kyle, your bug is 734:
Matt's bug is 735: Both will be fixed in 1.2.0rc5.

@_date: 2008-07-06 16:46:23
@_author: Mike Perry 
@_subject: Fwd: Flyspray task #698 - Uncaught exception on blocking local file network access 
Thus spake Geoff Down (downie at castlecops.net):
Hrmm. So this exception may just be because of the content policy
denying the load.. But I've re-opened the bug if you want to attach an
example file html page that triggers the exception.

@_date: 2008-07-06 20:13:31
@_author: Mike Perry 
@_subject: Torbutton 1.2.0rc5 Released 
We've had a whole slough of fixes since I posted the last release
announcement for 1.2.0rc2. The most significant should be improved
addon compatibility, better preservation of Firefox preferences that
we touch, fixing issues with Tor toggle breaking for some option
combos, and an improved 'Restore Defaults' button. This version also features Firefox 3 cookie jar support, and support
for storing cookie jars in memory, both of which were submitted by
Here's the complete changelog since the last announcement:
 06 Jul 2008
 * bugfix: bug 734: Fix exception with clearing history on toggle
 * bugfix: bug 735: Fix exception with blocking Non-Tor history writes
 * bugfix: bug 720: FF3 cookie jar fix submitted by arno
 * misc: translation updates for French, Farsi, and others
 * misc: demote "mapper check" log message to info
 * new: Option to not write cookie jars to disk submitted by arno
 27 Jun 2008
 * misc: Refuse to jar cookies under Firefox 3. Lame workaround for Firefox
   Bug 439384, but it's the best we can do. At least we won't destroy
   cookies anymore.
 * misc: Some strings were present twice in the en-US locale. Didn't seem
   to cause any problems, but probably should be fixed.
 27 Jun 2008
 * bugfix: Lots of compatibility updates with other extensions. Issues
   with SpeedDial, Google Notebook, TabMixPlus, and others have been fixed.
 * bugfix: Fix bug with first window/tab after restart being partially
   prevented from performing network activity and/or history access.
 * bugfix: Add an additional pref for blocking Non-Tor file url network
   activity. Off by default. This should fix issues with Sage addon in
   Non-Tor mode.
 * bugfix: Be better about saving all sorts of Firefox prefs that we touch
   so that users' Non-Tor preferences are remembered.
 * bugfix: Fix potential issues with FF3 sessionstore by updating component,
   and performing version detection.
 * bugfix: Separate toggle into a 3 stage process to eliminate potential
   race conditions and issues with javascript and other functionality
   not working after Tor toggle.
 * new: Added 'Test Settings' button to Proxy Preferences that uses
   check.torproject.org to verify Tor status.
 * misc: Improve 'Restore Defaults' to reset all prefs that we touch.
 * misc: Fix logging system to be more user-legible.

@_date: 2008-07-12 20:26:46
@_author: Mike Perry 
@_subject: Torbutton 1.2.0rc6 Released 
The sixth release candidate for the 1.2 series of Torbutton is out.
This should be the last release candidate before 1.2.0, I swear. It
features fixes for a nasty history loss bug, an exception during Tor
toggle, javascript being disabled in some tabs, better pref handling,
and more.
You can find the latest Torbutton at:
 (preferred)
Please report any bugs via:
Here is the complete changelog:
 * bugfix: Fix bug causing Firefox history to get cleared in some situations
 * bugfix: bug 753: Fix exception thrown during Tor toggle in some instances
 * bugfix: bug 758: Fix resize issue where 0x0 windows could be created
 * bugfix: Fix some potential permission denied issues with cookie jars
 * bugfix: bug 520: Fix issue where Javascript stayed disabled in some tabs
 * bugfix: Apply cookie lifetime settings to Tor settings on first install.
 * bugfix: Don't disable Firefox preferences when Torbutton is uninstalled
 * misc: Allow automatic updates in FF3 by default. They are secure now.
 * misc: Translation updates

@_date: 2008-06-09 00:10:35
@_author: Mike Perry 
@_subject: Torbutton 1.2.0rc2 released 
The second release candidate for the next stable series of the
security-enhanced Torbutton Firefox extension has been released.
This release features a fix for an annoying bug on MacOS, and adds
much clamored for options to start Firefox in a specific Tor state.
The same issues and concerns around Firefox 3 still exist. Please see
 and
As always, if you have Torbutton 1.1.14+ installed, the release is
available via "Find Updates" in your Firefox addons window, or at:
Here is the complete changelog:
 * bugfix: MacOS: Fix broken Tor state/toggle issues when all windows
   are closed but app stays open
 * misc: Potential performance improvements when many windows+tabs are open
 * new: Add 'locked mode' pref to allow users to disable one-click toggling
 * new: Add prefs to start Firefox with a specific Tor state.

@_date: 2008-06-12 16:26:48
@_author: Mike Perry 
@_subject: SPD talk: "Simulating a Global Passive Adversary for Attacking Tor-like Anonymity Systems"? 
Thus spake gojosan at mailhaven.com (gojosan at mailhaven.com):
A handful of comments about the paper (many of these they themselves
brought up, but some they did not):
0. They are really an active adversary here. They need to be
controlling a website in order to unmask users, or have control of
some exit nodes or their upstream routers, and must modulate the
bandwidth of TCP connections considerably (+/- 30-40KB/sec or more,
for a period of 10 minutes).
1. Their results for path recognition (25% false negatives, 10% false
positives) are based on their limited sample set of only 13 trial
circuits via a small set of nodes that must be geographically close to
and well-peered with their pinging 'vantage point(s)'. I suspect
reality is a lot less forgiving than this limited sample size
indicates when more nodes and trials are involved using the real Tor
path selection algorithm.
2. The bandwidth estimation technique they utilized (based on TCP
Westwood/CapProbe/PacketPair) is very sensitive to any queuing and
congestion that occurs between the target and the 'vantage point(s)'.
As soon as congestion happens along the path, these types of estimates
report a large amount of excess capacity (rather than no capacity) due
to the acks/responses getting compressed together in queues. The way
this has been 'fixed' in TCP Westwood+ is to filter out the high
estimates and perform weighted averaging to smooth fluctuations
(precisely what they are trying to measure). It would have been nice
if they provided some more realistic testing of their bandwidth
estimation consistency using real world nodes as opposed to the lab
results on half-duplex ethernet.
3. Based on my measurements last year, only the top ~5-10% nodes are
capable of transmitting this much data in an individual stream, and
only if all of the nodes in your path are from this set. Furthermore,
as load balancing improves (and we still have more work to do here
beyond my initial improvements last year), these averages should in
theory come down for these nodes (but increase for slower nodes). So
how they will fair once we figure out the bottlenecks of the network
is unknown. They could do better in this case, but it is probably more
likely the average stream capacity for most nodes will drop below
their detection threshold.
4. Right now these few fast nodes carry about 60% of the network
traffic. A rough back of the envelope calculation based on our
selection algorithm means that only ~22% (.6*.6*.6) of the paths of
the network have this property for normal traffic, and only ~4.5% of
hidden service paths (which are 6 hops).
5. Their error rates do get pretty high once they've begun
trying to trace the stream back to its ISP (on top of the rates for
just path recognition). Any other fluctuations in traffic are going to
add error to this ability, and I imagine traffic fluctuates like crazy
along these paths. They also assume full a-priori knowledge of these
routes which in practice means a full map of all of the peering
agreements of the Internet, and 'vantage point(s)' that have no
queuing delay to all of them..
A couple countermeasures that are possible:
1. Nodes that block ICMP and filter closed TCP ports are less
susceptible to this attack, since they would force the adversary to
measure the capacity changes at upstream routers instead (which will
have other noise introduced due to peers utilizing the link as well). I
am wondering if this means we should scan the network to see how many of
these top nodes allow ICMP and send TCP resets, and if it is feasible to
notify their operators that they may want to consider improving their
firewalls, since we're only talking about 100-150 IPs here. There are a
lot more critical things to scan for though, so this is probably lower
2. Roger pointed out that clients can potentially protect themselves
by setting 'BandwidthRate 25KB' and setting 'BandwidthBurst' to some
high value, so that short lived streams will still get high capacity
if it is available, but once streams approach the 10-20minute lifetime
needed for this attack to work, they should be below the detectable
threshold. I think this is a somewhat ugly hack, and should probably
be governed by a "High Security Mode" setting that would be
specifically tuned to this purpose (and be a catching point for other
hacks that protect against various attacks but at the expense of
All this aside, this is a very clever attack, and further evidence
that we should more closely study capacity properties, reliability
properties, queuing properties, and general balancing properties of
the network.

@_date: 2008-06-03 16:00:14
@_author: Mike Perry 
@_subject: Torbutton 1.2.0rc1 released 
The first release candidate for the next stable series of the
security-enhanced Torbutton Firefox extension has been released. This
release features functional support for Firefox 3. However, this
support has not been extensively tested. In particular, timezone
masking does not work at all. The workaround is to manually set the
environment variable 'TZ' to 'UTC' before starting Firefox. This works
on both Linux and Windows.
Firefox 3 users should keep a close eye on Torbutton. In particular,
the new Places history database code is connected to all sorts of
different parts of the browser, and it is unknown if 'disabling
history' actually prevents disk writes for many parts of its database.
It is also possible this code may perform strange network accesses at
odd times as well (the 'Livemarks' code is one case of this that has
known issues). Please keep an eye on your Vidalia window. Adventurous
users can also run wireshark, and/or help with the disk access
auditing by running Process Monitor on their Windows systems:
A list of other Firefox bugs known to impact Torbutton security can be
found at: Here is the complete changelog for 1.2.0rc1:
 * general: FF3 should now be functional, but timezone masking is not
   operational
 * bugfix: Fix Places/history component hooking in FF3
 * bugfix: Disable Places database in FF3 via browser.history_expire_days=0
   if history writes are disabled.
 * bugfix: General component hooking fixes for FF3
 * bugfix: Block favicon leaking in FF3
 * bugfix: Enable safebrowsing updates in FF3 (it's finally HMACd. Yay).
 * bugfix: Use Greg Fleischer's new useragent prefs in FF3.
 * bugfix: Properly reset cookie lifetime policy when user changes
   cookie handling options.
 * bugfix: Fix 'Restore defaults' button issues with custom proxy settings
 * bugfix: navigator.oscpu hooking was broken in 1.1.18
 * bugfix: Try to prevent alleged 0x0 windows on crash recovery
 * bugfix: Attempt to block livemarks updates during Tor. Only
   partial fix. Not possible to cancel existing Livemarks timer (one fetch    will still happen via Tor before disable). See Firefox Bug 436250
 * misc: Set plugin.disable_full_page_plugin_for_types for all plugin
   mimetypes just in case our custom full page blocking code fails

@_date: 2008-03-17 12:16:28
@_author: Mike Perry 
@_subject: Tor and Firefox 3 
Thus spake defcon (defconoii at gmail.com):
I've had some success using Torbutton-alpha with the latest Firefox
3.0b4. The bug with toggling Tor state (which was due to Firefox Bug
413682) seems fixed. For some reason, the crash detection that depends
on the same component of that bug is *not* working, though..
There are likely lots of other subtle bugs with components and events
not working the same though.. It's going to take a while to provide
the same level of security with FF3 as FF2. Basically we'll need to
re-verify all the various protections still pass, and they are sort of
scattered about the web right now.

@_date: 2008-03-17 12:40:26
@_author: Mike Perry 
@_subject: Torbutton 1.1.17-alpha released 
The 1.1.17 alpha release of the Torbutton Firefox extension is out.
Those of you who have installed 1.1.14 or later can upgrade by going
to the Firefox 'Addons' Menu and clicking 'Check for Updates'. Otherwise, download a copy via: The major enhancements include less annoying (I hope) window
resizing, fixes for installed extension/chrome disclosure issues,
and application of the javascript hooks to javascript: urls.
***NOTE***: The Date hooks are still unmaskable, which means a
determined adversary still can get access to your real timezone.
If concealing your timezone is important to you (and you subscribe to
the 'Just because you're paranoid doesn't mean they AREN'T after you'
school of thoughti :), you can achieve protection against an active
adversary under Linux by setting the TZ environment variable to 'UTC'
before launching Firefox. I have not tested if this (or an equivalent
variable) works for Windows or MacOS. It would be nice if someone who
uses those systems regularly could let me know so I can update the
website documentation. You can check by visiting
 with Tor disabled.
Other than that, I think we are starting to get close to a stable
release. The next release will probably be 1.2.0-rc.
Here's the changelog for 1.1.17 and 1.1.16 (since I skipped the
announcement for 1.1.16):
  15 Mar 2008
  * bugfix: Improve chrome disclosure protection (patch from Greg
    Fleischer)
  * bugfix: Block network access from file urls to workaround Firefox
    'Content-Disposition' file stealing attack (found/fixed by Greg)
  * bugfix: Apply Javascript hooks to javascript: urls (found by Greg)
  * bugfix: Improve Torbutton chrome concealment (found by Greg)
  * bugfix: Use 127.0.0.1 instead of localhost for IPv6 users
  * bugfix: Don't resize maximized windows
  * misc: Improve window resizing to only resize on document load,
    and to try to address drift by remembering window sizes
  * misc: Clear session history if clear history on tor toggle is set
  * new: Remove history hooks in favor of nsISHistoryListeners that
    prevent history navigation from alternate Tor states
  03 Mar 2008
  * bugfix: Fix yet more javascript unmasking issues found by Greg.
    Date is still unmaskable.
  * bugfix: Close tabs *before* toggling proxy settings if pref is
    set.
  * bugfix: Fix a couple exceptions thrown on resizing and plugin
    canceling

@_date: 2008-10-22 12:02:59
@_author: Mike Perry 
@_subject: Performance 
Thus spake Alessandro Donnini (alexdonnini at ieee.org):
There are some performance suggestions at:
but damn does that page have a tendency to descend into madness and
conflicting information quickly. I have done my best to pare it down
to the useful bits, but in case it mutates again, the most useful
performance tuning suggestions are the Firefox HTTP pipelining options
(assuming you use Polipo), and the CircuitBuildTimeout and
NumEntryGuards Tor settings. The Tor settings are by far the more
impactful of the two, I've found.
P.S. You should really be using Torbutton 1.2.0 with Firefox if you
want anonymity/privacy:

@_date: 2008-10-22 13:45:12
@_author: Mike Perry 
@_subject: Performance 
Thus spake Marco Bonetti (marco.bonetti at slackware.it):
Timeout is only observable for cases where circuits fail to complete
within that timeout period, and this information doesn't easily
transfer to circuits that do complete unless you are the guard node.
However, the guard already has much better identifers to work with
(such as IP, TCP fingerprint, and potentially some information on Tor
Now, a middle node could potentially use some statistics about how
quickly a guard is known to extend circuits and try to cluster
circuits by distribution of their timeouts this way, but it only gives
that middle node information for the circuits clients AREN'T using.
Because failed circuits are completely abandoned and not partially
restarted, this information does not readily transfer well for
circuits that succeed unless you are the guard node too (which means
you have two hops in the circuit, and would have much better luck
using that effort to have your two hops be guard and exit).

@_date: 2008-10-22 13:50:26
@_author: Mike Perry 
@_subject: Performance 
Thus spake Dominik Schaefer (schaedpq2 at gmx.de):
Actually, it should have a balancing effect where traffic
automatically avoids overloaded nodes that have trouble completing
circuit extends due to their load.
That is, unless the timeout is set too low (where clients create tons
and tons of circuit attempts without ever completing any). This could
easily lead to a DoS condition on the network, which is one of the
reasons we have not yet lowered the timeout in the Tor distribution.
My Google Summer of Code student (Fallon) was tasked with implementing
some statistics to determine the timeout automatically per client, but
unfortunately she did not complete her project due to time conflicts
for her unrelated thesis work...

@_date: 2008-10-22 16:24:20
@_author: Mike Perry 
@_subject: torproject svn changes 
Thus spake Roger Dingledine (arma at mit.edu):
Also, the most recent version of torflow is currently at which contains TorCtl (actually an alias to
 and a
bunch of scripts that make use of TorCtl.
Hopefully I will be merging back that branch into torflow trunk in the
near future.

@_date: 2008-09-05 19:14:35
@_author: Mike Perry 
@_subject: Google's Chrome Web Browser and Tor 
Also, more basic things: Cookie creation is blocked, but existing ones
still are present and are transmitted. Also, javascript history
disclosure attacks are not blocked. Timezone is of course still
available as well.  In short, Google's policy with Incognito appears to be that it only
will prevent stuff from being recorded to the local disk. Any remotely
exploitable privacy vulnerabilities are not covered in the scope of
the mode :/
This includes, surprisingly (or unsurprisingly), Google Search
History. It is not even disabled automatically during Incognito mode:
Also, Chrome lacks any sort of cross-platform extension API with which
to fix this.. Tears all around.
Thus spake Kyle Williams (kyle.kwilliams at gmail.com):

@_date: 2009-12-11 15:32:09
@_author: Mike Perry 
@_subject: Torbutton 1.2.3 Released. Feedback requested. 
Torbutton 1.2.3 has been released. It is available at
 and features many
bugfixes, including Firefox 3.5 compatibility fixes and privacy
The release also features three hidden options for reducing the number
of Google Captchas received during search. If you search about:config
for _google_, you should find them:
1. extensions.torbutton.xfer_google_cookies
  If True, this option causes Torbutton to transfer all non-ssl google
  cookies between country code domains just prior to fulfilling a
  request for a new google country. In other words, if you hit google.ca,
  solve a captcha, and then your exit changes for your next search
  causing you to get google.de, your captcha and PREF cookies should be
  transfered from google.ca to google.de.
  This should eliminate the need to solve captchas for every google
  country domain. It is on by default.
2. extensions.torbutton.regen_google_cookies
  If True, this option will cause Torbutton to hit google.ca to obtain
  a fresh set of google cookies every time Tor is enabled, or while
  cookies are cleared in Tor mode.   Since Google sometimes simply provides a 403 with no captcha when
  you use search keywords or the search box with Tor without any cookies,
  this option is provided to attempt to reduce that case. I am
  interested in feedback on how well it works.
  This option is off by default.
3. extensions.torbutton.reset_google_cookies
  This option is similar to the regen option, except that it recreates
  your google cookies from a hardcoded set that has solved at least one
  captcha. These cookies can be seen/modified by searching about:config
  for ".g*_cookie".
  Obviously this approach has very undesirable anonymity properties
  unless everyone were to use it with the same cookies. Unfortunately,
  this scenario may also lead to these cookies being banned by Google
  (especially if a spammer/scraper decides to steal them for their use).
  This option is off by default.
Any feedback on the above options would be appreciated.
Also, while drafting this email, I noticed that there is apparently an
obscure popup-related bug with 1.2.3:
If anyone can provide me with an example reproduction case, I would
greatly appreciate it.
Finally, at long last, here is the complete changelog for 1.2.3:
02 Dec 2009
 * bugfix: bug 950: Preserve useragent and download settings across toggle
 * bugfix: bug 1014: Fix XML Parsing Error on XHTML sites in Tor mode
 * bugfix: bug 1041: Preserve tab history in FF3.5
 * bugfix: bug 1047: Fix spurious user agent change notice
 * bugfix: bug 1053: Partial fix for 'TypeError: browser is undefined' error
 * bugfix: bug 1084: Preserve HTTP accept language for Non-Tor usage
 * bugfix: bug 1085: Fix test settings issues with dead privoxy
 * bugfix: bug 1088: Clean up some namespace issues in the main chrome window
 * bugfix: bug 1091: Fix a lockup when 'Ask Every Time' cookie pref is set
 * bugfix: bug 1093: Fix cert acceptance dialogs in Firefox 3.5
 * bugfix: bug 1146: Fixes for properly handling tab restore in FF3.5
 * bugfix: bug 1152: "Close tabs on toggle" prevents toggling in FF3.5
 * bugfix: bug 1154: Clarify "Last Tor test failed" message
 * misc: Disable geolocation in FF3.5 during Tor mode
 * misc: Disable DNS prefetch in FF3.5 in Tor mode and for Tor-loaded tabs
 * misc: Disable offline app cache during Tor mode
 * misc: Disable specific site zoom settings during Tor mode
 * new: Transfer Google cookies between country-code domains. This should
   make it such that captchas only need to be solved once per Tor session,
   as opposed to for each country.

@_date: 2009-12-11 15:57:27
@_author: Mike Perry 
@_subject: Torbutton Proxy Settings Questions 
Thus spake nnnnnnnnnnnn at Safe-mail.net (nnnnnnnnnnnn at Safe-mail.net):
Privoxy does not support ftp or gopher. When these fields are left
blank, Firefox defaults to SOCKS for these protocols. Sadly, the SOCKS
support in firefox is also broken for FTP it seems, but it does not
leak. Gopher on the otherhand, seems to work:
No. It just sets those defaults for you.
You're not likely to be any safer from what we know now, but stranger
things have happened as far as vulnerabilities in Torbutton go. In
general if you don't need these protocols, disabling them won't hurt.
Reducing your vulnerability surface where you can is never a bad
thing. However, the flip side to this is that passing them to privoxy
or polipo will make your browser behave differently in a noticable
way, and who knows if they are any better at handling these protocols
than Firefox's SOCKS layer alone..

@_date: 2009-07-08 23:43:49
@_author: Mike Perry 
@_subject: TorButton Question 
Thus spake Ringo (2600denver at gmail.com):
This is because Firefox will use the SOCKS proxy rule for these
protocols. If you set then to be handled by privoxy, it just refuses
to work. Firefox's SOCKS proxy at least makes an attempt (but then
fails due to either a bug in Firefox or Tor).
I have not tried a gopher server yet, though.

@_date: 2009-06-04 00:53:21
@_author: Mike Perry 
@_subject: tor controller hangs / doesn't reply 
Thus spake Roger Dingledine (arma at mit.edu):
Yes it works. It even has a control port password of mine in SVN! :)
How many more replies are we going to spend debugging hidden, super
secret source code? :)

@_date: 2009-11-20 08:54:40
@_author: Mike Perry 
@_subject: HTML5 deanonymization attacks 
Thus spake Marco Bonetti (marco.bonetti at slackware.it):
Yes, exactly. It would be nice to know if it is blocked even if you
click through the warning and accept it. That warning is actually for
blocking real external apps, not html pages registered as apps. The
html pages should still be blocked by other means, and if they are
not, I would like to at least investigate with a good test case to see
why not.
Yeah, and/or just a directory with the individual html files too.
Ideally it would be something I can link from the Design Document and
then click on individual tests to run them right there, for when I
make changes to Torbutton that may cause regressions.

@_date: 2009-11-19 11:57:21
@_author: Mike Perry 
@_subject: HTML5 deanonymization attacks 
Thus spake Marco Bonetti (marco.bonetti at slackware.it):
Hey Marco, thanks for this!
I have a couple of quick questions and a comment:
Do you have the test cases for the offline application protocol
handler registration? I'm curious if Torbutton will still block them
from bypassing the proxy or delaying themselves from running until
post-toggle, even if you click to allow the application to run. I
think it should still be blocked from doing anything terrible, but it
would be nice to know for sure.
In general, it would be really nice if we could have all your test
cases online so I can link them from the Torbutton Design Document, as
we have done with other research like yours. The hope is that one day
someone will consolidate all them into a good browser anonymity and
privacy validation framework (decloak.net and deanonymizer.com are
great starts, but still aren't totally complete).
Also, I'm curious about your comments about the differences in
implementation of video, audio and source tags in Firefox 3.6b.
And finally the comment: Torbutton 1.2.3 will address the geolocation
issue and a few others in Firefox 3.5. I am closing out bugs in
flyspray preparing for a release hopefully this weekend.

@_date: 2010-04-09 19:26:11
@_author: Mike Perry 
@_subject: Torbutton 1.2.5 Released 
Torbutton 1.2.5 has been released at This release provides the ability to automatically redirect to an
alternate search engine when Google presents you with a captcha. The
options are ixquick, bing, yahoo, and scroogle. In addition,
potentially identifying information (such as language, OS version, and
Firefox version) will be stripped off of Google Search Box queries by
This release will also only update Torbutton via Tor by default, to
address concerns with data retention by addons.mozilla.org, as well as
potential issues with Tor users being revealed via their Torbutton
update requests.
Here is the complete changelog entry for 1.2.5:
 * bugfix: bug 1169: Fix blank popup conflict with CoolPreviews
 * bugfix: bug 1246: Fix IST and other HH:30 timezone issues.
 * bugfix: bug 1219: Fix the toggle warning loop issue on settings change.
 * bugfix: bug 1321: Fix a session restore bug when closing the last window
 * bugfix: bug 1302: Update useragent to FF3.6.3 on WinNT6.
 * bugfix: bug 1157: Add logic to handle torbutton crashed state conflicts
 * bugfix: bug 1235: Improve the 'changed-state' refresh warning message
 * bugfix: bug 1337: Bind alert windows to correct browser window
 * bugfix: bug 1055: Make the error console the default log output location
 * bugfix: bug 1032: Fix an exception in the localhost proxy filter
 * misc: Always tell a website our window size is rounded even if it's not
 * misc: Add some suggestions to warning about loading external content
 * new: Add option to always update Torbutton via Tor. On by default
 * new: Redirect Google queries elsewhere on captcha (default ixquick)
 * new: Strip identifying info off of Google searchbox queries

@_date: 2010-04-09 19:43:27
@_author: Mike Perry 
@_subject: Torbutton 1.2.5 Released 
Thus spake Programmer In Training (pit at joseph-a-nagy-jr.us):
What is the difference between StartPage and Ixquick? I thought
startpage was just another domain ixquick happened to own?

@_date: 2010-04-10 02:31:50
@_author: Mike Perry 
@_subject: Torbutton 1.2.5 Released 
Thus spake Mike Perry (mikeperry at fscked.org):
I've written a bit more on the reasoning behind these two changes at:

@_date: 2010-08-19 19:32:16
@_author: Mike Perry 
@_subject: THE GLOBAL ADVERSARY [was: Tor Project 2008 Tax Return] 
Thus spake Mike Perry (mikeperry at fscked.org):
Since my first revelation, several people have emailed or messaged me
privately about how they can start working towards their beachfront
property. It warms my heart that there are so many interested in
taking The Adversary up on His generous offer!
The Tor Volunteer page actually lists Tor-related research problems at
the very top of its Research section at the bottom of:
The first three are directly relevant to the Global Adversary problem
and have been present at the top of this list for years. They've
actually been solved numerous times. Each time the result is buried
and the author gets their own beachfront black-ops resort.
If you believe you have a solution, simply pick up your phone and
clearly say "Attention: NSA. Attention: NSA. I have a solution to
subvert the Global Adversary" into the mouthpiece. That, or email
tor-assistants at torproject.org. They'll get it either way, and they
will ensure you are... taken care of.
There have also been several near-solutions in the past year or two
that did not qualify for beachfront property, and thus were still
published. Namely the 3 at PETS this year (sorry guys, better luck
next time!).
These still need to be added to anon-bib, reviewed, and evaluated.
One of the major problems with all this attack and defense work is
that each paper uses different metrics and a different adversary
model. This makes it hard to tell which attacks would still be able to
thwart which defense, and thus it is increasingly hard for The
Adversary to determine exactly which papers He needs to Unpublish.
In fact, a thorough academic review of all timing attack and defense
papers to date under common adversary and performance models is at
least enough to get you a beachfront black-ops time-share. The
Adversary has informed me that Steven Murdoch was looking into
developing these models, but he may be willing to coauthor to split
the time-share with you if you help evaluate attacks and defenses
using his models. Something to consider...

@_date: 2010-08-21 04:13:32
@_author: Mike Perry 
@_subject: Bigger Thinking [was: Tor Project 2008 Tax Return] 
Thus spake Al MailingList (alpal.mailinglist at gmail.com):
Actually there are several large-userbase companies that want to
include Tor by default in their product, either as a client, a relay,
or a bridge.  Unfortunately, the only answer we have for them in the
immediate term is "For the love of goddess don't do that, you'll
destroy Tor". Our immediate concern is making it possible to support at least a
fraction of one of these userbases in either the relay or the bridge
roll. The relay role will require a significant update to Tor's
directory mechanisms, and we are trying to drive academic research
forward in these areas. The bridge roll may be more immediately
doable, but we're not sure that bridgedb wouldn't just fall over yet
Actually, most competent law enforcement agents realize that what gets
them the most points are sting operations that topple entire
distribution rings, gangs, or bot herders. These sorts of stings
require heavy use of Tor. Roger and Andrew actually spend a good
amount of their time talking with law enforcement and giving
presentations about what Tor is and how they can use it to anonymize
their investigative activity.
Actually almost all of the people working for Tor today started out on
the mailinglists, frustrated with some aspect of Tor or other :). Of course, they also tended to naturally step in to some sort of
volunteer capacity along their areas of interest, as a result of this
frustration. Tor tends to care about this level of passion way more
than resumes or interviews.
The Tor Project is trying most of the things Julie has suggested. It
just takes time, effort, communication, and people. We don't mind
letting our consistently passionate volunteers talk to people about
Tor in official capacity, either.

@_date: 2010-08-06 23:48:36
@_author: Mike Perry 
@_subject: Legal response to real abuse 
Ideally, it would be great to hear from Wendy, Seth, and/or Peter to
cite specific precedent, but my understanding is the key legal concept
is that Tor routers are common carriers, and provide transit for any
material that attempts to use them. There is quite a bit of legal
precedent in the US that protects communication carriers from liability. This is also a main reason why we discourage attempts to monitor and
filter Tor exit traffic, because your legal responsibilities change.
So long as you are acting as a common carrier, you are no more
personally liable for events that traverse your network than Comcast,
Sprint, or Level3. Now personally, I think that what might be more likely to win you
points with your ISP is to reiterate that these events are
extremely rare in comparison to the number of requests and the amount
of traffic that you carry. The overwhelming majority of people are
using the service legitimately, and the incident rate is close to that
of the normal Internet.
It also helps to remind them that for serious cases, traditional
police work is still very effective. Almost all crimes (especially
harassment) are committed by people with means, motive, and
opportunity. These three factors are far more damaging to anonymity
sets than IP addresses, and the police have been working with
anonymously delivered harassment letters and the like for centuries.
Thus spake Trystero Lot (lot49 at callout.me):

@_date: 2010-08-24 01:20:40
@_author: Mike Perry 
@_subject: Police raid in Erfurt, Germany on "Perfect Privacy", a commercial anon-service 
English version:
Appears to be possibly related to their SSH/VPN service, not their Tor
nodes. As far as I can tell, they've run no Tor exits recently, only
Thus spake heidenheim at attac.de (heidenheim at attac.de):

@_date: 2010-08-24 08:27:53
@_author: Mike Perry 
@_subject: How to Run High Capacity Tor Relays 
After talking to Moritz and Olaf privately and asking them about their
nodes, and after running some experiments with some high capacity
relays, I've begun to realize that running a fast Tor relay is a
pretty black art, with a lot of ad-hoc practice. Only a few people
know how to do it, and if you just use Linux and Tor out of the box,
your relay will likely underperform on 100Mbit links and above.
In the interest of trying to help grow and distribute the network, my
ultimate plan is to try to collect all of this lore, use Science to
divine out what actually matters, and then write a more succinct blog
post about it.
However, that is a lot of work. It's also not totally necessary to do
all this work, when you can get a pretty good setup with a rough
superset of all of the ad-hoc voodoo. This post is thus about that
Hopefully others will spring forth from the darkness to dump their own
voodoo in this thread, as I suspect there is one hell of a lot of it
out there, some (much?) of which I don't yet know. Likewise, if any
blasphemous heretic wishes to apply Science to this voodoo, they
should yell out, "Stand Back, I'm Doing Science!" (at home please, not
on this list) and run some experiments to try to eliminate options
that are useless to Tor performance. Or cite academic research papers.
(But that's not Science, that's computerscience - which is a religion
like voodoo, but with cathedrals).
Anyway, on with the draft:
== Machine Specs ==
First, you want to run your OS in x64 mode because openssl should do
crypto faster in 64bit.  Tor is currently not fully multithreaded, and tends not to benefit
beyond 2 cores per process. Even then, the benefit is still marginal
beyond just 1 core. 64bit Tor nodes require about one 2Ghz Xeon/Core2
core per 100Mbit of capacity.
Thus, to fill an 800Mbit link, you need at least a dual socket, quad
core cpu config.  You may be able to squeeze a full gigabit out of one
of these machines. As far as I know, no one has ever done this with
Tor, on any one machine.
The i7's also just came out in this form factor, and can do
hyperthreading (previous models may list 'ht' in cpuinfo, but actually
don't support it). This should give you a decent bonus if you set
NumCPUs to 2, since ht tends to work better with pure integer math
(like crypto). We have not benchmarked this config yet though, but I
suspect it should fill a gigabit link fairly easily, possibly
approaching 2Gbit.
At full capacity, exit node Tor processes running at this rate consume
about 500M of ram. You want to ensure your ram speed is sufficient,
but most newish hardware is good. Using on this chart:
you can do the math and see that with a dozen memcpys in each
direction, you come out needing DDR2 to be able to push 1Gbit full
As far as ethernet cards, the Intel e1000e *should* be theoretically
good, but they seem to fail at properly irq balancing across multiple
CPUs on recent kernels, which can cause you to bottleneck at 100% CPU
on one core. At least that has been Moritz's experience. In our
experiments, the RTL-8169 works fine (once tweaked, see below).
== System Tweakscript Wibbles and Config Splatters ==
First, you want to ensure that you run no more than 2 Tor instances
per IP. Any more than this and clients will ignore them.
Next, paste the following smattering into the shell (or just read it
and make your own script):
# Set the hard limit of open file descriptors really high.
# Tor will also potentially run out of ports.
ulimit -SHn 65000
# Set the txqueuelen high, to prevent premature drops
ifconfig eth0 txqueuelen 20000
# Tell our ethernet card (interrupt found from /proc/interrupts)
# to balance its IRQs across one whole CPU socket (4 cpus, mask 0f).
# You only want one socket for optimal ISR and buffer caching.
# Note that e1000e does NOT seem to obey this, but RTL-8169 will.
echo 0f > /proc/irq/17/smp_affinity
# Make sure you have auxiliary nameservers. I've seen many ISP
# nameservers fall over under load from fast tor nodes, both on our
# nodes and from scans. Or run caching named and closely monitor it.
echo "nameserver 8.8.8.8" >> /etc/resolv.conf
echo "nameserver 4.2.2.2" >> /etc/resolv.conf
# Load an amalgam of gigabit-tuning sysctls from:
# # # # # and elsewhere...
# We have no idea which of these are needed yet for our actual use
# case, but they do help (especially the nf-contrack ones):
sysctl -p << EOF
net.ipv4.tcp_rmem = 4096 87380 16777216
net.ipv4.tcp_wmem = 4096 65536 16777216
net.core.netdev_max_backlog = 2500
net.ipv4.tcp_no_metrics_save = 1
net.ipv4.tcp_moderate_rcvbuf = 1
net.core.rmem_max = 1048575
net.core.wmem_max = 1048575
net.ipv4.ip_local_port_range = 1025 61000
net.ipv4.tcp_synack_retries = 3
net.ipv4.tcp_tw_recycle = 1
net.ipv4.tcp_max_syn_backlog = 10240
net.ipv4.tcp_fin_timeout = 30
net.ipv4.tcp_keepalive_time = 1200
net.ipv4.tcp_keepalive_time = 60
net.ipv4.tcp_keepalive_intvl = 10
net.ipv4.tcp_keepalive_probes = 3
net.ipv4.ip_local_port_range = 1025 65530
vm.min_free_kbytes = 65536
net.ipv4.tcp_syncookies = 1
net.ipv4.tcp_synack_retries = 2
net.ipv4.conf.default.proxy_arp = 1
net.ipv4.conf.all.rp_filter = 1
net.ipv4.conf.default.send_redirects = 1
net.ipv4.conf.all.send_redirects = 0
# XXX: ethtool wibbles # You may also have to tweak some parameters with ethtool, possibly
# also enabling some checksum offloading or irq coalescing options to
# spare CPU, but for us this hasn't been needed yet.
== Setting up the Torrc ==
Basically you can just read through the stock example torrc, but there
are some as-yet undocumented magic options, and options that need new
# NumCPUs doesn't provide any benefit beyond 2, and setting it higher
# may cause cache misses.
NumCPUs 2
# These options have archaic maximums of 2-5Mbyte
BandwidthRate 100 MB
BandwidthBurst 200 MB
== Waiting for the Bootstrap and Measurement Process ==
Perhaps the most frustrating part of this setup is how long it takes
for you to acquire traffic. If you are starting new at an ISP, I would
consider only 200-400Mbit for your first month. Hitting that by the
end of the month may be a challenge, mostly because their may be dips
and total setbacks along the way.
The slow rampup is primarily due to limitations in Tor's ability to
rapidly publish descriptor updates, and to measure relays.
It ends up taking about 2-3 days to hit an observed bandwidth of
2Mbyte/sec per relay, but it can take well over a week or more (Moritz, do
you have a better number?) to reach 8-9Mbyte/relay. This is for an
Exit node. A middle node will likely gather traffic slower. Also once
you crash, you lose it. This bug is about that issue:
There is also a potential dip when you get the Guard flag, as our load
balancing formulas try to avoid you, but no clients have chosen you
yet. Changes to the authority voting on Guards in Tor 0.2.2.15 should
make this less drastic. It is also possible that your observed
bandwidth will be greater than without it. However, it will still take
up to 2 months for clients to choose you as their new Guard. == Running temporary auxiliary nodes ==
One way to shortcut this process and avoid paying for bandwidth you
don't use is to spin up a bunch of temporary nodes to utilize the CPU
and quickly gather that easy first 2MB/sec of observed bandwidth.
But you need the spare IPs to do this.
== Monitoring ==
Personally, I prefer console-based options like nload, top, and
Damian's arm ( because I don't like the
idea of running extra services to publish my monitoring data to the
Other people have web-based monitoring using things like munin and
mrtg. It would be nice to get a script/howto for that too.
== Current 1-Box Capacity Record == Our setup has topped at 450Mbit, but averages between 300-400Mbit. We
are currently having uptime issues due to heat (melting, poorly
ventilated harddrives). It is likely that once we resolve this, we
will continually increase to our CPU ceiling.
I believe Moritz and Olaf also push this much capacity, possibly a bit
more, but with less nodes (4 as opposed to our 8). I hear Jake is also
ramping up some Guard nodes (or maybe I didn't? Did I just betray you
again Jake?)
== Did I leave anything out? ==
Well, did I?

@_date: 2010-08-25 00:36:42
@_author: Mike Perry 
@_subject: How to Run High Capacity Tor Relays 
I should have said this in my first post, but I believe that all
subsequent replies should go to tor-relays. This should be the last
post discussing technical details of relay operation on or-talk.
Thus spake coderman (coderman at gmail.com):
Hrmm, Tor does its own application-level keepalive. Perhaps that's how
this got merged in by confusion. Or maybe, like many of these, it was
just a blanket cut+and+paste move out of desperation to try to
increase capacity. The whole superset of voodoo thing.
Will this remove the ability to do PREROUTING DNAT rules? I know a lot
of Tor nodes forward ports and even IPs around.
Good suggestion though. Perhaps we should mention both options in the
final draft.
Oh shit, that is a relic of Mortiz's config. He is also planning to
provide VPN and VPS services. Good catch.
Also, does DNAT count as forwarding for the ip_forward option? I'd love to hear Roger and Nick's comments on this, but isn't it
possible this might also bottleneck well before 1Gbit? I am worried it
may depend largely on the architecture of the card and our use of
openssl. Their docs claim "up to 1Gbit" but this could be using highly
parallelized processing, which tor cannot really do, as I understand
Personally I think the hyperthreading option is the lowest hanging
fruit for maxing out a single Tor relay process for lowest cost.
Also, afaik, zero people in the wild are actively running Tor with any
crypto accelerator. May be a very painful process... I'm not really
interested in documenting it unless its proven to scale by actual use.
I want this document to end up with tested and reproduced results
only. You know, Science. Not computerscience ;)

@_date: 2010-08-25 01:24:21
@_author: Mike Perry 
@_subject: The team of PayPal is a band of pigs and cads! 
Thus spake David Carlson (carlson.dl at sbcglobal.net):
There have already been lots of excellent paypal-specific answers
here, but the more general problem is that any company on the web is,
or at least eventually will conider, making money of of your
information, any way they can.
Using the Firefox addon RequestPolicy really makes you aware of this.
For example, I've seen facebook domains sourced in my airline ticket
purchase windows. When I happen to be wearing my paranoid hat (pretty
often -- it's rather stylish), I am convinced this is facebooks' way
of getting to ground-truth on an identity they have a profile for,
because plane ticket use is strongly authenticated.
I'm sure the same thing can happen with any bank, or even online
merchant. Once they get a purchase with a cookie set and IP, they not
only know your location, but they can correlate it with the rest of
the marketing data they have on you, and if you dont clear your use
Tor+Torbutton, they can infer a list of the rest of the websites you
visit.  In this case, "they" of course, are the voracious advertising
In fact, because so many users are actually clearing cookies these
days, marketing companies have begun developing fingerprints to track
you even if your cookies and IP change:
 Torbutton blocks most of
these, but work needs to be done to block more.
So for me, Tor is about cutting that crap off at the bud. If I must be
strip-searched at the airport (digitally or not), and have my airline
ticket purchase IP recorded at the DHS[2], at the very least they will
not correlate that with my other Internet activity.
In fact, you could take the paypal conspiracy one further, in that
they also don't like many forms of prepaid gift card use. They are
simply not interested in collecting information that contains any
noise what-so-ever...
1. 2.

@_date: 2010-08-25 17:52:20
@_author: Mike Perry 
@_subject: Google and Tor. 
Thus spake Matthew (pumpkin at cotse.net):
This has been a known problem with Google for ages. There are numerous
ways we could improve this situation without requiring blanket
exemptions for Tor Exits (such as client side puzzles, or more
intelligent rate limiting algorithms that are more tolerant of our
typically cookieless but legitimate users coming in large masses from
the same IP). Unfortunately the DoS team at Google is unwilling to work with us to
find alternate ways of limiting these captchas at the moment. Tor has
many friends inside Google, but sadly the DoS team is independent
enough from the rest of Google that regardles of Google's opinion of
Tor or censorship circumvention, the DoS team is unwilling to devote
any development resources to improving this problem, and have declined
even meeting with us directly :(
Astute students of human nature will note that this is the result you
expect when you place a small group of people in a position of
unassaillable control of a resource for "security reasons"...
Our current solution is to automatically redirect Google Captcha
requests to alternate search engines such as ixquick, scroogle, yahoo,
or bing. This feature was introduced in Torbutton 1.2.5 and uses
ixquick by default. However, Google's recent switch to using encrypted.google.com for SSL
search caused our captcha detection code to break in Torbutton. So if
you are using encrypted search and/or HTTPS Everywhere, your captchas
will no longer be seamlessly redirected.
This should be fixed in Torbutton 1.2.6.

@_date: 2010-08-25 20:04:01
@_author: Mike Perry 
@_subject: Google and Tor. 
Thus spake Aplin, Justin M (jmaplin at ufl.edu):
Various horrible behaviors have come and go with this captcha system
over the past 3 years or so. Sometimes you just get a 403 with no
captcha, sometimes you have to solve a captcha, sometimes 2 captchas,
sometimes infinite captchas, and sometimes it forgets your query and
you have to start the whole process over again from a Google landing
My point is that the whole system is problematic on a number of
levels. I also personally believe that there are better ways of rate
limiting and screening queries from high-user count IPs that do not
involve cookies or captchas.
I also question Google's threat model on this feature. Sure, they want
to stop people from programmatically re-selling Google results without
an API key in general, but there is A) no way people will be reselling
Tor-level latency results, B) no way they can really expect determined
competitors not to do competitive analysis of results using private IP
ranges large enough to avoid DoS detection, C) no way that the total
computational cost of the queries coming from Tor can justify denying
so many users easy access to their site.
This is why I'd love a chance to meet with the DoS team to discuss
some of these points. However, I get the strong impression it is a
very secretive group that is especially wary of discussing their
methods, reasoning, or analysis and with anyone else, and is generally
given a blank check to enact policy without proper in-depth
cost/benefit analsysis because its actions are "for security".

@_date: 2010-08-25 23:11:46
@_author: Mike Perry 
@_subject: Google and Tor. 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
Good point. However I wasn't advocating whitelisting Tor exits, I was
advocating more intelligent treatment of all high user-count IP
addresses, and better mechanisms of rate limiting in general. It's my
understanding that a lot of NATed users also run into these captchas
during search.
To reduce scraping by suspect IPs, their servers could perform all
sorts of browser tests to ensure that there is a full working DOM
supported by javascript, which can be computationally costly to deploy
by scrapers.  They can also serve javascript code that performs
semi-large integer factorization in the background and post the
factors back with queries to rate limit scrapers computationally, or
at least tip the cost ratios more in favor of just paying for an API
key. Perhaps more effective, they could use various metrics to indirectly
estimate the number of humans behind an IP. There are plenty of Google
services and applications they provide that aren't really usable by
bots. The rate of use of these non-search services per IP should
provide a strong indicator of human activity behind that IP.
Again, the impression I got was that if they had done the analysis on
the captcha solve rate vs the query rate per IP, the cost/benefit
analysis of the DoS mechanisms they apply, or the cost vs
effectiveness vs user impact of alternatives, they certainly weren't
willing to discuss any of this with us. They also seemed disinclined to
meet to explore any realistic alternatives we could jointly develop in
both Torbutton and the DoS side to help reduce the captchas and 403s
experienced by our users.

@_date: 2010-08-27 15:08:04
@_author: Mike Perry 
@_subject: Google and Tor. 
Thus spake Orionjur Tor-admin (tor-admin at orionjurinform.com):
Well the current plan is to add support for FF4 and fix a smattering
of bugs, including this one, in the 1.2.6 release. However, I am also
trying to help fix bugs in 0.2.2.x, and help improve the Google Chrome
APIs to allow for a Chrome Tor mode
( amongst a few
other things that I feel are rather important in the near term. In
fact, I've been so busy lately that I haven't even fixed the issue in
git or my copy of Torbutton, so rest assured that I feel the pain as
much as you do. But it still may be a while.

@_date: 2010-08-28 17:56:31
@_author: Mike Perry 
@_subject: Tor seems to have a huge security risk--please prove me wrong! 
Thus spake Roger Dingledine (arma at mit.edu):
Yes. This is the approach we need to solve this problem. However, one
of the problems with getting it out of most academics is the bias
against easy reproducibility. In order for any of this research to be
usable by us, it must be immediately and easily verifiable and
reproducible in the face of both changing attacks, and changing
network protocols (such as UDP-Tor and SPDY). This means source code
and experimental logs and data.
Most computer science academia is inherently biased against providing
this data for various reasons, and while this works for large industry
with the budget and time to reproduce experiments without assistance,
it will not work for us. I believe it is the main reason we see
adoption lag of 5-10 years for typical research all over
computer-related academia. My guess is Tor not have this much time to
fix these problems, hence we must demand better science from researchers who claim to be solving Tor-related problems (or proving
attacks on Tor networks).
I've gone into a little more detail on this subject and the
shortcomings of timing attacks in general in my comments on Michal
Zalewski's blog about regular, non-Tor HTTPS timing attacks:

@_date: 2010-08-29 00:54:59
@_author: Mike Perry 
@_subject: Tor seems to have a huge security risk--please prove me wrong! 
Thus spake Paul Syverson (syverson at itd.nrl.navy.mil):
Yeah, though again I want to point out that what we are actually
looking at when we intuitively believe fingerprinting to be easier to
solve than correlation is the event rate from the base rate fallacy.
Otherwise, they really are the same problem. Correlation is merely the
act of taking a live fingerprint and extracting a number of bits from
it, and adding these bits to the number of bits obtained from a window
of time during which the event was supposed to have occurred.
Or, to put it in terms of event rates, it is merely the case that much
fewer potentially misclassified events happen during the very small
window of time provided by correlation, as opposed to the much larger
number of events that happen during a dragnet fingerprinting attempt.
Any classifier needs enough bits to differentiate between two
potentially coincident events. This is also why Tor's fixed packet
size performs better against known fingerprinting attacks. Because
we've truncated the lower 8 bits off of all signatures that use size
as a feature in their fingerprint classifiers. They need to work to
find other sources of bits.
Personally, I believe that it may be possible to develop fingerprint
resistance mechanisms good enough to also begin to make inroads
against correlation, *if* the network is large enough to provide an
extremely high event rate. Say, the event rate of an Internet-scale
anonymity network.
For this reason, I think it is very important for academic research to
clearly state their event rates, and the entropy of their feature
extractors and classifiers. As well as source code and full data
traces, so that their results can be reproduced on larger numbers of
targets and with larger event rates, as I mentioned in my other reply.

@_date: 2010-08-29 17:13:21
@_author: Mike Perry 
@_subject: Tor seems to have a huge security risk--please prove me wrong! 
Thus spake Paul Syverson (syverson at itd.nrl.navy.mil):
Ah, of course. What I meant to say then was that "passive
fingerprinting" really is the same problem as "passive correlation". I don't spend a whole lot of time worrying about the "global *active*
adversary", because I don't believe that such an adversary can really
exist in practical terms. However, it is good that your research
considers active adversaries in general, because they can and do exist
on more localized scales.
I do believe that the "global external passive adversary" does exist
though (via the AT&T secret rooms that splice cables and copy off
traffic in transit), and I think that the techniques used against
"passive fingerprinting" can be very useful against that adversary. I
also think a balance can be found to provide defenses against the
"global external passive adversary" to try to bring their success
rates low enough that their incentive might switch to becoming a
"local internal adversary", where they have to actually run Tor nodes
to get enough information to perform their attacks.
This is definitely a terminological quibble, but I think it is useful
to consider these different adversary classes and attacks, and how
they relate to one another. I think it is likely that we are able to
easily defeat most cases of dragnet surveillance with very good
passive fingerprinting defenses, but that various types of active
surveillance may remain beyond our (practical) reach for quite some
In most cases, we pretty intensely frown on these attacks on the live
Tor network, even for research purposes, so I don't think anyone is
asking for live user traces. However most of this research is done in
simulation, and it is rare if ever that the source code for the attack
setup, or the simulation traces are ever provided.
As I said before, it would be great if we could develop a common
gold-standard simulator that we could use for all of this research.
The UCSD people may be building something like this, but I also seem
to recall Steven Murdoch being interested in providing some model or
corpus for base-line comparison of all timing attack literature.
I don't think this is too off-topic, because I am saying that this
openness is what we need to be able to effectively study timing
attack and defense. I don't think it will be possible to succeed
without it.

@_date: 2010-08-29 19:39:28
@_author: Mike Perry 
@_subject: Tor seems to have a huge security risk--please prove me wrong! 
Thus spake Gregory Maxwell (gmaxwell at gmail.com):
According to the research groups Roger has talked to, yes, this is the
The problem though is that it's hard to publish a no-result, unless
its pretty a pretty surprising no-result, or at least a quantifiable
no-result. It's not terribly surprising that existing fingerprinting
techniques do not work well "out of the box" against Tor, because a
lot less information is available during a Tor session, and there is a
lot more noise (due to more than just the 512-byte cell size).
If someone actually worked hard and took all these things into
account, and still had a result that said "Fingerprinting on Tor does
not usually work unless you have fewer than than X numbers of targets
and/or event rates below Y", it still probably would belong more in a
tech report than a full academic paper, unless it also came with
information-theoretic proofs that showed exactly why their
implementation got the results it did.

@_date: 2010-08-11 03:05:24
@_author: Mike Perry 
@_subject: Restricted Exit Policy Port Suggestions? 
It's become clear that it is almost impossible to run an exit node
with the default exit policy in the USA, due to bittorrent DMCA abuse
spambots. I believe this means that we should try to come up with one
or more standard, reduced exit policy sets that allow use of the
majority of popular internet services without attracting bittorrent
users and associated spam.
Using previous threads, I have an initial sketch of such a policy at:
It includes the following ports: 20-22, 53, 79-81, 110, 143, 443, 465,
563, 587, 706, 873, 993, 995, 1863, 5190, 5050, 5222, 5223, 8008,
8080, 8888.
While looking over the Vidalia settings, I just noticed that IRC is
missing from this list: 6666, 6667, 6697. However, IRC is also a common source of abuse and DDoS attacks, and is
often forbidden by ISP AUP. Because of this, I was thinking we should
probably define 3 or 4 levels of Exit Policy:
1. Low Abuse (above list, possibly minus 465, 587 and 563)
2. Medium Abuse (above list, plus IRC)
3. High Abuse (default exit policy)
Now the question is, what other ports should we add or subtract from
this list?

@_date: 2010-08-11 08:52:33
@_author: Mike Perry 
@_subject: Restricted Exit Policy Port Suggestions? 
Thus spake andrew at torproject.org (andrew at torproject.org):
Yeah, unfortunately what this means in practice is "voting with your
feet" and leaving ISPs that simply do not want to devote the staff and
the stress to dealing with this spam for you, regardless of the law.
The problem is this drastically changes the effective market for
bandwidth for Tor. Bandwidth costs are plummeting, and exit node
operators (and thus the Tor network as a whole) are faced with a
choice: you can pay less than $1/Mbit and go with an ISP that is less
than ideal, but will still allow you to exit to most Internet
services, or you put your foot down and end up moving your node every
few months until you finally end up paying $20/Mbit with the RBN. Or, you shop around for non-US bandwidth.
Sometimes, you just need to pick your battles. If you believe the DMCA
is bullshit and want a full exit policy, I think the practical answer
is "Go outside the US for bandwidth". Or, be prepared to provider-hop
for a good, long time.
Yeah, perhaps that's not what we should call the options in the UI,
but that is really what it boils down to. You can run an exit node for
much longer without a complaint if you don't allow any form of IRC,
SMTP, or NNTP.

@_date: 2010-08-11 15:17:07
@_author: Mike Perry 
@_subject: Restricted Exit Policy Port Suggestions? 
Thus spake Mike Perry (mikeperry at fscked.org):
Now, what we *should* be doing is turning on the default first, and
then reducing it back to the restriced policy *after* complaints
arrive and the ISP refuses the budge.
They are not going to cancel service immediately, and if you argue
with them for a bit, you can at least try to educate some people (and
maybe make it easier for the next relay they get). This is what I've
done with my nodes, and this is what Moritz did too. So far though,
ISPs have insisted that either bittorrent goes, or we go.

@_date: 2010-08-16 11:31:52
@_author: Mike Perry 
@_subject: Tor Project 2008 Tax Return Now Online 
Thus spake Jonathan D. Proulx (jon at csail.mit.edu):
Yes. The larger threat is that funders can stear funding in a general
direction. Say, by prioritizing performance over censorship
resistence, or censorship resistence over anonymity research.
So far however, it appears that everyone involved is on the same page,
and believes that performance, usability, censorship resistence, and
general anonymity research are *all* important to our goal.
As an aside, while a global adversary is not something the Tor
research and development community feels it is currently capable of
defending against in general, there are limits to the ability of
even a global adversary to perform accurate dragnet analysis of all
Tor traffic.
This is primarly due to the Base Rate Fallacy:
In other words, the average Tor user doesn't have a lot to fear, IMO.
However, once you are targeted specifically by a global adversary, or
if you are visiting sites that are targeted by a global adversary,
your odds of escaping detection do go down drastically.
The big problem that Tor faces is that most schemes to protect against
this sort of adversary are either costly, unproven, or both. There
were a couple of promising papers at PETS this year, but they need to
have a bit more time to be reviewed by the research community.  They
also add non-negligible overhead.

@_date: 2010-08-16 22:49:24
@_author: Mike Perry 
@_subject: Tor Project 2008 Tax Return Now Online 
Thus spake Anon Mus (my.green.lantern at googlemail.com):
You're right, that's exactly why the work hasn't been finished yet.
Everyone smart enough to do it realized that we'd just cause git
conflicts with their work. They'd be foiled once and for all. ONCE AND
FOR ALL!
It has nothing to do with realizing that the best designs for these
sorts of networks to date still aren't certain to be foolproof or
fast, or that completing and proving such a design to be secure and
scalable under a useful threat model would be at least a master's
It has nothing to do with realizing that any naive padding solution
would be instantly broken, providing a unique fingerprint for everyone
using it, while *still* not providing substantial actual protection of
their traffic.
It has everything to do with the fact that the conspiracy is SO VAST
AND OPPRESSIVE that everyone smart enough to do this project realizes
that we'd just break their commits and there would be NOTHING THEY
COULD DO ABOUT IT.
Tor: 1, You Guys: 0.
It's great being on the inside.
I see you've been reading between the lines on our monthly status
reports, our roadmap docs, our trac projects, our specifications, our
proposal process on or-dev, our TODO files, and so on. Very clever of
you. For those not as swift as our detective here, the evidence (with full
revision history) is hiding in plain sight at:
The conspiracy is really too obvious in retrospect, especially if the
likes of you were able the figure it out. We should be more careful with our future conspiracies. This has been
noted in our files.
Don't forget all the University professors and grad students doing Tor
research independent of the Tor Project. They are paid off to keep
quiet, too. Most of them have island beachfront property (but under black ops front company names, of course). It's a pretty sweet gig.
Of course, you could add that same protection in too. But, then, of
course, we'd break your commits. This is the one advantage of
sponsoring Tor. The US Gov't quickly realized that otherwise, we'd
break their commits too. They had no choice, really. It really is the best revenue model for Open Source Development yet.
We should write a book, if it weren't so damn secret...
You know too much, Mr. Anon Mus. The Adversary has been alerted.
Prepare to be silenced (if we're lucky).

@_date: 2010-08-17 14:23:38
@_author: Mike Perry 
@_subject: TLS NPN (Next Protocol Negotiation) 
============================== START ==============================
Thus spake Seth David Schoen (schoen at eff.org):
It does seem like something we would try to use, but only if it were
deployed widely enough so that we weren't the only ones using it.
The point I would make is that its very likely that most services
will continue to operate on their traditional tcp ports, regardless of
NPN. Administrators hoping to be able to block protocols by a TLS
fingerprint seem to be barking up the wrong tree. Anyone wishing to
subvert their controls will use a custom TLS/stunnel bridge on an
acceptable port as defined by their policy. I think this indicates
that you are right.
The more effecive way I have seen to do these sorts of controls is by
policy enforcement on the software that the machines themselves can
run, rather than on the network.

@_date: 2010-12-09 19:29:25
@_author: Mike Perry 
@_subject: Torbutton, CSS3 and window size 
Thus spake Just A. User (just_a_user at justemail.net):
The short answer here is that new CSS3-based fingerprinting attacks
are currently not possible to fully defend against through
extension-land, and that while we do take them seriously, we don't
have a lot of options to truly protect against them in the short term.
JonDoNym is performing a bit of slight of hand on its users wrt to
these attacks. It only "protects" against these attacks by requiring
that Javascript be disabled, but this is not a full defense. The CSS3
"Media Queries" allow you to select entire stylesheets to be loaded on
the basis of screen resolution and display information:
Thus, media queries are quite capable of inducing element loads based
on screen resolution and font information, which can be used to ping a
server with information about your resolution without the need for
Javascript. The mechanisms for this are similar to the CSS-only
history attack that does not require Javascript and works on Firefox
2.x and 3.x: The JonDoNym test is only using the Javascript versions of these
attacks, and therefore the JonDoFox profile they provide is given a
green "pass" against them, even though a dedicated adversary could
extract the same information with CSS3 alone. When I run Torbutton
with Javascript disabled, I get very similar results to the JonJoFox
profile on their test (are you sure you had javascript fully
But again, the reality is this is not the whole story.
We are currently actively trying to get people at the W3C and inside
Google and Mozilla to address these issues, because short of us
patching the browsers directly, there is not much we can do here. We
may end up patching our Tor Browser Bundle builds if it doesn't appear
that any of these groups are taking these new fingerprinting vectors
seriously. This places us in an interesting legal situation with
Mozilla, because technically such a patch means that we can no longer
use the trademark "Firefox" to describe the browser we provide in this
Our goal for the W3C is to get them to define a common subset of
rendering behaviors that all browsers can adhere to while in "private
browsing mode". I believe the timeline for adoption of this standard
would be measured in multiple years, though.
Our goal with the browsers is to convince them to provide us with some
kind of API to interact with CSS and the rendering system. For Chrome,
their release cycle is faster and this process would be measured in
months (if we had all the other APIs we needed, see
But for Firefox, their release cycle is slower, and this time period
is probably still measuted in years.
So to sum it up, lots of rocks, and lots of hard places :/

@_date: 2010-12-02 16:55:02
@_author: Mike Perry 
@_subject: Very low performance in CriptolabTORRelays* 
Thus spake Daniel Franganillo (danielf at dilmun.ls.fi.upm.es):
I think no one is answering your mail because of this statement. If
the Tor network is blocked by your ISP, you can't exactly expect to
run a relay...
Did you confirm the block? Did you try connecting to some of the other
public tor relays? A simple way to do this is to just use Firefox and
type in  and see if you get a cert warning
or not.
Another way to do this is to try to use Tor as a client. Does that
How about using a client with bridges. Do they work?

@_date: 2010-12-02 17:04:33
@_author: Mike Perry 
@_subject: Active Attacks - Already in Progress? 
Thus spake Theodore Bagwell (toruser1 at imap.cc):
In this case, you are experiencing your guard nodes. This is a
protective measure where the Tor client remembers a set of 3 live
nodes and tries to use them for up to 2 months for its 1st hop... This
is done to protect against a wide variety of traffic analysis attacks.

@_date: 2010-12-18 13:25:48
@_author: Mike Perry 
@_subject: Fwd: Re: DMCA Infringement Notification: Copies of 14 complaints 
Hrmm. You probably shouldn't be running an exit router on your home
Internet connection, either. To my knowledge, no one has ever had
their door kicked in in the USA for running an exit router, but there
have been phone calls and visits. In other countries, people have had
all of their computing equipment seized, and in rare cases, have had
charges brought against them for copyrighted or other material found
that was completely unrelated to Tor.
It's best to keep your home connection running as middle or bridge
only, unless you are fully prepared for the risks of increased
attention to your home.
Thus spake scar (scar at drigon.com):

@_date: 2010-12-18 13:25:48
@_author: Mike Perry 
@_subject: Fwd: Re: DMCA Infringement Notification: Copies of 14 complaints 
Hrmm. You probably shouldn't be running an exit router on your home
Internet connection, either. To my knowledge, no one has ever had
their door kicked in in the USA for running an exit router, but there
have been phone calls and visits. In other countries, people have had
all of their computing equipment seized, and in rare cases, have had
charges brought against them for copyrighted or other material found
that was completely unrelated to Tor.
It's best to keep your home connection running as middle or bridge
only, unless you are fully prepared for the risks of increased
attention to your home.
Thus spake scar (scar at drigon.com):

@_date: 2010-12-03 00:14:30
@_author: Mike Perry 
@_subject: Very low performance in CriptolabTORRelays* 
Thus spake Daniel Franganillo (danielf at dilmun.ls.fi.upm.es):
Great! Now we're getting somewhere. Now, your question isn't "How do I
run a relay at a censored ISP" it's "Please help me use Tor at a
censored ISP." That is a question we are prepared to at least *try* to
answer :)
Can you access the following page:
If it too is blocked, blocked, it is also available via the
ssl-encrypted proxy link on ixquick:
Similarly it is in the Google Cache, which is now available over SSL.
If you feel you can follow those instructions, can we meet on IRC? Can
you access  on irc.oftc.net? Port 6697 is SSL, if you suspect
keyword filtering too.
Specify a time and we can give you a private bridge IP and try to
diagnose exactly how your ISP is blocking access to Tor.
P.S. The above goes for anyone who knows anyone having trouble
*accessing* the Tor network from anywhere else. Please contact me or
show up on  We are in desperate need of people inside China to help us with this.
So far we have zero people there who can help us diagnose what is
going on.

@_date: 2010-12-03 00:17:36
@_author: Mike Perry 
@_subject: Help me diagnose my Tor blocked/censored ISP! 
Actually, let's break this thread off into a new one with new subject, too.
Sorry about the double-post. Just want to make sure this hits the
search engines.
Thus spake Daniel Franganillo (danielf at dilmun.ls.fi.upm.es):
Great! Now we're getting somewhere. Now, your question isn't "How do I
run a relay at a censored ISP" it's "Please help me use Tor at a
censored ISP." That is a question we are prepared to at least *try* to
answer :)
Can you access the following page:
If it too is blocked, blocked, it is also available via the
ssl-encrypted proxy link on ixquick:
Similarly it is in the Google Cache, which is now available over SSL.
If you feel you can follow those instructions, can we meet on IRC? Can
you access  on irc.oftc.net? Port 6697 is SSL, if you suspect
keyword filtering too.
Specify a time and we can give you a private bridge IP and try to
diagnose exactly how your ISP is blocking access to Tor.
P.S. The above goes for anyone who knows anyone having trouble
*accessing* the Tor network from anywhere else. Please contact me or
show up on  We are in desperate need of people inside China to help us with this.
So far we have zero people there who can help us diagnose what is
going on.

@_date: 2010-12-28 21:05:40
@_author: Mike Perry 
@_subject: 27C3 on Tor 
Thus spake Roc Admin (onionroutor at gmail.com):
Here's a direct link to the relevant section:
The work seems to be pretty thorough, but it would be nice to have a
paper and/or the source to their classifier. The 27c3 website doesn't
seem to list much:
The results aren't very specific in the video. It looks like they
covered the major pitfall of timing attack research (the Base Rate
Fallacy) with their presentation of the True Positive rate and the
False Positive rate, but it's not 100% clear, because there's only a
single slide with the results:
The other detail that's not clear is if you train your detector for 5
interesting websites, and 2000 uninteresting ones, what happens if the
target is browsing sites outside of those 2000 uninteresting ones?

@_date: 2010-12-07 15:34:02
@_author: Mike Perry 
@_subject: Chrome and Safari IP leak 
Thus spake Roger Dingledine (arma at mit.edu):
Turns out that wget can be 302d between schemes to cause you to bypass
proxy settings. For example, if you have the $HTTP_PROXY environment
variable set but nothing for $HTTPS_PROXY, a 302 to an https url will
cause you to bypass proxy. I wouldn't be surprised if the same could
happen for an ftp url.
So the answer is "Just because you think your program is simple
doesn't mean it is. We haven't fully audited anything other than
Firefox, but we do know most of it isn't safe."
Robert Hogan *has* audited a few more apps, but only in conjuction
with his 'torsocks' utility: It looks like wget also has a note there about unsafe HTTP headers..
Not sure exactly what it is sending.

@_date: 2010-12-07 16:01:07
@_author: Mike Perry 
@_subject: Chrome and Safari IP leak 
Thus spake Karsten N. (tor-admin at privacyfoundation.de):
As Roger said, Chrome is not yet supported. We're working with Google
to change this:
But thanks for reporting this bug. Turns out it already has a ticket
in Chrome's bug tracker, but I wasn't aware of it:
I've added it to our list of Chrome issues at:
I will also ping the lead developer for Chrome proxy settings.
Unfortunately, they are currently on leave until early next year I

@_date: 2010-12-01 18:02:05
@_author: Mike Perry 
@_subject: Simulator for slow Internet connections 
Thus spake John Case (case at SDF.LONESTAR.ORG):
I've personally used Linux's NetEM for testing my Tor Circuit Build
Timeout learning code:
It worked well but it has a major drawback in that if you use netem on
the same machine as your code is running, you can't do real packet
loss simulations because the Linux networking stack hints to the TCP
layer that the loss was artificial so that window sizes are not
adjusted as they would be in reality:
Getting a patch to disable this behavior would be a great help.
Otherwise, I think we need to revise this task on our website to say
that we're looking for a Tor network simulator, not a slow network
simulator. Easy mistake, I guess ;)

@_date: 2010-02-13 14:14:28
@_author: Mike Perry 
@_subject: Torbutton : please offer better user agent choices 
Thus spake andrew at torproject.org (andrew at torproject.org):
Right. This is a very strange and frustrating thread. In fact, at
first I suspected it was just a troll looking to waste my time and
But to give Ms/Mr. Turtle the benefit of the doubt, here's the story,
one last time: The other features of Torbutton that allow one to shoot
themselves in the foot exist because they enable the functionality of
plugins or other addons or allow the user to work around bugs.
We are not in the habit of providing features that are demonstrably
bad for anonymity for no reason, and I am certainly not going to
give such work priority over much more important things such as
improving the performance of the network as a whole (for ex, my latest
work: The answer is "Use UA Switcher to give yourself a unique ID if you
want", and that's final. Hell, go ahead and write the SHA1 hash of
your address and social security number in there if that turns you on.
It still won't make you look one bit less like a Tor user, I can
promise you that.
Furthermore, if UA Switcher it had real malcode in it, it would have
been found by now. It is an extremely simple and seldom-updated addon
whose code is public and open source, and it has been tested to work
just fine with Torbutton. I am committed to fixing any
interoperability bugs that turn up with it or any other addons.
If update authentication failure or a.m.o tampering is your real
concern, perhaps someone in the community here can review and sign
Chris Pederick's releases, and/or request that he sign them as well.
That said, I do realize Torbutton's user agent string is in need of an
update, but I've wanted to avoid doing that when there are actual
privacy attacks that apply to the Torbutton versions before the
switch. Perhaps the next release will update us to the latest Firefox
3.5 Windows release.

@_date: 2010-02-14 18:18:18
@_author: Mike Perry 
@_subject: Path-spec - fast circuits 
Thus spake Nick Mathewson (nickm at freehaven.net):
Ok, I've gone ahead and fixed both the spec and the code in
mikeperry/consensus-bw-weights4 in my git repo.

@_date: 2010-02-18 17:44:30
@_author: Mike Perry 
@_subject: Path-spec - fast circuits 
Thus spake ilter y?ksel (ilteryuksel at gmail.com):
No, you can only select 'Dual' flagged exit nodes (Exit+Guard) for the
guard position. Hence it doesn't make sense to have a Wge weight.
In normal operation, Tor uses Guard nodes. If the user configured it
to use bridges, Tor behaves as if those bridges were its guard nodes.
If the user has specified a strict set of EntryNodes, Tor uses those
as if they were guard nodes.

@_date: 2010-02-20 19:28:25
@_author: Mike Perry 
@_subject: Prepaid Cell Data Plans (was: Mobile Tor stuff) 
Thus spake 7v5w7go9ub0o (7v5w7go9ub0o at gmail.com):
FYI, things are starting to open up as far as getting pseudonymous
access to these networks as well. I've actually done a lot of research
into this area recently, and the findings are rather promising.
Virgin Mobile has a rather nice USB dongle that will get you 4Mbit
down/1Mbit up, and it works right out of the box on Linux with modern
versions of NetworkManager (though I think you need to add $$ to the
device via a Windows or Mac machine first):
Little pricey for the data, but if you just buy a $10 card and hold on
to it, it can come in extremely handy in emergency situations where
you really need network access and can't find any wifi. Should be
quick enough to use skype, too.
Also, both AT&T and T-mobile now offer prepaid data plans that you can
walk into any store and buy with cash, though you have to know what to
ask for. Both have old-style prepaid plans that are not possible to
get with data, and new-style ones that can get data. Often their sales
people don't know about the new data plans, and can forget to properly
add data to your account, but you can do that yourself later by
logging in to your account via the web (via Tor of course :), if you
buy the right plan to start with.
T-Mobile has 3 prepaid plans: "Pay as you go", "Pay by the day", and
"Flexpay". The first two are garbage and cannot have data service. The
flexpay, however, actually comes with *unlimited* data access and tons
of minutes for $60/mo, and is refillable by cards you can buy in any
grocery store (or via prepaid credit cards):
I believe you can actually even get a cheaper flexpay plan and add
unlimited data as a $10 or $15 option. Great for use with an open
firmware and usb tethering!
Or, if you prefer to send all of your data to the NSA[1,2], AT&T now has
"GoPhone" prepaid plans that you can add data as a $5/1MB or $20/100MB
option. Obviously not as great of a deal as the T-Mobile plan, but
useful if your phone does not have the T-Mobile 3G bands (like the
iPhone). Note that most android phones do NOT have AT&T 3G bands yet,
but the Nexus One does have the hardware for these bands, and Google
has applied to the FCC for their use:
I think several other carriers are also offering prepaid data, but
most of those are non-GSM and non-SIM card based, so you can't really
use some of the more flexible smartphones like the android or the
Anyways, I thought I should report on all this research. I've been
waiting so long for the day when I could walk into a store, give
someone some money (hell, any amount!) and get data access. You have
no idea how many times I've walked into stores prior to this year and
tried to give someone a bunch of cash, only to have them tell me my
money was no good there because I wouldn't let them xerox my ID, run
my SSN and sign a contract.
Apparently 17% of the US market has now gone prepaid, too. I guess I
wasn't the only one fed up with contracts and the "papers please!"
mentality of the major carriers:
Perhaps we've finally arrived at the turning of the tide?
1. 2.

@_date: 2010-02-21 01:02:52
@_author: Mike Perry 
@_subject: Prepaid Cell Data Plans (was: Mobile Tor stuff) 
Thus spake grarpamp (grarpamp at gmail.com):
Everything in my post I explicitly tested myself, with the exception of
skype over the virgin modem. Both AT&T and T-Mobile gave me SIM cards
with prepaid plans capable of data access with cash without a contract
or ID using the GoPhone and FlexPay plans, receptively.
No sketchyness was required here. They asked if I was paying in cash
or looking to open a contract, and I specified cash and that was it.
It might have had something to do with being in a major city, or maybe
it is up to the store manager's discretion to require contracts for
certain types of plans or features? At any rate, I had no trouble and
did not even need to explain privacy concerns or anything like that.
However, when I purchased a SIM for their pay-by-day/pay-as-you-go
plan, that manager first asks me for an ID. I looked at him
strangely and said "Why do I need an ID? I'm paying in cash" and he
said "Ok, just write your name and birthdate down and I'll create your
account." Little did I know that this SIM card could not get any sort
of data plan added to it.
So maybe it has something to do with attitude and the expectation of
the salesperson/manager in addition to your own expectations? I also
didn't have my phone on me and was very confident technically about
the fact that I should just be able to buy a SIM and put it in my
phone later without hassle, perhaps that helped?
But these sorts of social subtleties are well beyond me, though. Maybe
they were able to sense that I've been so desensitized by all these
demands from me over the years that I really didn't care any more if
they would take my money or not? :)
Yeah, it's really sad that Virgin is CDMA-only. Or rather, given that
GSM security is totally broken[1], and GSM's TDMA modulation scheme is
horribly inefficient, it's really sad that the best smartphones are
GSM and not CDMA.
Prior to my experiences with T-Mobile and AT&T, I'd been relying on
Virgin Mobile. They've been the most straight forward carrier by far
in this regard. Basically everything about my experience with Virgin
in general has been as painless as possible, which has really
surprised me. In fact, as far as I know, Virgin was the first carrier
to allow you to actually disable location reporting for non-911 calls
via the phone UI. While I obviously don't trust that this can't be
overridden or actively triangulated anyway, it's at least nice to know
that precise location isn't being passively volunteered for historical
1.

@_date: 2010-02-21 01:56:31
@_author: Mike Perry 
@_subject: Prepaid Cell Data Plans (was: Mobile Tor stuff) 
Thus spake Mike Perry (mikeperry at fscked.org):
One other aspect of how these interactions happened was that I asked
to buy a GoPhone/FlexPay SIM, got the sales person to go through the
process of creating the account, and THEN produced the cash instead of
credit card + ID. This may have had something to do with increasing
their willingness to finsih the sale: they would have had to have
cancelled the whole deal just because I didn't have my ID on me and
didn't want to do a credit check for no reason...

@_date: 2010-01-21 14:09:42
@_author: Mike Perry 
@_subject: Tor Project infrastructure updates in response to security breach 
Thus spake Paolo Palmieri (palmaway at gmx.it):
Just as in the Tor repo, I gpg sign the Torbutton git tags. I also gpg
sign .xpis, but have been sloppy about posting them publicly.
As for actual Firefox-compatible builtin xpi signatures, the last time
I looked into those they were exceedingly complicated and needed a
special Code Signing Certificate, which required me bending over and
paying Verisign or some other SSL Mafia Member a lot of money
($200-500/yr) to examine my rectum for a while. Maybe the Tor Project
can get one of these for me, but I am not certain its really worth it.
I suppose I could also create a rogue code signing certificate and
provide that over SSL for people to install, but then I wonder if
vanilla Firefox will reject my XPIs then because they are signed, but
with an "invalid" cert.
For now, I think the right answer is "Fetch it over SSL" or "Check the
git/gpg sig".

@_date: 2010-01-22 12:58:11
@_author: Mike Perry 
@_subject: Tor Project infrastructure updates in response to security breach 
Thus spake Paolo Palmieri (palmaway at gmx.it):
You're right. I was considering addons.mozilla.org as the canonical
source of the xpi, but still, that can be owned too. In fact, I just
got a message from them informing me that they modified my torbutton
1.2.3 xpi to prevent it from being listed as compatible with FF3.6. So
they see fit to randomly modify the xpis too. Wonder what would happen
if I did have a code signing cert..
I've posted the gpg sigs for 1.2.2, 1.2.3 and 1.2.4 at:
No. The git:// protocol is not protected. You need to rely on the tag

@_date: 2010-01-28 13:04:50
@_author: Mike Perry 
@_subject: browser fingerprinting - panopticlick 
Thus spake coderman (coderman at gmail.com):
FYI, Torbutton has defended against many of these anonymity set
reduction attacks for years, despite how EFFs site may make it appear
 (
But I'm glad the EFF is raising attention to this detail. I just wish
they also pointed people at to refresh their memories on that too.
After all, in normal operation, your history leaks one fuckload of a
lot of bits. And that's a technical term. Sensitive ones too, like
what diseases and genetic conditions you may have (via Google Health
url history, or Wikipedia url history). It's pretty annoying that the
browser makers really have no plan to do anything about that massive
privacy leak.

@_date: 2010-01-28 14:33:47
@_author: Mike Perry 
@_subject: browser fingerprinting - panopticlick 
Thus spake Seth David Schoen (schoen at eff.org):
Ah yeah. I didn't see that at all. You should be linking to the
sentence subjects instead of "here" :). The modern versions phrase
could be changed to "Torbutton 1.2.0 and above" and still be correct,
but I actually didn't notice that page at all.
I also think the "Your browser fingerprint appears to be unique among
the N tested so far" string could be perhaps increased in size or also
have the number bolded too.
As an aside, since there are already some questions in  and
 I want to point out that Torbutton's obfuscation features
are only intended to make you appear uniform amongst other Tor users.
Tor users already stick out like a sore thumb because of using exit
IPs, and the small numbers relative to the rest of your vistor base
will make Torbutton's obfuscated settings appear very unique compared
to regular visitors.

@_date: 2010-01-30 17:21:02
@_author: Mike Perry 
@_subject: browser fingerprinting - panopticlick 
Thus spake 7v5w7go9ub0o (7v5w7go9ub0o at gmail.com):
That's not 100% correct. A superset of SafeHistory and SafeCache's
protections are in Torbutton in that Torbutton does not allow ANY
visited links to be displayed as visited and it clears the cache on
every toggle, and by default allows only memory caching.
However, SafeHistory and SafeCache were more intelligent in how they
operated for normal browsing. They used "same origin policy" rules
( for deciding when to
display links as visited and when to allow caching for certain page
elements. The idea was to prevent elements from doubleclick.net and
other randomly sourced domains from determining arbitrarily which
sites you visited, and from storing cross-domain unique identifiers
(of course now there's DOM storage for that...).
The reason why Torbutton didn't opt for the same origin policy method
is because Tor exit nodes can impersonate any non-https origin they
choose, and query your history or store global cache identifiers that
way. It was basically all or nothing for us.
But yes, it would be nice if Colin Jackson and company kept
SafeHistory and SafeCache updated for regular users. Sadly they seem
to have forgotten about it. I wonder if anyone will make a fork and
update it.

@_date: 2010-07-15 00:21:07
@_author: Mike Perry 
@_subject: Torbutton Documentation - Adversary Capabilities. 
Thus spake Matthew (pumpkin at cotse.net):
If you are also restarting the browser, or closing all windows, you
are probably safe from most direct javascript attack vectors. The main
danger is in leaving pages open after changing proxy settings. Then
direct unmasking is possible. Identifiers can be stored in the page
javascript itself.
However, Javascript still has quite a bit of ability to fingerprint you
based on your desktop resolution, user agent, timezone, any many other
things. Torbutton does a good job of blocking a lot of the
fingerprintable attributes, which make it hard to correlate your
non-tor browser fingerprint to your tor browser fingerprint. More work
still needs to be done here, but we do handle quite a bit of the major
fingerprinting sources.
See also:

@_date: 2010-07-18 06:12:00
@_author: Mike Perry 
@_subject: Problem with Torbutton on OS-X PowerPC 
torbutton-logger.js is the Torbutton message log system.  It is used
for development and debugging.  Normally it shouldn't even be active. Based on this message and your previous one, its possible you have
somehow changed it to report way more than it should. If you check the
"about:config" url, and enter a search string of loglevel you should
see the value "extensions.torbutton.loglevel." If it is set to a value
other than 4, you should reset it, and probably also go into your
Torbutton settings and click "Restore Defaults".
Thus spake bao song (michaelwprx at yahoo.com.au):

@_date: 2010-06-22 17:34:15
@_author: Mike Perry 
@_subject: Automated threat messages force limitation of Exit Policy (Softlayer) 
Thus spake Moritz Bartl (tor at wiredwings.com):
Out of curiosity, what exit policy are you now using? Perhaps we want
to standardize on a policy that is effective at reducing these
I'm not a lawyer, but as a common carrier/service provider, you should
be specifically exempt from these noticies, as you're not hosting
content and are not the infringing party.
If you've filed the counternotice, maybe suggest your ISP just blackhole
future mails from the abuse sender? Did they SWIP you the IP block?
Back in 2005, the EFF was actively looking for a test case to
demonstrate that Tor exit nodes and other service providers are exempt
via safe harbor provisions:
As far as I know, they never got their test case.
We can check to see if they are still looking for one, and what it
might take for your situation to develop into a good test case for
them. The abuse senders may actually have to initiate legal action
against you first, which is unlikely. Being able to tell your ISP
that the EFF will defend you in this unlikely situation might also
help your position with them.

@_date: 2010-06-26 18:00:11
@_author: Mike Perry 
@_subject: Automated threat messages force limitation of Exit Policy (Softlayer) 
Thus spake Moritz Bartl (tor at wiredwings.com):
Can you post a copy of your counter-notification? Did they say in
specific why they believe it doesn't meet the requirements?
Also, are you familiar with chillingeffects? They catalog DMCA-related
correspondence and provide some legal FAQs for counter-notice
This is the section that should be relevant:

@_date: 2010-06-27 19:36:16
@_author: Mike Perry 
@_subject: Automated threat messages force limitation of Exit Policy (Softlayer) 
Thus spake Moritz Bartl (tor at wiredwings.com):
Please get back to us in a week or so with info on your abuse
complaint rate with the new policy. I'll update
with the policy if it does in fact drastically reduce your abuse
complaint raint.
(Though I suspect the SWIP will also help greatly. I am beginning to
believe that these abuse-bot companies deliberately pick on new
hosters who do not have their own IP allocation specified to bully
them off the net).

@_date: 2010-06-30 04:25:56
@_author: Mike Perry 
@_subject: Automated threat messages force limitation of Exit Policy (Softlayer) 
Thus spake Moritz Bartl (tor at wiredwings.com):
Ok, I've updated
with this information. Let me know if there is anything else you think
might be helpful, too.
A blog would be great. Another option besides publishing the actual
complaints would be to draft template response letters for various
cases and publish those. I'm sure other potential exit operators would
greatly benefit from such a collection, and it would be a great thing
to link to in that post.

@_date: 2010-06-12 13:28:03
@_author: Mike Perry 
@_subject: Hidden Services Hosting and DMCA 
Thus spake Moritz Bartl (tor at wiredwings.com):
Actually, the uptime problem is a rather good reason not to
consolidate hidden services with your exit node. An anonymous user on
the I2P network used to run a public intersection attack on I2P router
uptime vs eepsite (hidden service) uptime. It was rather easy to
correlate which I2P nodes were running which services with this data.
Of course, running hidden services in a separate VM might not have the
correlation that using the same Tor process will, but host OS
downtimes will still be correlated. If it is known that you are a
large provider of hidden services, it becomes useful for an adversary
to closely monitor your host OS for downtime to correlate to downtime
of hidden services.
As a related point, you need to be very careful about your opsec when
providing services like this. While US law protects you from
incriminating yourself by revealing your own encryption keys
(probably), it does not protect you from divulging encryption keys of
your users if you have them, nor does it protect you from court orders
requiring you to install monitoring software into your user's systems
to see what they are doing.
Add in the correlation properties for hidden services or other data
that may be available due to knowledge of your hosting setup (think
apache+php versions, etc), and there may be a sufficient level of
cause for such court orders to be binding.
Of course, you can try to simply ignore these orders due to the fact
that you're German and they're not likely to extradite you over them,
but you'll probably lose your server, and you might have trouble
entering the US at a later date then.

@_date: 2010-06-19 04:04:50
@_author: Mike Perry 
@_subject: Downloading attachments with Tor - is this secure? 
Thus spake Matthew (pumpkin at cotse.net):
Yes, if you use Torbutton, the attachment itself will be downloaded
only via Tor.
If you do not use Torbutton, your browser may autolaunch a plugin or
helper application to download the attachment and display it, which
may *not* happen via Tor. See
 for
example exploits against non-Torbutton users.
Also, when you open your attachment after downloading it (either via
Tor or not), the program that opens it may be induced into making a
network connection outside of Tor. For example, .doc files, .pdf
files, .torrent files, and many many others can reference images,
urls, IP addresses, and other content from the Internet, which causes
the application that opened them to connect to a server outside of
This is especially dangerous if you are using Yahoo Mail, because even
if you trust the person who sent you the document, your attachment
will be downloaded in plaintext (via http, not https). This means that
the exit node you use can replace or alter your document to unmask
you (or worse, exploit your document reader and run arbitrary code).
If you need to view these documents in a safe way, your best bet is to
use VirtualBox or some other virtualization software to run a VM that
you can disconnect from the network while you view the file, and roll
back to a safe snapshot after you have viewed the file.
Torbutton has a warning to attempt to explain all of this when you
download documents handled by external applications, but it is a lot
to get across in such a small amount of space.

@_date: 2010-03-01 12:18:13
@_author: Mike Perry 
@_subject: Path-spec - fast circuits 
Thus spake ilter y?ksel (ilteryuksel at gmail.com):
Wgm exists for bridges, which don't have the Guard flag.
No, the proper way to handle this is to tune our algorithms that hand
out the Guard flag to ensure that Guards are always plentiful. These
algorithms are centralized and run on the directory authorities.
Not yet. I have verified that the formulas produce balanced results,
and that my solutions do satisfy the system of equations. I plan on
doing selection tests once the system is deployed to verify that
clients are actually performing selection at the rates specified by
the weights.
Large scale simulations are hard to do. Ideally the academic groups
that work on Tor in various universities could pool their efforts and
maintain a common reference Tor Testing Network. It seems like every
researcher is always making their own small Tor network of various
sizes and load..

@_date: 2010-03-27 03:44:55
@_author: Mike Perry 
@_subject: Tor Browser Bundle for GNU/Linux 1.0.0 Released 
Thus spake Erinn Clark (erinn at torproject.org):
I want to point out that this is the first bundle we are shipping with
NoScript and BetterPrivacy. We've decided to attempt this as a trial
in Linux TBB for a few reasons. After the remote font exploit of
Firefox 3.6 and the apparent ~2 month delay between exploit code and
fix, we've come to the conclusion that we need to do a bit more to
protect our users against Firefox 0day being held by the underground
and aboveground exploit markets. See:
We also want to provide at least some way for people to view YouTube
videos and other flash content without completely sacrificing their
privacy and anonymity while viewing all websites. Our plan is to make
it so that people who insist on viewing flash content can simply
uncheck "Disable plugins for Tor usage", and only be at risk when they
actually decide to load a plugin (possibly GnashPlayer) by clicking on
its NoScript Placeholder. Basically, we would like to replace this
long FAQ entry with a much simpler one that still has an appropriate
warning: In addition, we've decided to try to deploy a list of popular sites
that have insecure https functionality that can be secured by
NoScript. Right now, we are attempting to secure *twitter.com
*facebook.com blog.torproject.org  docs.google.com
addons.mozilla.org  We are open to any suggestions
for additions to this list, and what we might do about any problems
that arise.
The Noscript config shipped with the bundle has the following
additional general properties:
1. It disables the redirect to noscript.net on updates.
2. It simplifies the context menu down to just enable/disable javascript 3. It sets Javascript to be enabled by default.
4. It replaces most common media types and plugins with placeholders
We're open to any suggestions or comments about this approach. I am
also discussing usability issues with Giorgio to try to help make
NoScript a bit easier to use in general.

@_date: 2010-03-27 15:14:05
@_author: Mike Perry 
@_subject: Tor Browser Bundle for GNU/Linux 1.0.0 Released 
Thus spake coderman (coderman at gmail.com):
Yeah, this will make a fine addition to the beta TBB builds once it is
released. We will need help seeding it and the NoScript list most
Also, for those of you who want to try the NoScript config without
downloading the whole bundle, you can import it here:
Note that a couple bugs have been fixed for config importing in the noscript devel versions. You may want to consider using those too:

@_date: 2010-03-29 17:08:21
@_author: Mike Perry 
@_subject: google gears 
Thus spake M (moeedsalam at gmail.com):
Google Gears has not been fully audited for anonymity, so we don't yet
know the specific answer to this, but the outlook isn't good. Gears
components can store arbitrary data from websites, and the current
Gears implementation does NOT obey "private browsing mode" in either
Firefox or Chrome to conceal gears data. Gears data is also not
cleared when you "clear private data" in either browser.
I believe it does use Firefox's network stack, so proxy settings
should most likely be obeyed.
However, it is possible it can phone home to update its component
cache or to ping your gears websites at any time, regardless of your
current Tor mode.
It is also likely that gears data can be transfered over http as
opposed to https, which would mean that any exit node can spoof google
gears urls and probe your installation for gears data, which may
include authentication information or unique identifiers.
Risky business. I would recommend against it unless you're prepared to
audit it with wireshark first. If you do, please report back!

@_date: 2010-03-30 16:21:36
@_author: Mike Perry 
@_subject: Google Summer Of Code - Orbot 
Thus spake Kobe, Fan YANG (kobeyoung81 at gmail.com):
This is a great place to ask us about this sort of thing. Perhaps even
better is or-dev at freehaven.net, and we'd love someone to work on
Orbot for GSoC.
The Orbot bug tracker is at:
 and
has some items to be worked on. Otherwise you should perhaps directly
talk to Nathan (n8fr8 on  on irc.oftc.net), the current orbot
developer about what might make a good GSoC project. I've CC'd him.

@_date: 2010-05-03 00:37:05
@_author: Mike Perry 
@_subject: Tor configs 
These are controlled by Torbutton's Preferences->Security
Settings->Headers->"Don't send referer during Tor usage" option, which
sets the appropriate Firefox settings.
Thus spake zzzjethro666 at email2me.net (zzzjethro666 at email2me.net):

@_date: 2010-05-03 00:48:06
@_author: Mike Perry 
@_subject: circuit construction timeout values 
Thus spake Scott Bennett (bennett at cs.niu.edu):
Hi Scott. There are a couple bugs in the algorithm used. One of the
problems is that the Xm pareto value needs to be chosen a bit more
intelligently to deal with samples coming from multiple guards. The
other problem is that "synthetic" timeouts need to be clipped to a
lower value.
The algorithm is defined at
(don't you love our nice, short, easy-to-understand-and-predict gitweb urls? ;)
The bug to track this is at:
If you could upload the state file from that Tor to that ticket (after
stripping out the EntryGuard info), that would give me another
datapoint to test against, and to ensure that these are in fact the
problems you are seeing. Even 65 is a bit high for a circuit timeout,
so I suspect you are actually seeing both issues here.

@_date: 2010-05-25 19:52:09
@_author: Mike Perry 
@_subject: Tor Exit Node hosting: torservers.net 
Thus spake Moritz Bartl (tor at wiredwings.com):
Hi Moritz,
I for one thing this is a great idea. I also welcome and encourage
others to step up and try to start similar projects, once we have a
good pattern down for a model that seems to work.
However, a common problem with donation-run projects like this (and
non-profits in general) is that everyone expects that the project will
succeed because someone else will jump in before them and fund it/save
it. Economists often call this the free-rider problem, but I think it
is more closely related to "Diffusion of Responsibility":
Because of these fundamental aspects of human nature, I think it is
very important to set goals such as: "We will not start or maintain
this project at the target level until/unless we have X months of
future funding", where X is around 3 months initially, and ideally
6-12 months or more long term. I think its also very important for people to see what their level of
dollar contribution gets them in terms of a percentage slice of exit
bandwidth for the Tor network. At the volumes you will likely be
purchasing bandwidth at, this is likely to be a very very compelling
This financial data should be very public on your website. If the
account balance ever drops below the level that can support roughly
this many months of service, you should renegotiate your contract with
your ISP to a level of service that you can support, and begin
clamoring for more funding.
Without this level of public accounting and public announcement of
financial requirements, I imagine most people are just going to look
at your site and assume "Well, that's nice. Best of luck, hope it works
out for you!" and move on. I know, because that thought has been in
the back of my mind (although I already spend quite a bit of my
paycheck to support Tor-related infrastructure, so perhaps I
am justified :).
If instead it's clear to people that if they just donate that $10,
$50, or $200, that it will make a significant impact to your service
staying online for X amount of time with Y amount of additional
capacity, they are way more likely to step forward.
For what it's worth, the optimal one-time donation amount to
request for addons.mozilla.org addons has been statistically
determined to be $10. I'm not sure if the same
psychological/political/financial dynamics will apply here, though.
Your optimal requested donation amount may be higher or lower,
depending upon the impact people believe they will have with that
money, and any additional economies of scale you can present to them
for donating more/reaching a higher level of total funding.

@_date: 2010-05-25 20:48:19
@_author: Mike Perry 
@_subject: Tor Exit Node hosting: torservers.net 
Thus spake Moritz Bartl (tor at wiredwings.com):
The problem is that the Tor developers really don't know - they
primarily write software rather than practice law :). Andrew and the
Tor Board of Directors typically need to discuss these issues with
actual lawyers.
One of the sticky issues with trademark protection though is that if
you do not defend your mark in all applicable cases, you lose the
right to defend it in cases you actually do care about. So please do
not take any decisions about your use personally.

@_date: 2010-05-03 00:48:06
@_author: Mike Perry 
@_subject: circuit construction timeout values 
Thus spake Scott Bennett (bennett at cs.niu.edu):
Hi Scott. There are a couple bugs in the algorithm used. One of the
problems is that the Xm pareto value needs to be chosen a bit more
intelligently to deal with samples coming from multiple guards. The
other problem is that "synthetic" timeouts need to be clipped to a
lower value.
The algorithm is defined at
(don't you love our nice, short, easy-to-understand-and-predict gitweb urls? ;)
The bug to track this is at:
If you could upload the state file from that Tor to that ticket (after
stripping out the EntryGuard info), that would give me another
datapoint to test against, and to ensure that these are in fact the
problems you are seeing. Even 65 is a bit high for a circuit timeout,
so I suspect you are actually seeing both issues here.

@_date: 2010-05-25 21:11:11
@_author: Mike Perry 
@_subject: Tor Exit Node hosting: torservers.net 
Cool Story, bro.
Thus spake Scott Bennett (bennett at cs.niu.edu):

@_date: 2010-05-27 19:34:01
@_author: Mike Perry 
@_subject: HTTPS Everywhere Firefox addon 
Peter Eckersley of the EFF and I wrote this addon this past week
to make it easier to use Google's SSL search feature, among other
mixed-mode SSL sites:
The addon is based on the NoScript STS/HTTPS forcing engine, with
improvements in how rules are specified. Rules for our addon are
specified as XML files that allow arbitrary URL rewrite substitution
via regular expressions and exclude patterns. This allows us to write
more complete and less error-prone rules than NoScript's
include/exclude model allows.
The eventual idea is to allow an Adblock Plus style model, where users
can submit and exchange rule files and eventually create subscriptions
for the sites they use that partially support SSL.
We also hope that NoScript will share our rule format and update
mechanisms, so that our rulesets will be interchangeable.
Please give it a try and give us feedback. We also will be including
the addon in the next alpha release of the Tor Browser Bundle.

@_date: 2010-05-27 21:07:42
@_author: Mike Perry 
@_subject: HTTPS Everywhere Firefox addon 
Thus spake Jon Cosby (jon at jcosby.com):
The rule files exist in two locations - the addon installed set, and
the user installed set. The addon installed set are in your Firefox
profile directory under the following path:
./extensions/https-everywhere at eff.org/chrome/content/rules
User supplied files live in ./HTTPSEverywhereUserRules/ in the Firefox
profile directory.
We plan to have some form of UI to automatically install filters to
the user directory from the web, similar to the Adblock Plus
subscription list.
In the meantime, we'll gladly accept submissions as xml files for
inclusion in the extension itself.

@_date: 2010-05-28 16:41:08
@_author: Mike Perry 
@_subject: HTTPS Everywhere Firefox addon 
Thus spake Runa A. Sandvik (runa.sandvik at gmail.com):
Yeah, this addon doesn't have a UI. It was a research implementation
of the server-specified STS protocol (and the original source of this
idea), which allows servers to specify the browser use HTTPS for
certain paths. Our code is based on the NoScript implementation of
STS, which was also amenable to creating rules.

@_date: 2010-05-28 16:41:32
@_author: Mike Perry 
@_subject: HTTPS Everywhere Firefox addon 
Thus spake Erik de Castro Lopo (mle+tools at mega-nerd.com):
Added. I hope these have been tested ;)

@_date: 2010-05-08 11:47:45
@_author: Mike Perry 
@_subject: Running a stable exit node without interference (Was blutmagie quad core upgrade) 
Thus spake M (maillist at piirakka.com):
We've thought about this too:

@_date: 2010-05-08 15:24:37
@_author: Mike Perry 
@_subject: opening up (exit policy) a bit ... 
Thus spake John Case (case at SDF.LONESTAR.ORG):
As of Tor 0.2.2.11-alpha, the ratios used by clients is listed in the
consensus[1]*. See sections 3.2 and 3.4.3 of dir-spec.txt
You have, sort of. Because you do not exit to enough ports to get the
'Exit' flag, you will be treated as a middle or Guard-only node,
depending upon your uptime. This means the following weights will
apply to you in each of the three positions:
Guard: Wgg (if you are a Guard, otherwise 0)
Middle: Wmg (if you are a Guard, otherwise Wmm)
Exit: Weg (if you are a Guard, otherwise Wem)
In the current weight implementation we
"Handle bridges and strange exit policies:
     Wgm=Wgg, Wem=Wee, Weg=Wed"
This means that your non-Exit flagged node will be weighted like an
Exit flagged node for the exit position, but will be weighted as if
you were a non-scarce middle or guard node for the other positions.
In sort, you would in theory get slightly more total load than if you
were an actual Exit.
As to the ratio of your exit to non-exit load, that depends heavily on
if you have the Guard flag, if you are a Directory Mirror, what
percentage of the exit traffic actually flows over port 80, and how
many clients have upgraded to the new algorithm vs the old.
*[1]. If there is a bug or other issue, these weights may be
temporarily absent from the consensus. Currently, Bug 1294 is causing
us to drop weights when there are no Guard+Exit flagged nodes, which
can happen when Exits are scarce. When weights are absent, clients
fall back to the previous client-based weighting algorithm. By not
having an actual 'Exit' flag, you will be treated as a non-scarce
Guard or middle node for purposes of this old algorithm too, and
should see more load accordingly.

@_date: 2010-05-08 15:36:40
@_author: Mike Perry 
@_subject: opening up (exit policy) a bit ... 
Thus spake Mike Perry (mikeperry at fscked.org):
On second thought, this is not fully correct. You will in theory get
slightly more load than if you were just a Guard/Middle node. Since we
do not currently balance among different exit port classes, you might
still get less load than a full-on Exit when Exits are scarce, because
80 might not carry that much traffic in terms of bytes as other ports.
Not an easy question to answer in either case. Having good answers to
these questions might help us refine our load balancing algoriths

@_date: 2010-05-08 16:41:40
@_author: Mike Perry 
@_subject: opening up (exit policy) a bit ... 
Thus spake John Case (case at SDF.LONESTAR.ORG):
Yes. Though this brings up the other approxmiation of the load
balancing algorithms, which is that we balance per-connection, which
have non-uniform bandwidth use across ports and protocols. According
to 92.5% of the connections through Tor are HTTP, accounting for 58% of
the traffic.
So you should see a much larger number of TCP connections (and
possibly also total traffic) as comparted to if you also added port
443 and/or 6667 to gain the Exit flag. Especially if you are a Guard.
The extra data that we would need beyond that published in the paper
above is a data rate per connection by port, in addition to connection
duration information. Gathering this data in a safe fashion, and
figuring out how to use it are open questions (though probably not
terribly difficult ones).

@_date: 2010-05-11 18:33:02
@_author: Mike Perry 
@_subject: Tor Exit Node Sponsorship - looking for partners 
Thus spake Timo Schoeler (timo.schoeler at riscworks.net):
The counterpoint is that scale really works in our favor the other
way, along a number of different fronts:
1. Bandwidth will be significantly cheaper in bulk
2. ISPs take larger customers more seriously
   A. This means you're much more likely to get SWIP/ARIN 'whois'
      allocation to better handle abuse complaints.
   B. The ISP be much more likely to tolerate the occasional abuse
      complaint that makes it back to them.
3. There probably really aren't that many super-friendly yet
   affordable ISPs to begin with.
I feel like all this means that the answer here is for us to try to
create as many consolidated exit nodes like Olaf's and Moritz's as we
can, rather than nickle and diming it with a lot of small time nodes
that aren't going to last very long because ISPs don't want to deal
with them.
In fact,  especially underscores this point, because really, what is
the point of creating 'n' small time nodes at one tor-friendly ISP?
Anyone interested in surveilling that traffic will just watch the ISPs
uplink either way..

@_date: 2010-11-28 17:54:04
@_author: Mike Perry 
@_subject: Active Attacks - Already in Progress? 
Thus spake Theodore Bagwell (toruser1 at imap.cc):
Unfortunately, Exit bandwidth is really hard to maintain if it is not
centralized, and all bandwidth is much much cheaper in bulk. It is
very hard to convince an ISP to put up with the noise, attacks, and
abuse complaints if you are a low budget node:
Rather than cripple the network by forcing more clients to use slower
nodes more often, we have opted to try to document the process of
running a high capacity Tor exit node:
We have to do the best with the situation we actually have. Trying to
force the network to route as if it were the network we *wish* we had
will only make it completely unusable. Please help us to create the network we *wish* we had.

@_date: 2010-10-13 14:55:11
@_author: Mike Perry 
@_subject: Tor network connections constantly building / failing 
Thus spake Joe Btfsplk (joebtfsplk at gmx.com):
Your ISP may be blocking connections to the Tor network. What type of
internet connection is this? Work/school/library/home? What country
are you in? Have you tried other networks/open wifi to see if you get
the same result?

@_date: 2010-10-15 14:44:59
@_author: Mike Perry 
@_subject: Ubuntu Privacy Remix 10.04r1 out 
Thus spake Eugen Leitl (eugen at leitl.org):
I suppose that's one way to address the problem of the network
adversary... Sure looks like this means this post has nothing to do
with Tor, though.

@_date: 2010-10-16 03:54:01
@_author: Mike Perry 
@_subject: Ubuntu Privacy Remix 10.04r1 out 
Thus spake Eugen Leitl (eugen at leitl.org):
There may be some overlap, but all of those people are doing it wrong.

@_date: 2010-10-27 16:41:57
@_author: Mike Perry 
@_subject: Hints and Tips for Whistleblowers - their comments on Tor and SSL - I don't understand. 
Thus spake Seth David Schoen (schoen at eff.org):
This is not true if the user is using Torbutton. See the paragraph
about security.enable_ssl2 in:
This hack causes us to clear all TLS session ID and resumption state.
It's bloody, but it works. Firefox has also created an official API
for us to do this the "right" way that we will begin using in 1.2.6:
Torbutton also has code to isolate custom stored client and server
certificates, but this code tends to crash Firefox because of
refcounting issues in the TLS cert manager, so it is disabled by
default. We're waiting on this bug to be fixed to enable it:
In other words, like we do with everything else, we have spent quite a
bit of effort in dealing with TLS privacy issues, and the
"Whistleblower howto" link in question is almost 100% nonsense that
the author seemingly made up on the spot based on incorrect
assumptions that they didn't bother to verify or investigate...

@_date: 2010-10-03 13:46:29
@_author: Mike Perry 
@_subject: Torbutton 1.3.0-alpha: Community Edition! 
Thus spake Drake Wilson (drake at begriffli.ch):
Doesn't your suspicion that baseline psychology will lead users to use
tor:// over torhttp:// given the opportunity to use either tell you
anything about which interface is more user friendly?
Heh, it turns out this has the same problem, at least with Pidgin.
tor still creates an http hyperlink that when clicked
on directly would be loaded outside of Tor.
httptor://link.com does not create a hyperlink, though.. Nor does
Perhaps the way we could specify this is that officially, the scheme
format is [scheme]+tor://site.com where if scheme is omitted, it
defaults to http. But then that still leaves tors as the bastard child
short-hand for https+tor://site.com. But I'm fine with bastard
children. Call me an unrepentant utilitarian, but 2 computer scientists refusing
to use a feature for a reason that 90% of our userbase won't even
understand doesn't strike me as a compelling reason to do anything.
However, patches from said 2 protesters might change my mind ;)

@_date: 2010-10-04 17:04:00
@_author: Mike Perry 
@_subject: Torbutton 1.3.0-alpha: Community Edition! 
Thus spake Drake Wilson (drake at begriffli.ch):
Well I think that specifying that urls are technically officially
supposed to be http+tor://, but that the http+ can be omitted gives us
the best of both worlds. These urls seem to be then treated mostly
correctly by dumb link parsers, because they will just become tor://
links if parsed, which would then work as normal.
The exception is that https+tor:// may then be treated as just a
tor:// url by a link parser, which effectively converts it into a
torrified http url, dropping vital ssl support. Hence, I think we
should also provide tors:// as an "unofficial" backup scheme for these
So no, your suggestion wasn't totally busted. It just required lots of
attempts to make it actually be practical. :)

@_date: 2010-10-07 10:27:21
@_author: Mike Perry 
@_subject: AdvTor 
Thus spake Anon Mus (my.green.lantern at googlemail.com):
That's an interesting list. It looks like you just took the top 20 fastest
exits and listed them.
Are you excluding these because of proven malicious activity; because
of poor connectivity; because they are banned from most sites; or just
because you needed a button to make your Internet as slow as possible,
and Tor seemed like the best choice?

@_date: 2010-10-01 18:51:07
@_author: Mike Perry 
@_subject: Torbutton 1.3.0-alpha: Community Edition! 
Thus spake David Bennett (dbennett455 at gmail.com):
This is not the case. The way the featur works is that Firefox
instantly converts the url to the real scheme after enabling Tor and
before loading the page.
This rears its head in a lot of other places. For example, try
emailing, IMing or posting these urls to google groups. If you specify
tor:// as the prefix, worst case the url is not converted to a
hyperlink, but best case it is, and the user can just click on it.
However, all places I have tried to specify tor+ the
 portion of the url is transformed into a hyperlink by
the software, but the "tor+" part is lost. This leaves room for user
error and also makes things inconvenient.
Intuition also tells me that tor:// and tors:// urls will be easier to
use, understand, and remember by the general public.. Can you give
some examples/reasons why just using these schemes actually prevents
us from doing this scheme layering idea for other protocols in the
future (when it is supported)? In otherwords, why can't we just do both?

@_date: 2010-10-09 14:07:29
@_author: Mike Perry 
@_subject: Are these torrc entries necessary? 
Thus spake Matthew (pumpkin at cotse.net):
If you run tor 0.2.2.17+, the CircuitBuildTimeout is now automatically
learned, and typically results in a value around 3-5s for broadband
The other options I think were hacks to try to help make this lower
hardcoded timeout value give you more benefit. I wouldn't use them
with the new code.

@_date: 2010-10-10 14:08:49
@_author: Mike Perry 
@_subject: 0.2.2.17 issue? 
Thus spake Udo van den Heuvel (udovdh at xs4all.nl):
Did you build from source, or are you using packages? If so, which

@_date: 2010-09-25 17:04:14
@_author: Mike Perry 
@_subject: The best way to run a hidden service: one or two computers? 
Thus spake coderman (coderman at gmail.com):
Is this really true? One of the things I've wondered about here is
plugins, but since Torbutton disables them for other reasons I haven't
really looked into it. For insance, I know Java can create a socket,
and query the interface properties of that socket to get the interface
IP. Why not mac address? And if not java, can one of flash,
silverlight, pdf-javascript, or others do this? Already we have
location features built in to the browser based on nearby Wifi MACs...
The Java trick to get the interface IP does not require special privs,
so a randomized MAC would in fact help this scenario, if it were
somehow possible.

@_date: 2010-09-25 17:39:26
@_author: Mike Perry 
@_subject: The best way to run a hidden service: one or two computers? 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
Hah, yah, I forgot the context of this thread was hidden service
threats. This thought popped into my head a day after reading
coderman's original post and thinking about securing plugins in
Google Chrome.
But yes, your statement about command injection is absolutely true. In
fact, in some cases commands that run may even be restricted by an
AppArmour or SELinux policy (if you run Ubuntu 10 or Centos 5), but an
attacker still could run some socket syscalls and commands with these
limited privs.

@_date: 2010-09-30 15:57:48
@_author: Mike Perry 
@_subject: Torbutton 1.3.0-alpha: Community Edition! 
"Release early and release often" is the motto, or so I'm told.. Well
I never liked getting up early, but maybe we can at least try for
often with this one. But probably not..
Despite these shortcomings of mine (among others), Torbutton
1.3.0-alpha is the first release of Torbutton where most of the code
has come from our community members! This is great, because after many long years of Torbutton development,
I barely have enough time and sanity remaining to maintain bugfixes on
1.2.x. Not that I started with very much of either in the first place,
I suppose[1]...
And with that, it gives me great pleasure to announce Torbutton
1.3.0-alpha! Due to limitations of addons.mozilla.org, the alpha
series will only be available at the Tor website:
This release features "tor://" and "tors://" urls that will
automatically enable Tor before loading the corresponding http or
https url. Useful for bookmarks of your tor sites, or sharing urls
with other Torbutton users to ensure that they load them safely
through Tor. It also features a cookie manager that attempts to allow
you to protect specific cookies that you want to preserve between Tor
modes, as well as intelligent referrer spoofing.
All three of these features were written by Kory Kirk, for his 2009
GSoC summer of code project. (What did I say about "early"?)
It also features support for a Transparent Proxy or Tor router (or
your regular connection), where Torbutton's protections can be enabled
without using any proxy. This feature was written by Jacob Appelbaum
and Kory Kirk.
These features should be regarded as *experimental*. In particular,
the cookie manager needs testing, to ensure that it is actually
properly protecting and deleting the right cookies, without leaking
them from state to state. Someone should also pay close attention to
the referrer behavior to ensure it is behaving sanely.
What little time I have for Torbutton development will be devoted to supporting Firefox 4, and trying to work through this neverending set
of bugs for 1.2.x: However, it would be great if we could drum up some more community
interest in developing these and other features, too. In particular, I
think it would be really swell if the cookie manager could be extended
into providing a "New Identity" button, complete with an optional
timer to run periodically. There's tons of other potential features
waiting to be implemented in the "Enhancements" section of that trac
report, too.
Here is the complete ChangeLog for 1.3.0-alpha:
 * new: Support for transparent proxies in settings
   (patch from Jacob Appelbaum and Kory Kirk)
 * new: tor:// and tors:// url support to auto-toggle into tor mode
   (patch from Kory Kirk)
 * new: Cookie manager to allow individual Cookie protection
   (patch from Kory Kirk)
 * new: Add referrer spoofing based on modified same origin policy
   (patch from Kory Kirk)
 * new: Add DuckDuckGo.com as a Google captcha redirect destination
   (patch from aiden tighe)
 * bugfix: bug 1911: Fix broken useragent locale string on debian
   (patch from lunar)
 * bugfix: Fix captcha detection for encrypted.google.com
[1].

@_date: 2010-09-07 01:53:31
@_author: Mike Perry 
@_subject: How does Gmail know my local time zone (therefore ignoring the time zone of the Tor exit node) and what else can it see? 
Thus spake Matthew (pumpkin at cotse.net):
Please actually use Torbutton instead of speculating about what
protections it provides, trying to compensate with ad-hoc homebrew
approaches, and then complaining to the list when the results aren't
what you expect.
Noscript can have all sorts of surprising results when you allow
javascript from other domains.
Javascript cannot unmask your IP. The attacks on decloak and elsewhere
are all about causing plugins and external applications to launch,
which NoScript does not protect against.

@_date: 2010-09-14 18:30:19
@_author: Mike Perry 
@_subject: Google Chrome Incognito Mode and Tor 
(I'm cross-posting to or-dev and or-talk. Please remove one of the Cc's
as appropriate, depending upon the nature of your reply.)
For the past couple months, I've been doing a lot of work reviewing
and summarizing the major issues remaining before we can safely write
a Tor Incognito Mode extension for Google Chrome. I've been using
this ticket group on trac to track my progress:
I've also written a prototype Chrome extension that is functionally
incomplete and unsafe to use, but could use some review by any
Javascript ninjas out there:
The work has also been summarized in this blog post:

@_date: 2011-04-01 13:53:21
@_author: Mike Perry 
@_subject: [tor-talk] [Bug 280661] SOCKS proxy server connection timeout 
Thus spake grarpamp (grarpamp at gmail.com):
Is this an April Fools joke?
Oh wait, it looks like it's for post-4.0. *phew*. We wouldn't want to
have to not fork Firefox. That would spoil all the Trademark-suit
PR-explosion fun we have planed!

@_date: 2011-04-02 23:06:44
@_author: Mike Perry 
@_subject: [tor-talk] Google disable web-access to gmail for Tor-users? 
Thus spake Joe Btfsplk (joebtfsplk at gmx.com):
This is possible. The "unusual activity" message is unrelated to
cookie issues, and appears to have something to do with the exit node
chosen to connect to gmail. You can be asked for an SMS confirmation
from one exit, and then hit "New Identity" and then not be asked on
the next. It must have something to do with either geolocation, or the
types of activity their systems see from particular exits that make
them think bots are involved.
In once case, it happened while I was using a pseudonym to contibute
to another open source project and ask questions on a mailinglist. I
was unable to get the message to go away with "New Identity" (possibly
because sending mail to a milinglist smells extra-spammy?), so I
clicked through the help links and filled out some form explaining my
desire for strong pseudonymity, and they lifted the block without a
cell TB is not actually blocking any cookies here. At least not on purpose.
The TB feature that is causing this issue is one that is designed to
minimize the number of Google captchas Tor users must solve to use
Google Search. We attempt to transfer the captcha-relaed cookies from
all international domains, but we ended up mangling some login cookies
after a change to how Google auth works. The issue is fixed in the
1.3.x series, but not in 1.2. The plan is to release 1.4.0 as the new
stable ASAP, rather than backport these fixes to 1.2.x.
Otherwise, Torbutton's default cookie policy is to allow cookies to
persist in memory until either the Torbutton is toggled, or the
browser exits. We plan to eventually extend this functionality to
provide a "New Identity" button in the browser, to synchronize the
clearing of all Firefox identifiers with the "New Identity"
functionality of Vidalia/Tor, but this requires some additional
integration work...

@_date: 2011-04-08 15:35:44
@_author: Mike Perry 
@_subject: [tor-talk] endless list of scrubbed circuits 
Thus spake Joe Btfsplk (joebtfsplk at gmx.com):
One of the things that can cause this is a set of bad guards (the
first hop in your Tor circuits). If you got unlucky and Tor picked
only slow guards, this can cause you poor performance.
You can check them out in the vidalia window by noting the first hop
in your circuits. There should only be 3 different nodes chosen for
that first hop. Note you should not post your guard list in public, as
it can be used to identify you.
If that is the issue, you can try using bridges to see if that helps,
or you could try to stop tor and wipe away your tor state file, which
will cause new guards to be chosen.

@_date: 2011-04-08 17:29:17
@_author: Mike Perry 
@_subject: [tor-talk] TB for Win 
Thus spake Greg Kalitnikoff (kalitnikoff at privatdemail.net):
So are we. FF4 offers a ton of awesomeness that we want to leverage.
For example, HTML5 allows youtube to work over Tor! (If you opt-in and
set your useragent right):
But it is a lot of work. Every new Firefox release requires a ton of
addon API updates and auditing, and FF4 was a beast of a release in
this respect. We've done the API updates (Torbutton 1.3.2-alpha) but
we still need to do more auditing.
We're also planning on changing our release structure for Firefox 4.
We will very likely be maintaining our own (hopefully small) set of
patches against Firefox 4 and shipping Tor Browser Bundle as our only
supported platform, and discouraging the advanced tor packages and
Torbutton+OS Firefox setups (and removing or unrecommending Torbutton
on addons.mozilla.org). This also means that we need to sink a bunch
of effort into making sure Tor Browser Bundle is a working solution
for people on every platform.
So we're not sure exactly when all of this will be ready, but we're
working as hard as we can to make it ASAP.

@_date: 2011-04-11 16:33:08
@_author: Mike Perry 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
In a random bar about two years ago, a Google Chrome dev asked me why
Torbutton didn't just launch a new, clean Firefox profile/instance to
deal with all of the tremendous state separation issues. Simply by
virtue of him asking me this question, I immediately realized how much
better off Chrome was by implementing Incognito Mode this way and how
much simpler it must have been for them overall (though they did
not/do not deal with anywhere near as many issues as Torbutton
So I took a deep breath, and explained how the original use model of
Torbutton and my initial ignorance at the size of the problem had lead
me through a series of incremental improvements to address the state
isolation issue one item at a time. Since the toggle model was present
at the beginning of this vision quest, it was present at the end.
I realized at that same instant that in hindsight, this decision was
monumentally stupid, and that I had been working harder, not smarter.
However, I thought then that since we had the toggle model built, we
might as well keep it: it allowed people to use their standard issue
Firefoxes easily and painlessly with Tor.
I now no longer believe even this much. I think we should completely
do away with the toggle model, as well as the entire idea of Torbutton
as a separate piece of user-facing software, and rely solely on the
Tor Browser Bundles, except perhaps with the addition of standalone
Tor+Vidalia binaries for use by experts and relay operators.
The Tor Browser Bundles would include Torbutton, but we would no
longer recommend that people use Torbutton without Tor Browser.
Torbutton will be removed from addons.mozilla.org, and the Torbutton
download page will clearly state that it is for experts only. If
serious unfixed security issues begin to accumulate against the toggle
model, we will stop providing Torbutton xpis at all.
I believe this must be done for a few reasons: some usability, some
technical. Since I feel the usability issues trump the technical
ones, I'll discuss them first.
Unfortunately, the Tor Project doesn't really have funding to conduct
official usability studies to help us make the best choice for this,
but I think that even without them, it is pretty clear that this is
what we must do to improve the status quo.
I think the average user is horribly confused by both the toggle model
and the need to install additional software into Firefox (or
conversely, the need to *also* install Tor software onto their
computers after they install Torbutton). I also think that the average
user is not likely to use this software safely. They are likely to log
in to sites over Tor that they shouldn't, forget which tor mode they
are in, and forget which mode certain tabs were opened under. These
are all nightmare situations for anonymity and privacy.
On the technical side, several factors are forcing us in the direction
of a short-term fork of Firefox. The over-arching issue is that the
set of bugfixes required to maintain the toggle model is a superset of
those required to maintain the Browser Model, and contains some rather
esoteric and complicated issues that are unlikely to ever get fixed.
See  for
both lists.
This means more resistance from Mozilla to get the Toggle Mode bugs
fixed or even merged, less likelihood they will be used elsewhere, and
more danger they will succumb to bitrot. Related to this, the lag time
for normal Firefox bugs between authorship and deployment can be as
long as 3 years (and counting). See for example:
The Tor Browser bugs on the other hand are more directly usable by
Firefox in its own Private Browsing Mode, which makes them more likely
to merge quicker, and be maintained long-term. Also, because we will
be releasing our own Firefox-based browser, we will also have more
control over experimenting with them and deploying these fixes to our
users rapidly, as opposed to waiting for the next Firefox release.
So, we can either invest effort in improving the UI of Torbutton to
better educate users to understand our particular rabbit-hole tunnel
vision of design choices, as well as solve crazier Firefox bugs; or we
can reconsider our user model and try to simplify our software.
We don't have the manpower (ie: enough me) to do both.
I think this means we should go with the simpler option. The reason I am discussing this in so much detail here is because I
believe there is a chance that there are users out there who rely on
the toggle model and/or their OS Firefox build, and may be confused or
enraged by the new model. I'm asking this list to get an idea of how
many of those users there are, and to try to understand what the
overall costs of this sort of migration are.
I also ask this because I am a heavy user of the toggle model myself,
and abandoning it is sort of a leap of faith for me, too.
So can anyone bring up any specific issues that may be caused by the
We are collecting these issues as child tickets of this bug:
As an aside, we also are collecting a similar set of issues for the
removal of an HTTP proxy entirely from the tor distribution:

@_date: 2011-04-11 23:18:02
@_author: Mike Perry 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
Thus spake Anders Andersson (pipatron at gmail.com):
Thankfully, we do. Erinn has managed to create bundles that appear to
work on every Linux distro we could test, but she is looking for
We do this by shipping all our major dependencies with the bundle.

@_date: 2011-04-11 23:26:03
@_author: Mike Perry 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
Thus spake Jim (Jimmymac at copper.net):
Hrm, your use case would be "Download the TBB, and then configure it
manually to use an alternate proxy." You'd still be downloading (and
running) and extra Tor and Vidalia instance, but we're hoping to make
that seamless:
Otherwise, you'd fall in this boat:
But we're really hoping not to have to build a standalone Tor Browser
outside of the Tor Browser Bundle, because it adds an entire column to
the matrix of builds we'd need to do.

@_date: 2011-04-12 03:44:10
@_author: Mike Perry 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
Thus spake tagnaq (tagnaq at gmail.com):
Yes, this option and other proxy options still be there. However, we
will want to prune out a lot of the security options, especially the
ones revolving around toggle-related state isolation, and make
everything simpler in the options pane.

@_date: 2011-04-12 05:49:05
@_author: Mike Perry 
@_subject: [tor-talk] TB for Win 
Thus spake Flamsmark (flamsmark at gmail.com):
They will be stand-alone packages. No deps, no provides.
This is a tricky subject. Since it has taken their lawyers more years
than the SOCKS bug has to even *answer* us on the subject, we're going
to do whatever the hell we think is best, and wait for them to move.
We don't anticipate it happening soon. Since this is meant to be a
short term fork (for them, probably medium for us), our bet is that
they won't even notice.
Right now, the thing is called Minefield, at least on Linux, because
that was most expedient. We probably need to use at least some of the
more visible Firefox graphics in the long run, though.  Remember, it
should have a chance of looking like a regular web browser from a
distance, at least. I think this means it must look as much like
Firefox as possible, and shouldn't say Tor, but yet should still be
obvious to the user that it is a different browser. My current thought it that this means it calls itself Firefox and uses
the Firefox graphics, but it has a green onion button on the toolbar,
next to the url, signifying Tor use. This may still be too conspicuous
for some users. In fact, a prefs.js issue is preventing the button
from being displayed right now on some platforms, but I think we
actually do want the button there.. Or do we?

@_date: 2011-04-12 06:07:59
@_author: Mike Perry 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
Thus spake intrigeri (intrigeri at boum.org):
I believe Erinn is making a dependency graph and intends on updating
TBB whenever one of the built-in dependencies updates in debian. I
think she even has dreams of a machine doing this for her, and kicking
off automated builds. (I hope she doesn't despise me for revealing the
secrets of her dreams.)
I would prefer it if we can unify our prefs.js use, but I guess you
guys may want to support more things. I think with effort you can even
get flash running safely under a default configuration...
What do you anticipate being the other substantial feature differences
that prevent you from just providing a stock TBB?
Hrmm.. I don't think this will be the case... System extensions seem a
bad idea to source by default.. In fact, we should ensure we do not do
this, due to the potential to source distro branding extensions that
damage anonymity...
Can we figure out a way to come close to a common set of extensions
and configs, so the set of extensions you must add to TBB is minimal?
Do you have a list of your extensions anywhere?
Yeah, it may be some round trips before we figure out new tickets.

@_date: 2011-04-12 06:15:41
@_author: Mike Perry 
@_subject: [tor-talk] TB for Win 
Thus spake Greg Kalitnikoff (kalitnikoff at privatdemail.net):
If by QtWeb, you mean QtWebkit, then the Tor Project has actually
offered to pay the developer of a Tor fork of the Qt Webkit front end:
But he is quite happy continuing on as a volunteer. If torora proves
as functional and private as a forked Firefox, then we'll have to make
decisions on speed and ease of maintainance. Right now, I think it
lacks as extensive auditing and as comprehensive a featureset though.
But it is definitely moving along!

@_date: 2011-04-12 18:53:38
@_author: Mike Perry 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
Thus spake Milton Scritsmier (ktr-theonionrouter at dea.spamcon.org):
Yeah, my question to the list is that "will this new UI model ruin
the hardcore user's day?" As I said, I think it's pretty clear that it's the right step for
normal users. They only have to click on one thing, and a browser
shows up. Perhaps the UI needs some smoothing and some hints/cues/info
after that point, but we're just talking about the macro issues of the
install/use model itself here.
Absolutely. We're actively tracking barriers to us supporting Google
And we're also interested in Robert Hogan's Torora work.
Right now, Firefox is actually our only option though. The amount of
work remaining on the other two options is significantly larger.
We realize that the more options we have, the better off we are. For
example, Chrome has several extremely compelling security properties
that Firefox lacks. It's just that the rest of what we need is not
there yet.

@_date: 2011-04-14 04:39:56
@_author: Mike Perry 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
Thus spake J?r?my Bobbio (lunar at debian.org):
The reality is we have quite a lot of issues with every distribution.
It is true that Debian gives us the least amount of hassle, though.  I
suspect this may just be because we're lucky enough to be so strongly
socially connected to it. Because, man is it a rickety, towering
bureaucracy otherwise ;).
If Debian as a whole is willing to take our patches, that's great. We
hope they'll be merged into Mozilla eventually, so it could be a good
testing ground.
I agree that the approach above could work. If Debian wants to conjure
an alternate package that is really just a shell script that just
launches an /etc/skel copied TBB Firefox profile, this sort of thing
should be possible and fairly straight-forward. We can talk about this
on IRC, I suppose. It likely won't be a priority on Tor's side,
though. Also, I think we messed around a bit with remoting (aka new
window launching) on TBB Firefox, which may cause odd behavior for
your use case, or maybe not.. Erinn and sjmurdoch can tell you the
details of this (or I may be able to fetch them out of my subconscious
Our current working-plan is to provide an external repo, like we've
been forced to do for Ubuntu for other reasons. This ticket is
supposed to list the barriers to that:
But hey, so far there are none! :)
The long-term plan is to make Thandy the update future for our
packages. It is hardened against a lot of attacks that OS updaters are
not hardened against. We designed it because we thought it was the
future for all Tor packages, and I think this means we should start
acting like it. I think providing our own distro repositories is an
intermediate step to self-flagellate ourselves into actually bringing
Thandy online.
As a last resort, could you replace torbutton with an empty package? I
can give you a replacement torbutton that refuses to toggle... Is this
against the debian social contract? :)
Right. I don't think that anyone is going to forget the value of
non-web communications. It's too built-in to the Internet and too
readily useful. However, the slightly more nuanced political realities
of this may make you sad:
Sure. That's what torsocks is for. It's a great Linux app, something
we dearly wished existed on Windows (and worked better on Mac OS).
I envision torsocks working with the system tor package, rather than
the TBB one. They should run on different ports:
The reason for this is that torsocks apps are poorly anonymized at the
application layer, and you don't want these to leak data (like your
username, hostname, etc) concurrent to your tor web traffic.  The
easiest way to prevent that right now is to use your distro's tor and
our TBB at the same time.
(The long term way is to implement SOCKS password support both in Tor
and in Firefox:
I still consider torsocks an expert app, though.
So, in summary: Chaos and upheaval! Your bureaucracy is doomed!
Prepare for the paper shortage!

@_date: 2011-04-14 15:47:05
@_author: Mike Perry 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
Thus spake sigi (tornode at cpunk.de):
Yeah, we don't have any intention to stop Tor+Vidalia packaging,
because relay operators and experts will have use for them. This
presumably extends to the distributions. Again, I see the system Tor
being used with torsocks, RSS readers, irc, etc. Basically all the
system apps you've rigged through Tor that we haven't audited. Again,
these system apps should not be sharing circuits with your web
activity for anonymity reasons.
We do want to drop the HTTP proxies like a bad habit though:
Both polipo and privoxy are really starting to get unsafe in their
unmaintained states..

@_date: 2011-08-07 00:41:03
@_author: Mike Perry 
@_subject: [tor-talk] reddit.com wants EFF to disable HTTPS??? 
Thus spake grarpamp (grarpamp at gmail.com):
Speaking as one of N authors of this addon**, my stance is:
"Lolwut? Sounds liek g8 PR 4 U. I tink u shud soo every1 U can!"*
* Note1: I have no direct affiliation with the EFF. I'm sure the official legal opinion on this matter is slightly more nuanced. I'm
guessing it balances on the fact that the EFF is acting as a publisher
of rules that others submit and does not exercise editorial control.
I've personally argued that the addon should provide an arbitary
subscription model to avoid editorial liability entirely, but
apprently this is not necessary?
** Note2: I do not review rules, and I did not write this particular
P.S. HTTPS-Everywhere seems to only ship with a subset of reddit rules
enforced by default. Is this the "wrong" subset? Why is is "our"
responsibility to determine the "right" subset? Can't u jis fix ur
shit, reddit?

@_date: 2011-08-07 00:50:14
@_author: Mike Perry 
@_subject: [tor-talk] reddit.com wants EFF to disable HTTPS??? 
Uh, woops. Checked my tor inbox before checking my main inbox. The
main issue appears to be debugging CDN support for HTTPS for all urls
rather than any particular opposition to allowing anonymous access to
encrypted content.
Sorry for the noise.
Thus spake Mike Perry (mikeperry at fscked.org):

@_date: 2011-08-08 11:06:58
@_author: Mike Perry 
@_subject: [tor-talk] Hijacking Advertising to give a Tor Exit node 
Thus spake Javier Bassi (javierbassi at gmail.com):
I do. I use Tor for purchasing things because I have a real problem with
my purchasing activities being strongly correlated, data-mined and
sold. I've experienced inappropriate and embarrassing
non-context-relevant ads, poorly targeted political spam (virtual and
physical), and other annoyances due to advertising attempting to
target ME as opposed to what I am DOING at the time.
The straw that broke my back was Amazon recommendations related to my
personal life that were visible to my manager at work who was sitting
next to me at my computer while we looked for tech books. Thankfully,
I think his own mental ad-filter caused him not to notice.
Still, I quickly canceled my Amazon account and requested they delete
all purchase history.
Flash forward several years to today: There are no physical bookstores
(other than those for used books) left in my city. My choices for new
books are now to either order the book from Amazon, get a digital copy
on an e-book reader (the use of which is subject to monitoring and
deletion), or pirate a copy.
I strongly believe that this indicates there must be a demand for a
model for privacy that allows private commerce and ad revenue, but
defangs the nasty properties of online advertising that I and others
have personally experienced..
However, all this talk about intercepting advertising and modifying
Tor traffic is pure insanity. To those studying it: you're wasting
your time and you're probably breaking US law. Once again: this is the
path to 'BadExit'.
The right way to do this will probably look more like the Mozilla
model: partnering with search providers who will pay us for users that
we drive to their sites. The unique hurdle Tor faces for deals like
this is how to ensure that actual users are behind the browser.
Revocation systems like Nymble could be one answer. Javascript proof
of work mechanisms could be another.
There is also a body of research attempting to devise ways to target
users in a privacy preserving way. For a recent example, see
However, most of these have problems with non-contextual targeting as
well as requiring local disk storage of browsing activity.

@_date: 2011-08-22 21:56:37
@_author: Mike Perry 
@_subject: [tor-talk] New HTTP authorization attack 
Thus spake tor at lists.grepular.com (tor at lists.grepular.com):
None of this is news.
FYI, Torbutton traditionally handled both HTTP auth and cache through
the toggle feature. I've since realized that the toggle model was
broken, and we've been trying to supplant it in the 2.2.x Tor Browser
Our first defense for TBB users is the "New Identity" feature, which
will appear in 1.4.1 of Torbutton*:
Depending on how things go, we may or may not isolate HTTP auth to a
urlbar domain in Torbutton 1.4.1, but it is also on the roadmap for TBB
* "New Identity" will only work on Tor Browser Bundles.

@_date: 2011-08-23 08:23:55
@_author: Mike Perry 
@_subject: [tor-talk] New HTTP authorization attack 
Thus spake tor at lists.grepular.com (tor at lists.grepular.com):
Did I mention I don't like the toggle model? I thought I did :)
I guess you could also argue that "New Identity" is a toggle-ish
For the general TBB solution, see:
It is in 1.4.0.
As I said in the blog posts, I intend to isolate all browser state to
urlbar domain, and/or disable whatever features aren't amenable to
this. So far this means that 3rd party cookies must be disabled and DOM
storage must be disabled. HTTP auth can be isolated similarly to cache. See: SSL certificates are not isolated. They might never be. The SSL stack
is a nightmare.

@_date: 2011-08-23 09:01:00
@_author: Mike Perry 
@_subject: [tor-talk] New HTTP authorization attack 
Thus spake tor at lists.grepular.com (tor at lists.grepular.com):
Depending on how things go, we may or may not isolate HTTP auth to a                                                             urlbar domain in Torbutton 1.4.1, but it is also on the roadmap for
TBB 2.2.x-stable:
Yes, but I don't think the tracking potential is as high there as it
is for explicit identifiers, except where they can trick the user into
installing a client certificate.
If the adversary does trick the user to install weird certificates,
these are only stored in memory in TBB, and will be gone after a
browser restart.
So it is not as bad as cache, cookies, DOM storage, and auth.

@_date: 2011-08-23 13:13:34
@_author: Mike Perry 
@_subject: [tor-talk] New HTTP authorization attack 
Thus spake Julie C (julie at h-ck.ca):
I was referring to the integration of NSS with the rest of Firefox.
Based on my limited experience, NSS generally doesn't seem to like its
state munged around with. It sort of lives in its own world and the
interfaces to it are prone to race conditions and optimizations that
are build on the assumption that the current use case (one set of SSL
state for the entire browser) is the only desirable one.
But good luck on your sketch project. May the intermediate certs be
with you!

@_date: 2011-08-28 19:46:00
@_author: Mike Perry 
@_subject: [tor-talk] Torbutton 1.4.1 Released 
Torbutton 1.4.1 has been released at: This release features a "New Identity" menu option that clears browser
state, closes tabs, and obtains a fresh Tor circuit for future requests.
It also features a fix for breakage with Hotmail, and further isolates
browser state and identifiers to the url bar domain (see
However, the New Identity button and the Hotmail fix are only
available to Tor Browser Bundle users. If you are still using
Torbutton with a vanilla Mozilla Firefox, we strongly recommend you
download the Tor Browser Bundle 2.2.x alphas from
 and report problems you
experience, as we will be declaring them stable within the next
release or two. Stay tuned for a new Tor Browser release that contains Torbutton
1.4.1 tomorrow.
Here is the complete changelog:
 * bug 523: Implement New Identity (for TBB only)
 * bug 3580: Fix hotmail/live breakage (for TBB only)
 * bug 3748: Disable 3rd party HTTP auth
 * bug 3665: Fix several corner cases SafeCache isolation
 * bug 3739: Fix https->http CORS failure for SafeCache
 * bug 3414: Isolate window.name based on referrer policy
 * bug 3809: Disable referer spoofing (fixes navigation issues)
 * bug 3819: Fix API issue with cookie protections
 * bug 3820: Fix warning w/ session store filter

@_date: 2011-08-29 15:57:36
@_author: Mike Perry 
@_subject: [tor-talk] Torbutton 1.4.1 Released 
Thus spake Greg Kalitnikoff (kalitnikoff at privatdemail.net):

@_date: 2011-02-24 11:59:01
@_author: Mike Perry 
@_subject: [tor-talk] Exit snooping 'research' 
Thus spake Olaf Selke (olaf.selke at blutmagie.de):
There's also the approach described in section 5 of this paper, which
actually kind of clever, but might also catch things like intermediate
caching proxies. If we could figure out a way to get lots of random
black IP space and keep it secret, it would be a fun one to run
There's quite a few other side channels available if you can get on
the same ethernet segment as a sniffer, or on the same VM host as a
suspicious tor node.
Most of these techniques are also fairly easy to evade, if you try.

@_date: 2011-02-27 19:21:22
@_author: Mike Perry 
@_subject: [tor-talk] Advice for high throughput Tor node 
This discussion is better suited for tor-relays at torproject.org.
Also, for reference, here is the previous tor-relays thread on the
technical aspects of this topic:
And also the social side:
We really need to work on condensing that tor-relays thread into a
single document like the blog post. We've still got a lot of mystery
and voodoo to unravel in terms of utilizing all spare Tor capcity,
Thus spake Mitar (mmitar at gmail.com):

@_date: 2011-02-09 16:07:39
@_author: Mike Perry 
@_subject: Design Change Causing More Traffic? 
Thus spake Jim (jimmymac at copper.net):
I've just realized that this could be more people adopting the Reduced
Exit Policy, which takes up a ton more space in the Tor router
directory than does the Default Exit Policy:
I bet Karsten could tell us for sure, using the descriptor archive
We need to standardize a more succinct way to represent this policy,
once we converge on a set of ports that we like for it. Either that,
or create a way to represent the policy in the consensus just once,
and have nodes declare their conformity to that policy by only
specifying the token for it from the consensus...

@_date: 2011-02-10 18:29:04
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake grarpamp (grarpamp at gmail.com):
I've already addressed the rest of your points.  For the record,
you're just strawmanning here. I never made the claim this was safer.
I cited several engineering reasosn why this type of exit policy
is a pain for us.
I've also made the claim that there is no rational reason to operate
an exit in this fashion, other than to log/monitor/censor traffic or
because of undesirable network conditions, and no one has disputed
that claim.
Morphium gave us a reason, even if it was rather petty and irrational,
so he won't be getting the badexit flag. But for my vote in the
process, any other relay that does not give a reason for this policy,
or that can not give us one because of no contact info, will be
getting the flag. The same goes for exits that we detect RSTing 443,
or censoring 443, or throttling 443, or doing anything else to TLS
But I only have one vote out of three. Roger and Peter are free to
change their minds. Perhaps we should bring more people on board in
this process, too.

@_date: 2011-02-12 04:36:15
@_author: Mike Perry 
@_subject: Problem with downloading attachments in torbrowser for osx 
Thus spake M (moeedsalam at gmail.com):
It sounds like you're describing a problem that only you have. Usually
when this happens, it is because of a Firefox addon conflict. You can
try a couple of things:
1. Use Tor Browser Bundle:
It is a preconfigured Tor Browser that should work right out of the
box without conflicts. If it *still* has the problem, then next place
to look is your Antivirus software. If not, you can either keep using
it, or try to diagnose your addon conflict by trying the following:
2. Start firefox with a fresh profile
If you run firefox as "firefox -P", you can create a blank profile,
install torbutton in it, and verify it is OK. Then, gradually add in
all the Firefox addons you have until you notice the problem again.
3. Post your list of addons to this mailinglist or to that bug for
someone else to try to reproduce the issue.
This link works for me using Tor + Torbutton.

@_date: 2011-02-13 04:59:06
@_author: Mike Perry 
@_subject: "Cookie Mismatch" when using Gmail. 
Thus spake Matthew (pumpkin at cotse.net):
Can you please try the .xpi from this bug:
 and let
me know if it behaves ok for Google logins now? It may need a few
tries, iirc, this bug is random.
Be sure to go back in to about:config and reset
extensions.torbutton.xfer_google_cookies back to *true* before running
your tests.

@_date: 2011-02-14 02:04:31
@_author: Mike Perry 
@_subject: Scroogle and Tor 
Thus spake Matthew (pumpkin at cotse.net):
I second this.
If you can find a way to fingerprint these bots, my suggestion would
be to observe the types of queries they are running (perhaps for some
of their earlier runs from when you could ban them by user agent?).
One of the things Google does is actually decide your 'Captchaness'
based on the content of your queries. Well, at least I suspect that's
what they are doing, because I have been able to more reliably
reproduce torbutton Captcha-related bugs when I try hard to write
queries like robots that are looking for php sites to exploit.
I would love to hear more about the types of scrapers that abuse Tor.
Or rather, I would like to see if someone can at least identify
rational behavior behind scrapers that abuse Tor. Some of it could
also be misdirected malware that is operating from within Torified
browsers. Some of it could also be deliberately torified malware.
Google won't tell us any of this, obviously ;).

@_date: 2011-02-14 06:09:17
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake morphium (morphium at morphium.info):
Sure, dude. Since you've read everything that was said, I take it
you're volunteering to contact the other node operators and ask them
to give reasons for why they chose their exit policy?
Let us know their preferred email addresses when you're done. But
they'll have to survive a challenge and response round proving they
can modify their contact info field ;).

@_date: 2011-02-14 20:19:50
@_author: Mike Perry 
@_subject: Scroogle and Tor 
Thus spake scroogle at lavabit.com (scroogle at lavabit.com):
Great, now that we know the motivations of the scrapers and a history
of the arms race so far, it becomes a bit easier to try to do some
things to mitigate their efforts. I particularly like the idea of
feeding them random, incorrect search results when you can fingerprint
If you want my suggestions for next steps in the arms race for this,
(having written some benevolent scrapers and web scanners myself), it
would actually be to do things that require your adversary to
implement and load more and more bits of a proper web browser into
their crawlers for them to succeed in properly issuing queries to you.
Some examples:
1. A couple layers of crazy CSS.
If you use CSS style sheets that fetch other randomly generated and
programmatically controlled style elements that are also keyed to the
form submit for the search query (via an extra hidden parameter or
something that is their hash), then you can verify on your server side
that a given query also loaded sufficient CSS to be genuine. The problem with this is it will mess with people who use your search
plugin or search keywords, but you could also do it in a brief landing
page that is displayed *after* the query, but before a 302 or
meta-refresh to actual results, for problem IPs.
2. Storing identifiers in the cache
 has some PoC
of this. Torbutton protects against long-term cache identifiers, but
for performance reasons the memory cache is enabled by default, so you
could use this to differentiate crawlers who do not properly obey all
brower caching sematics. Caching is actually pretty darn hard to get
right, so there's probably quite a bit more room here than just plain
3. Javascript "proof of work"
If the client supports javascript, you can have them factor some
medium-sized integers and post the factorization with the query
string, to prove some level of periodic work. The factors could be
stored in cookies and given a lifetime. The obvious downside of this
is that I bet a fair share of your users are running NoScript, or
prefer to disable js and cookies.
Anyways, thanks for your efforts with Scroogle. Hopefully the above
ideas are actually easy enough to implement on your infrastructure to
make it worth your while to use for all problem IPs, not just Tor.

@_date: 2011-02-14 21:20:21
@_author: Mike Perry 
@_subject: Scroogle and Tor 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
I hate polipo. I've been trying ignore it until it fucking dies. But
it's like a zombie that just won't stop gnawing on our brains. Worse,
a crack smoking zombie that got us all addicted to it through second
hand crack smoke. Or something. But hey, it's better than privoxy.
I was under the impression that we hacked it to also be memory-only,
though. But you're right, if I toggle Torbutton to clear my cache,
Polipo's is still there...

@_date: 2011-02-15 03:26:43
@_author: Mike Perry 
@_subject: Please Badexit: 
Thus spake morphium (morphium at morphium.info):
These are running a slightly modified default exit policy. They allow
443. They are fine by me.
Funny you should mention this node. A researcher flagged it once in a
test to detect sniffing, but was not able to reproduce it later. Maybe
they just turned off their sniffer and got lucky :). There were also
serious issues with the methodology though, and it may have been a bug
in the scanning technique.
However, at this point we are only going after nodes that carried
unencrypted versions of both mail *and* web. The reason we did this
was because another researcher actually detected another node that he
*was* able to reproduce. It had this exact type of exit policy. It
calls itself 'agitator'.
When we found that sniffer, we looked for other exit policies similar
to that one, and found the five here that caused so much controversy.
We probably should have came out with all this earlier, but the
researcher requested we keep their methodology secret until
publication. It also needs some work in the reproducibility dept...
At any rate, this node appears to (now?) carry 443. Did it's policy
just change?
Same as Tory0.

@_date: 2011-02-15 06:31:14
@_author: Mike Perry 
@_subject: Please Badexit: 
Thus spake morphium (morphium at morphium.info):
I think you've become a troll. Sorry 'bout it, man.

@_date: 2011-02-15 21:10:46
@_author: Mike Perry 
@_subject: Contacted by "oompaloompa" operator: BadExit removed 
I was contacted by the operator of oompaloompa. He has changed the
exit policy of his two nodes to the "Reduced" policy:
He said that he started those two nodes as a test to experiment with
Tor, and picked the exit policy quickly off the top of his head,
keeping it brief because it was tedious to write.
He also gave the following reasons why one might want an exit policy
like this (though he said none of these were his reasons):
1. Crypto may not be legal
The problem with this is that Tor is already pumping a ton of crypto
that was designed to look as much like web TLS as possible. Chaning
your exit policy doesn't really help this.
2. IDSs could prevent attacks
This would be a great idea in theory, if it ever worked. In practice,
IDSs end up being censorship devices for security mailinglists,
exploit advisory info, and other information on computer security.
We've actually already BadExited quite a few of these types of nodes,
because our exit scanner detects the censorship.
3. Plausible deniability due to eliminating additional TLS fingerprints
This is an interesting one, and I think I misread what he meant when
he first said it, but if it means not having the additional TLS
fingerprints of tor client traffic so that your TLS traffic doesn't
stand out in the Tor noise, I don't think this works out for you. You
end up being obvious because your node would not exit to any TLS
At any rate, because the Exit Policy has changed, I've personally
updated my authority to remove the BadExit. I believe we're still
waiting on one of Roger or Peter.

@_date: 2011-02-16 02:15:47
@_author: Mike Perry 
@_subject: Contacted by "oompaloompa" operator: BadExit removed 
Thus spake tor at lists.grepular.com (tor at lists.grepular.com):
The contact info there is not a valid email address. He contacted me
privately via a different one. Since he hasn't updated his contact
info to the new address, I'm guessing he prefers not to list it. I
have no personal issues with this. I haven't actually spoken to Roger
or Peter yet though, they may feel different (though I doubt it).

@_date: 2011-02-18 04:39:39
@_author: Mike Perry 
@_subject: Undeletable cookies 
Thus spake Irratar (irratar77 at gmail.com):
This is news to me. Are you using the default Torbutton settings? When
we tested this in the past, Torbutton was protecting against it. I
also just tested it now, and it did not recover my cookie.
Perhaps one of your other addons betrayed you? Did you enable plugins?
Or perhaps you have a misconfigured polipo storing these cookies in
its cache?
The Tor Browser Bundles are a good way to ensure you have a properly
configured, vanilla Tor setup.
Actually, web application layer privacy attacks *are* a Tor issue. We
try very hard to protect against them:

@_date: 2011-01-31 16:00:19
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake tor at lists.grepular.com (tor at lists.grepular.com):
3/5 of the nodes provide contact info. 2/5 are run by "Joe Blow", and
the other is run by "nobody at example.com"
Just for grins, I did in fact send an email to Mr. Blow's gmail
address. It of course bounced. Which means it is available on gmail if
he wanted it, but he didn't even bother to create it. He's obviously
real intent on being a member of the community.
But don't worry, at some point Mr. Blow et al will realize that their
packet captures stopped grabbing passwords and are only seeing
encrypted middle and guard node traffic. They'll probably show up
then, proclaiming their innocence from the rooftops, demanding they be
allowed to "help" the network.
But do feel free to spend your time going above and beyond, trying to
track our 4 heroes down before then. I'm sure they're well worth your
time and effort to outreach. Pick a nice Saturday afternoon and spend
it calling ISPs and NOCs trying frantically to get in touch with our
unjustly punished martyrs here... Heck, take a day off work!
It's not true exit bandwidth here. It's janky bandwidth with lots of
bad properties, such as the tendency to break mixed-mode websites as
Curious Kid pointed out, and the load balancing issues I mentioned. We
should do the same for all http-but-not-https exits for this reason.
Again, non-bittorrenting exits have a real hard time attracting enough
80+443 traffic. All of our metrics indicate they are not overloaded
the vast majority of the time, and tend to end up pushing half of the
bytes/sec as their bitorrent-supporting peers. There is plenty of
spare port 80 capacity. The network is bottlenecked in other ways
(probably actually in the queues of overloaded middle and guard nodes,
which these jerks would be more directly assisting).

@_date: 2011-01-31 16:56:13
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake tor at lists.grepular.com (tor at lists.grepular.com):
The truth here is that these nodes are not behaving in a way that
encourages trust in their usage. All we ask is that they adjust their
exit policies to allow encryption, but there is no way to ask them
this, so they are badexited until such time as there is a way to
communicate with them. They will remain valid middle and guard nodes
until they rekey with policy supporting encryption (and the Exit
You're right. I apologize for my tone to you. I am merely frustrated with the amount of mental energy devoted to
what so plainly appears to me as a simple policy: If you carry the
unencrypted version of the service, you should carry the encrypted
version. I am just getting frustrated with the length of this thread
and still the lack of any valid, rational reason why this policy
itself is an unjust one.
It seems pretty plain to me that we're actually worried about offending
the sensibilities of people who for some unknown (but rationally
obvious) reason refuse to carry encrypted exit traffic.
So the idea that we should devote yet more effort to catering to
people whose motivations are extremely suspect (and who seemingly have
no real interest in being members of our community) is causing me to
Sure. Perhaps we will include such a patch as part of
 Or, perhaps it
will just be a second-order effect that means you're just not used as
often because you're not a true Exit (which is already the case for
these nodes to some extent).
But again, I think this is more of a long-term idea.
In the meantime, we can enforce this policy with code on the exit
scanning end, by emailing everyone with valid contact info who exits
to 80 but not 443, to start (as that is the most obviously broken

@_date: 2011-01-08 14:25:09
@_author: Mike Perry 
@_subject: "Cookie Mismatch" when using Gmail. 
Thus spake Matthew (pumpkin at cotse.net):
Try changing this last setting
(extensions.torbutton.xfer_google_cookies) to false. It is designed to
try to move your google cookies from one domain to another to avoid
requiring you to solve captchas for every google country domain.
It could be breaking something in the signon process, especially if
you get redirected to/from a country domain during login (by using a
german exit, for example).

@_date: 2011-01-11 21:26:43
@_author: Mike Perry 
@_subject: geeez... 
Thus spake Dirk (noisyb at gmx.net):
The tips in the blog post are not "how not to get caught". In fact,
every one of them is about telling people as early in the process what
is going on, and who to contact if there are issues. This is done
because at scale (gigabit speeds), abuse complaints happen way more
frequently. With the default exit policy, you will get about 50
automated DMCA complaints per day at gigabit speeds. With the
bittorrent-resistant reduced exit policy from that post, you get about
5 per week. So it is entirely about reducing your work load for
managing your exit, and keeping the noise away from your ISP.
As previous threads indicate, law enforcement can and does still
contact you. The goal again is making this easy, so no one needs to
kick in any doors.
Some of us are also compiling abuse response templates. The goal for
abuse responses is to inform people about Tor, and to suggest
solutions for their security problems that involve improving their
computer security for the Internet at large (open wifi, open proxies,
botnets), rather than seeking vengeance and chasing ghosts. The
difference between these two approaches to abuse is the difference
between decentralized fault-tolerant Internet freedom, and fragile,
corruptible totalitarian control.
I'm not a lawyer, but our largest exit (blutmagie) has run in germany
for the past 4 years or so.
We have discovered that the most effective way to run tor servers is
in bulk, because smaller providers are not willing to put up with
occasional abuse complaints that do get through to them, because doing
so costs them human resources and dollars. Bandwidth also is
considerably cheaper in bulk than it is at residential or even shared
hosting/VPS prices.
Consider donating to  or setting up your
own similar project and collecting donations to leverage the economies
of scale inherent in bandwidth prices. Obviously, the more people
doing this the better (for distributed trust).
See also the thread at:
 at freehaven.net/msg14159.html for
some insight into the arcane technical details involved in running
high capacity tor relays.

@_date: 2011-01-12 02:30:04
@_author: Mike Perry 
@_subject: geeez... 
Thus spake Timo Schoeler (timo.schoeler at riscworks.net):
Here's the (freshly updated) set of abuse complaints that reflects
what myself and a handful of others have dealt with over the past 6
months or so:
Notably absent from that list is a DMCA response, but the EFF provides
one for that case:

@_date: 2011-01-12 03:06:47
@_author: Mike Perry 
@_subject: geeez... 
Thus spake Mike Perry (mikeperry at fscked.org):
I've also gone ahead and updated the blog post with new tips for exit
node operators:
The two main changes are links to the ARIN registration pages and
forms, and tips on forming an LLC to run your node for civil liability
protection in the US.

@_date: 2011-01-12 03:53:55
@_author: Mike Perry 
@_subject: Gmail saying "cookies are turned off" but they are not 
Thus spake Praedor Atrebates (praedor at yahoo.com):
This is is a bug in Torbutton. It is caused by the hidden setting:
This setting was introduced to reduce the number of captchas that
google presented, so that you would only have to solve a captcha once,
instead of once per country code domain. It seems to be interfering
with gmail logins when your country code changes.
Setting this hidden pref to false in about:config will fix the issue
for you. See ticket  for info on patches/fixes:
Also, please read the archives more closely. This was *just* discussed
in a different thread.

@_date: 2011-01-04 01:32:30
@_author: Mike Perry 
@_subject: Torbutton 1.3.1-alpha released 
Torbutton 1.3.1-alpha has been released at:
This release features a fix for the nasty pref dialog issue in 1.3.0
(bug  as well as Firefox 4.0 support. Thanks to new APIs in
Firefox 3.5 and better privacy options in Firefox 4, Torbutton has now
been simplified as well. While we still provide a number of XPCOM
components, the number of native Firefox components we replace has
shrunk from 5 to just one.
However, the amount of changes involved in supporting Firefox 4 were
substantial, and it is likely that these changes as well as the
removal of old code has introduced new bugs. I've done my best to test
out operation on Firefox 3.6 and 4.0, but I have not tested Firefox
3.0, and I may have missed other issues as well. Please report any
issues you notice on our bugtracker:
Here is the complete changelog:
 * bugfix: bug 1894: Amnesia is now called TAILS (patch from intrigeri)
 * bugfix: bug 2315: Remove reference to TorVM (patch from intrigeri)
 * bugfix: bug 2011: Fix preference dialog issues (patch from chrisdoble)
 * bugfix: Fix some incorrect log lines in RefSpoofer
 * new: Support Firefox 4.0 (many changes)
 * new: Place button in the nav-bar (FF4 killed the status-bar)
 * misc: No longer reimplement the session store, use new APIs instead
 * misc: Simplify crash detection and startup mode settings

@_date: 2011-01-13 21:24:43
@_author: Mike Perry 
@_subject: geeez... 
Thus spake Mitar (mmitar at gmail.com):
That's not what we're saying, but I suspect you may just be trolling.
You're certainly straw-manning...
The same techniques that law enforcement use when these same
sophisticated adversaries use black market compromised botnets:
In these cases, police need to do police work: gathering technical
data and examining content for evidence to aid in the investigation;
and infiltrating groups and performing stings (for which they often
use Tor).
You think criminals obey the law?
Both China and South Korea have instituted fully authenticated
"internet drivers licenses", and not only has cybercrime not vanished,
it continues to flourish and profit from new markets that trade in these
credentials and the use of authenticated connections through proxy.
Even a fully cryptographically secured and authenticated Internet
would still be *just* as vulnerable to abuse, all other things being
equal. Grandma could even be required to have her iris scanned before
entering her bunker to use her military-grade encrypted, authenticated
PC that is otherwise disconnected from the Internet while her iris is
not available. But as soon as she scans her iris, the malware on her
machine would wake up and inform its masters that it is ready to do
their bidding.
The only way to really curtail these social problems is to properly
address their root causes. Taking freedoms away seems like an easy
quick fix, but in reality, there is no gain, only more insecurity.
This is why Tor is not part of the problem. In fact, its use by law
enforcement for stings, infiltration, and investigation indicates it
is also part of the solution.

@_date: 2011-01-15 11:02:00
@_author: Mike Perry 
@_subject: How to use Google Gadgets with Tor? - Is this possible? 
Thus spake Matthew (pumpkin at cotse.net):
I've noticed that some mashup services mysteriously break when Google
decides to give them/you a captcha. This could be happening to you. You
could try to solve a google captcha by issuing some queries and/or
using Google maps first, to see if this makes any difference. Usually
once you have the cookies for a session that solves a captcha, Google
does not make you solve another.
You could also install an addon to observe the requests your browser
uses in both non-Tor and Tor accesses of this gadget to see if the
requests appear different for some reason. That may help diagnose the

@_date: 2011-01-16 15:45:29
@_author: Mike Perry 
@_subject: How to use Google Gadgets with Tor? - Is this possible? 
Thus spake M (moeedsalam at gmail.com):
Google gadgets that rely on Google browser plugins such as Google
Gears are not safe, because we canot protect against them. However,
Torbutton's normal protections for the web should keep Google gadgets
that use plain AJAX safe, from a privacy point of view. Of course
though, you are probably not private to Google at this point, esp if
you are logged in to a gmail account. But I assume you're aware of
that and what this means in terms of privacy consequences, and are
comfortable with that tradeoff.
We do *not* recommend disabling Torbutton to get your Google gadgets
to work. Then you become signifcantly less private, both to Google and
to the rest of the web.
If we can't get to the bottom of this and it seems likely that
Torbutton is actually the cause, please file a bug report at
 But so far it
seems like there is some other issue which we have not yet gotten to
the bottom of.

@_date: 2011-01-16 16:05:13
@_author: Mike Perry 
@_subject: How to use Google Gadgets with Tor? - Is this possible? 
Thus spake Matthew (pumpkin at cotse.net):
Let's try some science. We need a control, so lets create a blank
Firefox profile. This requires running firefox with a command of
'firefox -P'. This will bring up the profile window and then you can
create a blank profile and try to set your proxy to use Tor and try it
again, and then try non-Tor. Then we can see if you get the same exact
results, or if your old profile got damaged by one of your addons (it
can happen).
If the issue does *not* happen with a fresh profile, try adding your
addons back one at a time until it does. Then maybe we can get

@_date: 2011-01-29 20:52:12
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake Gregory Maxwell (gmaxwell at gmail.com):
Various research groups occasionally experiment with using side
channels for detecting recording exits. Their results are not usually
reproducible, though (no source code, poor design, poor quality
control, too easy to mitigate, etc). :/
They do occasionally find interesting stuff. But then they either
publish, or get rejected, and then shut down their code and forget
about it.
I agree. We already have scripts to detect this, we just have not yet
decided to actually use them yet. I believe we should.
Currently, 5 nodes exit to *only* plaintext ports for web and email.
There are about 50 others that exit to the plaintext versions for web
or email. I believe we hould ban these 5 immediately, and consider banning the
other 50 after issuing the appropriate announcements.

@_date: 2011-01-29 20:57:43
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake Mike Perry (mikeperry at fscked.org):
Sorry, the 5 are:
NOTICE[Sat Jan 29 20:56:43 2011]:Nodes allowing plaintext but not secure:
        ElzaTorServer=009E71AED2C5580E942AC1743D1C440C5B2C459E
        QuantumSevero=4BF2F90E6E1905E2FB4F371E471422150D722A93
        gatereloaded=550CC9724FA77C7F9260B93989D22A70654D3B92
        oompaloompa=775DF6B8CF3FB0150A594F6E2B5CB1E0AC45D09B
        oompaloompa2=BABBF0694251E5AFF7BF3A0A02EFDC12CB99B05F

@_date: 2011-01-29 22:45:02
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake Eddie Cornejo (cornejo at gmail.com):
Yeah, I believe you're missing the fact that these ports also contain
plaintext passwords than can be used to gain access to information on
these and other accounts that may or may not have ever traveled over
tor. That is the difference.
See above.
We don't need bandwidth that bad.
I believe that allowing these nodes sends a message that we are OK
with people monitoring plaintext traffic, because it is anonymized. We
have never been OK with this.
People use plaintext at their own risk, and yes, they should know
better, but this does NOT mean that we are comfortable feeding them to
the wolves.
If said exits are really interested in helping, they should alter
their exit policy to allow encryption and then rekey. They will be
banned by identity key, not by IP. Rekeying without fixing the exit
policy will just result in IP bans.

@_date: 2011-01-29 23:23:55
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake Eddie Cornejo (cornejo at gmail.com):
We can detect nodes that fail encrypted connections. We currently scan
for failure of port 443. We also detect throttling by virtue of our bw
authorities measuring using 443.
443 is the second-most trafficed port by byte on the Tor network,
occupying only ~1% of the traffic. If stingy exit nodes really want to
waste hours to pinch pennies from their malicious exit policy, they
can try crafting a throttling policy that we can't detect. Seems like
there are better ways to spend their time. Like reading other people's
So no, I'm not terribly concerned about second-order effects of this.
We're not trying to identify wolves. We are sending a message to the
Not really. In reality, it's up to those who write the code to decide
what is available and how it works ;). Welcome to The Golden Path.
At some point, we intend to shrink exit policies further as Tor scales
to more decentralized schemes. Those exit policies will likely be
represented as bits representing subsets of ports. When that time
comes, we will very likely combine encrypted and unencrypted versions
of ports together, removing this option entirely.

@_date: 2011-01-30 20:54:28
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake morphium (morphium at morphium.info):
There is no rational reason to carry the unencrypted version of a
service but not the encrypted version, except to log data. So unless
these 5 nodes were all just playing their favorite lotto numbers in
their exit policy, they were being jerks.
I am aware that every operator can sniff regardless of policy. Every
operator can do a lot of things. The fact that even good exit policies
can do bad things is not a necessary condition for allowing bad exit
Frankly, this in-your-face selfishness of *only* accepting the
unencrypted data because "fuck it, that's the only data I want to log"
just rubs me the wrong way. Not one of those 5 had legit contact info.
Two of them actually bothered to fill out the field, but filled it in
with a fake email address. All of them just wreak of disrespect for us, for the network, and for
our users. Essentially, it's that disrespect that earned them the
BadExit flag.
If this means that sending the message to them means we take out a few
irrational actors in the process, that's fine. I don't much want
people playing lotto in their exit policies either. They can stick to
middle node and put their lotto numbers in their contact info. I
promise that it will work just as well.
*sigh*. And so the cat herding begins. Are you really protesting this
policy decision with civil disobedience? Really? Fighting for Great
Justice everywhere, eh?
Do you have a rational reason why we should allow people to carry the
unencrypted version of a service but not the encrypted one, other than
"Well, they could be bad actors even with a good policy!"
Or is it just because you feel that someone told to do something and
you don't much like being told what to do, regardless of the
I forbid you from jumping in the nearest lake!
I also forbid you from taking your freshly-gimped exit node in for a
swim with you!

@_date: 2011-01-31 00:59:47
@_author: Mike Perry 
@_subject: Blocked from yelp.com? 
Thus spake David Carlson (carlson.dl at sbcglobal.net):
To hell with yelp.
It's not clear if the bans are intentional - if they just believe
that selling user's privacy against their will is their official
business model, or if it's just a DoS detection mechanism gone
haywire. Given that *residential* exits are showing up as banned, I'm
guessing it's not the latter... Go them.
Use Google Maps (aka Places on mobile). It aggregates yelp and a
handful of other sites, and does not ban tor. It occasionally gives
you a captcha, but this is better than a ban.
P.S. Just to open myself up to a fun libel suit, I've heard rumors
that yelp takes bribes to filter ratings in various ways. I'm sure the
filters are only beneficial, and help to remove spam posts and other
"malicious" content. In the face of rumors like these, it really is
better to get your information elsewhere, especially from an

@_date: 2011-01-31 02:35:38
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake morphium (morphium at morphium.info):
This is not true. The exit nodes in question account for ~6% of the
network Exit-flagged bandwidth. That is, *IF* they actually had the
Exit flag (they did not), they would have provided 6% of that
bandwidth. They do not have the Exit flag, however, so they provide
This allows me to explain another reason why I have no problem banning
these obviously malicilously (or in your case, irrationally) speced
nodes. They make our lives harder for load balancing.
We put a lot of work recently into trying to correct load balancing
bugs wrt to node flags over the years. The algorithms have been
through four revisions, the last two of which were mine:
These equations are still only an approximation. If you'll direct your
attention to ticket  you'll see that we really need to
differentiate between bitorrent-supporting exit and exits using the
default policy vs the "reduced" exit policy:
Having to further differentiate our load balancing weights for
lunatics who decide to exit to 80 but not 443 requires us to create
yet a third category of weights, unless we choose to ignore the 1-2%
of exit bandwidth that appears to exit over port 443 (though it's
hopefully rising, thanks to our efforts in developing+deploying
So when I said in my earlier post that we don't need exit capacity
that bad, I meant it. Thanks, but no thanks. You are contributing
negative productivity, and none of the non-bitorrenting exits really
will notice your absence in terms of load. Please direct yourself
towards the nearest forbidden lake.
But whatever. For your exit, it's not even worth the effort for a
badexit line. We'll get you in the next batch. Or if not that, in the
solution for Now, back to development.

@_date: 2011-01-31 15:41:35
@_author: Mike Perry 
@_subject: Is "gatereloaded" a Bad Exit? 
Thus spake Curious Kid (letsshareinformation at yahoo.com):
These people should not be Tor nodes. A good portion of the public
network is on port 443. If you can't reach that port, lots of circuits
clients try to build through you will fail. Failed circuits have a
negative impact on latency, esp if they were not pre-launched
predicted circuits. Byzantine circuit failures also make it difficult
to differentiate between overloaded, CPU-bound nodes, malicious nodes,
and just plain janky nodes - all of which we would like to
be able to take into account for future load balancing decisions.
Ex: This is an excellent point, and yet another reason why we should not
allow asinine exit policies unless there is good reason for them. So
far there is still no rational reason posted why you should allow 80
and not 443 and still be considered a desirable Tor node to use. Just
a lot of handwaving about the freedom to be a jerk, and fears over
shunning volunteers who run fast exits to grab passwords. Moreover, I strongly believe that we should be working on converging
our choices of exit policy down to fewer options for many practical
engineering and usability reasons. Exit policies already take up an
absurd amount of capacity in terms of descriptor and even
networkstatus storage. If we can standardize on a group or groups of
ports (such as the Vidalia GUI attempts to do), we can describe sane
exit policies using much fewer bytes. And we can load balance more
intelligently among exits with standard policies, as I mentioned
So to me, there are plenty of reasons to do this, and not a whole lot
of reasons not to do it, other than handwavy notions that "it
shouldn't matter", when in fact as you have pointed out, it does

@_date: 2011-01-05 13:57:22
@_author: Mike Perry 
@_subject: Tor uses swap? 
Thus spake andre76 at fastmail.fm (andre76 at fastmail.fm):
This is a good question. Tor has a torrc option that is off by default
to disable all swap activity *by the tor process itself*:
'DisableAllSwap 1'.
However, this is not all you need. Your web browser can still be
swapped arbitrarily to disk. Unfortunately, this is difficult for us
to control for two reasons:
1. It is not possible to access the system calls relevant to this from
Torbutton until Firefox 4 (which provides JS-Ctypes to addon
developers) is in common use.
2. Even if we do this with a custom TBB build, most operating systems
require root/administrator priviledges to disable swap activity. The other alternative is to set up encrypted swap. The Ubuntu
documentation on encryption is pretty sad and disorganized:
But I think there should be an option to set up encrypted swap during
the installation process. There certainly is on other modern distros
like Fedora and even CentOS.
Other than swap, Torbutton should be blocking all history writes by
Firefox in Tor mode by default.

@_date: 2011-01-05 13:57:22
@_author: Mike Perry 
@_subject: Tor uses swap? 
Thus spake andre76 at fastmail.fm (andre76 at fastmail.fm):
This is a good question. Tor has a torrc option that is off by default
to disable all swap activity *by the tor process itself*:
'DisableAllSwap 1'.
However, this is not all you need. Your web browser can still be
swapped arbitrarily to disk. Unfortunately, this is difficult for us
to control for two reasons:
1. It is not possible to access the system calls relevant to this from
Torbutton until Firefox 4 (which provides JS-Ctypes to addon
developers) is in common use.
2. Even if we do this with a custom TBB build, most operating systems
require root/administrator priviledges to disable swap activity. The other alternative is to set up encrypted swap. The Ubuntu
documentation on encryption is pretty sad and disorganized:
But I think there should be an option to set up encrypted swap during
the installation process. There certainly is on other modern distros
like Fedora and even CentOS.
Other than swap, Torbutton should be blocking all history writes by
Firefox in Tor mode by default.

@_date: 2011-07-06 18:05:31
@_author: Mike Perry 
@_subject: [tor-talk] Torbutton 1.4.0 released 
Torbutton 1.4.0 has been released at:
The addon has been disabled on addons.mozilla.org. Our URL is now
This release features support for Firefox 5.0, and has been tested
against the vanilla release for basic functionality. However, it has
not been audited for Network Isolation, State Separation, Tor
Undiscoverability or Interoperability issues[1] due to toggling under
Firefox 5. If you desire Torbutton functionality with Firefox 4/5, we recommend
you download the Tor Browser Bundle 2.2.x alphas from
 or run Torbutton in its
own separate Firefox profile.
The reasons for this shift are explained here:
If you find bugs specific to Firefox 5, toggling, and/or extension
conflicts, file them under the component "Torbutton":
Bugs that still apply to Tor Browser should be filed under component
Bugs in the "Torbutton" component currently have no maintainer
available to fix them. Feel free to step up.
(No, simply mis-filing your Torbutton toggle bugs under
TorBrowserButton won't cause them to get fixed accidentally. It will
just annoy me slightly as I relocate them to the correct component).
Here is the complete changelog:
 * bug 3101: Disable WebGL. Too many unknowns for now.
 * bug 3345: Make Google Captcha redirect work again.
 * bug 3399: Fix a reversed exception check found by arno.
 * bug 3177: Update torbutton to use new TorBrowser prefs.
 * bug 2843: Update proxy preferences window to support env var.
 * bug 2338: Force toggle at startup if tor is enabled
 * bug 3554: Make Cookie protections obey disk settings
 * bug 3441: Enable cookie protection UI by default.
 * bug 3446: We're Firefox 5.0, we swear.
 * bug 3506: Remove window resize event listener.
 * bug 1282: Set fixed window size for each new window.
 * bug 3508: Apply Stanford SafeCache patch (thanks Edward, Collin et al).
 * bug 2361: Make about window work again on FF4+.
 * bug 3436: T(A)ILS was renamed to Tails.
 * bugfix: Fix a transparent context menu issue on Linux FF4+.
 * misc: Squelch exception from app launcher in error console.
 * misc: Make DuckDuckGo the default Google Captcha redirect destination.
 * misc: Make it harder to accidentally toggle torbutton.
1.

@_date: 2011-07-08 09:31:19
@_author: Mike Perry 
@_subject: [tor-talk] Torbutton 1.4.0 released 
Thus spake tagnaq (tagnaq at gmail.com):
We haven't blocked addon updates since Firefox started authenticating
them in Firefox 3. See the changelog entry under 1.2.0rc6 for this
(CHANGELOG in the unzipped .xpi).
Sorry I missed this. Will reply there.

@_date: 2011-07-08 09:38:29
@_author: Mike Perry 
@_subject: [tor-talk] Torbutton: 'Disable Updates During Tor' - Option 
Thus spake tagnaq (tagnaq at gmail.com):
Authentication is done now. We still provide the option because of fingerprinting issues of
downloading xpis in the clear over tor. It will soon become a hidden
option only, because we can only protect against fingerprinting in Tor
Browser, which should have a fixed set of addons.
Now that authentication is enabled, this is mostly an anonymity issue,
This is extremely interesting. Seems to indicate that to preserve the
same level of update security that Mozilla provides, we should be
hardcoding certificates for both the HTTPS-Everywhere and torbutton
update urls, as they do not go through versioncheck (anymore)..

@_date: 2011-07-09 10:15:32
@_author: Mike Perry 
@_subject: [tor-talk] Torbutton 1.4.0 released 
Thus spake tagnaq (tagnaq at gmail.com):
Tor browser has set a few options that we need to reconsider. I think
this option is among them, but Erinn may know the reasoning behind
setting it for TBB in the first place.
I filed this ticket for it:

@_date: 2011-07-15 14:27:12
@_author: Mike Perry 
@_subject: [tor-talk] Traffic retention of TOR-Relays in Denmark 
Thus spake Andrew Lewman (andrew at torproject.org):
Well, the original question seems to be "should we trust danish Tor
servers", not "are Tor users safe inside Denmark?" I think you
answered the client side well, but didn't touch the issue with tor
servers. I'll do my best to talk about the server side.
The risk for the server side comes from an adversary's ability to use
the connection log/sampled log to correlate traffic at the entrances to
the network (Guard nodes) with traffic exiting the network (Exit
Let's talk about Guards first.
In the event of Session Logging (2.2.1), there probably is not enough
information to be a serious threat against Guard nodes. Tor clients
use a fixed set of guards, and keep TCP connections open to these
guards for a long time, regardless of activity. However, packet sampling (2.2.2) is actually more of a threat.
I believe the closest we have in the research arena to answer this
question is Steven Murdoch's work on sampling Internet Exchange
 (paper)
 (slides)
Sections 4 and 5 are the relevant sections from the paper.
His results were best against very large, loud client flows. Small
flows (like web traffic) proved hard to accurately correlate even with
high frequency sampling rates.
So the answer is Danish tor servers are "probably" safe as Guard nodes
for web traffic.
However, Exits are a different story. Session Logging there probably will provide more information than
sampling for Exits. How serious is this threat? It seems bad to me. It
probably gives enough information that we may want to think about
avoiding using Danish exits with EU Guards, or building some more
general mechanism for dealing with cases of known data retention..
The simplest answer to all of these end-to-end statistical attacks is
"more network diversity" and "more users", though. Network diversity
helps to reduce the chance of picking an entry and an exit observed by
the same party. A larger userbase means that even when both ends are
visible, it is harder to correlate flows accurately. This is because
as the event rate of similar sized traffic goes up, correlation
accuracy goes down.
But I'd love to hear what Steven, Roger, Nick and Paul think about all
this, too.

@_date: 2011-07-28 09:07:12
@_author: Mike Perry 
@_subject: [tor-talk] Orweb v2 - now supports Android 2.x and 3.x 
Thus spake Nathan Freitas (nathan at freitas.net):
Yeah, as a heads up to the community, the first tests that we need done
is to verify that intermediate cert download, HTTPS OCSP, DNS
prefetch, and FTP are all being properly proxied. There are known
issues with the Chrome proxy implementation that cause these items to
bypass proxy settings. It stands to reason that there is a risk for
similar leaks on the Android browser. Some manual and/or stress testing over a wifi link + wireshark should
be sufficient here (though finding a page that sources ftp:// urls may
be tricky. You probably will need to create that yourself).

@_date: 2011-06-04 00:15:42
@_author: Mike Perry 
@_subject: [tor-talk] EFF Tor Challenge 
Thus spake CACook at quantum-sci.com (CACook at quantum-sci.com):
I commend your efforts to jump into something new. Diversity in our
community and especially our relay pool is extremely important. Please
don't be discouraged.
That said, I think you're over-engineering this. Exploits are a numbers
game.  If you are concerned about being popped by random, untargeted
malware, your odds are honestly much higher through the web browser
(actually its plugins) than through the Tor relay component, as others
have alluded to earlier in this thread. There are too few Tor relays to
make them attractive targets for someone's botnet or for harvesting bank
account passwords.
However, targeted attacks are much more of a concern. In these cases,
the adversary is either targeting the Tor network to deanonymize users,
or targeting you personally.
If they are targeting Tor, the thing you need to be worried about is
attempts to extract your relay keys from your harddisk or otherwise
analyze tor traffic underneath the relay-to-relay crypto. For this
reason, best practices are using an encrypted loopback volume that
only gets mounted while Tor is running, and/or rekeying your relays
after mysterious unexplained/unexpected downtimes. It probably also
means running on bare hardware (as opposed to a VPS) because of the
threat from an unknown host OS and possibily even malicious guests.
Isolating and hardening the system against the Tor daemon doesn't make a
whole lot of sense from a cost/benefit risk-analysis point of view. The
adversary who is after Tor only wants 'tor' and not much else. Isolation
doesn't change their capabilities in this regard.
If you believe the target is you personally, then the recommendation is
to rent bare hardware in a colo, have it imaged with something standard
("Ubuntu LTS" and CentOS are decent choices for keeping modern yet
remaining supported and providing decent hardening mechanisms for
everything else), use it only for tor, keep it far away from your
personal equipment, and run it out of a distinct legal
entity/corporation (to dissuade legal attacks against your person).
Good luck!
P.S. If you have any more specific questions about relay operation,
join us on tor-relays:

@_date: 2011-06-04 00:55:27
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake tagnaq (tagnaq at gmail.com):
We're going to try really hard to avoid this by default. See the first
two options in the client UI section under "advanced options":
However, the tricky bit is that we may not know the real IP address of
the destination server with certainty. We may have to rely on the DNS
cache and/or an additional resolution (which may not even be possible
if the user is using an HTTP proxy without SOCKS).
This means that for the intersection of HTTP Proxy users who do not
have a SOCKS proxy set who ALSO use private sites that are actually
signed by a CA in the default root set may still have these "private"
certs submitted to the observatory.
We don't expect this set to be very large, but just in case, the EFF
intends to do server-side scrubbing if the private_opt_in post
parameter is set to false. Hopefully this will not be needed, but
we'll need to see what the prevalance of this case is in the field to
be sure.

@_date: 2011-06-04 12:09:52
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
If this option is set, the browser addon itself will try to check the
server IP and determine if it is RFC1918 ("Address Allocation for
Private Internets"). If the domain resolves to a private range, it is
considered private. The browser should be able to perform this lookup
so long as the user isn't *only* using an HTTP proxy.
Are you saying that you expect there to be a lot of publicly routable
IP addresses that use certificates signed by CAs in the default root
set out there? How can these be considered private? They are already
in the observatory DB from the IPv4 scan..
Or are you saying you expect there to be a lot of HTTP proxy users out
there who do not have a SOCKS proxy but who access certs signed by
public CAs?
EFF only needs to do this query if the browser could not (because it
was using an HTTP proxy without a SOCKS proxy). Does this scare you
less or more? I'm getting confused by the reactions in this thread.

@_date: 2011-06-04 12:56:15
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
I think you missed the first half of my email where I explicitly said
EFF shouldn't need to do this under normal circumstances. It only
needs to do this when the browser fails to do so itself. Do you expect
this to be common?
The observatory itself could also be running a tor client for these
resolutions, just in case they do end up being common.
P.S. When the browser does attempt to do these resolutions, should
they be done via Tor or via whatever local resolver/proxy was used to
access the domain? Doing it via Tor exposes potentially private names
to exits, but doing it locally will fail to detect attacks where the
MITM is able to operate on the user's own infrastructure (because they
can just make sure that the domains they MITM resolve to RFC1918).

@_date: 2011-06-16 11:07:55
@_author: Mike Perry 
@_subject: [tor-talk] Good email services? 
Thus spake andre76 at fastmail.fm (andre76 at fastmail.fm):
This is getting to be a FAQ, though the extra restrictions you put
here probably means you've got like 0 options. However, there are at
least a handful of SSL-secured webmail services.
AFAIK, all of these support encryption and all have free accounts:
gmail.com (sometimes requires SMS at random intervals)
Any volunteers to create a wiki page or add it to our current wiki
FAQ? Bonus points for listing which ones also support POPS/IMAPS.

@_date: 2011-06-21 11:20:07
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake tagnaq (tagnaq at gmail.com):
Ok, I probably should recap these scenarios here. I realized I forgot
to reply to you.
To make sure we understand one another (and everyone else understands
us): the remaining information disclosure scenarios we're talking
about are limited to two:
1. User has a private network whose DNS is set to resolve private
names to public IP addresses which normally would not have been
reachable in the IPv4 scan, and whose TLS certs are also signed by a
public trusted root CA. This is a weird setup, but it's a big world.
I guess it could exist somewhere.
2. User has private network on RFC 1918 space, yet uses an HTTP proxy
to access it (which means we can't tell that it is private IP space).
Said user is also using TLS certs signed by a public trusted root CA.
This config is less weird, and detectable by us. It makes me think we
should handle this user specially somehow?
Your point is that in these two cases, with the default protection
mechanisms defined in
these two users could still end up sending their public-yet-private
certs to EFF.
Should we somehow warn the HTTP proxy user about the possibility of
private TLS certs being submitted if they try to opt-in to the
This seems to be a reasonable option to me. I've added this to our
spec page above.
But is there a better option? Do you think it might be likely that
either of these users will disable OCSP for these certs, or otherwise
indicate anything about these public-yet-private certs that we can
detect in their config?
And is there anything else?

@_date: 2011-06-21 14:17:16
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
Ugh, sorry. You've said this a couple times now, but each time I had
assumed that when OpenSSH added SOCKS4A+5, they also added this
extension. Turns out you are right, they did not. You still can't do
resolutions, so this type of SOCKS proxy is the same as an HTTP Proxy
in that respect.. Ugh.
Yes, the added attack potential worries me too. Does this tradeoff
mean we should turn on "[ ] Check/submit certificates for private DNS
domains" by default? I think it might.
The answer depends on if we prioritize providing protection over
automatically withholding info that may be private. It is my feeling
that since this feature is meant to be opt-in, we should prioritize

@_date: 2011-03-08 19:13:42
@_author: Mike Perry 
@_subject: [tor-talk] blog.torproject.org - SSL certificate expired 
Thus spake Daniel Bryg (fermenthor at gmail.com):
Thanks, this has been taken care of. Sorry for the delay.

@_date: 2011-03-10 00:34:56
@_author: Mike Perry 
@_subject: [tor-talk] Making TOR exit-node IP address configurable 
Thus spake Moritz Bartl (moritz at torservers.net):
Exactly. Perhaps we should just check for RFC 3514 compliance at entry
nodes? :)
In all seriousness, the only way this can fly is if it is transparent
to the user, and doesn't ever actually block their activity.
I described how such a system could work here, but someone would have
to build it:
Any other system that tries to only break "just some kind" of
malicious traffic is bound to fail (and in rather hilarious ways).
Skynet just isn't that good yet.  Maybe some day the machines will
protect us from ourselves, but that day is not today.

@_date: 2011-03-20 17:58:06
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
I've spent some time working with the EFF recently to build a
distributed version of the SSL Observatory
( to be included with HTTPS
Everywhere. The draft API and design sketch is here:
The brief summary is that it will be submitting rare TLS certificates
through Tor to EFF for analysis and storage. We will also leverage the
database of certificates to provide notification in the event of
targeted MITM attacks**.
I am trying to decide if this is a bad thing to enable by default for
On the one hand, we have taken a lot of precautions to ensure that the
EFF is given the minimal amount of useful information, and retains
even less (such as no high-resolution timing information). The EFF is
extremely trustworthy, and has an army of lawyers on-hand to defend
against subpoenas or legal requests for excessive data retention.
Furthermore, the OCSP revocation servers have just as much or more
information, and who knows what they do with this same information.
In all likelihood, they probably sell it to netcraft and whoever else.
It is valuable.
On the other hand, the EFF intends to publish as much of the
information gathered with this system as it can for analysis by the
wider Internet community. This will likely include raw SQL dumps of
the resulting certificate database.
So, the question for the bikeshed discussion then is what should the
default state of this collection be? Our thought is to provide
HTTPS-Everywhere users with this dialog on first-run
However, I'm not sure that this is going to work for Tor Browser
Bundle users (which ships with HTTPS Everywhere) who may have the TBB
on readonly USB keys or live cds.  They may end up being asked each
time they start.
Is this a decent compromise? The other option is to not even bother to
ask users who have a working tor installed, on the assumption that
since we can submit certs through tor, it is always safe to do so. We
may end up doing this instead of always asking them. Is this wrong? If
so, why?
** Due to a limitation of the Firefox APIs, we cannot actually prevent
the load of any content that is delivered by a MITM attacker. We will
resort to an after-the-fact message that will inform you of compromise
and advise you get to a more secure Internet connection immediately to
change your password.
Perspectives ( has this same limitation,
but it uses DOM manipulation to make you believe it has actually
prevented the page load, when in fact your authentication tokens have
also already been transmitted at the time of notification of MITM.
Perspectives also has just enough differences that we decided to work
on a different implementation. The EFF wants to turn every user into a
vantage point, so that we can gather information on the extent of
targeted, CA-authenticated MITM events. They want to find a silver
bullet against the CA model, to conclusively prove that it can't
possibly provide the security properties it claims. The Perspectives
protocol is not set up to do this.

@_date: 2011-03-20 20:05:44
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake coderman (coderman at gmail.com):
Leaving this for pde and/or Seth.
The reality is we won't have the Firefox APIs to actually prevent
content load after certificate inspection any time soon, so it's not
feasible to trust this as your only security measure. Monsterous hacks
might make this possible sooner, though...
On a timescale where we can provide real security rather than just
analysis and post-pwnage notification, we can build multiple databases
to submit to/query, just like Perspectives. There's also no real reason why you can't use both Perspectives and
HTTPS-Everywhere. Then you can get both of our half-assed
after-the-fact notifications that you were owned :)

@_date: 2011-03-21 04:03:19
@_author: Mike Perry 
@_subject: [tor-talk] Torbutton 1.3.2-alpha released 
Torbutton 1.3.2-alpha has been released at:
This release features several fixes for some annoying Firefox 4
exceptions and popup issues, as well as a score of other bugfixes.
I am hoping that this will be the last release before 1.4.0, so please
report any issues you notice on our bugtracker:
Here is the complete changelog:
* bug 1624: Use nsIDOMCrypto::logout() instead of the SSLv2 pref hack
* bug 1999: Disable tor:// urls by default
* bug 1968: Reset window.name on tor toggle
* bug 2148: Make refspoofing more uniform
* bug 2359: Fix XHTML DTD errors on FF4
* bugs 2465+2421: Fix javascript hook exceptions+issues in FF4.0
* bug 2458: Opt out of Firefox addon usage pings
* bug 2377: Limit the Google captcha cookies copied between google TLDs
* bug 2491: Clean up checks for when to jar protected cookies
* bug 1110: Add popup to ask if we should spoof English Accept: headers
* misc: Remove a noisy FF2 nsICookieManager2 fallback check.

@_date: 2011-03-21 17:09:38
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
The problem with 171 (SOCKS username/password to split streams across
different circuits, for those playing at home) is that Firefox also
lacks username and password fields in the proxy APIs for SOCKS, so we
cannot do this for anyone except for TBB users.
But, if the EFF runs an exit enclave at observatory.eff.org, shouldn't
this solve the same-circuit correlation problem? Tor should prefer
using that exit enclave in all cases when it is up in this case.

@_date: 2011-03-21 17:16:25
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
Well, we are planning on shipping a list of the most popular TLS leaf
fingerprints in the addon itself to reduce load on the observatory.
This would be what "rare" means for deciding when to submit.
But this is still likely too common to ask every time. For those users, yes. But even if only one user is submitting
self-signed certs, each observatory instance can also check the site
itself, much like Perspectives.

@_date: 2011-03-21 20:16:10
@_author: Mike Perry 
@_subject: [tor-talk] Iran cracks down on web dissident technology 
Thus spake Aplin, Justin M (jmaplin at ufl.edu):
By the way, for people reading this doing advocacy in the field, this
is probably the worst justification you can give to people, even
technical people.
As soon as you tell someone to audit the code themselves, you are
placing a huge burden on their shoulders that they must deal with
somehow before they can trust it, even if they don't begin to believe
you are implicitly signaling something to them that you can't say out
Roger has spent a lot of time experimenting with people's reactions to
his answers to questions like "So, is tor secure?" or "Are there
really no back doors?" and the response that invariably freaked
already uneasy people out was "The source code is available. Check for
Whenever he told people this, invariably they assumed that he was
secretly trying to tell them that there was in fact a backdoor, and
that he was implicitly asking them to find it. He actually got the
best responses when he essentially just told people, "Sure it's
secure. Trust me, I wrote it.".
AFAIK, though, he has not extensively tested the more nuanced response
that Paul gave in his replies. But I think that if you can shorten
that down, it can work too, possibly better.
For example: "Trust the community. So many different people have
worked on, volunteered for, attacked, reviewed, and researched
tor-related topics from so many different institutions and backgrounds
that it is *the* most extensively studied and independently reviewed
anonymous communications system ever designed, let alone built. This
makes it secure."
But perhaps the average person's eyes will *still* glaze over half way
through that sentence, and you may be better off starting with Roger's
empirical favorite of "Oh, trust me, it's secure" first :)

@_date: 2011-03-21 22:09:43
@_author: Mike Perry 
@_subject: [tor-talk] Iran cracks down on web dissident technology 
Thus spake Joe Btfsplk (joebtfsplk at gmx.com):
Despite Lucky closing the thread in response to your conspiracy theory
in favor more productive matters, I didn't get enough sleep last night
to be productive, so I feel like trying to inject some reason into
this thread.
To distill your argument down, you've said so far:
1. Tor was/is funded by a government.
2. Governments only act out of self-interest.
3. Governments often have ulterior movies.
4. Governments have inconceivable power.
You've argued that   and  together means that Tor cannot be
trusted. It appears we may have dissuaded you from this, because of
the fact that so many other individuals and entities have also had a
hand in Tor research and development.
You seem to have somewhat independently argued that  means that Tor
cannot be trusted against (any) large government(s). This,
unfortunately, may be true for some governments. Extremely well funded
adversaries that are able to observe large portions of the Internet
can probably break aspects of Tor and may be able to deanonymize
users. This is why the core tor program currently has a version number
of 0.2.x and comes with a warning that it is not to be used for
"strong anonymity". (Though I personally don't believe any adversary
can reliably deanonymize *all* tor users, for similar reasons as
detailed here: but attacks on anonymity are subtle and cumulative in nature).
The goal of Tor is to balance the interests of as many different
parties as possible to provide distributed trust, and to raise the
amount of resources that any one adversary must have before it can
compromise the network. Academic research also focuses on ways to
improve the network characteristics of tor to defend against
wide-scale observation (think dummy traffic and Paul's topology
research), but so far none of these approaches has proved either
robust or lightweight enough to actually deploy.
In fact, the best known way we have right now to improve anonymity is
to support more users, and more *types* of users. See:
This is also why it is not the case that point 2 means that Tor is
necessarily broken just because The Tor Project has done the legwork
to show these and other groups how a robust Tor is useful for them.
The Tor Project has done this because every new entity that believes
Tor is useful makes Tor stronger and more anonymous for every other
Most of the governmental entities that like Tor either like it because
they use it (think FBI stings, investigative research, and soldiers
deployed overseas), or because they understand that a "liberation
technology" like Tor is both great PR for them, and a great tool in
diplomacy and statecraft, to deploy in countries where it is clear
that better information flows will weaken or even topple unfriendly
These are good enough first-order benefits to discount some ulterior
bait-and-switch conspiratorial motives, I believe. Couple this with
the fact that the real serious "cybersecurity" threats come not from
tor, but from sophisticated, well funded adversaries that have their
own botnets that can leverage the same properties of the Internet
that tor leverages, regardless of tor's existence.
Once this is understood, there isn't really a whole lot of downside to
government entities encouraging a stronger Tor that these entities
don't already have to deal with in other ways (such as better
information security).
Of course, it still is concerning that any entity that can fit into
argument  might be able to break tor, but hey, it's still 0.2.x.
We're working on it ;).

@_date: 2011-03-22 21:19:46
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
In Firefox 3.x, yes. But the threading support in FF4 is such that we
cannot expect to have access to very many XPCOM interfaces or share JS
objects with new threads, and post-FF4 we may be stuck with the XUL
version of WebWorker threads, which have even less access. Not the way
we want to go, I think.
We should patch TBB to send a u+p and try to get this patch merged
upstream for post-FF4.
Yeah, we need to start issuing requests for the IP, because the DNS
request itself is an anonymity set fragmentation issue (since it won't
go to the enclave, but will be mixed with other tor traffic). The EFF
says using the IP for submission should be doable: the IP address they
plan to use should be stable in the medium term.

@_date: 2011-03-23 16:14:42
@_author: Mike Perry 
@_subject: [tor-talk] How evil is TLS cert collection? 
Thus spake Robert Ransom (rransom.8774 at gmail.com):
Supposedly some CAs will sign certs for IPs. We can alternatively
distribute a self-signed cert with the xpi and install it
pragmatically. Not sure which route to take. The latter is more
secure, but the cert will show up in the user's "trusted certs" window
in Firefox, which may or may not bother people.

@_date: 2011-05-01 21:06:40
@_author: Mike Perry 
@_subject: [tor-talk] Torbutton 1.3.3-alpha released 
Torbutton 1.3.3-alpha has been released at:
It should also be possible to update from 1.3.x by using Firefox's
addon update feature.
This release has been issued primarily to address a mixup with the
maxVersion field of Torbutton 1.3.2-alpha, which prevented Torbutton
from working with Firefox 4.0.1.
When used with Firefox 4 or the alpha Tor Browser Bundles, it also
features support for youtube videos in HTML5, but you must currently
opt-in for youtube to provide you with HTML5 video as opposed to
flash: Here is the complete changelog:
 * bug 2777: Clear OCSP cache on tor toggle
 * bug 2832: Update spoofed user agent to Firefox 4.0
 * bug 2838: Make cookie protections dialog work
 * bug 2819: Move JS hooks to new JS1.8.5 hooking support on FF4.
 * bug 3042: Fix version compatibility issue with FF4.0.1+

@_date: 2011-05-01 23:30:37
@_author: Mike Perry 
@_subject: [tor-talk] exit bandwidth question 
Thus spake Olaf Selke (olaf.selke at blutmagie.de):
We are also experimenting with throttling high-volume flows at entry
guards through consensus parameters for the followup work to this blog
I'd guess that because of your default exit policy, you are seeing the
decrease due to throttling of bittorrent traffic.
Here is the experiment log if you'd like to check for correlation. I'd
be interested to hear if all of these correlate to decrease volume, or
just some of them:
perconnbwrate=40960 perconnbwburst=10485760
bwconn start: Fri Apr 22 09:57:34 UTC 2011
bwconn end: Sun Apr 24 01:57:57 UTC 2011
perconnbwrate=40960 perconnbwburst=104857600
bwconn start: Tue Apr 26 11:32:40 UTC 2011
bwconn end: Fri Apr 29 05:26:20 UTC 2011
perconnbwrate=20480 perconnbwburst=104857600
bwconn start: Fri Apr 29 05:26:20 UTC 2011
bwconn end: Sun May  1 21:23:18 UTC 2011
I've been meaning to create a public "experiment board" wiki page
somewhere with this and other experiment info, but I've been meaning
to do a lot of things these days.

@_date: 2011-05-02 06:44:06
@_author: Mike Perry 
@_subject: [tor-talk] To Toggle, or not to Toggle: The End of Torbutton 
Thus spake anonym (anonym at lavabit.com):
Yes. This is the way we should go. In fact, it looks like setting the
about:config extensions.enabledScopes may be all you need:
We will be disabling that for TBB builds. You'll just need to flip it

@_date: 2011-05-30 13:49:39
@_author: Mike Perry 
@_subject: [tor-talk] Police was here - whats next? 
Thus spake Clemens Eisserer (linuxhippy at gmail.com):
What country did this happen in? What city?

@_date: 2011-05-31 13:34:06
@_author: Mike Perry 
@_subject: [tor-talk] Police was here - whats next? 
Thus spake andrew at torproject.org (andrew at torproject.org):
Expanding on this, if the reason that your node was seized was because
it transmitted something forbidden (leaked, classified, copyrighted,
illegal, etc), having a copy of that material in your possession is
just about the stupidest thing you could do.
For most situations, this immediately makes you just as guilty as
whoever first downloaded the material. Even if it is encrypted, your
key material can be leaked, extracted, and/or compelled in many
situations you probably have not thought about, or at least you
certainly did not mention here.
Beyond this, in the US, storing any communications data is also
illegal with narrow exception:
What you are describing above is probably outside of the exceptions in
(2)(a)(i) for US folks.
The best answer is: Don't run exits co-mingled with your personal
data or on home connections.

@_date: 2011-10-10 13:07:25
@_author: Mike Perry 
@_subject: [tor-talk] Tor Browser Bundle: PGP encryption built-in? 
Thus spake Arturo Filast? (art at globaleaks.org):
I think the enigmail vulnerability surface is way more manageable than
an arbitrary webby one, though perhaps less useful.
The problem with a browser extension is that the very thing that makes
it useful is what makes it so risky. A GPG plugin of any kind becomes
a vector for all sorts of nasty web attacks that would have normally
been stopped by the server, such as XSS, XSRF, and various sorts of
webbugs. On top of that, you need to protect against XUL XSS (which
yields arbitrary code exec), as well as the privacy issues of
leaking side-channels about the existence of certain keys in an
otherwise anonymous browsing session.
I'm not sure exactly what the FireGPG author expects to gain my moving
all of this stuff to NPAPI. A naive use of his NPAPI code could easily
lead to an *increase* in the vulnerability surface, not a decrease.
And that's even assuming he codes the NPAPI bits safely.
I think your first task is to find out exactly what this guy thinks he
did wrong in JS+XPCOM, and why moving to a more complicated language
like C++ will make it better, and not worse.
If he won't answer or won't tell you, stay the hell away from his
I think Robert is negative because the idea just sets off all sorts of
warning bells. I definitely agree that this doesn't make the idea not worth doing.
Personally, I think it would be way easier and safer to devote the
effort into securing Thunderbird for GPG and Tor so we could just
bundle that, but I understand the benefits and appeal of having
everything in the browser.
But man, tread with care. GPG-in-a-browser is like a minefield of
killer beehives in a jungle filled with wild dogs. Oh yeah, and when
the dogs bark, they shoot bees at you.

@_date: 2011-10-10 19:07:19
@_author: Mike Perry 
@_subject: [tor-talk] Ideas to securely implement PGP encryption/decryption 
Thus spake Moritz Bartl (moritz at torservers.net):
Actually, these attacks are generally prohibited by strong isolation
between the content script and the XUL script. In XUL, you can read
the ciphertext, extract it, decrypt it, and display it in a protected
XUL window without introducing risk, IF all steps are done properly.
There are some subtleties here involving special priviledge isolation
wrappers (via XPCSafeJSObjectWrapper and others), but there is no
fundamental reason that it is impossible. Just complicated and tricky,
in either NPAPI and XPCOM (but probably worse with NPAPI, because you
won't get the priviledge isolation wrappers for free like XPCOM).
The one exception is deception: One could imagine all manner of
clickjacking-esque games that could be designed by malicious
javascript to capture context clicks or mouseovers to create a fake
password menu. Authentication and decryption UI should be designed to
exist primarily outside of the content area for this reason.

@_date: 2011-10-10 22:47:09
@_author: Mike Perry 
@_subject: [tor-talk] Ideas to securely implement PGP encryption/decryption 
I more or less give this plan my stamp of approval. Just mind the
gaps, and careful with NPAPI! I am able to review and advise XUL+XPCOM
code for security.. But for NPAPI, we'll need someone else.
Anyone on-list have any expertise with processing untrusted DOM
data in NPAPI, and then rendering output safely in browser windows?
Sounds like a minefield to me, but perhaps it's safer and easier than
I expect?
Thus spake Fabio Pietrosanti (naif) (lists at infosecurity.ch):

@_date: 2011-10-11 13:37:27
@_author: Mike Perry 
@_subject: [tor-talk] Ideas to securely implement PGP encryption/decryption 
Thus spake Moritz Bartl (moritz at torservers.net):
Yes, good to clarify. I was assuming that all encryption and
decryption UI would be 100% independent of the normal content window,
aside from perhaps a context menu (though even that is prone to
deception issues and clickjacking).
The UI should not provide a way to encrypt text that has already been
typed into a form. Even non-malicious JS can screw you for that user
model. For example, Gmail will save plaintext drafts of your email
periodically "just in case", which will defeat the purpose of the
addon entirely.
The UI should open an alternate XUL window for user input using a
context menu or toolbar button, and should instruct users not to type
sensitive plaintext into existing form boxes prior to use of the XUL
Lots of tough UI issues to solve on the encryption side, it seems.
Perhaps almost as tricky as safely handling the potential hostile
input and safely displaying the output for the decryption side.

@_date: 2011-10-11 14:19:36
@_author: Mike Perry 
@_subject: [tor-talk] Tor Browser Bundle: Usability Improvement Proposal 
Thus spake Greg Kalitnikoff (kalitnikoff at privatdemail.net):
If you speak Russian, you may want to point these people at the new
Tor Browser Design doc:
 especially the
requirements section:
We're starting to see a few different browser bundles arising due to
people not being satisfied with our choice of Firefox and for various
other operational reasons. One variant Andrew saw took the smallest web
browser they could find, embedded a Tor client in it, and provided the
resulting 2M package as something like "MicroTor".
They certainly sound useful, but the problem with these approaches is
that they often don't even state if they've done the *bare minimum*
audit to ensure all browser activity actually uses the proxy settings
of their pet browser:
For micro-browsers especially (even popular ones like Google Chrome),
you're likely to see them relying on OS functionality as opposed to
built-in functionality. In the case of the SSL stack, this can mean
immediate proxy bypass for SSL connections and/or OCSP data. See:
All of this is not to mention the efforts we're investing into
ensuring the Tor Browser has good privacy properties, too:

@_date: 2011-10-13 01:48:00
@_author: Mike Perry 
@_subject: [tor-talk] notice - newer ver available just after install 
Thus spake Koh Choon Lin (2choonlin at gmail.com):
What URL are you guys being sent to on check.torproject.org? Have you
tried restarting Tor Browser in the past couple hours? You need to
restart to actually perform the versioncheck...

@_date: 2011-10-13 01:59:31
@_author: Mike Perry 
@_subject: [tor-talk] Convergence.io + Tor 
This was discussed before, though in a random thread.
See: Thus spake Roc Admin (onionroutor at gmail.com):

@_date: 2011-10-13 10:35:38
@_author: Mike Perry 
@_subject: [tor-talk] notice - newer ver available just after install 
Thus spake Marco Bonetti (sid77 at slackware.it):
Yes, we made this page warn because all TBBs fetching it without
adding uptodate=1 were assumed to be the old, vulnerable versions.
In hindsight, what we should have done was also create a small=2 page
with no warning, for use as the default in new TBBs when the versions
file is inaccessible. I didn't expect this case to happen, but I also
didn't expect deployment of  to span 24 hours..

@_date: 2011-10-14 13:07:10
@_author: Mike Perry 
@_subject: [tor-talk] still problems - update available 
Thus spake Joe Btfsplk (joebtfsplk at gmx.com):
The process is driven by Torbutton, and works like this:
1. Download 2. Compare each entry in that list against the about:config value
3a. If we found a match in the list, load
3b. If we did not find a match in the list, load
3c. If there was a parse error or the download failed, load the
default homepage, which should be
In the case of 3c, there should be a Torbutton WARN message in
Tools->Web Developer->Error Console that tells you the nature of the
Which check.tp.o URL is your TBB loading?
What is the value of torbrowser.version?
Is there anything in the Error Console?

@_date: 2011-10-14 17:07:34
@_author: Mike Perry 
@_subject: [tor-talk] still problems - update available 
Thus spake Joe Btfsplk (joebtfsplk at gmx.com):
Yeah, we actually have a bug for the user_pref issue:
I would argue that you're actually doing it backwards. Firefox copies
over your existing files with the new version.
But you're right, the user_prefs bug makes this direction painful for
you if you want to keep your prefs.
We have disabled the Firefox update process because we've assumed that
Thandy will appear somehow. I am doubting that this will ever happen,
though, since we have no spare development effort to shepherd Thandy
into a release for at least the entire duration of the tor 0.2.3.x/TBB
2.3.x release cycle, and possibly beyond..
I've just created this ticket for me to look into the Firerfox
updater, to see if we can just deploy that instead/as a stop-gap:
I would recommend just overwriting your old TBB dir with the new data.
Sometimes we change prefs+create new ones, which could cause bugs for
you when you copy old-over-new. I guess you're right in that we should
only be doing that for built-in prefs, too, though.
If there are a lot of prefs you need to change, you (or we) might also
be doing it wrong. Might I ask which ones you need to keep?

@_date: 2011-10-30 16:09:37
@_author: Mike Perry 
@_subject: [tor-talk] Freedom Hosting admin revealed by Anonymous - Tor 
Thus spake hikki at Safe-mail.net (hikki at Safe-mail.net):
Hahah. By involved, I guess you mean "mentioned near?" This post seems
to provide exactly enough evidence to clear me from having anything to
do with Freedom Hosting.
If you pull the netcraft data for any of my servers going back 15
years, you'll see I've never put a *BSD machine on the Internet. You
will, however, find me trolling various BSD mailinglists about
installer issues, lack of update authentication, build issues, and
poor driver support.. You see, I've never even gotten the shit to
install on anything other than one computer I found in a dumpster, and
it had a broken ethernet driver that I could not even recompile the
source to fix. I reinstalled the computer with a proper OS, and then
put it back in the dumpster.
I suspect I'm just being trolled because I seem to be interested in
personal and legal insulation for my professional activity. Why am I
interested in that? Oh I dunno, maybe because I work on an anonymity
network and run some of its exit infrastructure, and I knew that
sooner or later it would mean having to deal with trolls like these,
or worse?
Anyways, I'd like to thank "Anonymous" for clearing my name, even if
they did have to do so in the most libelous way they could come up
with :). Good show, guys. Good show. *slow clap*.
Yeah, the whole network. Way to read between the lines on some solid
investigative reporting. Pastebin: It's like the New York Times. You
can take that shit to work.

@_date: 2011-09-05 17:40:40
@_author: Mike Perry 
@_subject: [tor-talk] TBB 2.2.32 & Automatic Updates 
Thus spake Erinn Clark (erinn at torproject.org):
Btw, I plan on bypassing this enabledScopes setting and solving this a
different way. I hope to have the solution ready by the end of the

@_date: 2011-09-05 18:22:07
@_author: Mike Perry 
@_subject: [tor-talk] TBB 2.2.32 & Automatic Updates 
Thus spake cgp3cg (cgp3cg at gmail.com):
Are you sure about this? Torbutton should be handling this under
Preferences->Security Settings->Forms..
The first checkbox is checked for you, yes?
If not, this could be a regression against Torbutton.. But I haven't
experienced it, as far as I know.
Where/how did you observe the password saving?

@_date: 2011-09-05 18:36:34
@_author: Mike Perry 
@_subject: [tor-talk] TBB 2.2.32 & Automatic Updates 
Thus spake sigi (tornode at cpunk.de):
You are misunderstanding the situation. See other replies.
Please bear with us. The DigiNotar fiasco forced us to release the
Firefox 6-based TBBs as "stable" at least 2 weeks early (if not a full
month), because we were unable to do source modifications to Firefox
3.6 on Windows to properly deal with the certificate updates and the
initial "Dutch exemption".
We would appreciate it if you tried to help us by diagnosing bugs and
issues rather than calling our integrity into question over bugs that
slipped in during a very high pressure situation.
We hope to better answer these questions in a Tor Browser Bundle
design document. Just one of the many other items that were supposed
to go into a new "stable" release that got pushed aside due to recent

@_date: 2011-09-05 20:29:41
@_author: Mike Perry 
@_subject: [tor-talk] TBB 2.2.32 & Automatic Updates 
Thus spake cgp3cg (cgp3cg at gmail.com):
Please keep an eye on this. We are seeing some weird non-determinism
crop up all over the place wrt prefs. It is possible that it is
because we are using user_pref() calls as opposed to pref() calls in
our version of prefs.js, and there is some race condition or other
failure in a preference observer that is causing some of the prefs to
randomly fail to apply:

@_date: 2011-09-06 13:23:52
@_author: Mike Perry 
@_subject: [tor-talk] Using public Wi-Fi for access 
Thus spake David Carlson (carlson.dl at sbcglobal.net):
You are entirely correct in your guess as to how the system works,
authenticates you, and tracks you.
However, this does not mean that you're "compromised". If you use a
default Tor, the wifi owner will at best see you log in, and then see
that you are Tor user, and not much after that. If you are using Tor
with bridges, they will likely not know even this much.
If you are on a Linux system, you can get the package 'macchanger',
which can spoof your mac address to valid addresses by arbitrary
vendors.  This can alleviate the risk of your laptop being tracked
from access point to access point. Similar utilities exist for
Windows. For MacOS, Steve Jobs deemed that you must be tracked at all
times (he likes to 'Think Different'), unless you decide to purchase a
USB wifi device, in which case he will allow you to change the MAC
address from the command line using 'ifconfig'.
However, a serious adversary may still be able to fingerprint your
wireless driver based on the 802.11 protocol headers[1], or if there
is a big white van parked nearby, by the actual radio signature of
your specific device[2]. The former will not specifically deanonymize
your device, but likely just narrow it down to chipset and possibly
driver version. The exact capabilities of latter in the field are not
widely known. Ambient noise and other devices may likely interfere
with RF fingerprinting on a large scale. 1. 2.

@_date: 2011-09-08 00:05:31
@_author: Mike Perry 
@_subject: [tor-talk] Tor spying 
Thus spake Greg Kalitnikoff (kalitnikoff at privatdemail.net):
Yes. We haven't included Perspectives and related pre-Convergence
addons because the Firefox APIs are not sophisticated enough to notify
the user of SSL MITM before your browser sent authentication data. They
expect to improve them soon, but confusion still remains:
IIRC, Moxie's Convergence bypasses the API problem by creating a
synthetic proxy that MITMs you and re-signs your HTTPS certificates as
either "good" or "bad" internally (after notary verification) to
prevent the authentication transmission. It also makes use of OpenSSL
functions for certificate inspection through js-ctypes, which adds a
little more complexity into the mix.
While functional, this approach needs to be reviewed and digested a
bit by the security community before we jump right on board and toss
it in. It will also require some testing and auditing to ensure it
properly behaves with Tor's proxy in all cases. We don't have to do this testing ourselves (indeed, it is not high
priority right now - we don't even have a trac ticket for it), but
we'd like an external audit to be well documented and thorough if we
were to rely on it. The audit should also be done with Tor Browser
AFAIK, Tor Browser Bundle users should be able to install his XPI and
use it now, but beware that doing so will reduce your anonymity set to
exit node observers (due to the presumably low adoption rate of
Convergence today).

@_date: 2011-09-09 20:42:14
@_author: Mike Perry 
@_subject: [tor-talk] TBB 2.2.32 & Automatic Updates 
Thus spake sigi (tornode at cpunk.de):
I realized I neglected to mention that you can view the philosophical
underpinnings of our approach here:
Much of that thinking will be reflected in the design document.

@_date: 2011-09-10 14:24:30
@_author: Mike Perry 
@_subject: [tor-talk] TBB 2.2.32 & Connection issues 
Thus spake David Carlson (carlson.dl at sbcglobal.net):
This could be a firewall issue caused by the windows autoport feature.
In some cases, apps launching from USB sticks can be more restricted
in terms of internet access than hard disk apps normally would.
We disabled autoports on windows for this reason in today's release:

@_date: 2011-09-26 17:15:29
@_author: Mike Perry 
@_subject: [tor-talk] Tor and resumed TLS handshakes 
Thus spake Mansour Moufid (mansourmoufid at gmail.com):
Ugh, you are absolutely right.
Previously we dealt with SSL Session IDs only by clearing them upon
toggle, on the assumption that Tor sessions would be short lived. We
also clear them with the "New Identity" button in Tor Browser, so Tor
Browser users are not entirely defenseless.
However, you are right: We should not allow third parties to use TLS
session resumption from different top-level origins in Tor Browser.
I've created two tickets for this:
 and
The first ticket is to just disable TLS session resumption, and the
related HTTP Keep-Alive feature for Tor Browser Bundle 2.2.x. The
second ticket is to find a proper way to actually isolate these
features to the URL bar domain.  may not happen on a reasonable
timescale, but I set the milestone to TBB 2.3.x anyway.
Thanks for finding this!

@_date: 2011-09-26 17:18:52
@_author: Mike Perry 
@_subject: [tor-talk] Fw: Hotmail with Tor [is their a solution!?] 
Thus spake William Wrightman (williamwrightman at yahoo.com):
We cannot safely fix this issue for Torbutton. You must use Tor
Browser to access hotmail safely.
See  for details
on how to use hotmail with Torbutton unsafely, if you insist on using
Torbutton with regular Firefox.
Otherwise, download Tor Browser:

@_date: 2011-09-29 00:46:28
@_author: Mike Perry 
@_subject: [tor-talk] Fw: Hotmail with Tor [is their a solution!?] 
Thus spake William Wrightman (williamwrightman at yahoo.com):
The short answer is "maybe". Yes, you can cobble together your ad-hoc collection of addons to
prevent proxy bypass, and to clear your cookies, cache, DOM Storage,
SSL session IDs, HTTP Auth, and other identifiers. But then, most
likely, you are the *only* person with this request fingerprint and
browser behavior.
Do you still have anonymity? Probably. Most likely, nobody will put
the effort forth to fingerprint or correlate you (despite it being
laughably trivial). But still, we can't recommend this approach
because people who adopt it will be very linkable between different
For people who want anonymity, the safest option is the most popular
one. The problem with the ad-hoc addon approach is that even if it is
the most popular (and our numbers indicate that it may be), everyone
will do it slightly differently even with the same addons, and their
request patterns and browser behaviors will be very unique. In fact, if we ever see headlines about a Tor user compromised, my
money is on it being due to that user having used a custom or obsolete
Frankly, I do not believe we have the numbers right now for anyone to
give a shit about us. That much has been clear so far from our
relations with Mozilla, Adobe, and others. (Though, to their credit,
Google usually asks us "How do we help you actually matter?" rather
than dismissing us from the outset with "Who cares about Tor? Tell us
when you have something normal people can use.").
However, I may be a tiny bit cynical and jaded. YMMV.
