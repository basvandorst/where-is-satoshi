
@_date: 1994-11-17 14:20:07
@_author: Eric Hughes 
@_subject: Re: Islands in the Net 
From: tcmay (Timothy C. May)
   Language is an example we ought to look at more closely, as both of us
   have noted. In contrast to the "data structures" we love so much,
   natural language is a way of creating a more fluid data structure, a
   more nuanced statement.
The version of language though, that I was referring to were formal
languages, the stuff of DFA's (deterministic finite automata) and
push-down automata.  The advantage here is entirely in their
formality, in that precise interpretations of a formal language can be
made.  A great benefit derives from the explicit formulation of the
semantic scope of particular representation.  A formal language _can_
"mean exactly what I want it to mean, neither less nor more."
The social process of creating these interpretations ("meanings") and
getting everyone to agree upon them, however, can be tortuous.  We in
the ASCII world all agree that the number 65 represents the capital
letter 'A', but the letter 'A' is a further abstraction, albeit
universally shared in the literate world.  Interpretations of data
structures almost universally share this trait; they are reductions of
one abstraction to another.
Two major problems about compatibility can be framed in terms of
formal languages: the need for well-formed data structures and
the coexistence of multiple data structures.
The formal language notion of recognition is merely an algorithm for
set membership, the set being called the "language".  "Is this string
of symbols a member of the language or not?"  Is layman's terms, the
problem is with data corruptions.  While everyone knows data
corruption is a problem, deciding what data is corrupt and what is not
is sometimes difficult; witness the habitual arguments between client
and server writers about whose implementation is wrong.  Even fairly
clear standards like RFC-822 (mail) leave wide holes in
The second problem is less immediately pressing and ultimately more
important.  Given a string of bits, what exactly _does_ it refer to?
One can pass it through all the recognizers one has, but it may still
not be uniquely determined as being a particular kind of data.
Compatibility between data of different types will be of vital
importance to achieve systemic robustness.
Any set of languages, though, can be made compatible by prepending a
common language which acts as a dynamic type specifier.  Unix has
the beginnings of this with its " syntax for picking the
interpreter of an executable.  The problem with the Unix version
of this is that a particular interpretation binary is specified, not
an actual language specification.
   Natural language is often misinterpreted, hence the value of data
   structures. For example, I'm glad my financial accounting at my stock
   broker is handled with robust data structues, but I'm also glad to be
   able to communicate my goals and desires in a natural language.
Well, there's someone somewhere who understands both the formal
language and the natural language; it can be either oneself or an
intermediary.  Now the formal language may be quite flexible and
understandable and admit synonyms, but the contextual nature of human
languages mitigates against their strict interpretation.
One of the real-life characteristics of natural language which isn't
present in computer systems is a way of correcting misunderstandings.
If one person misunderstands another, further conversation can ensue.
If the computer interprets a command differently than the commander
intended, disaster can ensue.  Suppose I want to delete some data and
then I change my mind:
E: Computer, please get rid of this old correspondence.
C: OK, boss, all done.
E: No wait, I need one particular series of those back.
C: Sorry, all gone.
E: What do you mean, "all gone".
C: I destroyed them utterly.
E: Why?
C: You asked.
This stuff has been a theme in SF humor forever.  I find it highly
ironic that the computer industry, so steeped in SF themes, hasn't
thought more about how to alleviate this problem.
As a very basic example, consider the issue of data persistence.  No
standard operating system has at a deep level the notion of "backed-up
data".  The replication and redundancy could take many forms,
including tape, network disk, or data haven.  This particular issue is
going to be an obstacle for the widespread deployment of digital cash.
When a disk crash (hard or soft) means that you lose fungible money,
either the problem gets fixed or the system doesn't propagate.
   What's the common theme? Agents. Chunks of code which also have local
   processing power (brains, knowledge).
I don't think that agents have any relation to the problem of mapping
natural languages to formal languages.  Perhaps you mean something
else by this reference.
   Someone sent me private e-mail on this "Islands in the Net" topic, and
   talked about "payloads of data carrying their own instructions," in
   reference to the Telescript model of agents. (I wish he'd post his
   comments here!) This approach, also typified in some object-oriented
   approaches, seems to be the direction to go.
   > If steel were like software, there would be a knob on each beam that
   > allowed you to change, for example, the balance between hardness and
   > toughness.  Knobs mean random knob-twiddling.
   Actually, such "dynamic buildings" are becoming more common, I hear.
Now add knobs to the thermal expansion coefficients, the densities and
masses, the rates of oxidation, the stress-strain matrix elements,
etc.  If materials engineering were like software, we'd have _both_
nanotechnology and everybody living in trees because they didn't crash
so often.
   But the effect is to increase the "state space" which must be tested,
   and we are led to "testability" and "provable correctness" of
   programs, two interesting areas of programming. So far we've seen
   little application of these ideas to Cypherpunks interests.
Not unexpectedly, since these apply to all software, not just
cryptography software.
   > The more specific inspiration for the general form of the remailer
   > syntax is Jon Bentley's theme of "Little Languages".     I'm hopeful that the recent interest in TCL, Safe-TCL [...]
The "little" in little languages might be taken to mean "Not Turing
Complete".  His expository language, as I recall, is the language of
floating point numbers, which, alternately, is the question "how do
you write down a mantissa and an exponent."  Another little language
would be email addresses -- still not completely standardized,
although blessedly mostly so.
   We "locally clear" (approximately the same as "readable on its face")
   cash and commercial paper because of an assumption that forgery is
   difficult and unlikely. When forgery becomes common in some area,
   merchants carry lists of suspected numbers, IDs, etc., and the
   "readable on its face" criterion erodes.
These two are not the same at all!  "Readable on its face" means that
you can actually determine _entirely from the front side of the
document_ what the instrument says.  If there is an inclusion by
reference, then it's not readable on its face.  If there is a
condition external to the instrument, such as a condition of services
rendered, then it's not readable on its face, since some event
external to the instrument determines its value.
"Readable on its face" just means that one knows what is said, _not_
whether one believes it or not.  Those actions which turn the note
into a lie are called "conversions" as a group, and forgery is just
one form of conversion.  (Stealing a note is another.)
With a naive implementation of Chaum's blind signature, all you have
is a string of bits that can be verified only with some public key.
Nowhere in the bits themselves is there an explicit representation of
how much the bill is worth, what currency it's denominated in, when it
expires, who issued it, etc.  These signatures alone are not facially
   We need to find a way to get back to exploring the various nifty
   systems that are being described in the crypto papers, but which lack
   any real implementation. Fandom and enthusiasm will only carry so far in prototyping.  One of
the reasons that the remailers have attracted such interest is that
they do something proximately useful.  The questions of reliability
and utility that are mentioned here really are key to getting more
people trying out stuff.

@_date: 1994-11-17 14:30:28
@_author: Eric Hughes 
@_subject: Re: Islands in the Net 
Again, as a wanna-be programmer, I *try* to use binary formats only where
   the data or information is peculiar to a particular program; if there's a
   chance that it will be shared with something else, I try to use text.
The thing about all data is that most all of it eventually gets
shared, even the stuff that one program might think proprietary to
   >The general issue may be quite profound.  If we want to use textual
   >representations and general purpose text tools, then a digital
   >signature _qua_ authenticator loses its use, since a text tool,
   >because it is a general purpose text tool, cannot verify the
   >signature.
   Sorry - you lost me on this one. When I see a PGP signature on a posting,
   isn't that an ascii-fied digital signature? Doesn't the textual
   representation of that signature have value/meaning? The word "_qua_" (Latin, therefore italicized, represented by
underlining) roughly means "as".  The textual representation of a
signature *as* text has no value *as* a signature; it's just an
arbitrary collection of symbols.  The value of a signature only arises
when one performs a cryptographic operation on it, which by definition
is not a textual operation.
We all know the standard for displaying (length-limited) text.  But
the first characters at the top from left to right until the
end-of-line.  Move down one line and repeat.  But how does
one represent the _authentication_ information in text.  Typeface?
Color?  A vertical bar?  Enclosure?  One solution might simply be to discard before viewing any text whose
authentication information doesn't match, and then one can assume that
all information that looks like it's authenticated actually is
authenticated.  The PGP cleartext signature format, for example,
suffers seriously in facial readability because the signer is only
implicitly identified by the Key ID, and that's inside the armor

@_date: 1994-11-18 09:14:14
@_author: Eric Hughes 
@_subject: Re: Islands in the Net 
I have rearranged quotations from the original for more cogency of
   From: amanda ("Amanda Walker")
   Real assets are unique simply by virtue of being physical objects,
   and are liquid (in the long run) by virtue of having inherent
   value.
   The other is that to be successful, digital cash needs to be
   liquid.  For a token to be liquid, it must be backed by real
   assets.
This is just not what "liquid" means.  A liquid asset refers to the
speed with which it can be traded, not what kind of value it has.
"Liquid" is an adjective about timeliness, not about resolution.
There are plenty of liquid assets which don't have "real" value, the
"real" in "real estate", i.e. physical existence.  Promises, for
example, have value, but not "real" value.  A negotiable promissory
note, i.e. a promise to deliver money (money which may be real or
virtual), is a liquid asset, but not a real asset.
   Currency, however, has no inherent value.  Its only value lies in
   its being made up of unique tokens which can be exchanged for real
   assets.
Currency is not just paper money.  Currency also includes minted
specie (e.g. gold coins), other minted coins, silver certificates, and
federal reserve notes.  Sometimes currency _is_ the real asset, as in
Krugerrands.  Sometimes currency is a promise to deliver real assets,
as a silver certificate (the _old_ greenbacks).  Sometimes currency
represents a fiat value, as with today's greenbacks.
If you take a dollar bill to a Federal Reserve Bank, you won't be able
to turn that physical representation of a dollar of fiat currency into
anything that's still money and at the same time backed by real assets.
Just because it's a fiat currency doesn't make it any less a currency.
   Also, if it loses its ability to be exchanged for real assets it likewise    loses its value (e.g., Confederate dollars from the Civil War).
Under this reasoning, today's dollar bills should be worthless.  They
aren't.  Real assets are not the only form of value.
   Governments are the classical examples of entities which have
   sufficient resources to back a currency, although cartels in the
   private sector can also do so (VISA/ MasterCard, for example).
What currency do Visa or Master Card issue, perchance?
They don't issue currency.  Not all forms of money transfer involve
currency, though, so credit cards can move money around without moving
currency around.
The constitution of the USA reserve currency making power for Congress
and so far they haven't relinquished any of it.
   So far, though, no one has solved either the uniqueness problem or the    liquidity problem for digital cash.  As a result, it might be more    realistically be called "digital scrip", at least so far.
The uniqueness problem is entirely solved by what Chaum calls the
"spent number database" (a term I abhor).  Some of the other offline
techniques can be used to implement a tradeoff between uniqueness and
The problem you refer to as liquidity is really the backing problem.
It has also been solved, but not yet implemented.  All it takes is for
someone to incur a legal obligation to return money for digital cash,
which means a functioning digital cash business, of which there are
not yet any.
   Right now, digital currency only works by being a pointer to a
   token, not the token itself.
This is an insightful comment.  Its truth is unavoidable with any open
digital money transfer system.  The security of the scheme cannot rely
upon secure channels controlled by the bank (since it is an open
system), so the items transferred must be entirely informational.
Information doesn't obey conservation of mass, and so can't act as a

@_date: 1994-11-18 22:26:01
@_author: Eric Hughes 
@_subject: Re: Islands in the Net 
From: amanda ("Amanda Walker")
   Hmm.  I had thought about using "valuable," but that seemed too ambiguous.     "Negotiable" maybe?
The standard word for something that is worth something is "value".
If I sell you a promissory note, I exchange value for a note.  That
value can be in the form of cash, money on deposit, or even other
Negotiable means something else entirely.  A negotiable instrument is
an instrument that can be transferred with certain protections over
and above the transfer of a normal contractual obligations.  The
requisites for negotiability are, basically, those that make the
instrument suitable for sale in a secondary market.  The instrument
must be in writing (not oral).  It must be signed.  It must contain an
unconditional promise or an order for a particular sum of money and
must contain to other promises, orders, etc.  It must be payable to
order or to bearer.  The exact details may be found in your standard
commercial paper review guide.
   > Sometimes currency represents a fiat value, as with today's greenbacks.    It's not entirely a fiat value; in effect, it's backed by the
   strength of the economy.  Backing specifically refers to the relationship between the currency
and the issuer of the currency.  A fiat currency means that the
government created the currency by fiat, i.e. out of the blue.  A
dollar may derive value from the underlying economy, but it is not
backed by the economy, since the economy is not an entity.
   The difference between a ruble and a
   dollar was not the fiat value (they were the same, as I remember),
   but in the fact that it was a lot easier to exchange dollars for
   real assets.
Both rubles and dollars are fiat currencies, yes.  The dollar is a
relatively well managed currency and the ruble was not.  Therefore the
dollar was in greater demand than the ruble, and hence easier to use.
The difference is entirely in degree.
   For the record, I think that going off the gold standard was a bad
   idea, but growing up in the days of double-digit inflation probably
   gave me a biased opinion of floating currency.
Well, when you finance a war with an inflating fiat currency, that
leads to price increases.  Inflation is a tax which the government
does not need the IRS to collect.  Thankfully the foreign exchange
markets now quickly penalize any country that mismanages its currency
   While it has been somewhat eroded since the start of the Drug War,
   dollars are still exchangable for real assets, even though the
   government is no longer backing them directly.
The USA gov't, howeve, is backing the dollar still; it's just not
backing the dollar with specie (gold and silver metal).  The reason
that Confederate dollars are no longer valuable as money is that the
Confederate government no longer exists.  A fiat currency is backed by
several properties of active governments: legal tender laws, income
taxes paid in the national currency, procurements, etc.
   > What currency do Visa or Master Card issue, perchance?    Little plastic tokens that are accepted more places than the government's    paper and metal ones.  If it quacks like a duck...
A credit card is not a currency.  It is a means of payment.  Not all
means of payment are accomplished through currency.  One does not say,
for example, that checks are a currency merely because I can pay for
things with them.

@_date: 1994-11-19 06:41:45
@_author: Eric Hughes 
@_subject: Re: I Like ASCII, not MIME and Other Fancy Crap 
>Let's take that poll of what people use. I am curious.
   PC Eudora, Trumpet, the WS_* 'suite', Mosaic. [...]
OK, OK.  Let's NOT take that poll over the mailing list!
Kan't dictum certainly applies here; think about what would happen if
everyone else did the same.  Hint: there are over 600 addresses on the
mailing list.

@_date: 1994-11-19 07:41:36
@_author: Eric Hughes 
@_subject: Transaction costs in email system 
From: tcmay (Timothy C. May)
   My point? Much wheel-spinning. Like trying to read Amanda's "X11" GIF,
   and then wondering if my Netcom disk quota was being sucked up by a
   hidden file somewhere! Or jumping through hoops to download a
   PGP-encrypted note to my home machine, decrypting it, only to find a
   "Like, wow, this PGP sure is neat! Like, rock on, dude!" message
   awaiting me!
   [...]
   There's got to be a better way.
Tim's rant is one of the best illustrations of the effects of
transaction costs I've seen recently.  Tim's story perfectly
illustrates the reason why the computer software industry doesn't move
faster.  TYLISUM -- Ten Years Later I Still Use Microsoft.
The costs here are the of transaction of switching software systems.
In order to understand exactly what the transaction cost is, we posit
two worlds with respect to, say, email handling.
  World 1: The status quo.  Adequate capability.  Zero marginal
benefit.  This is the baseline we'll use to see if we can make an
  World 2: The amazing world of MIMEzine, the mail reader that sucks
out your brain into the computer.  A $500 value, but available to you
at no charge from your friendly ftp site!
Note that there is no monetary exchange in either of these worlds.  I
want to make it perfectly clear that transaction costs are usually
non-monetary, even though they are, in a strict sense, paid.  In
standard bad old economic analysis, the mail reader is a good
(i.e. worth something) that is available for no cost, and so clearly
would be used by everybody, because it's in everybody's best interest
to do so.  As Coase pointed out, not so fast.
In order to accurately assess the economic effect of this transaction,
you have to look at the whole thing, from start to finish.  Here is a
not so outlandish sequence.  Some of the following costs can be shared
between multiple transactions, some can't.
1.  Which friendly ftp site has MIMEzine?  Make an archie query.
  Cost: time to make an archie query
2.  How do I use archie?  Find out by reading the documentation.
  Cost: time to read documentation and figure out how you'd
  actually use it.
3.  How can I possibly find out what ftp site has the file?  Have
someone tell you Use archie.
  Cost: time to ask your computer friends, which you've spent a long
  time cultivating.  [See note below on this topic.]
  Alternate Cost: $25-$40 for one of those internet books.
4.  Download MIMEzine using ftp.
  Cost: see above for archie, and analogize.
5.  Compile MIMEzine for Unix.  (Binary distributions need not apply.)
  Cost: Ever ported?
6.  Learn how to use MIMEzine.
  Cost: time to read manual. time to correct screwups created by
inadvertent use of your previous mailreader's keyboard bindings.  time
spent hunting for instruction on how to set up "proactive filter
mocking", which you just have to use.
7.  Customize MIMEzine for you own environment.
  Cost: time to learn what all the little configurations options do.
time to choose a place in the directory structure.  time to twiddle
until you've got it just right.  8.  With probability p=3/4, decide that you absolutely can't stand
MIMEzine because of some braindead misfeature that makes you less
productive or because it's not really compatible with everything else
you're using.
  Cost: multiple all the preceding costs by 4=1/(1-p) to reflect that
you keep trying packages until you find one you like.  In my own
experience, I think a multiplier of 4 is on the low side.  9.  The benefits of using MIMEzine!
  Benefit: Savings of an hour or so a week handling your email.
Increased ability to handle content types you're not really interested
Transaction costs are _all_ of the costs above, since, of course, the
package is free, or rather, free(?).  To summarize:
World 1: The status quo.  Often acceptable.
World 2: The new technology.  Frequently an extreme time sink for what
you get out of it, even if it's free software.
Is it any wonder that software progresses slowly?
A note on friendship networks.  The need to have a network of friends
that you use to find out about computer stuff is an indicator of
serious lack of scalability in the technical and social design of
computer systems.  Not everyone has time to cultivate a techie
network, and most people don't.  This indicator is both a design
criterion and a test.  One should design software so that it can be
used without needing to ask question, and one can guage success in
this by seeing the number of questions that are actually asked.
There is much more to be said about categorization of transaction
costs and what can be done to alleviate them.  Later.

@_date: 1994-11-19 08:24:19
@_author: Eric Hughes 
@_subject: Re: Islands in the Net 
From: tcmay (Timothy C. May)
   For example, I tend toward Amanda's point of view, that credit cards
   "quack like a duck."
I don't think I can stress the following enough, but understanding the
following principle is necessary (not convenient, or helpful, or
replaceable) to understand how payment systems work:
** The most important thing about a transaction system is not how it
** works a transaction succeeds, but what happens when it fails.
Failure properties are more important than financial properties.  The
the expectations about float, rates of interest, time to clear and
settle, etc. are all meaningless if the failure properties don't
create a robust system.
Anyone at all can design a transaction system which works for
successful transactions, but designing for failure is enormously and
surprisingly difficult.  For example, here's a transaction system
that works only when there are no failures.  Everyone memorizes
the amount of money they have.  When two people do a transaction,
one persons increases their money by the same amount that another
person decreases theirs.
Now obviously this system doesn't work.  But the reason it doesn't
work is because of failures -- increasing balances between
transactions the obvious one.  Note that if all the implicit
constraints are met the naive system above does actually work.
Let me be blunt.  Most transaction systems people run by me show the
same naivete as those who design ciphers for the first time.  These
naive systems just won't work, and those that propose them just
haven't thought through the issues, and usually have been ignorantly
unaware that there are any.
"Why can't you just ..." is, unfortunately, most often said in mock
ignorance rather than humility.
I should note, though, that almost all these systems _do_ work
reasonably well under simple failures.  That means that they could be
deployed, but that they won't scale to many users.  Thus while they
might be suitable for a club like the hypothetical Hacker Privacy
League (which cypherpunks is _not_), they aren't suitable for
universal use.
As a primer and milestone, I'll make the bald assertion that
bankruptcy of the financial institution is one of the most important
failure modes to consider.  The argument that this almost never
happens is made only by those who haven't estimated the cost of this
failure more.  Once you have a good appreciation about bankruptcy and
payment systems, you'll be well on your way to having the mental
framework necessary for dealing with the issues.
I don't intend to lecture on this list about these issues.  These are
extremely arcane yet important details, and I hope to derive part of
my livelihood from them.
   When I make a purchase with my credit card, and
   the thing clears, both the merchant and I act as if we've just
   exchanged money.
To take this particular example, what happens if it doesn't clear?  Is
this different that, say, with a check or with cash?
   Anyway, there are many forms of "money," with many things that make
   the forms "money-like." A "means of payment" is only one of the functions of "money".  It is
useful to keep this clear.

@_date: 1994-11-28 13:53:29
@_author: Eric Hughes 
@_subject: Re: Transparent Email 
The big problem    with key distribution is the web of trust:  who gets to decide which keys    are good?
This whole area of key distribution has generated much confusion.  A
perfect world is described, and then everyone is assumed to
participate in achieving this world.  This approach of generality,
however, is notably more complicated than a world where responsibility
for security is partitioned, where  each user does not have to worry
about all the possible systemic security issues.
Proposition: You don't need to be responsible for making sure that the
other person is being spoofed; that's their responsibility.
A common situation where this proposition makes a significantly
simpler system is exactly in the case described, where you and your
email correspondents wish to exchange keys.  Suppose, in addition,
that you two met online and that your only channels of communication
are electronic.  The goal here is to create persistence of identity;
identification with a physical body is not needed.
In the PGP case you start with your own key, which you trust, then
look for a chain of signatures to the destination.  This chain can be
rather cumbersome to produce.  It's overkill, as well, since all you
really needed to know is that the key was not being translated on your
own end.  The PGP trust chain largely accomplishes that, true, but not
as simply as possible.
Alternatively, you save the first piece of email that you receive from
your correspondent; it has a digital signature on it.  Now _by
whatever means_, you obtain a public key by which to verify that
signatures on email you receive are the same.  You yourself need to
ensure that you aren't getting spoofed; you can do this by, say,
having your correspondent send mail to two different locations, or by
using a second channel to obtain the key by, or by using a PGP trust
chain, if one is available.
The original model for public key communications seems to have been
one channel with an interposer.  The real world is much more
complicated than that.  One can obtain good protection, at least as
good as a trust chain, by crossing organizational boundaries.  The
argument that trust chains are better because they are cryptographic
carries no weight; the decision at each link to make a signature is of
social, not cryptographic, character.
In particular, the design of PGP that ties key management inextricably
to encryption is bad and will contribute to an inflexibility that will
eventually sink PGP if it is not corrected.
   Perhaps we would have    a default web, which would have everyone's key in it.  This is a really bad idea.  Some "public" keys should not be made
public, but rather revealed only to the correspondent.  Forward
secrecy is the reason.  If the public key has never been in the
possession of an opponent, and assuming the results of the public key
operation yield little or no information about the modulus, then when
the keys are changed and destroyed, no amount of factoring can find
the private key because the public key isn't around to factor.

@_date: 1994-11-28 20:55:57
@_author: Eric Hughes 
@_subject: Re: Transparent Email 
Ok, I should start off by saying I'm not sure I followed everything Eric    said in his post, so this might not be a great answer to him.
Well, I didn't address everything in your post, either.  Does that
make us even?
   My posts were predicated on the assumption that transparent encryption    and signatures are worthwhile and necessary.
Well, yes, I certainly agree.
My point about key distribution, partly, that you don't need to solve
it before you get a basic system.  Separation of key distribution and
encryption allows you to implement the encryption seamlessly and do
the key management by hand.  Since use of keys is more frequent than
distribution, you can make a big win by getting the encryption working
right first.
   I think we ought to be moving in that direction, for two reasons.  The
   first is that most people -- including most of us -- aren't willing to do
   much work in order to sign and encrypt our email traffic.
I am still considering the "sign-or-delay" proposal for the toad.com
server, that is, sign your articles to the list or they'll be delayed
and eventually rejected.
   > This approach of generality,
   > however, is notably more complicated than a world where responsibility
   > for security is partitioned, where  each user does not have to worry
   > about all the possible systemic security issues.
   I understand this criticism.  But if we abandon generality, I don't think    we can achieve transparency.
The generality I was referring to was non-locality, where decisions
taken remotely by other persons must be considered by the user.  The
analogy in programming languages is scoping, i.e. global vs. local
   But the whole point of the system is that    there is no need for the two correspondents to worry about exchanging    keys:  it all happens automatically.  I think this is exactly the wrong approach if you want rapid deployment.
Case in point--PEM.  The PEM folks had basic encryption down pretty
quickly and then spent years (like two or three times as many)
figuring out key distribution.  And the key distribution mechanism
they came up with has political problems and very few people use it.
Had PEM released an initial RFC with just encryption etc. in it when
they were done with it, we'd all be using PEM today.  We aren't.
PGP is used more than PEM because it's key distribution system allowed
you to use uncertified keys.  PGP isn't used much because it
integrates so poorly with other software.  PGP insists upon doing
every goddamn thing it knows how to do whenever you invoke it.  I tell
PGP to process a message, not to decrypt it.
How to do encryption and decryption is mechanism.  How I decide what
keys I trust is policy.  Separation of mechanism and policy is a good
thing.  (Good defaults for policy also help.)
A package which has this right--swIPe.  The initial swipe code works,
and all it does is encryption.  Right now you have to do key
management manually.  That's OK, because that can be another
   On the low end, we have a default web of trust, which is    sort of crummy because it's not terribly difficult to spoof.     But my goal was to meet this criticism by making the system open to other    webs, and to place as few restrictions as possible on people who want to    create and use falternative webs.
My point is that you don't need webs at all.  They have their uses, to
be sure, but they aren't the last word in key distribution that
they're often made out to be.  Bilateral distribution of keys for
electronic-only communication can work out just fine, providing enough
different communications channels are available.  There was a post I
made last year about the email provider signing keys which is relevant
here.  (If someone could repost it, ...)
   I didn't    mean to imply that all public keys ought to be on the default web.  I    meant that you ought to be able to get *a* public key for an aribitrary    address from the default web.
The publication of a key, however, reveals the _existence_ of that
arbitrary address.  On the other hand, if that address sends a
message, then the public key should be available to those who see it.
For Usenet participation, for example, a default key repository is
useful and does not affect forward secrecy, which has already been
compromised by posting a public message with signature.
   Basically, it comes down to this:  in a transparent system, if you want    to mail me, somehow your mailer will have to get a copy of my key without    your doing anything about it.  That's a good final goal, but I really think it ought not to be
included in the first subgoal.
There are substantial problems with achieving both transparent key
access from a single mailer and assurance against that mailer being
spoofed.  All such solutions seem to require global, non-partitionable
information, making the problem difficult, not insurmountable.  If,
though, the mailer runs on trusted hardware and has multiple links to
the outside world, automated solutions seem possible.
   The problem is:  how do we let the machine make this decision on it's    own, without imposing a single web of trust on users?
In my ideal view, keys should be certified by the communications
providers.  Since the comm providers are necessarily involved with
interposition attacks (it's their equipment, after all), participation
by them seems desirable and, in some sense, minimal.
Let us again restrict the problem to mappings between email addresses
and keys.  This restriction, as noted, covers a huge percentage of
real interaction.  The provider of email services has agreed to send
messages that are addressed to X to X's mailbox, without alteration.
If you get the provider to sign X's key and transmit it to the world,
then X, via another channel, can get a copy of that signed key and
verify that the provider is not interposing.
Likewise, the internet provider agrees to deliver mail addressed to
users at site Y to Y's mail daemon.  Y has the same interest in
spoofing vis-a-vis the internet provider as X does vis-a-vis Y.  The
argument is recursive, and bottoms out at the other end of the
communication link.
Clearly, an exhaustive analysis of internet protocols in terms of
these explicit promises and obligations would be enormous.  It would
also be a firm foundation for secure communications.  Nevertheless,
it's benefits might be approximated by creating provider keys and
site-signing keys.

@_date: 1994-11-29 06:50:14
@_author: Eric Hughes 
@_subject: Re: The Market for Crypto--A Curmudgeon's View 
From: tcmay (Timothy C. May)
   It's just that my "rant buttons" are pushed by an argument I'll call
   the "crypto isn't being used by enough people, so we'll have to make
   our own lives harder to set an example" argument. Let me review the exact proposal.  First, a recognizer is set up at
toad.com to distinguish between digitally signed and unsigned
messages.  Second, some action on the message would be taken, which
would gradually increase in effect over time.  The first action would
be to add a header to the end of the mail identifying it as unsigned.
A later action would be to delay the mail at the server for some
amount of time.  A final action would be to delete or bounce messages
that weren't signed.
I note that Tim is not objecting to the nature of these effects, but
rather their existence, especially since he is not addressing the
timing of any ramped up vigor at the server.  Just to set the record
straight, refusing messages would be at the very least over year away,
and certainly wouldn't be taken until crypto mail readers were widely
available.  For purposes of discussion then, I leave out message
deletion and only address the server actions of notification and
One underlying premise of Tim's argument is that the presence of these
actions at the server makes his life harder.
In what way?  The server will not require a digital signature.
Unsigned messages will still be sent to the list.  There need be no
change in the way that one sends and receives mail.
I refuse the argument that toad.com server actions make anybody's life
I'm not saying that these server actions would have no effect, far
from it.  The effects are all in the social realm and have far more to
do with peer pressure and social position than with technology.  Can
it be said that being marked as a non-signer makes one's life harder?
I think not, perhaps others feel otherwise.
I do, however, agree with the other two premises of Tim's
hypothetical.  I do think that crypto isn't being used by enough
people.  I realize that the exact meaning of 'enough' is subjective,
so let me rephrase.  I do think that crypto is being used by fewer
people than I want.  I also believe that setting an example is a good
thing, because it signals an achievable task to those who are
considering doing it.
When I first proposed server actions last year, it was with the full
realization that I wouldn't be signing my own posts and would thereby
be subject to the delay (the first-proposed action).  This post isn't
signed either.

@_date: 1994-11-29 07:10:01
@_author: Eric Hughes 
@_subject: Re: Transparent Email 
From: alex (Alex Strasheim)
re: signature checking at the toad.com server
   It seems to me that such a rule would stifle discussion and encourage    people to store their keys on insecure accounts.
Good!  That means they'll have generated a key.
One of the problems with cryptography generally is a prevailing
attitude that crypto isn't worth using unless it provides security as
complete as it can offer.  I reject this attitude.  Partial security
is better than no security.  Protection against some threats is better
than no protection.  Storing a key on a public machine is OK, just
fine, hunky-dory, just so long as it doesn't induce false beliefs
about a lack of protection from sysadmins and other roots.
   The real solution is to try to build tools which will make it so easy to    use crypto that there's simply no reason not to do it.
Sure.  No argument.
I will disagree, however, with a conclusion that insists that these
tools have to be the first to be built.  Partial progress is desirable.
Or to put it the words of the old homily:
Don't let the best become the enemy of the good.

@_date: 1994-11-29 22:36:06
@_author: Eric Hughes 
@_subject: Re: The Market for Crypto--A Curmudgeon's View 
Let me be REAL clear about this.  The immediate proposal is to mark
and possibly delay unsigned messages to the list.
The proposal does NOT include bouncing messages or preventing use.
These options are acknowledged as possibilities for the future.  They
are not on the table right now.  I, unlike the gov't, will warn you of
your impending doom.
   From: tcmay (Timothy C. May)
   Not to trivialize this proposal by frivolously insulting it, but
   consider a mailing list that decided to delay/bounce any messages that
   were not written in TeX, or in Acrobat, or whatever. I don't think you are frivolously insulting it, but I do think you are
ignoring the basic distinction I made about the difference between
measures which prevent use and measures which do not.  The use of the
syntax "delay/bounce" denies exactly this distinction.
   [...] to delay/bounce any messages that
   were not written in TeX, or in Acrobat, or whatever. How would people
   react who lacked these capabilities, or preferred to use alternatives
   (like simple unadorned text), or who merely object to an enforced
   standard?
I have two answers, one for delay, the other for bounce.
1.  For delay or other non-preclusive measures, those who do not use
the valorized feature can still use the list.  They get signalled in
some fashion that use of the valorized feature is desired.  I consider
this primarily a communication mechanism.
I wish to communicate to everyone one the list that using digital
signatures is something that I want everyone to do.  In particular,
that means that you, the current reader of this message, are one of
the people I want to use digital signatures.  Rhetoric is not as
effective as a policy embedded in software that people interact with.
Doing is more effective than hearing.
2.  For bouncing or other preclusive measures, those who do not use
the valorized feature can't participate in the discussion.  This would
in many situations be counterproductive, but in others, say, an
experimental group discussing design in Acrobat, absolutely vital.
As this is not germane to the actual proposal, I leave off here.
   But that Eric [...] has some notions of
   what people _ought_ to be using does not seem to be enough to
   effectively bar those who helped form the Cypherpunks group (many of
   us) just because they choose to communicate in one particular way.
I want you, Tim May, to use digital signatures.  There, that's
explicit and verbal.  I do understand if your software doesn't
cooperate.  I've been there.  I'm not (to repeat) talking about a
proposal to eliminate you from the list.
Does a mark or a delay constitute an "effective bar" from
participation on this list?  I think not, although I'm entertaining
   If some flavor of PGP is mandated, I expect I'll unsubscribe (as I
   can't stand reading but not posting...lurkers obvious feel otherwise).
Whoa!  We went from an effective bar to an actual prevention there.
That's not what I'm talking about.
And I'm not tied to PGP by any means.  You want to make a digital
signature with some other piece of software?  Fine.  I'll add it right
   Absent a compelling reason, a market reason, why bother with someone's
   notion of ideological reasons?  I'm not a libertarian (neither big L nor small l), and I don't find an
identity between compelling reasons and market reasons, as apposition
The implementation of function at the server is a communication
between me, Eric Hughes, the implementor of that nasty shit, and you,
the participant in the cypherpunks list, that I want you to use
digital signatures.  Now, because of my position as de facto list
maintainer, I can do this and you can't.  I've got the bully pulpit,
and while I've not used it much, I am beginning want to spend some it
on urging crypto deployment and usage.
Not all is lost for erstwhile communicators.  One could write a filter
to look for unsigned posts and pipe them off through a suitably hacked
'vacation' filter which would send them a missive (but not too often)
encouraging the use of cryptography and which would include pointers
to software.  This kind of communication is similar in form but not in
scope to what I've proposed for the list.  In fact, if someone were to
bundle this kit up, I suspect it might receive fairly wide use.
   [...] perhaps I'd insist that all posts be paid
   for in digital cash...or bought, or whatever. You hypothetical includes an insistence.  Mine does not.
   Again, I thought the proposal was to ultimately reject non-signed
   articles?
There's a very explicit disclaimer to contrary in the original.  To
paraphrase, it acknowledged the possibility of rejection but removed
it from immediate consideration.
   Speaking of this, it's already pretty clear who signs and who doesn't.
   What could be clearer than "----BEGIN PGP SIGNED MESSAGE---"?
What about random headers with things like:
X-Signature: none
X-Warning: Cryptography Non-User
X-Heckle: Yo! Too _good_ to use crypto?
X-Lazy: Jeez, Eric's even got a Unix box at home and _still_
        isn't signing?
X-Bozo: God, Tim's been on this list for over two years and
        he still doesn't sign his posts?
X-Traitor-To-The-Cause: [For the satire impaired, note the use of the phrase "satire impaired"
at the beginning of this sentence.]
   If the proposal is to stamp a scarlet
   letter on non-signers, it seems overly harsh, somewhat petty, kind of
   insulting, and not needed.
A scarlet letter is a reasonable apt analogy, except the intent is not
to create outcasts.  Harsh?  I still fail to see that.  Petty?  What
trivial mattr is being blown out of proportion?  Insulting?  I'm sure
some people can take it that way.
Not needed?  Perhaps not, but I may _want_ it.

@_date: 1994-11-29 22:46:46
@_author: Eric Hughes 
@_subject: Re: whats all this nonsense 
From: jrochkin (Jonathan Rochkind)
   I'm not sure if Eric is suggesting that everyone submit their public key to
   the list or not.
No, I'm not, because I consider that problem not yet satisfactorily

@_date: 1994-11-29 22:48:06
@_author: Eric Hughes 
@_subject: Re: Anarchists break rules, details at 11, was: The Market for Crypto--A Curmudgeon's View 
From: pfarrell ("Pat Farrell")
   A few days delay, which is what I think we are talking about, will clearly
   make following threads more difficult.
I wasn't thinking about days.  As far as specifics, I was thinking
about two or four hours to start with.
   And add to noise on the list,
   as the content of an early-non-signed message may be repeated and
   signed by someone else later on.
It may add noise at the beginning, certainly.  It may give rise to
some pause before sending off an unsigned message on a triviality, as
   Whatcha trying to do, eric, lead that anarchists?
Herd cats.  Merely because it can be difficult does not mean it's
never worthwhile.

@_date: 1994-11-29 23:02:35
@_author: Eric Hughes 
@_subject: Re: signing messages 
From: greg (Greg Broiles)
   Seems like one way to encourage the use of digital signatures is to
   start forging messages from people who don't ordinarily sign their
   messages. Necessity is the mother of invention, and all of that.
How about a vacation-like program that automatically finds .sig
blocks, stores them in a database and appends them at random to other
   Eric, would you mind clarifying the purpose of the "sign-or-delay"
   rule? Last time this came up I assumed that it was to encourage    folks who had 95% of the tools/initiative to start using crypto    techniques on a day-to-day basis to get off their asses and do so;
   but other people seem to have different ideas about the purpose(s)
   of such a practice. Some of the reasons I've explained just recently.
You are correct in the reason you state, also.  Providing an incentive
for those who are mostly there already will push many to act.  I think
that is a good thing.
One benefit I did not anticipate is an outcome of the large number of
people actually having gone through the process of setting up their
own signing mechanisms.  There are many more people now who have
hands-on experience setting these crypto mechanisms for themselves and
who consequently have a much better understanding of the
implementation issues involved.  For some problems action is ten times
more effective than theorizing.
   I think it might be interesting to try the "sign-or-delay" rule on
   a part-time basis - perhaps weekends only, or never on weekends, or
   only during December, or whatever.
This is a good suggestion.  It makes the transition even more gradual.

@_date: 1994-11-29 23:07:24
@_author: Eric Hughes 
@_subject: Re: Mandatory sig workaround 
Eric sets the list to slow down unsigned posts and somebody else sets up
   a remailer that generates a key for each post, signs it, and forwards
   it.
   It always happens that when hacker A tries to enforce an arbitrary rule
   on other hackers, hacker B will find an automatic workaround.
Fine.  I still win.  My purpose is to communicate that I want list
users to use encryption.  If you feel the need to use someone else's
service, then you have at least been exposed to the fact that
signatures are desired at toad.com.
Some people may find a way around it.  OK.  I still get the initial
sign-on message that new users see.  Most people get the message.
That's what I want.

@_date: 1994-11-29 23:10:39
@_author: Eric Hughes 
@_subject: Re:  Sign-or-delay 
From: wcs (bill.stewart +1-510-484-6204)
   Well, it's easy to require people to include PGP signatures.
And, as I've said, that's not what I'm talking about.
   On the other hand, how carefully were you planning to make your
   system check signatures - does toad.com have the spare cycles
   to validate them all, or are you really going for syntax only?
Well, I was going to do syntax only, because the real benefit is in
changing local software architecture to make automatic any operation
on outgoing mail.  If that operation is encryption, so much the
better, but the larger strategic goal is to alter architecture.

@_date: 1994-11-29 23:19:13
@_author: Eric Hughes 
@_subject: Re: Transparent Email 
Does not everyone get a complete header like the one below from    Eric's post with incoming mail?  Everyone gets it, but the better readers don't show it to the user.
Many people don't even know about those hidden headers, perhaps most.
   I had assumed that because every mail received here has such a    header that everyone else could also see who sent my mail,    signed or not.  That is why I have not signed my posts.
The Received: fields can be forged.  You can even forge your own with
the cypherpunks remailers and    BTW, Pipeline does not allow anonymously-sent direct mail -- as    a take it or leave it policy.  So we cannot manipulate headers    to forge from this Windows-driven end.
That's what the :: syntax was invented for, for folks who can't
manipulate headers in their systems.  The original purpose was for
Fidonet, and Tom Jennings, who couldn't use the remailers at the time.
What :: does is glue in the headers you want _at the receiving end_.
If your service passes message bodies with no harm, these soon-to-be
header fields will pass just fine.

@_date: 1994-11-29 23:24:33
@_author: Eric Hughes 
@_subject: Re: Transparent Email 
From: alex (Alex Strasheim)
   I know, but I'm a little squeamish about leaving my keys unprotected.
Then make up separate insecure keys for transmission to the host.  Add
an attribution which says to disbelieve any signature made with this
   Also, I'm not very fond of the idea that encrypted email would be    decrypted when it got here and left in plaintext on the mail spool.
Some protection is better than no protection.  Protection in transit
is still protection, even if it is not universal.
   Otherwise it
   wouldn't be practical to use this setup in an office or school
   environment, because anyone could boot your machine with a floppy and
   steal your key. That's a different threat than interception of mail, remember.  A
partial solution is better than none.
One of PGP's many problems is that it's policies for key use are quite
restricted.  There's no way, for example, to make a receive-only key.
rom owner-cypherpunks  Tue Nov 29 23:24:34 1994
Return-Path: Received: by toad.com id AA18942; Tue, 29 Nov 94 23:24:34 PST
Received: from netcom13.netcom.com by toad.com id AA18930; Tue, 29 Nov 94 23:24:28 PST
Received: by netcom13.netcom.com (8.6.9/Netcom)
X-Mailer: ELM [version 2.4 PL23]

@_date: 1994-11-30 07:04:43
@_author: Eric Hughes 
@_subject: Re: net.welfare approaching 
From: lmccarth ("L. McCarthy")
   Personal anecdote time: I've been trying to promote the use of dig
   sigs at my site. [...] The short point of this overlong narrative
   is that leading by example can have a significant effect, and
   shouldn't be dismissed lightly as a means of raising crypto
   awareness.
This is exactly the kind of communication I want to promote.
Communication by allowing others to observe your actions can be far
more powerful than abstract arguments in favor of that action.

@_date: 1994-11-30 13:43:59
@_author: Eric Hughes 
@_subject: Re: Mandatory sig workaround 
From: snyderra (Bob Snyder)
   I don't sign/encrypt to
   mailing list, as many people get disgruntled by it, and can cause
   problems of it's own.
Now encryption I can see disgruntlement at, but a cleartext signature?
   How about just an annoyance responder that sends a piece of mail to
   people who post without signing/encrypting, telling them they should
   be encrypting, that it's the preferred method of doing things, and to
   do so in the future if possible?
I've convinced myself this is a good idea for my own personal mail, at
least.  As for the list server, some explanation and pointers are in
order, to be sure, though not with each message.  But "just" a
responder?  I don't think that induces a sufficient incentive.
   As a side note, if you want people to sign their notes, why aren't you
   doing so now?
For the same reason that Tim isn't--it's too difficult.
Now I've just recently set up a new email machine and I expect that
I'll be able to get signing set up on it before the end of the year.
I have plenty of irons in the fire already, and this isn't the top
   it would seem that signing
   your own messages would be a good way of starting things toward the
   direction you want to go.
It certainly would.  My priorities on this are to get myself set up
for signing.  Then I need to get a recognizer written, then to hack
vacation to use alternate database files, then to get my own personal
resource list compiled, then to set my personal nagware.  Only after
all that do I intend to alter the list.

@_date: 1994-11-30 13:50:59
@_author: Eric Hughes 
@_subject: Re: Effects of Marking/Delaying Nonsigned Posts 
From: jamiel (Jamie Lawrence)
   [...] delays will degrade
   the quality of discussion on the list (time lag for only some has
   a way fragmenting discussion, as anyone with a sometimes-slow link
   can attest).
If the delays remained entirely unexpected or random, quality would
degrade.  Humans, however, have an uncanny ability to modify their
own behavior.
I am also willing to risk a small amount of degradation to encourage
people to actually use encryption tools.
   If you are set on this idea, may I echo someone else's suggestion
   of an autoresponder to annoy those posting without signing? I think this is a good idea which will help the communication intent
of the whole proposal.
   [...] we all still know who is not signing [...]
Having notification that a message wasn't signed was never presented
as one of the purposes of the proposal.

@_date: 1994-11-30 14:41:50
@_author: Eric Hughes 
@_subject: Re: We are ALL guests (except Eric) 
From: jamesd (James A. Donald)
   We cannot
   tell him that it is unfair or unjust to manage the list in
   certain ways.
Oh, you can, but I am Free To Ignore you.
These discussions on the interest of power are fascinating to me.  So
many of them do not take into account my own desires to create a
useful discussion forum, which desires bind me tighter than any law
ever could.  There are some very interesting implications of this _de
facto_ solipsism to achievement of equilibria in games with iterated

@_date: 1994-11-30 14:45:28
@_author: Eric Hughes 
@_subject: Re: "You aren't following the _rules_!" 
From: rarachel (Arsen Ray Arachelian)
   I agree with Tim on this.  There's no way I'm going to leave PGP on
   poly's machines with the key right there for anyone who manages to
   hack into photon or prism (and yes, it has happened) to set up a fake
   pgp asking for the passphrase to my key.
Your key, singular?  Keys are cheap!  Everyone should have a bundle.
In addition, since I'm not planning on verifying the signatures at the
server, you are free to fake them.  Of course, if you fake them,
you'll have to set up just about the same amount of software as if you
used real crypto.  Since so much of deployment delay comes from bad
architecture, I consider setting up to fake a good thing.

@_date: 1994-11-30 15:11:41
@_author: Eric Hughes 
@_subject: Re: We are ALL guests (except Eric) 
From: cactus (L. Todd Masco)
Todd's good discussion of social lists addresses well some of the
social aspects of a decision to modify the server to do something.
   It is certainly not a clear case in my mind: Eric might be able to
   pull it off without pissing too many people off, he might not.
   This discussion is part of what will determine that.
What is certainly clear enough to me is that the list is certainly
social enough that without discussion the endeavor would certainly
   I'll make a prediction: requiring digital signatures will annoy most    those people who are independant and don't care to be told that they
   should at least ostensibly provide a strong identity/posting mapping.
1. Independence.  Higher levels of richness (and I mean much more than
wealth) require higher levels of interaction.  There is a qualitative
difference between, on one hand, violence and coercion and, on the
other, inducements and interactions.  Both can reduce independence.
Then again I don't feel that liberty and independence are what I
desire most.
2. Strong mappings.  Two solutions already presented here allow a
workaround.  Pseudonymous and one-time keys both work, as does an
autosigning alternate entry point.  I say great, build them.
Apropos of one-time use keys, will PGP function properly on a 20 bit
modulus?  Another non-key would be to generate a short key and post
both public and private halves.
   thought that this was one of the common assumptions of this list: that
   anonymity as well as pseudonymity was a goal worth achieving.  Requiring
   signatures seems several steps backwards.
The first time a signature appears, it's anonymous.  The second time
it appears it's pseudonymous, and references the preceding message.
Requiring signatures does not prevent anonymity.
   as I suggested last night, such a list address could be set to
   automatically sign all posts
Why do I suspect that such a service will be available at
cypherpunks  I don't mind; I think it would be useful service
and entirely compatible with what I want to accomplish.

@_date: 1994-11-30 15:21:04
@_author: Eric Hughes 
@_subject: Re: Authentication at toad.com: WTF? 
From: cactus ("L. Todd Masco")
   Does the idea of having the list software check signatures strike
   anybody else as a Bad Idea?  You mean, like the proposer (me)?
I think it _would_ be a bad idea to have the server check all
signatures, and I said so last night.  That's why I only plan on doing
syntactic checks.
Steve Witham understands this.  Steve, didn't you used to fake all of
your sigs, from the last time this got discussed?

@_date: 1994-11-30 15:32:54
@_author: Eric Hughes 
@_subject: Re: We are ALL guests (except Eric) 
From: dmandl
   I agree with Tim that effortless encryption/signing of email is still a
   dream for most of us.  I don't think there should be any "punishment" for
   not signing (not even having the non-signer's mail delayed).  Delay seems to be now third on the list of potential server actions.
First and second are adding header lines and sending back exhortations
and pointers.  It may be that we never need to add delay.  I'm not
stuck to the idea and am content to see what actually happens.

@_date: 1994-11-30 15:53:43
@_author: Eric Hughes 
@_subject: Re: "Cyherpunks Named Official Signing Authority" 
From: tcmay (Timothy C. May)
   If the intent of a "Compelled Signature" (tm) policy [...]
Putting it in quotes doesn't prevent it from being a misrepresentation.
Are you saying that adding notifications and delays is compulsion, or
   [...] is to get people
   used to signing messages, why not get them used to _verifying_ sigs as
   well? If the crypto hooks are there for sending mail, you're more than
halfway there for receiving mail.  And yes, this is also something to
Your argument can be construed to say that since I can't encourage
signature checking, that I should add that to my list of requirements.
I've been pretty vocal about my desire for partial benefit short of
what is possible.  If server actions don't help signature checking,
OK, well then, they don't, ca va.
   Imagine the P.R. value to these Net.Cops: "But even the Cypherpunks
   require all posts to be signed!."
If the net cops are going to acknowledge a merit in a cypherpunks
position, I say let them.  The opportunity to educate the other
listeners that signatures are not the same as personal identity is an
opportunity not to be missed, especially when your opponent hands it
to you.

@_date: 1994-11-30 16:20:33
@_author: Eric Hughes 
@_subject: Re: Auto-Verifying of Sigs 
From: JLICQUIA ("JEFF LICQUIA (CEI)")
   Really, the only "unknown" with signed messages is whether they are valid    or not; it's pretty easy to distinguish the unsigned posts.  The purpose of adding a header line to mark unsigned articles is _not_
to indicate that they aren't signed, it's to editorialize on the fact
that they're not signed.
There has been an argument that since marking doesn't accomplish
anything you couldn't already see, that it's useless.  Fine, the
premise is specious, because it's not intended to mark unsigned posts,
it's to comment on them.
   May I propose a "better" way (you be the judge here): Proxy the job.
A proxy should have it's own subscription list, which makes it an
opt-in system.  Other than that, I think a verifying proxy is a good

@_date: 1994-11-30 16:32:07
@_author: Eric Hughes 
@_subject: Re: Shouldn't "toad" messages be signed? 
From: tcmay (Timothy C. May)
   It seems clear to me that by the logic of this thread, *all* messages
   passing through toad to us should naturally be _signed_. Perhaps someone else's logic.  Not mine.
I'm not talking about putting cryptographic material on toad.  There
are not only key distribution problems (for sig checking) but also
security problems (for sig making).  I've stated clearly two or three
times now that I was planning to use syntactic and not cryptographic
   After all,
   how do we know if an "approved" message has indeed passed through
   toad? Someone else could be spoofing the account.
This is specious.  The server exists as a communication mechanism, not
as an authentication mechanism.  Were the list restricted, either in
acceptance or in transmission, it would have authentication properties.
It's not, and it doesn't.
   This will produce nested sigs, as I attempted to illustrate above
   (apologies if I got the precise syntax wrong). The precise syntax doesn't matter.  The nesting problem is a weakness
in PGP, which can't add on a second signature to the block at the
bottom of a clearsigned message.
   And will today's tools allow easy extraction of first the toad sig,
   then the enclosed sig?
I doubt it.  On the other hand, my original proposal was to encourage
the _making_ of signatures, not their checking.  If you insist that my
proposal includes checking as a basic element, you'll be arguing
against a straw man.
   Seems to me that if Eric wants to start encouraging use of sigs, that
   a good first start would be for toad to sign all messages.
What Eric wants to very specifically encourage is the making of
signatures on outgoing posts.  Anything else is a bonus, not a premise
to find inconsistency in.

@_date: 1994-11-30 18:15:37
@_author: Eric Hughes 
@_subject: Re: We are ALL guests (except Eric) 
From: cactus (L. Todd Masco)
   What makes this a difficult issue to call (for me) is that you have
   partial authority as an "original founder," a much more persuasive position
   than the bureaucratical "list maintainer" status.  Thank god you didn't capitalize those.
   I think the question is not whether you desire liberty and independence
   but whether you desire the company of those who value liberty and
   independence strongly enough to abandon this forum at the slightest
   perceived breach of their autonomy.  I don't.
I apply Tim's Calvinist Stoicism stance to this situation.  Put
crudely, if people bolt at the first sign of encroachment, fuck 'em.
There is a matter of degree here which is quite important.  A small
notification in the header of the message is hardly much at all.
Preventing a message from going through, however, is a qualitatively
different thing.  If there are people who can't tell the difference,
or worse yet, who won't acknowledge it, I'm not going to feel too
   I think that you'll probably be able to pull off some compromise: the
   one that I like most is that of an independent agent or two, automatically
   checking all signatures and occasionally admonishing those who don't
   use them.
That and simple notification in the header.  I am as yet undecided
which one I think might come first.
   The former would even be a valuable tool with far wider
   application than cypherpunks, esp. if written such that it could be
   used on newsgroups or even over NNTP.
Well, I did say today that I'll get the thing working on my own
personal mailbox first.
   The thing that's particularly alluring about the independent agent idea
   is that you don't have to (ab?)use your position as list maintainer to
   implement it,
This is both an advantage and a disadvantage.  On one hand, harmony is
maintained.  (I hear the guffaws too.)  On the other, the message
isn't nearly as strong.  To reiterate, I am willing to use my
position to send a stronger message.
   OTGH, pgp is a bigger
   cycle-sucker than I necessary want to have running all the time on our
   poor little microVAXen.  Yet another reason to have an less-than-fully secure key for that location.

@_date: 1994-11-30 18:21:34
@_author: Eric Hughes 
@_subject: Re: Effects of Marking/Delaying Nonsigned Posts 
From: jamiel (Jamie Lawrence)
   Multiply that by a possible 25% (arbitrary) of the list being delayed [...]
This afternoon I considered starting the initial delay at one minute
and incrementing the delay by one minute each time a message gets
delayed.  Perhaps the increment would be 15 or 30 seconds--whatever.
The point is that the delay would ease in slowly and folks would get a
chance to adjust.
   >Having notification that a message wasn't signed was never presented
   >as one of the purposes of the proposal.
   My mistake then, I thought you had proposed marking messages as unsigned
   as an intermediate step.
I had proposed marking them, true, though not as notification, but
rather as automated commentary.  Notification is a (trivial and
useless) effect of the measure, but not its purpose.

@_date: 1994-12-01 08:02:20
@_author: Eric Hughes 
@_subject: Re: "Cyherpunks Named Official Signing Authority" 
From: tcmay (Timothy C. May)
   First of all, I am generally commenting on this:
   "I am still considering the "sign-or-delay" proposal for the toad.com
   server, that is, sign your articles to the list or they'll be delayed
   and eventually rejected." [Eric Hughes, 1994-11-28]
Tim, I've not been referring to that exact proposal for some time now.
In very specific detail, I have dropped the premise that they might be
rejected.  This happened almost immediately after this recent
discussion began.  I wanted to restrict discussion to what might be
implemented first to avoid the (alas, unavoided) less than productive
discussions about what could happen later.
Was I insufficiently clear that I was now discussing a smaller
What I see is that you are refusing (by omission) to address the
subject at hand.  I see a direct, if not intentional, effort to
address something that is not what I have been talking about.
   "Eventually rejected" mean to me that unsigned messages will not be
   passed through to the list. I call this a "compelled signature" in
   that the signature is compulsory, not optional.
This is all well and good, but it is on a different but related
I ask again the quetion that I specifically asked before.  I'll even
not abbreviate to be clear that I'm actually asking for two things.
Does a marking action by the server create a compulsion to sign?  Does
a delay action by the server create a compulsion to sign?

@_date: 1994-12-01 10:19:03
@_author: Eric Hughes 
@_subject: Re: We are ALL guests (except Eric) 
From: tcmay (Timothy C. May)
   I haven't said I plan to leave the list. I've said that if my posts
   are blocked/bounced/rejected, I would likely choose not to remain.
Let me ask something more proximate.
Tim, if the server puts a header on mail that identifies it as unsigned,
how will you feel about seeing your mail marked as such?  What might
you do about such a situation?
   I will register a note of purely personal frustration that many have
   framed the current debate in terms of "Eric's list" and "If Eric wants
   to do it this way, then this is how it should be done," etc.
   I have no animosity toward Eric, but think this is a misguided
   rewriting of history. Ah, assigning credit.
Let the world know that there would be no cypherpunks without both Tim
May and me.  Tim and I met at a party at Hugh Daniel's place; we were
the first two to arrive.  We became pretty much instant friends when I
said that I was going to work with Chaum in Amsterdam.  A year later
Tim was gracious enough to put me up at his place for a few days when
I was there, ostensibly as it turned out, to look for housing.  I was
much more interested in conversation that accommodations, and Tim and
I had a three day conversation in which the germ of cypherpunks was
developed (among many others).  Tim and I spent a lot of time later
working on the first meeting, which was held with people we both knew.
Why is it then, that people refer to "Eric's list"?
At our first meeting, John Gilmore offered both a computer for a
mailing list and a site for a meeting.  We are no longer meeting at
Cygnus, but we are still using John's machine.  I began maintaining
the mailing list, and with this was a symmetry breaking.  As many of
you know, I spent hours and hours and hours doing mailing list
maintenance (adding and deleting by hand) and dealing with all of the
problems.  I don't spend so much time on that anymore because of
majordomo, but I still do deal with the bounces and the complaints and
the exceptional requests.
Cypherpunks is certainly _not_ "Eric's group", but the mailing list is
not unreasonably called "Eric's list".
Personally, I hate the term "Eric's list".  I try to avoid saying "my
list" in coversation as shorthand for "the list I'm the maintainer
for" because of the potential confusion with "the list I own".  I find
the property argument, at root, specious.  Information can't be owned
in any sort of natural sense, even though one _can_ remain vigorously
silent.  The comments of Dave Mandl and Todd Masco about the social
character of mailing lists address the actual issue, which is
political and not legal.
Yet there is still the realpolitik that I do maintain the list.  While
there are some internal checks (I need Hugh's cooperation for certain
things), the fact remains that I can make changes basically
unilaterally.  Pragmatically speaking, the phrase "Eric's list"
reflects this situation.  In addition, the phrase is short.  When one
is not distinguishing between subtleties, short phrases win and long
phrases lose.
So there are three reasons why the phrase arose: history, position,
and brevity.  When a deduction from the phrase relies upon some other
possible subsumption, all may rightly point out an unintended meaning.
Now we must shift subjects.  What good is assigning credit if no use
can be made of it?  Many substitutes are available for obtaining a
good feeling.  Social position allows one to influence the world.  One
of the most valuable abilities in the world is the ability to get
people to listen to you.  This is not new, merely highlighted by the
collapse-generating properties of computer networks.  Tim and I and
many others have spent much time devoted to writing clearly enough
that we will be listened to preferentially, both for clarity itself
and for the anticipation of clarity.
The whole "cypherpunks write code" nexus assumes this communication
process.  It's comfortable to write manifestos, express your position,
be indignant at the government, and teach privacy.  We generally live
in free societies where there is little recourse taken against speech.
It is must less comfortable to use tortious cryptography, run a
remailer, finesse export controls, and deploy code.  Far and away the
most extreme reactions have come from what people did and not from
what they said.  Speech affects the world, but action affects it more,
because every word that affects the world only through a sequence of
body motions.  Cypherpunks get listened to not because we talk a lot;
that's insufficient.  Cypherpunks get listened to because we do
"Actions speak louder than words" is true for local politics as well
as global.  Both Tim and I yammer a lot, but I do the list work.  The
assymetry is not incidental.  In discussing potential server actions,
I do not feel constrained come to agreement with any single voice,
including Tim.  I have a lot of respect for Tim and with respect to
cypherpunks generally I try not to put myself above him, but with
respect to the technical underpinnings of the list I feel no such
constraint.  This difference is a long consequence of actions chosen
by both parties.
Now, Tim, I don't know exactly that you feel slighted in this debate
with respect to origins and their values, but I suspect that you do.
If so, I regret that, but ask you to, well, deal with it.  Symmetry is
broken, cypherpunks is no longer new, and we who appeared
interchangeable to the world two years ago now seem different.

@_date: 1994-12-01 10:51:21
@_author: Eric Hughes 
@_subject: Re: Warm, fuzzy, misleading feelings 
From: dcwill ("Dr. D.C. Williams")
   While I can see merit in both sides, the pro-sig argument is
   weakened by their endorsement of sig spoofing. If the object is to
   heighten awareness of crypto and digital signatures, what possible
   Good can follow from setting the example that "cypherpunks simulate
   signatures"?
To someone who doesn't know what a digital signature is at all, it
doesn't matter if it's real or faked.  Communication to these people
is entirely from the odd-looking form of the appendages.
The ability to spoof a signature is an artifact of incomplete notions
and implementations about key distribution.  Were these problems
solved, I would consider actually verifying all signatures.  These
problems are not solved to my satisfaction, however.  The inability to
check a signature does not, however, render useless those other
functions that still work.  I advocate partial progress, and the lack
of a benefit is not sufficient argument against things that actually
   The way I see it, either sign or don't sign, but attaching a
   bogus signature block to a message for the sole purpose of pacifying
   a mailing list requirement diminishes the significance of crypto
   and sullies the image of all who participate. If you don't have a public key, it doesn't matter if the signature was
real or faked; you still can't verify it.
One of the purposes of this proposal is to encourage people to change
their software to automatically sign.  The harder part of this is to
change it to do anything automatically.  The signature making part is
fairly trivial by comparison.  The benefit I want more, of the two, is
the automaticity.  If, for whatever reason, actual signing can't
happen, I am content with the form of a signature.
   Make a
   new key pair that's used solely for the purpose of signing your
   list mailings.
That's fine, and I agree with the idea as a solution to the insecurity
of keys on a public machine.  I do not, however, feel I need to insist
that everyone do this.
   By the same token, I don't see how this proposal does much to spread
   the Good Word.
1. Crypto-unaware people will see the form and ask what it is.
2. Crypto-aware people will alter their software to do something
  2a.  Many, perhaps most, of these people will use real crypto once
auto-something already set up.

@_date: 1994-12-01 11:07:07
@_author: Eric Hughes 
@_subject: Re: "Cyherpunks Named Official Signing Authority" 
From: pfarrell ("Pat Farrell")
Re: majordomo alterations
   so that it pipes messages thru a filter to classify signatures.
   [...]
   We get classes like:  [5 listed]
What I was thinking was the following.  There would be a recognizer
that, given a message, would output "yes, something looks like a
signature to me", or "no, there is nothing that I recognize as a
signature".  Based on this true/false answer, the server would either
perform an action, or not.
I was thinking of no notion of classes, but rather mere presence or
   Maybe we need to have majordomo sign the message/header
   so we know that the true c'punk classifier has verified it?
WARNING: The following paragraph does not have direct relevance to the
issue at hand.  It discusses servers which might verify signatures,
which my current proposal does not have in it.
What I have realized in the interim is, that if a server is to verify
a signature, the server should sign not the message but rather the
signature.  After all, the signature is what was being verified, not
any property of the message.  The user can still detect message
alteration, by first verifying the sig-on-sig, and then comparing the
hash value in the original sig to a hash on the message.
   But then we ask, Hmmm, is this a hacked majordomo? After all, no sane
   person will read and manually verify the flood of c'punk messages.
   So some daemon is doing it all. And daemons can be hacked.
Trust always terminates somewhere.  How far back you go is a question
of worth and of effort.  Ceding some trust to toad.com may be
desirable for some but not for others.  Merely because it is not a
complete solution to all problems doesn't mean it's not worth doing.
   anyone else see a solution?
I do, but it involves program+proof ideas and is far from ready for
deployment.  I have no interest in solving those problems right now.
There is benefit to be had from crypto, even if the first
implementations only protect certain things.

@_date: 1994-12-01 11:13:51
@_author: Eric Hughes 
@_subject: Re: We are ALL guests (except Eric) 
From: cactus (L. Todd Masco)
   >To reiterate, I am willing to use my
   >position to send a stronger message.
   Sure.  I'm not sure the message would get through as you're framing it,
   though.  People don't react well to messages that are put too strongly...
   a gentle, gradual approach is more likely to get through.
Several approaches to gradualism have been usefully suggested in this
debate, and I appreciate that.
Just to be sure, I was expressing a willingness, not an imminent intent.

@_date: 1994-12-01 11:16:21
@_author: Eric Hughes 
@_subject: Re: Warm, fuzzy, misleading feelings 
From: werewolf (Mark Terka)
   If thats the case.....isn't it an equal pain in the ass to go to
   the trouble of forging a sig? :> You would likely have to go
   through more key strokes and other routines to forge one. Why not
   just play by the rules and sign a message?
This is a perfectly good rephrasing of one of the main rationales
behind the proposal, namely, that the architectural issues are more
important than the actual crypto use.  (Not exclusively important, but
more important.)

@_date: 1994-12-01 11:26:01
@_author: Eric Hughes 
@_subject: Re: Hazards of encouraging forged dig sigs 
From: lmccarth ("L. McCarthy")
   I foresee a
   situation in which a large portion of the list traffic uses forged or
   meaningless signing-server-appended dig sigs. When I establish automatic
   signature validation for incoming mail here Real Soon Now, there will be    plenty of noise generated by all the `false' negatives in the data to make
   a mockery of the authentication process. Recall my comments on transaction failure in a different context last
week.  What is important there is what happens under failure, not
under success.
Sig checking requires an analysis of the pragmatics of failure,
i.e. what happens.  What seems abundantly clear, no matter what
actions are taken, is that it will be actions plural rather than
action singular.  The decision process to decide what happens is much
more significant architecturally that what actually does happen.  An
embedded action, i.e. a hardcoded policy, would be bad, and since sig
failure handling is a relatively unexplored area, one can do it right
the first time.
Assuming such a failure recovery decision process, the actions are
simple: ignore, flag, discard, bounce, get key, etc.  None are
particularly difficult; the decider is what is hard.  Now, assuming
both decider and actions, you can very simply ignore all sig failure
for cypherpunks.
   Encouraging cryptographically
   valid signatures was the first suggestion I'd seen in this entire debate
   which seemed to promise tangible benefits; Syntactic checking also encourages valid signatures, just not as
   encouraging cryptographically
   invalid signatures is the first notion which appears to offer tangible
   detriment.
It's a problem that won't go away that the existence of bogus
signatures merely make the problem imminent and proximate.

@_date: 1994-12-01 11:36:31
@_author: Eric Hughes 
@_subject: Re: The Market for Crypto--A Curmudgeon's View 
From: abostick (Alan Bostick)
   Yes, but you are denying the way in which delaying, like bouncing,
   actively interferes with the timely forwarding of non-signers' messages,
   while merely marking them is a more passive form of harrassment.  A delay for one minute (assuming notice for the delay) is hardly
different than notification only.  A delay for a month is hardly
different than a bounce.  Not all delays are the same.  They cannot be
analyzed as a single category but are better analyzed with respect to
the characteristic time scales of the discussion.
   You keep insisting that delaying unsigned messages does not interfere
   with non-signers' abilities to participate in the discussion.  I say you
   are wrong.  It's a positive hindrance.  This is statement is true for large delays and false for small ones.
The interesting issue to me is where a boundary might lie.
   (Are you going to make sure that all the signatures are valid, or will
   you accept someone sticking a PGP signature into their .sig and using it
   over and over?)
At first, it would just be a recognizer for syntax, but at both ends.
A second effort might actually hash the message but not bother with
the signature itself.  The second effort would require almost all the
processing involved in a real signature and require the same
architecture.  It would not, however, be subject to the key
distribution problem that I don't want to make a prerequisite.
It occurs to me that a format with just a hash might be generally
useful against random data corruption, and not just a workaround hack.

@_date: 1994-12-01 11:40:47
@_author: Eric Hughes 
@_subject: Re: Warm, fuzzy, misleading feelings 
From: jamesd (James A. Donald)
   -----BEGIN PGP SIGNED MESSAGE-----
   A checker that merely checks if a signature looks like    a signature merely makes cryptography look stupid, like
   a power ranger suit.
Well, the message you posted doesn't look like a PGP signature.
It has similarities, but wouldn't pass the recognizer.
As I've said before, there is partial benefit to an incomplete
recognizer.  I do not want to abandon this benefit merely because
others are more difficult to obtain.
I don't understand why a recognizer set up at a single location makes
all cryptography look stupid.

@_date: 1994-12-01 11:57:04
@_author: Eric Hughes 
@_subject: Re: Warm, fuzzy, misleading feelings 
From: tcmay (Timothy C. May)
   More that just making crypto look stupid, [... it] defeats
   the whole purpose of user-to-user verfication.
Solutions that are bottom up are fine so long as they're not required
to remain on the bottom.  If a service (not the one I'm proposing)
were to actually verify sigs, then some people might want to trust it
and some might not, depending on their desires and abilities.
   I'm interested in systems which actually allow me to _really verify_
   sigs if I have to [...]
And so am I.  There is less incentive, however, to set up a sig
checker when there are few signatures to check.  I don't think we need
the whole crypto world to come into bloom at once.  In fact, I don't
that _could_ happen and that expecting that sort of parallel
development is a positive hindrance to deployment.
   I wasn't kidding earlier today (apologies that I'm reading the later
   mail first, as I just got home) when I argued that toad messages ought
   to be signed. That is, all traffic from toad. I didn't think you were kidding, nor did I think that the PGP
deficiency you pointed out was trivial.
There have been major issues about trustability at toad.com and it is
inappropriate at the current time to consider trusting signatures it
might make.  Again, I don't feel that this problem needs to be solved
in order to encourage people to use digital signatures.
   If sigs are to be compelled [or bounced ...], then such sigs
   should *actually be checked*, with the resulting checked messages then
   signed by toad/Eric/Hugh/John/whatever.
There is some merit to this idea, assuming that signatures are to be
used as access control.  The current proposal, however, does not
include that and hence the argument above is premature.  I'd like to
examine it later at some point when it is more timely.  In the
interim, though, I leave with an open question: "What would such a
server signature represent?"
   Anything less than this is actually counterproductive, as it fosters
   a non-Cypherpunkish view of placing trust in others to do what
   technology allows one to do directly.
Another non-Cypherpunkish view is to prevent the creation of systems
which allow you to use an agency relation to let someone else do
something for you.  For reading cypherpunks mail on a slow machine, or
someone else's machine, I'd be glad to use an agent (the legal
denotation here) to verify signatures.
What is definitely non-Cypherpunkish is to promote systems that
require trust relations that would not be entered into freely, like
the first PEM certificate mechanism.

@_date: 1994-12-01 12:00:00
@_author: Eric Hughes 
@_subject: Re: Effects of Marking/Delaying Nonsigned Posts 
From: tcmay (Timothy C. May)
   > This afternoon I considered starting the initial delay at one minute
   > and incrementing the delay by one minute each time a message gets
   > delayed.  The counter would be global to the server, not local to each user.
   A concrete basis for comment.
You'll likely want to comment again, though.

@_date: 1994-12-01 12:04:55
@_author: Eric Hughes 
@_subject: Re: We are ALL guests (except Eric) 
From: tcmay (Timothy C. May)
   > I apply Tim's Calvinist Stoicism stance to this situation.  Put
   > crudely, if people bolt at the first sign of encroachment, fuck 'em.
   Indeed. But if my messages are bounced or delayed excessively, I will
   of course have no reason to remain. My own Calvinist Stoicism.
I would not say that bounces or long delays were a first sign of
encroachment.  But it does seem that we have not been addressing the
same idea.
   > To reiterate, I am willing to use my
   > position to send a stronger message.
   Bluntly, Eric, this is what is so disturbing about your position. You
   are willing to "use your position" to essentially purge the list
Again, I've not been speaking of this end result, except insofar of a
desire to avoid it.
[re: special small keys for low security applications]
   I don't buy this, and hence will have my messages delayed or bounced.
   I want my key to be useful for real uses, not just "Power Ranger" (a
   la James Donald) uses.
It appears then, that we disagree about the value of a half solution.

@_date: 1994-12-01 12:08:20
@_author: Eric Hughes 
@_subject: Re: WHAT THE.. (was: Manditory key sig.. 
From: yusuf921 (Syed Yusuf)
   in all this discussion about how well it would work and ways around it,
   I think I've missed the problem that people are trying to solve.
I want more people to actually use cryptography.  I don't phrase it as
a problem, with it's implicit value judgement, but rather as what I want.
   isn't it ironic that privacy advocates are suggesting manditory
   loss of anonimity (which is what forced signing is).
The first appearance of a key is anonymous.  The second and later are
pseudonymous.  Even mandatory signing (which is not what is being
proposed) does not eliminate anonymity.

@_date: 1994-12-01 12:45:22
@_author: Eric Hughes 
@_subject: Re: We are ALL guests (except Eric) 
From: tcmay (Timothy C. May)
[re: reaction to marking]
   I won't do anything. I might not even notice it. I've never felt that
   this was important, though I also think it's pretty much useless (as
   it's so obvious who's at least making the appearance of signing).
I'm thinking of using something real obvious as a marker, similar in
spirit to what I posted the other day:
X-Advocacy: Eric Hughes wants YOU to sign your message.
I may actually use something very close to this, perhaps with the name
instead of the personal pronoun.  This header would be attached only
to message without recognized signature.
[re: reaction to delay]
   Delays of hours or more would affect my participation on the list.
   Bounces of course would. Those have been my concerns.
I have realized all along that bouncing messages would be extremely
disruptive; I apologize to the list if I made that less than clear.
As far as specific times, I think the cutover happens somewhere
between two and four hours.  If delays get used, you can be sure
they'll start small and rise slowly.
   My issue is with the
   views that are long the lines of "It's Eric's list, and if he says we
   can only write about Croatian youth hostels, well, hey, it's _his_ list!"
I am also far less than persuaded by such arguments.
   I don't feel slighted, not that that would matter.
Well, it would matter to me.  But then again, I'd first try to
acknowledge any such feelings, and then I'd tell you fuck off if you
couldn't deal with reality.  But Hey! that just me, I suppose.
   I'd feel just about as strange (I hope) if people were saying "Look,
   Tim's the boss. He's the Big Kahuna. If you don't like his policies on
   his list, leave."
"This is one _tasty_ burger"
   Clearer?
Yes, clearer.  Fortunately for me, I was locally famous in high school
in (drum roll) competitive classics.  I experienced some of exactly
the kind of subservience accorded to famous people.  I developed a
distaste for it then, which has not left.  I have some understanding
of the loneliness of celebrity.  When a sycophant doesn't treat you
like a peer, there's little point in trying to even out the
relationship.  It's almost always doomed.
Here are Eric's two sentence advice on celebrity.  If you want to know
famous people, don't treat them differently than others.  If they
therefore ignore you, leave.

@_date: 1994-12-01 12:52:08
@_author: Eric Hughes 
@_subject: recent voice over data 
the great voice-over-data protocols and products introduced by
   Intel, Rockwell, ZyXEL and others at Comdex which will make
   Voice-PGP so much easier
As I understand these voice-over-data products, the voice goes over
analog, added to the modem signal.  The modem signal is interpreted,
and then reconstructed and subtracted from the incoming signal,
leaving voice.  Very clever, but insufficient for secure phones.

@_date: 1994-12-01 13:01:26
@_author: Eric Hughes 
@_subject: Re: Warm, fuzzy, misleading feelings 
From: dcwill ("Dr. D.C. Williams")
   I would prefer to teach fewer of them to speak than teach a larger number
   of them to grunt.
I would rather that the fewer speak and that the rest grunt rather
than remain silent.
   A bogus signature is, of course, unverifiable. Why waste effort requiring
   something as non-functional as a spoofed signature?
For the architectural changes that have to be made to do such a thing
   Why? Even AOlers can make a bogus sig as a .sig file and attach it to
   every outgoing message.
But this doesn't create even a bogus signature.  There's still a line
at the top to add.  This misunderstanding about what constitutes valid
syntax colors your whole argument.
   Then the vast majority of grunters will put a spoof in their .sig files
   and be "done" with crypto.
.sig spoofing won't work; it's only the bottom half.  That's the whole
point, is that some active action must be taken, be it once to set up
something automatic or many times with each message.  In the first
case, the automaticity is obtained, a postive benefit of itself.  In
the second, a value is recalled to mind each time.
   I'm disappointed that your
   original objective has been compromised by an "automatic-spoof-is-good
   -enough" clause.
It's not good enough, but it is partial progress.  Merely because one
technique doesn't accomplish everything is no reason to abandon it.

@_date: 1994-12-01 16:53:25
@_author: Eric Hughes 
@_subject: Re: Where to get PGP for SunOS 
Did you look at ftp.csua.berkeley.edu?  The cypherpunks directory has
a whole bunch of PGP versions, including the latest generic Unix one,
as I recall.

@_date: 1994-12-01 16:58:36
@_author: Eric Hughes 
@_subject: Re: recent voice over data 
From: die ("Dave Emery")
   at a very low level relative to the data.  I believe there are also maximum rates on the data when used with
voice (4.8 kbps?) and the modulation doesn't use echo cancellation.
With the lower bit rate you can get away with a lot, particularly with
modern DSP's.

@_date: 1994-12-01 17:07:08
@_author: Eric Hughes 
@_subject: Re: Brands excluded from digicash beta 
From: jamiel (Jamie Lawrence)
   And that rule of thumb completely ignores the fact that if a
   transaction is fouled up anywhere along the line, one finds extensive
   legal liability involved instead of a 'mere' corrupt table in a database.
When the algorithms include "Call legal dept. and sue", the ability of
most programmers to design systems goes out the window.
Jamie's estimate of the magnitude of the problem is probably
overstating the case, but not much.

@_date: 1994-12-01 18:10:41
@_author: Eric Hughes 
@_subject: Re: E-money Good or Bad? 
From: KDAGUIO
Welcome to cypherpunks, Mr. Daguio.  Steven's article was unclear (to
me, at least), about just what you do for the ABA.  Could you provide
a more lengthy introduction?
   Whoa! Much of content of the discussions I had with Mr. Levy
   concerned the importance of protecting privacy and security for
   everyone.  None of those comments made the cut.  Yes, I have
   concerns about fully anonymous digital cash, but while I am not a
   full on crypto-anarchist, neither am I a crypto-facist.
There are two senses of the phrase "protecting privacy and security
for everyone".  The first, that I favor, construes the context
strictly, that is, privacy and security with respect to only the
transaction system in question.  The second construes the context
broadly, taking into account anticipations external to the system to
arrive at a judgement of what constitutes protection.  It appears that
you, Mr. Daguio, are much closer to the second than the first; if this
is inaccurate, please correct me.
I believe these two notions of protection are irreconcilable with each
other.  Protection of privacy to me means that only me and my
counterparty know that we have transacted and how much we have
transacted.  Digital cash techniques address the first of these and my
own Remote Auditing protocols can be used for the second.  Note that I
did not say that the bank need know, because both these technique
allow the bank to remain willfully ignorant and yet have an assurance
that they, the bank, are not at risk.  Protection of security means
protection against fraud and assurance of continuity of service.
On the other hand, if we assume that protection of security means that
the populace should be protected against narcoterrorists by denying
them a conduit for funds, then the strong privacy referred to above
cannot b maintained.  Nor even, in fact, can the security be
maintained, as a recent seizure of funds in transit inside New York
indicates.  (Very delicate work; the window of opportunity for the
feds was on the order of an hour, as I recall, and even though they
needed a court order, they hit it.)
I am partial to the first because, at a deep level, it can be stated
exactly what the requirements are, and relatively concisely.  The
second interpretation requires any number of assertions about the
outside world and its chains of causality.  Moreover, the second
interpretation includes a significant amount of discretion by public
officials who are not directly accountable to the public.  Not one of
the executive branch officials in charge of financial matters, however
construed, is elected.  Congress has ceded discretionary authority to
regulators and has largely left the task of interpretation to them.
This discretion with respect to what constitutes security is, to me, a
Very Bad Thing.  At the whim of a department, it may suddenly be
declared that something new is now disapproved of.  The color of law
is used to justify these changes, but they coincide neither in
necessity nor in sufficiency with the law.  To my knowledge, there was
no intensive and large scale investigation into Rostenkowski's
affairs, much less the Clintons's commodities, questionable
activities, if true, certainly constitute bribery.  In a parallel
issue, the FBI is known to have intercepted (legally, mind you) credit
card purchases for grow lights, unquestionably legal even if
associated with one of the least significant forms of drug use.  So
not every illegal thing is followed (not even the most serious) and
legal things are.
   Let me ask you a question.  If people can communicate over the
   net anonymously, tranmit unreadable messages, and transfer
   unlimited amounts of fully anonymous money, haven't you, in
   addition to protecting some of the interests of minorities, also
   perfected a mechanism by which people with evil intent can engage
   in criminal activities completely unobserved and with no fear of
   prosecution?
No, we have not.  What we have perfected (assuming your hypothetical)
is a system where anybody with whatever intent can move money around
with a strong assurance of predictability.  This is manifestly _not_
the same as engaging in criminal activities completely unobserved.  To
pick only the most obvious examples, drug organizations still need to
manufacture and distribute, and these will always remain very tangible
   I have always believed that people won't come outside to play
   with you unless they feel safe.  We want electronic commerce to
   work everywhere in the world.
Well we want it to work everywhere in the world, too, because that
increases the opportunity for regulatory arbitrage.
A parallel with eurocurrency markets is instructive.  If England
allows an anonymous system and the USA doesn't, then I'll open up a
eurodollar account in England and transact there.  If England doesn't
want to allow the system to operate there, but is willing to hold
dollars for another bank in, say, Hong Kong and Hong Kong allows
anonymous transaction, I use a dollar account there.
In fact it's because of the ability to perform transactions of this
nature at arbitrary points in the globe that anonymous systems will be
very difficult to prevent in the long term.  There will be money in
it, you see, and military protection and fiber optic cable is not
particularly expensive for a national government which wants a new
industry, like, say, India or South Africa or Vietnam.  There's a
distinct possibility that the first country to deploy these systems
will set up a new world financial center, and that's playing for the
big time.

@_date: 1994-12-01 18:21:13
@_author: Eric Hughes 
@_subject: Re: Eric, please can you clarify 
From: j.fletcher (Jonathon Fletcher)
     Can you clarify your intention for the list ? I'm a little puzzled by
   the alternatives that are flying about. The first time this got debated was last year.  There the proposal was
check sigs, delay, eventually bounce.  That's not what I'm proposing
this time.
I mentioned this again, and the discussion started up again.  Almost
at once I wanted to avoid the flames from the previous time, so I
restricted the proposal to be for marking and delaying only.
   Are you intending to implement both of
   these, one of these, or one now and the other later ? First of all, I'm not "planning" on any right now.  I am considering
doing some of them and I have decided to do some related work.
The first action would be autonag; messages sent back to non-signers
from the server.  The second would be automark; header fields for
advocacy would be added to the messages.  The third would be delay for
some as yet unspecified interval.
The timing of these is not decided, and would certainly be iterative.
   What type of
   checking are you intending on signatures - just syntax or signature
   verification ?
At first, only syntax checking.  The problems of key distribution
prevent otherwise.
   I apologize for asking for clarification, but I've lost the signal in
   amongst all this noise.
No, actually, a summary was in order.

@_date: 1994-12-01 20:28:29
@_author: Eric Hughes 
@_subject: Re: making public keys public 
From: lmccarth
   If you're not going to make the public key public, why use public key
   cryptography at all ?  Save time and effort and use a symmetric cipher.
You can't do authentication with a shared secret key, because there's
nothing to differentiate the two sides of the link.
In addition, a closely held public key might be held by 10 people;
with secret keys there are 90 different private keys instances to

@_date: 1994-12-01 21:55:42
@_author: Eric Hughes 
@_subject: Re: ERIK HUGHES: EGOTISTICAL PRICK 
ask him why he hasn't graduated
   from college!!
A.B. 1988 University of California, Berkeley.  Mathematics.  GPA 3.9.

@_date: 1994-12-02 07:11:10
@_author: Eric Hughes 
@_subject: Re: Cypherpunks@hks.net service 
From: dmandl
   What's next, automated key-signing
   services?
There are two purposes to signing a key.  The first is to fix a bit
pattern and have an assurance that it hasn't changed.  The second is
to attest to the mapping between a key and some entity.
PGP, for example, very explicitly does both.  It asks you when you
sign a key if you're sure that the person is who is advertised.  I
consider this behavior broken, not the least because it's hostile to
pseudonymity.  This hardcoded policy hinders the use of PGP in other
For email-only social contact (i.e. legally uninvolved) the
attestations of personal mapping are unnecessary and sometimes
downright undesirable.  Some people may want them, true, and there
will be a need for that mechanism, but it should not be the only
choice available.
An automated key-signing server can affix a sequence of bits perfectly
adequately.  So can digital timestamping algorithms, but they are not
generally available.  Suppose the existence of just two auto-signing
servers.  I, a pseudonym, send my key to each of these servers and get
back a two signatures on my key.  It is unlikely now that someone can
spoof my key.  The distribution for the signing keys of these servers
must be done right, but since there are fewer auto-signing servers
than things signed, more effort can be taken to do this, for example,
by publishing some hashcodes in a book.

@_date: 1994-12-02 07:19:32
@_author: Eric Hughes 
@_subject: Re: Brands excluded from digicash beta 
From: paul ("Paul Dinnissen")
   > The more I deal with Digicash, the better First Virtual looks. My
   > technical preference is for using Brands or Chaum cash; at present,
   > though, there aren't any shipping Brands servers, and the Digicash
   > folks don't seem to be able to get all their socks in one bag.
   We feel somewhat troubled by these comments.  As well you should.
The facts of the matter is that First Virtual currently provides a net
benefit by moving real value (e.g. dollars) around, and Digicash does
not.  Until the Digicash system can move real value, there is no
reason to use it.
The technology is irrelevant.  _If_ you can move real value, you can
provide a benefit.  _Only if_ you can move real value can you provide
a benefit.

@_date: 1994-12-02 07:22:31
@_author: Eric Hughes 
@_subject: Re: Authentication at toad.com: WTF? 
From: wcs (bill.stewart +1-510-484-6204)
   Trusting someone else's verification
   is less than ideal security policy :-)
But likewise, preventing folks from letting someone else (their legal
agent) perform verification for them is a less than ideal political
There are going to be lots of good reasons (mostly of cost) to use
agency relationship for security.  It would be profitable to
characterize the threats and come up with some solutions rather than
to deny that these things will happen.

@_date: 1994-12-03 08:58:16
@_author: Eric Hughes 
@_subject: Re: First Virtual? 
How can you really compare the proposed DigiCash systems versus
   FirstVirtual?  One is a 'toy' system for moving credit card numbers
   around without actually broadcasting them in the clear, the other
   is a cryptographically secure digital cash type system.
Digicash and First Virtual and Net Bank are all payment systems.  The
primary benefit is moving money.  _All_ other benefits are secondary,
including privacy and security.
As far as actually being a payment system, it's Digicash's trial which
is the toy system.  It can't move money.  First Virtual, no matter
what its flaws, can.  Not particularly securely, not quickly, but
money will move.  Just because FV is a bad payments system doesn't
mean it's not a payments system.
There's no question at all that Digicash's technical means are
superior to First Virtual's.  But technical means alone do not make a
business and Digicash at this moment doesn't have a business but
rather only a possible opportunity for one.
First Virtual has all sorts of problems.  Its security sucks.  It will
have a higher fraud rate than other credit card uses.  Merchants won't
particularly like it because of this and the delay in payments.  Users
won't like it because the interface sucks.  It's not fully fungible
money, because you can't use it for arbitrary commmerce.  Fine.
Because of all these concerns, FV won't be suitable for many purposes,
but it will be for some.
What FV's commercial advantage will be is that they'll have a
pre-existing user base on hand when the improved system comes.  This
is a not insignificant advantage, since it's much easier to deal with
someone you've already been dealing with than with somebody new.

@_date: 1994-12-03 09:02:37
@_author: Eric Hughes 
@_subject: signature checking at the server 
Unbelievably, I don't think this old canard has come up yet in this
   I've always perceived    PGP(Tm) as something I would use when I really had    something sensitive to send a friend, If you encrypt only some messages and not others, every use of
encryption will indicate that something significant is going on, which
is a first class message of its own.  Only if all messages to
particular correspondents are encrypted do you reveal no information
about importance.
Encryption still has benefit here, but the argument that it should
only be used when important has no merit.

@_date: 1994-12-03 09:14:35
@_author: Eric Hughes 
@_subject: Re: MIT Keysigner CA 
From: cdodhner (Christian Odhner)
   I trust a key to be an introducer if and when    I am sure that a signature by that key means that the signed key belongs    to the identity (be it "real" or a 'nym) it claims to represent. There is a qualitative difference between a real identity and a
pseudonym identity.  A real identity has a body attached to it and a
pseudonym identity does not.  The phrase "belongs to" cannot be used
in the same sense for both of these, and the failure to discriminate
between them is a fallacy.
With a pseudonym, the identity _is_ the key.  All you need to do is to
ensure that the pattern of bits in the key does not change during
As far as an MIT autosigner, the signature will simply represent a
reduction to the trustability of the MIT account assignment procedure.
This is not a reduction to bodily identity and should not be construed
as such.
In fact, a MIT autosigner is exactly what I was talking about when I
advocated that communication provider sign keys.  (Good work as usual,
Derek.)  The signature here represents an attestation that a given key
(that is, a given identity) can be reached through a particular
Almost all email is effectively pseudonymous already, even if there is
a shadow of the procession of bodies behind the email.  It makes good
sense to speak of mailing to a key; this is the logical operation of
creating an informational space accessible only to the holder of a
secret.  A mailbox is merely a physical and technical means for
reaching that space.

@_date: 1994-12-03 09:35:12
@_author: Eric Hughes 
@_subject: Re: Disclaimer within signed body? 
Todd's autosigner raises some good issues about what signatures can
actually represent.  Todd's service takes an incoming message,
attaches a note about technical means and also a signature.
As Todd points out, this signature represents the fact that a message
destined for the cypherpunks list passed through his server.  But Todd
also wants the signature to attest to the disclaimer attached to the
mail.  The signature, therefore must be affected by both segments of
text, that is, the disclaimer must be inside the signature.
There is also, however a desideratum that the original message be
preserved to the greatest degree possible.  Since two text segments
must go inside the sig block, there must be a packaging syntax to
represent a two part message composed of the original message and the
disclaimer.  There is already a syntax which accomplishes this for
I'm not going to get the syntax of this example right.

@_date: 1994-12-03 14:21:11
@_author: Eric Hughes 
@_subject: Re: Brands excluded from digicash beta 
From: alex (Alex Strasheim)
   > Until the Digicash system can move real value, there is no
   > reason to use it.
   I think I'm missing something here.  Isn't the Digicash system in a
   beta-phase?  At this point, aren't they just trying to work out the kinks
   and show people that it works? Yes, it is granted that Digicash is in beta, and not polished.  But
beta testing usually happens after all significant functionality is
present.  The Digicash beta isn't moving real money, and that's a
significant functional deficit.
   Obviously, a system that hasn't been deployed isn't as useful as one that
   has.  This is substantially my point.  DC and FV are not directly
comparable, because one does something directly useful and the other
   The question is, once Digicash is released for real, how will it    compare to FV?
Who can say?  It hasn't been released for real.  Clearing and
settlement in a payments system are _most_ of the problem, not sugar
coating.  FV is leveraging Visa for settlement, but Digicash currently
has nothing.

@_date: 1994-12-04 06:54:46
@_author: Eric Hughes 
@_subject: Re: ecash trial issues explained 
From: usura (Alex de Joode)
   One of the limitations of the DDS is that mail only can be send to
   adresses that are in the .nl domain, so you cannot forward your mail.
Can't it be packaged up and automatically sent through an Amsterdam
anonymous remailer back to oneself?

@_date: 1994-12-04 06:53:52
@_author: Eric Hughes 
@_subject: Re: Brands excluded from digicash beta 
From: jrochkin (Jonathan Rochkind)
   The current digi-cash software, as I understand it, would work
   find in a real-cash situation.  You would just need to pay for your ecash.
"Just"?  That's where _most_ of the problem is.

@_date: 1994-12-04 06:56:46
@_author: Eric Hughes 
@_subject: Re: Brands excluded from digicash beta 
From: alex (Alex Strasheim)
   Unless Digicash has significant problems with banks or governments that I    don't know about (always a possibility), I have a simple rule of publicity here.  If there were a bank who had
already agreed to back ecash, would it not already have been
announced?  Since no announcement of the sort has been forthcoming, I
conclude that the probability that such a backer exists right now is

@_date: 1994-12-08 17:29:35
@_author: Eric Hughes 
@_subject: Re: backing ecash 
From: alex (Alex Strasheim)
   Suppose Digicash opened up a digital currency exchange in Amsterdam.
   [...]
Left unexamined here are the ways in which various things can go
   Edollars would still have value here in Lincoln, NE USA.
How much?  Not full value, that's for sure, because of the risk cost
associated with getting the edollars back to Amsterdam.  What happens
when womthing goes wrong in Amsterdam?  What happens?  What effective
recourse does a USA holder have with respect to a Netherlands company?
Your basic idea, however, is right on target, that you don't need to
be a bank to issue digital currency.  On the other hand, with that
realization your problems are only beginning.

@_date: 1994-12-08 17:36:43
@_author: Eric Hughes 
@_subject: Re: Dec. 10th Bay Area Cypherpunks Meeting 
Aren't there multicast provisions at SGI? Eric?
We may be multicasting this weekend.  Far more important than my
involvement is that of our host there at SGI, Katy.  Her crew gets the
MBONE running.  There are some fiddly things with the SGI firewall,
etc., that I just don't understand.
So I'm passing the buck.  Katy?

@_date: 1994-12-09 05:43:46
@_author: Eric Hughes 
@_subject: Anonymity in the foreign exchange markets 
The following two page spread advertisement is from the Economist Nov
12, 1994.
Note that not only are they selling anonymization services for *huge*
sizes, they're also selling traffic analysis avoidance.
From what I know about the business, a typical commission is 1%, or
somewhere around $10 million for th advertised transaction.

@_date: 1994-12-09 07:20:04
@_author: Eric Hughes 
@_subject: Re: Secure DAC? 
From: sinclai (SINCLAIR  DOUGLAS N)
   [re: a constant current consumption chip]
   I fail to see how this would increase cryptographic potential.  However,    it would seem to mask the device's EMR.  One of the largest sources of radiated signal goes out the power
supply.  Some of the really high security chips, evidently, double
every gate for constant current draw.

@_date: 1994-12-11 09:43:02
@_author: Eric Hughes 
@_subject: Re: "Crypto Anarchy and Virtual Communities" 
From: tcmay (Timothy C. May)
   I hate to put files in my ftp account, as Netcom's ftp site is grossly
   overcrowed and nearly all attempts to access it fail. (Netcommies are
   roadkill on the I-way.))
Tim May, famous net.commie.
Uh, wait, ...

@_date: 1994-12-12 17:45:34
@_author: Eric Hughes 
@_subject: Re: Time to exhaustively break 40-bit RC4? 
From: ianf ("Ian Farquhar")
   No, because as you're doing an exhaustive keysearch, you can "pipeline"
   the key generation process in software.  Each key requires 256 swaps,
   certainly, but there are only two swaps difference between the key
   for "0000000000" and "0000000001" (assuming a 40 bit key).  Not by my count.  The key data length for a forty bit key is only 5.
That means that each byte of the key data is used about fifty times in
key setup (256/5).  Those initial changes in the internal key
permutation table then propagate under iteration.
Now I haven't looked very closely at how to optimize this search, and
it's not even clear that it's possible.  There are 256! possible
permutations for the internal key, which is a lot more than 2^40
possible (external) keys.  It's quite possible that the internal keys
are just not particularly close to each other.  Close here, say, is
the minimum number of swaps needed to take one key to another.
It's possible that some arrangement other than incrementing the key
yields internal key correlations that speed up software internal key

@_date: 1994-12-12 18:04:14
@_author: Eric Hughes 
@_subject: IPSP and Netscape 
I've tried really hard to stay out of this, but this one is just too much.
The question is about IPSP, the swIPe-like IP level security protocol.
   From: kipp ("Kipp E.B. Hickman")
   Name one router that speaks the secure protocols you are
   documenting? Name one PPP based bridge that does? Show me, today,
   what percentage of the Internet is covered by these standards?
   [ ... later ... ]
   My company's network hardware is typical. It is filled with
   expensive devices that don't understand IPSP or IPNG. In fact, most
   of the world is constructed this way.
The protocol does IP-within-IP encapsulation, which means that every
single router deployed is able to carry the secured traffic.
Now, this is not so egregious an error by itself (it is, but I'm being
polite), but coupled with the claims that SSL is better than anything
else out there, I see an argument from chauvinism rather than one from
Since IPSP works at the IP level rather than at the TCP level there
are protocol stacks that have to change.  This is not immediate.  It
may be that IPSP is not the quickest or best way to link security, but
that is not the point I am making here.  The original denial of IPSP's
potential utility was made in complete ignorance, ignorance so great
to lack even the most basic understanding of the subject at hand.
I cannot trust abbreviated arguments from such a source.  I can,
however, examine ones which are complete and well thought out and
demonstrate some understanding of tradeoffs.

@_date: 1994-12-12 18:11:05
@_author: Eric Hughes 
@_subject: public key algorithms and Netscape 
The claim was made here by someone at Netscape that no suitable public
key algorithms existed other than RSADSI technology.  I don't remember
how explicit this claim was; it may have been an implication of some
more general statement.
I note that the folks at Netscape must never have heard of elliptic
curve algorithms for public key technology.  I would hazard that
representatives at RSADSI stated or implied that such technology was
covered by their patents.  I would then ask if they said so in
Making claims about a patent that are knowingly false is grounds for
vacating the patent.
The IEEE P1363 working group on cryptography standards is moving
forward with elliptic curve cryptosystems but not with RSA because of
patent issues.  Coincidence?

@_date: 1994-12-12 18:20:15
@_author: Eric Hughes 
@_subject: Re: Clarification of my remarks about Netscape 
From: kipp ("Kipp E.B. Hickman")
   If this hadn't been made clear already, then hopefully this will:
It's clear to me.  "We're going to use some security, as long as it's
called SSL and our authorship is on the document."

@_date: 1994-12-12 18:21:06
@_author: Eric Hughes 
@_subject: Re: Clarification of my remarks about Netscape 
Please provide a reference for "Photuris".
Ah, the hazards of not going to IETF...

@_date: 1994-12-12 18:37:39
@_author: Eric Hughes 
@_subject: Re: [cpunks] Re: public accounts / PGP / passphrases 
From: werner (tim werner)
   But I agree that the idea of buying a laptop so you can use PGP at work
   is odious.  There must be a better way.
But remember, the computer you normally use at work is the property of
your employer, and they are Free to Deny You Privacy with it at work.
It remains to be seen where the chips will fall with respect to
workplace privacy generally.  Perhaps workplace email is a good
argument for wireless.

@_date: 1994-12-12 18:49:11
@_author: Eric Hughes 
@_subject: Re: BofA+Netscape 
How many times will there remain the confusion between what is
achievably optimal and what is permitted?
   From: jamesd (James A. Donald)
   Now plainly they should listen very carefully to what the guys
   at CERN say about SGML tags, but as far as I can see, the groups that
   you want them to take consensus with, have no standing in this matter.
This is all very Libertarianly Correct, certainly, but it may also be
downright stupid.
If one WWW company manages to fragment the web, the total value
available to all drops, and it may also be that individual value is
also less.  Communications technologies have use-value superlinear in
the number of people using compatible systems, so fragmentation always
reduces total value.  Whether the individual fragmented value is
greater or larger than an individual non-fragmented value I cannot
say.  I do know that free software has this tendency to be easily

@_date: 1994-12-12 18:55:26
@_author: Eric Hughes 
@_subject: Re: Broadcasts and the Rendezvous Problem 
From: cactus ("L. Todd Masco")
   That's not a very good approach: a human has to add a new remailer into
   the "net" by adding it to the systems polled.  Not only is the human
   intervention a Bad Thing, but having a central registry of remailers
   is bad infrastructure.  A more "web-of-trust"-like mechanism is desirable.
In terms of autopinging, certainly human intervention is not desirable.
This begs one question though, namely, "how does one gain trust in a
remailer?".  Certainly likelihood of service can be automated, but
other forms of trust cannot.  Human intervention is necessary each
time someone begins to trust a remailer.  That intervention can be for
one's own use or for someone else's, but automatically trusting new
remailers is Not Good.
The question then becomes "what is the structure of human intervention
required to change the trust in a remailer?".  Use of agency will be
desirable, certainly.
These questions of human relations need to be examined before
technical means of communication can be profitably pinned down.

@_date: 1994-12-12 20:59:35
@_author: Eric Hughes 
@_subject: Re: BofA+Netscape 
From: jamesd (James A. Donald)
   Eric, read more, flame less, you might learn something.
Ah, I see.  Disagreement equals flaming.
   I posted a lengthy explanation of why it was counter productive    to take consensus with those who are lagging. And since they were _your_ ideas, they were correct.  You did not
reply to the substance of my own comments.  I now must hypothesize
that you didn't understand them.  I am at least polite enough to
refrain from implying that you didn't read them.
   A few years back, when the standards for new RAM chips
   were debated
The analogy between physical manufactures and compatible software is
inaccurate.  I implied that in my post, but I take it you didn't
follow my conclusion very far.
   In short, when the leading edge company dominates the
   standards committee, it is of little use, and when the    old companies dominate the standards committee, it is
   actually harmful.
The domain of applicability of this situation is not universal.
There is good reason to believe that it does not apply here.

@_date: 1994-12-12 21:43:10
@_author: Eric Hughes 
@_subject: Re: BofA+Netscape 
From: jamesd (James A. Donald)
   Because they did not have any substance.  You claimed I was
   arguing from libertarian correctness.
Perhaps you don't know the meaning of whitespace and paragraph breaks.
I did claim you were arguing from libertarian correctness.  Now that's
just an insult, which I do not retract.
In a second paragraph, I began a new argument which did not depend on
your subjective state of mind.  I currently think that you just got a
weensy little inflamed and didn't bother to try to understand the
argument, projecting that the remainder must be similar.
   This was not the case, as you now implicitly acknowldge
   by belatedly addressing the argument I did make instead
   of the argument that you alleged I made.
Oh, please.  Go back and read what I originally wrote.  Perhaps I
overestimate your ability to ascertain relevance, though.
   The short of your argument is that Netscape will fragment the
   net by running out there and dumping something in the market
   place without consensing with all the big boys.
This is not an argument.  This is a premise.  I suggest you go back
and try to summarize what I actually said.  (Hint: it has to do with
game theory.)

@_date: 1994-12-12 22:58:57
@_author: Eric Hughes 
@_subject: Re: Winsock & PGP Integration 
From: jcorgan (Johnathan Corgan)
The proposal is to spoof protocols under windows.  The idea seems
perfectly sensible to me.
   Except one.  What all of these agents have in common is that they
   interface with the Windows Sockets API to establish TCP streams
   that are used in the POP and SMTP protocols.  Since these are well
   known and standardized protocols, this gives us our toehold.
How might an interposed winsock DLL recognize what high level protocol
it was going to spoof?  Getting the port number will be a very good
approximation, but I'm not convinced of its reliability.
As to the general issue of MSWindows v. Unix, the Unix predominance
for remailer software involves the fact that Unix is on the bulk of
the machines connected to the Internet.  It's more reliable for
offering network services than MSWindows and it's got a cleaner
architecture for reconfiguration.  None of these explanations,
however, means that there won't be more MSWindows that Unix boxes for
a long time.

@_date: 1994-12-12 23:54:42
@_author: Eric Hughes 
@_subject: Re: BofA+Netscape 
From: jamesd (James A. Donald)
2. Typographically Challenged.
   Eric Hughes replies:
   > Perhaps you don't know the meaning of whitespace and paragraph breaks.
   And then he contradicts himself:
   > I did claim you were arguing from libertarian correctness.  Now that's
   > just an insult, which I do not retract.
Aren't we dense today?
Paragraph 1: Insult
Paragraph 2: Argument
Whitespace and line breaks are used as thematic separators.  Let me
use very small words now: The first paragraph was about one thing, and
the second paragraph was about something else.  There was a blank line
between the two which means that these two things are not like each
4. Striving to think.
   I argue that good standards are created by victory in the
   market place, and bad standards are made by committees
   and consensus.
Without altering the denotation of the sentence I can interpret this
as "all good standards" and "all bad standards".  Well, that sounds
like an example of Libertarian Correctness to me.
The flies in the market place _uber alles_!
   You argue game theory that would be valid given your premise
   that cooperation works in this case.  You are seriously misrepresenting my position in this restatement.
First, you will not distinguish between a simple indicative and a
modal form.  What I was pointing out is that it's not clear that
cooperation doesn't work, i.e. it may work.  "May" here is the modal
form.  Second, you will not distinguish an implication from its
converse.  I argued that, given plausible game-theoretic assumptions,
that the best outcome is cooperation.  Game theory is the premise;
cooperation is the conclusion.
Mind you, I'm talking to the _rest_ of the list here.
6. A tip: avoid auctions.
   You do not reason using game theory, you use it as a code
   to express moral claims without having to justify them.
James Donald asked be asked me what iterated dominance was a couple of
weeks ago.
James, do you know _anything_ about game theory?  Anything at all?

@_date: 1994-12-13 00:06:13
@_author: Eric Hughes 
@_subject: Re: What, exactly is elliptic encryption? 
From: db (Doug Barnes)
   For the different isomorphisms of the curves, you can then
   construct addition of coordinates, subtraction, multiplication
   and division, such that the results are also points on the
   curve. This makes this set of points an abelian group too. Well, you actually get just addition and subtraction as binary
operations.  Multiplication is integers by elliptic curve elements and
is shorthand for multiple additions.  Division doesn't always make
   You can then do a Diffie Hellman analogue substituting
   multiplication for exponentiation, and a El Gamal analogue
   substituting multiplication for exponentiation and addition
   for multiplication. The multiplication takes an integer (the exponent analogue) by a curve
element (the base analogue).
   There is an IEEE group    working on a proposed standard at the moment; I need to get back    to my contact with them to find out where they are at now.
Burt Kaliski of RSA Labs is the chair of P1363.  Archives are at

@_date: 1994-12-13 09:45:10
@_author: Eric Hughes 
@_subject: Re: What, exactly is elliptic encryption? 
From: perry ("Perry E. Metzger")
   Basically, there are ways of extending public key methods into fields
   other than the integers modulo some prime
Small correction.  While integer modulo a prime are fields (i.e. they
have division), elliptic curve solutions only have a group structure,
which is usually written as addition.

@_date: 1994-12-13 10:43:14
@_author: Eric Hughes 
@_subject: Re: IPSP and Netscape 
From: kipp (Kipp E.B. Hickman)
   IPSP was not in my vocabulary at the time of the first posting. Ignorance
   was briefly bliss :^)
This indeed was exactly the problem.  Might I suggest that a some
amount of acknowledgement of the outside world and a survey of
existing work would solve most of Netscape's PR problems on this list?

@_date: 1994-12-14 06:41:38
@_author: Eric Hughes 
@_subject: Re: Legal implications of a PGP DLL 
From: bshantz
   [..] I never found out [...] what was decided in regards to the
   legal implications of a PGP functional DLL for Windows.
If a PGP DLL were rewritten from scratch and placed in the public
domain the only concern would be patent licensure.  By rewriting,
you've removed any sort of copyright issue.
The only was you'd get an RSA license is to use RSAREF.  That means
that use of the DLL would be restricted to non-commercial use.  You'd
also need an IDEA license, but I suspect that if you're just doing
something PGP compatible you'd be able to obtain that, especially
since it would be non-commercial because of RSAREF.
If you need commercial accessibility, you'd need licenses from RSADSI
and Ascom-Tech.  You could then give the DLL away, but RSADSI wants
minimum royalties, so you'd be subsidizing the public.  I don't know
the situation with Ascom.

@_date: 1994-12-14 06:55:21
@_author: Eric Hughes 
@_subject: Re: Elliptic crypto is patented 
From: rishab
   Incidentally Next Computer's Fast Elliptic Encryption, FEE, used
   elliptic curves, and is patented (by R E Crandell, USP#
   5,159,632,27 October 1992); Does anybody have a copy of this to see exactly what is claimed?
   elliptic crypto is probably
   covered by the DH/PKP patents.
If you believe RSADSI it is.  Now, are they going to say otherwise?
The fact of the matter is, you can't patent ideas, nor general
characteristics of devices.  You can patent particular processes or
mechanisms for particular purposes.  If you come up with a different
process or mechanism, the patent does not cover it.  If you come up
with a different purpose (!), the patent does not hold.  The limitation to this difference is the doctrine of extension.  A
patent covers not only the particular thing patented but also things
substantially similar to it.  This is to prevent trivial changes from
remaining unprotected.
Another, less relevant, protection is given to inclusion.  If a device
includes a patented mechanism, then the patent is required to practice
the device, even if the larger device is also patented.  Ciphers
typically do not include other specific ciphers wholesale, so this
doesn't typically apply.  One big exception is the blind signature,
which does use specifics of RSA.  This may be one of the issues with
respect to restricted availability of the ecash trial in the USA.
In my opinion, RSADSI is claiming far too much for their patent
portfolio.  In particular, claiming "all public key" is just hogwash.
Elliptic curve cryptosystems certainly use a different enough
mechanism not to fall under extension.  El Gamal is a completely new
mechanism; if RSADSI wants to claim that modular exponentiation for
crypto is covered, they'll have a hard time actually arguing that one.

@_date: 1994-12-14 06:57:54
@_author: Eric Hughes 
@_subject: Re: It works. 
From: storm (Don Melvin)
   Funny thing is, last night I actually had a valid reason to send something
   that I wanted to make sure didn't get read along the way ($ involved).  I
   had all the pieces, they were in place, they worked.  And due to time
   constraints, I wouldn't have been able to do it, if everything hadn't
   been ready.
   So, thanks Eric.
You're welcome.
Your story underlines one of the main reasons to set up personal
crypto sooner rather than later.  When later comes, it may be too

@_date: 1994-12-14 07:05:56
@_author: Eric Hughes 
@_subject: Re: Legal implications of a PGP DLL 
From: eric (Eric Hughes)
   The only was you'd get an RSA license is to use RSAREF.  That means
Excuse me.  "The only way you'd get a _free_ RSA license ..."

@_date: 1994-12-14 07:08:56
@_author: Eric Hughes 
@_subject: Re: Using HotWIRED without provoking junk mail 
From: avi (Avi Harris Baumstein)
   -at least this wired staffer was somewhat amused with the prospect
   (rather than annoyed, as i had expected). I ran into one of the Hotwired guys at a couple of weeks ago.  Not
only didn't he mind particularly, he thought it most appropriate that
the general purpose pseudonym account was called 'cypherpunk'.
   -the account is well used.
In fact, the 'cypherpunk' is by far and away the No. 1 user of
Hotwired.  Maybe 'cypherpunks' will become number No. 2.

@_date: 1994-12-14 07:46:26
@_author: Eric Hughes 
@_subject: properties of FV 
From: nsb
   Wrong.  A First Virtual transaction takes place as a single step via
   mail, FTP, or WWW.  *After* the transaction there is an email exchange
   to confirm the purchase [...]
If this email exchange is necessary and not merely advisory, then it's
part of the transaction, unless you have a far different notion of
transaction than I do.
   This depends on your definition of anonymity.  There are two forms of anonymity: counterparty anonymity and issuer
anonymity.  FV claims the first but not the second.  "Far from
anonymous" may be a little confusing, but it's certainly far from
completely anonymous.
   I think this meets most practical standards for anonymity, [...]
That depends on your standards, I suppose.  It's certainly not
sufficient for anonymous mail with digital postage.
   > and its minimum transaction cost
   >    is high enough to rule out its applicability for very small
   >    transactions.    Wrong again.  We explicitly permit seller-based accumulation, [...]
Net clearing of this form requires the creation of an entire billing
system for small value which then settles through FV.  The very nature
of such a net billing system requires linkability of transaction to
transaction, or in other words generates identity.  So FV is
unsuitable for small value anonymous transactions.
   We expect to make our money on
   information products, not on the commerce engine.
At 29 cents plus 4% per settlement transaction, I find this comment
disingenuous in the extreme, even after paying Visa for settlement.
   > it seems odd to build a unconditional rejection into
   > the payment system, especially for products that can't be
   > returned in any meaningful sense.
   Of course it can be done without bundling it into the payment protocol. But, I suspect, it can't be done if you want to piggyback on Visa's
settlement system.
   By "bundling" it into the payment
   protocol, we have been able to achieve a vast SIMPLIFICATION of the
   payment protocol.
You haven't simplified the protocol, you've simplified your business
   It is not a coincidence that we are the first (and so
   far, still the only) system that is operational with real money.  I question "first".  Certainly one of the first.
In any case,, it isn't a coincidence that you were able to start up
quickly, because you didn't build a settlement system for real value
but rather used someone else's.
   [... earlier in the post ...]
   (And FYI, we know whereof we speak: we use cryptography
   heavily internally, and we are extremely aware both of its power and
   utility AND of the practical difficulties in its use.)
   [... then later ...]
   The email confirmation is indeed a bit
   cumbersome if it gets invoked very often and your mail system isn't
   FV-smartened.
So if you're planning on removing the cumbersomeness of your current
protocol with software, why is it that you don't have an option to
turn on crypto, whose cumbersomeness can also be mitigated with
This position seems, well, inconsistent.

@_date: 1994-12-14 08:56:55
@_author: Eric Hughes 
@_subject: A short primer on algebra 
In the interest of good mathematical terminology, here is a short
primer on the most basic algebraic structures.  The definitions are
not complete but rather evocative and are designed to prevent
Field -- has addition, subtraction, multiplication, and division.
Examples are the real numbers (R), the complex numbers (C), and the
rational numbers (Q).  An important class of fields for crypto are
integers modulo a prime (Z/pZ or F_p).  An important class of fields
for error coding are polynomials with binary coeffients modulo an
irreducible polynomial (F_2[x]/p(x)F_2[x]).
Ring -- has addition, subtraction, multiplication, but no division.
Every field is a ring but not vice-versa.  Examples are the integers
(Z), the integers modulo a composite number (Z/nZ) and polynomials
with various rings, including R[x], Z[x].
Group -- has either addition/subtraction or multiplication/division,
but not necessarily both.  Every ring is a group under addition, but
not vice-versa.  If the group is commutative, we write the operation
as addition typically; if not, we use multiplication.  Examples of
commutative groups are solutions of an elliptic curves and rotations
in the plane.  Examples of non-commutative groups are permutations,
rotations in three dimensions, and Euclidean transformations of the

@_date: 1994-12-14 17:18:09
@_author: Eric Hughes 
@_subject: Re: rad 
From: ianf ("Ian Farquhar")
   The main reason why noone from the NSA comments is simply because
   there is a perception that anything they say will be taken as NSA policy,
   disclaimers notwithstanding.
Sounds like a job for a remailer.

@_date: 1994-12-15 07:39:41
@_author: Eric Hughes 
@_subject: Re: properties of FV 
> Net clearing of this form requires the creation of an entire billing
   > system for small value which then settles through FV.     No, it doesn't require an entire billing system, because it lives
   entirely on the seller's machine and does nothing except the pre-billing
   accumulation for a single seller.
Just because it's all on one machine doesn't make it not a billing
system.  If it does "nothing except pre-billing", then it doesn't
have the ability to tie into FV.
Such an "accumulation system" has all the properties of a standard
billing system.  It has accounts with accumulate claims, it
periodically asks the customer to pay off liabilities, and it must
check that payment has actually been made.
Just because the values are small, the process is partially automated,
and it all happens much quick does not prevent it from being a billing
system.  Personally, I'd call it a receivables system, because that's
much closer to existing terminology for the actual accounting function.
I'm not trying to imply that you couldn't cobble something up fairly
quickly, but I have my doubts that a good quick hack will scale
appropriately for even a modest sized operation.
   > The very nature
   > of such a net billing system requires linkability of transaction to
   > transaction, or in other words generates identity.  So FV is
   > unsuitable for small value anonymous transactions.
I would still like to you address this issue, if only to acknowledge
the above characterization.
   > At 29 cents plus 4% per settlement transaction, I find this comment
   > disingenuous in the extreme, even after paying Visa for settlement.
   We're charging 29 cents plus 2%, and this includes all the charges to
   the credit card networks, the banks, and our financial transaction
   processors.  We are NOT operating on a big margin here.
As I had recalled from reading your materials, you were charging 29
cents plus 2% on one leg of the transaction plus an additional 2% on
the other.  Rereading, this is not the case.  Am I remembering a
previous situation?
   As I said in an earlier post this morning, this *is* an option we will
   probably support eventually, although I don't think it is as easy to
   make crypto easy-to-use as it is to make checkboxes easy-to-use, at
   least not without deeply compromising the security of the crypto system.
Partial security is better than no security.
Deep compromises only happen if your expectations of the crypto system
are larger than deserved.  If all you expect is a partial solution,
other aspects of the cryptography fall away.  Just because crypto
_can_ do more than one might use it for is no argument for getting
_some_ benefit out of it.
You've not seen this recently on cypherpunks, but I've been stressing
recently the need to deploy partial solutions.  Roughly speaking,
crypto is good for transit security and storage security.  The primary
security problem with FV is transit security, not storage security.
This is a known solved problem.
There are issue of security of private keys stored on Internet
machines.  Were possession of such a key required in order to crack
the system, however, it would be _in addition_ to everything else
already required.  To mitigate key storage risk I would recommend a
key generated entirely and only for use with FV.
One of the underlying conceptual problems with allowing a key to be at
risk is some sort of belief that compromises of secret keys should
never ever EVER be allowed to happen.  This is ludicrous.  When the
benefit of the use of a private key means that it might be
compromised, don't rely upon it's not being compromised.
In particular, if a digital signature does not, by agreement, carry an
implied warrantee of identity, then there's no problem at all.  Use
the crypto entirely for transit security.  If someone hacks your
machine and grabs your passphrase and forges a transaction, at least
the intruder has to grab your passphrase.

@_date: 1994-12-15 07:52:11
@_author: Eric Hughes 
@_subject: FV fine print 
In looking over the FV docs, I found the following interesting tidbit.
Interpretation is left to the reader.

@_date: 1994-12-15 09:10:50
@_author: Eric Hughes 
@_subject: Re: FV fine print 
From: nsb (Nathaniel Borenstein)
   FYI, this is a direct carryover from the standard terms & conditions of
   a Visa/MasterCard merchant account.  Now that's what I thought it might be, and I'm not particularly
surprised.  If you use Visa, you have to play by Visa's rules.
On cypherpunks, though, information lifetime is just one of those
generally interesting questions.
This information storage requirement is reminiscent of the Bank
Secrecy Act of (I think) 1974.  Is this clause from Visa/MC a direct
(or indirect, even) result of that act, or is this just coincidence?
This is banking arcanity, not crypto arcanity, and I'm not expecting
an answer very hard.

@_date: 1994-12-15 13:16:08
@_author: Eric Hughes 
@_subject: Re: Algebra 
So, how is division defined in Fp?
There's a wonderful little theorem of broad technical use which says
(a, b, m, n are all integers, or more generally, elements of a
Euclidean domain)
   \forall a, b \in Z \exists m, n \in Z : a m + b n = gcd( a, b )
What this says is the greatest common divisor of 'a' and 'b' is a
linear combination of them.  The algorithm to find the gcd is the
Euclidean algorithm; the algorithm to find the constants 'm' and 'n'
is the extended Euclidean algorithm.
To define multiplicative inverses in F_p, substitute 'p' for 'b' in
the above equation.  The gcd of 'p' and any non-zero element of F_p is
1.  (And we already knew you can't divide by zero.)  Now, reduce the
equation modulo p; this turns elements of Z into elements of F_p and
the second term of the addition goes to zero.  What you get is
   \forall a \in F_p \exists m \in F_p : a m = 1 (mod p)
That's the existence of multiplicative inverses in F_p.  Use the
extended Euclidean algorithm to calculate them.
Eric

@_date: 1994-12-15 13:37:12
@_author: Eric Hughes 
@_subject: Re: properties of FV 
[re: making a receivables system for small value]
   Assuming that thing that you're "cobbling together" is based on a
   reasonably robust database engine, it should scale a long, long way. It's not the technology but the number of different kinds of
exceptions to track that cause it not to scale.  You don't need to
solve those problems right away, though.
   > Partial security is better than no security.
   That's a *very* interesting statement.  I'm not at all sure what it
   means, so I'm not sure if I believe it or not.  Sometimes partial
   security is worse than no security because it gives people a false
   *sense* of security.  It's like this.  If there are two ways to break into my house, bashing
in the front door and climbing through second story windows, it's
better to have a strong front door and no bars on the upper windows
than to have no strength in the front door and still no bars.
Regardless of the security, users need to understand what it gives
them.  This is orthogonal to the choice of security, as well as to the
persistence of thick-headedness in society.
   > In particular, if a digital signature does not, by agreement, carry an
   > implied warrantee of identity, then there's no problem at all.  I sense that I this wording was less than fully explanatory.
What this means using FV as an example, say, is that FV will not claim
that a signed message actually originated from someone.  A signature
would be _advisory only_, and carry no legal weight as a signature or
a proof of identity.  You can still require signatures, because this
does improve security.
Suppose that a customer disavows a signed transaction, saying "Someone
must have hacked my account".  What you could _not_ do in this example
is then to claim that "Well, it must be your account; it has your
signature on it", because _by agreement_ the customer is not making
any implicit claims about who actually holds the private key.  In
fact, the disclaimer of a warrantee of identity makes _explicit_
the fact that the private key is not relied upon to be held secretly.
This is partial security.  It is not all that can be accomplished with
crypto; it is only a part.  The partial security, however, still has
   > Use
   > the crypto entirely for transit security.  If someone hacks your
   > machine and grabs your passphrase and forges a transaction, at least
   > the intruder has to grab your passphrase.
   This is exactly the way we would expect to use crypto layered on top of
   First Virtual's protocols, if and when such cryptographic protocols are
   deployed widely enough to have penetrated af meaningful portion of our
   market.
"If and When" is Yes and Today.  Anybody who can autosign their
outgoing mail can participate in this kind of transaction already.
Assuming the above agreement is made with respect to private keys,
there is _no_ risk to the customer about loss of secret keys, and no
greater risk to the merchant than what currently obtains.
The dreams of utopia in cryptography are beginning to hold back
deployment as much as architectural problems.

@_date: 1994-12-16 10:35:47
@_author: Eric Hughes 
@_subject: Thoughts on 15 day CJ crypto 
As most of you know, the SPA/NSA deal for auto-approved export
requires 512 bit RSA and 40 bit RC4.
Everyone knows that 40 bit RC4 is weak cryptographically, but no one
particularly thought that 512 bits RSA was -- weakening, maybe, but
not down in the real-time crack range.
I had an insight yesterday as to that particular requirement.
Consider the standard kind of way that one uses a hybrid crypto
system.  The secret session key is encrypted with the public key.
There are now two ciphers that can be broken.  And you only need to
break one of them.
So the NSA breaks 40-bit RC4 by brute force.  The keyspace is small.
What is left unsaid about the search is that candidate decryption keys
need to be selected.  You can't do a ciphertext only attack if the
plaintext is random bits.
The 512 bit RSA can be used to verify candidate keys.  Doing 2^40
modexp's is probably not how it's done (but it might be), but if you
can eliminate the bulk of candidate RC4 keys in some other way (by
looking at trial decryptions) then you've got a way of verifying the
rest of them.  If trial decryption can eliminate, say, one of every
hundred or thousand keys then the RSA verification could be done in
real time.
So it's possible the RSA requirement is in there to provide an
assurance that the right key was selected.

@_date: 1994-12-17 10:27:10
@_author: Eric Hughes 
@_subject: Re: Thoughts on 15 day CJ crypto 
From: hfinney (Hal)
   This would suggest, though, that RC4 alone would not be allowed, only RC4
   plus RSA.
Or perhaps RC4 at 32 bits.  All these restrictions are key length
dependent.  If you have a smaller search space, you can spend more
time examinining candidates.
   Also, are there restrictions on the encryption exponent?  A 1024 bit RSA
   with a small encryption exponent would be faster to check than a 512 bit
   RSA with an arbitrary 512 bit encryption exponent.  These are public key operations, remember.  The public exponents are
usually only a few bits long anyway, no matter what the modulus.

@_date: 1994-12-17 10:48:28
@_author: Eric Hughes 
@_subject: Re: properties of FV 
From: nsb (Nathaniel Borenstein)
   > "If and When" is Yes and Today.  Anybody who can autosign their
   > outgoing mail can participate in this kind of transaction already.
   However, I have the impression
   you missed the phrase "deployed widely enough to have penetrated a
   meaningful portion of our market".  The argument I see here is like this: "Not very many people have it,
so we can't use it."  Under this rule, FV shouldn't worry about
support for smart front ends, because most people don't have them
already.  FV shouldn't try to deploy mechant software, because most
people don't have it already.  Now I know that you're not claiming any
of these ridiculous things, that is, outside of cryptography.
What I am suggesting is that FV _allow_, not require, the use of
encryption.  Your main concern with cryptography, it seemed, was theft
of secret keys.  As you agree, that concern can be disposed of.  Now
the reason not to use crypto rests on paucity of existing sites which
use it.  If FV were to _require_ crypto, there would be grounds for
concern.  Yet neither of us think that a crypto requirement is
appropriate for the current FV mechanism.
So why, then, will not FV lead for crypto rather than follow?
It must not be the software integration.  PGP-encrypted mail can be
recognized by a regular expression and filtered if you want to
preserve a single address, or even easier make another address.  Raph
Levien's premail will automatically encrypt mail for outgoing users,
It must not be the licensing.  Perfectly legal PGP can be had from
Viacrypt, even for server applications as FV would need.
It must not be for marketing.  Offering merchants a system where the
customers can undertake an effort to lower the merchants's fraud rates
seems like nothing but a win.
It might be for saving face.  Having argued against crypto so
publicly, changing positions so rapidly might be seen to look bad.
So, I'm confused.  What _is_ still the problem?

@_date: 1994-12-17 14:35:53
@_author: Eric Hughes 
@_subject: Re: Time to exhaustively break 40-bit RC4? 
From: hfinney (Hal)
   I notice in the Netscape SSL spec the 40-bit export-approved RC4
   key generation is a little more complicated than I would have thought.
[The RC4 key is a hash of the external key. Are 40 or 128 bits of this
hash used?]
   If the former, then this extra hash step should really slow down
   exhaustive search of the key space.  If the latter, then it is not clear
   why the master key is key-size restricted at all since it is not likely
   to be used in searching the key space.  It doesn't really matter, from a crack designer's point of view.  It
all depends on what keyspace you're actually searching.  You can
search either the external key (40 bit) or the internal key (larger).
Clearly you have to search the external keyspace.
In order to search the external keyspace, you have to simulate the
whole algorithm, which in this case is not _just_ RC4 but also
preliminary key setup phase.  It's just another part of the algorithm.
To make the distinction precise, what you're searching is not 40-bit
RC4 but rather 40-bit RC4-as-used-in-SSL.  The compound algorithm is
not identical to the underlying algorithm.
This is one of the design problems in Weiner's DES-cracking machine
(designed and unbuilt), that it can only crack DES as such and not
minor modifications to it.  The machine uses a little polynomial
generator (similar to using CRC) to be able to partition the keyspace
among processors and to keep the pipelines full.  This is a hard-wired
The architectural improvement needed in a practical machine would be
an interconnect for key candidate sequencing.  This would add to the
cost of the machine, but only by, say, 20% at most.  It would be
expensive as interconnects go because the bandwidth is so high.
Suppose an RC4 cracker existed with the above interconnect.  In order
to crack RC4-SSL, you'd need a second simulator that did all the
hashing and spat keys out its interconnect.  Such a front end would
have to be designed for every particular configuration used.

@_date: 1994-12-17 14:42:55
@_author: Eric Hughes 
@_subject: Re: Thoughts on 15 day CJ crypto 
From: hfinney (Hal)
   Maybe it would be wise when using limited-length
   session keys to use larger encryption exponents just to confound an
   exhaustive search of the session key space.  It would, but remember that you're generally going to be generating
those keys with the application that will be using them eventually.
One could write a spoofer, perhaps, to generate you're own keys, but
most people won't be using it.
   I think it is surprising
   if there is no limitation on encryption exponent size for these
   exportable key systems, assuming that is the strategy the government is
   using.
Consider the position from the viewpoint of the NSA.  Suppose that the
hypothesis is correct, and session keys encrypted with short exponents
are used to verify candidates.  You haven't told anybody this is the
reason for the particulars of the restrictions.
So, do you, the NSA, write the restriction into the regulation?  Or do
you rely on the fact that the developer will optimize public keys for
The first strategy reveals tactics.  The second carries some risk.

@_date: 1994-12-21 10:21:01
@_author: Eric Hughes 
@_subject: Re: properties of FV 
From: nsb (Nathaniel Borenstein)
   The work involved in adding optional cryptography is much more than you
   might think, particularly because of our internal security architecture.
    Basically, without going into a lot of details, the FV crypto-engine
   would have to live on the non-Internet machines that are not in our
   direct control, and this would enormously complicate the limited
   (batch!) communication we facilitate between the Internet and
   non-Internet machines.
The perceived need for crypto "below the line" comes from the
viewpoint that the system needs to be completely secure because crypto
failures must be prevented at all cost.  Rubbish.  The subsequent
claim that you couldn't possibly put crypto on the Unix boxes which
are in your control is therefore also bogus.
Let's assume that FV were to have a customer agreement that did not
contain an implied warrantee of identity for a digital signature.
Therefore if the crypto gets hacked it's just as if the email system
gets hacked.  Therefore keeping public keys (we're not talking about
FV actually signing anything) above the line on a Unix box is no
different than trusting the mailer on that same Unix box.
I really don't believe FV would have to put crypto on EDS equipment.
   The crypto option is one we're very interested in adding
   eventually, but at this point it would be a major strain on our
   resources.
I think you are far overestimating what it would take.
   Moreover, frankly, if we did it, that would only serve to
   mix our message in many peoples' perception.  It's hard enough
   explaining to reporters that "we've discovered that crypto isn't needed
   for commerce."  Their chance of understanding our message would NOT be
   enhanced if we then added "but we're providing crypto as an option
   anyway."
The message that it's "not necessary for commerce" is reactionary to
the assertation that it is necessary.  By positioning FV in an
adversarial role with respect to cryptography, you'll have the same
problem no matter when you introduce crypto.  I personally think
you'll have a harder time changing your position later, after more
people have been exposed to FV's current position.
A much better public position is that "you can do commerce with or
without crypto", which asserts independence rather than negation.
These two public positions are _not_ identical; they are similar, but
don't be fooled by some positivist notion of denotation into thinking
that they're the same.

@_date: 1994-12-22 09:54:31
@_author: Eric Hughes 
@_subject: MEETING NOTICE: IEEE RSA/Diffie-Hellman Working Group 
The following is the notice for the IEEE P1363 working group.  The
official title includes RSA and Diffie-Hellman, but these two
algorithms are on hold because of patent issues.  The committee is
going forward on elliptic curve systems.
Here's how this committee works.  The working group is composed of
individuals, not representatives of companies.  Anybody can show up
and participate.  The voting rules are as follows.  If you've shown up
at two of the last three meetings, you can vote.  That's it.
The next meeting is typically set at the current one.  The meetings
are held in conjunction with various security conferences, typically,
to make it easier for everyone to attend.  The last two meetings were
at CRYPTO in mid August in Santa Barbara, CA and at the Fairfax, VA
security conference in early November.  The next one will be possibly
at the Oakland, CA conference held in May at the Claremont Hotel.
I'd urge all interested parties to make an effort to attend.

@_date: 1994-12-23 08:10:10
@_author: Eric Hughes 
@_subject: Re: SSL server experiment 
From: kipp (Kipp E.B. Hickman)
   The 1.1 version of server&client will support 128 bit stuff...The 128
   bit client will not be available for ftp though...bloody export laws
How will the 128 bit client be available?

@_date: 1994-12-23 08:39:03
@_author: Eric Hughes 
@_subject: Re: Making sure a program gets to the receiver intact 
From: an169306
   How can I insure a program, once put on FTP sites stays untampered with?
The best solution is not digital signatures but rather digital
timestamping.  The question is not persistence of authorship but
rather persistence through time.  Digital timestamping is not keyed.  The Haber-Stornetta algorithm uses
only one way functions.  The certificate the timestamping algorithm
spits out gives a way of verifying that the modification state
(yes/no) is the same as that of the timestamping root, shared by many
participants.  The assumption is that spoofing the root of the
timestamp system is hard, exactly because it is shared widely.
The initial system published the root in the NYT announcements
section.  Since then, Haber and Stornetta have started Surety
Technology, which is commercializing the patent.  Their new system
doesn't have a single point of failure at the root, it appears, but I
don't know details.
The problem of detecting modification is not the same problem as
assuring that version one was written by the same author as version
two.  The asker of the original question said nothing of versioning.
The question applies to first versions as well, where persistence of
identity is not at issue.
Digital signatures will work to affix a pattern of bits, but as with
digital signatures, if the key is modified, so might be the signature.
Yet digital signatures require private keys, which do persist through
time, and so there is an issue of forward security.  The private key,
if compromised, might be used to sign a statement that the signature
on the binary was a forgery!  With digital timestamping, no keying
information exists to be compromised, so the affixation of bit pattern
is permanent.
   The holes:
   1:  Someone hacking the keyservers, substituting a key for all the people
       who signed, and modifing the archive to show that.
   2:  Someone breaking into my apt, sticking a keyboard monitor on, getting
       my passphrase and key.
This is all a problem of economics.  What is it worth to compromise
the binary?  How much does it cost to perform the compromises?
In fact the real problem is deeper.  The binary, public key, and
signatures can simply be entirely replicated.  Now a person trying to
distinguish between one binary/key/sig triple from the other must rely
upon some social process to distinguish, which is not much different
than the original problem of distinguishing two binaries claiming to
be the same thing.
This is where digital timestamping shines.  The timestamp algorithm
yields time ordering of the various binaries.  Now the discrimination
problem between binaries can be resolved by choosing the _earlier_
one.  We assume that the spoofer has only access to the public version
in order to create an alteration.  Note that this solution doesn't
protect against an insider publishing a modified version before the
actual release.
This is not to say that binaries shouldn't be signed.  A common trojan
horse attack on binaries is to release "bug-fix" versions.  It is in
this situation that the persistence of identity of authorship is

@_date: 1994-12-23 08:43:23
@_author: Eric Hughes 
@_subject: Re: Is it possible to break Norton Encrypt?? 
From: GERSTEIN ("ADAM GERSTEIN, _THE_ MACGURU")
All this moralizing about the issue of breaking someone else's
encrypted files seems to mask one important question:
Does anybody here know jack about Norton Encrypt?

@_date: 1994-12-24 08:50:02
@_author: Eric Hughes 
@_subject: Re: Thoughts on 15 day CJ crypto 
From: karn (Phil Karn)
   Isn't it common practice to pad out a plaintext block with random
   garbage to the size of the modulus before you RSA-encrypt it?
   [...]
   Wouldn't this thwart the kind of attack you describe?
It would, but not having ever applied for a 15-day CJ, I can't speak
to the details of what the implementations actually do.  Perhaps they
permit random padding, perhaps not.  It's certainly possible that the
padding is required to be fixed; that certainly in the style of NSA
'requests' for 'features'.
Can anybody here shed some light on the subject?

@_date: 1994-12-27 12:06:18
@_author: Eric Hughes 
@_subject: Re: Are 2048-bit pgp keys really secure ? 
From: danisch (Hadmut Danisch)
   Usually a candidate number is send through a probabilistic prime test
   which says either "No, not a prime" or "a prime with a probability of
   at least 50% ". Usually this test is repeated 10 or 20 times, so after
   passing this iteration the probability of having a prime number is at
   least 1:2^10 or 1:2^20 . The probability of a composite passing one trial is extremely small,
much smaller than 50%.  _And_ the trials with different moduli are
_not_ independent, so you just can't multiply the probabilities
together.  Rather, you have to calculate a chain of conditional
There was a paper in the last seven or eight years on this.  I believe
Pomerance was one of the authors.  Ask on sci.crypt for details.
   I am also not
   convinced yet of the Fermat test. Why not use a Rabin-Miller-Test ?
Rabin-Miller would be better.  It would be instructive to examine the
conditional probability that a composite number which fails
Rabin-Miller passes Fermat.  I understand it's vanishingly small.

@_date: 1994-12-27 18:38:02
@_author: Eric Hughes 
@_subject: Re: Making sure a program gets to the receiver intact 
From: wcs (bill.stewart +1-510-484-6204)
The specific question is tampering of files on archive sites.  The
larger issue is information, particularly software, distribution.  My
position is that timestamping is a better solution than signatures for
the tampering issue and that both are useful for the larger issue.
   Some good points, but on the whole I'll disagree.  Either way, the solution    pretty much comes down to "eternal vigilance"....
Well, "eternal vigilance" is really "public information".  Both the
timestamping problem and the signature problem resolve down the same
problem about secure _cleartext_ transmission.  How do people gain an
assurance that they have the same shared piece of information?
The first advantage that timestamping has over signatures is that
timestamps are temporal and signatures are not.  Private keys for
signatures change over time by design, but timestamp roots do not,
also by design.  That is, once a timestamp root has been securely
transmitted, there is an assurance that everything up to that point is
OK.  Spoofing a signature, however, can be done by spoofing a key
change; there are public information solutions to this as well, but
they still do not have temporal assurances.
The second advantage is the the timestamp roots are more widely shared
than individual public keys.  Because more people look at this one
piece of information, it's much harder to completely forge.  The cost
of verification is smaller per person, but there is much more total
verification performed.
The root keys in a certification hierarchy have the same property of
wide sharing, but the effect on public key distribution is not the
same.  The creation of the timestamp root is a _technically_ linkage
of all the individual timestamps, while the root key of a certifying
authority creates _social_ links between the root key and the other
keys.  The technical linkage is stronger.
   The interesting technique that digital timestamping provides is that it
   lets you show that the version you claim you posted to the ftp site
   got there before the [different] version that's there now.
You can also post a public announcement, timestamped, which has the
location and the timestamp of the information and the archive.  This
public announcement has public information properties as above.
   To use that technique, either you need to broadcast the details of the
   digital timestamping in an unhackable public fashion, The "unhackable" nature is not even necessary to assume.  All you need
is the ability to post public information with some non-zero
probability of success.  Eventually the public information gets out.
The timestamp will indicate priority.
There's also the possibility of timestamping the entire directory tree
periodically.  This is all publicly verifiable, so an interposer would
have to intercept the very first transmission and could not come along
later and perform undetectable corruption.
   On the other hand, without signatures, it's not too hard for a Bad Guy
   to store bogus files on the server and get them timestamped too -
Sure, that's the whole point.  Any information protection, signatures
or timestamps, can simply be replicated.  The timestamp algorithm
gives you a temporal ordering to distinguish between the two, which
signatures don't have.
On the other hand, I'll amplify Matt's point by pointing out that any
deployed mechanism to increase the difficulty and cost of information
subversion is better than what exists now, which is strictly ad hoc.
The integration issues of any public authentication system will be
difficult, regardless of the underlying mechanism.

@_date: 1994-12-27 18:41:01
@_author: Eric Hughes 
@_subject: Re: Why I have a 512 bit PGP key 
From: ianf ("Ian Farquhar")
re: personal account tripwire
   The problem is that although you can protect the data file of
   hashes (by using a pass phrase to encrypt it), protecting the
   binary which does the checking is rather more difficult.
Why not recompile the binary?  All it needs to be is something like

@_date: 1994-12-27 20:52:26
@_author: Eric Hughes 
@_subject: Re: Why I have a 512 bit PGP key 
Read Ken Thompson's Turing Award lecture for why that isn't
   sufficient. Its quite amusing.
I'm quite familiar with the work.  [For those who aren't, it's about
compilers that compile in self-perpetuating bugs from their own source
The question, however, is not one of possibility but timeliness.
Attacks against persistent information are easier than attacks against
transient information.  If the sysadmin is going to go modifying
compilers, it's no longer annoyance.

@_date: 1994-12-27 20:55:04
@_author: Eric Hughes 
@_subject: Re: Why I have a 512 bit PGP key 
From: ianf ("Ian Farquhar")
   I take it you mean recompile the binary every time?  Because you'd
   need to have source around to recompile it from, and the attacker
   could modify that source even more easily than he or she could hack
   the binary.  The idea is to make tampering with the binary detectable.
Recompile the binary from newly uploaded source each time.  MD5 source
isn't more than about 10K long.  That's all of a few seconds of upload
   I am pretty much certain that to make such
   a system perfectly secure under these conditions is impossible.  That's right.

@_date: 1994-12-27 23:13:16
@_author: Eric Hughes 
@_subject: Re: Why I have a 512 bit PGP key 
From: ianf ("Ian Farquhar")
   > Recompile the binary from newly uploaded source each time.  MD5 source
   > isn't more than about 10K long.  That's all of a few seconds of upload
   > time.
   Irritating [...]
???  An upload can be automated, just like anything other solution.
   [...] and also insecure (system admin intercepts the upload and
   replaces it with source of his or her own).
_Every_ solution to this problem is insecure, when it comes down to
it.  What you asked for is something that makes things more difficult.
Interception can be made quite difficult.  Make the "upload" consist
of simulating a keyboard typing the source code into emacs.  Change
the file name each time.  Obfuscate the source by redefining variables
each time.  Pipe the output directly into the compiler; hell, compile
straight from stdin!
You can't go about protecting against the modification of binaries by
relying upon one of your binaries being better protected than the
rest.  There's an infinite regress involved here.  The solution is to
go outside the regress.  Recreating the binary from scratch is one
way.  I'm sure there are others.
   >    I am pretty much certain that to make such
   >    a system perfectly secure under these conditions is impossible.
   Is there a standard proof for this, though?  I suspect that there is, but
   have not discovered it.
Get the essay that Perry mentioned and start there.  Keep in mind that
object code can be interpreted in many different ways, only one of
them typically expected.

@_date: 1994-12-28 07:51:50
@_author: Eric Hughes 
@_subject: Re: Why I have a 512 bit PGP key 
From: jeffb (Jeff Barber)
   > ???  An upload can be automated, just like anything other solution.
   Then the automated part (script or whatever) simply becomes another piece
   that needs to be protected.
There need be no part of the script/etc. that relies upon persistent
information on the target machine.  You can simulate the whole thing
as typing, if need be.
   You've merely added the compiler and its
   associated utilities to your regression list.  It occurs to me that there's no need even to use the compiler, if
you're willing to upload binary images directly.  And if you want to use the compiler, the effort involved in making a
recognizer for an ever mutating source is not trivial.  Variable names
can change, parse trees can change, control structures can change.
   Nothing is gained --
   other than additional irritation and delay.
Additional cost of subversion is _exactly_ the issue here.  We're not
talking about perfect security; that's impossible in this case, and
has been acknowledged as impossible.  What is at issue is making it
difficult for a not-completely-dedicated-to-your-destruction sysadmin
to subvert personal files.
Furthermore, the pragmatics of a personal tripwire are that it only
needs to indicate failure once.  As soon as I found out that my files
weren't safe in their place of residence, I'd leave.  The practical
question should not be one of fighting a running battle with a hostile
root; root always wins, period.  A useful outcome of this discussion
would be a feasible way of detecting the first modification.  Almost
always this will not be a full-scale effort.

@_date: 1994-12-28 08:20:02
@_author: Eric Hughes 
@_subject: Re: Why I have a 512 bit PGP key 
From: pfarrell ("Pat Farrell")
   >> Read Ken Thompson's Turing Award lecture for why that isn't
   >> sufficient. Its quite amusing.
   But I see it as more germane than Eric. It is not about
   arbitrary self perpetuating bugs from source. It is
   about serious security holes that are self perpetuatated
   by the binaries of the complier. "Bugs" is shorthand for any arbitrary deviation from nominal source
code function.  Come on, do you expect a one sentence summary to be
accurate in all detail?
   Drawing from Thompson, a simple MD5 is not sufficient.
A single, unchanging, global MD5 source would be insufficient.  That's
not what I mentioned, but rather a constantly changing MD5 source.
One could also change the arbitrary constants in the MD5 source for a
"personal MD5".
Here's a summary of these self-perpetuating false compilers.  There is
an intermediate source code with the arbitrary deviant function
expressed.  A true compiler compiles this into the false compiler.
The arbitrary function includes a recognizer and a payload.  The false
compiler recognizes the source code of the true compiler.  At this
recognition, the corresponding payload is compiled in.  The payload
includes all the arbitrary deviant function of the intermediate
source, including the recognizer.  Thus the false compiler will
compile itself from the true source.  [This is a summary.  I believe
Thompson's original work has a full intermediate compiler; this makes
the attack easier to perform, but is not essential.]
Any such attack on the compiler requires a recognizer.  This is the
point of weakness, since recognizing arbitrary function is mighty
difficult.  The strongest form of the problem is unsolvable; it's a
quick corollary from the solution to the halting problem.  Practically
speaking, however, the problem is more tractable, because the ability
to change the source to some arbitrary form is not unconstrained.  You can, however, make recognizing a source _extremely_ difficult.
Plus, if you're only interested in finding the first integrity
failure, the recognizer has to work on a source which the author of
the recognizer hasn't even seen yet!  Even with public source code of
a source scrambler available to the recognizer author, the scrambler
can use combinatorial explosions to eliminate hooks for recognition.
Reordering of parallelism, for example, or creative use of aliasing --
the number of techniques available is huge.
And that's only for a single algorithm.  Lots of functions exist that
will detect modification.  CRC's are a good example; there are _lots_
of primitive polynomials available for making your very own personal
CRC checker.  Remember, you only really need to detect the first

@_date: 1994-12-28 08:26:08
@_author: Eric Hughes 
@_subject: Re: Are 2048-bit pgp keys really secure ? 
From: danisch (Hadmut Danisch)
   > Rabin-Miller would be better.  It would be instructive to examine the
   > conditional probability that a composite number which fails
   > Rabin-Miller passes Fermat.  I understand it's vanishingly small.
   What is "vanishingly small" ?
Small enough to ignore for the practice of "pretty good" security.
There are algorithms to prove primality.  See Cohen's excellent _A
Course in Computational Algebraic Number Theory_, from Springer.
   Does anyone know how many Carmichael-Numbers exist?
An infinite number.  This was just proven in the last two years.  The
density of Carmichael numbers is very small.  As I recall, this paper
also included Pomerance, but I don't remember if he did the bulk of
the work or not.
   If you found a Carmichael-Number consisting of primes bigger than
   the primes in your small-numbers-sieve, the Fermat-test won't detect
   it as a non-prime.
Miller-Rabin will, however.  Since most of the time generating a
modulus has to do with testing composites, the added time for a few
more modexp's to do M-R is small.  The large effort is that of the
authors of the crypto package to implement and debug it.

@_date: 1994-12-30 10:31:35
@_author: Eric Hughes 
@_subject: Re: My "netcard" 
From: crawford (Michael D. Crawford)
   I made a bunch of cards from Avery 5371 Laser Business Cards (about twelve
   bucks for 250 cards, at most office supply stores).
A good choice for stock.  I've done stickers, but they don't work
nearly so well.
   On the back is a headline "PGP Public Key Encryption Key", followed by
   these instructions:
I'd also recommend putting you key fingerprint on the card for those
people who _can_ get your key off the Internet and who just want to
verify that it's accurate.

@_date: 1995-01-02 05:45:01
@_author: Eric Hughes 
@_subject: Re: Anonymous payment scheme 
From: skaplin (Samuel Kaplin)
   I was looking at at the bigger picture. Any merchant who accepts Visa or MC
   could now accept anonymous payments. No hassle at all on their part.    [...]
   The key
   would be not to have the card attached to the account. If the card is
   attached to any type of account, then there are reporting requirements. Visa was talking about an electronic traveller's check, which, from
what I could tell, instantiated an account in the sum of the value of
the card purchased, which was then drawn down by purchase.  The card,
evidently, had no embossing on it.  Personalization was limited to
some account id which would last the lifetime of the balance and then

@_date: 1995-01-05 00:02:06
@_author: Eric Hughes 
@_subject: Re: Warning letter from Co$. [any comments ?] 
From: avi (Avi Harris Baumstein)
   i know there has been much chatter on this subject, but are there
   truly any precedents that could hold on the anonymous distribution of
   copyrighted material?
Cubby v. Compuserve is relevant here, as well as that bookstore case
in the 50's that I never remember the name of.  Mike G., can you help
me out on this one?
These cases are about other kinds of wrongs (libel in one and
obscenity (?) in the other), but copyright violation doesn't seem to
be have any particular features to set it apart from the basic
principle of these.  Namely, if you know, you're responsible; if you
don't, you're not.  This, you all realize no doubt, is a gross
simplification of a long chain of reasoning.
   what
   exactly constitutes a trade secret, and what sort of laws apply?
The short answer is that if you didn't sign a trade secret agreement
or are party to one by some other relationship (such as agency), then
a trade secret that comes your way is no secret any more.
   >    clients'  property   rights.    Courts   are   holding   such
   >    contributory  infringers  liable.   Two  examples  are:  Sega
   >    Enterprises Ltd.  v.  Maphia BBS, 30 U.S.P.Q.  2d 1921  (N.D.
   >    Cal.   1994) and Playboy Enterprises v.  Frena, 839 F.  Supp.
   >    1152 (M.D.  Fla.  1993).
   what of these cases? is this just an example of typical lawyerly
   intimidation tactics? I have personal experience with the first case.  It was a local BBS
run by a friend of a friend, and I got involved a year ago right after
the seizure.  (It was, BTW, a _civil_ seizure of a BBS, not criminal.)
I believe the case settled out of court.  There were court documents
approving the seizure however; I don't know if these set precedent or
not.  I suspect not, because the action was entirely _ex parte_ (Latin
for one-sided).  Mike, again?  Other legal folk?
I know nothing about the second one.
   nhow do you remailer-ops plan to react? my first
   instinct (were i running a remailer) would be to ignore it, on grounds
   that i wouldn't examine any mail passing through. The people who keep logs, yes, are in more danger than those who don't.

@_date: 1995-01-05 20:43:54
@_author: Eric Hughes 
@_subject: Re: DES for HP48 
From: sinclai (SINCLAIR  DOUGLAS N)
   There used to be some code on soda to do DES on an HP48 palmtop/calculator.

@_date: 1995-01-06 18:31:50
@_author: Eric Hughes 
@_subject: Re: for-pay remailers and FV 
This whole fracas between blind-sig money and FV money is a symptom of
the confusion between clearing and settlement.
Roughly speaking, clearing is when authorization moves (i.e. a
liability is created), and settlement is when money moves (i.e. when
that liability is discharged).  Clearing should always happen at or
before settlement.  In order to do on-line digital postage, you need
clearing to happen at the point of remailing.  Settlement can happen
at some later time.
Settlement need not be in real money.  The liability of other
settlement facilities can be used.  This is in fact how central
banking works.  Only the central bank moves "actual" funds; everyone
else moves liabilities around.
To wit, a remailer consortium would do best to issue a local banknote
usable only by themselves and have customers settle with the
consortium issuer, rather than any member of the consortium itself.
If the consortium issuer were to use blind sigs, the consortium
members wouldn't be able to ascertain who paid.
The mechanism for settlement could be credit cards directly, mailed in
checks, even FV.  The preferences of the consortium members for issues
of timeliness of settlement, reversibility, loss sharing, etc. would
decide the actual choice of settlement mechanism.

@_date: 1995-01-06 20:28:32
@_author: Eric Hughes 
@_subject: Re: for-pay remailers and FV 
From: jamesd ("James A. Donald")
   > This whole fracas between blind-sig money and FV money is a symptom of
   > the confusion between clearing and settlement.
   It is nothing to do with that confusion.
Keep your day job.
   > To wit, a remailer consortium would do best to issue a local banknote
   > usable only by themselves and have customers settle with the
   > consortium issuer, rather than any member of the consortium itself.
   > If the consortium issuer were to use blind sigs, the consortium
   > members wouldn't be able to ascertain who paid.
Get it?  The first sentence refers to a "local banknote".  The second
sentence refers to a particular way of issuing that banknote.  Passage
from the general to the specific.
   The problem that we are discussing is how to solve them    without using Chaumian money.
Think about how a local clearing organization allows this.

@_date: 1995-01-06 20:33:00
@_author: Eric Hughes 
@_subject: Re: A Fire Upon the Deep 
From: weidai (Wei Dai)
   This is quite sensible given that in the Zone universe, you may have no
   idea how much computing power your enemies have, so no cryptography
   that is only computationally secure can really be trusted.
I asked Vernor about this one a few months ago.  He got lucky on this
one.  He thought that some advances in theory might render the whole
idea ridiculous.  It was not the case that he was considering relative
computational power, which works much better in context, especially
given the hints of some computational power beyond Turing machines.
A great one-liner about debating public-key, in any case.

@_date: 1995-01-09 09:09:35
@_author: Eric Hughes 
@_subject: Re: More signal than YOU can handle. 
From: cactus ("L. Todd Masco")
   For the moment, all of the archives that Eric just dropped me are on
   ftp://ftp.hks.net/cypherpunks/All
This includes all the stored messages at toad.com from the beginning
of time up to a few months ago.  I've got a short lacuna at toad.com
from some deletion I never understood, but it's only a few weeks long
and is covered by Todd's archive.
I would like someone to make an official enumeration of the articles
as they passed out to the list for global reference.  You may
self-volunteer by grabbing the archives above and starting.

@_date: 1995-01-09 09:24:53
@_author: Eric Hughes 
@_subject: Re: Data Haven problems 
From: dfloyd
   While programming my data haven code, I am wondering how to guard against
   spamming the data haven parser.
Here's an example of where the mechanism/policy distinction helps a
lot.  Mechanism here is how you store data.  Policy is how you decide
whether to accept a particular request.
The suggestions to date have all suggested particular policies to put
into your code (with the exception of Bill Stewart).  In addition,
almost all of these suggestions have been pay-per-use.  As significant
as policies are, they aren't your most important issue right now.
The single thing you need to get right today is the means of
separating the mechanism from the policy.  Different operators will
have different policies.  If it's difficult to change policies, fewer
services will be offered.
The issue of policy separation is a software architecture one.  I
don't know the structure of your code, but I'd suggest that whatever
it looks like, that you make a (1) clean interface and that you (2)
document it.  If you do these two things, you'll have substantially
achieved separation.
I think you should spend more time worrying about the interface than
about the specific policies.  In order to focus on the policy
interface, I'd suggest an extremely simple policy to work with,
namely, an access list.  Anyone listed can use the server; everyone
else is denied.  That will get you started.
I would distribute your first code with a simple policy such as this.
It will allow prototypes to get worked on.  Since a data haven isn't
of much use without clients for it, a simple policy is adequate for a
first release.

@_date: 1995-01-10 10:11:37
@_author: Eric Hughes 
@_subject: RSA Licenses Commercial Distribution Rights to RSAREF (URLs to PressRelease) 
I've been waiting for this, for oh, about two years now.

@_date: 1995-01-11 20:51:57
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
My question is how do I know it is encrypted?  Calculate an entropy measure of some sort.  Entropy is a measure of
disributional skew.  Maximum entropy means minimum skew.
For human-readable text of any sort, the monogram entropy, i.e. the
entropy of individual characters, will _always_ be detectably less
than maximal.  Encrypted text will always be near maximal.  The two
are easy to distinguish.  ASCII-armored encrypted text will always be
right at 6 bits per byte.
For speed of implementation, you don't need even to look at much text.
You can get a statistically significant measure quite quickly from the
first couple of kilobytes.  And since you're only really worried about detecting non-randomness,
you don't even need to calculate the exact entropy but rather an
approximation of it.  This approximation can be done with entirely
fixed point arithmetic, if you're a bit clever about it.
A practical system would cut out a notch at 6/8 for ASCII armor, which
would make approximation techniques a bit tricky.  More practical is
just to detect ASCII armor with a regular expression recognizer and
de-armor it before the entropy check.

@_date: 1995-01-11 20:57:42
@_author: Eric Hughes 
@_subject: Re: Remailing pricing and cover traffic 
From: pierre (Pierre Uszynski)
   Let me try to deal with the first
   two to conclude that many professionally run remailers may very well
   stay free or close to that for a long time:
[summary: cross-subsidies for hiding another businesses]
Cross-subsidies are common in other industries, why not in privacy
provision?  No particular reason why that won't happen.
Nevertheless, the remailer is getting paid for one way or another.  In
addition, virtual link encryptors to some other commercial remailer
may be a better way of providing cover traffic.
It is refreshing, though, to see thoughtful discussion about alternate
economic arrangements.  The twin requirements of supporting the
physical remailer and preventing swamping do not immediately and
necessarily lead to pay-per-use.

@_date: 1995-01-11 21:04:05
@_author: Eric Hughes 
@_subject: Re: Multiple symetric cyphers 
From: cactus (L. Todd Masco)
   I'm wondering: would the strength be increased by using a randomly selected
   symetric cypher? Strength is not right aspect.  Global risk is reduced, simply because
the aggregate cost of a breach is reduced.
But selecting a single cipher is just as much a fixed policy as a
randomly selected one is.  Far better to let the user pick a policy,
both about sent and accepted ciphers.
   I guess this reduces to: do strong cyphers have "signatures" of some sort,
   by which the type of encryption can be derived? If they do, they're likely not _strong_ ciphers.

@_date: 1995-01-11 21:07:27
@_author: Eric Hughes 
@_subject: Re: Why use plastic for remailers and DH? 
From: s675570 (Angus Patterson)
   This point may have been raised before, but anyway, unless you're using a    swiss-bank issued credit card [etc. ...], why would anybody want to use    something as completely traceable as a credit card to pay for a remailer    or a data haven?
Because not everyone needs paranoid levels of security.
Just because the truly paranoid won't use a service doesn't make it
useless.  Vebum sapienti...

@_date: 1995-01-11 22:09:55
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
From: daleh (Dale Harrison (AEGIS))
   Won't work!  You can always embed an encrypted message in what 'looks'    like plaintext.
So people can write special software that gets their message rejected
by an entropy filter.  This is a disadvantage?  It looks like an
irrelevancy to me.
Seems to me that a quite reasonable condition of use of a remailer is
that what is passed isn't human readable.

@_date: 1995-01-12 08:04:01
@_author: Eric Hughes 
@_subject: Re: Data Havens..A consumer perspective 
From: carolb (Censored Girls Anonymous)
   1. You have what I want or need.
You have a _service_ I want to use.
   8. Welcome to the world of data "coatchecking".
"Data coatchecking" certainly has different connotations than "data
haven".  I think for marketing purposes, the name "data haven" is
inaccurate.  A data haven, one might expect, has semantic structure to
it.  Offsite storage is much less than a data haven; it's much more
like a remote file system.
Using the word "haven" to refer to a remote storage facility removes
the connotation of ordinary usage, which, as we all know is a
perfectly upright, normal, and (for those in the USA) a downright
Capital-A _American_ thing to do.
   From the moment the data leaves their hands, until I return it,
   they have no right, nor I no obligation, to divulge anything about it.
You don't want the operator of a remote storage facility revealing
links about usage patterns of individuals, but as far as the data
itself goes, there's no reason it couldn't be made public (there's
also no good reason _to_ make it public, either).  Someone who sends
plaintext to a remote site is foolish.

@_date: 1995-01-12 08:09:33
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
Of course, we're not just dealing with text.  So the scheme has got to be
   changed a bit so as to be able to detect unencrypted GIFs, and mu-law
   files, and as yet to be determined unknown files.  Each of these data formats has it's own regex recognizers available.
Just apply them.
The point, though, is to enforce the presumption that the remailer
operator does not, in fact, look at the traffic in order to understand
the content.  You don't need a completely airtight algorithm in order
to do this.

@_date: 1995-01-12 08:14:14
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
From: daleh (Dale Harrison (AEGIS))
   It's an artificial example, but one that points out that merely doing a    frequency analysis on the datastream isn't enough to guantee the correct    answer.
You don't always need the correct answer.  You just need the correct
answer most of the time.  You're trying to create a presumption about
behavior.  Ensuring that you can't read almost all of the traffic is a
pretty good way to assure people that you don't try to make sense of
any of it.
The fundamental purpose here is social communication about intent.
   Reliable remailer software will have to worry about false postives    as well as false negatives; especially if it's a fee-for-service operation.
I just don't agree with this.  If you feel it needful to install an
entropy filter, expect that its failures will simply accrue to the
general unrealiability measurement for that remailer.
And there's no reason you couldn't publish the algorithm so that a
user couldn't check the entropy for themselves in advance.
   Of course the implicit assumption in that statement is that encrypted    traffic hasn't been outlawed or regulated, or that the sender doesn't want    to 'appear' to be sending encrypted traffic.
I don't design for the paranoid.

@_date: 1995-01-12 08:24:36
@_author: Eric Hughes 
@_subject: Re: Multiple symetric cyphers 
From: cactus (L. Todd Masco)
   >Strength is not right aspect.  Global risk is reduced, simply because
   >the aggregate cost of a breach is reduced.
   Isn't it?  If an attacker does not know what cipher is used and breaking
   each is computationally expensive (though not prohibitively so) doesn't
   that add extra complexity?
Suppose that several symmetric ciphers are used and that one of them
is broken.  You then attempt to break all of the messages; the ones
that don't break are presumed to be one of the other ciphers.  So it
does nothing to improve strength.  Note, though, that the _rest_ of
the messages remain unbroken.
I am assuming that it's unlikely that all of the ciphers will be
broken simultaneously.
   Related: is there, in general or in any known specific cases, any
   loss of security in using sym. cipher A on ciphertext B (of another
   sym. cipher) with the same key?  With different keys (I would think
   not, but I vaguely remember mention of something here long ago)?
If you use the same key, the size of exhaustive search does not

@_date: 1995-01-12 08:33:46
@_author: Eric Hughes 
@_subject: Re: Multiple symetric cyphers 
From: paul (Paul Robichaux)
   Must I
   require the user to tell that program what cypher was used to encrypt
   the file she wishes to decrypt?
Only if you don't want to store the type alongside.  See below.
   Is storing the cypher type as part of the encrypted file a weakness?
Well, it's no weaker than current systems.  PGP stores the cipher type
in the source code: it's always IDEA.  One should allow, however, the
cipher type to be empty alongside the data so that another tool can
store cipher information.

@_date: 1995-01-12 08:38:56
@_author: Eric Hughes 
@_subject: Re: Data Havens..A consumer perspective 
From: root (Nesta Stubbs)
   > 3. I will let you do anything to the data you wish, so long as I     >    get it back intact.
   why would you give the haven owner free run?  I mean naturally he does    have free run with your data once he gets it, That's exactly the reason, namely, to make the agreement between
individuals match the underlying nature of information.  This is
different in the trust in silence about the user.  This is also not to
say that the operator can't undertake to make assurances about where
bits go and don't go.
   I am sure you    woudln't want your data stored ona  public access Unix system, or in    plaintext.
So don't store it in plaintext.  The operator of the data storage
facility has no responsibility for this.
   if the datahaven is turned into a data broker
I don't know about you, but I don't like paying money for random bits.
   well what would be thepurpose of this data haven you propose except as a    extra storage pace for data, like if you dont have space on your own    drive?
Even when you've got enough of your own disk space, it's still subject
to failure.  Putting data in multiple places reduces the possibility
of unrecoverable catastrophe.

@_date: 1995-01-12 14:54:26
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
From: hfinney (Hal)
   The idea of offsite storage doesn't seem that helpful since you can just
   store the data on your own disk in encrypted form.  I'll tell you one really useful facility for offsite storage, and
that's private key backup.  Use a secret sharing arrangement, say 5
out of 7 reconstruction, and send out 7 chunks.  Now, give a different
pointer-to-chunk to each of 7 different people.  In the case of
catastrophe, you can recover your key.
Too paranoid not to let your key out of your sight?  Then don't do
Here's another use.  I'd like to interlock offsite backup with my
digital money withdrawals, so that my money is always backed up.
Let's be clear; the code that dfloyd is working on is offsite
storage in a reasonably secure form.  It's not a data haven.

@_date: 1995-01-13 09:48:25
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
From: daleh (Dale Harrison (AEGIS))
   Paco begins by    inventing the new [format] of which only Paco knows the internals.
Fine.  The operator has no idea of how to make sense of this data
format.  Just because someone in the world has an interpretation for
it doesn't mean that I do.
No operator of any data service can be expected to know about every
data interpretation.  The key here is "good faith".  An operator can
undertake a good faith effort to remain ignorant about content.
The argument that "it passed the filter, so it's approved" is bogus.
The counter is that "it passed the filter, so I personally have no
idea what's inside it."  Knowledge here is personal specific
knowledge, not an acknowledgement of a possibility.

@_date: 1995-01-13 09:51:59
@_author: Eric Hughes 
@_subject: Re: Microsoft TrueName (tm) (fwd) 
From: rah (Robert Hettinga)
   Eric, what'll you take for "remailer.net"? ;-).
Addresses under remailer.net will be available to operators of
approved remailers.  Approved is yet to be defined, so no one could
possibly satisfy the conditions for it yet.
In the meanwhile, I'm using as a vanity license plate.

@_date: 1995-01-13 09:54:19
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
From: Ben.Goren
   Here's a solution:
What problem, pray tell, does this solve?  It seems far more
complicated than it need be.
   Alice sends a file to Dave's DataHaven. When Alice wants her file back, she
   sends to Dave a secure hash of the file, a key with which to decrypt it,
   and a handful of plaintext at the beginning of the file. Dave decrypts the
   file that matches the hash with the key Alice gave him; if the file begins
   as Alice says it should, Dave returns the file to Alice.

@_date: 1995-01-13 10:02:18
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
> ... Seems to me that a quite reasonable condition of use of a remailer is
   >that what is passed isn't human readable.
   From: pstemari (Paul J. Ste. Marie)
   Perhaps I missed this, but why?  If someone is going to plant
   kiddie porn or whatever on you, does it really matter if they
   encrypt it first or not?
If you can't read it, it's not kiddie-porn *for you*, although it
might be for someone with the key.
Encryption fragments meaning subjectively.  A magazine, for example,
has a fixed center of meaning for all who can read the language.  A
magazine looks the same to all who look at it.  An encrypted file
looks different to those who have the key from those who do not.
Encrypted data is fundamentally different from paper-and-ink data in
this way.  The metaphor of "planting it on somebody" does not apply to
data that the "somebody" can't read.
   I forget the name of the cypher (Vigere, perhaps--the one that uses
   a series of Caesar-like cyphers keyed by a password), but you could
   just run it through that with a password of
   abcdefghijklmnopqrstuvwxyz and you'd flatten out the distribution
   enough to get it by casual inspection.
Fine.  It think that would suffice.  If you can't easily read it, you
can't be expected to have read it.  The operator of a data service has
_zero_ motivation to cryptanalyze something.  If they happen to apply
a viewer to the file (for whatever reason), they don't _want_ to see
what's inside.

@_date: 1995-01-13 10:09:41
@_author: Eric Hughes 
@_subject: Re: essential characteristics of a Data Haven 
From: adamfast (Adam Feuer)
   what differentiates a "data haven" from "reasonably secure offsite
   storage"?
Right now, that's easy.  Data havens don't exist, and prototype code
for reasonably secure off-site storage does.
The key distinguishing feature of off-site storage is that it stores
data only as bits, structured and segmented, but not interpreted _as_
anything but bits.  A data haven, on the other hand, holds things that
someone disapproves of, otherwise there's no need for a haven.  _A
fortiori_, if someone disapproves of it, it must mean something.  Raw
bits don't mean anything, or rather, they can mean everything.

@_date: 1995-01-13 10:14:13
@_author: Eric Hughes 
@_subject: Re: Anonymous payment scheme 
From: Paul.Foley (Paul Foley)
   NZ Telecom are conducting an experiment with using phonecards in
   softdrink vending machines.  There was an article in The Dominion
   newspaper's _InfoTech_ magazine crying out for the Government to stop
   it, claiming Telecom's creating an independant (from the Reserve Bank)
   currency, will destroy the New Zealand economy, etc., etc.
Sounds like your basic central banking ignorance.
Look folks, just so y'all don't look like idiots, remember this: A
means of payment is not the same thing as a currency.

@_date: 1995-01-13 11:14:22
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
From: lce (Larry E)
   The goal is to convince the two groups of concerned parties[, in
   short, users & lawyers,] that the remailer operators don't know the
   contents of what's passing through their remailers:
This is exactly right.  With a sealed box which you can't look in at
all, this is easy.  Providing an assurance on a general purpose
computer is more difficult.  And yes, it _is_ always possible to
simulate a filter that's not a filter, blah, blah, blah.  We are in
the realm of social interactions here, not in the realm of technology.
   The remailers are operated by people who want to promote information
   flow, not restrict it.  They provide an important service that is of
   critical importance to some people and groups who use the net.  They
   shouldn't be held accountable for the few who abuse the remailers,
   and encryption helps prevent that from happening.
I agree with this argument.  It is the germ of discourse about the
public policy of remailers and anonymity generally.  I want to point
out the rhetorical content of this statement, though, more than my
agreement with it.
The cypherpunks list is filled with paranoid nay-sayers who can't
distinguish their own paranoia from a legitimate technological
failing.  I feel a dire need for a positive rhetoric of cryptography.
I want to be 'for' something and to know what it's good for rather
than to be against everything that doesn't meet my personal desires.
How many times have I seen particular solution whose response is "But
I want more, and this won't work for that"!  The most self-deceptive
say "It can't be done", the slightly more honest say "You can't do
it", and none say "I will not do it".  So now all you people who think
that remailers don't work, don't run one.  Good, I see most of you are
already complying with this directive.
Even the simplest remailer has utility.  If there were no utility,
then nobody would use them (duh).  It is not only foolishness and
idiocy but also mendaciousness to say that "remailers just don't
work".  It is constructive to say, however, that "the current
remailers don't work against the following opponent", but this is not
usually the case.  Rather, the speaker's paranoia silently projects
their own requirements onto a technical discussion, leaving only
Look at the recent conversation over postage for remailers.
Paraphrasing: "Credit cards won't work because they're not anonymous".
My response: "Bullshit".  Using a credit card as a means of payment
does put constraints on usage, but it doesn't prevent usage (duh
redux).  What credit card payment does do is to require more effort in
order to link email transactions.  This is an unalloyed good, but pure
silver instead of gold.  There are better ways, one of them First
Virtual, which at the least has counterparty anonymity; another, blind
sigs (as yet unusable for payments).
The implicit assumption here is that "If I can't use it to smash the
state, it's worthless".  Well, thank you very much for constraining my
ability for privacy with your political agenda.  And I have a hint for
all the state-smashing wannabe-businesspeople out there: the ones who
have a business (less secure) now will eat your lunch for the business
(more secure) later.
To be dry and academic about this, I'd say that the problem was an
insufficiency in threat modelling.  But that just doesn't quite mean
the same thing, n'est ce pas?

@_date: 1995-01-13 11:17:44
@_author: Eric Hughes 
@_subject: Re: time stamping service (again) 
From: sdw (Stephen D. Williams)
   It should have minimize bandwidth, minimize cpu, minimize storage
   levels of service to allow different levels of users to have
   different possible impact on the machine.  (Ie. : local, paying,
   regional, unknown, domain, etc.)
This is the area of policy, for which there are no general purpose
solutions that I know of.  I see a need for a general purpose module
that would accept authorization requests from various end-user
services (remailing, timestamping, storage, etc.) and return yes or
no.  If money is part of the policy, this is the place to implement
That said, I don't think the lack of a policy engine prevents a
cypherware distribution from happening.

@_date: 1995-01-13 11:21:15
@_author: Eric Hughes 
@_subject: Re: Data Havens..A consumer perspective 
From: root (Nesta Stubbs)
   are you saying that there is an agreement between the data haven operator    and the user?
There's always an agreement, implicit or explicit.
   Right now were are getting into so many fraggin different definitions of    data haven, that this conversation is loopng over itself infinetly.  Well, the 'data haven' that started the topic of discussion was a
misnomer; it's really an off-site storage facility.  I don't know
about the rest of the list, but I'm more concerned with discussing
working code.

@_date: 1995-01-13 18:00:08
@_author: Eric Hughes 
@_subject: Re: How do I know if its encrypted? 
From: Ben.Goren
   That of the data haven operator being able to deny knowledge of the
   contents of files people send him. He'll only return files that, when
   operated on by a strong cryptographic algorithm, make sense. This idea doesn't work for the purpose intended.  I'll upload straight
ASCII.  When you ask for an decryption key, I'll make one up randomly,
apply the decryption algorithm to the flat text, and send that back to
you as a confirmation.
The real question is "Makes sense to whom?".  You can't enforce a
requirement of encryption, but you can make sure that you can't make
sense of most of it.
   As best I can tell, none of the previous suggestions guarantees that the
   file is unreadable.
You don't need a guarantee of unreadability.  What is needed is a
presumption that files were not read.  If they are unreadable, then
they weren't read, but there are other ways of creating that

@_date: 1995-01-15 12:46:09
@_author: Eric Hughes 
@_subject: Re: voice pgp 
From: 73211.3713 (Loren Fleckenstein)
   I've heard mention that Phil Zimmermann was going to demonstrate Voice
   PGP at the January Cypherpunks meeting at Cygnus. 1.  We've been meeting at SGI for several months now.
2.  Phil Z. was there; there was no demo.  Draw your own conclusions.

@_date: 1995-01-16 13:21:10
@_author: Eric Hughes 
@_subject: Re: request for factorising code 
From: aba
   I have had a look at the exported version of Netscape's WWW browser
   which has support for secure transfer of info, and it says it uses RSA
   keys limited to 40
That's RSADSI's RC4 cipher, not the RSA public key cipher.

@_date: 1995-01-17 13:28:41
@_author: Eric Hughes 
@_subject: Re: Does encrypted equal safe? 
From: marko (Mark Oeltjenbruns)
   >If you can't read it, it's not kiddie-porn *for you*, although it
   >might be for someone with the key.
   >
   to be transporting or storing for others that know it is kiddie-porn?
Do you want it to be, or not?
This is exactly the situation I was talking about when I emphasized
the need for a positive rhetoric.  We have here a situation for which
I see the need for a clear statement of position and persuasive
arguments in its favor.
The law gets created by discussion.  If we as a group fail to
articulate our positions, these positions won't be represented and,
failing other advocates (who?), will have no place in the law.  Legal
support of privacy technology will be necessary for its long term
The structure of the argument quoted below is primarily that of "this
can't be right".  I can only infer advocacy that operators of privacy
services must be primarily responsible for content.  This is to say
one of several things, none of which I desire.  It is to say privacy
service operators who don't know content and who don't know identity
should not exist, because no sane person would take upon themselves
the liability of the world.  It is alternately to say that privacy
service operators must know content and filter it.  It is alternately
to say that such operators must know identity and be able to transfer
liability, and these last two are not mutually exclusive.
If you don't want this situation, speak up now.  I desire the approved
existence of privacy services which offer true privacy and as
completely ignorant as possible operators of them.
   >Encryption fragments meaning subjectively.  A magazine, for example,
   >has a fixed center of meaning for all who can read the language.  A
   >magazine looks the same to all who look at it.  An encrypted file
   >looks different to those who have the key from those who do not.
   But why does the meaning of the data assume to change?
Because I want it to.
Meaning is subjective.  If I see encrypted text, am I to be held
responsible for having seen through an encryption for which I hold not
the key?  Merely because someone knows a transformation into a
disapproved form does not mean that I do.
   If I take my stack of kiddie-porn and put it in a box with a big
   strong lock on it, in a way physically encrypting it, change the
   meaning of what I have?
Ask your local postal or parcel service.  Is your local letter carrier
responsible for the possession of kiddie porn while walking around
with the mail in their sack?  I certainly hope not.  That would be a
ludicrous situation.
More accurately, it would be an outrage.  Pushing responsiblity for
interpretation, the ascertaining of meaning, onto people who transport
and store either physical goods or information would be to require
them to become deputies in enforcement.  The policeman inside indeed!
No one is required to love the State nor its dictates.
   >Encrypted data is fundamentally different from paper-and-ink data in
   >this way.  The metaphor of "planting it on somebody" does not apply to
   >data that the "somebody" can't read.
   It is fundamentally a different process, but does that make it
   different from the locking the physical data in a box as above?
It is identical in its removal of any knowledge of content from the
state of mind of the holder.
What is different is that encrypted data is even more clear in its
removal of knowledge.  With a physical container, the boundary of the
container can be breached.  With a crypto container, it is impossible.
   It seems to me that what you are saying is that because the data is
   in a form that I can't understand, I'm safe from trouble.  Now it seems to
   me that this is not all that different from changing the form or appearence
   of physical data and saying I'm not responsible for it.  If you personally enclose a physical object, you haven't removed your
own state of knowledge about the contents.  But if you give the
package to someone else, they don't know the contents.  Even when the
package changes hands, the state of knowledge doesn't.
The War on Certain Drugs has had the unfortunate effect of stretching
the imputations of knowledge to holders of Certain Drugs.  If a single
person denies a state of knowledge, yet has physical possession of
some Certain Drug, a court may assume that the possessor is lying.
And the fact that certain situations like this have been legislated
badly makes them no less totalitarian.
On the other hand, someone in the business of taking packages from
many different people can reasonably argue that they have no specific
knowledge of the contents of any of them.
   stuff that I had no idea of what it was since it was *locked up*, to
   transport over to location X and I got busted half way there am I safe?
I'll consider this a reasonable argument if you can show that some
analogous delivery service has been busted in this way.  And not all
delivery services are common carriers.
   Can I say that even though someone is using me to
   spam or distribute kiddie porn, I have no reason to try and stop it since I
   don't know what they are doing?  I can tell from this situation that you yourself wouldn't not feel
comfortable running a remailer.  So don't do that.  I see you're
already not doing that; good.

@_date: 1995-01-17 13:30:48
@_author: Eric Hughes 
@_subject: Re: Another problem w/Data Havens... 
From: jcorgan (Johnathan Corgan)
   It just occurred to me when reading this another method for ensuring the
   "I can't tell what's in it" condition with a data haven operator.  Why not
   use a secret sharing system where the contraband data is split into a number
   of pieces and sent to different havens?
   [...]
   Ok, Eric, go ahead and blast your holes in this argument :)
How do you know that what you the operator of the storage service gets
was generated by secret sharing?
The suggestion of having certificates that say "I encrypted this" are
interesting, but merely transfer the problem onto that signer.

@_date: 1995-01-18 07:44:09
@_author: Eric Hughes 
@_subject: Re: Another problem w/Data Havens... 
From: grendel (Michael Handler)
   [automatically split and redistribute]
   If the authorities attempt to indict you for possessing illegal
   information / kiddie porn / whatnot, they have to prove that you
   interfered with the automatic redistribution process and examined the
   contents of the submission. If you in fact did not look at the submission,
   they would have a difficult time doing so. This is exactly the right kind of approach, I think.  It's more
expensive to implement than a readable-reject filter, but then I
expect a continuum of services.
The key legal point is "interfered with the automatic redistribution
process".  If an operator can point to those fixed properties of a
system which keep the operator ignorant, an opponent trying to prove
otherwise will have difficult time.

@_date: 1995-01-18 07:54:12
@_author: Eric Hughes 
@_subject: Re: (none) 
From: beattie (Brian Beattie)
   I disagree, one can use e-mail to steal.  E-mail consumes resources,
   resources for which the sender may have no right to use.  It's not theft if there's no direct benefit to the actor.  It does
consume resources, there's no argument about that.  Note, however,
that the scope of any such resource use is with the message as a bit
sequence; no meaning or interpretation of the content is even
relevant.  That is, the resource use does not relate to the email as
communication, merely as a technical operation.
The question remains whether such resource use can ever be considered
unauthorized.  Certainly it's impolite; that's not at issue.
I argue that if you hook your machine up to the Internet, you've
implicitly authorized people to send you packets -- as many as they
want and of whatever nature as they want.  No service provision I've
ever seen gives any recourse to the end user against the provider for
"bad" packets.
I also think this is the one great flaw in the design of the Internet;
namely, that the sender has all the control over what packets flow
over the net.  A receiver can ask for a slowdown or cessation, but
there's no obligation to do so.  This will be, if anything, the
limiting factor in scalability of the internet.

@_date: 1995-01-18 08:07:43
@_author: Eric Hughes 
@_subject: Re: (none) 
From: jalicqui (Jeff Licquia)
   I'm sure that when your hypothetical remailer comes up and I decide to spam
   you with your own words (now I wouldn't do that, now would I? ;-), your
   sysadmin will be comforted by knowing that it's only ones and zeros filling
   his hard disk.
Why sendmail doesn't have anti-spam protection at this point is beyond
me.  Denial of email service to one user should not deny service to
all others.  I consider broken any email system that crashes a machine
because of a disk partition filling.
When your email provider gave you an account, was there an agreement
as to how much mail you could receive?  If there wasn't, that provider
has no good reason to complain if you receive as much email as
possible.  Merely because some else decided to send it to you does not
relieve a provider who has agreed to deliver all mail of that
Moral: If you operate an email service, don't offer unlimited fixed
price email.
   In the real world, however, there will
   always be problems with "acceptable use" and "abuse", along with the
   additional problems with establishing policy and so on.
"Acceptable use" is shorthand for "It's a little rickety, please don't
play hard."  That is, the technical means to limit the consequences of
abuse were not developed, because everyone was willing to play nice.
This doesn't scale, and it will have to be fixed before everyone will
put their home computer directly on the net.

@_date: 1995-01-18 08:13:26
@_author: Eric Hughes 
@_subject: Re: Key backup (was: How do I know . ..) 
From: dcwill ("Dr. D.C. Williams")
   The "spread spectrum" approach might well be indicated for some life-or-
   death key security matters, but the vast majority of PGP users probably
   don't need or want to play Spy vs. Spy with their friends to backup keys.
You use your friends now because off-site storage facilities are not
yet available.  The software for distributed remote backup has yet to
make this operation transparent.
   I recognize that you can't just leave your private keyring lying around
   [physical storage mentioned]
I suspect that most private keys in the future will be held in PCMCIA
cards (initially) and then their smaller replacements.  Backing up a
private key to these allows use of a safe deposit box.
   If it's still "passphrase-protected", an attacker would a) have to know
   what to look for
For scalability, most people will use some standard method, whatever
it is.  This limits the search space of an opponent.

@_date: 1995-01-18 19:01:47
@_author: Eric Hughes 
@_subject: On DH public key crypto 
Diffie and Hellman did have a public key cipher based on matrices in
their original paper; they knew at the time it didn't work.
This is not the same algorithm as the D-H key exchange protocol.

@_date: 1995-01-18 19:39:11
@_author: Eric Hughes 
@_subject: Re: Key backup (was: How do I know . ..) 
From: dcwill ("Dr. D.C. Williams")
   Safe deposit boxes, by virtue of their accessibility to law enforcement,
   are subject to search and seizure under court order and are sealed
   in certain cases (probate). This makes them likely to be the first place
   to look when the Feds decide that we can't have keys anymore. I am not designing systems for the paranoid fantasy of an inspection
of all safety deposit boxes by government agents in search of
I am interested in designing systems which will fit into business as
usual, that are inconspicuous by their prevalance, and which will be a
part of ordinary and usual protection of data by cryptographic means.
Our goals appear to differ enough to preclude my continuing
involvement on this topic.

@_date: 1995-01-18 19:52:16
@_author: Eric Hughes 
@_subject: Re: (none) 
From: beattie (Brian Beattie)
   I must assume that the actor who spams me or sends me unsolicited
   email or any email for that matter derives some benifit from this    activity or they would not do it.
Much tort involves perceived gain by the tortfeasor, but that doesn't
make it theft.
   If I make it clear that I do not wish to receive email from an individual
   or group and that individual or group continues to send email then I contend
   that they are using my resources in a way that I have not authorized.
So who are you making it clear to, if the parties sending the email
are anonymous?

@_date: 1995-01-19 16:27:26
@_author: Eric Hughes 
@_subject: Re: *.techwood.org 
# Maybe it's time for Eric to figure out what he's going to do    # with remailer.net.
Standardization, is what.  It's not ready, so no names yet.
   From: strick
   If anyone wants a third-level domain name *.techwood.org for their
   linux box, send me mail *from root* on your box, telling me what
   third-level name you want.  This is the right avenue right now for a non-.edu remailer address.
Immediate, cheap, etc.
And incidentally, it's a great idea to use a different domain name for
these services.

@_date: 1995-01-19 16:33:41
@_author: Eric Hughes 
@_subject: Re: The Remailer Crisis 
From: frissell (Duncan Frissell)
   I offer to pay for and operate a remailer account on any system that will
   have me.
best.com, based in Mt. View, CA.  Mail to postmaster or try
the other standard extensions.
I'm sure there are others.
   Do we have the software yet to run a remailer out of an account?
When I wrote the first cypherpunk remailer, this was a design
criterion.  In other words, yes.

@_date: 1995-01-21 08:45:46
@_author: Eric Hughes 
@_subject: Re: Data Vaults (vs. Data Havens) 
From: tcmay (Timothy C. May)
   I don't think we ought to call these uses "data havens." Save the term
   "data haven" for those places, in cyberspace or in real space, that
   sell access to Nazi medical experiments, that sell illegal birth
   control information, that buy weapons secrets, and so on. I fully concur.  The connotations of the word "haven" imply activities
that ordinary people don't see themselves doing.  This means that
ordinary people won't generally use something called a "haven", even
if they might use exactly the same service called something else.

@_date: 1995-01-21 08:48:34
@_author: Eric Hughes 
@_subject: Re: The Remailer Crisis 
From: Jaeson.M.Engle (Rhys Kyraden)
   I thought that it was in Perl. I have tried pulling Unix Perl scripts and
   running them under MacPerl, but it doesn't quite do it. In fact, it usually
   doesn't do anything but spew errors back at you.
Perl has a lot of Unix-ism in it.  The original remailer, which was
really simple and stupid, only used stdin and stdout and pipes, ...
Oops!  Pipes may or not be supported [well] on the Mac platform.
I suspect a port won't be particularly straightforward.

@_date: 1995-01-21 09:12:11
@_author: Eric Hughes 
@_subject: Re: Remailers-in-a-box 
From: greg (Greg Broiles)
   In this model, who deals with mailbombs/spams/requests for address blocks?
   It is this sort of administrivia (plus the threat of liability) that
   makes running a remailer troublesome, not a lack of someone's $20/month.
This point is right on.
   I think it's disingenuous to say that "X pays the bills for the network
   link; X purchased the hardware and keeps it running; the box is in X's
   house/office; X is the person who reads complaint mail and responds (or
   fails to); but because Y sends X $20/month, the remailer (and attendant
   liability for its mis/use) belongs to Y."
The whole point of separation of operations and ownership is to
actually separate them.  If the computer/network service owner (X
above) is participating in any _semantically meaningful_ way in the
operation of the remailer service, then they too are part of the
remailer service.  If the computer/network service is responding to
complaint mail, or even getting properly directed complaint mail, they
are exposing themselves to participation in the remailing service.
As with liability for content, the important issue here is the state
of mind of the computer/network operator.  If they know sufficiently
many details about the nature of the remailer operation, the boundary
of separation is breached.  Unfortunately, the standard mechanism of complaint on the internet is
the postmaster address.  Complainants do not always follow the nice
complaint instructions in the headers of email.  A remailer run out of
a shell account will have postmaster complaints addressed to the
computer/network operator rather than the remailer operator.
Therefore, a second postmaster address is required.  A second
postmaster address means another domain name.  This new domain name
can be either a subdomain or a brand new one.  I don't think it will
matter much, although a domain not related to the computer/network
operator would further the separation.
Now setting up new domain names, while pretty easy, requires the
cooperation of DNS operators.  Typically these connections have been
informal and a low barrier to entry but only if you know somebody who
does domain names.  DNS operation is not yet a separate service to
buy, but I suspect it will become so.  In the meanwhile the offers of
DNS provision by John and Strick are welcome.
   [...] I don't think that anyone - not courts,
   and not the world-in-general - is going to pay attention to that    formalism when it's clear that a machine essentially under the control
   of X is being used for 'antisocial' means.
As important as legal protections are, direct action against spammers
attacks the machine infrastructure directly.  A word to the wise
computer/network provider.

@_date: 1995-01-21 09:18:48
@_author: Eric Hughes 
@_subject: Re: Remailers-in-a-box 
From: tcmay (Timothy C. May)
   In this model the owner of the machine (who is not himself a remailer,
   only a seller of accounts) simply ignores all such issues of
   mailbombs, spams, request for address blocks.
   [the form letter might include]
   "If you have problems, talk to the
   sender, not to me."
In order to make such a discharge anywhere near believable, you'd have
to provide a way for the complainant to get in touch with the sender.
The sender in this case is the remailer operator.  It would also be a
standard courtesy to forward the misdirected mail.
   Currently the
   remailer sites = remailer accounts, so they have little or no
   protection.
One of the services that RiaB might do well to offer is subdomaining.
It's pretty easy to direct all subdomain mail, which includes
postmaster mail, to a single email address.

@_date: 1995-01-23 06:58:51
@_author: Eric Hughes 
@_subject: Re: jpunix.com and MX'ing 
From: perry ("John A. Perry")
   > A question, from an internet mail novice:  How does the 'invisible'
   > remailer advertise itself as its 'visible' name in it's outgoing
   > mail?  Perhaps the easiest thing to do is to add a Received: field to all
outgoing remailed mail so that it appears that the visible site is
handling the invisible site as if it were UUCP or a firewall or
mailhub or something.  Since anybody who really wants find out who
actually owns the machine is going to, you might as well indicate the
real relation up front, namely, that the owner of the visible machine
routs mail for the invisible one.  In other words, there would be two
Received: fields in outgoing remailed mail.  The first (lower, later
in the stream) Received: field would be generated by the remailer
software.  The second would be added by the system sendmail.
It will be tricky to make this look just right.
Another way to mask this is to give the remailer its own IP address.
It's easy to recompile extra slip interfaces into a kernel; each gets
its own IP address.  Routing the output of the remailer through these
extra interfaces can require some hackery, though.  I only know about
this second hand, but evidently the BSDI 1.1 release added some BSD
4.4 feature that makes this kind of IP hack much easier.  With an extra IP address, you then register a full suite of domain
names just like normal.  This could be a new second-level domain or a
subdomain of, say, techwood.org.  You'll want SOA, A, MX, and PTR
records.  The NS entry for the relevant domains (esp. PTR records)
will generally reveal the computer/network operator, but again, this
is a technical relationship only.  What you have done is pretty
completely separated the technical infrastructure from the remailer
What we're creating here, of course, is virtual machines.  Unix
kernels have supported multiple processes and multiple users for a
long time.  I expect multiple virtual machines this decade.
   The MX record idea was not    meant to totally hide a remailer. It was meant to act as a "casual"    mask for the remailer.
And I think this mask is quite good.  It's generally a good idea to
try the easier-to-deploy solutions first and see if they work.  All
the IP spoofing above takes a bit of work to do.  Just using an MX
record and getting a second postmaster address is clearly the first
thing to do.

@_date: 1995-01-23 11:46:39
@_author: Eric Hughes 
@_subject: Re: jpunix.com and MX'ing 
From: perry ("Perry E. Metzger")
   In 4.4 kernels, you just configure an alias address.
What is the mechanism by which a particular process picks an outgoing
IP address?

@_date: 1995-01-23 20:01:32
@_author: Eric Hughes 
@_subject: Re: The Remailer Crisis 
From: wcs
   > One thing I should've noted is that a Linux-based cheap remailer is
   > mostly useless without a "live connection" to the Net.    I disagree - live connections  are great for fast-response systems,
   but we got along just fine in the uucp dialup world with occasional
   connections; And if get someone to do secondary MX for you that _is_ fulltime
connected, then the only latency for mail is the poll time.  If you're
on an ISDN line, for example, you can get online and poll every five
minutes for ten seconds at a time (ten seconds only when there's no
mail), cutting down line charges for fulltime _idle_ connectivity by a
factor of thirty.  Not all that expensive at all, really.

@_date: 1995-01-24 07:02:02
@_author: Eric Hughes 
@_subject: Re: The Remailer Crisis 
From: root (root)
   Exactly how does this work at your location Eric? Here in Southwestern Bell
   we don't use the D except for call initiation and termination. There is no
   useage tarriff other than this. The standard residential tariff here in Pac Bell is flat rate duing
non-business hours and per-minute during them.

@_date: 1995-01-25 08:42:32
@_author: Eric Hughes 
@_subject: Re: e$: Guilds, Friedman, and Web-servers for mutual funds 
From: rah (Robert Hettinga)
   You can sell anything digitable on the net.
   Securities are mostly traded on a book-entry
   basis, that is, in IBM mainframe(still!) computer accounting systems. The
   back offices are all automated. In the interest of buzzword-compliance, book entry securities in the
USA are called ADR's -- American Depository Receipts.  ADR facilities
are privately operated; Bank of New York has (if I'm remembering
correctly) the single largest share of this market.

@_date: 1995-01-26 20:43:22
@_author: Eric Hughes 
@_subject: Re: Reordering, not Latency (Was: Re: Remailer) 
From: andrew_loewenstern (Andrew Lowenstern)
   Is this even technically possible?  That is, wholesale monitoring of     disparate portions of the net from a single access point.  If I were doing global Internet monitoring, I wouldn't be doing it
in-band.  Too much cooperation by the vendors required; too much
discovery.  Rather, I'd gain access to the trunks directly and do my
own demodulation and decoding.

@_date: 1995-01-28 20:22:57
@_author: Eric Hughes 
@_subject: Re: Again, where to upload code? 
From: rrothenb (Robert Rothenberg)
   Tried it. Permission denied.
Did you try reading README.UPLOAD in pub/cypherpunks yet?

@_date: 1995-01-29 09:10:23
@_author: Eric Hughes 
@_subject: Data Bank 
From: norm (Norman Hardy)
   The hat check specifies the secure hash of the data, the
   penalty to be paid upon failure to produce the data, and the cost of
   redeeming the data. This sentence contains the single best idea in the whole proposal,
which is to specify liquidated damages in the retrieval note.  (Most
of you will be saying, What?)
One of the largest costs of any conflict resolution is deciding, once
the existence of damage has been agreed upon, exactly what the scope
and worth of that damage was.  "Liquidated damages" are a term of art
referring to a pre-agreed upon worth of the damage in question.  One
most often sees them in construction contracts, where the contractor
will agree to pay a fixed amount per day for each day late.  Rather
than bickering over how much a delay is worth, the two parties agree
in advance to value each day of delay at a given amount.  This kind of
agreement is cheaper _for both parties_ than going to court.
In the data bank case, the liquidated damages are the amount to be
paid upon failure to produce data.  In this case, there's no need even
to call it a penalty.  The data bank agrees to produce either data or
a fixed amount of money.  They get to choose, and it will almost
always be cheaper to remit data rather than money.
   The hat check is signed blindly by the bank and is a
   bearer instrument. There's no need to have it signed blind.  A blind signature is useful
when two parties have some persistent relationship with the
intermediary; when they don't have identity, there's no need for
blinding.  Take, for example, a money bank.  Two account holders who
wish to transact also wish to keep that transaction secret; in order
to do so, they use a blind-signed note, which prevents the linkage
from being determined by the bank.  The reason that the blind
signature is necessary is that the two parties have accounts with the
bank, that is, they are known to it in advance.  These two wish not to
create more information at the bank, that is, more information than is
already known.
On the other hand, this model of a data bank does not have account
holders.  The relationship between this data bank and its customers is
embodied in the retrieval notes ("hat checks").  Furthermore, if two
parties wish to move data through the data bank, the storage and the
retrieval transactions can be trivially linked because they are about
the _same_ piece of data.  The hash of the stored data is the same as
the hash of the retrieved data.  Because data is not fungible -- one
block of data is not like another -- the parties who use this data
bank as a intermediary of transmission must remain anonymous to the
data bank if they are to remain unlinked.
A blind signature will not alleviate the need to remain anonymous to
this data bank.  Suppose (somehow) the data bank was able to sign
blind the right sort of retrieval note.  So fine, the retrieval note
doesn't reveal the linkage directly.  But the retrieval note must
contain the hash of the data being retrieved.  The hash can't change;
it's the access key.  So the unchanging part of the note is what gives
the link away.  We therefore conclude that there's no need for a blind
signature here at all.
   Cancel a hat check: A holder of a hat check may sell it back to the bank at
   a negotiated price thus releasing the bank from the threat of paying a
   penalty in the future.
This cancellation can't be done well.  Remember that the parties are
remaining anonymous to the data bank.  In order to release the data
bank of an obligation, some party would have to make some signed
statement releasing the data bank from the obligation.  But making a
signature reveals identity, perforce.
Furthermore the retrieval note is a bearer instrument, but it's a
_digital_ bearer instrument, which means you can't simply give the
note back to the data bank.  There's no piece of paper to return.
Once the note is out there, it's out there forever.  There can be lots
and lots of bearers.  Which one of them gets to release the data bank
of its obligation?
   The hat check may specify expiration dates, cancellation terms etc. The retrieval note very well should specify an expiration date, since
otherwise the data bank has specified an obligation in perpetuity.  A
perpetual obligation is much less stable than a fixed-time one.  The
value to the data bank of disappearance grows larger as the cost of
storing the data increases.  No new external revenue is coming in (by
definition -- otherwise you've got a renewable agreement, which is
different) and all you've got is costs.  So there becomes little
reason not to simply abscond with the assets and deny any outstanding
A customer, therefore, would be wise not to deal with a data bank
which signed perpetual obligations.  If a customer wants indefinitely
long storage, the best way to do this is with a set of interlocking
obligations with mutually ignorant parties.
   The bank is explicitly permitted to disseminate the data and may
   well do so to lay-off risks. In this sense a data bank is like in
   insurance company that spreads and shares risks. A hat check may be
   viewed as a life insurance policy for the data.
This is exactly why liquidated damages are such a good idea.  By
making explicit the cost of data loss, a data bank can much more
accurately calculate it's risks and costs.  Indeed, the ability to lay
off risk of loss is what can create a stable economy of data storage.
There are lots of extraneous elements in the proposal that I've not
addressed.  I wish to highlight what is valuable and not to dwell on
what is not.

@_date: 1995-01-31 21:21:38
@_author: Eric Hughes 
@_subject: Re: Frothing remailers - an immodest proposal 
>It seems to me that the current remailer web suffers a fundamental flaw.
   >It is simply too static.
It is worthwhile remembering that a remailer network has two
characteristics of service: the fact of delivery, and silence in the
internal facts of that delivery.  That is, you want your email to get
there, but you don't want anybody else to know how it got there.
There are correspondingly two trusts in the function of a remailer,
namely, a trust in reliability, and a trust in silence.
It is very important to remember that only one of these is externally
verifiable.  Your mail gets to its final location; you can tell that.
What you can't tell (external to the remailer) is whether the remailer
kept a copy of the mapping between input and output messages.
Now, dynamic rerouting is good for better delivery, but is bad for the
trust in silence.  Trust in externally unverifiable properties is
_not_ transferrable.  Just because I believe that my regular remailer
is OK does not mean you do.  The creation of these links of trust is
not something that can be automated solely by the remailer operators.
The end users of the remailers are the endpoints of this trust
relationship.  The end users must be involved, either directly or
through some (legal) agent, in the manipulation of these relationships.
Any solution which tries to do this independent of the end user is
broken, by definition.

@_date: 1995-01-31 21:29:07
@_author: Eric Hughes 
@_subject: Re: ESP Unix encrypted session protocol software 
From: mab (Matt Blaze)
   [this = storing secrets]
   At the extreme, fixing this is a Hard Problem.  In practice for establishing
   a reasonably secure session, it all depends on how much you worry about a
   full-blown (two way) spoofing attack against IP.
I know Matt realizes, but let me repeat for the rest of the list.
Just because plain old Diffie Hellman is subject to active attack
doesn't mean it's useless.  Some protection is better than no
protection at all.  It's still worthwhile implementing some security
to make an opponent's task harder than to implement no security.
And just because some people find this level of security inadequate
does not mean that everyone else does.

@_date: 1995-01-31 22:08:49
@_author: Eric Hughes 
@_subject: The security characteristics of crypto modules with secrets 
From: mab (Matt Blaze)
   I think better than expecting the world to switch over to
   cumbersome, multilevel secure OSs is to equip such servers with
   inexpensive tamper-resistant cryptographic modules that never reveal
   their secrets.
This is certainly the first step to take, even if it's not a complete
   At least then you're guaranteed that there can be only
   one instance of a machine's identity out there at a time, and have some
   hope of detecting the theft of the key material.  Unfortunately, this isn't really true.
Let's take as our model general purpose computers which can't store
secrets connected directly to crypto modules which can.  Furthermore,
let us assume that these general purpose computer are subject to
intrusion.  In other words, it's today's servers with attached crypto.
Now, the crypto module can't authenticate the machine it's plugged
into, because, by definition, that machine can't keep a secret.  One
ends up in an infinite regress here in one tries to assume a secret in
the place we have assumed otherwise.  Because the crypto module can't
authenticate the machine, it will reply to service requests from both
the local and approved machine and any remote and unapproved machines
that can gain access to the module.  The software on the server can be
subverted in order to allow the local crypto module to service remote
The attack works like this.  First, subvert the system software on
some server, probably through existing implementation defects.  Now,
install new software on that server that allows other machines to make
remote procedure calls to the module.  Set up a client on an
impersonating machine that make remote calls to the subverted server
whenever it needs to spoof.  The remote calls will most likely be an
encrypted protocol, to boot.  The easiest way to detect this
externally will be an additional delay in response, that is, doable
but not particularly reliable.
This is not to say that crypto modules are useless.  They have a great
use in recovery.  Because the secret doesn't leave the module, you
have an assurance after recovery (reboot from CDROM, for example) that
nobody else has the secret.  There won't be a need for an immediate
key change, at least.  What you don't get is a complete loss of
assurance of identity.
The prevalent use of modules further reduces the likelihood of initial
attacks based on spoofing.  Since active IP attacks require the
subversion of routers, and since router software is much more
difficult to subvert than general purpose servers, adding crypto
modules to routers would be a big win.

@_date: 1995-02-01 08:54:28
@_author: Eric Hughes 
@_subject: Re: The security characteristics of crypto modules with secrets 
The advantage of a secure crypto module on an insecure server (or
   router or whatever) is in limiting the scope of successful attack. Just to expand on this, the scope is limited in _time_, not space.
That's, when you pull out the module (literally or figuratively), the
attack is known to be over -- and don't plug it back into a machine of
unknown state.
   The main important
   difference between this attack and just learning the server's secret
   is that it only remains useful as long as the attack is undiscovered.
Yes.  Typically, once the attack is discovered, the method used in the
attack is also discovered.  The particular hole is then patched.  The
system can now be put back online without fear of immediate

@_date: 1995-02-01 08:58:07
@_author: Eric Hughes 
@_subject: Re: ESP Unix encrypted session protocol software 
From: tedwards (Thomas Grant Edwards)
   I am thinking of the    use of a trusted adjudicator who could receive information from both the    original participants and check to see if the two keys matched.
How do you authenticate the adjudicator?
You'll have to communicate with the adjudicator and verify one of
their signatures.  You can just as easily exchange signed DH
parameters directly with the other party and verify the signature of
your correspondent.
This is another one of those problems where potential solutions often
just lead to infinite regress.

@_date: 1995-02-02 06:45:22
@_author: Eric Hughes 
@_subject: Remailer encryption module 
From: nzook (Nathan Zook)
   I also believe that hacking PGP is a bad thing (tm), because it means that
   every time an upgrade comes out, it will need to be re-hacked, and once you
   start hacking, when do you stop?
I agree.  PGP just does not have the support for the encryption
required for mixing remailers.  These deficiencies have been known for
about two years at this point and still nothing has happened.  I
expect this not to change anytime soon.
That means that we have to replace PGP as the encryption module for
remailers.  The first thing to do is to design a data format which
supports what the remailers need now, and nothing speculative.  Since
this data format has a single purpose, we can make new revisions more
easily than for a general purpose package.
Once we get a data format, implementations will follow.

@_date: 1995-02-02 08:36:40
@_author: Eric Hughes 
@_subject: Re:  Why encrypt intra-remailernet. 
From: nzook (Nathan Zook)
   When I say that the Mark I remailers are laughably easy to crack, I mean
   laughably easy.
By whom?  I am hearing a general denunciation of the current remailer
system.  These blanket denials are false on their face, because they
are not true in every circumstance.
   The only reason that our systems are actually able to do any good is that
   our threat model _is not_ an LEA--with government resources, and government
   patience.
_Our_ threat model?
There is not one threat model.  Each person has their own threat model
and their own desired level of security.  An individual also desires
more security for some messages than others.  The current remailer
network is good for some purposes and bad for others.
Every evaluation of security _must_ include the nature of the security
desired, because there is no single concept called "security" which is
the same in every situation.

@_date: 1995-02-02 08:48:23
@_author: Eric Hughes 
@_subject: Re: Remailer encryption module 
From: perry ("Perry E. Metzger")
   > Once we get a data format, implementations will follow.
   The obvious data format is MIME's "Security Multiparts".
That's not a complete answer.  That's kind of the obvious package, but
it addresses nothing of the interior.

@_date: 1995-02-02 15:44:26
@_author: Eric Hughes 
@_subject: Re: Remailer encryption module 
From: allan (Allan Bailey)
   [re: not using PGP for remailers]
   Isn't this what the forthcoming PGP RFC is about?  Not to my knowledge.  As I understand it, they're just trying to
standardize a PGP format by documenting what the code can actually
handle and what was already planned into it.
   Also, what about the PEM "standard"?
PEM carries too much identification on the outside of the encryption
wrapper to be of good practical use against traffic analysis for
regular mail, much less remailer mail.
   Consider what CP did with his(her?) PGPTools kit.  As long as we have
   an agreeable dataformat "standard", the implementation becomes
   irrelevant.  I expect someone to have library come out that does the format.  The
format need not be very complicated.  Getting rid of all the key
distribution features makes a format much easier indeed.

@_date: 1995-02-03 11:52:36
@_author: Eric Hughes 
@_subject: Re: Remailer encryption module 
From: warlord (Derek Atkins)
   > I agree.  PGP just does not have the support for the encryption
   > required for mixing remailers.
   How
   is PGP deficient?  What do you need PGP to do in order to get it to
   work right with remailers?
Note that I said mixing remailers, not just regular remailers.

@_date: 1995-02-03 15:14:54
@_author: Eric Hughes 
@_subject: Re: MX'ing and jpunix.com 
From: perry ("John A. Perry")
   to myriad.pc.cc.cmu.edu. What good does this do? I have an agreement with
   myriad.pc.cc.cmu.edu (Matt Ghio) where myriad will take the MX-pointed
   record and additionally alias it through the smail daemon on myriad. This is the beginning of private name service.  The machines behind
this MX record are not particularly visible to the outside.  Given the
existence of such machine, it makes sense to consider giving them
names which are also not too visible from the outside.
A group of remailer operators who had access to the DNS setups on
their machines could create their own personal top-level domain.  For
sake of discussion, let's call it ".cp".  Now random Unix boxes on the
Internet won't be able to gain access to .cp addresses, but the
remailer club would.  Outside parties would be able to be shown .cp
addresses but would not be able to resolve where the machines actually
were on the Internet, much less find them IRL.  (Access control on who
can pull .cp records will have to be added the the DNS software in
order to do this.)
Consider this in the light of Matt Ghio's MX service.  Matt MX's for
the alias.net addresses.  Inside alias.net, the individual remailers
could use .cp addresses to talk to each other.  In fact, those who
want zero contact with the outside world could advertise only .cp
addresses and mail only to other .cp addresses.
For sake of experimentation, I've set up a primary top-level
nameserver here on my machine for ".cp".  In order to access it,
you'll need to act as a secondary name server for the domain.  Hacking
alternate roots into BIND comes later.  Just add the following line to
your named.boot file:
    secondary       cp      204.94.187.1    db-secondary.cp
If you do this, you'll be able to ask for a second-level domain.
If you want a .cp domain, send mail to
    hostmaster
Tell the kind hostmaster what name you want, what you want it for,
where you name servers are, etc.  This is an experimental service and
is not guaranteed to be reliable.  It might also serve as a test bed
for doing cryptographic name service trials.

@_date: 1995-02-05 20:32:42
@_author: Eric Hughes 
@_subject: Re: "encrypt tcp connections" hacks 
Perry advocates IPSP as an almost-panacea for Internet security.  I
disagree.  I'll quote only the most relevant bits:
   From: perry ("Perry E. Metzger")
   > I don't just want one or two encrypted applications -- like
   > the Kerberos telnet and rcp -- but something to transparently provide
   > privacy for all TCP sockets -- like SMTP sockets between (re)mailers,
   > NNTP, X11, FTP, MUDs, etc.
   Well, in the long term, my hope is that people use IPSP for this. It
   will mean that the kernels on their machines simply deal with all this
   stuff and that userland applications get to ignore it 90% of the time.
   [...]
   However, I'd say that this isn't going to be a permanently deployed
   thing on the net -- that much we can be pretty sure of.
The basic problem with assuming IPSP as a universal encryption
solution is that it answers an incomplete threat model.  IPSP works
where you trust the endpoints but not the intermediates.  When you
don't trust the endpoints for silence, but do trust them for routing,
IPSP doesn't work.  Let me make this concrete:
TIA on netcom.
Suppose I'm running extruded netcom ports on winsock clients using TIA
to multiplex the serial line.  (Some of you may be doing this right
now.)  My Netscape connection is passing from my MS Windows machine
through netcom over the internet to my web server of the moment.  IPSP
doesn't provide end-to-end security in this case, because the endpoint
for the IP packet (netcom) doesn't coincide with the endpoint of the
actual connection (the home machine).  A maxim:
Trust boundaries are not the same as machine boundaries.
It's fallacious to argue simply that everyone's going to be _on_ the
Internet soon enough anyway, and that this problem will go away.
Absolutely not.  If anything, this kind of proxying for Internet
connectivity is going to be come _more_ common, and that as a result
of cypherpunk projects for realtime proxy services, such as web and
ftp proxies.
You don't want to trust the proxy in an anonymization service to do
your crypto for you, just like (if you're smart) you won't trust your
secrets to netcom even for processes, much less for filesystems.  And
you can't say that all proxies are going to be IP-to-IP proxies,
either.  Some of them are going to be proxying the whole protocol,
some will participate partially, some not at all.  What this does
indicate, however, is that the need for peer-to-peer encryption will
be necessary at _each_ level of abstraction, and pretty much forever.
It will be an interesting and practical exercise in trust modeling to
figure out how to pass one layers policy requirement for a secure
channel to a service offering at a lower layer.  The problems involved
here are going to be extremely difficult to make work for anything
approaching generality.

@_date: 1995-02-06 12:13:17
@_author: Eric Hughes 
@_subject: Re:  Cooperation 
From: hfinney (Hal)
   I do like the idea of standards.  In fact I wonder if the current "mark
   1" remailer command set shouldn't be documented as an Internet RFC.  If an RFC is issued, I personally would like to clean up the syntax
and get the remailer operators to upgrade accordingly.
In particular, I chose Request-Remailing-To: as a purposefully obtuse
experimental name.  It deserves to die.
My preferences are for the following:
Anon-Send-To: for anonymized email
Send-To: for normal forwarded email
Anon-Post-To: for anonymized Usenet posting
Post-To: for a regular mail-to-Usenet gateway
I want to capture the distinction between Usenet and email as well as
to support plain forwarding of text for people with connectivity

@_date: 1995-02-06 12:25:10
@_author: Eric Hughes 
@_subject: Re: "encrypt tcp connections" hacks 
From: perry ("Perry E. Metzger")
   Eric Hughes says:
   > Perry advocates IPSP as an almost-panacea for Internet security.  I
   > disagree.
   Well, no; it doesn't fix things like mail for which the data needs to
   be protected but not the link. In the case of email, there's the same discrepancy I pointed out
earlier -- the machine or filesystem boundary is not the same as the
trust boundary.  This will happen for email as well as more live and
online communications needs.
   TIA is sort of a short term hack people are using to get around having
   to have their administrators manage SLIP or PPP properly; I suspect
   this difficulty will vanish with time.
I agree with you that this particular example may be short lived, but
you appear to have ignored the more fundamental point I was making.
Namely, the existence of communications proxies which _change_ the
level of abstraction will be with us forever.  The TIA unix end
switches from TCP-to-the-world to IP-to-the-PC.  That's a level
   IP is ultimately designed to be a proxy protocol that will work over
   anything -- stuff like TIA simply gets around temporary mental
   difficulties among providers in seeing things that way...<
I'm not saying that IP proxies won't exist.  What I am saying is that
other forms of proxying will also exist.  Not all policies will be
able to be enforced at the IP level.  As soon as you want security
policy to apply to non-IP abstractions, IPSP is no longer primary,
even if it's still involved.
Firewall policies are a prime example of security policy enforced at
the TCP and UDP levels, with access control by port number.  External
firewalls, a class that includes packet laundries, web proxies, and
IRC anonymizers, will not for the most part operate at the IP level.
It's certain that IP security will greatly increase the overall
security of the Internet.  I'm not advocating its removal but rather
the acknowledgement that higher (and lower) level abstractions will
require their own cryptography.

@_date: 1995-02-06 13:15:06
@_author: Eric Hughes 
@_subject: Re: Cooperation 
Eric says:
   > In particular, I chose Request-Remailing-To: as a purposefully obtuse
   > experimental name.  It deserves to die.
   From: perry ("Perry E. Metzger")
   I'd say that it would work far better if things were changed to MIME
   formats. You would send a message by recursively encapsulating your
   message to be remailed inside a MIME message. Simple and clean...
That's fine.  I like MIME, but the issue is cleaning up the existing
remailers, none of which use MIME, and the chaining scripts, none of
which do either.
Getting everybody to support Anon-Send-To: in addition to
Request-Remailing-To: is a very simple and straightforward fix for an
acknowledged syntactic inanity.

@_date: 1995-02-07 11:28:01
@_author: Eric Hughes 
@_subject: Re: dna ink 
From: perry ("Perry E. Metzger")
   Digital "signatures" are the first real unforgeable authentication
   technology mankind has developed.
Impossibility is a pretty strong concept, and here, as elsewhere, it's
an exaggeration.  Digital signatures are not unforgeable.  If you
steal the private key, you can forge signatures.  The unforgeability
is exactly as great as the strength of the container where the private
key lies.  The issue of incarnation, if you will, is perhaps the
single most important issue for actual deployment.
It's a matter of economics.  The cryptographic barrier is
insurmountable, but it's not the only barrier.  So don't try to breach
the cryptography; try to breach one of the other elements of the
[Perry, I promise it's not personal; it just _seems_ like I'm
nit-picking on everything you write this week.]
A remark on the meaning of forgery.  Let me rewrite what Perry said:
   Digital "signatures" are the first authentication technology
   mankind has developed where forgery is impossible to detect.
An indistinguishable signature can still be a forged signature.  A
forged signature is one that is made by the wrong person.  If the
wrong person gets the private key, signatures made by that person are
forgeries, even though nobody can tell them apart.
This point is not merely pedantic.  The concept of forgery adheres to
the person committing the act, not the act itself.  A piece of data
which presents itself as a signature, but which does not pass the
verification process, is not a forged signature but an invalid one.
The external inability to distinguish proper digital signatures from
forged ones has profound effect on the legal interpretations of the
physical signing device (hardware+software).  I wish only to point
this out and leave discussion to another thread.

@_date: 1995-02-07 20:10:39
@_author: Eric Hughes 
@_subject: Re: a new way to do anonymity 
From: weidai ("Wei Dai")
   P.S. I never gave a name for the protocol... let's call it Pipe-net.
I don't think we really need a separate name for it just yet.  The
idea is composed of two pretty much independent elements: packet
forwarding and virtual link encryption.  These can be implemented
separately and then combined to yield the kind of network interaction
Getting the details right will be difficult, and I'd suggest that is
where the discussion might profitably turn next.

@_date: 1995-02-07 20:23:52
@_author: Eric Hughes 
@_subject: RE: a new way to do anonymity 
From: jcorgan (Johnathan Corgan)
   There are many, many analogies you can draw about a network of this
   type to an ATM (asynchronous transfer mode) network.  Thank you for the analogy.  It's always good not to reinvent the wheel
when you don't need to.
   The switched path could be set up and torn down dynamically by the user by
   interacting with the "switch" at each point to select the next hop the    encrypted byte stream will follow.
When you set up a mapping on a packet forwarder, this is exactly the
kind of initialization that would be required.  It is also at this
point that keying would be negotiated, etc.
   Fixed length data packets (at the encrypted telnet level) also make it very
   easy to aggregate individual circuits into higher bandwidth pipes that
   connect server to server.
Now here's an important detail that needs to get done right.  Is the
forwarding for fixed length packets, variable length packets, or
streams?  Is this decision global or local?  What are the latency and
aggregatation effects?  How important are these for different classes
of data?  (telnet v. voice, e.g.)
I'd suggest just getting something running first, to get some
prototyping experience.

@_date: 1995-02-08 06:20:39
@_author: Eric Hughes 
@_subject: RE: a new way to do anonymity 
From: jcorgan (Johnathan Corgan)
   One of the lessons learned in the years-long debate between the
   telco folks pushing synchronous time-division multiplexing point to
   point circuit switches and the data folks pushing variable length
   packet-switched broadcast medium networks is that fixed length
   packets can give you both TDM and statistical multiplexing.
There's an important difference here.  Namely, the telco/ATM folks
were building hardware from scratch and we're not.  We're layering on
top of an existing Internet routing environment.
This doesn't mean that your point is wrong, but that it may no longer
be true when the base layer is IP.  I'm not familiar enough with the
ATM arguments to know whether they're still valid in this other

@_date: 1995-02-08 06:59:37
@_author: Eric Hughes 
@_subject: Re: WSJ Article on Sen. Exon's Legislation 
he says, adding that a failure by the government to act    would be "an open invitation to some of the hardcore pornography getting    into our homes."
I don't know about the rest of you, but I'd rather have that ol'
hardcore pornography in the privacy of our homes, where it belongs,
than in public, where innocent children might gain access to it.

@_date: 1995-02-08 19:51:32
@_author: Eric Hughes 
@_subject: Re: Effects of S.314 (Communications Decency Act) 
From: dmandl (David Mandl)
   For a while, we were all convinced that the FCC left all these rules
   impossibly vague on purpose, just so that you didn't even know how to obey
   the law if you wanted to.  Everyone a potential criminal.
Just like the banking world, where it's no secret at all.
Did y'all know there's a separate market segment in the banking
business called "Compliance"?

@_date: 1995-02-08 20:10:38
@_author: Eric Hughes 
@_subject: Re: Hastur CT status 
From: cactus (A Loose Affiliation of Millionaires and Billionaires and Babies)
   For instance, I've asserted several times here that X.509 keys
   can be fully modelled as special cases of PGP web-of-trust keys
   with one additional field, the expiration time.  Nobody has flamed
   me, but nobody has agreed with me... since I've only read the X.509
   spec and never actually used them, I'd like some assurance that I'm
   not missing some subtleties in this approach.
The only real question about a particular string of bits claiming to
be a public key of a certain persona is whether the operator trusts
that the key does belong to that persona.  PGP and X.509 models both
provide their own kinds of assurances to individuals who might use a
key.  The relation between the user and the claim of ownership is the
important relationship.  Any sort of key certificate, of whatever
sort, is merely an aid to gaining trust.
Key certificates don't prove ownership.  Key certificates transfer the
need for trust in the key to the need for trust in the certificate.
Put another way, a key distribution system allows a user to trust
something harder to fake than a single key.  The transfer is the
critical point here; instead of trusting one small thing, you can
trust one larger thing.  We hope that the larger system is worthy of
our trust.
Neither PGP nor PEM is a general purpose key distribution system,
although PGP is more general than PEM.  Both have their various
arbitrary and capricious policies hardcoded into both spec and source.
I would recommend, Todd, that you not try to unify the various key
distribution systems.  It's premature.  Rather, provide a local policy
hook for the user (and this is _not_ just the sysadmin, as you know)
to specify how much trust pertains to each given keydist system, and
of what idiosyncratic sorts.

@_date: 1995-02-08 20:14:43
@_author: Eric Hughes 
@_subject: Re: skronk 
From: kipp ("Kipp E.B. Hickman")
   You are right here. However, our observation is that an interesting
   chunk of the world is moving towards using X.509 based certificate
   infrastructures for many things.
It's that interesting chunk that RSADSI is pointing out to you.  When
you see the world through the eyes of a vendor ...
And you know, of course, that PEM really stands for Patent Extension
I don't really blame you much.  I mean TIPEM handles all the X.509
stuff just fine and PGP can't get out even the simplest of libraries,
or even a partial library.

@_date: 1995-02-08 20:20:48
@_author: Eric Hughes 
@_subject: Re: MIME based remailing commands 
From: hfinney (Hal)
   Is there precedent for
   adding service-by-mail functionality in this way?  You mean, like MIME?
   (Maybe "Latency"
   might be used in a future extension of RFC822 for some other meaning than
   what we are using it for.)
The command should be Add-Delay: if you want to acheive the result of
some latency.  (Those who don't recognize the double-edged nature of
this remark are welcome to make fools of themselves in public.)

@_date: 1995-02-08 20:23:40
@_author: Eric Hughes 
@_subject: Re: skronk 
From: kipp ("Kipp E.B. Hickman")
   Yes, there will be. We haven't formalized it yet, but we have been
   getting enough interest to warrant it. Understand that this is not
   the main thrust of our business (selling source code), so it will
   certainly take some time to put it all together.
Pardon me if I point out that when you write a new facility and want
people to be compatible with it, there needs to be source code
available for distribution.  Perhaps this is merely a lapse in
corporate self-awareness and fundamental lack of planning.  I could be

@_date: 1995-02-08 20:27:14
@_author: Eric Hughes 
@_subject: Re: MIME based remailing commands 
From: perry ("Perry E. Metzger")
   xpat says:
   > IMHO, an ideal message would have the ability to handle nested objects
   > of varying types, MIME is only a start.
   What is it precisely that you might want to encapsulate that MIME
   can't encapsulate?
Perry, you're missing the whole point, just like the exchange a few
days about a remailer format standard.
MIME is primarily a packaging standard.  MIME does not define the
innards, the payload, the contents.  MIME is only a start at what the
complete data format should look like.  You say MIME, and you've not
completely specified the data format, but rather constrained it in a
way that most everybody basically agrees with, including me.

@_date: 1995-02-09 12:33:43
@_author: Eric Hughes 
@_subject: Re: Effects of S.314 (Communications Decency Act) 
From: tcmay (Timothy C. May)
   Unlike the
   Digital Telephony Bill, which was on greased skids, [...]
As far as I have been able to puzzle out, the source of this claim
were the same parties that wanted to work a "compromise".  I have
never really trusted its veracity.
There was lobbying by the FBI, to be sure, but was there not also
lobbying for previous such bills (including S.266)?

@_date: 1995-09-06 01:28:08
@_author: Eric Hughes 
@_subject: ANNOUNCE: September 1995 SF Bay Area physical meeting 
What: September 1995 SF Bay Area physical meeting
When: Saturday, 9 September 1995
      12:00 noon - 6:00 p.m.
Where: that hard-to-find loft space at 2nd & Brannan
       where we had July's meeting
This month's meeting is the "Even More Catastrophically Overnamed
Fourth Annual Cypherpunks Conclave, Congress, Schmooze-Fest, Meeting,
and Feast".
It's been three years since the first meeting at my house at the time
in Oakland.  If you only come to one meeting a year, come to this one.
It's canonical.
The agenda for this meeting is completely empty.  I've been out of
town for all but a total of about three weeks since the last meeting
two months ago (and I'm gone the rest of this week and flying in
Saturday morning).  So where in the past we've had something
approaching a schedule, this time I've not made even a pretense at
scheduling.  So just show up -- we always find something good to talk
And besides, if you don't show up, you can't here about my unexpected
genetic discovery!
Directions follow.  See you there.

@_date: 1996-01-31 00:40:53
@_author: Eric Hughes 
@_subject: re: FV Demonstrates Fatal Flaw in Software Encryption of Credit Cards 
Thanks to Sandy Sandfort for bringing this to my attention.
   Date: Mon, 29 Jan 1996 15:07:46 -0500 (EST)
   From: nsb (Nathaniel Borenstein)
   As you may already have heard via the popular press, First Virtual
   Holdings has developed and demonstrated a program which completely
   undermines the security of every known credit-card encryption mechanism
   for Internet commerce.
I'm breaking my silence in cypherpunks to respond to what must be the
most self-serving and fatuous expression of "concern" I've seen in a
To wit:  Ohmygod!  PC's don't have perfect integrity!
Will someone please write a filter for common email packages which
automatically removes selected First Virtual transactions from the
confirmation messages?  Encryption isn't the issue, Nathaniel, and you
know it.  Me, I prefer bad faith over stupidity as an explanation for
this latest outpouring.
To all those Internet payment analysts out there:
   Financial institutions are in the business of risk transfer.  If
you don't transfer risk in some form, you're not a financial
institution but rather a service bureau.  Managing endpoint integrity
risk is just one of the kinds of risk an Internet payments provider
has to deal with.  First Virtual has demonstrated time and again that
they're pretty clueless about the whole subject of risk.  As a result,
I don't give them more than about two years longer before they go
belly up.

@_date: 1996-03-14 12:58:13
@_author: Eric Hughes 
@_subject: Kid Gloves or Megaphones 
I've been engaged in a background discussion with some folks about how
to treat a new protocol, when to speak, etc.  Elements of that
discussion have become relevant to the list widely.
The situation is thus.  Ian Goldberg et al. have developed a protocol
for simultaneous payer and payee anonymity.  It appears to be novel,
albeit not entirely unanticipated.  The protocol works with the
existing bank signing oracle and could interoperate with Mark Twain's
current system.
The suggestion was made, paraphrasing -- couldn't we just not talk
about this too loudly yet?
... NO!
Perhaps the single most important lesson I've learned from cypherpunks
is that code alone doesn't cut it.  Not code alone, not code widely
distributed, not even code widely used.  Some measure of toleration in
society for activities conducted in private is _necessary_ for long
term success.  Not convenient, not easier, but necessary.
The whole Clipper situation testifies to this.  Unless there is a
public concensus that people generally should be able to use their own
cryptography, then such use will become marginalized.  Legislatures
will outlaw, the public will disapprove, and vigilantes will hunt down
improper use.  That, in my book, means we've lost.
Code is clearly still necessary.  Code demonstrates what actually
happens.  To write code is to invoke and evoke the latent and
insufficiently articulated desires for privacy in the world at large.
Similarly with anonymous transactions.  Unless a similar concensus
exists, we will have another marginal activity.  Again, I count this a
Backlash will result from later disclosure that the payment systems we
generally as cypherpunks have undisclosed properties, that we as a
loose group have dissimulated and even lied outright about the
capabilities of the systems we advocate.  This backlash will wipe away
many gains we might have made and eliminate the possibility of future
The backlash will be justified, because it will be the natural result
of a demonstration of bad faith.  One such demonstration now, and who
would know when the next was coming, or that we had not hoarded
encrypted agendas all along in our hearts?  And then, since we would
not be believed, all the propaganda of our opponents will triumph.
The Four Horsepersons will come trotting out in grand inquisitional
spectacle, and there will be no counterpoint, because the devil's
advocate will have been discovered to have been guilty himself.
It is foolishness itself to deceive a public which is substantially in
favor of the program of complete privacy.  We must appeal to the
public that finally will decide, not to some officials today who have
power and tomorrow who will not.  Clipper itself was not defeated by
constructive engagement with the Clinton wiretap administration.
Clipper was defeated by a general call to arms.
Therefore, shout out to the world that payee anonymity is possible with

@_date: 1996-03-15 14:59:59
@_author: Eric Hughes 
@_subject: Re:  Kid Gloves or Megaphones 
Date: Thu, 14 Mar 1996 10:18:27 -0800
   From: hfinney (Hal)
   So while I admire Eric's ethical concern about making relevant
   information about the properties of ecash available, it is also important
   to understand the possible outcome.
My concern is not ethical, although upon re-examining what I said I
can see how that might appear that way.  My concern is entirely
pragmatic.  Disclosure is the ethical act, true, but in this case the
ethicality is performative, it is the active principle itself.  The
issue is one of legitimacy and the epistemology of a group.  Telling
the truth is not just a morally good idea, it is a pragmatically
useful one.
If we do not disclose what we know now, _regardless_ of the immediate
outcome, we will lose in the end.  If we lose now, we will never have
been able to win at all.  The debate which must be taken to the public
is whether we want payee anonymity or not.  I am confident that people
want their privacy and are willing to let others have theirs as well.
If they do not, the world is not as I understand it, and I have some
hard thinking to do.
   One thing I notice that was missing from Eric's posting was a description
   or reference to exactly how the payee anonymity is achieved.  Is it his
   intention to tell people that it is possible, yet to keep secret how it
   is done?
I didn't invent it.  I'm going to let Ian describe it when and how he
