
@_date: 1997-01-25 02:10:58
@_author: Julian Assange 
@_subject: language drift 
One of my projects involves tracking language drift; i.e the relative
change in word frequency on the internet as time goes by.  This is
useful for predicting concept movement, and the anglisization
rates of non-English language countries.
Now, one day while browsing the frequencies from the 10 billion
word corpus, what do I see?
God     	2,177,242
America 	2,178,046
designed        2,181,106
five    	2,189,194
December        2,190,028
-Julian Assange

@_date: 1997-01-24 22:01:40
@_author: Julian Assange 
@_subject: language drift 
One of my projects involves tracking language drift; i.e the relative
change in word frequency on the internet as time goes by.  This is
useful for predicting concept movement, and the anglisization
rates of non-English language countries.
Now, one day while browsing the frequencies from the 10 billion
word corpus, what do I see?
God     	2,177,242
America 	2,178,046
designed        2,181,106
five    	2,189,194
December        2,190,028
-Julian Assange

@_date: 1997-06-25 10:27:56
@_author: P 
@_subject: Underground extract: System X 
Anyone read this book? Apparently the first in-depth investigation
into the international computer underground to come out of the
Southern-Hemisphere - or so I'm told ;)  - J.A
Extracts from Underground - The true nature of System X
  Extracted from Chapter 10 - "Anthrax - The Outsider"
   Note: System X's name has been changed for legal reasons.
   Sometimes the time just slipped away, hacking all night. When the first hint
   of dawn snuck up on him, he was invariably in the middle of some exciting
   journey. But duty was duty, and it had to be done. So Anthrax pressed control
   S to freeze his screen, unfurled the prayer mat with its built-in compass,
   faced Mecca, knelt down and did two sets of prayers before sunrise. Ten
   minutes later he rolled the prayer mat up, slid back into his chair, typed
   control Q to release the pause on his computer and picked up where he left
   off.
   This company's computer system seemed to confirm what he had begun to
   suspect. System X was the first stage of a project, the rest of which was
   under development. He found a number of tables and reports in System X's
   files. The reports carried headers like 'Traffic Analysis', 'calls in' and
   'calls out', 'failure rate'. It all began to make sense to Anthrax.
   System X called up each of the military telephone exchanges in that list. It
   logged in using the computer-generated name and password. Once inside, a
   program in System X polled the exchange for important statistics, such as the
   number of calls coming in and out of the base. This information was then
   stored on System X. Whenever someone wanted a report on something, for
   example, the military sites with the most incoming calls over the past 24
   hours, he or she would simply ask System X to compile the information. All of
   this was done automatically.
   Anthrax had read some email suggesting that changes to an exchange, such as
   adding new telephone lines on the base, had been handled manually, but this
   job was soon to be done automatically by System X. It made sense. The
   maintenance time spent by humans would be cut dramatically.
   A machine which gathers statistics and services phone exchanges remotely
   doesn't sound very sexy on the face of it, until you begin to consider what
   you could do with something like that. You could sell it to a foreign power
   interested in the level of activity at a certain base at a particular time.
   And that is just the beginning.
   You could tap any unencrypted line going in or out of any of the 100 or so
   exchanges and listen in to sensitive military discussions. Just a few
   commands makes you a fly on the wall of a general's conversation to the head
   of a base in the Philippines. Anti-government rebels in that country might
   pay a pretty penny for getting intelligence on the US forces.
   All of those options paled next to the most striking power wielded by a
   hacker who had unlimited access to System X and the 100 or so telephone
   exchanges. He could take down that US military voice communications system
   almost overnight, and he could do it automatically. The potential for havoc
   creation was breathtaking. It would be a small matter for a skilled
   programmer to alter the automated program used by System X. Instead of using
   its dozen or more modems to dial all the exchanges overnight and poll them
   for statistics, System X could be instructed to call them overnight and
   reprogram the exchanges.
   				      ---
   No-one would be able to reach one another. An important part of the US
   military machine would be in utter disarray. Now, what if all this happened
   in the first few days of a war? People trying to contact each other with
   vital information wouldn't be able to use the telephone exchanges
   reprogrammed by System X.
   THAT was power.
   It wasn't like Anthrax screaming at his father until his voice turned to a
   whisper, all for nothing. He could make people sit up and take notice with
   this sort of power.
   Hacking a system gave him a sense of control. Getting root on a system always
   gave him an adrenalin rush for just that reason. It meant the system was his,
   he could do whatever he wanted, he could run whatever processes or programs
   he desired, he could remove other users he didn't want using his system. He
   thought, I own the system. The word 'own' anchored the phrase which circled
   through his thoughts again and again when he successfully hacked a system.
   The sense of ownership was almost passionate, rippled with streaks of
   obsession and jealousy. At any given moment, Anthrax had a list of systems he
   owned and that had captured his interest for that moment. Anthrax hated
   seeing a system administrator logging onto one of those systems. It was an
   invasion. It was as though Anthrax had just got this woman he had been after
   for some time alone in a room with the door closed. Then, just as he was
   getting to know her, this other guy had barged in, sat down on the couch and
   started talking to her.
   It was never enough to look at a system from a distance and know he could
   hack it if he wanted to. Anthrax had to actually hack the system. He had to
   own it. He needed to see what was inside the system, to know exactly what it
   was he owned.
   The worst thing admins could do was to fiddle with system security. That made
   Anthrax burn with anger. If Anthrax was on-line, silently observing the
   adminsÕ activities, he would feel a sudden urge to log them off. He wanted to
   punish them. Wanted them to know he was into their system. And yet, at the
   same time, he didnÕt want them to know. Logging them off would draw attention
   to himself, but the two desires pulled at him from opposite directions. What
   Anthrax really wanted was for the admins to know he controlled their system,
   but for them not to be able to do anything about it. He wanted them to be
   helpless.
   Anthrax decided to keep undercover. But he contemplated the power of having
   System X's list of telephone exchange dial-ups and their username - password
   combinations. Normally, it would take days for a single hacker with his lone
   modem to have much impact on the US military's communications network. Sure,
   he could take down a few exchanges before the military wised up and started
   protecting themselves. It was like hacking a military computer. You could
   take out a machine here, a system there. But the essence of the power of
   System X was being able to use its own resources to orchestrate widespread
   pandemonium quickly and quietly.
   Anthrax defines power as the potential for real world impact. At that moment
   of discovery and realisation, the real world impact of hacking System X
   looked good. The telecommunications company computer seemed like a good place
   to hang up a sniffer, so he plugged one into the machine and decided to
   return in a little while. Then he logged out and went to bed.
   When he revisited the sniffer a day or so later, Anthrax received a rude
   shock. Scrolling through the sniffer file, he did a double take on one of the
   entries. Someone had logged into the company's system using his special login
   patch password.
   He tried to stay calm. He thought hard. When was the last time he had logged
   into the system using that special password? Could his sniffer have logged
   himself on an earlier hacking session? It did happen occasionally. Hackers
   sometimes gave themselves quite a fright. In the seamless days and nights of
   hacking dozens of systems, it was easy to forget the last time you logged
   into a particular system using the special password. The more he thought, the
   more he was absolutely sure. He hadn't logged into the system again.
   Which left the obvious question. Who had?
     ________________________________________________________________________
     [This extract may be reposted non-commercially and without charge only]
   Underground; Tales of Hacking, Madness and Obsession on the Electronic
   Frontier, by Suelette Dreyfus; published by Mandarin (Random House
   Australia); (P) 475 pages with bib.  or

@_date: 1997-10-17 20:56:52
@_author: Julian Assange 
@_subject: Marutukku - cryptographic filing system 
Marutukku (my cryptographic file system/block device) is due for first
beta sometime next week. Before release, I'd like some (strong!)
criticism of the sub key generation / chaining techniques I'm
using. But first, for those who haven't a frigging clue what Marutukku
is, here is a hastily drawn non-cryptographic (more about that later)
features list:
          kernel drivers)
          on the Linux port, but no promises).
          types can be created in the regular manner (or even a swap
          partition ;)
Marutukku supports a variety of ciphers, and the cipher used for the
lattice (which is used to generate sub-keys for each file-system
block) generation is independent from the cipher used for block
functions. At the moment it only makes sense to talk of the lattice
generator in terms of a stream cipher or a block cipher/hash algorithm
in OFB. My design principles along the way have attempted as far as
possible to cover as yet unknown vulnerabilities in the under-laying
ciphers used with good management of IV's, salts, sub-keys, chaining
etc.  Some of these steps may pose no additional security in relation
to certain attacks (i.e secret vs public IV's) on particular ciphers
but most come at little cost compared to the encryption itself.
Primary key/salt generation walk though:
Instance/Lattice generation:
Block key generation:
LEFT	   |     RIGHT|
L-SUBKEY 0|L-SUBKEY 1|
L-SUBKEY 1|L-SUBKEY 2|
   ....   |   ....   |
L-SUBKEY n|L-SUBKEY n|
FS block encryption:
Prof. Julian Assange  |If you want to build a ship, don't drum up people
together to collect wood and don't assign them tasks
proff          |and work, but rather teach them to long for the endless
proff  |immensity of the sea. -- Antoine de Saint Exupery

@_date: 1997-10-27 09:19:33
@_author: Julian Assange 
@_subject: cryptographic anecdotes 
I'm involved in producing a segment on cryptograpic issues for Radio
National (ABC) to be aired latter this week. I have no problems with
the technical issues but could use some (reliable) "colour" i.e small
quirky or unusual anecdotes that will draw in and hold the larger
order of listeners who don't otherwise have any cryptography/
cryptographic-policy background.
Prof. Julian Assange  |"Don't worry about people stealing your ideas. If your
 Ideas are any good, you'll have to ram them down
proff          | people's throats."
proff  |                -- Howard Aiken

@_date: 1997-11-15 21:11:34
@_author: Julian Assange 
@_subject: Re: Gieger dies in poverty...not! 
No, just an illiterate.
Prof. Julian Assange  |"Don't worry about people stealing your ideas. If your
 Ideas are any good, you'll have to ram them down
proff          | people's throats." -- Stolen quote from Howard Aiken
proff  |

@_date: 1997-12-06 14:00:46
@_author: Julian Assange 
@_subject: Rubber-hose proof (cryptographically deniable) file-systems. 
Here's a copy of some correspondence in relation to my implementation
of a `rubber hose proof' (cryptographically deniable) file system
(actually implimented as a block device on which you can mount any
file system). I'm happy with the cryptographic strength of the system
(but feel free to comment anyway). That said, I'm not convinced that
my avoidance of media (i.e disk surface) analysis attacks (which could
potentially show the pre-sense or otherwise of cryptographic file
systems other than the "duress" ones) is entirely effective. I'd like
some comment from gauss-ridden declassification guru's here :)
Here's how I'm implementing `aspects' in Rubberhose/marutukku;
`aspect' is the term I'm using to refer to the
cryptographically-deniable (i.e rubber-hose-proofed) "portion", of a
maru extent i.e it's a different _aspect_ (view) of the same
underlying physical block extent.
I decided that random split lengths don't add to the security of the
scheme - only 2x from my calculations - which isn't enough to warrant
the increase in memory use and complexity involved.  The extent is
simply divided up into n splits (say 1024 or one every 256k, whichever
is smaller). Each aspect has an encrypted 32bit block remap list
(which is simply a linear array because of the fixed split size).  A
split avoidance bit-map is created from these per-aspect remap lists
on instantiation of the aspects. An individual aspect looks like so
(when saved):
typedef struct
    m_u32 keySum; /* key checksum */
    u_char masterKey[MAX_KEY];
    u_char latticeCipherType, blockCipherType;
    u_char pad[MAX_BLOCK - (4 + MAX_KEY + 1 + 1) % MAX_BLOCK]; /* block align */
} maruCycle;
typedef struct
    maruCycle cycle;
    u_char keySalt[MAX_PASSPHRASE];
    maruLatticeKey latticeKeySalt[2];
    u_char blockIV[MAX_FS_BLOCK_SIZE];
    u_char latticeSalt[2*MAX_LATTICE_DEPTH*MAX_BLOCK_KEY]; /* must be 64 aligned */
    m_u32 remap[MAX_SPLITS];
    m_u32 iterations;
    maruCipher keyCipherType;
} maruHeaderAspect;    There are an array of (8 by default) of these constructs in a maruHeader.
The smap accessor macros are simple:
	SMAP_SET(p, n) (((p))[(n)/(sizeof(maruSmap)*8)] |= (1 << ((n) % (sizeof(maruSmap)*8))))
	SMAP_CLR(p, n) (((p))[(n)/(sizeof(maruSmap)*8)] &= ~ (1 << ((n) % (sizeof(maruSmap)*8))))
	SMAP_ISSET(p, n) (((p))[(n)/(sizeof(maruSmap)*8)] & (1 << ((n) % (sizeof(maruSmap)*8))))
By default, each unused maruHeaderAspect struct contains random noise
(except for keyCipherType, which defaults to being the same for all
aspects) and is of course indistinguishable from a valid maruAspect
without the associated key.
Instantiation example:
Say you have three valid aspects, a1, a2 and a3. Arbitrarily, you have
chosen a1 to be the simple duress aspect (i.e ``you expect us to
believe you have solitary letter of donation to the Polit Bureau Ball
in your entire encrypted file system?! Do you know what this is Nikov?
. THIS is the finest cryptanalytic device known to
man. THIS is a RUBBERHOSE! *thwap* *thwunk* *boink*. Now... what's the
*real* key Nikov... or should we call you... Nikolay Bukharin?''), a2 to
be the limited disclosure aspect ("Dear diary. Nikita, Ivan, Boris and
came over today and smoked a *shit load* of hash. Not wanting to
offend, I had a toke, but like that capitalist dog
^H^H^H^H^H^H^H^H^H^H^H^H^H illustious leader of the freeworld, was
careful not to inhale.") and a3 has your ice-9 formula nicely tucked
You decide one fine morning that you want to add an ATP pre-cursor as
a catalyst to your ice-9 recipe of destruction (ostensibly, you plan
to generate this stuff from cultures of genetically modified mouse
liver cell mitochondria), and provide the a1, a2 and a3 pass-phrases.
a1, a2 and a3 are decrypted. the aspect remap is parsed and used to
create the physical block "avoidance" map (checking for conflicts
along the way).
Joyous about the frozen seas to come, you copy the ATP pre-cursor
catalyst into a3 and the file system tries to write a new block - e.g
b28 - to a3.  b28 is translated through the a3 remap table to b-1
(unallocated). A random block remap number is generated e.g b595 and
tested against the avoidance smap. If free, it is marked and chosen to
be the new a3 mapping, otherwise the algorithm simply does a circular
hunt for the next free entry in the avoidance smap.
Naturally, reading only requires the key of the aspect you are
interested in (divulging). Writing to one aspect without the keys to
the other aspects will randomly trash them as new splits are assigned.
This would be the simple end of it, were it not but for magnetic
domain leakage/disk surface wear analysis attacks. Theoretically, this
sort of attack could used to demonstrate access patterns by the drive
head in regions outside those used by the duress aspect blocks. What
we want to do here is to make sure the non-data carrying
magnetic/other properties of the disk substrate are as close to a
Jackson Pollock painting as is possible. i.e totally random :) Three
methods are used:
All aspects are defined to take up 100% of the marutukku extent from
the file-system perspective - this is essential to our deniability
scheme. This works fine with most file-systems - e.g UFS, because they
only write to a small fraction of their addressable blocks when
formatted - i.a few super-blocks and inode, rather than zeroing every
block, and so split usage for a given aspect reflects population of
the file system that pertains to it.

@_date: 1998-01-15 08:07:24
@_author: Julian Assange 
@_subject: Re: Crypto Kong penetration. 
My first recomendation would be to change the name. Quickly.

@_date: 1998-03-27 22:59:10
@_author: Julian Assange 
@_subject: Deniable Cryptography [was winnowing, chaffing etc] 
Marutukku (my rubber-hose proof filing system) addresses most of these
technical issues, but I'd like to just comment on the best strategy
game-theory wise, of the person wielding the rubber-hose.
In Marutukku the number of encrypted extents (deniable "virtual"
partitions) defaults to 16 (although is theoretically unlimited). As
soon as you get over about 4 pass-phrases, the excuse "I can't recall"
or "there's nothing else there" starts to sounding highly plauseable.
Ordinarily best strategy for the rubber-hose wielder is to keep on
beating keys out of (let us say, Alice) indefinitely till there are no
keys left. However, and importantly, in Marutukku, *Alice* can never
prove that she has handed over the last key. As Alice hands over more
and more keys, her attackers can make observations like "the keys
Alice has divulged correspond to 85% of the bits". However at no point
can her attackers prove that the remaining 15% isn't simply
unallocated space, and at no point can Alice, even if she wants to,
divulge keys to 100% of the bits, in order to get the un-divulged
portion down to 0%. An obvious point to make here is that
fraction-of-total-data divulged is essentially meaningless, and both
parties know it - the launch code extent may only take up .01% of the
total bit-space.
What I find interesting, is how this constraint on Alice's behaviour
actually protects her from revealing her own keys, because each party,
at the outset can make the following observations:
Rubber-hose-squad: We will never be able to show that Alice has
Alice:		   (Having realised the above) I can never prove that I
Alice certainly isn't in for a very nice time of it (although she
she's far more likely to protect her data).
On the individual level, you would have to question whether you might
want to be able to prove that, yes, infact you really have surrendered
the last remaining key, at the cost of a far greater likelihood that
you will. It really depends on the nature of your opponents.  Are they
intelligent enough understand the deniable spect of the cryptosystem
and come up with the above strategy? Determined to the extent they
are will to invest the time and effort in wresting the last key out of
you? Ruthless - do they say "Please", hand you a Court Order, or is it
more of a Room 101 affair?
But there's more to the story.
Organisations and groups may have quite different goals in terms of
key retention vs torture relief to the individuals that comprise them,
even if their views are otherwise co-aligned. I'm not talking about
some mega-complex multinational 8 level hierarchy. A simple democratic
union of two or more people will exhibit this behaviour.
When a member of a group, who uses conventional cryptography to
protect group secrets is rubber-hosed, they have two choices (1)
defecting (by divulging keys) in order to save themselves, at the cost
of selling the other individuals in the group down the river or (2)
staying loyal, protecting the group and in the process subjugating
themselves continued torture.
With Marutukku-style deniable cryptography, the benefits to the
individual derived from choosing tactic (1) are largely
eliminated. Individuals that are "otherwise loyal" to the group, will
realise this and choose tactic (2).
Presumably most people in the group do not want to be forced to give
up their ability to choose defection. On the other hand, no one in the
group wants anyone (other than themselves) in the group to be given
the option of defecting against the group (and thus
themselves). Provided no individual is certain* they are to be
rubber-hosed, every individual will support the adoption of a
group-wide Marutukku-style cryptographically deniable crypto-system.
* Actually a complicated threshold.

@_date: 1998-03-28 08:42:53
@_author: Julian Assange 
@_subject: NRA support for crypto [was Rivest's Wheat & Chaff - A crypto alternative] 
I guess that was a bit mean. I'm just not sure one is really a
cryptographer till one is spending the majority of their time doing it
and earning a living (or a lot of respect) due to the quality of the
work produced. i.e dabbling in cryptography != I've made significant
contributions to the state of the art (I know you have made useful
contributions to other parts of the security world). We .... is often
used as a psychological ploy, to convince people the argument that
follows is their own. Given that I strongly disagreed with the
substance of your message, perhaps I took a dislike to the We
.... business a little too eagerly.
So your suggesting putting your weight behind a tactical metaphor of
the FBI? Effectively letting them control the landscape of the debate,
by implanting into the public's minds that guns equal cryptography.
You now have a situation where all strong cryptography is out-lawed
(err, when was the last time you purchased a A42 tank cannon?)
domestically, everything requires export permits (wadda ya mean I can't
post my 10 gauge to Zurich without a license?!) and weak cryptography
is exposed to a whole host of restrictions, including key size
limitation (small arms only), speed limitations (it's dangerous to be
able to encrypt too many messages quickly and automatically), usage
registration (1 32 bit 8 round IDEA cipher and 2 40 bit barrel-loaded
RC4's in farmer Jones' bedroom), cooling off periods (can't let people
encrypt on a 'whim), exclusion of un-desirables (you want a crypto
license and you haven't been in the state 3 months/had a psychiatric
illness/were convicted of an offence/are under the age of 21/listen to
NPR?!), necessity (I need that there 56 bit 8 rounder for rabbit
'crypting; I had to encrypt, officer, in a suburban environment - it was
self defence against hardened criminal hackers!).
Breaking cryptography saved lives in the war, this is extensively
documented over hundreds of clearly defined cases [see Kahn's epic
work]. How many lives both-sides using cryptography saved is
intangible. I suspect the completely unreal situation of all-sides
having open communications would have saved a truly huge number of
 I honnestly believed you had been done over by D. Vulis there

@_date: 1998-06-20 11:40:35
@_author: Julian Assange 
@_subject: AUcrypto mailinglist 
With things starting to heat up here in Australia (DoD/DSD has
recently taken to making some exceptionally nasty noises about
prosecuting Eric Young, Tim Hudson and the rest of the Australian
CryptoMozilla team). I'd like to remind everyone who's interested in
aussie/nz crypto issues of the aucrypto mailing list.
                    _   _   _  ____ ______   ______ _____ ___
                   / \ | | | |/ ___|  _ \ \ / /  _ \_   _/ _ \
                  / _ \| | | | |   | |_) \ V /| |_) || || | | |
                 / ___ \ |_| | |___|  _ < | | |  __/ | || |_| |
                /_/   \_\___/ \____|_| \_\|_| |_|    |_| \___/
                      Australasian & Pacific Cryptography
               mail the word "subscribe" to aucrypto-request
                                     or
              mail the word "subscribe" to aucrypto-d-request
                            (AUCRYPTO weekly digest)
WHEN YOU HAVE SUBSCRIBED
    Send in a brief synopsis of who you are and why you are interested
    in AUCRYPTO as your first message to the list (this helps
    to stimulate discussion and debate as well as provide a sense
    of the AUCRYPTO community). As a [small] example:
      "Hello AUCRYPTO! My name is Sara Harding. I'm a technical services
       officer working at the AFP (Australian Federal Police), specialising
       in cryptogrpahic issues."
Send mail to:
        aucrypto-request
        aucrypto-d-request (AUCRYPTO digest)
with the subject or body of:
        subscribe
Send mail to:
        aucrypto-request
        aucrypto-d-request (AUCRYPTO digest)
with the subject or body of:
        unsubscribe aucrypto
To send a message to the list, address it to:
        aucrypto
Messages under 700 bytes in size will not be accepted. Send your
one-liners to nobody
If you are replying to a message already on the AUCRYPTO list using
your mail programs reply facility you may have to change the reply
address to aucrypto This is because the AUCRYPTO mailing
list program is configured to have return replies sent the author
in order to avoid receiving the replies of misconfigured "vacation"
programs which automatically send email saying "I've gone to the
moon for two weeks to hunt rare bits".
Monthly back issues of aucrypto since January 96 are available from:
        ftp://suburbia.net/pub/mailinglists/aucrypto
You can also instruct the mailing list processor to automatically scan and
retrive messages from the archive. It understands the following commands:
        get filename ...
        ls directory ...
        egrep case_insensitive_regular_expression filename ...
        maxfiles nnn
        version
        Aliases for 'get': send, sendme, getme, gimme, retrieve, mail
        Aliases for 'ls': dir, directory, list, show
        Aliases for 'egrep': search, grep, fgrep, find
        Lines starting with a ' are ignored.
        Multiple commands per mail are allowed.
        Setting maxfiles to zero will remove the limit (to protect you against
        yourself no more than maxfiles files will be returned per request).
        Egrep supports most common flags.
        Examples:
        ls vomume96 (for aucrypto digest)
        ls latest (the latest directory containes the archived messages)
        get latest/12
        egrep some.word latest/*
The list processor software is based on the excellent Procmail/Smartlist
by Stephen R. van den Berg  with
some minor extensions by Julian Assange .

@_date: 1998-09-10 05:10:42
@_author: Julian Assange 
@_subject: cypherpunks archive 
I'm looking for a/the cypherpunks archive, particularly one that
covers 92-present. infinity.nus.sg doesn't seem to work anymore.
