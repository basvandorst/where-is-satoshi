
@_date: 1993-05-21 18:26:06
@_author: Mark Edward Zimmerman 
@_subject: Godelization, sf, etc. (was: Re: cypto + compression) 
the sf story that you're alluding to is, I believe, Fred Pohl's "Gold
at the Starbow's End" --- a cover story in ANALOG magazine ca. 1968
--- which I remember fondly precisely because of the idea used which
you mention, namely, encoding a big message compactly as the sum of
various powers of small numbers ...  though the author got it pretty
badly wrong, as I pointed out in a letter published some months later
in the same magazine --- the sum of powers that he gave in the story
was *much* too small to hold a significant amount of information, and
(worse) he thought that one couldn't get any of the answer without
writing the entire number --- obviously wrong, as a little modular
arithmetic can get out the powers quite easily....  but it's a nice
idea and the story was quite good otherwise.... :-) ^z

@_date: 1993-06-06 04:51:32
@_author: Mark Edward Zimmerman 
@_subject: random access into an encrypted file? 
I'm enjoying the discussion of encrypting file systems, but have a
perhaps-naive question: can the methods recently proposed here work
for fast "random" access of bytes from the middle of a possibly-large
Specifically, over the years I have written some free-text
information-retrieval programs which build complete inverted indices
to every word in a chosen text file (which may be many megabytes long,
limited by disk space, not by RAM) --- and in order to fetch and
display text quickly from an arbitrary point in the file, my programs
do a lot of fseek() operations.  If a file is encrypted under various
schemes, I wonder how long it would take to fetch byte 100,000,000?
Could it cause me some performance problems?  :-)
Just thought I'd raise the issue....  BTW, if anybody wants to work
with large text files, the stuff I've done is all free under GNU GPL;
for nicest user interface, see Mac version which hides behind
HyperCard (in INFO-MAC archive at sumex-aim.stanford.edu, under
directory info-mac/card with a name beginning "freetext", I think).
Generic command-line C code to build indices is "qndxr.c" in various
archives, and the generic command-line browser is "brwsr.c".  See
description in THE DIGITAL WORD, eds. Landow & Delany, MIT Press,
1993, pps. 53-68, for more details.  Briefly, the programs let you
scroll around in alphabetized word lists, generate key-word-in-context
displays and do simple proximity filtering, and retrieve chunks of
text on demand, very fast.  Index-building is 15-20 MB/hour on an
older Mac II-class machine, 60-80 MB/hour on a Sparcstation, etc.
Best,  ^z  (no relation!)
