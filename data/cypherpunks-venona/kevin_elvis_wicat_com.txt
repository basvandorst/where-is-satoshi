
@_date: 1995-01-26 09:26:14
@_author: unknown_name 
@_subject: MixMaster remailer source 
A little while back when the "remailer crisis" discussion was in
full swing, L. McCarthy recommended the Mixmaster remailer as being the
most modern. After several days of hunting, I have utterly failed to
turn up the source to this remailer. Can anyone provide me a pointer?
    On a slightly related note, is there a validation suite for PGP? The
MIT distribution does not include OS/2 binaries, unfortunately, but I
have managed to get a clean build. It seems to work, but I simply don't
know enough about PGP to be sure that it really is a fully working
    Kevin
    At Intel, quality is job 0.999731.

@_date: 1995-01-31 13:53:01
@_author: I will address the implementation of this later 
@_subject: Frothing remailers - an immodest proposal 
It seems to me that the current remailer web suffers a fundamental flaw.
It is simply too static. When a remailer disappears, service is
disrupted and messages are lost. Humans have to statically route their
messages through the web either by hand or using relatively primitive
tools such as the chain script (not to belittle the useful work that has
been done, but it is by no means idiot proof yet). Basically, the
current web of mailers shows nothing of the dynamic nature that has kept
the internet alive and has offered us a decent chance at truly anonymous
communications, nor is it easy to use to its full potential.
Consider a more dynamic web of remailers. I envision remailers that
actively advertise their presence on the web so that all active
remailers are aware of all other active remailers. This advertising is
to have very low latency so that a new mailer can be known to the web
within minutes (I will address the implementation of this later). Thus,
remailers can constantly be appearing and disappearing without impact on
the web as a whole (I refer to this dynamic web of remailers as a
"froth"). Imagine also that remailers are allowed to dynamically perform
the routing functions that are currently done statically offline (for
reasons I will discuss shortly).
Now, given all this, what do we gain? First, consider my situation
(which is what started me on this line of thinking); my company has a
leased 56K internet link. I cannot consume this valuable bandwidth with
a remailer during business hours. However, if remailers could pop up and
announce their presence to the web, I could run a transient remailer for
several hours in the wee hours of the morning when the line use is
Another benefit would be the possibility of remailers with no fixed
physical location. A remailer can shift from host machine to host
machine daily, as long as there is a decent mechanism to locate it.
The use of such transient routers implies allowing dynamic routing. If
any given remailer may go down or move at any point, it is impractical
to expect users to keep track of which are up at the moment and create
static routes in the current manner. The only reasonable solution I have
come up with is to allow the remailers themselves to choose routing,
given that they have full knowledge of the current state of the froth.
This also confers additional benefits. It has been pointed out that most
traffic across the web is currently unencrypted. It seems to me that any
such message should be fair game. The remailer should be allowed to
encrypt the message and pick a pseudo-random path through the web,
incorporating transient remailers along the way. This adds greatly to
the encrypted traffic on the net, as well as making sure that the
transient remailers are used. It even provides some degree of privacy to
originally non-encrypted messages.
We could of course still allow users to statically route their messages
through the web, or allow combinations (I want this message routed
through remailers A and B to endpoint C; however, remailers are granted
authority to route this message through a maximum of three additional,
randomly chosen remailers between each step). This has the added
advantage of taking the work of routing messages off the user (unless
they really want it). Think about the proposed extension to MixMaster to
allow separate parts of a multi-part message to be routed separately,
and consider whether you really want to have to do this by hand. I
strongly suspect that most messages are currently routed via boilerplate
scripts, which has to make the job of traffic analysis much easier for
our good friend Eve.
By the way, a brief rant on a related topic; people speak of not
trusting remailers any further than necessary, while I am clearly
suggesting granting more authority and trust to the remailers. This
notion of not assigning trust is simply nonsense. When you send a piece
of mail to a remailer, encrypted or not, you are assigning complete
trust in that remailer to keep you anonymous and not to forward your
mail to the NSA immediately.
This does lead to a related problem, however; if we allow remailers to
pop up at random and join in the froth, how do we know that Deitweiller
won't set up a number of black hole remailers that take your mail and
throw it away, disrupting the froth, or forward it to nphard
Fortunately, we already have the PGP web of trust model in place and can
use it to good effect in this case. Remailers should simply not route
mail through any remailer whose public key is not trusted unless
explicitly ordered otherwise. This requires remailer operators to
cooperate to some extent to validate one another's remailer keys, but
does confer the great advantage of portable remailers as mentioned
above; if I run a trusted remailer on one machine, I can move it to
another machine, and as soon as I advertise the new address and the PGP
public key, it is a trusted and useful part of the froth.
While we are advertising a PGP key and internet address, we might as
well incorporate other useful information. For instance, remailers could
advertise their maximum latency. This would allow us to send messages
into the froth with the instructions "Keep this message moving for at
least one hour and at most three hours and then deliver to endpoint C"
and allow remailers to make informed decisions about routing this
message (there are some interesting issues in making routing decisions;
if we can assign a cost to the link between each pair of remailers, do
we want to attempt to optimize the route for least cost? Or stick with
random routing to attempt to hinder traffic analysis?). I'm sure that we
can come up with other useful information to assist routing decisions
(available bandwidth, cost per letter, protocols supported, etc.)
Now, the question of implementing remailer advertising. If there is an
existing internet protocol for advertising entities with sufficiently
low latency, I am not aware of it (my background is in Novell and OS/2,
so I'll happily be corrected!) DNS is the closest model to what I want,
but is excessively tied up in bureaucracy and has horrific propagation
times. Thus, we will have to roll our own.
I can think of two reasonable solutions to this problem. The first is a
central authority model: there exist well known servers that each
remailer has to report into when starting up and shutting down. This
model has obvious benefits (ease of use and implementation, minimal
bandwidth usage) and obvious drawbacks (a single point of failure, or at
best very few, distinctly against the cypherpunk philosophy, requires
high-bandwidth, stable servers (read expensive)).
The second solution involves a broadcast model; each remailer
periodically broadcasts its presence to the entire net (say every T
minutes). Any process wanting a full list of all remailers simply has to
monitor the broadcast channel for T minutes to get at least a good
approximation. The problem here is one of delay (to locate a remailer, I
might have to wait T minutes) and bandwidth choking. Obviously, spamming
the entire internet with UDP packets advertising remailers would earn us
no friends (I'm not even sure that it's technically feasible). What we
need is a net of machines to carry the broadcast messages with numerous
well known access points.
By happy coincidence, there exists just such a network (actually,
several of them) that we can subvert for our twisted purposes. It's
called IRC. We can create a dedicated channel that carries the remailer
broadcast messages (to be honest, I have no real idea how to do this, but
one of the wonderHackers out there surely does? otherwise I might
actually be forced to read the RFCs (oh horror!)). I doubt that any
remailer operator will have trouble finding an IRC host to attach to in
order to monitor the broadcasts.
This is obviously a stopgap solution, but provides a method for
jumpstarting the froth without requiring a froth to advertise the froth.
With regard to the bandwidth concerns, I can't imagine that less
than a hundred remailers generating <1K messages every few minutes
(about ten minutes feels like a good value for T) can bring IRC to its
knees. When we get more than a hundred or so remailers up, we'll worry
about bandwidth!
And to the inherent latency problem of the broadcast model, the easiest
solution is to have well known servers cache the advertising information
for immediate access. Not too coincidentally, these caching servers look
a lot like the central point of authority servers in the first solution.
Thus, we can have both the convenience of a central authority model with
the dependable broadcast model to fall back on if it becomes necessary.
Unsolved problem, by the way: it would obviously be nice to have
human-readable names for remailers (the PGP key becomes the true unique
identifier, but I'd much rather pick "Soda remailer" from a list than
four lines of armored ASCII). How can we guarantee unique names and/or
prevent problems resulting from collisions?
Obviously, this process hasn't reached more than the pipe-dream stage
yet. I am very interested in comments and proposals before I start
trying to create some trial implementations. Be gentle, though - it's my
first time.
    Kevin

@_date: 1995-02-01 15:23:59
@_author: posted from a backwater site in Sweden 
@_subject: Re: Fundamental Question? 
Consider the incoming directory on my local news host:
jlc:/usr/spool/news/in.coming$ ls -l
total 401
-rw-r--r--   1 news     news       172237 Feb  1 16:08 21705-000000.t
drwxr-xr-x   2 news     news         1024 Jan 31 13:43 bad/
-rw-r--r--   1 news     news        79792 Jan 27 12:35 nntp.a00606
-rw-r--r--   1 news     news       130025 Feb  1 16:09 nntp.a21731
drwxr-xr-x   2 news     news        21504 Jan 21 12:57 save/
-rwxr-xr-x   1 news     news          194 Nov 30 14:22 unz*
jlc:/usr/spool/news/in.coming$ grep Date 21705-000000.t | more
The majority of incoming messages are two days old (this was on Feb 1 at
16:10, GMT -7); the worst instance in this particular batch was six days
old (posted from a backwater site in Sweden).
Before you object that this is obviously a poorly-connected site, we're
on a leased 56K line two hops from the backbone (we're fed by BYU, who
is in turn fed by the University of Utah, one of the original four
internet sites and as well fed as you get). Our server is keeping up
with the incoming news. I suspect this is a pretty typical scenario.
    Kevin

@_date: 1995-02-01 15:48:30
@_author: perhaps within certain GMT hours or dates 
@_subject: Re: Frothing remailers - an immodest proposal 
Aye, there lies the rub. How exactly does one determine if a site is
active or generate a current list of active sites? It is not enough to
ping the site or even to successfulyl deliver mail to it: the fact that
something is alive and running sendmail does not make it a remailer.
Likewise, a remailer cannot select an alternate site on behalf of the
user if the routing is chosen by the user, as each "envelope" is
encrypted specifically for a given remailer. I suppose one could develop
client software that built several redundant "envelopes" for alternate
mailers, but that would get out of hand pretty quickly, both in terms of
the effort of generating a secure message and in term of the size of a
Scripting is useful (hell, the ::Request-Remailing lines are effectively
a script) but not until there is data to operate on.
Not a bad idea, actually.
    Kevin

@_date: 1995-02-01 16:17:20
@_author: on some other thread 
@_subject: Re: Frothing remailers - an immodest proposal 
True, but this has two basic assumptions that I disagree with: first,
that we can guarantee delivery of a broadcast message to all interested
sites; and second, that remailers never go down for unexpected reasons.
When the day comes that both networks and software are perfect, this
method will be reliable. Of course, you are also right that broadcasting
is undesirable; that is why I am pondering a way to minimize the impact.
But, if my understanding of remailer operation is correct, this has two
potential problems: first, I will still receive mail during the day,
causing a bandwidth concern (I know, it's probably not a problem right
now, particularly since users will probably choose to avoid a remailer
with a possible 16 hour delay); and second, the machine delivering mail
to me simply has to trust that a remailer will in fact pop up on this
machine to process the stored mail. There is no way of determining that
mail is not simply going into a black hole. And even if I try to be nice
when the mailer goes down permanently and tell everyone not to route
mail through it any more, that news still has to travel via word of
mouth to all users of the web.
I am not happy with my proposed advertising methods, and was quietly
hoping for some guidance from internet gurus in this point (the irc
suggestion in particular is a pretty shaky straw man). However, see my
earlier message (on some other thread) about Usenet propagation times.
Propagation times in days do not seem to be rare (post to misc.test and
see when the last reply comes back). While this is better than
word-of-mouth propagation, it does not offer the very low latency I was
looking for.
It strikes me as critical; right now, a user has to choose to trust a
set of remailers, given no assistance other than a list of "reliable"
ones. Given an extended web of trust between remailers, the user can
choose to trust one remailer (I have no idea how to make this process
more palatable) and immediately gain the security of a large web of
remailers (maybe you are right about that instant gratification
    Kevin

@_date: 1995-02-01 17:00:38
@_author: e.g. which remailers are in operation at this moment 
@_subject: Re:  Frothing remailers - an immodest proposal 
Firstly, I certainly do not propose that we remove user-supplied
chaining; it is obviously vital to true anonyminity. What I am
suggesting is that we allow remailers to introduce more noise into the
mix using information that users cannot easily obtain for themselves
(e.g. which remailers are in operation at this moment). In the
apparently common case of unencrypted messages crossing the net, this is
at least no worse than the current situation. Of course, we would also
have to allow users to specify that no munging of the route be allowed
(some form of scripting). Trusting remailers to obey this request
requires no more trust than we already place in them (which, I believe,
is considerably more than most seem willing to admit).
If you succumb to the temptation and trust remailer  totally, then you
of course run the risk of sacrificing anonyminity. However, if you do
not trust remailer  so completely and specify a chain of remailers,
but allow remailer-generated routing between the points on that chain,
you gain resistance to traffic analysis as well as making it possible
for smaller transient remailers to play a useful role.
I don't see what would prevent this from happening now. The only degree
of cooperation I require from remailer operators is that they agree on
some software standards and that, if they choose, they create extended
webs of trust via signing one another's keys. There is no requirement
that all remailers or remailer operators trust all other remailer
operators; in fact, I think this would be undesirable, even if the trust
were justified.
Again, remember that control lies with the user. If you choose, you can
allow a remailer to bounce your mail through its web of trust before
forwarding it to the next point on your chain. I do not believe that
this increases the risk of losing anonyminity. I do also propose that
this be the default behavior in order to provide naive users with some
degree of security, as well as using their traffic to obscure that of
more sophisticated users.
True, all true (I seem to be saying this a lot today). My transient
remailer problem can be solved by publishing the times of availability
(assuming, of course, that my remailer will always be up when
scheduled). My only serious objection to this is that there will always
be more clients with more operating systems and platforms than there
will be servers. I don't expect that it will be easy to create new
standards for remailers and get significant numbers of operators to
implement or use them, but I do believe that that task is easier than
making smart clients available on all possible platforms.
[ Safe-TCL comments deleted]
This is a fine suggestion; as I mentioned in an earlier message,
scripting is not useful without data to operate on. You have suggested a
number of data that a remailer could usefully provide to a message,
making scripting more useful. Of course, you have to trust that the
remailer is not lying to your script.
[ More Safe-TCL comments and a plea for smarter clients rather than
smarter servers, to which I reply with the earlier argument, deleted.]
    Kevin

@_date: 1995-02-01 17:18:11
@_author: legal 
@_subject: Re: Frothing remailers - an immodest proposal 
First, I must admit to being somewhat out of my depth here; this seems
to be becoming a philosophical problem. With that shameful admission out
of the way, let me bull ahead regardless.
It seems to me that I can choose to trust in the fact that *your* trust
in other remailers is well founded. This then becomes a third category
of trust for a given remailer: trust that it will deliver (verifiable);
trust that it will be silent (unverifiable); and trust that its
operator has good judgement in choosing who to trust (unverifiable).
These latter two are, and should be, the end users responsibility.
Now, as I have mentioned in an earlier message (I'm being far too
verbose today) I am proposing that dynamic routing be optional, though
the default behavior, for reasons mentioned there. Thus, if I, as user,
choose to allow dynamic routing (through omission - I must admit, I am
becoming less fond of the notion of this as default behavior - it begins
to smack of the heresy of "implied consent") I am expressing the third
flavor of trust, just as by using the remailer at all, I am expressing
the second variety.
Of course, I still have to trust that a remailer will honor my routing
requests. However, I believe this falls fair and square into the second
category (trust in silence)
    Kevin
    ( I have no joke here, I just like saying "I trust a remailer if
      it is trusted by an entity I trust to trust remailers".)
