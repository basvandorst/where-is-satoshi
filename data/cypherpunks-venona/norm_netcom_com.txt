
@_date: 1992-12-04 15:51:08
@_author: Norman Hardy 
@_subject: Re: digital banking 
As I understand Chaum's Digi-Cash scheme the bank customer is protected both against bank fraud and merchant fraud but not against collusion between the two. The customer need not be unknown to the bank in order that her purchases with bank notes be unknown to the bank. This is where blind bank signatures come in. Neither need the merchant be unknown to the bank. Remailers are unnecessary to hide connection between the merchant and his customers. The bank knows both but has no way to associate them.
This being the case, the bank customer is protected against a false denial of deposit. When one deposits Digi-Cash in a bank he presumably waits for an indication from the bank that the cash was still valid (not previously deposited). The customer retains this indication as a receipt which is signed by a private bank key. A bank's positive reputation is useful but not necessary at this Another concern is the false denial of payment by the merchant. If the merchant's customer is willing to reveal to a judge that she paid the merchant, and she retained the note with which she paid, and the bank retains a record of the merchant's deposits then she can argue that it was she that caused the bank to mint the note since only the person for whom the note was minted and the merchant who had cashed it (and the bank) should know its bits. This would require that the bank respond to the judicial query "has bank customer M deposited note x?".

@_date: 1993-01-09 17:52:25
@_author: Norman Hardy 
@_subject: Politics of Rmailers 
If your mail system is broken enough that it inserts signatures without
  your permission, and you have no way to controlling it, it's broken.
  End of statement.  Fix it or ditch it.  I can imagine a system administrator choosing to require that
all mail originating from his machine include a signature that correctly identifies the local name of the sender.
I make this special point to illustrate a broader problem with
remailers: They require operators of remailers to be sympathetic
with the ends of the users of remailers. This obviously does not
include the entire population for at least the recipient is not
sympathetic. I suspect that technical solutions sought in recent
mail will founder in presence of the politics of the operators
of the remailers. I understand that routing your message thru
at least one "friendly" remailer may be enough but if your reasons
for using remailers are not sufficiently popular, then society,
in some form, will pressure the friendly remailers to betray
the sender without advance warning.
If society polarizes into camps then there may be remailers in
each camp. A remailer in one camp is unlikely to service messages
from the other. Barriers then arise. I think that the technical
issues are only the tip of the iceberg.

@_date: 1993-04-11 00:18:32
@_author: Norman Hardy 
@_subject: Re: REMAIL: cypherpunks strategy 
I just got around to Greg Broiles interesting note where he describes
his practice of using several account names. He feels apologetic about it.
Authors have used pen-names for a long time without opprobrium.
The mathematician Eric Temple Bell wrote science fiction under the pen name
"John Taine". Several authors have written different styles of works,
one pen name per style. As I understand the law there is nothing illegal
in using an alias as long as the purpose is not fraud, which is already
illegal. One must protect the reputation of each alias.
Where aliases are common negative reputations loose their bite but the
benefits of positive reputations provide incentives for good behavior.

@_date: 1993-04-12 10:54:32
@_author: Norman Hardy 
@_subject: Trusting PGP 
At last I have read the operating instructions for PGP 2.2. I am impressed. I raised the issue of trusting PGP. John Draper correctly suggested that it was possible to trust PGP because the code was available for inspection.   I agree that this places PGP far ahead of various competition regarding trust. I propose, however, that if there were a single specification that covered various file formats and perhaps program logic, that PGP would eventually gain substantially more trust. Here is why.
As it is now, someone who reads the code to establish his trust in PGP must be familiar with C, in which PGP is written, number theory and various crypto threats and weaknesses. There are certainly such people. If, however, there were one operating specification then many more people would be attracted to the effort, ultimately yielding greater trust in PGP. Cryptographers without the skill or tenacity to read the code could contribute, as could programmers without the crypto theory. Each class would consult the specs, the programmers to verify that the code implemented the specs and the cryptographers to ponder whether programs with such specs were appropriate for their market.
Such specifications are required for government rated secure software for just this reason.

@_date: 1993-04-19 01:31:45
@_author: Norman Hardy 
@_subject: Hellman's Hints 
I presume that Hellman meant to say             "K1 and K2, and thence UK"
in place of "K1 and K2, and thence K" at least it makes sense that way.
A later posting from Hellman (I think) emmended the description
of the transmitted message from
    E{ E[M; K], E[K; UK], serial number; SK}
to  E[M; K], E{ E[K; UK], serial number; SK}
If you know SK then you can compute (E[K; UK], serial number)
Then knowing UK (= K1+K2) you can compute K
from which you get M via E[M; K].

@_date: 1993-04-20 14:45:48
@_author: Norman Hardy 
@_subject: Webs of Trust vs Trees of Trust 
I have worked with the NCSC (National Computer Security Center)
on certifying operating systems according to the "Orange Book".
As I understand RIPEM there is a tree of agencies such that everyone
must trust all elements of the tree between him and the root.
This is much ingrained in all of the legally mandated security
systems that I am aware of. It assumes, at first glance, that there
is a root, an inner sanctum, which is totally trusted by all.
The Orange Book for operating system security has such assumptions
embedded deeply. We had to essentially weeken our security features
by disableing our "mutually supicious user" logic to meet their
It is a pervasive mind-set in military security.

@_date: 1993-04-20 15:46:00
@_author: Norman Hardy 
@_subject: Webs of Trust vs Trees of Trust 
I have worked with the NCSC (National Computer Security Center)
on certifying operating systems according to the "Orange Book".
As I understand RIPEM there is a tree of agencies such that everyone
must trust all elements of the tree between him and the root.
This is much ingrained in all of the legally mandated security
systems that I am aware of. It assumes, at first glance, that there
is a root, an inner sanctum, which is totally trusted by all.
The Orange Book for operating system security has such assumptions
embedded deeply. We had to essentially weeken our security features
by disableing our "mutually supicious user" logic to meet their
It is a pervasive mind-set in military security.

@_date: 1993-04-20 17:08:25
@_author: Norman Hardy 
@_subject: Anonymous Remailers, WB etc. 
If I were chartered to be prepared to find the source
of anonymous mail, and had the money, attitude and
resources that skeptics among us assume are available
for such efforts, here is how I would proceed. This plan
is due, in part, to my experience in building secure operating
I would catalog the various weaknesses of Unix and perhaps
other systems where the remailers live.
I would make a list of remailers and suspected remailers.
I would design programs that would inhabit the remailer machines
benignly except for gathering information that I need.
Such efforts are a natural by product of the public NCSC charter
to know OS weaknesses.
I would further examine the IP protocols for weaknesses.
Those protocols trust not only the machines thru which the data flows but also trusts other machines on the net not to
introduce phony datagrams that at least bolix legitimate
traffic and may well spoof it. This is aided by a real time
passive tap on the links carrying the legitimate traffic.
It is not the style of this group to study OS security and I don't
propose to change the style. OS security and protocol security may,
however, be an Achilles heel to anonymity.

@_date: 1993-04-22 21:40:43
@_author: Norman Hardy 
@_subject: If strong crypto were illegal 
Curriously the chip ostensibly makes it nearly impossible
for the government to prove that you are using strong crypto
on top of skipjack (Clipper).

@_date: 1993-04-22 21:40:55
@_author: Norman Hardy 
@_subject: If strong crypto were illegal 
Curriously the chip ostensibly makes it nearly impossible
for the government to prove that you are using strong crypto
on top of skipjack (Clipper).
I suppose that the a govenrment agency could use a trap-door
to discover that plain text was not plain, then get a warrant,
then present evidence that you were using strong crypto.
Such might eventually lend credence to the belief that there
was a trap-door.

@_date: 1993-05-09 15:37:14
@_author: Norman Hardy 
@_subject: Early Battles 
I remember hearing an anecdote from a fairly private but unclassified
source. According to this source NSA was incensed when IBM first developed
Lucifer for banking applications, especially because they published
details in a Scientific American article. NSA accused IBM of stealing
secrets from NSA thru IBM employees having access to NSA technology as
part of their jobs developing hardware and software for NSA. IBM was of
course prepared for this eventuality. They quoted an early paper by Shannon suggesting that a mixture of transpositions and permutations would likely produce strong ciphers. This is, of course, the heart of both Lucifer and DES.
NSA backed off.

@_date: 1993-05-25 18:08:12
@_author: Norman Hardy 
@_subject: Steganography 
Here is a pitfall to be avoided in Steganography using
low bits of AD converter output. Such converters may be biased
in their low bit. If you hid 2,000,000 bits in a digitized image
you would probably get from 998,000 to 1,002,000 one bits
if you took no precautions. A real digitizer might well be
expected to produce more than
1,100,000 one bits or less than 900,000. Falling too close to
50% would be a clue that the data was not the yield of a
AD converter. Stuffing a few percent of extra one bits according
to a random number generator known to the receiver makes the
data look more typical.
There may be statictical dependencies with the next more
significant bit as well.
Some elementary statistics can be done on the yield of a real image scanner to examine this issue.

@_date: 1993-06-07 10:48:16
@_author: Norman Hardy 
@_subject: Re: CryptoStacker, long term vision 
When the Iranians took over the American Embassy in Teheran they,
acquired access to the machines there. Subsequently there was talk
of computer systems that were guaranteed to be volatile except for
ciphered disks. There would be an unciphered boot block on disk that
did not have the key to the rest of the disk but did have code
to read and decipher the rest of the operating system.
That key, however, would be in a safe place such as Washington DC.
The system could not be booted until
the key was available, presumably thru secure communications.
If you trusted the operating system to only use the key for reading
and writing the disk but not otherwise then pulling the plug made
the all data in the computer inaccessible baring action from

@_date: 1993-06-08 19:12:57
@_author: Norman Hardy 
@_subject: CERT netnews 
Netnews group "comp.security.announce" seems to be the product of CERT.
About once a week, on the average, they post something relating to
the security of some specific operating system. The few postings that
I have seen seem directed to the sys-op (typically Unix) regarding
some common practice with security implications or often holes in
the defaults that some system comes with.
What I have seen there is technical and not political.

@_date: 1993-07-08 08:08:55
@_author: Norman Hardy 
@_subject: DigiCash 
If someone is implementing Chaum's DigiCash I have some
input. Pleas send me e-mail.

@_date: 1993-07-16 16:36:56
@_author: Norman Hardy 
@_subject: Names and Reputations 
I'm having a philosophical problem regarding when to sign someone
    else's public key.
It strikes me that while a public key may be properly associated with
someone that you know by sight it may more generally be associated
with an abstract reputation. Connecting a face to a public key may
be less useful than connecting a public key with someone that
I recognize by reputation. I don't know Stephen Wolff by sight
but I do know him by reputation and have conversed with
him by e-mail. If during these conversations we had exchanged
public keys, even thru insecure channels, then that would be
more reliable than exchanging keys with someone that I met
in person who claimed to be Steve Wolff but with whom I did not
have time to converse. Steve's reputation with me arose thru a book
he wrote. If he had included his private key there it would be
better yet. (Public keys had not been invented then.)
Having been influenced by Steve's book I would be inclined to
accept Steve's opinions in related areas, if they were signed
by his private key. I need not know what Steve looks like!
In CyberSpace it ultimately seems that the public key supplants
ordinary names and all reputations are connected to public keys!

@_date: 1993-07-16 21:03:15
@_author: Norman Hardy 
@_subject: Re: Names and Reputations 
That is a good point too. Perhaps the laws and practices of Notary Publics
may serve for one degree of assurance. They commonly need to know who
is asking them to notarize something such as a will. I don't remember
how they do this.
I suppose that a Notary public should have a published public key that
she uses like her seal.

@_date: 1993-07-17 14:14:47
@_author: Norman Hardy 
@_subject: Diffie Hellman 
What is the best reference to the Diffie Hellman key
exchange algorithm? (Preferably on line)

@_date: 1993-07-18 09:59:58
@_author: Norman Hardy 
@_subject: Diffie-Hellman Weakness Weakness 
It has been mentioned several places that the Diffie-Hellman key exchange
algorithm is subject to the man-in-the-meddle attack. There is
a weakness in the attack that I understand. I suppose that
the attack goes as follows where I am the man in the middle:
I am able to install an active wire tap that allows me to substitute the
data traveling in either direction. I have a fast computer to help me.
I want to conceal my activity but learn what transpires.
Upon receiving signals to begin DH protocol I respond to each side separatly
"lets go". I establish a secret session key with each side. I am unable to
cause the two keys to be equal except by passing the b^x going one way and b^y
going the other. In this case I know neither x or y and can't read the traffic.
I must choose my own random numbers zx and zy and replace b^x with b^zx and
b^y with b^zy. X and Y now enter secure mode with the secret keys b^(x*zy)
between me and X and b^(zx*y) between me and Y. I can read the traffic.
If the connection is digitized voice and if X should happen to mention the
low ten bits of b^zy to Y then Y would notice the discrepency since Y knows
that he sent b^y. The jig is up. I don't know how to do voice recognition
so as to intercept the vocal quotation of b^zy and change it to a quotation
of b^y in a way that Y would not notice. I would have to simulate X's
Curiously there seems to be no analog of this precaution for digital DH
communicators. If there is a secret protocol for comparing b^y over the
nominally secured channel then there may as well have been a secret key
in the first place. If there is a public protocol for comparing b^y then
I can follow that protocol my self.

@_date: 1993-07-27 23:36:32
@_author: Norman Hardy 
@_subject: Digital Silk Road 
This is the stuff that Dean Tribble and I talked about at
a couple of Saturday Cypherpunk meetings in Calif.
While it has nothing directly to do with crypto it is an
architecture that avoids central control and thus has
an anarchical flavor.
Let me know if you can't use either RTF or PostScript
or cant do FTP.
Abstract: of The Digital Silk Road
Existing and proposed mechanisms for digital money all require large overhead
to transfer money between parties. This overhead makes them unsuitable for
extremely low cost activities such as delivering and routing packets.
We propose a money system with extremely low transaction cost built into the
communication protocols. The money introduced by this system is much more
like coins than like bank accounts; it supports only small transactions,
requires limited trust among the participants, and requires no central bank.
With this as a foundation, we then describe elements of an open system that
fully supports network resource management, routing, interconnection with
the Internet, and so forth, across trust boundaries with competing providers
for all services. This supports a style of informal information commerce.
This paper is available thru anonymous ftp at
netcom.com:pub/joule/DSR1.ps.gz and DSR1.rtf.gz.
The file format, .rtf, (Rich Text Fotmat) can be read by many different
word processors including those from Microsoft, MacWrite II,
and some Unix systems. I will produce other formats with a bit of pressure.

@_date: 1993-07-28 23:12:02
@_author: Norman Hardy 
@_subject: Re: Digital Silk Road 
The "gunzip" command expands .gz files on some Unix systems.
I hear that some ftp systems magically do it for you but
I can't confirm that.
If none of that works let me know.

@_date: 1993-07-29 12:37:14
@_author: Norman Hardy 
@_subject: Digital Silk Road 
There is a flat ASCII version of the paper at anonymous ftp:
   netcom.com:pub/Silk/DSR1.txt
It will soon move to
   netcom.com:pub/joule/DSR1.txt

@_date: 1993-07-29 18:12:27
@_author: Norman Hardy 
@_subject: Digital Silk Road (Yet once more) 
Sorry for the bad permission bits.
There is a flat ASCII version of the paper by anonymous ftp:
   netcom.com:pub/Silk/DSR1.txt
It will soon move to
   netcom.com:pub/joule/DSR1.txt
It is also available by anonymous ftp at
netcom.com:/pub/joule/DSR1.ps.gz and netcom.com:/pub/joule/DSR1.rtf.gz

@_date: 1993-08-02 07:41:29
@_author: Norman Hardy 
@_subject: ftp access to the Silk Road Paper 
The Digital Silk road paper is now availnle in three forms at
netcom.com:pub/joule/DSR1.ps.gz, DSR1.rtf.gz and DSR1.txt
netcom.com may sometimes be too busy and then direct you to one of several other machines any of which can access the files.

@_date: 1993-08-06 11:15:13
@_author: Norman Hardy 
@_subject: NSA and Trust Webs 
While US military security models are thoroughly hierarchical
I imagine that when NSA deals with foreign countries regarding ciphers
used to communicate between governments and regarding mutual foes it too
uses a web of trust more Byzantine than most amateurs dream of.

@_date: 1993-08-11 13:07:22
@_author: Norman Hardy 
@_subject: Re: Software Patent Institute 
I am interested in the issue of patenting ideas that have
already been put into practice or that would be obvious
to any of many practitioners. I have a patent and my
patent attorney included in the ideas that were not
new. We were not motivated to spend the time and money
to revise the patent to avoid this. The patent examiner
had little experience in programming and missed the
old ideas.
I would be curious to know what software patents exist
and the outcome of any court fights to overturn patents
on ideas that were indeed not new.
I am not good a keeping track of publications where I
have learned of ideas but I often do know people who were
using various ideas going back to 1955 when I began
programming professionally.
I do not know very much about patent law but I understand that
IBM, for instance, regularly publishes "Technical Disclosures"
which is mostly comprised of the work products of IBM patent attorneys
when they have decided that it is not worth the expense of
patenting some particular idea.
It would be good to have a public repository of programming ideas
that are good but not worth patenting.
Let me know how I can help.

@_date: 1993-08-11 14:37:23
@_author: Norman Hardy 
@_subject: Re: Secure voice software issues 
Can someone tell me how fast CELP is when written in C?
(On some particular machine.)

@_date: 1993-08-11 23:32:44
@_author: Norman Hardy 
@_subject: Re: Secure voice software issues 
Eric Blossom  says:
I have been reading the PowerPC 601 manual (MPC601, The Macs of early
1994). It is dangerous to
believe performance figures. They give you the world in one chapter and then take it back here and there in bits and pieces.
Here is what I see however. Simple single precision floating point
operations can issue one per cycle. The book mentions several
floating point ops that take more than one clock in a pipeline stage.
They don't mention floating multiply-add. I think one can issue each
clock. I-unit instructions can issue in the same clock as floating
point ops. If you do the block trick used to multiply matrices then
one load is required per multiply add. All this leads to the optimistic
estimate that the 50MHz machine can sustain nearly 50 fmadd's per
microsecond on a 50MHz chip. Inner products are much like matrix multiply
which is a benchmark where the RS/6000 (The MPC601's father) achieved
nearly one fmadd per clock, and that was double precision!
128 excitation vectors each of 60 single precision loats fit in the on
chip cache, but it is tight.
There may be enough margin here for it to work with no special DSP.
I'll be in Yosemite for a few days so I won't be able to respond
immediately to comments.

@_date: 1993-08-26 12:07:32
@_author: Norman Hardy 
@_subject: Re: Source Code NOT available for ViaCrypt PGP 
The proper paranoid must worry whether the licenced PGP
does what it is supposed to do. One can
compare the output of the ViaCrypt PGP with that of
the current version. Discrepencies would merit great
suspicion and perhaps disassembly. Improper paranoids
might be comforted in the knowledge that many proper
paranoids were comparing the two versions.
I have not studied the format of the PGP output.
Is it possible for the ViaCrypt PGP to interoperate
with the current version unless it comforms completely?
We must clearly worry about undocumented new formats.
Incedently why do the code owners trust the customer
to not illegitamitely copy the binary program,
but not trust the customer
to not illegitamitely copy the source program?

@_date: 1993-08-26 14:42:34
@_author: Norman Hardy 
@_subject: Re: Source Code NOT available for ViaCrypt PGP 
Regarding Secret key generation.
cme (Carl Ellison) says:
I presume this is true.
I include a Scheme program that finds the first
prime in an arithmetic sequence. It uses a function published in Knuth.
You can either study my program or compare its output with some program
written by someone else to the same spec. If people are interested
I will annotate the code and its output better. As it is now
the prime that it finds is the last number that it outputs before it stops.
Curiously it has a probability of error which is large for small numbers
but exceedingly small for large numbers, just the opposite of human testers.
I claim that this is a good specification for choosing your secret primes.
It has a slight advantage over merely finding the first prime beyond some
specified number because that tends to find primes that follow long runs of
composites. It just now (as I edited this) found the prime 1000000000000000
as the first prime in the sequence 10^80+11*n. I typed (scan (expt 10 80) 11)
to the interpreter to get this. It took several minutes.
I used MacGambit on a 68030.
The output theoretically depends on the hokey random number generator here
but if two implementations yield different answers due to different random
number generators Knuth and others would be very interested!
For use in real RSA application we should include a function that hashes
typed in text into a bignum. A good hash of long text is a very good
random number! It need not be a crypto hash!
(define (ex x)(write x)x)
(define (rand31 seed) (lambda()(let* ((hi (quotient seed 127773))
(lo (- seed (* 127773 hi)))(test (- (* 16807 lo) (* 2836 hi))))
(set! seed (if (> test 0) test (+ test 2147483647))) seed)))
(define (gbrand max seed)(let* ((rq (rand31 seed))
  (nq (let v ((c max)(n 0))(if (< c (expt 2 31))
   (cons (let w ((cx c)(nx 1))(if (< cx 2) nx (w (quotient cx 2)(+ nx 1))))n)
  (v (quotient c (expt 2 31))(+ n 1)))))
  (z (car nq))(n (cdr nq))(k (+ (* 31 n) z)))
(write(list max k z n))
; max, k, n, z, L and m are non-negative integers.
; 2^(k-1)<=max<2^k. k=31*n+z. 0= a P) (j (modulo a P) P)
   (if (even? a) (let((q (j (/ a 2) P))
   (m (modulo P 8))) (if (or (= m 3)(= m 5))(- q) q))
   (let((q (j (modulo P a) a)))
   (if(or (= (modulo P 4) 1) (= (modulo a 4) 1)) q (- q)))))))
(define (mod-exp b p m)(cond ((= p 0) 1)
   ((even? p)(let ((x (mod-exp b (/ p 2) m)))(modulo (* x x)m)))
   ( (modulo (* b (mod-exp b (- p 1) m)) m))))
; The following is by Solovay & Strassen as presented in Knuth page 396.
(define (p-test a P)(if(zero? a)(cdr 2))(and (odd? P) (= (gcd a P) 1)
   (zero? (modulo (- (j a P)(mod-exp a (/(- P 1) 2) P)) P))))
(quote "The function scan below returns the first prime in the")
(quote "arithmetic sequence a + n*b")
(define (scan a b)(let* ((g (gcd a b))(n (modulo b 210))
  (random (gbrand (+ a (if (positive? b) 0 (* 2000 b))) 228765))
  (probe (+ 1 (random))))
   (if (> g 1) (list "Always divisible by" g)
     (let more ((a1 a)(m (modulo a 210))(cn 0))
    (if (and (let all ((l (list 2 3 5 7)))(or (null? l)
      (and (positive? (remainder m (car l))) (all (cdr l)))))
        (let all ((l 20)(p probe)) (or (zero? l)
          (and (ww cn (pt p a1))
      (all (- l 1)(+ 1 (random)))))))
      a1
      (begin (display ",")(more (+ a1 b)(modulo (+ m n) 210)(+ cn 1))))))))
(define (pc wx) (let zz ((q (- wx 1))(s 0))(if (zero? q) s
   (zz (- q 1)(+ (if (p-test q wx) 1 0) s)))))
; The following prmality test is from second edition of
; volume 2 of Knuth's "The Art of Computer Programming",
; page 379.
(define (pt x n) (or (= n 2)
   (let* ((pr (let z ((q (- n 1))(k 0))(if (odd? q)(cons q k)
               (z (quotient q 2)(+ k 1)))))
          (q (car pr))(k (cdr pr))(nm1 (- n 1)))
   (let lp ((j 0)(y (mod-exp x q n)))
       (or (and (= j 0)(= y 1)) (= y nm1)
       (and (< (+ j 1) k)(lp (+ j 1)(modulo (* y y) n))))))))
 ; 10^100-797, 10^200-189, 10^299-171, 10^300-69 are prime.
 ~.
 ~.

@_date: 1993-08-26 14:57:34
@_author: Norman Hardy 
@_subject: Re: Commercial PGP: Verifying Trustworthiness 
At least the Commercial PGP is not tamper proof and examination can,
in principle, discover the backdoor. After discovery it would
impossible to deny.

@_date: 1993-08-26 15:15:49
@_author: Norman Hardy 
@_subject: Re: Commercial PGP: Verifying Trustworthiness 
peter honeyman  says:
This means that I am trusting the "pseudo-random" stuff not to be
some secrets that PGP has read from my disk. The only benefit
that I see to the pseudo-random stuff is to send the same message
to several people without revealing the fact that the messages are
the same except to those that can decode the messages.

@_date: 1993-08-26 19:15:51
@_author: Norman Hardy 
@_subject: Re: Commercial PGP: Verifying Trustworthiness 
Forwarding for cdodhner (Christian D. Odhner)
I could very well be wrong about this one, but since pgp uses a random
idea session key each time you encrypt, wouldn't that in fact ensure that
no two encryptions of the same file with the same public key are ever the
same? Why then would random stuff be needed? Happy Hunting, -Chris
PGP public key available upon request.

@_date: 1993-08-26 19:22:37
@_author: Norman Hardy 
@_subject: Re: Commercial PGP: Verifying Trustworthiness 
cdodhner (Christian D. Odhner) says:
I knew that! I forgot that! Thanks for reminding me. Back to the drawing board!
A protocol where the user controlled the session key would be more awkward
but would solve that problem. On the otherhand that isn't the PGP protocol.

@_date: 1993-09-05 08:46:00
@_author: Norman Hardy 
@_subject: Remailer Reliability 
sameer (Sameer Parekh) says:
There was a paper sometime back (10 years I would guess) called
"Sharing Secrets". For any j and k such that 0 pairs. The secret was the
value of f(x) for yet another public value of x. The paper described
how to do this in finite fields.

@_date: 1993-09-13 13:13:43
@_author: Norman Hardy 
@_subject: Re: Stegno and DAT and digital music... 
The DAT coding is 16 bit fixed point. The lowest bit always has
the same value which is nearly 90 db below the loudest sound.
This is perceptible when it is the only signal as is demonstrated in CD demonstrator disks. A steganographer might merely not put
data in quiet passages. Alternatively he could plausibly claim that
it was caused by a gentle breeze outside the recording studio. In the
later case he should add some noise to the next to bottom bit,
or generate and add some -85 db white noise and then replace the
bottom bit.

@_date: 1993-09-16 16:34:47
@_author: Norman Hardy 
@_subject: Abstract: of The Digital Silk Road 
Existing and proposed mechanisms for digital money all require large overhead
to transfer money between parties. This overhead makes them unsuitable for
extremely low cost activities such as delivering and routing packets.
We propose a money system with extremely low transaction cost built into the
communication protocols. The money introduced by this system is much more
like coins than like bank accounts; it supports only small transactions,
requires limited trust among the participants, and requires no central bank.
With this as a foundation, we then describe elements of an open system that
fully supports network resource management, routing, interconnection with
the Internet, and other information services, across trust boundaries with
competing providers for all services. This supports a style of informal
information commerce.
To appear in "Agoric Systems: Market Based Computation",
edited by Wm. Tulloh, Mark S. Miller and Don Lavoie.
A draft of this paper is available thru anonymous ftp at
netcom.com:pub/joule/DSR1.ps.gz, DSR1.rtf and DSR1.txt.
The file format, .rtf, (Rich Text Fotmat) can be read by many different
word processors including those from Microsoft, MacWrite II,
and some Unix systems. I will produce other formats with a bit of pressure.

@_date: 1993-09-16 18:19:24
@_author: Norman Hardy 
@_subject: How to use cipher programs without trusting them. 
The shortest summary of all this is that cipher program should be
deterministic and written to a public spec so that they may be checked
short of the hazardous task of reading code.
This may be quixotic but that has never stopped me. I propose here a way
to choose secret random numbers and random primes without having
to trust a single program exclusively. Suppose that you want to choose a
random n bit number. You type text while trying to make it random in some
subjective sense. The text accepts only space and letters and ignores all
else. The text is interpreted as a base 53 number and reduced modulo 2^n.
Note that 53 and 2^n are relatively prime. Experiments have shown that
this type of "typewriter random" produces about one or two bits of
information per character depending on the typist. This assumes an unspecified
form of information compression which I do not recall. It did, however,
look for patterns that were specific to people trying to type random
characters at a keyboard. One caution: if choosing random numbers this way
becomes routine one falls into habits that makes the numbers no longer
Different programs can easily be written according to such a standard and
their results compared. The skeptic runs two or three programs and
compares the output. After a few trials it may be reasonable to trust
one of the programs. A natural adjunct of such a program is a prime tester
that seeks primes in some arithmetic sequence. The sequence is chosen
according to published rules from keyboard selected random numbers.
I hear that PGP pads messages with random information in order to thwart
known plaintext attacks. This is wise but the paranoid wonders how
the random information is selected. The padding prevents output from two
programs from being compared for compliance.
Some will argue that if the cipher program were malicious it could stash
your secrets somewhere on your disk that was destined for export for
reasons unrelated to ciphering. The SoftPC story below indicates that
there are problems even when the cipher program is programmed to spec.
I know of operating systems where cipher programs may be installed so as
not to have the authority to stash your secrets away. I don't know
whether such operating systems will ever see commercial use.
There are several problems with keyboard timing. The first that I saw
mentioned arises when running such a program on SoftPC which is a clever
program to execute programs designed for IBM PCs on the Macintosh. The clock
appears not to run (I think the story is) and while the random numbers
look impressive they depend only on the number of keystrokes and nothing else!
There is much more technology such as SoftPC coming down the pike.

@_date: 1993-10-22 11:12:56
@_author: Norman Hardy 
@_subject: Re: Paper Shredders 
The garbage disposal in a kitchen sink is very effective.

@_date: 1993-10-25 14:53:23
@_author: Norman Hardy 
@_subject: Shamir Sharing 
The following code may be useful in applications to share secrets a la
Shamir. Beware the warning about pseudo random numbers!
 0
Shamir Sharing
Warning!! We use the stock random number generator.
You must replace it if you really want to keep a secret!!
67 is prime and 67^4>2^24. We use the field of integers modulo 67.
We want to produce k<67 versions of a secret so that we may
reconstruct the message when q (0 and libraries
in some systems claiming to be ANSI C!
typedef struct{long quot, rem;} ldiv_t;
static ldiv_t ldiv(long a, long b)
{ldiv_t A; A.quot = a/b; A.rem = a % b; return A;}
 N 67
   typedef unsigned long u25 /* 32 bits */;
static char mt[N][N], dt[N][N];
static void it(void){int i, j;
  for(i=0; i= (u25)N*N*N*N) printf("Foul value\n");
 if(quor > dis || dis >= N)
   printf("Committee size must not exceed distribution and "
      "distribution must be less than N\n");
 {ldiv_t A = ldiv(sec, N), B = ldiv(A.quot, N), C = ldiv(B.quot, N);
  char a[4]; a[3] = A.rem; a[2] = B.rem; a[1] = C.rem; a[0] = C.quot;
  {int k; for(k = 0; k<4; ++k)
   {char coef[N-1]; coef[0] = a[k];    {int m; for(m = 1; m=0; --m)
       q = M(coef[m] + mt[q][n] - N);
       w[n-1][k] = q;}}}}}}
 C 4
int main(){it();
if (0) {int i, j; for(i=0; i<N; ++i) for(j=0; j<N; ++j)
   if(mt[i][dt[j][i]] != j)
     printf("Ouch, %d, %d\n", i, j);}
{char dx[12][4]; split((u25)12345678, C, 8, dx);
 {int i, j; for(i=0; i<8; ++i)
   {printf("%2d ", i+1);
   for (j=0; j<4; ++j) printf("%c", '0' + dx[i][j]); printf("\n");}}
{int q[C] = {8, 3, 7, 1}; char dz[C][4]; {int i, j;
   for(i=0; i<C; ++i) for(j=0; j<4; ++j) dz[i][j] = dx[q[i]-1][j];}
 printf("%ld\n", join(C, dz, q));}}}

@_date: 1993-10-25 16:13:32
@_author: Norman Hardy 
@_subject: Error in Shamir sharing 
Please substitute 'rand()' for '22'. '22' was an artifact of debugging!
Get the full copy by ftp at

@_date: 1993-10-28 22:08:17
@_author: Norman Hardy 
@_subject: ViaCrypt PGP 
Congratulations and good luck. I have a Mac and will not be buying
you PC version. I might well buy a Mac version especially at the $99
introductory price. I hope you send me e-mail when you have a Mac
I am impressed with PGP and would be willing to pay for a "legal"
version. I have no important secrets but may still buy the program as
a matter of principle.
I have a couple of (free) ideas you may be interested in.
(Consider this a customer request if there are any lawyers about.)
As I understand PGP, it generates random numbers by timing keystrokes
for at least two purposes, first to avoid known plain text and second
to choose large primes for the RSA key. If there were an option to
generate those random numbers by a published mapping from input
text then the following benefits would accrue:
The paranoid could compare the output of your program with others written
to the same spec to gain assurance that programs operated to spec. This
is especially critical in key generation. I would propose that the spec
would be to choose the prime from among an arithmetic sequence A+Bn
where A and B are derived from the input text.
The paranoid would know that the cipher text contained no covert or subliminal
Both of these benefits would accrue without having to read the code for either
of the systems compared. It would need to assume no collusion to achieve this
Some paranoids would see the threat of exposure as sufficientreason to
trust the program.
Another advantage is that I could run your PC version on my Mac using SoftPC.
I understand that PGP does not get random keystroke timing under SoftPC.
Yet another advantage would be to those who wish to keep their private key
in their head. This would require remembering and correctly typing about
1000 characters at each computer sesion. An optional text checksum would thus
be strategic and not compromise security.
I understand that the quality of keyed data may be poor. Shannon estimated
that such data could provide about one bit of information per character.
It might be difficult to provide a sufficient warning to users unfamilliar
with information theory on the dangers of known or guessed sayings as input
text. Unlike some cryptographic applications weekness in the random
numbers does not induce sudeen failure. The effort in breaking a public
key declines slowly with declining quality in the random numbers.
Keystroke timing may well be the best default however.

@_date: 1993-11-17 13:01:17
@_author: Norman Hardy 
@_subject: Re: Should we oppose the Data Superhighway/NII? 
de Sola Pool's book 'Technologies of Freedom' gives an excellent
description of issues of monoloplies and their motivations.
He describes a scheme that I think was adopted in Boston.
The scheme was to grant a cable monolopy but require the
cable owner to lease half of the cable capacity to a
competitor at some prespecified price. There was thus
competition between suppliers of programs.
The arguments for a natural monopoly were accommodated
(Space on the phone pole, cost of laying cable)
and yet competition was achieved.
That was one of the few books that I have read that actually
changed some of my opinions on economics.
The author described why rational, non corrupt regulators
might grant such a monopoly. He did not imply that such monopolies
were not corrupt.

@_date: 1993-12-22 22:15:46
@_author: Norman Hardy 
@_subject: Hut six 
"Hut Six" by Welchman seems to be out of print.
The book describes early Bletchley Park work
on the German Enigma cypher system.
Does anyone know where to get a copy?

@_date: 1994-01-14 18:15:47
@_author: Norman Hardy 
@_subject: Re: why govt's get bigger 
Any sucessful biological entity acts in its own self interest. It need not
be logical or concious. The libertarian would call the governement a
parasite. The book Bionomics by Rothchild examines this anology in detail.

@_date: 1994-01-18 14:58:47
@_author: Norman Hardy 
@_subject: Re: RSA Questions 
Laudable Paranoia!
In short the numbers: cipher, decipher, plain, d and e must all be
relatively prime to p and q for all of this stuff to work. In practice,
since p and q are very large, the probability of the cryptanalyst finding
another value d that deciphers your message is about the same as him
finding p or q. That is the same probability of him factoring pq by
guessing. In your example 138 out of 996980 is about the probability of
being divisible by either p or q. You might check to make sure that the
message that you are enciphering is relatively prime to p and q. You could
better spend your, however, verifying that your hardware had not made a
mistake, which is more likely, unless, however you are sending one of your
factors so that a friend can share your secret key. In that case, however,
anyone with your public key can compute your secret key,

@_date: 1994-01-20 14:54:24
@_author: Norman Hardy 
@_subject: Re: APPLIED CRYPTOGRAPHY - Index 
...etc. ...
Thanks for the index. You probably sold another book here.

@_date: 1994-01-22 19:46:27
@_author: Norman Hardy 
@_subject: Re: Where can I get RFC-822? 
If you can use ftp then the following is the root of all RFC's:
For anonymous ftp, please use host ftp.nisc.sri.com:rfc/rfc882.txt

@_date: 1994-01-22 20:26:29
@_author: Norman Hardy 
@_subject: Re: Remailers: The Next Generation 
Perhaps the following nested headers might be more cost-effective to
quantizing message length:
Pad-Me-By: 3289   (Add 3289 random bytes to the end of this message)
Truncate-Me-To: 1433  (Remove all but the first 1433 byte of this message.)
The message would then change size as it traveled thru the mixes.

@_date: 1994-02-08 08:06:46
@_author: Norman Hardy 
@_subject: Magic Money ftp 
Is there somewhere that I can ftp the Magic Money protocol from?

@_date: 1994-02-15 18:09:34
@_author: Norman Hardy 
@_subject: Re:  Clipper and Traffic Analysis 
If Public switches are made 'tap ready' then such a map may easily be made
and kept up to date without human erffort.

@_date: 1994-02-15 18:39:47
@_author: Norman Hardy 
@_subject: Re: cypherpunks meeting in Mt. View last weekend. 
At 18:52 2/15/94 -0500, wcs
That was "Chip Morningstar", not "Chip Rosenthal".

@_date: 1994-02-16 13:45:13
@_author: Norman Hardy 
@_subject: Re: 
ATM = Asynchronous Transfer Mode. This is a switched service running at at
least 155 Mb/sec using optical fiber. 600Mb are expected to follow not much
later. A single strand to customer premises provides that bandwidth full
duplex. The strand provides for many multiplexed virtual circuits a bit
like X.25 except that it will probably be priced according to a bandwidth
selected at call setup and you will be prevented from exceeding that rate
during the call. This service should be sufficient for video. Simillar
technologies are being built for local LANs where each computer has a full
duplex 155 Mb potential instead of the aggregate 10Mb provided by Ethernet.

@_date: 1994-02-18 12:01:03
@_author: Norman Hardy 
@_subject: Re: REAL WORLD ENCRYPTION 
Perhaps you can sell your technology to government witness protection
programs. Perhaps you could even sell your service if you could prove that
only the money was at risk (and not the location of users).

@_date: 1994-02-26 09:56:09
@_author: Norman Hardy 
@_subject: Re: Infomercial 
I don't encrypt my stuff but I gain much peace of mind when I know that I
could. This suggests that I should encrypt in order to maintain that right.

@_date: 1994-02-28 21:23:12
@_author: Norman Hardy 
@_subject: Re: standard for steganography? 
Has anyone done statistical studies of low bits of pixels or sound samples?
I suspect that they are often far from random. A flat 50% distribution in
the low bits might standout like a sore thumb. I can imagine the the low
bit can be distributed dependently on such things as the next to low bits
or 60 cycle power at the recorder. Some AD converters are known to produce
60% ones or some such.  Like mechanical typewriters, AD systems probably
have there own idiosyncrasies. Given a flat stream of cipher data, there
are techniques to reversably introduce such variations to mimic the biases
of real AD converters without much data expansion.
It is my wild guess and conjecture that with such statistical variation
built in there would be no effective statistical test for a given file
containing hidden messages.

@_date: 1994-03-01 00:17:41
@_author: Norman Hardy 
@_subject: Re: standard for steganography? 
'AD converter' = 'Analog to Digital converter'.
Here are three schemes each with flaws:
Consider an alphabet of 10 bit characters with a probability distribution
such that each bit has an expected value of .6 (instead of the normal .5).
The character 000000000 has a probability of .4^10 = .000105 and
p(1111111111) = .6^10 = .006046. Do a Huffman encoding on this alphabet.
000000000 codes as 13 bits and 1111111111 codes as 7 bits. Take the cipher
stream and execute the Huffman decode(!) operation on the cipher stream.
Out comes a sequence of 10 bit bytes with 60% ones. To retrieve the
original cipher stream execute the normal Huffman coding algorithm and get
the original stream. The flaw here is that Huffman assigns some probability
to each of the 10 bit characters which is 2^-7, 2^-8, ... 2^-13.  The
intermediate probabilities are not represented. This would show up without
too much data.
Another scheme is called 'arithmetic coding'. It avoids the above
probability quantization but is tricky to program. I can't find a reference
to it just now but it should appear in any modern book in information
theory. Unlike Huffman it does not code each character into a definite
number of bits but codes a sequence of several characters into a 'real
number'. Adapting this to numbers that real computers can use is tricky.
Again you feed the flat cipher stream into the decoding end of the
algorithm and get biased bits.
The above two schemes are information efficient. With a 60% bias you get
97% efficiency. If you are willing to settle for 80% efficiency you can
merely establish a RNG synchronized at sender and receiver that sends a bit
from the cipher stream with probability .8 and sends a one with probability

@_date: 1994-03-06 16:34:06
@_author: Norman Hardy 
@_subject: Format of PGP ciphered message 
Is there any specification of the format of a PGP enciphered message short
of the program itself?

@_date: 1994-04-03 10:20:54
@_author: Norman Hardy 
@_subject: Re: Web of Trust? 
Ideally, perhaps in cyberspace, one's public key is spread along with X's
reputation, i.e. thru the same channels. When a reputation for X reaches
you so does X's public key. You say that you want Henry Kissinger's public
key. I respond that by whatever means you know that there exists such a
person, you will (in cyberspace) already know his public key. The logical
limit of this idea is that the public key becomes the name and the key
authentication issue dissolves into the mist.
We trust reputations because they reach us thru diverse paths. Public keys
arriving thru diverse paths should likewise carry extra weight.
As crypto becomes more common reputations will eventually belong more to
public keys than to names. The question will then be not "What is Henry's
public key?" but "What is the name of the person who knows the secret key
that corresponds to this public key?". I suppose that Detwiler feared being
unable to answer that question in specific cases. I don't.
In the meantime, redundant webs that parallel the normal information webs
thru which reputations propagate should provide public keys at least as
reliable as the reputations themselves.
One particular case is of interest. If you contract with me to process some
of your secrets, I will agree not to divulge those secrets except under the
protection of a one of a set of public keys that you give me. In such a
case the web of trust model can be usefully employed and is not
intrinsically limited in the number of levels.

@_date: 1994-04-07 16:11:53
@_author: Norman Hardy 
@_subject: RE: Pseudonyms and Reputations 
Only those others whose reputation for taste in giving endorsements you
have come to trust.

@_date: 1994-04-10 16:03:04
@_author: Norman Hardy 
@_subject: Zero Knowledge, Hamiltonian Cycles, and Passwords 
Page 85 in Schneier's "Applied Cryptography" begins a good introduction to
zero knowledge proofs and such.

@_date: 1994-04-24 17:25:06
@_author: Norman Hardy 
@_subject: Re: Warrentlesss SEarches (fwd) 
Thanks for your perspective. I have imagined that if I found it necessary
to live in such a place that I might favor choosing a building with some
sort of covenant, explicitly agreed to by all tenants, that allowed
searches for weapons. I take it that you would not find that to be a good
idea. Do you have other ideas along such lines?

@_date: 1994-05-09 23:48:33
@_author: Norman Hardy 
@_subject: Re: Patents on RSA will expire soon.... 
The algorithm that factored RSA129 takes about exp(sqrt((log n)(log log
n))) steps.
Indeed 10^17 instructions is just about how much work was required to
factor RSA129--.
That formula gives about 10^29 for a 1024 bit number. If computers double
in speed every 18 months then they will be only 32 times as fast when the
patents expire.

@_date: 1994-05-10 00:06:02
@_author: Norman Hardy 
@_subject: Re: This is an abstract from a talk at Cornell University... 
I recently saw a video tape of a talk by Feynman on quantum computers. It
was taped in '86 or '89 I think. It was his presentation of 'balistic'
quantum computers. In that talk he refered very briefly to the David Deutch
idea of the many worlds computer but was sceptical, but not entirely
dismissive of it.
In other comments Feynman seemed to think that the many worlds idea was not
very useful. It would certainly be useful if it helped design such a
computer. I would bet against it.

@_date: 1994-05-11 14:11:39
@_author: Norman Hardy 
@_subject: No Subject 
There was a long article in April 11, 1994 Forbes: "AUCTIONING THE
AIRWAYS", by George Gilder". It had a supprising amount of technical
information about a new technology similar to spread spectrum. The article
has a "too cheep to meter" flavor that I do not agree with but it does
present some interesting information and ideas.
It is about 43k bytes and is available via anonymous ftp at

@_date: 1994-05-11 21:53:21
@_author: Norman Hardy 
@_subject: Re: MIT TOC SEMINAR--ADI SHAMIR--MONDAY--MAY 16--4:15pm 
About 10  years ago there was a Scientific American article about visual
encypherment. The decoder required no computing hardware. A one time pad
was available at both ends in the form of an array of 1000 by 1000 random
black or white pixels in the form of a transparency. When it was time to
code a black and white image an array of pixels were produced with each
pixel being black with a probility proportional to the darkness at that
point of the 'plain-image'. That was exclusive ored with the one time pad.
This yielded a random set of black and white pixels and was transmitted
physically by insecure courrier. It it reached the destination it would
ideally be exclusive ored with the other copy of the one time pad. The
receiver could more easily align the cypher-image with the one time pad and
see a fairly good image. This yields the 'and' function in place of the
'xor' and provides about half of the image quality in the information
theortic sense.

@_date: 1994-05-16 23:08:52
@_author: Norman Hardy 
@_subject: Re: Rabin decryption 
Page 545 of Knuth's "Seminumerical Algorithms" gives a method of finding
the square root modulo a prime. It is efficient but non-trivial to program.
Incidently its worst case running time is as big as the number (actually
bigger) but its expected time is something like (nog n)^2.
My most recent errata list for Applied Cryptography does not amend page
289. I will mail you that list if you don't have it.

@_date: 1994-05-25 12:59:08
@_author: Norman Hardy 
@_subject: Re: Graph isomorphism based PK cryptosystems? 
I talked to a lawyer very recently about this. She does not specialize in
patent law but does deal with it. The situation is confusing and fluid.
Here is what I think I heard, ommiting occasional caveats:
If the patent office knows of prior art (as indicated in some publication)
it will not issue a patent. If it does not know then it may issue the
patent even if the art is well known outside the patent office. (Software
is very new to the PO.) When a patent is contested by virtue of duplicating
prior art the PO may admit that they goofed and invalidate part or all of
the patent. The PO doesn't like to do this. Litigation is the next step and
a judge decides if there was prior art. This is usually expensive. The case of the recent Compton multimedia (?) patent was so egregious that
the patent office said that they had goofed and would reconsider. I have
not seen the patent but the rumour is that there were few ideas that had
not been covered in Goodman's (?) book on Hypercard (?).  The book had been
out for while before the patent was granted (or submited, I think).

@_date: 1994-05-25 12:57:45
@_author: Norman Hardy 
@_subject: Re: Trust Models 
I agree to your condition and would be glad to look at your paper.
Trust issues are at the core of secure operating system design as well.

@_date: 1994-05-25 19:53:59
@_author: Norman Hardy 
@_subject: Re: Graph isomorphism based PK cryptosystems? 
I think that you are refering to IBM's "Technical Disclosures" publication.
Its entries are in the form of patents, presumably in less finished form.
They carry thru the process of writing up the patent, at least in rough form,
and then decide whether to go to the greater expense of patenting it.
If they decide not to patent it they publish it in Technical Disclosures.

@_date: 1994-06-05 17:01:15
@_author: Norman Hardy 
@_subject: Re: The Illogic of Clipper 
I think that NSA, FBI & CIA hope that Clipper will become a de facto
standard resulting from its being required for certain kinds of
interactions with government agencies. If this were to happen non-clipper
products would have a more difficult time attaining a critical mass. The
real purpose of Clipper can thus be stated as an attempt to prevent the
success of some de facto standard that the government could not tap. I
recall hearing someone from NSA say something very much like this.

@_date: 1994-06-12 16:18:57
@_author: Norman Hardy 
@_subject: Patent Numbers 
Does anyone have the US Patents numbers for Chaum's DigiCash scheme?

@_date: 1994-07-03 01:24:40
@_author: Norman Hardy 
@_subject: Re: Dr. Dobbs Dev. Update 1/5 July 94 & Schneier 
In C, {int j... if(j & (j-1)) not_exactly_one_bit; ...}

@_date: 1994-07-04 12:35:09
@_author: Norman Hardy 
@_subject: Re: Pass Phrases 
NSA must have an interesting collection of literature on line. They need
high bandwidth (but not rapid) access to it. This could be the beginning of
a new business if they ever turn their swords into plowshares. Conversely
if anyone aspires to digitize a great deal of literature I am sure that NSA
would subscribe, thus seeding a new industry. I seem to recall something
about a Midwest university beginning to digitize a large body of

@_date: 1994-07-04 12:35:10
@_author: Norman Hardy 
@_subject: Re: Remailers 
In the middle 70s, after Tymnet went international, I would occasionally
send a megabyte to our Paris computer in a proprietary compression format.
I do not believe that NSA spent the time to decode our format, although it
would been relatively easy for them to do so. I can only conclude that they
did not then have blanket surveillance in place, else they would have
contacted me. Both their capacity and international traffic have increased
many times. I suspect that I could do the same now.

@_date: 1994-07-09 20:52:33
@_author: Norman Hardy 
@_subject: Re: (fwd) Re: BSD random() - any good (source included)? 
A good RNG must pass all such tests. The idea of just one test is itself
dangerous. It would be a generous person who would collect such tests and
organize them to a common interface. Only then would you begin to have "one
test": the collection of these tests.
I coded a blum filter a few years ago which requires about 16,000 random
bits. I tried several prngs in various libraries, then implemented several
from literature including Knuth. All of these caused the filter to work at
about half efficiency. I could find no bugs in the filter code. Then I
recalled that there was a DES routine available. I used DES to generate the
random bits. The filter then worked close to the theoritical maximum!

@_date: 1994-07-14 00:29:34
@_author: Norman Hardy 
@_subject: Re: Idle question... 
... Quoting someone else
How many have access to the masks?

@_date: 1994-07-20 22:35:15
@_author: Norman Hardy 
@_subject: Re: Triple encryption... 
DAT tape, not RAM, I think. At $5 per GB I get $5*10^11 to hold the info.
MITM requires a sort of this which requires roughly log(10^20) passes with
a favorable constant. This will wear out a bunch of DAT drives but that is
relatively minor. This is about an order of magnitude bigger than a project
that I considered once to find the optimal solution to the Rubics cube.

@_date: 1994-07-25 19:40:49
@_author: Norman Hardy 
@_subject: Re: Double DES calculations 
There may be more than one way that MITM (meet in the middle) may be used
to attack Double block cyphers. I assume the following attack. You know
some block of plain-text P and corresponding cypher text C. You believe
that C = E(k, E(j, P)) where E(k, p) is the encypherment of p with key k.
D(k, E(k, p)) = p. You need to find keys k and j. Classic MITM is to
produce a file A with records:  for each k, and file B with
records  for each j. Sort both A and B on the second field.
Pass over the sorted files looking for a record from file A whose second
field is the same as a record in file B.
To substantially shorten the ammount of tape used by a factor 2^n at the
expense of evaluating C and D 2^n more often do the following:
For m from 0 to 2^n-1 Do
  Produce file A with records:  for each k where
    (the right n bits of E(k, P)) = m. (discarding other records)
  Produce file B with records  for each j where
    (the right n bits of D(j, C)) = m
  Sort files A and B on second field.
  Pass over files looking for records from A that match records from b in the
  second field.
This is still a daunting job and evaluating its magnitide requires several
assumptions. The most obvious is the cost of evaluating C and D. Next is
the cost of reading and writing tape.

@_date: 1994-07-26 00:11:38
@_author: Norman Hardy 
@_subject: Re: CYPHERPUNKS TO THE RESCUE 
Sounds like an application for a "challenge-response" system. But that
would require transmission from garage unit to car unit.
If there were syncnronized clocks then the signal could be a function of
time so that the above replay would fail. That requires only a PRNG.
Both units could compute the next password from the same PRNG but this
would require a "backspace" button on the car unit for those occasions
where the garage unit failed to hear a broadcast signal. A "reset to new
known state" for both units would be required for when the state became
hoplessly confused.

@_date: 1994-07-26 09:27:08
@_author: Norman Hardy 
@_subject: Re: CYPHERPUNKS TO THE RESCUE 
Seems good. But to thwart replay of the signed message the garage unit must
never accept the same signed number twice. How about the car unit signing
successive numbers. The garage unit would remember the last number that it
accepted and only accept signed numbers larger than that. Garbled
transmissions would then cause no problems. They would be fixed by yet new
transmissions, just as with current units.

@_date: 1994-07-26 09:37:56
@_author: Norman Hardy 
@_subject: Re: CYPHERPUNKS TO THE RESCUE 
Seems good. But to thwart replay of the signed message the garage unit must
never accept the same signed number twice. How about the car unit signing
successive numbers. The garage unit would remember the last number that it
accepted and only accept signed numbers larger than that. Garbled
transmissions would then cause no problems. They would be fixed by yet new
transmissions, just as with current units.
P.S. Better yet: There is no need of Public key technology. It suffices for
the car unit to send DES(k, n) on the nth transmission. k is a constant
secret key shared between car unit and garage unit. Garage unit decodes and
verifies that n is greater than it has seen before.

@_date: 1994-08-11 22:53:51
@_author: Norman Hardy 
@_subject: Re: IDEA vs DES 
The PowerPC floating point is even more impressive. The fmadd instruction
can do "a <- b*c+d" every other clock or 30 per microsecond on the low end
Power Mac. If we store 24 bits of a multiple precision number in successive
elements of an arrary then the inner loop of a multiply is a routine such
void m8(float * a, float * b, double * p)
{p[0] = a[0]*b[0];
p[1] = a[0]*b[1] + a[1]*b[0];
p[2] = a[0]*b[2] + a[1]*b[1] + a[2]*b[0];
p[3] = a[0]*b[3] + a[1]*b[2] + a[2]*b[1] + a[3]*b[0];
p[4] = a[0]*b[4] + a[1]*b[3] + a[2]*b[2] + a[3]*b[1] + a[4]*b[0];
p[5] = a[0]*b[5] + a[1]*b[4] + a[2]*b[3] + a[3]*b[2] + a[4]*b[1] + a[5]*b[0];
p[13] = a[6]*b[7] + a[7]*b[6];
p[14] = a[7]*b[7];}
The overhead consisting of loads and stores can largely be hidden since the
601 can issue both a floating point and fixed point instruction in a single
clock.  1000 bit numbers can thus be multiplied in (1000/24)^2
(1/30,000,000MHz) = 59 microseconds. The outer loop is also significant but
I would expect that it can be done in under 100 microseconds. Modular
exponentiation of 1000 bit numbers should take about 2*(1000/24)^3
(1/30,000,000MHz) = 2.5 ms without outer loop overhead.
The MPW compiler from Apple doesn't compile this code well and I may have
to write it in Assembler. The documentation that comes with MPW does not
discourage assembler and MPW (from Apple) includes a great assembler!
In another context I wrote some C code that compiles some optimized 601
machine code (to move pixels fast) and executes it. You don't need no
stinking assembler.

@_date: 1994-08-12 18:35:51
@_author: Norman Hardy 
@_subject: Re: IDEA vs DES 
This morning I said:
Sorry, I goofed! Thanks to Phil Karn for catching me on this. I omitted a
factor of 12 which is half of the number of bits in one of my "words". With
24 bits per word the 601 could do a 1000 bit by 1000 bit multiply in
(1000/24)^2 fmadd instructions, plus several times (1000/24) fixed point
instructions. The fmadd takes 2 clocks. Doing the modular multiply requires
about twice as much. Exponentiating by an n bit number requires about n/2
modular multiplies worst case. Doing mod(n^k, m) for 1000 bit numbers thus
requires about 2*2*(1000/24)^2*1000/2 clocks. For the slowest (60MHz) 601
this is 58ms.

@_date: 1994-08-14 21:36:55
@_author: Norman Hardy 
@_subject: Re: Secret sharing made short 
Obvious only in retorspect.
Elegant in any case.
Solving that problem had been at the back of my mind for several weeks.

@_date: 1994-08-28 09:56:04
@_author: Norman Hardy 
@_subject: Re: DSPs 
Modular reduction is scarcely worse than the multiplication. If I have a 60 word
multi precision number N to be reduced by a 30 word number M, I compute a guess
by dividing the 32 bit most significant bits N by the most significant 32
bits of M.
I then multiply this quotient by M and subtract that from N. That reduces N by
some multiple of M leaving N mod M unchanged. The error in the guess might
mean that N is less than 32 bits shorter than it was before the operation but
this method gets nearly 32 bits per pass. The inner loop of the is the same as
in multiplication.
For all of this using the floating point unit wins on most modern CPUs.

@_date: 1994-09-04 10:49:06
@_author: Norman Hardy 
@_subject: Force is not physical 
Can someone send me a copy of Eric Hughes Wednesday essay "Force is not
physical"? I somehow lost the machine version.

@_date: 1994-11-28 09:07:31
@_author: Norman Hardy 
@_subject: Re: Transparent Email (WAS disable telnet to port 25) 
If I have never sent you mail, consider how I got your e-mail address?
You could have sent your public key to me along with your e-mail address.
If your public key is too big you could include a phoneticized secure hash of
your public key and I could check big brother (the CA). I suspect that initial
bits of a public key serve pretty well as a secure hash. Perhaps all email
addresses should be accompanied by such a hash. The more initial bits
the harder to find a fake public key with sutiable mathematical properties
and initial bits that agree with your real pulic key.
If an email address and its associated PK are sent thru unauthenticated
channels a man in the middle can substitute the PK. In the same situation,
however, the man in the middle can substitute the email address!

@_date: 1994-11-28 23:54:48
@_author: Norman Hardy 
@_subject: How to not have to trust CAs 
I have been reading RFC1422 which describes the hierarchy of authorities
(CA = Certificate Authorities) proposed for distributing public keys for
PEM and such. One must trust the CA which is a leaf of this hierarchy. If
higher elements of the hierarchy are corrupted there is also danger but
perhaps it is less. One interesting thing that I learned is that RFC1422
specifically allows for "personas" as in pseudonyms. Their treatment of
CRLs (Certificate Revocation List) is most of the complexity and hard to
understand and implement. It is a hard problem.
Here is a different scheme that involves such a hierarchy but does not
require one to trust anyone in the hierarchy except concerning denial of
service. The scheme allows one to check the hierarchy. I ignore the
revocation problem in this note.
The idea stems from an idea that came from Belcore I think. The Belcore
idea posits a tree of nodes where each node holds the secure hash of each
of its children. The secure hash of the root node is published in the
Sunday New York Times and a few other places. There are weekly editions of
the tree. If I may want to prove to you in the future that some certain
piece of data exists this week, then I arrange to put a secure hash of that
data in some leaf of next weeks edition of the tree. If I should ever need
to present proof, I display the contents of each of the nodes between my
leaf and the root. (I got that list a few days after I submitted my secure
hash.) You can compute the hashes of each node and observe that they each
occur in the superior node. You compare the secure hash of the root node
with what is in the Times. The only plausible explanation is that someone
had the data  at the date of publication.
My CA scheme is a variation of the above. A certificate is a (name --
public key) pair. The names are stored in a tree in alphabetical order.
Each node in the tree holds a pair (first name in child node, secure hash
of child node) for each of its children. (This is much like a B-tree.)
The tree is available thru an untrusted CA. When you request the public key
from the CA corresponding to some name, all nodes from the leaf with that
name, thru the root are returned. You verify the secure hashes as in the
Belcore scheme. You also verify that name stuff in the intermediate nodes
is correct. The later is to prevent the CA from showing one public key to
some requesters and another key to others.
My secure mail agent queries the data base upon each new edition to ensure
that my own public key is reported correctly. (Besides being published in
the Times, the hash of the top node is transmitted once per minute in video
blank time on NBC.) Since the data base can't tell different requesters
different things, the agent can be sure that all requesters will be
informed of my correct key.
I would prefer to change my public key at most once per month and then only
with a month's notice. This gives me time to verify that the CA is telling
the truth about my PK and warn correspondents otherwise. This avoids the
attack of the CA publishing a bogus public key to which it knows the
private key in order to decipher mail intended for me. In all, changing
public keys may be more dangerous than not!
This system still has several flaws. There is a single point of failure.
Failure is not immediately catastrophic as old keys can continue in use. If
you mistrust the CA you must inform your correspondents quickly, (via a
signed message). If there are several such hierarchies then each user with
a public key must subscribe to each lest one of the hierarchies lie about
his public key.
I think that revocation is better solved (easier code and smaller data) by
Blum filters but that is another story. The policy revocation problems are
still difficult.

@_date: 1994-12-06 11:40:52
@_author: Norman Hardy 
@_subject: MacPGP 
Does anyone know of a manual for the Mac PGP 2.6?  I can find the functions
that I need in the command line interface manual but then it is unclear how
to get excatly that function thru menu selections. The command R function
reads commands from a file. It is awkward and keeps warning you that it is
I can imagine writing such a manual but before I know the answers it would
be inaccurate and after I know the answers it would seem superflous.

@_date: 1994-12-18 23:21:09
@_author: Norman Hardy 
@_subject: MacPGP 
Now I have something nice to say about MacPGP: It can take its input and
output from the clip board. This makes it about half as much work as it was
before. Look in "Dialog Shortcuts" under the "Options" menu.

@_date: 1994-12-19 16:11:11
@_author: Norman Hardy 
@_subject: Re: IPSP 
I would very much like to see the IPSP stuff. I have searched several MB of
new and old mail and found no references to a source.

@_date: 1995-01-05 01:07:06
@_author: Norman Hardy 
@_subject: Re: another factoring thing. . . . 
I think that that kind of quantum computer is much less likely to be built
to impact RSA style crypto, than some revolutionary sort of factoring
algorithm. It is not clear whether the tolerances required for the quantum
computer can ever be met and it is not entirely clear if the quantum
principles are correct. I don't entirely rule it out however.

@_date: 1995-01-28 15:49:18
@_author: Norman Hardy 
@_subject: No Subject 
Protocols for a Data Bank
The purpose of a data bank is to store large bodies of information for long
periods of time. I suggest here some protocols and contracts for a data
bank and its customers. We then discuss risks, incentives and
stratification of the data storage industry. These ideas implicitly rely on
several types of cryptography-- public key, secure hash, symmetric ciphers
and blind signatures. To explain these technologies here would
substantially obscure the presentation for those who know of such things
and help very little for those who don't.
Here are several transactions that a data bank engages in.
Acquire data: A client anonymously sends a collection of data along with
funds sufficient to warrant the bank's holding the data for a few days and
computing its secure hash. The bank knows the data only by its secure hash.
Selling Hat Checks: The bank will sell a hat check to anyone who will pay a
negotiated price. The hat check specifies the secure hash of the data, the
penalty to be paid upon failure to produce the data, and the cost of
redeeming the data. The hat check is signed blindly by the bank and is a
bearer instrument. Any holder of a hat check can present the check along
with the redemption fee and demand the data. The data bank must then either
produce the data or pay the penalty to the holder of the hat check. A
particular hat check is canceled whenever the bank pays the penalty like a
spent Chaum DigiCash note. The bank can sell multiple hat checks for the
same data. Different hat checks for the same data may specify different
Sell a copy of an acquisition: Any one can request a piece of data
identified only by its secure hash. The bank is free to sell a copy of the
data to anyone with the secure hash. The bank sets the price.
Publish index: The bank can publish its list of hashes. (This makes data
hunters possible.)
Cancel a hat check: A holder of a hat check may sell it back to the bank at
a negotiated price thus releasing the bank from the threat of paying a
penalty in the future. This also allows the bank to retrieve the physical
storage where the data is stored if it is sure that it has not sold other
hat checks for the data.
The hat check may specify expiration dates, cancellation terms etc. The
bank is explicitly permitted to disseminate the data and may well do so to
lay-off risks. In this sense a data bank is like in insurance company that
spreads and shares risks. A hat check may be viewed as a life insurance
policy for the data.
Dividing trust may be done by agreeing on a notary. Upon redemption, for
instance, a trusted notary might examine the hat check, accept the payment
specified therein from the client, pass over the data on its way from the
bank to the client while computing the secure hash, and if the secure hash
matches that in the hat check, deliver the payment to the bank. The notary
need not have long term financial stability as must the bank.
Brokers may have an interface similar to a bank. They return baskets of hat
checks. This reduces the risk to the client that one of the data banks will
fail financially and be unable to pay the penalty. The broker need not be
financially stable.
Data Hunters can engage in knowing who has what data. Given a hash they can
tell you what banks have the data. This would presumably require a new
protocol with the bank. This might be the ultimate URL or URI server.
Inflation can damage incentives. Hat checks might be denominated in gold or
currency baskets or what ever.
RSA modulus size is critical for long term contacts. 2K bits of modulus or
more may be warranted.
I can imagine the Getty Museum digitizing its Rembrandts and storing the
results in a data bank. The data might be insured for $100,000,000. The
bank would disseminate the data to increase security and lower its risk.
The museum would probably encrypt the data and share the key and hash ala
Shamir for safe keeping. The museum would not share the hat check because
it wants to be the one paid upon default.
A data bank, or any other player, may find that keeping data profitable
beyond the point of any outstanding hat checks. It can make money by
supplying copies of the data in return for a fee plus secure hash. Indeed
new hat checks may be sold after the last had expired. Data banks thus have
an incentive to disseminate their list of holdings in the form of hashes,
as input to bounty hunters.
Design Considerations
It may seem strange that the data bank does is willing to sell data to who
ever will pay. I suggest that because it is so easy to encipher the data
and not have to trust the bank. You can distribute the key thru what ever
channels you transmit the secure hash of the data.
Note that bank clients are always anonymous. Data is never held for some
known person. Data may be held solely for speculation. The purpose of the
penalty is to motivate the bank to keep data for which there is no reason
to forecast sales revenue.
The Bank's State
Logically the bank can perform all of these transactions by merely keeping
the unordered set of acquisitions. It is practically necessary to index
these by their secure hash but this can be rebuilt on demand. It must keep
canceled hat checks lest it become liable to extra penalties. The bank need
not keep records of hat checks that it has sold unless it wants to know
when it can delete acquisitions. It may want to keep marketing information
to know when acquisitions are worth keeping merely to sell copies of.

@_date: 1995-01-28 21:11:45
@_author: Norman Hardy 
@_subject: Re: Protocols for a Data Bank 
You are right. I forgot that the blind signer knows nothing of what we
signs. The protocol requirements seem clear but I lack a protocol. I think
I have a fix but I will be more careful before I post.

@_date: 1995-01-29 09:15:38
@_author: Norman Hardy 
@_subject: Re: Protocols for a Data Bank 
This is a corrected version. I was wrong to suggest that the protocol was
similar to blinded signatures.
Protocols for a Data Bank
The purpose of a data bank is to store large bodies of information for long
periods of time. I suggest here some protocols and contracts for a data
bank and its customers. We then discuss risks, incentives and
stratification of the data storage industry.
Here are several transactions that a data bank engages in.
Acquire data: A client anonymously sends a collection of data along with
funds sufficient to warrant the bank's computing its secure hash and
holding the data for a few days. The bank knows the data only by its secure
Selling (Hat) Checks: The bank will sell a check to anyone who will pay a
negotiated price. The check specifies the secure hash of the data, the cost
of redeeming the data, and the penalty to be paid by the bank upon failure
to produce the data. A client proposes the details of a check as
follows: Send (SH(acquisition), redemption price, penalty, SH(Secret)) to
the bank along with a proposed price. 'Secret' is a secret random number
chosen by the client for this negotiation. If the bank agrees it signs and
trades the signed message for the proposed price, or it may propose another
price. The signed message is the check and is a bearer instrument.
Redeem data: Any holder of a check can present the check along with the
secret, the redemption fee and demand the data. The data bank must then
either produce the data or pay the penalty to the holder of the check. A
particular check is canceled whenever the bank pays the penalty like a
spent Chaum DigiCash note. The bank can sell multiple checks for the same
data. Different checks for the same data may specify different penalties.
Sell a copy of an acquisition: Any one can request a piece of data
identified only by its secure hash. The bank is free to sell a copy of the
data to anyone with the secure hash. The bank sets the price.
Publish index: The bank can publish its list of hashes. (This makes data
hunters possible.)
Cancel a check: A holder of a check may sell it back to the bank at a
negotiated price thus releasing the bank from the risk of paying a penalty
in the future. This also allows the bank to retrieve the physical storage
where the data is stored if it is sure that it has not sold other checks
for the data.
Checks may specify expiration dates, cancellation terms etc. The bank is
explicitly permitted to disseminate the data and may well do so to lay-off
and reduce risks. In this sense a data bank is like an insurance company
that spreads and shares risks. A check may be viewed as a life insurance
policy for the data.
Trust may be divided by agreeing on a notary. Upon redemption the bank
examines the check to see if it has been canceled. If it knows the Secret
which produced the SH(Secret) of the check, the check is canceled.
Otherwise a mutually trusted notary takes the check, accepts the redemption
payment specified therein from the client, passes over the data on its way
from the bank to the client while computing the secure hash. If the secure
hash matches that in the check the notary delivers the payment to the bank.
If the hash fails to match, the transaction is aborted and a penalty
transaction begins. The bank delivers the penalty to the notary and the
client delivers the secret to the notary. If the hash of the secret matches
that in the check then the notary delivers the secret to the bank
(canceling the check) and the penalty amount to the client. The notary need
not have long term financial stability as must the bank.
Brokers may have an interface similar to a bank. They return baskets of
checks. This reduces the risk to the client that one of the data banks will
fail financially and be unable to pay the penalty. The broker need not be
financially stable.
Data Hunters engage in knowing who has what data. Given a hash they can
tell you what banks have the data. This might be the ultimate URL or URI
Inflation can damage incentives. Checks might be denominated in gold or
currency baskets or what ever.
RSA modulus size is critical for long term contacts. 2K bits of modulus or
more may be warranted.
I can imagine the Getty Museum digitizing its Rembrandts and storing the
results in a data bank. The data might be insured for $10,000,000. The bank
would disseminate the data to increase security and lower its risk. The
museum would probably encrypt the data and share the key and hash ala
Shamir for safe keeping. The museum would not share the check because it
wants to be the one paid upon default.
A data bank, or any other player, may find that keeping data profitable
beyond the point of any outstanding checks. It can make money by selling
copies of the data. Data banks thus have an incentive to disseminate their
list of holdings in the form of hashes, to support data hunters.
Design Considerations
It may seem strange that the data bank does is willing to sell data to who
ever will pay. I suggest this because it is easy to encipher the data and
not have to trust the bank. You can distribute the key thru what ever
channels you transmit the secure hash of the data.
Note that bank clients are always anonymous. Data is never held for some
known person. Data may be held solely for speculation. The purpose of the
penalty is to motivate the bank to keep data for which there is no reason
to forecast sales revenue. Unlike Chaum bank notes, the issuance of a hat
check may be  associated with the redemption. The depositing of data and
hat check issuance, however, may be anonymous. Data redemption may be
anonymous but collecting a substantial penalty may be difficult to arrange
anonymously. Managing anonymous transactions is a difficult but orthogonal
The Bank's State
Logically the bank can perform all of these transactions by merely keeping
the unordered set of acquisitions. It is practically necessary to index
these by their secure hash but this can be rebuilt from the acquisitions
themselves. When it looses data it must keep canceled checks to avoid extra
penalties. The bank need not keep records of checks that it has sold unless
it wants to know when it can delete acquisitions. It may want to keep
marketing information to know when acquisitions are worth keeping merely to
sell copies of. The bank will need to keep records of the checks that it
issues for financial auditors (to satisfy owners of the bank.)

@_date: 1995-01-29 10:22:04
@_author: Norman Hardy 
@_subject: Re: Data Bank 
My second posting crossed in the mail with Eric's notes.
Yes, I was confused.  jpp had yet other valid objections.
I have a novel sense of cancelation in mind. The check is canceled by the
mere fact that the bank knows the Secret that produced the SH(Secret) in
the check. The bank need not acquire or maintain a signed check revocation.
This is sort of like Chaum's spent bills. This requires the client to trust
the bank during the penalty transaction or to require escrow service. I
have modified the original to describe this better.
Any bearer. Just as any bearer of a Chaum bill can spend it. Only he who
spends it first, can spend it. Disseminate your hat checks carefully. That
is another reason that Getty, in the example, holds the hat check
Good points. I anticipate more complex broker services here.
I like the idea of a penalty for delay in retrieving the data aside from
penalty for loosing the data. This may be strategic in the bank's arranging
for the storage and retrieval from other sites and banks.
Thanks. I will try to produce an emmended version thru ftp soon.

@_date: 1995-01-29 16:16:16
@_author: Norman Hardy 
@_subject: Data Bank Protocols 
See ftp://ftp.netcom.com/pub/Si/Silk/DataBank.txt
for updated proposal for DataBank protocols. I have addressed, to a degree,
points made by Eric, and corrected the blunders pointed out by
jpp I am glad to e-mail this to anyone for whom ftp is awkward.
Thanks all.

@_date: 1995-01-30 20:47:36
@_author: Norman Hardy 
@_subject: Re: ESP Unix encrypted session protocol software 
....>As for the alternatives, I think the picture is pretty bleak, to tell
There would be on a secure "multi-user, unattended server". They are not
easy to come by and they arn't really Unix. I don't get on my soap box very
often but I couldn't resist your execelent opportunity. I think that
security requires good crypto and good OS security. There are Orange book
rated systems that are rated to run hostile software in the same machine
with Top Secret information.

@_date: 1995-02-01 13:03:39
@_author: Norman Hardy 
@_subject: Re: ESP Unix encrypted session protocol software 
I trust that that the attack refered to is the "man-in-the-middle". I find
it very curious that there is a simple fix to the attack for the enctrypted
voice channel. Each unit displays to its human a few bits of g^(xy). One
human quotes them vocally to the other. If there is a man in the middle the
bits are unlikely to match. What I find curious is that there seems to be
no automated analog to this precaution. It has to do with the difficulty of
substituting the vocal signals that code these bits. This is too hard for
either computer or man (in the middle). I write to stimulate a solution. I
have none.

@_date: 1995-08-25 19:06:35
@_author: Norman Hardy 
@_subject: Re: Billing for internet usage 
Ideas like these are discussed in my "Digital Silk Road" paper which is now
accessible as " There may soon
be a PostScript version available.
These are the ideas that I presented at a Cypherpunks meeting about a year ago.

@_date: 1995-09-20 09:43:46
@_author: Norman Hardy 
@_subject: Re: NSA and Netscape Crack 
Once upon a time NSA would find weeknesses in friends' crypto systems and
tell them about it -- depending, of course, on the situation. It was a
reciprocal practice. We don't know that NSA didn't tell Netscape.

@_date: 1995-09-21 18:25:21
@_author: Norman Hardy 
@_subject: Pitfall in producing random numbers 
I think that it was on the cypherpunks list that I learned of how PGP for
the IBM PC, running under emulation on the Mac failed to produce good
random numbers. The virtual PC clock proceeded forward by very predictable
manner. Perhaps the details were different but the nature of the pitfall is
clear. I did not notice that pitfall mentioned in RFC 1750. (Its the only
hazard that I know of that they missed.)
The only thing I can think of protecting against this is to do some simple
checks against more obvious ways that virtual clocks might produce times.
Low order bits should not always be zero. The differences between
successive readings should not be constant. Two clock readings separated by
a computation of known length should be within a factor of a few of the
expected value. If not try again once or twice.
Such tests are imperfect but I think that they would have noticed the
virtual clock on the virtual PC. If they fail the program can require the
user to enter the seed, with all that that entails.

@_date: 1995-09-21 20:18:02
@_author: Norman Hardy 
@_subject: Re: Patents and trade secrets was: Encryption algorithms used in PrivaSoft (fwd) 
That trick is probably at least 200 years old. There were once
"quarter square" tables published that started
  i     q(i)
000 000
001 000
002 001
003 002
004 004
005 006
i [1^2/4]
It works for all parities. ab = q(a+b) - q(a-b)
These tables were published in nautical navigation books.
Mechanical analog computers sometimes used this trick to
multiply shaft positions. There would be a cam that computed
the square of one angle, expressed as another angle.

@_date: 1995-09-25 14:25:25
@_author: Norman Hardy 
@_subject: Re: "random" number seeds vs. Netscape 
Very interesting. I wouldn't be too sure that a transmitted signal at a
single frequency is the only signal that an opponent could use to bias your
random numbers. How do you "test for randomness". I think that signal to
noise arguments, phrased in terms of entropy, can protect you against
unknown and unwanted signal. (Ironically you want a very low signal to
noise ratio!) Perhaps you merely take n/(S/N) bits from the HRNG when you
need n bits and run them thru MD5. Here S is the signal strength of the
maximum plausible unwanted signal, and N is the noise of the diode.
I encourage both diode theorists and information theorists to quibble with
the above formula!

@_date: 1995-10-03 21:00:14
@_author: Norman Hardy 
@_subject: The Evolution of  Cooperation (Towards a mathematical theory of reputation?) 
I highly recommend Axelrod's short book, The Evolution of  Cooperation, for
those (like me) who find it hard to think clearly about trust issues. You
have probably heard about prisoner's dilemma, tit-for-tat etc. Axelrod is a
very early worker in this field. He set up a tournament of programmed bugs
that competed with each other in an artificial environment. They could
survive only by cooperation with other bugs. The could also cheat.
Axelrod does not use the term "reputation" but it what one bug gains or
looses as it interacts with other bugs in iterated encounters.
I read the book about two years ago. Only last night did I realize that
those ideas helped me think about the MITM threat.

@_date: 1995-10-03 20:57:05
@_author: Norman Hardy 
@_subject: MD4 collision 
Hans Dobbertin in Germany has found two messages to which
MD4 assigns the same hash.

@_date: 1995-10-05 19:25:24
@_author: Norman Hardy 
@_subject: Re: Simple Hardware RNG Idea 
You presumably use the oddness of the count for your random bit in some
predetermined time interval. External radiation can change, but not bias
the parity. If the counter saturates, the counter may be biased towards one
parity but the software can easily detect saturation presuming it gets the
You can use the source in a smoke detector.

@_date: 1995-10-06 03:28:38
@_author: Norman Hardy 
@_subject: Re: Simple Hardware RNG Idea 
What you really need is entropy (information). I propose concatenating
several counts and sending them thru MD5. The counts are distributed the
same way but are independent so that the entropy of the concatenation is
the sum of the entropies. Each count has a Poisson distribution. That tells
you how many bits of entropy there are in the input to the MD5. Take that
many bits, rounded down, as your random bits.
If there are an average of x bits in a time interval then the probability
that the count will be exactly K is (x^K/(K!))exp(-x). That is the Poisson
distribution. The entropy is then:
- sum[i=0 to infinity]  (x^K/(K!))exp(-x)log( (x^K/(K!))exp(-x))
= - sum[i=0 to infinity] (x^K/(K!))exp(-x)(log(x^K/(K!)) - x)
= - sum[i=0 to infinity] (x^K/(K!))exp(-x)(K*log(x) - log(K!) - x)
Here is a klutzy Scheme program to evaluate these:
(define (sum g)(letrec ((ss (lambda (n)
         (if (= n 0) (g 0) (+ (g n) (ss (- n 1)))))))
           (ss 30)))
(define (log2 x)(/ (log x)(log 2)))
(define (fact n)(if (= n 0) 1 (* n (fact (- n 1)))))
(define (p x k) (* (/ (expt x k)(fact k))(exp (- x))))
(define (en n)(sum (lambda(x) (let ((c (p x n)))
  (if (= c 0) 0 (* c (log2 c)))))))
(en 1) => 2.07
(en 3) => 2.92
(en 10) => 3.73
(en 15) => 4.0
I.e. if 1 count is expected on average there are two bits of entropy
in the count (supprising!) and if the count averages 10 then there
are 3.7 bits worth. It goes up as the log.
Before you bet your enterprise on this scheme consider that the math
was done at 03:30 AM.

@_date: 1995-10-16 18:03:05
@_author: Norman Hardy 
@_subject: Using deterministic programs to select private RSA keys. 
Much has been said recently here about how to produce truly random primes.
Suppose you are selecting a secret key to be used by a bank to sign its
documents. Short of examining the code very closely, or writing your own,
you are vulnerable to a program that selects primes from a vastly reduced
set. If this program behavior is known then discovering the secret primes
may be vastly easier. Writing your own code, or examining other's code, is
error-prone and requires trusting someone who knows more math than most
programmers. Here is an alternative that requires only simple high school
math to understand.
I define a simple protocol and commission several independent programmers
to implement it. The protocol is to accept a sequence of key strokes for
printable ASCII characters. Whitespace is ignored except that two
successive newlines terminate the input. MD5 is applied to the input stream
and the result is used to start the search for the prime.
The required entropy must come from the keyboard. Each of these programs
are used with the same input and the yields are compared. It is even better
if the programs are bought on the open market. The more divers the
interests of the programmers, the less likely there can be an undetected
The naive objection to this is that the keyboard input will be less than
perfectly random. That is certainly true. The input need not be random--it
is only necessary that there be sufficient entropy. There is a real hazard
that the user does not understand the issues and will merely type in the
first paragraph of the Gettysburg address, having heard that there is about
one bit of entropy per character in the English language.
If several bank officers trust each other but not the other's grasp of
entropy they can each enter text since the accumulated entropy only
increases. (They need not hide the text from each other.)
MD5 only produces 128 bits. It might be wise to require more than 128 bits
of entropy. The scheme as described can only ever produce 2^128 distinct
primes. That is small compared with the number of 1K primes. But having to
test 2^128 primes seems hard enough. Are there other attacks?
You might argue that trusting a program to choose secret keys is no worse
than trusting your operational signing software. True. You can confine that
operational software and compare the yields of programs by different
programmers. (The software of the Space Shuttle uses such redundancy.) The
confinement program must supply any required random salt or padding.

@_date: 1995-10-17 17:29:46
@_author: Norman Hardy 
@_subject: Re: Using deterministic programs to select private RSA keys. 
Indeed, but the point of the proposal is a determinate and reproducible
program behavior so as to gain confidence that the output is correct by
comparing output of several programs.
Sounds good.

@_date: 1995-10-19 04:15:00
@_author: Norman Hardy 
@_subject: Re: Simple Hardware RNG Idea 
What you really need is entropy (information). I propose concatenating
several counts and sending them thru MD5. The counts are distributed the
same way but are independent so that the entropy of the concatenation is
the sum of the entropies. Each count has a Poisson distribution. That tells
you how many bits of entropy there are in the input to the MD5. Take that
many bits, rounded down, as your random bits.
If there are an average of x bits in a time interval then the probability
that the count will be exactly K is (x^K/(K!))exp(-x). That is the Poisson
distribution. The entropy is then:
- sum[i=0 to infinity]  (x^K/(K!))exp(-x)log( (x^K/(K!))exp(-x))
= - sum[i=0 to infinity] (x^K/(K!))exp(-x)(log(x^K/(K!)) - x)
= - sum[i=0 to infinity] (x^K/(K!))exp(-x)(K*log(x) - log(K!) - x)
Here is a klutzy Scheme program to evaluate these:
(define (sum g)(letrec ((ss (lambda (n)
         (if (= n 0) (g 0) (+ (g n) (ss (- n 1)))))))
           (ss 30)))
(define (log2 x)(/ (log x)(log 2)))
(define (fact n)(if (= n 0) 1 (* n (fact (- n 1)))))
(define (p x k) (* (/ (expt x k)(fact k))(exp (- x))))
(define (en n)(sum (lambda(x) (let ((c (p x n)))
  (if (= c 0) 0 (* c (log2 c)))))))
(en 1) => 2.07
(en 3) => 2.92
(en 10) => 3.73
(en 15) => 4.0
I.e. if 1 count is expected on average there are two bits of entropy
in the count (supprising!) and if the count averages 10 then there
are 3.7 bits worth. It goes up as the log.
Before you bet your enterprise on this scheme consider that the math
was done at 03:30 AM.

@_date: 1995-11-19 04:30:18
@_author: Norman Hardy 
@_subject: Re: Request for URL'S 
The following seems to be a pretty good nexus:
There is, of course
A crypto legal centre:
Happy Hunting

@_date: 1995-11-20 23:51:31
@_author: Norman Hardy 
@_subject: Re: Good Enough? 
I don't like to harp on this but you have stated the scenario so clearly,
that I ask:
If  the user cannot trust you to generate keys for him, why should
he trust the code that you provide to him? That code can have
errors like the old Netscape code except planted on purpose so
that the private key is guessable in 2^40 tries.
There are two answers, I think.
   The code is public and the user
   hopes that any flaws will be publicized.
The second is to use keyed information (not timing but character
information) to provide the random seed. That is the idea behind
my post a few weeks ago:
"Using deterministic programs to select private RSA keys"
Some may find that method less hazardous then trusting the culture
of publishing flaws in code.
I can forward that posting to anyone interested.

@_date: 1995-11-25 14:18:47
@_author: Norman Hardy 
@_subject: Re: Virus attacks on PGP 
Yes it would be hard. When you choose your own protection as above an
opponent would have to mount a significant effort just to get your stuff.
Yes, but if your particular habits became widespread, an intelligence
agency could amortize the virus effort across many victims.
Here is just one such complicated virus:
Sit in the OS watching for PGP to be launched. Patch PGP on the way in. The
patch writes to disk the location and password for the secure key ring.
Concurrently the virus watches for there to be IP service and sends the
disk information as a UDP.
Alternatively the virus waits for idle time, (screen saver time) and dials
an 800 number having turned off the modem speaker. But don't send the same
data twice!
There is a significant hazard for the virus producer here if someone finds
the code and learns the 800 number. I am sure that the Telco would help
locate the physical phone to which the 800 number led. UDP provides more
ways to pigeon drop the secret so as to protect the reader of that data.
Perhaps you can send the UDP to the NY-Times (or to your favorite enemy)
over a line that you are tapping. The NYT will discard it and no one is the
wiser. The virus is then anonymous.

@_date: 1995-11-26 07:50:13
@_author: Norman Hardy 
@_subject: Learning Elliptic Curves 
I have found an easy introduction to elliptic curves. It is "Rational
Points on Elliptic Curves" by Joseph H. Silverman & John Tate.
(Springer-Verlag ISBN: 0-387-97825-9 or 3-540-97825-9) It is a breezy
undergraduate introduction. It emphasizes the mathematical elegance. It
mentions crypto applications but does not delve deeply.
Schneier recommends "Elliptic Curve Public Key Cryptosystems" by Alfred J.
Menezes. (Kluwer Academic Publishers ISBN: 0-7923-9368-6) That book has
only a very compressed theory section which already requires knowledge of
field theory. I think that the first book is a good intro to the second,
which does cover crypto applications.
What I learned is that elliptic curves are an alternative to finite fields
for crpto purposes. Here is what they have in common:
There are many (2^70 -- 2^2000) values any one of which can be represented
in the machine in constant space. a_i is the ith one of these values. If
someone sends you a_i it is real hard to figure out what i is. There is an
operation that isn't too expensive for computing a_(i+j) given a_i and a_j.
For some big integer i you can compute a_i in about (log i)^3 steps. For
RSA, knowing how to do these two computations does not reveal what the
period of the sequence is, i.e. what is the first i such that a_0 = a_i.
Knowing the period is tantamount to knowing the private key.

@_date: 1995-11-27 07:24:46
@_author: Norman Hardy 
@_subject: Re: Elliptic curves, current status? 
Not with any assurance. I don't trust my own knowledge yet.
I think that the opinion is that the discrete log problem is harder
with elliptic curves than for prime modulus arithmetic for numbers
of a given size. That is why you can use fewer bits.
The inner loop in some elliptic curve systems is not multiply-add
(as is the case with number fields)
but other operations that are as efficient with gates but less
efficient with normal machine instructions.
There are probably an order of magnitude more people that
have studied and published about the problems of breaking
prime modulus crypto than elliptic curves. Perhaps progress
will be faster should elliptic curves be studied by more people.
There are a lot of tricks to speed up discrete logs in for prime
modulus schemes that don't seem to work for elliptic curves.
There are many parameters to an elliptic curve crypto system.
I haven't seen any taxonomy of which kinds are good and which
have been shown to be week. In contrast there seems to be a
consensus about how to pick primes for RSA or Diffie-Hellman.
I am certainly no expert. Perhaps this will prompt comments
from someone who can point to real information.

@_date: 1995-12-03 02:51:42
@_author: Norman Hardy 
@_subject: Re: Netscape gives in to key escrow 
The Netscape browser chose the wrong time, this morning, to tell me that my
demo copy was about to expire.

@_date: 1995-12-28 21:29:25
@_author: Norman Hardy 
@_subject: URL for cypherpunks 
I am putting up some solutions to the Garage Door problem that was
discussed here perhaps a year ago. I would like to refer to the cypherpunks
by URL. Are there currently any appropriate URLs ?

@_date: 1996-01-04 14:33:36
@_author: Norman Hardy 
@_subject: A Mondex like Protocol 
Two Mondex units, upon command of their respective operators, can pass
money from one to the other via infra_red signals. I think that this
requires tamper proof units.
I understand that the Mondex protocol is currently undisclosed. I have no
information about that protocol but am merely trying to find a protocol
that fits the little that I know about Mondex. Are there other guesses?
Here is one way it might work. Upon an operator receive command, the payee
unit transmits a DH greeting along with the value of a counter located in
the payee unit. (The integrity of the counter value in the greeting is
somehow ensured.) It continues to send this greeting while it awaits a
Upon a pay command from its operator, a payer unit transmits a DH greeting
and continues to send that while it awaits a greeting. When either unit
receives a greeting it computes the shared secret key ala DH. The payer
decrements its cash value and generates a pay order enciphered under the
secret key. The pay order includes the counter value from the payee's
greeting. This order is transmitted repeatedly until an acknowledgement is
received or times out. If it times out then the money is lost. When the
payee receives a pay order, it verifies that the counter value is correct
and then increments the counter, preventing replay. The payee then
increments its cash value and sends ciphered acknowledgements for a brief
period. The payer may give one final acknowledgement acknowledgement which,
if lost, merely means that the receiver will time-out sending
The common DH modulus is known to all units and but otherwise secret. This,
of course, requires a extraordinary tamper resistance. Only the state must
be kept secret, not the hardware behavior.
Here is the money integrity argument for this protocol. The units are
collectively responsible for preventing counterfeiting. For counterfeiting
to happen some unit must increment its cash value when there was no
corresponding decrement in another unit. A unit increments its cash value
when it decodes a pay order from someone who knows the global secret DH
modulus. That someone must have been a legitimate unit that decreased its
cash value. Replay is impossible because each such transaction is uniquely
identified by the recipient's counter value. The recipient never increments
its cash value twice for the same counter value.

@_date: 1996-01-05 22:00:11
@_author: Norman Hardy 
@_subject: Re: cyphernomicon FTP site? 
I was using Lynx just now to do something like this (Mediacity was kaput).
I couldn't find out how to tell lynx to save the file. Do you know how?

@_date: 1996-01-11 11:46:11
@_author: Norman Hardy 
@_subject: A Mondex like Protocol (2) 
An improved Mondex like protocol
About a week ago I posted a protocol that meets the requirements of the
Mondex cards as I understand them. It was overkill. I wasn't clear in my
own mind what properties of Diffie Hellman I was depending on. Here is an
improvement that does not use DH and thus uses less compute power.
Two Mondex units, upon command of their respective operators, can pass
money from one to the other via infrared signals. I think that this
requires tamper proof units.
I understand that the Mondex protocol is currently undisclosed. I have no
information about that protocol but am merely trying to find a protocol
that fits the little that I know about Mondex. Are there other guesses?
When a receiving unit, the payee, is instructed by its operator to be ready
to receive a payment, it increments an internal counter. The payee
transmits an infrared message including its unique id, the counter value
and a simple checksum. This message is repeated until some timeout or a
valid transmission from a payer is received.
The payer unit, having been instructed by its operator to pay, awaits such
a message. Upon receipt it decrements its local balance and constructs a
record consisting of the payee's id, the payee's counter value, the payment
amount and a secret shared by all money units. The payer then transmits a
message with the payment amount, and the secure hash of the record. This
transmission is repeated until an acknowledgment or a timeout.
Upon receipt the payee is able to reconstruct the payer's record and
compute the secure hash. If the computed hash matches the received hash
then the payee can be sure that some legitimate payer unit has decremented
its local balance and it is thus valid for the payee to increment its value
by that amount. It then transmits one acknowledgment.
If the receiver's transmission is garbled but the checksum does not catch
it then the transmitted money is lost. The payer thinks it has authorized a
balance increment but no unit recognizes the authorization as its own.
Garbled transmission from a payer are ignored when the hash check fails.
Subsequent transmissions will hopefully succeed.
Note that this scheme uses no crypto.

@_date: 1996-01-18 04:03:35
@_author: Norman Hardy 
@_subject: "trust management" vs. "certified identity" 
This is reminiscent of a recent idea of mine. Imagine the following signed
I (fingerprint = ...) claim that the code X with SH (secure hash) = ...
satisfies contract with SH= ... when its free code pointers are bound to
other code conforming to contracts identified within X by their SH's.
The contracts would be either formal or informal.
When a Java program arrives at a client it can warrant its services if it
finds local access to warranted sub-routines. (For this purpose behaviors
of objects are sub-routines.)
The Java loader can build warrants recursively with such declarations. They
would, of course, be relative to the reputation of signers of the above
I have just sent for your paper.

@_date: 1996-01-26 03:14:47
@_author: Norman Hardy 
@_subject: The cost of breaking RC4 with a 40 bit key. 
I think that special hardware to break RC4 would require 256 bytes of
registers and only a few hundred control gates. Lets say 5000 transistors
per "module". You can put several hundred modules on a chip. Each module
can easily do one step in 5 ns. I havn't figured out what the attack would
be (known plain text etc.) and hardware to handle that might be more. In
mass production the marginal cost of such a chip might be $100.  Perhaps
trying one key requires 100 steps. I get the cost per key trial as follows:
(100  $/chip)(100 steps/trial)(5 (module*ns)/step)/
((10^9 ns/sec)(10^8 sec/(economic lifetime))(200 modules / chip))
10^(2+2+.7 - (9+8+2.3)) $/keytrial= 10^(-15+.4) $/keytrial
 = 2.5*10^(-15) $/keytrial
I compute the cost of breaking a 40 bit key as 2.5*10^(-3) $ or one quarter
of a cent.

@_date: 1996-02-05 15:17:16
@_author: Norman Hardy 
@_subject: cipherpunk mail at Netcom.com 
The list of addressees is made from the "From" fields that include
"netcom.com" in CP mail that appeared on the CP list Tuesday and Wednesday
last week. I have received no CP mail since then. Have you?

@_date: 1996-02-09 11:49:05
@_author: Norman Hardy 
@_subject: Money & CreditCard URLs 
Here is a fragment of html that points to several online money or payment
The first two, SEPP & STT, are the two credit card protocols from the
previously competing camps and out of which the new standard, SET, is
supposed to emerge. STT and SEPP are vague in different ways. Perhaps their
offspring will be more completely specified. They both hide the credit card
number from the merchant. I would be pleased to receive further such URLs.
Money Protocols
NetBill Cybercash, and
First Virtual,
The Millicent
Mark Twain Bank

@_date: 1996-02-18 14:29:21
@_author: Norman Hardy 
@_subject: Counting bits Fast 
I hear that there may be those out there burning many compute cycles
counting one bits in piles of data.  There is code at
that might provide a factor of ten over more obvious bit counting code.

@_date: 1996-03-02 09:20:25
@_author: Norman Hardy 
@_subject: Re: SET spec available 
I am unable to find the specs. Anyone have an URL?

@_date: 1996-03-29 12:47:13
@_author: Norman Hardy 
@_subject: Re: WSJ on Big Java Flaw 
Thanks for the pointer. I found it most interesting. I suppose that I am
glad that I am not the only one who doesn't know how DNS works.

@_date: 1996-04-08 17:21:22
@_author: Norman Hardy 
@_subject: Re: Why sign pubkey? 
Thanks for the post. There is someone with a quite legitimate reason to
sign a newly generated public key with "Norman Hardy" in the user id string
but without my my e-mail address. He is one of the several other Norman
Hardy's in the U.S.  I could include a very short biography which would fix
that ambiguity.
I only send secrets to people that I have some reason to trust. I gain
trust sometimes from having met someone in person and talked for a few
hours. If I get a business card with a key finger print and e-mail address
(or URL) then I am safe from such spoofing as described in your post. Her
name plays no role in the transaction.
If I trust her because you recommended her to me, then perhaps I can get a
fingerprint and URL from you. Again I need no name.
In both of these cases the URL is merely a convenience. If she moves her
web page, a search engine will soon find it given a part of the finger
print included in the web page. Unless the attacker has compromised the
search engine, I need merely send mail enciphered by her public key to the
e-mail address given in each web page claiming to own the public key. Only
she will be able to read the mail.
  Put URL & finger print on business cards.
  Include URL and finger print in recommendations.
  To send a secure message to some whose URL & trusted print you have:
    Check the URL for a public key whose print matches the trusted print.
      If that fails use a search engine for a better URLs.
    Send mail to each e-mail address found on a web page passing the test.
Recommendations should include a little text about what things the designee
should trusted with. Programs like PGP that follow trust chains should
display the text from each recommendation in the chain.

@_date: 1996-04-28 06:23:45
@_author: Norman Hardy 
@_subject: Re: trusting the processor chip 
In the days of microcode this was my best (worst?) scenario. Setting up for
fast divide has been an art long before Pentium divide fame. In microcode
you don't spend time testing for cases that you can prove won't happen.
Some obscure cases can arise only with a rare combinations of two 48 bit
operands. The microcode flaw would be to put the processor into privileged
mode even while getting the right answer. There would plausible deniability
even if the flaw were discovered. (Gosh, I didn't test for this fall thru
case because here is the proof that it can't happen.) Of course there is a
bug in the proof but no one reads proofs. This can now be exploited by
anyone that knows what division leaves the machine in privileged state.
This is an attack on those systems that are rated to run untrusted machine
code, using privileged mode code to limit the operation of the untrusted
Only one person is necessary to pull this off. He must be trusted to
produce microcode and the implementer of the divide algorithm. Test code
will not find the transition to privileged code just because you can't test
the whole machine state after every tested instruction. Normally the bogus
privileged state of the machine will quickly expire (on the next interrupt)
and will cause no permanent state change even in those few cases where a
magic division occurs naturally.

@_date: 1996-05-05 04:56:08
@_author: Norman Hardy 
@_subject: URLs for Capabilities 
I am preparing a talk for this morning at CP in PaloAlto. Here are some
relavant URLs.

@_date: 1996-05-24 15:03:38
@_author: Norman Hardy 
@_subject: Re: Runtime info flow in Java 
I began to look at your paper online but that works poorly for me. My
printer does not handle A4 paper. PostScript seems inflexible in this
regard. If it were available in 8.5 X 11 inch format you would have least
one more reader.
I am interested in your paper because you define the problem as we do.
There are some who think that capability architectures are the solution.
There is little information on how to solve these problems with
capabilities. I am trying to find time to address some of these issues.
KeyKOS is a capability based operating system that is designed to solve a
variety of security problems. There are some papers at
 and
We find that Java as a language conforms well enough to capability
principles even though not using the term. Some of the primordial classes
do not conform and indeed it was there that the Princeton group found the
problems that are most difficult to fix.

@_date: 1996-05-24 15:07:03
@_author: Norman Hardy 
@_subject: Re: [hrdware] anti-Tempest video settings 
I imagine that a color combination that cancels for an antenna in one
location will not cancel for another location. Many monitors have separated
wires for the separate colors.  A color combination that cancels for one
antenna polarization may not cancel for the other.

@_date: 1996-05-25 17:06:47
@_author: Norman Hardy 
@_subject: Re: Runtime info flow in Java 
I agree with everything that Bill Frantz said. I certainly didn't mean to
imply that a system such as Java could not be secure.
I can't think about a whole system at once. We developed KeyKOS over a span
of several years and we were able to convince the NCSC it had a firm
security foundation. The NCSC convinced us to do some formal descriptions
of our system to articulate some of our previously undescribed programming
patterns. These said in a somewhat mathematical way how capabilities work.
(Like you can't do something to zot unless you have a capability to zot.
etc.)  Object references in C++ and Java pretty much conform to these
capability patterns. In Java you can get an object reference only when you
create the object or some one passes it to you (or you get it thru a shared
variable). In C++ you can also get an object reference by casting and other
None of these formalities seemed the least bit surprising. There was no
deep mathematical insight here. It was merely restating the familiar in
very different terms. The exercise did lead us over some old territory with
new eyes and we saw some easily eliminated covert channels that we had been
unaware of.
We do not have a complete map between capabilities and Java. There are
things about Java that we have not mapped to capabilities yet. For instance
any piece of code in a Java program that can declare a reference to an
object of classs Zot is also able to invoke any of the public constructors
for Zot. This may be too strong an ability. (In KeyKos you could create a
zot just in case you held the capability to the zot creator.) Perhaps you
put all of the constructing code in static methods for Zot and make all
constructors private. It is important that some code be able to construct
Zot instances that other code is unable to construct.
Java's security manager classes are not capability like. They seem to us
too much like merely a series of plausible decisions for which we can see
no general principles. Each decision makes sense but we have no feeling
that they are complete.
I suppose that the above sounds as if I am saying "Trust us. We know all
about security.". Unless the end user is able to understand just what the
lattitude that the applets in his machine have, he has no security. Java
will not be secure until the security principles can be understood by the
intelligent end-user. I think that you must make graphically explicit which
agents in the computer have access to the phone. You may be keeping secrets
because untrusted agents can't phone home, or because they can't see the
secrets. Current user interface design is predicated on the idea that such
issues should not concern the end user. I dearly wish that when some
application in my Mac complains that it can't get the phone, there were a
way for me to find out who was using the phone and take it away from him. I
would also like to easily deny applications access to the phone. Even more
I would like to explicitly grant phone access to an application just as I
must plug my modem into the phone line before it can transmit bits from my
house. In such a system I could begin to reason about where the secrets
were going or why things didn't work.
Access to the phone should be via a capability. The same goes for TCP
connections, the ability to send a user data gram to a given IP address.
Access to a random stream of bits should be via a capability. Access to a
particular file or directory should be a capability. etc. etc. Everything
should be a capability!!!

@_date: 1996-06-04 06:50:03
@_author: Norman Hardy 
@_subject: Re: Fate of Ecash if RSA is cracked? 
The "Idea Futures" forum has established odds on this. The current odds are
currently 60% that a 1024 bit number will be factored by 2010 and 30% that
a 512 bit number will be factored by 1997.
See  for Idea Futures and
 for odds for various questions.

@_date: 1996-06-14 11:32:33
@_author: Norman Hardy 
@_subject: Class III InfoWar: TST Article 
There are two things that they may be speaking of:
1. Causing transient errors to crash the system and cause restarts that may
take many minutes.
2. Actually damage the machines.
I imagine that only a small fraction of the energy required to damage the
hardware is necessary to introduce serious transient errors. IBM used to
test the main frames as they installed them. They had to resist several
inch sparks drawn between the machine and a one meter frame. Software
diagnostics ran during the test. I think that few desk top machines would
survive that.
EMP (Electro Magnetic Impulse), a side effect of nuclear devices, is
purportedly able to damage electronics over distances of many miles. Some
weapons may be designed to enhance this.
Ordinary high explosives can produce a scaled down result. EMP is strategic
only because it  damages electronics that are too far enough to be damaged
by the blast. I suspect that high explosive EMPs are similar in this
The physics behind this is not abstruse. A significant part of the
explosive energy can be turned into EMP whether the source is nuclear or
chemical. How well it can be directed is probably highly classified. The
"antenna" is vaporized in either case and dissipates much of the energy.
The energy comes out in 10's of microseconds for high explosives and
fractions of a microsecond for nuclear. I don't know how much it takes to
fry an IC but judging from the wrist straps that are recommended for
installing ICs I would guess that it is a fraction of a Joule. (I once
discovered that a one Joule jolt really hurt.)
Faraday cages attenuate EMP by the same factor that they attenuate secrets.
I think that if a blast doesn't damage the cage then neither will the EMP.
Of course the cage may survive but fail to protect the interior
(insufficient attenuation). I don't know whether a cage sufficient for
tempest is sufficient for EMP protection. Comm lines and power cables go
thru the cage and cause problems here as well. Perhaps hefty surge
protectors suffice here. Communications equipment outside the cage should
at least be equipped to recover quickly upon transient error and not tear
donw circuits. Normal error control can then hopefully compensate for the
transient.  (IP, ATM, Frame relay??)
A large capacitor can discharge a lot of power in a short time without
causing nearly so much commotion as an explosion. Discharging a one kg
25000 volt capacitor makes a lot of noise, however. I don't know how well
it can be muffled.

@_date: 1996-06-16 10:40:22
@_author: Norman Hardy 
@_subject: If you knew what we knew ... 
The following is a paragraph from the executive summary of the NRC Crypto
policy paper: "Cryptography's Role in Securing the Information Society".
The conduct of the debate regarding national cryptography policy has been
complicated because a number of participants have often invoked classified
information that cannot be made public. However, the cleared members of the
National Research Council's Committee to Study National Cryptography Policy
(13 of the 16 committee members) concluded that *the debate over national
cryptography policy can be carried out in a reasonable manner on an
unclassified basis*. Classified material is often important to operational
matters in specific cases, but it is neither essential to the big picture
of why cryptography policy is the way it is nor required for the general
outline of how technology will and policy should evolve in the future.

@_date: 1996-06-19 19:48:38
@_author: Norman Hardy 
@_subject: Re: Class III InfoWar: TST Article 
Interesting idea. I have no idea about impact on humans.
The capacitor connected to some wierd shape antenna all assembled in
a vacuume to muffle the sound upon discharge would probably be
reusable. It also probably provides only a fraction of the energy of
a high explosive version.

@_date: 1996-07-07 08:52:53
@_author: Norman Hardy 
@_subject: Re: NYT/CyberTimes on CWD article 
This seems to be an application for Bloom filters.
See page bottom of page 561 in Knuth's "Searching and Sorting", First Edition.
(Vol 3 of Art of Computer Programming)
With a Bloom filter you can hide which URLs you reject yet quickly rejecting
particular URLs.
Compute SHA(URL) yielding 160 bits. Divide that into 16 ten bit quantities
b[i], for 0<=i< 10.
Reject the access if P[b[i]] = 1 for each i. P is an array of 1024 bits
computed by someone
with the index prohibitorum. (pardon my Latin)
Yes, this excludes 1/1024 "falsely accused" URLs, but you get the idea.

@_date: 1996-07-12 08:47:12
@_author: Norman Hardy 
@_subject: Re: Metered Phone 
Better that the phone count calls (as in the Netherlands) than record the
number called (as in the United States).

@_date: 1996-09-14 12:19:05
@_author: Norman Hardy 
@_subject: Re: 56 kbps modems 
I imagine that both modems in a connection become phase locked with the
underlying 8K digital carrier. Then each modem signal element is carried by
just one 8 bit digital sample. That carrier moves 8 bit bytes 8000 times
per second. Stopping at 56 Kb instead of 64Kb means that a 7 bit DA
converter for the sending modem and a 7 bit AD converter in the receiver,
plus some fancy analog filters to undo the subscriber loop effects. Going
for 64Kb would require twice the signal to noise ratio on the local loops.
I think that modern PBXs have a digital link to the phone company. This
would mean that an ISP would not have to buy fancy modems. A modified PBX
could transmit and receive bits to a computer directly. It will impact the
phone compnany's ISDN service but I don't think that they can stop this.

@_date: 1996-09-16 11:50:24
@_author: Norman Hardy 
@_subject: Re: What is best policy paper on crypto? 
I think that they meant the NRC (National Research Council) report. It is at:

@_date: 1996-09-17 12:49:06
@_author: Norman Hardy 
@_subject: Re: Gaining trust in OCO crypto code 
I agree with most of Bill's points. It is the right sort of analysis.
Actually if you generate 100,000 RSA keys with the algorithm the birthday
effect says that
you will have some collisions. Of course even 100,000 key generations takes
a long time.
For some purposes. On the transmitting end if the enemy can choose the
plain text then a tested but bogus implementation can take special action
upon seeing a signal in the plain text stream. One such action would be to
merely shut down. On the receiving end a bogus implementation can detect a
signal inserted in the cipher text by the enemy and cause damage. I havn't
thought of any low visibility attacks but I suspect that there may be some.
If random number generation is specified not to be integral to RSA key
generation, then two or more untrusted programs, from mutually hostile
sources, can generate your RSA key if they yield the same output from the
same input. In paranoia situations I would rather trust my keyboard random
than an algorithm chosen by my enemy.

@_date: 1996-10-02 14:32:00
@_author: Norman Hardy 
@_subject: Re: Weaknesses in Smart Cards? (Re: FLA_wed) 
As best I can figure, extracting the secret from a Mondex card gives you not
merely the money from the card, but the "digital plates" with which to mint
arbitrarily much more money. I only say this because the only protocol the
I can think of that fits what we do know of Mondex has this problem. This fault
does not plague Chaum cash.
I don't know how to code the card application so that a transient errors
won't just occasionally cause the secret to be exported. Then again that
may be possible to code it for "fail safe". If it were my money backing
the Mondex cards, I would want to know how it worked.

@_date: 1996-10-02 16:09:17
@_author: Norman Hardy 
@_subject: Re: Weaknesses in Smart Cards? (Re: FLA_wed) 
I can imagine a protocol that would allow the Mondex card to issue several
brands of card that would normally appear to be one uniform brand until
fraud was suspected or proven. Then only money passed thru the compromised
brand would be suspect. News of the counterfeit brand would be spread among
cards by a contagion algorithm. One morning your card would greet
you saying that $38 of your cash is counterfeit, or worse, that your card
could issue no money to other cards, but could be returned to the issuer
for a partial refund.  I would not want to hide my Mondex card under the matress
for my old age.
I recall hearing something about Mondex that suggested to me that the
card rembered recent large receits and that money had fingerprints
so as to remember, to a degree, where it had been recently. When questioned
about the privacy issues they responded that of course only the authorities
would be able to retrieve such information.

@_date: 1996-10-21 16:57:54
@_author: Norman Hardy 
@_subject: cypherpunks ftp site 
I am trying to get some code from .
I get:
ftp> get README.MIRRORS
200 PORT command successful.
425 Can't create data socket (128.32.43.51,20): Address already in use.
Any suggestions to how to get eliptic.src and elliptic.doc reported to be
at ? I searched AltaVista.

@_date: 1996-11-03 14:40:57
@_author: Norman Hardy 
@_subject: Re: NSA Report: Anyone seen this? 
I just finished reading the report "How to Make a Mint: The Cryptography of
Anonymous Electronic Cash" by Law, Sabett & Solinas. It can be found at
It is very well written with only identification of the issues except in
the last short paragraph where they clearly lean toward government
They identify and distinguish interests of the bank, the consumer's
privacy, and the government. Some of the measures that they describe
(providing for traceability) might well be done by a bank operating in an
anarchy. Imagine that you are running a bank in an anarchy and the son of
one of your good customers is kidnapped and held for ransom. Suppose that
the kidnapper is a good customer of another bank with whom you have an
arm's length relation. The arguments are not simple. Only towards the end
does the paper begin to conflate the interests of the government and the
bank. Some of the law enforcement purposes that they describe would apply
to the anarchy bank, others would not.
The paper is the best description I have seen of several advanced money
schemes. It has a better description of Chaum's off-line scheme than I had
seen before. It describes sever even more advanced schemes, both abstracted
form the mathematical details, and then with the details filled in.

@_date: 1996-11-21 21:59:37
@_author: Norman Hardy 
@_subject: Computer CPU chips with built-in crypto? 
An important paper on tamper-proof hardware, discusses CPUs that cypher
their memory bus.
html:           postscript      ftp.cl.cam.ac.uk/users/rja14/tamper.ps.gz
Has special relevance to smart cards.

@_date: 1996-12-09 20:43:23
@_author: Norman Hardy 
@_subject: Re: Go to my website 
I looked at your site with Netscape 3.0 with my Mac. I use 18 point font
which is larger than the default. I like more pixels per character. The
text in the left column is thus truncated. Some web pages that use frames
somehow cause the text to adapt to the available space. I don't know how
html manages this issue.

@_date: 1996-12-14 12:32:16
@_author: Norman Hardy 
@_subject: Re: Magic Numbers in MD5 
Perhaps random numbers would be stronger but they would not be manifestly
MD5's formula for t_i precludes the possibility that the definer of MD5
chose the numbers
accoriding to some undisclosed principles that would allow him a trap door.
The following code computes the magic numbers without requiring trig functions:
static word si[64];
static int md5init()
{double c1=0.5403023058681397, s1 = 0.8414709848078965;
int j; double a=1, b=0;
for(j=0; j<64; ++j)
 {double p = a*c1 - b*s1, q = a*s1 + b*c1;
  a=p; b=q;
  {union{double d; struct{int high; int low;} fx;} z;
   z.d=(fabs(b)-1.1e-10)+1048576;
   si[j] = z.fx.low;
 }}}
An alternative would have been to let t_i be MD4(i) or SHA(i).
Using SHA to define MD5 would have required collusion between Rivest
and NSA to allow for a trap door. Even then it would have been very difficult.

@_date: 1996-12-23 19:16:45
@_author: Norman Hardy 
@_subject: Re: [PGP-USERS] Password Keystroke Snarfer Programs (passphrase protection) 
The only way I know to solve this problem is to get a real operating system.
This excludes the Mac, DOS and its descendents.
First the kernel must be designed to prevent programs from installing
themselves wherever they wish. (Gasp, even useful prrograms!) Second
they must not be encumbered with piles of tools written by people with
no sense of security. Such tools are often installed with more authority
than they should require. There is a Unix system call that displays the
most recent command that any user has typed. This call is used by the
ps command to describe the origin of a task.
Perhaps NT is new enough that it hasn't gathered all of these holes.
I don't use NT so I wouldn't know.
