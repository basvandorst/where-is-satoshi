
@_date: 1996-06-29 14:45:31
@_author: Andrew Tridgell 
@_subject: rsync and md4 
I've recently released a package called rsync that uses a checksum
search to provide very efficient file update over a slow link.  (see
ftp://samba.anu.edu.au/pub/rsync if you are interested)
Now I'd like to calculate some probabilities of failure of the
algorithm. The fundamental thing I need to know to do the calculation
is the probability of a random piece of data of length n having the
same md4 checksum as another given piece of data of the same length.
A first guess might be 2^-128 but I know that this sort of thing is
rarely that simple. Is md4 that good?
Note that I am not interested in "attacks" on md4 as such as the
source of the random data is just another file provided by the same
user, so it won't have been specially designed to defeat md4. If the probability is within a few orders of magnitude of 2^-128 then
can I also be sure that if I only use the first b bits of a md4
checksum it will be within a few orders of magnitude of 2^-b ? There
is an option in rsync to use a shorter checksum by truncating
md4. This saves some bytes on the link at the risk of lowering the
confidence. Why md4? I chose md4 because it seemed to be the fastest of the
reputedly strong, publicly available checksum algorithms. Suggestions
for alternative algorithms are welcome.
Cheers, Andrew

@_date: 1996-06-30 15:10:34
@_author: Andrew Tridgell 
@_subject: Re: rsync and md4 
The birthday paradox doesn't apply in my case I believe. Its not an
all-to-all comparison. One file is "given" by the user. I'm definately
not a crypto-expert, however, so I could be wrong.
I'd like to know more about this. You'd have to read the tech report on rsync. It does not download the
whole file when a checksum mismatch is found, that would be next to
useless. It effectively creates binary diffs of the two files, without direct
(local) access to both files. As far as I know this is a new type of
In practice the hashes and checksums dominate the data that is sent
over the link. They total about 1/30 of the total file size for the
default settings.
Do you have references to the md4 collision stuff? The situation I
have is a bit unusual so its just possible some of the results may
apply. It already uses a 16 bit hash as a first level filter and a 32 bit
"rolling checksum" as the 2nd level. The 2nd level fails about 25
times on a 25MB test file I've been using. The failure rate goes as
the square of the file length. When the 2nd level fails it is detected
by the md4 hash which has to be much stronger.
Cheers, Andrew

@_date: 1996-06-30 15:01:44
@_author: Andrew Tridgell 
@_subject: Re: rsync and md4 
I thought md5 was slower than that, but I'm only going by my
(addmitedly poor) memory of some comments in the tripwire docs. I'll
give it a go sometime.
One annoying think about the md4 implementation that I have is that on
little endian machines it byte reverses the words in the buffer its
hashing so I need to make a copy of the buffer each time. Is there a
version of md4 that doesn't do this?
Cheers, Andrew
