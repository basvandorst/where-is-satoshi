
@_date: 1995-10-16 11:58:16
@_author: Jeff Williams 
@_subject: Re: proposal: "security spectrum scale" (SSS) 
Unfortunately, severity is a question of perspective.  In some
environments, an operating system crash could be considered catastrophic.
In others, it just means reboot and continue.  I'm not a policy wonk,
but security is relative to what you care about.
There already was a USSR, but I think it ultimately failed :-}
For some starters, you should check out:
   A Taxonomy of Computer Program Security Flaws
   Landwehr, C.E., Bull, A.R., McDermott, J.P., and Choi, W.S.
   ACM Computing Surveys, Volume 26 Number 3, September 1994
Which organizes flaws according to how they enter a system, when
during the lifecycle they enter, and where in the system they
manifest themselves.  Some additional papers are available at the
NRL web site.
To whom?
The only way to unify security rankings is to constrain the problem by
assuming an environment and intended uses for the system.  It sounds
like you are assuming a low assurance workstation with an internet
connection which is used for non-critical home or business purposes.
Ironically, the digraphs you propose look sort of like Orange Book
ratings.  Evaluation results, however, tell you something (not everything
by a long shot) about how trustworthy a product is.  Your rating seems
to indicate the exact opposite.  How about a B2 product with a G3 flaw?
I believe that that flaw rating is *exactly* the same problem as product
security rating.  But that's a different discussion.
Any flaw rating system needs to consider how it will deal with advancing
protection technology.  For example, susceptability to viruses is much less
critical than it would be if there were no anti-virus software available.
Similarly, having a microkernel operating system makes me less susceptable to
crashes.  Should a flaw rating decrease as technology adapts to deal with it?
Also, how do you rate situations where flaws are combined to mount an attack?
For example, I crack a weak password to get a guest account.  Then I snag an
unprotected password file and crack it to get root.  Then I leave an
trapdoor to get back in later.
--Jeff Williams

@_date: 1995-10-17 08:24:53
@_author: Jeff Williams 
@_subject: Re: Security Spectra 
Please watch your attribution.  Vlad Nuri proposed this rating scheme.
I absolutely agree with you on this point.  I'll point out again that this
is the same problem as creating a rating scheme for the security of
It is popular these days to jump on the risk assessment bandwagon and
forget about assurance.  This occurs because people think risk assessment
is a quick fix that you can do after the system is built and configured.
Some holes cannot be patched.
--Jeff Williams

@_date: 1996-01-26 01:58:14
@_author: Jeff Williams 
@_subject: Re: V-chip? 
But what if they *ask* you nicely to label your work?
  "If you think your message is offensive, violent, or racist,
   would you please consider labelling it?"
I don't think I'd mind.  In fact, *optional* labels would make me more likely
to post such material, because I'd have some confidence that it would only be
read by people who want to read it. (And they could even find it more
There's nothing inherently wrong with labelling information. When messages
here are labelled [NOISE], I know to avoid them. This sort of
meta-information is helpful and good.
The precedent is what's troubling. Someone will probably try to mandate the
labels...Someone will try to write a law that says "Anyone who posts what I
consider offensive without a label is guilty." This is what should be
fought...not labels.

@_date: 1996-01-26 14:20:25
@_author: Jeff Williams 
@_subject: Re: "This post is G-Rated" 
What if there was a flag on each message which the author could leave
"UNSPECIFIED" or indicate "NOT INTENDED FOR KIDS." You could attack by
marking a bunch of bland stuff "NIFK" or you could leave some porn
"UNSPECIFIED".  Either way, I think the situation is better for kids. I hope
that the majority of Internet users are not actively trying to get porn to
I see labels as helpful rather than restrictive. A label provides additional
information to help people find the information that they want. That
information can also be used to help you cut out the information you don't
want. If parents want to use this flag because they think it might help their
kids, great.
Maybe nobody would use the flag, but I don't see how it could hurt. If I had
kids, I would appreciate having the option of sorting out all the stuff that
is "NIFK" by the author.

@_date: 1996-06-25 13:44:00
@_author: Jeff Williams 
@_subject: Re: info assembly line, "flits" (long) 
To me, bits don't need context any more than atoms do.  Their whole beauty
(like atoms) is their simplicity.  You can build incredibly complex
structures (like jaguars) from the simplest of particles (or bits).
Negroponte's analogy begs the question of the physics of cyberspace.  They
are clearly different from the physics of the real world.  Imagine if you
lived in a world where objects could be duplicated extremely quickly,
cheaply, and perfectly.  You could send things around at the speed of light.
Nothing ever happens except by the action of a program.  What would be
valuable to you in this world (crypto-relevance)?  Why would you care about
"where" anything is?  Why would you bother to "move" something?
Putting aside the implementation problems with "flits", I don't think there
is any need to make cyberspace behave like the real world.  The best things
about cyberspace are the differences with the real world.  I agree we need to
work on the interfaces between worlds, but that doesn't equate to making them
the same. A major problem with your note is that it confuses the bit-atom level view of
the world with the document-jaguar level.  People don't have to interact with
bits any more than they have to deal with atoms.  The properties you are
seeking are at a higher level than bits and are already in early development
(OpenDoc and others).   The "information assembly line" is at this higher
level and does not require "flits".
Thanks for a provocative note.

@_date: 1996-07-12 05:54:28
@_author: Jeff Williams 
@_subject: Re: ANNOUNCEMENT: PGPfone Beta 7 Now Available for Download 
Does the Blowfish implementation address the weakness described
Warning:  Blowfish can be cracked.  (I apologize for
the sensationalism.  I also apologize if this has
been mentioned before.  This needs your attention.)
I have found a way to crack 80 bytes of ciphertext encrypted with the blowfish algorithm (ECB mode), 25% of the time.   Blowfish, as printed in "Applied  Cryptography, Second Edition", and as corrected in Bruce Schneier's Errata Sheet, using a randomly generated 64 bit key, can be cracked in much less than 10 minutes on a Pentium 120MHz (10 minutes is worst case).  According to my calculations, with optimizations, I could cut this down to about 5 seconds to 2.5 minutes worst case.
I investigated this further, and it turned out
to be a source code implementation error.
There is an implementation error in published
Blowfish Code. The program chokes on the commented  "choke" statement, below:
bfinit(char *key,int keybytes)
It chokes whenever the most significant bit
of key[j] is a '1'.  For example, if key[j]=0x80,
key[j], a signed char, is sign extended to 0xffffff80 before it is ORed with data.   For examle, when:
- -and-
data=0xffffff80 (0xffffff81,etc.) upon exit from the above "for(k=...)" loop.  ORing all of these 1's into data effectively wipes out 3/4 of the key characters!  (that is, 3/4 of the key characters are known to be set to 1 when the 4th key byte to be ORed into data has a 1 in the most significant bit.)  For a randomly selected 32-bit key, there is a 50% chance that 3/4 of the key could be considered as all '1's, even if they weren't that way to begin with. This is obviously a security issue.  Note, contrary
to my previous statement, the key length in bytes
_does not_ need to be divisible by 4 to exploit this
implementation flaw.
The following fix has been verified to work:
Another fix is to declare 'key' as 'unsigned char *'.
Other fixes are possible.
NOTE:  Most test vectors will not check for this bug        because they use keys comprised of ASCII        (value<0x80) strings.  This bug does not show
       up when every character in the key has a value
       less than 0x80.
This should be corrected and noted in the source code for blowfish.  Also, test vectors with unsigned character values greater than 0x80 should be generated and published.
I did not notice this bug in the "Applied Cryptography"
errata.  It should be noted there, too.
This flaw may or may not be present in other implementations of the Blowfish algorithm.  Thanks to non-standard use of
the 'union' construct, I think others who use blowfish may
or may not have avoided this bug.  In cases where this bug
has been avoided, it may have been done purposefully or
Mike Morgan, 			Hardware Engineer
Digi International, 		mmorgan
