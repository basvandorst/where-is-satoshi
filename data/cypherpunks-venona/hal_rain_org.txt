
@_date: 1996-10-11 21:25:38
@_author: Hal Finney 
@_subject: Re: AW: Binding cryptography - a fraud-detectible alternative to key-esc 
Another flaw with schemes of this time (in terms of failing to meet their
goals) is that they cannot detect superencryption and other forms of
non-standard encryption of the message body proper.  All they can really
do is verify from the outside that the same session key is encrypted for
the two recipients (the intended recipient and the Government Access to
Keys Party - let's not abuse the term by calling him a Trusted Third
Party).  But they can't be sure that the session key is sufficient
information to decrypt the message.
The session key could itself be a PK encrypted form of the actual
message session key, so that the true recipient would have to run the PK
decryption algorithm through two iterations before he actually got the
real message session key.  Or the message could be simply superencrypted
using a non-escrowed encryption system, then encrypted using the GAK
technique so that it looks fine from the outside.
These kind of techniques could be detected by the recipient, but as
Adam Back points out there are much simpler techniques if we just want
the recipient to be able to tell whether the key has been encrypted for
the GAKP.  For that matter if *he*'s really concerned about it he can
forward the plaintext to whatever governments he likes.

@_date: 1996-10-12 13:59:32
@_author: Hal Finney 
@_subject: Re: pgp, edi, s/mime 
I have recently gone to work for PGP, Inc.
PGP 3 will support both discrete log and RSA cryptography.  It will
interoperate with both, so that when you send a message to someone
who has an RSA key, it will use RSA, and when you send to someone who
has a discrete log (El Gamal/DSS) key, it will use discrete log
algorithms.  So there is full compatibility with existing keys, while
allowing people to move to cryptography which will be patent free
in the U.S. after next year.
A free version will be available with this functionality, with
source code.  Existing users of PGP will hopefully find it easy
to upgrade.
I cannot say when it will be available, other than to say that the
functionality exists for generating and using all these kinds of keys,
and we have four programmers, including myself, working full time on
getting this version out.

@_date: 1996-10-13 11:04:10
@_author: Hal Finney 
@_subject: Re: pgp, edi, s/mime 
Thanks for the kind words about my participation with PGP Inc.  My comment
was really meant more as a disclaimer, though.  Realize that I am now
a corporate employee in the field rather than a hobbyist, so set your
mental filters accordingly.
Also, my activities right now are mostly a matter of helping with the
finishing touches.  Hard work over the past couple of years by Colin
Plumb and Derek Atkins has produced the bulk of the code base for PGP
3 and the follow-on products.
Still it is very exciting and gratifying for me to be working in this
field which I love and which is so important, and I am enjoying it
very much.

@_date: 1996-10-13 22:34:50
@_author: Hal Finney 
@_subject: Re: Blinded Identities [was Re: exporting signatures only/CAPI] 
The "blinded identities" problem is one of the oldest that we have
discussed here (although not much recently, of course!).  It is basically
similar to what cryptographers call "blinded credentials" and is closely
related to electronic cash, as Michael Froomkin's example from Stefan
Brands points out.  I posted an idea a few years ago for how to use the
technique to solve the related problem of remailer abuse.
A simple way to approximate what you want is to use a standard blinded
signature exactly as is done with David Chaum's DigiCash.  The customer
comes to you and presents some proof of identity.  This may be in
person via standard paper documents, or on-line via some cryptographic
credential as you suggested.  You make a list of all of your customers,
and make sure that this customer is new, someone you haven't seen before.
Now you simply give him a blinded cryptographic signature, of exactly the
same form as the blinded coins given out by DigiCash.  He unblinds it,
and he is left with a signed credential from you, but one which is
unlinkable to his identity.
When he interacts with you, he displays this credential as proof
that he is a customer in good standing.  If he violates the terms of
your contract, you disable the credential (add it to a list of bad
credentials).  He can't use this one any more, and he can't get a new
one because he is on the list of people who already got their credential.
This simple solution suffers from several problems, some of which are
endemic to this class of solutions and others which can be addressed
with fancier crypto.  Among the fundamental problems we have first that
verifying identity reliably is difficult to impossible.  If people are
motivated badly enough, they can forge whatever documents they need.
Then they keep signing up with new identities like the kids who use
AOL throwaway accounts.
Second, if the customer ever loses his credential, he is screwed.
He comes to you with some sob story about how his disk crashed and his
dog ate his backups, but you have no way of knowing if he actually lost
his credential, or if he is an abuser who got his credential cancelled.
Another problem is that groups of users can share credentials, so that
some hacker club can get a bunch, one for each of them, and then they
can all abuse your ISP, getting credentials cancelled, but able to keep
going as long as one is left.
Problems which can be fixed include that credentials could be stolen,
like phone card numbers, so an innocent person gets his credential
cancelled and then we are back to the second problem above.  You can
mostly solve this by having him create a key when he first registers
with his credential and require all his interactions to be protected by
this key.  There are also more elaborate solutions where he wouldn't
actually send his credential over, but use zero knowledge techniques
to prove that he had one.
Unfortunately David Chaum has a pretty good set of patents covering
blind signatures, so for a commercial venture you'd probably have to look
into the legal situation.  I can send you a list of Chaum's patents in
the area if you want it.  (I had it on my web page but my ISP quit so
I need to get a new page going.)
Some of the other practical issues are also mentioned in Michael
Froomkin's article, like waiting a while after you get your credential
before you use it.

@_date: 1996-10-14 11:37:48
@_author: Hal Finney 
@_subject: RE: RE: Binding cryptography - a fraud-detectible alternative to 
I have not read your paper, but let me illustrate via what may be
a similar scheme how criminals can use the key management infrastructure,
create messages which look good from outside, yet which still cannot
be read by the GAK (government access to keys) people.
In ElGamal encryption we start with a message session key M which we
want to send across.  We have the public key y1 = g^x1 of the recipient
(^ is exponentiation).  We choose a random blinding factor xm, and
calculate ym = g^xm.  We send ym and M * (y1^xm).  y1^xm equals
g^(x1*xm), and the recipient can recover this by ym^x1.
Now with two recipients, if we choose the same blinding factor xm for
both, we send ym = g^xm, and both M * (y1^xm) and M * (y2^xm).  We use the
two different recipients' public keys y1 and y2.  I believe this can be
checked from outside by taking the ratios of these two factors (y1/y2)^xm
and using known methods to prove that this is of the proper form.
This can be circumvented though simply by replacing M, the true session
key, with M' = M*(y1^xm), where y1 is the intended recipient (and y2 is
the GAK party).  We send M'*(y1^xm) and M'*(y2^xm).  Outsiders still
verify that this is of the proper form.  And the intended recipient
can calculate the true M by dividing twice by y1^xm instead of once
(in effect M' is the El Gamal encryption of M for party 1).  But the GAK
party, who gets M'*(y2^xm) and recovers M', finds it useless in trying
to decrypt the message.
This shows how keys from a standard infrastructure can be used in a
slightly non-standard way to confound your scheme.  Granted, the parties
involved have to share knowledge about using the keys in this non-
standard way, but that is only one bit of information and not at all
hard to distribute.

@_date: 1996-10-17 15:35:09
@_author: Hal Finney 
@_subject: Re: Anonymous Auth Certificates [was: Re: Blinded Identities] 
(Sorry about quoting so much, but I liked Steve Shear's succinct problem
I don't see how authorization certificates solve this problem.  How
would you determine if someone was qualified to receive an authorization
certificate?  And what would you do to make them stop using the service
if they abuse it, and to stop them from getting new authorization

@_date: 1996-10-21 07:04:39
@_author: Hal Finney 
@_subject: Re: Anonymous Auth Certificates [was: Re: Blinded Identities] 
(Sorry about quoting so much, but I liked Steve Shear's succinct problem
I don't see how authorization certificates solve this problem.  How
would you determine if someone was qualified to receive an authorization
certificate?  And what would you do to make them stop using the service
if they abuse it, and to stop them from getting new authorization

@_date: 1996-10-18 08:21:12
@_author: Hal Finney 
@_subject: Re: Anonymous Auth Certificates [was: Re: Blinded Identities] 
Yes, biometric data is another way of preventing multiple credentials.
However it will not work well in electronic form.  What you'd need would
be a network of stations to take fingerprints and give credentials,
("is a person" credentials) which would then be used for getting access
to other services where you're supposed to only use them once (voting
for example).  This requires a fairly elaborate infrastructure and social
commitment to this solution to the problem.
Somehow too it is hard to see how to sell a system as a privacy enhancement
when its first step is to take fingerprints of the whole country.  "But
we're not saving your names, honest!"  I don't know if it would fly.
Tim May argues that alternative solutions which are more local will be
better.  In the case of the abuse situation, maybe you could just have
people put down a deposit of $100 or so.  Then they get an anonymous
credential which they can use for access.  If they abuse their access,
their credential gets disabled.  As long as their abuse is worth less
than the deposit you'll be OK.  And at any point they can turn in their
valid credential and get their money back.  No identities are needed at
any point in the scheme.
Actually I think you need to use a blinding protocol when you acquire
the certificate, rather than trying to run a one-way function on the
unblinded cert.  The output of a one-way function looks random and
meaningless unless you supply the input.  And if the input identifies
the user then you've lost the anonymity.

@_date: 1996-10-22 09:12:04
@_author: Hal Finney 
@_subject: Re: one-body, one-cert 
[This is picking up a discussion from the SPKI list on the topic of
anonymous credentials.  I think cypherpunks is a more appropriate forum.]
I think in a system like this, participants would need to understand the
limitations and design the protocols with them in mind.  Ideally, getting
access to someone else's keys would be made very difficult, more so than
it is today, since the consequences could be so much more drastic.
It would be as though evil spirits roamed the world and could invade the
consciousness of careless people, taking over their bodies and forcing
them to commit horrendous acts.  In such a world we could expect people
to take whatever careful precautions are possible to avoid such threats.
Furthermore, systems which apply punishments for bad behavior would have
to be aware of the possibility of such occurances.  It would generally
not be appropriate to impose draconian consequences for a single bad act.
Rather, the possibility would always have to be considered that such
actions were not the fault of the apparent perpetrator.
We might expect to see systems in which single instances of misbehavior
are forgiven, but patterns of repetitive bad conduct are punished.  I
believe protocols similar to the ones Jim McCoy mentioned from Chaum
can provide very flexible (although possibly inefficient) means for
controlling credentials in a variety of ways.
In the context of limited-participation credentials, then, a reasonable
policy would be not to strictly cut off anyone who broke the contract,
but rather to consider extenuating circumstances.  For example, if a
credential is stolen and the owner is aware of it (say it is locked in
a hardened smart card), and he can prove that he made a good faith effort
to notify service providers that they should invalidate the credential,
then this would excuse misbehavior.  Even without this kind of evidence,
it may be appropriate to give people a limited number of second chances.
True, this allows an unscrupulous person to violate the rules some
number of times and get away with it.  However this may be tolerable
as a generally low level of background noise.  No society is perfect.
Being able to largely deter contract violations while still maintaining
privacy for the participants would in my opinion be superior to the
world we seem to be heading towards, one in which dataveillance, profiling,
and tracking are the norm.

@_date: 1996-10-22 14:51:10
@_author: Hal Finney 
@_subject: Negative credentials 
There has been some discussion here and on the Simple Public Key
Infrastructure (SPKI) mailing list about anonymous credentials and
abuse.  This is something we have of course talked about many times
over the years but I don't think we have ever had a specific look at
Chaum's approach to the "negative credential" problem.
In essence his method allows you to prove that you haven't cheated on
any of your contracts, without revealing any more about yourself than
that.  Chaum uses what he calls "sequenced couples", which are
sequences of pseudonym pairs such that credential A on one pair of the
sequence can be transformed by the user into credential B on the next
pair.  This ties into his whole scheme, which is a bit too complicated
to explain here.
What I will describe is a very simplified version of what Chaum has.
Chaum's description can be hard to follow but takes care of a lot more
possibilities.  His full paper, which BTW is my favorite crypto paper
of them all, is:
   "Showing Credentials Without Identification: Signatures Transferred
   Between Unconditionally Unlinkable Pseudonyms," D. Chaum, Accepted but
   not Presented Auscrypt '89.
The general idea is this.  Every time you engage in a contractual
relationship with someone it is done under the auspices of an
"anonymous credential" organization.  You first show your contract
partner a credential from the AC org which guarantees that you have
not cheated anyone so far.  After you participate in your current
interaction, if it completes to everyone's satisfaction, you are given
a new credential by the AC org which proves that you still haven't
cheated.  Each credential can only be used once, so if you cheat
someone you can't get a new one.
There is a simple and obvious solution which satisfies these
requirements.  That is to use a blinded signature exactly as is done
with DigiCash coins.  You get your first credential on registering
with the AC organization.  (Here we have a bit of a bootstrapping
problem, in that the AC org needs to make sure you don't register more
than once.  But actually since things will be blinded you can just
use your SS# or other identity documents.)  The credential is a blind
signature, unlinkable to your identity.
When you go to contract with someone, you show your credential and the
AC confirms that it hasn't been used before (exactly like checking for
double spending on coins!).  The AC marks the credential as being in
the "in use" state (putting it on its own private list of such
credentials).  Then when your contract completes successfully, your
partner certifies this fact to the AC, and it then retires your old
credential and issues you a new, freshly blinded credential.  This
credential is unlinkable to your earlier one or to your identity, but
it proves that you haven't cheated and you can show it the next time
you need to make a contract.
Now, obviously this simple solution has problems:
 - You can transfer credentials to other people.
 - You could get cheated by your contract partner who won't authorize
   a new credential for you even though you completed your contract.
 - There is no way of distinguishing someone who's done dozens of
   successful contracts from someone who's done only one.
 - You can only have one contract going at once.
Although this solution is somewhat simplified, hopefully it will give
people a picture of how negative credentials can be dealt with while
still retaining full anonymity in contract relationships.

@_date: 1996-10-24 11:23:14
@_author: Hal Finney 
@_subject: Re: Netescrow & Remailers? 
Up until now, when remailers have gone down it has not been in a
circumstance in which escrow would help much.  Generally they are
taken down voluntarily or at the request of someone in authority
(the owner of the computer they are running on, in many cases!).
In these situations there would not be a problem in transferring
the key to someone else.
There have been a couple of times, particularly early in a given
remailer's life, where people have clumsily deleted their remailer's
key and had to create a new one.  In such a circumstance a secure
backup capability would be useful.  But you don't really need the
kinds of recovery that Matt's idea provides.
Conceivably a remailer operator could be dragged off in chains, but
it doesn't seem like a very probable scenario.  Even then more
traditional secret sharing based distributed backups would seem like
a better fit than "net escrow".  The main distinguishing feature of
the latter is that society as a whole can choose to release a key
without the owner's approval, but not any lesser group.

@_date: 1996-10-31 07:24:40
@_author: Hal Finney 
@_subject: Re: Privacy Issues 
I recommend the web/gopher site managed by Chael Hall and Karl Barrus.  It has a collection of articles
from the early days of the cypherpunks list when we initially explored
a lot of the ideas which are getting rehashed today.  In fact, I
would recommend this to all new readers of the list in order to
understand what has been discussed before and what some of our goals
have been.  Looking back, some of the essays seem a bit naive in our
hopes and expectations for what crypto would do; things have turned
out to be more corporate, more political, less grass-roots, than many
of us expected.  But the basic issues have remained much the same.

@_date: 1996-10-31 09:17:09
@_author: Hal Finney 
@_subject: Discrete logs 1 
"Even adders can multiply using log tables..."
PGP is moving to discrete log based cryptography.  It will still
support RSA, but people will be encouraged to generate discrete log
keys.  It will use RSA to encrypt to people with RSA keys, and
discrete log crypto to encrypt to people with discrete log keys.
Many discrete log cryptosystems will be patent free after next year.
It may be that they will become more popular over the next few years
for that reason.  RSA has several more years before its patents
Most people are not as familiar with the math behind discrete logs as
they are with RSA.  The general idea of the difficulty of factoring is
pretty easy to understand.  It's much easier to multiply two large
primes together than to figure out what the primes were just by
looking at the result.  Discrete logs require a little more
First I am going to write a little bit about the lore of logarithms.
I think today a lot of people don't know what they are.  When I was a
boy, in the 1960's, computers and even calculators were not widely
available.  Yet engineers in many fields needed to perform
calculations.  Reaction rates, material strengths, friction, current
flow, all such calculations require multiplication and division of
numbers with several significant digits.  The choices were basically
to multiply it out the long way, which was slow, error-prone, and
wasteful because it generates twice as many digits as you need; use a
slide rule, which usually only gets you two or three digits of
accuracy; or to use log tables, which could get you four or five, or
sometimes even more, accurate digits.
The logarithm of a number is the power that you have to raise some
specified base (usually 10 for these purposes) to in order to get that
number.  The logarithm of 100 base 10 is 2 because 10**2 = 100.  The
log of 1000 is 3.  For numbers not powers of 10, the logarithm has
fractional parts.  The logarithm of 20 is about 1.3, for example.  To
multiply two numbers, you find their logs and add them, and then turn
the result back into a number.  To divide, subtract the logs.  So most
of the work is just in looking up what the logs are using published
Actually we do use logs in a crude form in much of cryptography.  Any
time you say that the product of two 512 bit numbers is 1024 bits what
you mean is that the log base two of the smaller numbers is about 512,
and so the log base two of their product is 512+512 or 1024.
By the time I was in high school calculators were becoming fairly
widespread, but we still learned how to use log tables to do
multiplication and division.  Whole books were published containing
nothing but tables of the logarithms of numbers.  You can still find
these sometimes in used book stores.  There were lots of tricks to
using these tables which we had to learn.  Logarithms of numbers less
than 1 are negative, but the trick was to treat them as the sum of a
positive fractional part and a negative integer, so for example the
log of .2 was treated as +.3 - 1.  This made it easier to look up the
values.  And there were special sub-tables within the tables to help
with interpolating, looking up log values between the entries in the
table.  Using these you could get more accuracy in your answers.  All
this was part of the craft of working engineers and scientists of the
It's hard for people today, raised on throwaway and even virtual
calculators, to understand the sense of power that came from using
logs for calculations.  Until we learned these advanced techniques the
only accurate alternatives were the terribly tedious hand methods.
Being able to get results by adding up a few numbers from a book was
an amazing improvement.
The discrete logs used in crypto have very different mathematical
properties than regular logarithms, but I thought this bit of history
would spark some memories in old-timers and give a new perspective for
younger people.

@_date: 1996-11-11 10:39:40
@_author: Hal Finney 
@_subject: Re: Secrecy: My life as a nym. (Was: nym blown?) 
Black Unicorn makes a lot of good points regarding privacy.  One thing
I wanted to follow up on:
I have two kids entering their teens, and I'm sure other list members are
parents as well.  What can we do for our children to help them enter their
adult lives with better chances to retain privacy?  Unicorn mentions keeping
them absent from school on picture day, although I'm not sure how much this
helps.  I suppose it makes it harder for an investigator to find out what
they look(ed) like.  Then when they get old enough to drive you have a new
problem avoiding the photo (and thumbprint) on the license.
Are there other measures which parents could take while their children are
young to get them off to a good start, privacy-wise?

@_date: 1996-11-11 10:39:52
@_author: Hal Finney 
@_subject: Re: Rarity: Crypto question enclosed 
There are a few things available or in the works right now.
Most of the PGP key servers respond to WWW requests already.  You connect
to them on a port, the HTTP port, send some standard textual commands
following the HTTP protocol, and get the requested PGP keys back in text
form.  How does this differ from what you were thinking of?
Other proposals, including Ron Rivest's SDSI, envision an environment where
most people make their own keys available via a URL.  Certificates would
have this URL in them and you could check it to make sure the key has not
expired or been revoked.  Then the only problem is distributing the URL...
John Gilmore's SWAN project is working to put keys into Domain Name System
(DNS) databases.  He has sample code which will get keys dynamically via
DNS calls, and DNS servers are now available which will support the new
data types necessary.  You can actually get his own key right now from
toad.com via this method.  This is a binary protocol rather than a textual
one but could be a good way to do it.
So I think you are right that on-the-fly key grabbing is the direction
in which things are moving, replacing large local databases of keys.

@_date: 1996-11-11 10:41:36
@_author: Hal Finney 
@_subject: So how does the crypto crackdown go? 
I've enjoyed Peter Hendrickson's provocative postings and the many good
responses.  However I don't think we should forget that the FBI and
other law enforcement agencies almost certainly do hope to ban strong
encryption in the U.S. and in other countries as well.  So it is worth
discussing how the ban is likely to happen and what impact, if any, it
would have.  I could see such a measure going into effect after the next
terrorist attack as part of a comprehensive bill that also includes
taggants in explosives, more permission for wiretaps and surveillance of
terrorists, and similar items on the LEA laundry list.
Keep in mind the effects of the current ban on U.S. exports of crypto
technology.  Obviously this have not stopped crypto from moving
overseas.  But it has definitely had significant effects.  It is _not_
widely ignored, at least in public.  That is why we work so hard to
overturn it; if it had no effect, we wouldn't care.  Companies are much
more careful about how and whether they will distribute crypto on the
net; for many months Netscape's free software didn't have strong crypto;
Americans even on this list are afraid to publish algorithms and envy
Adam Back's freedom to do so.
My guess about how a crypto ban would go is that it would be an extension
of the export ban, and be based on interstate commerce regulation.
It would ban distribution of crypto software, commercial, freeware,
and shareware, which had the ability to hide the content of messages.
Exceptions would exist along the lines of the recent export proposals,
where the software would be OK to use if it had a small key size with
an approved cipher, or other means to ensure law enforcement access.
The ban might also cover stego and stealth type software, at least if
that were the primary purpose of such programs.  The U.S. would also
work to convince foreign countries to implement similar bans.
One question is whether they would also try to make it illegal to use
(rather than to distribute) crypto software.  On the one hand, if they
don't do that, they have a problem with all the installed base of code.
But the legalities of stopping people from encrypting code on their own
computers, or writing crypto programs for personal use, seem a lot more
questionable to me, and I don't know how much precedent there would be
for that kind of restriction.
So as I see it the main target of the ban would be distributors of
software rather than end users.  This would be in line with the often
stated goal of the law enforcement people that their main concern is with
crypto that is built in, transparent, and trivial to use, rather than
hacker's crypto.
So what are the impacts of this kind of ban?  They might not be all that
bad.  Already on the net Americans have to be careful about what they
say.  We can't describe crypto algorithms because they might leak
overseas.  With a ban on domestic distribution we would still be
prevented from talking about crypto.  So this is not very different.
Commercial companies building in crypto would have to go back to
escrowed or weak encryption.  All those export controlled sites would
treat Americans the same as foreigners and prevent them from getting
the strong crypto.  The few commercial products sold in the stores which
do crypto would have to be changed.  Strong crypto might be distributed
via an underground network, but this would be about as risky as running
Internet sites that export strong crypto is today.   There are very few
such sites, although granted there is little call for them because
overseas crypto sites are widely available.
The end result is that almost nobody in the U.S. would have access to
strong crypto, except for the motivated few who write their own, keep
old strong versions around, or obtain new strong software illegally.
This sounds bad, but as far as actual _users_ of strong encryption it
is not so different from the way things are today.  Weak/escrowed crypto
would still be widely used and built in to communication software.
The big question in my mind is whether they could get away with banning
the use of strong crypto rather than its distribution.  This would be
much more effective from the law enforcement perspective.  But they
have not tried this so far even for international messages, presumably
due to the serious Constitutional questions it would raise.

@_date: 1996-11-13 09:30:27
@_author: Hal Finney 
@_subject: Re: So how does the crypto crackdown go? 
This is a very helpful and thorough analysis.  However it does not address
the possibility of a ban on the sale/distribution of strong crypto, rather
than a ban on its use.
There are several reasons why I think the former is more likely:
 - PRECEDENT FROM ITARS
   The current bans on export of encryption software limit the distribution
   of the software itself, not of encrypted messages.  Extending this ban
   to domestic distribution would imply banning distribution but not use
   of crypto software.
 - NOT A PRIVACY ISSUE
   The privacy issues would be much less relevant because it is no longer
   a matter of just what you do in the privacy of your own home.
 - OUT OF THEIR OWN MOUTHS
   The Clinton administration's original veiled warning, quoted in
   Michael's paper, denied that "every American, as a matter of right,
   is entitled to an unbreakable commercial encryption product."  Noting
   the use of "commercial" this suggests a ban on sales rather than
   use.
 - COMMERCIAL REGULATION
   Not being a lawyer, I can only speculate that the interstate commerce
   clause would give more justification for a ban on distribution than on
   use.
 - FOOT IN THE DOOR
   Conceivably such a ban, if successful, would provide new arguments for
   advancing to the second stage of a ban on usage after some time.
   The impact of the usage ban would be less due to the lack of access
   most people would have to such software, and the (arguably) demonstrated
   effectiveness of the government approved software almost everyone would
   be using by that time.
 - BIG BROTHER IS WATCHING
   We have long speculated that the government's real interest is in
   making mass surveillance more practical, with the stated concerns about
   criminals being merely a convenient cover.  Commercial restrictions
   would be consistent with such motives since they would have more
   impact on the innocent many than the motivated few.
A ban on sales and distribution could still be opposed on First Amendment
grounds, especially if it becomes established that software is speech.
Still there are many restrictions possible on commercial speech so even
a favorable precedent in this area would not preclude some regulation of
software distribution.
We could also argue that such a ban is de facto equivalent to restrictions
on use, since most people would not then have access to privacy preserving
software.  In that case the many excellent arguments which Michael brings
forward to oppose such restrictions would be relevant.
And what would be the implications for freeware crypto?  Could
distribution of such software be subject to regulation in the same way
as commercial programs?  Then there are the issues relating to speech
about crypto which are currently being litigated.  Presumably domestic
restrictions on such speech would have to reach a much higher standard
of demonstrated need than restrictions on export.
For these reasons I think that domestic regulations on the sales
and distribution of strong crypto would not be a sure thing for the
government, but would be a lot easier for them than restricting use.
This suggests that it is a likely direction for them to take after the
next terrorist attack.

@_date: 1996-11-13 21:00:52
@_author: Hal Finney 
@_subject: RE: Remailer Abuse Solutions 
I had a similar thought a few months ago.  Actually with DigiCash there
is a specially nice feature from the point of view of the remailer.
Suppose the cash is embedded in the message headers itself.  The remailer
receives the message with the cash in it, turns it in at the bank to
make sure it is good, and withdraws a new blinded coin which it sticks
in the headers of the outgoing message.  The eventual recipient of that
message can then have his software turn in that coin and if it is good
that raises the priority of the message for him to read.
The nice thing is that if the recipient doesn't have the DigiCash software,
he will never cash the coin.  That means that the remailer can, after a
delay, reclaim uncashed coins for its own use.  It doesn't have to charge
postage explicitly, but it benefits as a middleman from unclaimed postage.
This would also of course encourage people to learn to use digital cash
so they could take advantage of these pennies from heaven in their

@_date: 1996-11-15 17:23:31
@_author: Hal Finney 
@_subject: National Emergency 
Michael Froomkin posted to the cyberia list a pointer to the Clinton
administration's new export policy.  He has a copy on his web site at:
.  The thing
I found interesting is that it refers to the fact that we are currently
living under a state of national emergency!  I searched on the whitehouse
web site and couldn't find the executive order referred to (maybe it was
classified) but did find this one:
Apparently this state of emergency is still in effect.  This is what
gives the President the power to unilaterally make changes in the export
policy.  It would be nice if our congresspeople would take some
responsibility in this matter.

@_date: 1996-11-15 20:34:34
@_author: Hal Finney 
@_subject: Re: Playing Cards 
I heard that Bruce Schneier has devised a cryptosystem based on a card
deck for a future book by Neal Stephenson.  It is supposed to be simple
enough for a person to use manually, but complicated enough that it can't
be broken by computer.  Your idea of using cards as a one time pad is
somewhat similar, maybe, although I think Bruce's was designed to be
useful for long messages, providing computational rather than unconditional
This is very interesting; I've never seen this algorithm before.  It
is a nice way to turn a number into a permutation, and vice versa.
This would be 4*4! + 2*3! + 1*2! + 1(was 3)*1! + 0*0!, or as you say:

@_date: 1996-11-16 08:07:22
@_author: Hal Finney 
@_subject: Re: Remailer Pricing 
I agree with this very much.  For a long time we have had two contradictory
notions floating around: nobody will pay for remailing services because
free ones are available, and the remailer network can't be reliable because
the operators don't have the resources to make them work better.  Clearly
if people understand that the choice is between free remailers that don't
work well and for-pay ones which do, things look a little different.
Peter's idea of having the remailers keep accounts for people receiving
anonymous mail, possibly even sending them a monthly check, would
completely change the spam equation.
Actually when I ran a remailer I had a small key because it was on a system
which I did not control.  The small key was meant as a signal to potential
users that my system wasn't all that secure.
The big problem that I always saw with the for-pay remailing model was
the fear of greater liability when abusive mail goes through the remailer.
I felt that operating a service for free would make it easier for me
to argue that I was offering a public service, while running it for pay
would mean that I would be profiting from the abuse.  I don't know if
this is really a valid argument, though.

@_date: 1996-11-16 10:46:36
@_author: Hal Finney 
@_subject: Re: Members of Parliament Problem 
I don't quite follow how this would work.  If Trent issues a blind
signature, then that means (doesn't it?) that he doesn't see what he
is signing.  So how can he confirm that the message is actually from
a member of the group when he doesn't see it?
Not all of Chaum's proposals in the original paper from Eurocrypt 91
have this property.  Here is what he has, somewhat simplified.  Z is
the trusted party for those protocols which use one.
1) Each group member makes up a key which he will use for one signature.
Z signs each key to certify that it is a member of the group.  People
don't re-use keys so that messages are unlinkable.  Z can tell who sent
which message since he knows the keys.
2) Z publishes an RSA modulus N, gives each group member a secret exponent
si, and publishes v = the product of all the si.  Members sign message m
by producing m**si mod N.  Then to confirm the signature they engage in a
zero knowledge protocol to prove that the signature is of the proper form
and that si divides v (without revealing si).  Chaum gives a protocol for
3) Z again publishes an RSA modulus N, and each group member chooses his
own RSA modulus Ni = pi * qi.  To sign message m he produces m**pi mod N.
He then proves in zero knowledge that the signature is of the proper
form and that pi divides the product of all the Ni (without revealing pi).
This is the same zero knowledge protocol as in (2) above.
4) Members agree on a large public prime p with generator g.  Each member
chooses a secret exponent si with public key ki = g**si mod p.  (This is a
standard discrete log cryptosystem setup.)  To sign message m he produces
m**si mod p.  He must then prove in zero knowledge that the signature
is of the proper form and that si is the private exponent corresponding
to the public key of some group member, without revealing exactly which
group member it is for.  The protocol for this is not very efficient.
It uses a cut and choose concept and has to be iterated multiple times.
In methods 1, 2, and 3, Z can tell who made a signature.  In method
2, Z can forge signatures for other members.  Method 4 doesn't use
a trusted party.
Method number 4 is very similar to Chaum's original proposal for
undeniable signatures, although the zero knowledge proof is very different
since he doesn't want to reveal which particular key his exponent
corresponds to.
In the Eurocrypt 94 paper by Chen and Pederson they show a very nice
protocol for proving that you know the exponent corresponding to
one of a set of Diffie Hellman public keys.  This is similar to the
problem in (4) above.  Given k1=g**s1, k2=g**s2, ..., you can prove
that you know one of the si without revealing which one.  The protocol
is pretty simple and just requires one challenge and response, although
the amount of data sent is proportional to the number of ki in the set.
This could be used to prove group membership anonymously.  If there
were a list published of public keys of people on the cypherpunks list,
you could prove you were on that list without revealing your identity.
I think it could be made a signature protocol by having the challenge
c depend on a hash of the message.  But the authors don't do it that
way, they do a more complicated protocol because they are seeking to
achieve unconditional rather than cryptographic anonymity.

@_date: 1996-11-16 10:48:22
@_author: Hal Finney 
@_subject: Re: Remailer Abuse Solutions 
This digital cash scheme has a big disadvantage which the authors try
to play down.  The problem is that all spending by a particular user is
linkable.  It can't be connected to his True Name but all of it is
linked, in effect, to his nym.  This is bad because it allows profiling
and dossiers to be built up about nyms with interesting spending patterns,
which could then be used to identify which ones should be candidates
for intensive efforts to discover their identity.
Most other digital cash schemes don't allow linkability of the payor's
activities, which is a much better approach.

@_date: 1996-11-16 11:14:09
@_author: Hal Finney 
@_subject: Re: San Jose Mercury News declares encryption battle over 
So it sounds like the idea is to build crypto around card tokens.  I think
HP has been pushing this for some time.  The question is, will this somehow
become the only way to get access to crypto?
Unlike the earlier IBM/CIA announcement, this time Netscape and Microsoft
have apparently been brought on board.  That is a lot worse because these
companies are where most people are going to get their crypto in the future.
If they have open standards, we can make good crypto available.  But if
this announcement signals some kind of closing of the system so that only
hardware tokens will be used, it could become a lot harder to make strong
crypto available.
There are also the economic questions about how much these key cards are
going to cost, and whether they are going to be routinely supplied with
computers or an extra cost item that consumers have to go out and buy.
If the latter, a lot of people won't bother, and we'll just have that much
larger a barrier to widespread use of crypto.
It is certainly very disturbing to see these new moves.  Obviously a great
deal of behind the scenes negotiations and pressure has been occuring.
You have to wonder why Netscape, for example, would forego the opportunity
to differentiate themselves from rival Microsoft by positioning their product
as the one which refuses to bow to government pressure on crypto.
It's also not clear what the hardware manufacturers get out of this.
Their sales overseas have never been blocked.  There has been no demand
for custom crypto hardware.  I don't see how they have been harmed by an
inability to ship computers with built-in encryption hardware.  Granted
there are some possible applications for such systems but I don't see the
market demand which would drive this decision.

@_date: 1996-11-16 11:17:41
@_author: Hal Finney 
@_subject: PGP acquires PrivNet 
The company I work for, PGP, Inc., announced yesterday that it had bought
PrivNet, makers of Internet Fast Forward cookie-blocking software.  More
info is on the PGP web site at   Personally I have a
passionate and irrational hatred of cookies so I am very glad to see this
move!  I can accept them if I'm browsing through an online store and they're
being used to keep track of what I've bought, but so many sites these days
are just snoopy as far as I can tell.  Down with cookies!

@_date: 1996-11-16 22:25:26
@_author: Hal Finney 
@_subject: Re: Members of Parliament Problem 
We had quite a bit of discussion of Brands' technology on the list a
couple of years ago.  Take a look at which has several pages discussing discrete logs and some of the ideas
behind Brands' protocols.  Unfortunately I am getting cut-off versions
of these pages tonight, along with occasional failures to find a route
to this server, so hopefully it is just the net acting up again.

@_date: 1996-11-16 22:32:55
@_author: Hal Finney 
@_subject: Re: Remailer Abuse Solutions 
I had proposed a similar idea to this a few years ago.  You would dispense
tokens, each of which needed to be included in an anonymous message.
So this prevents spam.  But it can also deal with abuse.
After sending the message, if it was not abusive, a new blinded token
would be broadcast which could only be decrypted by the sender of the
original message.  But if it was abusive, no new token would be sent.
Remailer users would watch these token broadcasts and get their new
tokens each time they sent a message.  The remailer might have to delay
issuing the replacement tokens for a day or two to give the recipient
time to complain.
If you gave everyone in the world an initial supply of a few tokens,
then every time they abused, they'd lose one.  But as long as they use
the remailer reasonably they can continue to use it forever because they
get a new token for each one they use.  Messages still remain completely
unlinkable and the remailer has no way of learning anything from the
tokens it sees since they were all issued in blinded form.

@_date: 1996-11-16 22:49:20
@_author: Hal Finney 
@_subject: Re: The Utility of Privacy 
David Brin has an article in the December issue of Wired arguing that
privacy is obsolete and was never that great an idea in the first place.
I corresponded with him a few years ago when he was working on a draft
of a book which would develop this idea.  Needless to say, I disagreed
with many of his views.  Here is an excerpt from a letter I sent to him
where I defended the notion that privacy is valuable:
You suggest that the main motivation which someone might have for protecting
privacy is that they are engaged in some illicit activities:
page 45: "Why should I really care if someone sees this?  I have nothing to
But aren't exceptions to this quite common in real life?  What about the gay
man who doesn't want to come out of the closet?  What about the
environmentalist who works in the clerical department of an oil company with
little tolerance for such beliefs? What about the closet atheist in the
fundamentalist Midwestern town?
Maybe you'd say that all of these people should expose their secrets, or have
them exposed for them, and that the world would be a better place. (Actually,
you do seem to say this, and I'll discuss it later.)  But I think this assumes
a certain level of tolerance on the part of society. What if this is wrong?
What if society, or just your neighbors, or your boss, is not so tolerant?
What if you lose your job, or get hounded from your neighborhood, once these
secrets are exposed?
I really don't think we have any right to second-guess the decisions people
have made about what they will reveal and what they will keep private.  They
are the ones who have to live with the consequences.  They are the ones who
should make the decisions.  For you to say that people should have "nothing to
hide" is awfully facile.  If you had admitted in your book to be a pedophile
or a white supremacist, coming out of the closet as a demonstration of your
faith in the values of openness, that would at least indicate that you had
experienced that of which you had written.  But of course even that would not
give you the right to presume to tell others to follow the same course.  In my
Furthermore, there is a long tradition of anonymity and pseudonymity in
literature.  Probably the most prominent examples are the Federalist Papers,
published anonymously due to fear of political retribution.  The whole area of
politically-inspired anonymity is another counter-example to this notion that
people only want privacy for evil purposes.  How can you look back at the
history of even this country, which probably has one of the best records in
the world, and feel confident that no one will ever be wiser to express an
unpopular view anonymously?  Even if you feel safe about it in the U.S., your
suggestions would have world-wide impact. There are many countries in the
world where criticizing the government will have to be done anonymously if it
is done at all.
This raises the point that anonymity may promote criticism.  You go to some
lengths to praise the value of critical commentary as a route to the truth.
Yet in real life political considerations are one of the most potent blocks to
criticism, and these often apply most strongly to those who are in the best
position to criticize.  It is only through anonymity that much of the most
useful criticism can arise.  This is why we have our "whistle-blower" laws,
anonymous informants, etc.  Yes, anonymity can be easily misused in this
regard.  Information supplied anonymously needs to be carefully verified
before it can be relied on.  But I don't see the value in stripping the shield
of anonymity from people who would like to expose some injustice but are
afraid of the personal consequences.

@_date: 1996-11-17 13:05:48
@_author: Hal Finney 
@_subject: Re: Computer CPU chips with built-in crypto? 
This sounds like something which might be used in a set-top-box or
"information appliance" application where pay-per-use programs would
be loaded from a CDROM or network connection.
People have been dreaming about pay per use software for many years.
It is a similar idea to the "mini application" concept which would
replace the monolithic super-apps, the Microsoft Words and the giant
do-everything web-browsers/newsreaders/mail-clients, with small, single
function utilities.  This is part of the idea behind Apple's OpenDoc
and Microsoft's OLE.  In the same way, instead of buying a big program
for hundreds of dollars, you'd just download and use the functionality
you needed for a small fee.
Yet in practice it is not clear whether either of these trends will have
any market success.  Monolithic applications seem to be doing very well,
with more integration being the trend, not less.  And the whole idea
of introducing metering to a market which is used to paying just once
for access is one which is bound to meet resistance.  Look at AOL which
is going to single-charge unlimited access to the net.
So in both cases the trend looks to be going in the opposite direction.
Another possible application for the built in encryption is software
piracy protection.  You'd unlock software for your CPU but it would
not run on anybody else's without a different key code.  Here again
there is not much benefit to the end user, unless software prices come
down dramatically when this device is used.  But otherwise the computer
manufacturers are selling computers which have features which will limit
the powers of the buyers, and having to sell them more expensively to
boot because of the special chip.  In these days of razor thin profit
margins in the PC business it is hard to see how this will sell.

@_date: 1996-11-17 17:40:29
@_author: Hal Finney 
@_subject: Re: Members of Parliament Problem 
The 4th method of Chaum's, from Eurocrypt 91, somewhat satisfies this,
as does a method from the Eurocrypt 94 paper.  Each person can choose
his own public key g**x for a discrete log system.  However, the problem
is that all members of the group have to choose the same prime p as the
modulus, and generator g, for their discrete logs.
The issue of using a common modulus in discrete log systems has been
somewhat controversial.  I think when the government first proposed DSS
they planned to do something like this, one modulus with everyone having
different secret x values with corresponding public keys y = g**x mod p.
This has the advantage that public keys are smaller since everyone uses
the same g and p.  So all you need is one value for your public key.
Without this you have to have g, y, and p be your public key so it is
3 times bigger.
The problem is that the way the main discrete log algorithms work,
once you have broken one discrete log for a certain g and p you can break
all the others very easily.  So the particular g,p pair which is chosen
for everyone to share becomes one very big, fat target to try to apply
discrete log algorithms.
Now this is not necessarily as bad as it seems.  Unlike the case with RSA,
there is no secret information which could be leaked to make solving these
discrete logs easier.  Nobody knows how to do it.  So the only way it can
be done is by a massive operation roughly similar to factoring an RSA
modulus the size of p.  Choosing p of 1000 or 2000 bits should still make
it effectively impossible for anyone to do this.  The numbers are simply
far too large.
Still the consensus of opinion with discrete logs is that the advantages
of slightly smaller keys have not been great enough to justify the risk
involved in having eveyone share a modulus, even though that risk is
seemingly insignificant.  On the other hand maybe for cases like this
the additional advantages to common moduli would be enough to tilt the
argument in the other direction.

@_date: 1996-11-17 18:51:25
@_author: Hal Finney 
@_subject: HP's crypto technology 
I was poking about on the hp web server, trying to get some more hints
about the technology they are pushing:

@_date: 1996-11-18 10:09:19
@_author: Hal Finney 
@_subject: HP proposal available 
HP has put up info on its crypto proposal at You can also try  if that
URL is slow.
The basic idea is what we had been speculating, their old
"International Cryptography Framework" based on hardware crypto cards.
It has now been given government approval, which is no big surprise
since the system looks like it's been designed by fed bootlickers.
The claim of other companies signing on is less impressive than it
sounds.  They're using Microsoft's Crypto API, and of course Microsoft
would like plenty of companies to use it.  Intel offers to build some
hardware, which is more business for them.  "Netscape and VeriFone are
exploring a wide range of uses for ICF technology."  That's all they
say about those companies.  This is hardly a commitment; Netscape and
other companies generally keep abreast of everything happening in the
field to keep their options open.  So this is not a resounding
The one good thing about the plan is that since it is very complicated
and requires specialized hardware, we probably won't see any impact from
it for years.  Hopefully it will be obsolete before it can be deployed.
The plan itself is an NSA wet dream.  Not only do you need a token
from Big Brother to activate the crypto in your computer (the token
can be hardware or software, but the crypto card itself apparently
must be hardware), it's also necessary for any application which wants
to use crypto to supply an application specific certificate to the card.
This lets the law enforcement bureaucrats not only determine who gets to
use crypto, but which applications get access to it.  If you want to build
an app which will use crypto you'll have to get permission from the
authorities in order for them to give you a certificate which you can
compile in to let your app run.
The one thing which was not clear was how much of these rules would apply
within the U.S.  In fact notably missing from the press release, white
paper, overviews, slides, etc. on the web site was any discussion of civil
liberties impact.  It certainly was not listed as one of the considerations
in the design of the system.
Overall, I'd say this is just HP trumpeting the unsurprising government
approval of their ICF system and turning it into a press event by providing
some lukewarm "endorsements" from well known companies.  This system looks
to me like it's got a long way to go before it becomes a widely used

@_date: 1996-11-19 08:56:02
@_author: Hal Finney 
@_subject: Re: Rogue Governments Issuing Policy Tokens 
I don't think this would happen.  Some kind of secret information or
hardware is going to be needed to create policy tokens.  (Otherwise
anybody could make one.)  That means that HP, and therefore ultimately
the U.S. government, is going to have to approve those governments which
are allowed to issue such tokens.  HP will have to provide them some
special hardware or something to make them.  The tokens will only be
accepted if they have proper secrets inside them.
I can't see the U.S. allowing Libya and similar countries to create policy
tokens.  The whole point of this exercise is to prevent these countries
from being able to use strong crypto.  So they will certainly not be on
the approved list.
Does this represent an attempt to establish a de facto U.S. hegemony over
the world, where the U.S. government gets to decide which other governments
have access to crypto?  Not necessarily; other countries will still have
the option to use computers made outside the U.S.  The fact of international
competition will still exist.
If the HP initiative does become a widespread standard (which I think is
unlikely at this point) then we will see the same sorts of flight towards
non U.S. computers that we now see towards non U.S. crypto companies.
Why should an Israeli company buy an American computer with a policy chip
that is ultimately under the control of the U.S. government when they
can get one locally made which has no such restrictions?
And of course all this focus on hardware tokens ignores the fact that
the alternative of software-only crypto will still be present, both for
the domestic market and for the international market where the products
don't come from the U.S.  This will represent additional competition
which the HP proposal must face.
For these reasons I don't think the HP idea solves the export problem
for U.S. hardware and software makers.  And the response by opinion leaders
has ranged from ho-hum to negative, despite the self-serving cheerleading
by HP management.  Companies which try to sell computers with these chips
in them risk getting a "big brother inside" (to use Tim's very effective
slogan) reputation.  I think this initiative is going nowhere.

@_date: 1996-11-20 18:02:45
@_author: Hal Finney 
@_subject: Re: Anon 
As I mentioned a couple of days ago, science fiction writer David Brin
has an argument against not only anonymity, but _privacy_ as well.
Where cypherpunks tend to think of privacy as both beneficial and
inevitable, Brin sees it as harmful and doomed.  He has an article in
the December 1996 issue of Wired discussing his ideas.
BTW cypherpunk Doug Barnes is also quoted several times in the long
article in that issue by Neal Stephenson (Snow Crash, The Diamond Age)
about the undersea cables that carry most transnational information

@_date: 1996-11-20 18:09:15
@_author: Hal Finney 
@_subject: Re: Why I Don't Read SF Much Anymore 
I find this to be largely true as well.  The cyberpunk genre does the
best job at grappling with the impact of communications tech but it is
traditionally dystopian.  It would be nice to see a story about better
living through crypto.
What fiction can people recommend which presents crypto/privacy issues
realistically?  How about this new book that Neal Stephenson is working
on, does anyone know what it's about?  His short story, "Hack the Spew",
a few months ago (in Wired, I think?) had a strong crypto flavor.

@_date: 1996-11-20 18:27:41
@_author: Hal Finney 
@_subject: Re: Stewart Baker on new crypto rules 
What I see this as is a call to come up with architectures that will allow
transparent phase-in of government key access (so-called "key recovery")
technology.  The current HP proposal fits in very well with this model.
The appear to be planning on using standard API's so that applications
will be able to switch to using key escrow software without changing the
applications themselves, just the OS.  Maybe there could be a transition
period where both the old and new crypto would both be accepted, then
after a period of time the old wouldn't work any more.
As Baker goes on to say:
This suggests to me that we need to be vigilant in watching for systems that
will allow for easy "drop in" of key escrow.

@_date: 1996-11-23 13:32:47
@_author: Hal Finney 
@_subject: Re: how much entropy in common answers 
You have to estimate the probability that the attacker will guess what you
have chosen.  This will depend on how much the attacker knows about you.
If he knows that you're Irish, it will help in the question above.  If he
knows the names of your brothers, it will help a lot more.  Probably
it is best to be conservative in assuming what your attacker knows.
If you have four brothers and nobody whom the attacker could ask will
know who is your favorite, but you think he could find out there names,
then he has probably a 1/4 chance of guessing right.  (Actually he
might do better by preferring older brothers rather than younger, etc.)
The amount of entropy is then negative log 2 of the probability, or 2
in this case (2**-2 is 1/4).
For cars, if 50% of people like you would have chosen Mustangs, 40% Camaros, and the remaining 10% scattered among other brands, then
if your favorite car was a Mustang that is only worth about 1 bit.  But
if your favorite car was an Oldsmobile there might be only 1/100 chance
of the attacker guessing that, so it could be worth 6 or 7 bits.

@_date: 1996-12-16 16:49:43
@_author: Hal Finney 
@_subject: Hard to Tax Scenario 
Robin Hanson, inventor of the Idea Futures prediction market, is a very
creative and thoughtful writer who has posted to this list occasionally.
He says he sent the message below to the CP list over the weekend, but
I didn't see it.  I am including it (in bits and pieces) in its entirety
for the benefit of others who may also have missed it.
For those who don't know, by the way, David Friedman is the son of
Nobel prize winning economist Milton Friedman.  Both father and son
have libertarian leanings, and David in particular has tackled some
of the hardest problems which would be faced by an anarchic society.
So we are imagining a future scenario in which medicine is commonly if
not universally practiced via these remote means?  Or do we have two
classes of doctor, the anonymous virtual ones and the identified ones
that you go and see in person?  I ask because at least some of the
difficulties Ann faces seem due to her virtual practice.
The need for a cover story raises the question of from whom Ann has
to keep her secrets.  In a society where (we will stipulate) 30% avoid
taxation, the moral significance of not paying taxes will be different
than it is today.  We had some interesting posts in an earlier discussion
on this list describing the situation in Italy, where apparently tax
avoidance is raised to a higher degree than in the U.S.  It sounded like
it has the approximate moral status that speeding does here, a minor
infraction which almost everyone does some if not all of the time.
In some sub-cultures no doubt the tax avoidance rate would be even higher.
In such a society Ann may not have to care that much about keeping her
secrets, as long as she doesn't have too high a profile at tax time.
Well, that last part is true for me already; I telecommute to a company
300 miles away and have no social life with my co-workers.  For that
matter my wife and I have practiced cocooning for several years,
and I haven't had a close friend from work since the early 1980's.
Being married makes this easier, of course.
The other part of this scenario, where Ann interacts with her co-workers
via fake faces, does seem disturbing.  I could imagine, though, that this
might be common in such a culture.  Maybe everyone pretties themselves
up when on the videophone.  If there is widespread understanding that
most faces are at least somewhat false, then perhaps going all the way
to a completely faked up face would seem more acceptable.  But to someone
from my generation it will be hard to accept.
It is possible that we might see a more performance-based certification
rather than a recommendation based one.  My wife is a physical therapist,
and she had to pass a licensure exam given by the state which qualifies
her to practice.
In an earlier message to me Robin pointed out the crucial role played
by recommendations in hiring decisions.  Certainly I would be much more
likely to hire someone who listed his previous jobs and for whom I could
get good recommendations by his earlier supervisors than an applicant
who insisted that this information was confidential.
Robin also suggested that there could be a selection effect, so that the
doctors from good schools with good grades would use these advantages to
maximize their income, and so the only anonymous ones would be the ones
who didn't have these qualifications.  This could lead to a situation
where most anonymous service providers were assumed to be inferior to
regular ones, so they would get less money even if they were actually
just as good.  (I apologize to Robin if I missed the point of his
earlier discussion or am presenting it incorrectly.)
Even with such disadvantages, a doctor like Ann might accept a lower fee
at first while she builds up her reputation as an anonymous doctor with
talent and ability.  After a few years she could hope to have overcome
the stigma which (we will suppose) anonymous doctors face and display
some strong recommendations based on her successes.  In the long run
this could be a winning strategy due to the tax savings.
(I haven't given the problem of reselling certificates enough thought to
discuss it in any detail.  There have been some discussions of "is a
person" credentials which could apply, but that opens up a big can of
This is an interesting problem which I haven't seen discussed before
in this form.  In Vinge's original "True Names" people were afraid of
harrassment and physical threats if their identity were discovered, but
Robin's example of the danger of being exposed as a tax evader could be
very bad as well.  If there is this much tax avoidance, we might assume
that tax rates are high, and penalties for tax evasion are high as well.
On the other hand, if tax evasion is nearly universally practiced,
perhaps there are strong cultural pressures against turning someone in.
There is also the question of how good the technology is for anonymous
communication.  At best it would appear to require a widespread infra-
structure, and if this is used largely for tax evasion it is hard to see
how it could survive.  So I think this would be a very significant issue
to be faced by the prospective 'nym.
It is hard to judge how high the various prices are that she pays.
The socialization aspect may not be important if she has friends outside
work.  The risks of being caught will depend on factors we don't know,
like the technology and legal system.  Rather than assuming that tax
rates are the same, it might be more plausible to assume they have gone
up in order to keep revenues stable.
Another problem which Robin didn't mention is the issue of insurance
payments.  It is hard to see how Ann's patients can get reimbursed for
their expenses if we assume that Ann is in effect a "black market" doctor.
This problem may be somewhat specific to the medical scenario, but I
suspect that many other professions are going to have trouble switching
to a cash basis.  Anyone whose customers are businesses, for example,
will face the problem that the businesses' books will need to show that
an expense is justified in order to deduct it.  This will be a major
problem for the "anonymous firm" we have discussed occasionally.
One difficulty I find with this scenario is its science fictional nature.
It is hard for me to consider details about the life of a doctor who works
via VR.  Also, if we are already in a situation where 30% of people are
avoiding taxes there will certainly have been major changes in society,
but I don't know what they will be.  This makes it hard for me to focus
on the issues specific to Ann's anonymity.  However I do like Robin's
choice of a concrete and vivid example like this.

@_date: 1996-12-20 11:39:24
@_author: Hal Finney 
@_subject: Re: Executing Encrypted Code 
Probably an easier way would be for the chip manufacturer to issue a
key certificate (signature) on the chip keys.  Then it is a trivial
matter for any software manufacturer to verify that a proferred chip
key is legit; just check the cert.
Hey, it's a free world, right?  Some people only run authenticated
code from big companies; other people turn off the authentication
bit in the CPU and can run any old thing they stumble across on the net.
Everybody's happy.  The first group doesn't have to worry about viruses,
or at least they have somebody to sue if they see one, and the second
group gets to run all the freeware and PD code they can today.
Yes, I think this is a point often missed in these discussions.  People
say, why would I want a CPU which will limit the software I can run,
something which will let a software maker give me a version of his
program which will only run on my CPU and which I have no ability to
share with others?  What's in it for me?
The answer presumably is that the software manufacturer will sell software
with such limits for much less than he will sell unlimited software.  That's
because software piracy is such a major problem, and this way he can be
protected against piracy from this copy of his program.  So people with
these CPU's can buy their software a lot cheaper.
Now if you only use pirated software anyway, which you get for free, then
obviously this is not much of an incentive.  It is only for people who
pay for their software.  But that is a significant market.
Of course the big downside is that the track record of tamper resistant
hardware has not been too strong lately!  If a system like this gets into
widespread use and somebody finds out that shooting X-rays at the chip
exposes its secret key, you've got a big problem.

@_date: 1996-12-30 09:59:31
@_author: Hal Finney 
@_subject: Re: New crypto regulations 
The regs, as Lucky pointed out, do hint at restrictions on OCR fonts in
the future.  However this is obviously doomed since as OCR technology
advances the distinction between OCR and non-OCR fonts will vanish.
I imagine that a special purpose character recognition engine could be
built to work on any known, monospaced font, as is typically used for
source code.
In this light, the explicit exemption for printed materials is really
quite welcome.  It has never been 100% clear that a book of source code
is exportable.  Yes, we've had some favorable court cases recently but
none of these have been fully resolved.  Rumors were posted here that
the NSA came very close to trying to stop the export of the original PGP
source code book from MIT Press (and supposedly arranged for MIT to be
punished later for its audacity).
Having all sides agree that crypto source code can be exported in printed
form is an important step in the right direction.  We can still contest
the issue of restrictions on machine readable exports.  In an era where
electronic publishing is becoming as important as paper publishing for
expressing ideas, we can continue to push to extend the exemption to
machine-readable images of the pages of the book, and later to actual
source files.

@_date: 1996-12-31 12:34:27
@_author: Hal Finney 
@_subject: Re: Hardening lists against spam attacks 
This is an interesting idea, however it will be possible for someone with
a respectable public persona to continue getting tokens indefinately for
posting abusive anonymous messages.  There is no way to link the anonymous
tokens with the ones which were issued to good subscribers.
An alternative is to give each subscriber only a small, fixed number of
blinded tokens which he will use for the lifetime of his subscription
to the list.  When someone posts anonymously, they use up one of their
tokens.  Then, if the message was not abusive, a new blinded token is
created, encrypted with the public key of the good-guy anonymous poster,
and broadcast to subscribers.  This way good anonymous posters will get
to keep posting, while abusive ones will shortly run out of anonymous
posting tokens.
The big problem with schemes like this is the difficulty of defining
"good" posts in an acceptable way.  Some list members are hard-line
freedom-of-speechers and don't want to see any limitations on list
postings.  Others would probably classify 80% of the messages on the list
at times as grounds for termination of posting privileges.  Everyone will
have their own thresholds.
There is also the administrative problem of who will judge the posts.
This could take a large commitment of time.  I'm sure many of us
have gotten behind in our list reading from time to time and it can be
intimidating to return from a trip to find hundreds of messages waiting.
Imagine how it would be if you were supposed to be reading them and
looking for bad messages.
We might also want to consider the paradoxical possibility that if we
remove the junk, the list will die!  At least now we are constantly
reminded that the cypherpunks list exists.  Other lists like the
cryptography and coderpunks can sometimes go for quite a while without
any posts at all.  On CP you have the sense of a dynamic community where
you can hope for a response to your posts, more so than on a list which
is silent for days at a time.

@_date: 1997-01-02 11:44:22
@_author: Hal Finney 
@_subject: Re: Hardening lists against spam attacks 
I think this is an interesting theoretical discussion, although it's
not clear whether it is actually a good idea to try implementing this.
This requires Bob to trust the server to keep his identity secret.
Although you _say_ that majordomo didn't associate the token with
the userid, how does Bob know that?  Certainly majordomo did, when
Bob subscribed, see the association between the userid and the token.
Now he has to trust that it has been forgotten.  Even if it has, what
about eavesdroppers on the list channel?  What about the operator on the
machine, who is peeking at what majordomo is doing?  This mechanism will
not provide enough anonymity for most posters.
An alternative similar to what I proposed earlier is for majordomo to
provide a blinded token, one which it doesn't see.  This would be used
specifically for anonymous postings.  It does have the problem that it
allows linking postings by the same pseudonymous nym - all will have the
same token.  But maybe we want to encourage that.
(The full proposal I made involved use-once tokens, just like online
digital cash, so that there would be no linkage and it would allow
real anonymity.)
This unsubscribe/resubscribe issue has been mentioned before as a problem.
I am not too concerned with it, for a few reasons.  First, it may not be
too difficult to recognize that it is happening.  If the same user name is
used we can prevent issuing new tokens on an unsubscribe/resubscribe cycle.
If different user names are used but common domain names (an attack which
many people could mount) we could recognize that with somewhat more difficulty,
and mark those domains as special.  Most people would have trouble getting
lots of different accounts with different domain names.  Eric Hughes maxim,
"all crypto is economics", applies here.  We can easily make it much more
difficult for flooding attacks to occur.

@_date: 1997-01-03 09:06:04
@_author: Hal Finney 
@_subject: Re: OCR and Machine Readable Text 
Before you get too carried away by the capabilities of off the shelf
character recognition, read Phil Karn's experience trying to produce
a working DES program from the pages of Applied Cryptography.  It was
easier than writing it himself, but it was still far from a turnkey
operation.  This is from

@_date: 1997-01-09 12:20:00
@_author: Hal Finney 
@_subject: Re: [IDEA] Cypherpunks Super Computer (was Re: The Upcoming DES Challenge) 
A few years ago I coded up a TCL interface to Pr0duct Cypher's
PGPTOOLS library.  It did bignum arithmetic from the command line,
and also let you use MD5 and IDEA on files and buffers.  Unfortunately
I had a major disk crash and was never able to recover my last version,
and I never got back to it.
Safe-TCL has never gotten the scrutiny of Java, but IMO if it ever
does it will be found to suffer from its own flaws.  At this point
I think Java is farther along the path to safety.
I do like the idea of a widely available, installed, crypto-capable
scripting language.  This would be an ideal basis for trying out new
crypto protocols and algorithms, without having to write a whole program
from scratch.  We have been talking about setting up DC nets for years,
for example.  The concept is so simple as to be almost trivial.  But
the infrastructure is the hard part - dealing with the I/O issues, the
multiple architectures, all the configuration issues.
I suspect that Java, when it gets its security API, may be a good
candidate for this kind of system.  It's already got high level socket
I/O, and with a bignum package and some basic crypto primitives like
one way functions, you could do a lot with it.  You still have the
problem of trading off safety for utility, though.

@_date: 1997-01-09 12:19:59
@_author: Hal Finney 
@_subject: Re: [IDEA] Cypherpunks Super Computer (was Re: The Upcoming DES Challenge) 
[Sorry if this is a re-post...]
A few years ago I coded up a TCL interface to Pr0duct Cypher's
PGPTOOLS library.  It did bignum arithmetic from the command line,
and also let you use MD5 and IDEA on files and buffers.  Unfortunately
I had a major disk crash and was never able to recover my last version,
and I never got back to it.
Safe-TCL has never gotten the scrutiny of Java, but IMO if it ever
does it will be found to suffer from its own flaws.  At this point
I think Java is farther along the path to safety.
I do like the idea of a widely available, installed, crypto-capable
scripting language.  This would be an ideal basis for trying out new
crypto protocols and algorithms, without having to write a whole program
from scratch.  We have been talking about setting up DC nets for years,
for example.  The concept is so simple as to be almost trivial.  But
the infrastructure is the hard part - dealing with the I/O issues, the
multiple architectures, all the configuration issues.
I suspect that Java, when it gets its security API, may be a good
candidate for this kind of system.  It's already got high level socket
I/O, and with a bignum package and some basic crypto primitives like
one way functions, you could do a lot with it.  You still have the
problem of trading off safety for utility, though.

@_date: 1997-01-18 16:57:14
@_author: Hal Finney 
@_subject: Re: microcurrency: Netscape vs. Microsoft 
I assume you are referring to secure web connections via SSL in talking
about crypto.  In that case there was a very strong pent up demand for
the service.  Customers were afraid to send credit card numbers and
other personal information across the web.  Sellers were pressuring the
net server companies to do something to quell these concerns so on-line
selling could succeed.  Netscape did it, and in the grand tradition of
the net, implementation beat design and SSL defeated SHTTP.  In its early
versions SSL had a lot of problems but it was a good enough solution for
what it needed to be.
The question is whether there is similar market demand for pay per view
web pages.  Do web service operators think they can offer value added
services which will motivate customers to click through the for-pay link?
Maybe porn would be a good initial market.  There are so many sites
where you've got to sign up ahead of time for $20 or so for a month's
membership.  This is a considerable barrier.  But if you could just take
a peek for $.50 there would be a lot of people interested.  Porn is what
started the VCR market before it later "went respectable", so maybe the
same thing could happen here.  I know that a lot of the initial vendors
with First Virtual were selling racy pictures, although I think the
company has taken steps to reduce their association with that market.
This is not exactly the microcurrency that Vladimir is talking about
but it would be a good model for integrating some payment system with
a browser and it could serve as the foundation for other for-pay pages
with lower fees.
There is also the issue of sellers learning to use the various payment
systems which are out there.  Here again if Netscape and Microsoft would
just pick one then everyone could standardize on it, which would
increase acceptance a great deal.
Ecash as it is implemented now has the problem that the customer has to
open a special bank account.  What you need is a payment system where
you can use your existing VISA card and withdraw cash against it into
your electronic wallet.  This is pretty close to the FV model but their
payment system is somewhat clumsy.
I haven't followed the electronic payment market closely for the last
couple of years.  Are there any payment systems which look like good
candidates for integration with browsers?

@_date: 1997-02-12 17:57:26
@_author: Hal Finney 
@_subject: Re: anonymity and e-cash 
I wish I could have heard that, it sounds good...
A simple idea we have discussed for full anonymity uses the idea of
exchanging coins at the bank.  You make an anonymous connection to
the bank, supply some ecash you have received along with some blinded
new ecash.  The bank verifies that the ecash is good and signs your
blinded ecash, sending it back to you.  You unblind it and have good,
fresh smelling ecash which you can keep, spend, or later deposit in
your account.
If the merchant performs this exchange operation on-line as soon as
he receives ecash, then his anonynmity is protected.  The customer is
protected too, by the blinding he used when he withdrew the ecash earlier.
So both sides remain anonymous.
It sounds like Ian may have worked out details of a system where third
parties do these exchanges.  Banks may be reluctant to allow them for
liability reasons, and the market, abhoring the vacuum, will supply
intermediaries who perform exchanges for a fee.
Resolving the various forms of cheating is the hard part.  When Lee asks
about a signed receipt, it is hard to understand what is the point if the
seller is fully anonymous!  A signed receipt from a freshly-minted key
is not of much use to anyone.
If the participants are using persistant pseudonyms then whatever
reputation capital they have can be put on the line when cheating happens,
although it still may be hard to tell who cheated whom.  Did the customer
pass bad cash and claim it was good, or did the merchant deposit good
cash and claim it was bad?
The same thing could happen every day at the supermarket, of course.
A customer insists they paid $20 but got change for a $10.  If dozens of
customers say the same thing has happened to them, we start to mistrust
the market, while if several businesses say this particular customer
has made the same claim to them, we blame the customer.

@_date: 1997-02-13 06:43:00
@_author: Hal Finney 
@_subject: Re: anonymity and e-cash 
This provides no anonymity with respect to the bank, right?  The bank
knows who is paying whom.  That's not very valuable IMO.  The bank is
still a centralized place where all this transaction information exists,
a fat target for privacy opponents.  I'd say that anonymity to the
bank is more important than anonymity to the merchant for this reason.
So I think you're going at this backwards.
The big question with identity certificates is what procedures were followed
in verifying the identity when the cert was issued.  If the CPA publishes
some standard method, and his reputation is strong enough that people will
trust him to follow it, then it might well be worth money to you to have
him sign it.  This is the traditional role of the Certification Authority.
It depends on the circumstances where you expect to use your key.  Within
a small to medium circle of associates there may be some group members
who sign keys and are trusted by other members of the group.  There is
no particular reason for it to be difficult.  If you want a signature which
will be accepted by everyone in the U.S. you have a harder problem.

@_date: 1997-02-12 17:23:45
@_author: Hal Finney 
@_subject: Re: anonymity and e-cash 
I wish I could have heard that, it sounds good...
A simple idea we have discussed for full anonymity uses the idea of
exchanging coins at the bank.  You make an anonymous connection to
the bank, supply some ecash you have received along with some blinded
new ecash.  The bank verifies that the ecash is good and signs your
blinded ecash, sending it back to you.  You unblind it and have good,
fresh smelling ecash which you can keep, spend, or later deposit in
your account.
If the merchant performs this exchange operation on-line as soon as
he receives ecash, then his anonynmity is protected.  The customer is
protected too, by the blinding he used when he withdrew the ecash earlier.
So both sides remain anonymous.
It sounds like Ian may have worked out details of a system where third
parties do these exchanges.  Banks may be reluctant to allow them for
liability reasons, and the market, abhoring the vacuum, will supply
intermediaries who perform exchanges for a fee.
Resolving the various forms of cheating is the hard part.  When Lee asks
about a signed receipt, it is hard to understand what is the point if the
seller is fully anonymous!  A signed receipt from a freshly-minted key
is not of much use to anyone.
If the participants are using persistant pseudonyms then whatever
reputation capital they have can be put on the line when cheating happens,
although it still may be hard to tell who cheated whom.  Did the customer
pass bad cash and claim it was good, or did the merchant deposit good
cash and claim it was bad?
The same thing could happen every day at the supermarket, of course.
A customer insists they paid $20 but got change for a $10.  If dozens of
customers say the same thing has happened to them, we start to mistrust
the market, while if several businesses say this particular customer
has made the same claim to them, we blame the customer.

@_date: 1997-02-12 23:07:29
@_author: Hal Finney 
@_subject: Re: anonymity and e-cash 
This provides no anonymity with respect to the bank, right?  The bank
knows who is paying whom.  That's not very valuable IMO.  The bank is
still a centralized place where all this transaction information exists,
a fat target for privacy opponents.  I'd say that anonymity to the
bank is more important than anonymity to the merchant for this reason.
So I think you're going at this backwards.
The big question with identity certificates is what procedures were followed
in verifying the identity when the cert was issued.  If the CPA publishes
some standard method, and his reputation is strong enough that people will
trust him to follow it, then it might well be worth money to you to have
him sign it.  This is the traditional role of the Certification Authority.
It depends on the circumstances where you expect to use your key.  Within
a small to medium circle of associates there may be some group members
who sign keys and are trusted by other members of the group.  There is
no particular reason for it to be difficult.  If you want a signature which
will be accepted by everyone in the U.S. you have a harder problem.

@_date: 1997-03-28 12:15:36
@_author: Hal Finney 
@_subject: Re: remailer spam throttle 
This is a potential problem, but there are some other considerations.
First, there is no particular reason why one recipient of some email from
the remailer should know or even suspect that other people have the same
email waiting.
Then, to defend against raids like this, the material could be separately
encrypted to each recipient.  There would be no way to know that material
sent to one recipient matched material sent to someone else.  The raiders
would just find a bunch of encrypted files.
Of course, if it were a sting operation, with the recipients being lured
or entrapped into requesting information they shouldn't, then the sender
might avoid using these countermeasures.  However, there wouldn't really
be any need to use a remailer for a sting operation like this, it could
be done just by offering the material from an ordinary address.
More generally, I think we need to keep in mind what a remailer does and
what it doesn't do.  The essential function of the remailer is to provide
anonymity via mixing messages.  It does not provide confidentiality of
message contents.  That has to be taken care of by encryption.  And,
as I wrote yesterday, it doesn't (can't) keep secret who the people are
who send and receive anonymous mail.  All it can do is to disguise which
particular people send and receive to each other.
The same is true of a DC-net or a perfect Chaumian mixnet.  These systems
do not disguise their particpants, or protect the confidentiality of their
message contents; they only hide the knowledge of who is talking to whom.
Having said that, I do like some aspects of this idea:
(The "default true" is going to allow the same kinds of abuse which we
have seen in the past.  Some remailers may be able to tolerate this, but
as we have seen, many can't.)
This is what I like.  It's a lot simpler than trying to keep a copy of
the anonymous mail and deliver it later when the person asks for it.
Just let him know that someone is trying to reach him anonymously, and
let him enable that if he wants to be able to receive the next anonymous
message that comes in for him.  You can load his permission message down
with all kinds of disclaimers that say he knows he's likely to receive
obscene, threatening and illegal material, that he doesn't mind, that
he knows the remailer is an automated system which doesn't look at the
contents, etc.  Not only does this give you a defense but it makes the
person think about what he's getting into, so he will in fact be better
prepared when something bad comes his way.
Plus, having taken positive action to enable receiving anonymous mail, he
will hopefully be more knowledgable about how to request that you stop,
and it won't be such a big deal.  He opens the pipe, and if he gets a
face full of sewage, he closes up the pipe right away.  You warned him.
Key servers wouldn't be the only place to store this information.  I think
the remailer could keep its own list, especially if it were defaulting
to "off".  This way recipients wouldn't have to generate and submit PGP
keys, which is more work than just sending a reply to a remailer giving
the OK to receive anonymous mail.
More cautious or politically vulnerable remailers might default in the
other direction.  It would be a matter of the individual situation.

@_date: 1997-04-07 22:15:21
@_author: Hal Finney 
@_subject: Anonymous cash via intermediaries 
The paper by Rivest on lottery tickets as micropayments, at:
is a clever idea, but he mentioned something in passing at the end
Anonymous cash is most useful in the context of anonymous communications.
If you are achieving anonymity via "mix" technologies, like the remailers
or Wei Dai's proposed PipeNet, then the same network which hides the
communications path could hide the payment path.  You pay the first
mix in the chain, which pays the next, and so on until the person at
the end receives payment.  Even with a non-anonymous payment system,
you get the effect of anonymity.
With intermediaries like this, you could use, say, First Virtual's
credit-card based payments.  If you want to buy some information
anonymously, you set up a remailer chain to send the request to FV.
With that you include a payment to that first remailer, requesting
forwarding.  The remailer accepts the payment, processes the message,
and when it forwards it, it sends along a payment of its own (from its
own account) to the next remailer in the chain, again requesting
forwarding.  This continues until the last remailer forwards the
message to the final recipient, making a payment of its own in
response to the forwarding request.
In order to figure out who paid whom, an observer would have to trace
through the remailer chain.  And if they could do that, they could
follow the message too, breaking the anonymity.
(I had proposed a similar idea of forwarded non-anonymous payments a
couple of weeks ago, but that was specifically in the context of
paying for remailers.  Rivest's idea would extend this to a general
payment scheme.)
I see some obvious problems, but perhaps they can be patched up.  The
remailers would have to be honest and trustworthy (not to mention
brave, clean, and reverent); if the payment somehow got lost en route
it could be difficult to verify who had pocketed it.  There is some
anonymity lost by having all the remailers in the chain know how much
is being paid, even if they don't know who is involved.  If online
payment schemes were used, they could leave traces which would allow
after-the-fact tracing of the payment path (and therefore the message
Despite this, the convenience barriers to the use of anonymous cash
might make it worth looking into "payment remailers" (or web
redirectors).  As long as there are at least two forwarders in the
chain you have a minimal level of anonymity, and your payments should
be as anonymous as your communications.

@_date: 1997-04-12 12:07:51
@_author: Hal Finney 
@_subject: Re: anonymous credit 
I think this is a very intriguing idea.  Let me try to spell it out in
more detail with some concrete numbers.
A zero-coupon bond is one with a purchase price less than its face value.
After the maturation of the bond, it can be redeemed for its face value.
The purchaser of such a bond is loaning money to its buyer, and he will
be paid off at the end of the loan period with more money than he put in.
For a ten year bond, maybe the purchase price is 1/2 its face value.  A
$1000 bond would be purchased for $500, and redeemed in 10 years for $1000.
An "anonymous" bond would be a bearer bond, one which is sold without any
record of who bought it, and which can be redeemed at maturity by whomever
holds it.
In the example above, the U.S. government sells, say, $1 billion worth of
these 10 year zero coupon bonds.  It will have to pay back $2 billion in
ten years at maturity.  The $1 billion in revenues is then distributed
evenly to everyone in the country.  Assuming a population of 250 million,
each man, woman, and child gets $4.
In ten years, in order to pay off the redeemed bonds, $2 billion of special
taxes will be collected.  This will amount to $8 per person.
As Wei says, each person in the country (who doesn't participate in the
bond sale) is given $4 now, and must pay $8 in ten years.  In effect he
is given a $4 loan, payable in ten years.
If he does not want that loan, he can take his anticipated $4 and buy $4
worth of the bonds during the bond sale.  This produces no gain or loss
of money, but he gets the bond.  Then, in ten years, he turns in his bond
for $8, and uses that to pay off the $8 in taxes.  He ends up without
any change in his financial state, neither loaning nor borrowing money.
(There is a slight complication in that at the time of the bond sale,
people who want to offset their loan with a bond purchase won't yet have
the loan funds to buy the bond; and at the end, people want to pay
off their tax with the bond redemption, but the government can't redeem
the bonds until it collects the tax.  I'm not sure if this is a serious
problem or not.)
Now, if this picture is correct, this isn't exactly how I would have
thought of an anonymous loan.  The people receiving the distributed
revenues from the bond sale are essentially borrowing money from the
government.  Every borrower is identified, and must pay back his loan
in ten years via his taxes.  So the loans are fully identified and
not anonymous.
What does happen though is that some (or most?) of the people can offset
their loan by anonymously lending money (buying bonds).  In effect
they have borrowed money from the government, non-anonymously, but then
have the option of lending all of it back, anonymously.  At the end, it
is impossible to know which people have retained their loans and which
people have cancelled them.  So you don't know who has borrowed money,
and this therefore is effectivelly equivalent to an anonymous loan.
Maybe a non-governmental body could be used in place of the government.
Suppose a group of people wanted to allow some members to borrow
money anonymously.  For example, a church group wants to help members
through tough times via loans, but they don't want the recipients to
be identified and bear the stigma of needing charity.
Wei's idea could still be used: the church sells its own bonds, redeemable
at some future date for more than the face value.  The funds from the
sale are distributed evenly to all members.  Members who don't want to
borrow make purchases at least equal to their receipts.  Then, after
the time period, everybody has to pay a special membership fee ("tax")
so that the bonds can be redeemed.  If some people can't pay, the other
members will have to be willing to pay more to cover their defaults.
One practical problem with this idea is that the amount of money loaned
per person is small compared to the volume of transactions going on,
especially for large groups.  In my example above, each person only
anonymously borrowed $4, given $1 billion worth of transactions.  That's a
lot of paperwork with associated transaction costs for a small value.
With smaller groups the idea might actually be more practical, although
there is less anonymity then.

@_date: 1997-05-03 06:19:36
@_author: Hal Finney 
@_subject: Re: A new system for anonymity on the web 
Actually here in the U.S. most people have access to unmetered Internet
access these days.  Local and national ISP's are almost always that way,
and AOL offers that option now as well.  I find that I tend to browse in
"flurries", paging around a bit, then settling down to read for a while.
But you're right, I did not consider the interference among multiple
paths running through a jondo.  That issue applies to the higher speed
links as well.  If average path length is n, then on average there
will be about n paths going through each jondo (assuming all "home"
jondos have set up paths).  So the question will be whether the average
person uses more than 1/n of the bandwidth available during the time he
is connected.  This will no doubt depend on the pricing model for Internet
service, as you suggest.
Yes, latency would be cumulative, and I just tested mine and found it
was 160-220 ms, about the same as what you saw.  So running through say
5 jondos at the end of modem paths would add about a second of latency.
I think this would be fine if it only happened once per web page, but
almost intolerable if it was once per tiny picture.
This is an intriguing idea.  Secure multiparty calculation protocols allow
calculations to be made such that neither machine would have access to
all the data.  It is an interesting question how this could be applied
to the anonymous communication problem.
In this specific case, if the Crowds system were enhanced so that
end-to-end encryption was used (which seems very practical and useful),
you could run a jondo on your PC whose only function was to link to
the jondo on the ISP and then set up the additional path through the
jondo net.  The path between your local PC jondo and the end one in the
path would be encrypted, so even root on the local ISP could not see the
contents of what you send down the jondo path.  He might still be able
to see when you were sending and when not, but he couldn't tell where
it was going.

@_date: 1997-05-03 06:16:02
@_author: Hal Finney 
@_subject: Re: Bypassing the Digicash Patents 
Bob, if I understand you correctly, you've suggested that digital
bearer instruments will in the long run actually be more efficient than
conventional book entry based transaction models.  Anonymity will be
cheaper than identified transactions.
But, if digital bearer certificates of all kinds are, as you suggest,
cheaper and more efficient than conventional ones, why can't we just
use ordinary non-blinded digital instruments and ignore the identifying
For example, XYZ Co. could issue a signed note saying "Serial number
12345, worth 100 shares of XYZ Co.".  A bank could issue a signed note
saying "Serial number 54321, worth $100 at DigiBank".  These can be done
with ordinary digital signatures.  No blinding or patent issues arise
(by the end of this year, when the patents expire!).
These are not blinded, so they are in principle traceable.  They have to
have unique serial numbers to solve the double spending problem, and those
could be used to track them.
This makes them less attractive from the privacy perspective, but what
about from the point of view of the financial markets?  Can they just
ignore the serial numbers and treat them as the bearer certificates you
have been talking about?  (Don't real bearer certificates often have
serial numbers on them?)
Maybe this geodesic market you're talking about (which I don't understand
at all) could work with current technology?

@_date: 1997-05-05 02:41:52
@_author: Hal Finney 
@_subject: Re: Bypassing the Digicash Patents 
It is hard to understand why a system where it is impossible to track
payments (Chaumian anonymity) is cheaper than one where it is possible
to do so, but we choose not to.  If avoiding tracking payments is cheaper
than tracking them, why wouldn't participants just not bother to track
them even when they theoretically could?
Granted, there are situations where taking away someone's options can make
him better off.  The classic example would be the Prisoner's Dilemma, which
I will assume people here are familiar with.  Given the choice to cooperate
or defect, standard analysis predicts that both players will defect.  Remove
that option, and they will be forced to cooperate, leading to a better
("lower cost") outcome for both.  The structure of the game forced them to
take advantage of an option which has the net result of costing them more.
The question is whether this kind of reasoning would apply financial
transactions.  Is it really true that taking away the option of tracking
transactions is going to save money overall?  Sure, not keeping records
is a priori going to be cheaper than keeping them, but the question is
how much the loss of those records is going to hurt you.
Presumably records are kept to protect against various risks.  Without
that protection, you need other means to control the risk.  But if those
means exist and they are cheaper than record-keeping, then again even
without anonymity it should be cheaper to use those methods in place of
the records.
I think we would need to see a more detailed explanation of exactly why
it is that people can't save money today by avoiding keeping records,
when they could do so if it were impossible to keep records.
(One possible explanation is that it would be a regulatory effect.
People are forced by the government to keep records, to their detriment,
that they would prefer not to keep.  With anonymous bearer certificates
it would not be possible to keep the records so people might hope to
escape the regulations.  However the problem with this reasoning is that
the same forces which require the record-keeping would be likely to ban
the use of instruments which prevent keeping records.)

@_date: 1997-05-09 23:52:18
@_author: Hal Finney 
@_subject: Re: El Gamal 
The next version of PGP will offer the combination of El Gamal for
encryption and Digital Signature Standard (DSS) for signatures, as
an alternative to RSA.  These are based on the discrete log problem.
El Gamal is really almost the same as Diffie-Hellman.  You have a
secret x, he has a secret y, and together you calculate g^(xy) which
is your shared secret.  With DH you then just use that shared secret
as your message encryption key; with El Gamal you multiply (or xor,
or add...) your key with the shared secret.  PGP uses El Gamal so that
we can send along not only key info but also which algorithm to use for
the message body encryption, and also a checksum.
It is true that El Gamal encrypted messages will be about 128 bytes bigger
than RSA for 1024 bit keys.  DSS on the other hand produces somewhat
smaller signatures than RSA, by about 85-90 bytes.  But neither of these
is really significant in typical applications.
The Diffie-Hellman patent expires September 6, 1997.  I gather that it
would also cover El Gamal since that is a variant.  The Hellman-Merkle
"knapsack" patent, which claims to cover all public key cryptography,
expires October 6, 1997.  After that date, at least some forms of public
key cryptography will be unpatented in the U.S.  The RSA patent expires
September 20, 2000.  It is possible that the next three years will see
greater use of discrete log cryptography because of the patent state,
although RSA has a significant "brand" advantage in the business market.
(This patent info is from "Handbook of Applied Cryptography", from
Menezes et al, which I recommend as a supplement to Schneier.)

@_date: 1997-05-14 02:51:19
@_author: Hal Finney 
@_subject: Re: `careerpunks' 
Coderpunks has not been very active, I think (although I don't always
notice which messages come from which lists).  Perry Metzger's moderated
cryptography has had some good discussions lately, including
contributions from such people as Carl Ellison and Matt Blaze.  There
was an interesting proposal from James Donald for a possible approach
to what they are calling CACK, "Corporate Access to Corporate Keys",
without facilitating GAK, "Government Access to Keys".
The cypherpunks list continues to have the edge in political commentary
and bomb-making instructions. :-)

@_date: 1997-05-14 05:44:16
@_author: Hal Finney 
@_subject: Re: Public Key Break Paper 
I was curious to see this paper, since it would be an earth-shattering
result if true, but unsurprisingly it is not as amazing as it sounds.
First, it is not a general attack on public key cryptography, but
rather it is a specific method for attacking RSA.
Second, I remember seeing this algorithm discussed on sci.crypt in the
past, probably in 1996.  I don't know if it came from this same guy
or if somebody else (re)discovered it.  But the discussion there indicated
that the algorithm was not as efficient as claimed.  The claim is that
it takes an amount of work proportional to the number of bits in the
modulus, which would indeed be a breakthrough.  Actually I think it will
take about (2^n)/n iterations, making it a very poor method (*).
Third, it claims to break RSA without factoring, but actually the algorithm
could be used to factor n.  The algorithm gives you (p-1)(q-1) or a
large factor thereof, and as discussed on sci.crypt a few months ago,
this is enough to let you find p and q (through a tricky method whose
details I don't remember!).
(*) The final string of 1's will be as long as the value of the phi(n)
factor being found, which will be on the order of 2^n, so there will
be about 2^n 1's in the final string, more than there are atoms in the
universe for numbers of interest.  (You don't have to store the whole
string though.)  Each iteration adds at most n bits to the string, so
the number of iterations must be as above.

@_date: 1997-05-19 04:42:03
@_author: Hal Finney 
@_subject: Re: referers and W3 (fwd) 
I'm not sure what Netscape action you are referring to, but if it is
giving the users the option to block the Referer tag, RFC2068, which is
HTTP/1.1, already endorses this:
     Note: Because the source of a link may be private information or
     may reveal an otherwise private information source, it is strongly
     recommended that the user be able to select whether or not the
     Referer field is sent. For example, a browser client could have a
     toggle switch for browsing openly/anonymously, which would
     respectively enable/disable the sending of Referer and From
     information.
and later:
   We suggest, though do not require, that a convenient toggle interface
   be provided for the user to enable or disable the sending of From and
   Referer information.
I use Eric Murray's fine "cookie jar" privacy program when I am web
browsing on my Linux system (
It blocks cookies and advertisements via a very flexible config file
mechanism.  It also eliminates other privacy-revealing outgoing data,
including Referer, and could be easily modified to play all kinds of
games with Referer for the adventurous.
In the news recently, Ticketron is blocking links from some Microsoft
affiliated sites due to a disagreement about licensing.  I don't know the
details of how it is done technically, but possibly it is done by looking
at the Referer tag to see if the user linked from the Microsoft site.
If so, this would be a good example of the browser sending information
which is detrimental to the user.

@_date: 1997-05-19 13:50:27
@_author: Hal Finney 
@_subject: Re: referers and W3 (fwd) 
Eric Murray, , writes, regarding Referer spoofing:
One practical idea would be to set up the config file so that whenever
URL X is referenced, specified URL Y is sent as the referer.  This could
be useful for accessing web sites which won't show you information unless
(or if) they see a certain value in the referer field.

@_date: 1997-05-20 03:08:58
@_author: Hal Finney 
@_subject: Re: Information Hiding Workshop 
The second URL above has abstracts from the conference, many of which sound
very interesting from a CP point of view.  It's kind of strange though that
this topic encompasses both steganography and fingerprinting.  The first
has connotations of freedom, while the second connotes restrictions.  What
both have in common is embedding information undetectably and/or unremovably.
The conference proceedings, "Information Hiding", are currently checked out
from the local university library but I will be looking for them.  There
sounds like a lot of good stuff.  Check out the URL for the T. Aura paper
below; it has some statistics on actual LSB distributions in digital
images, with implications for doing truly undetectable stego.
Below are a few of the abstracts, with URL's for more info where available.
Stretching the Limits of Steganography R Anderson, Info Hiding 96 pp 39--48 The author provides a brief overview of the state of the art in
steganography, and shows how public key steganography is possible ---
at least in the presence of a passive warden. The basic idea is that
if the communicating parties can manipulate at least one out of n bits
in the cover text, then the warden can not distinguish the parity of
successive blocks of n bits from random noise; accordingly these parity
bits can be used to hide cipher text in plain sight. Information theoretic
limits of general steganography are also discussed, and it is shown
that parity techniques can make many systems more efficient. Finally,
the differential effectiveness of active and passive wardens is discussed.
 Computer Based Steganography: How It Works and Why Therefore Any
Restrictions on Cryptography Are Nonsense, At Best E Franz, A Jerichow, S Mller, A Pfitzmann, I Stierand, Info Hiding 96 pp 7--21 The authors discuss a system for hiding ciphertext in the low order bits
of an ISDN telephone signal, and report measurements of the perceptibility
of various covert signal levels as a function of the cover signal and
background noise. They also discuss the meaning of perfect and pragmatic
security in the stego context. They argue that steganography is easy,
and thus restrictions on crypto will simply force criminals to use stego
which will make the law enforcement job harder.
Practical Invisibility in Digital Communications T Aura, Info Hiding 96 pp 265--278 The author discusses some of the problems of information hiding,
including synchronising with a cover message which is a stream such
digital audio. Where the cover message is a block, such as a digital
picture, his technique is to use the Luby-Rackoff construction to
embed the hidden bits pseudorandomly throughout the picture. A test
implementation using SHA as the underlying primitive is reported.
 Establishing Big Brother Using Covert Channels and Other Covert Techniques Y Desmedt, Info Hiding 96 pp 65--71 The author discusses a number of ways in which covert technologies
that are initially deployed for relatively mundane purposes, such as
copyright protection, can end up being subverted to provide the means
of surveillance. This problem could become progressively more serious
as more and more everyday objects become endowed with some kind of
intelligence and communications capability.
Anonymous Addresses and Confidentiality of Location IW Jackson, Info Hiding 96 pp 115--120 The author describes how anonymous remailers can be used to process
personal location information from active badges. The goal is that each
user should be able to control who has access to information about his
location; the mechanism is that the remailers forward this information
to a server that the user trusts to enforce his security policy. The
crypto protocols used in this system are described.

@_date: 1997-05-20 23:57:17
@_author: Hal Finney 
@_subject: Re: Public Key Break Paper 
The unbalanced RSA idea, by Shamir, was to choose primes p and q with p
considerably less than q, e.g. p = 500 bits, q = 4500 bits.  With numbers
of this size, the difficulty of factoring a 5000 bit n = pq is still just
as hard as if p and q were both about 2500 bits.  Then, you only encrypt
numbers < p, and it turns out that you can do the decryption mod p rather
than mod n, so decrypt is much, much faster than for a conventional 5000
bit modulus.
There have been some attacks on this.  The main limitation is that the
encrypted number is supposed to be < p.  There is a chosen-cyphertext
attack, taking an x a few bits larger than p, encrypting it, and asking
for the resulting decryption.  This produces x mod p, which combined
with x can be used to find p.
Another attack along these lines is to guess x about the size of p, send
a legitimate message based on it, then watch the receiver's behavior to
try to determine whether the message had decrypted correctly.  If x < p
it would decrypt OK, otherwise it would decrypt to garbage.  Repeat this
to narrow down an interval containing p.
I believe these were presented by Quisquater at the Crypto 96 rump session,
although I think he was referring in part to some attacks which had already
been discovered.

@_date: 1997-05-22 01:38:55
@_author: Hal Finney 
@_subject: Re: Why I think Jim Bell is getting railroaded 
plan to commit a crime involving multiple individuals, and at least one
overt act taken in furtherance of the plan.  For example, if people get
together and plan a kidnapping, then one member goes out and buys some
rope, that could be enough to represent conspiracy to commit kidnapping.
You don't actually have to do the kidnapping to be convicted on conspiracy.
If Bell got together with his friend and talked about disabling government
computers with "carbon fibers" (whatever those are), and he then goes
out and buys a source of carbon fibers, a case could be made that this
would represent the crime of conspiracy.  (We don't know yet whether either
of these thing actually happened, of course.)
Now his lawyer can argue that the conversation was purely hypothetical
speculation of the type which technically minded people commonly engage
in, and the carbon fiber source (if it exists) was acquired out of
curiosity based on the discussion.  Then it would be up to the jury
to decide whether Bell's actions actually were part of a planned crime
or not.
In this context his writings and hostile relations with government
agencies could conceivably be used against him, if his lawyer did try
to argue that his conversations were just innocent speculation.
