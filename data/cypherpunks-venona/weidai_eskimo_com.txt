
@_date: 1994-08-19 01:43:08
@_author: Wei Dai 
@_subject: timestamp.c 
*  by
*  Wei Dai *       Put the line "|timestamp" in your .forward file, and this
*  program will automaticly scan all your mail for a certain subject heading
*  and if found, will sign the body of that mail with PGP, and send it back.
*  Otherwise, the mail goes to your regular mailbox.
*  This is probably most useful as a "trusted" time stamping service.
*  Use for experimental purposes only.  Feel free to modify it, but please
*  send me some e-mail if you do more than change the       MAILBOX "/usr/spool/mail/weidai"
 MAILLOCK "/usr/spool/mail/weidai.lock"
 PGPPATH "/u/w/weidai/.pgp"
 LOG "/u/w/weidai/.timestamp.log"
 COMMAND "Time Stamp This Mail"
 MAXLINE 1024
 FROM "From "
 SUBJECT "Subject: "
void Remove_nl (char *);
        char sLine[MAXLINE], sFrom[255], sFile[255], sTmp[255];
        char *p;
        FILE *fOut, *fMail, *fLog;
        int bDoIt, fd;
        fLog = fopen(LOG, "a");
        sprintf(sFile, "/tmp/pts_%d", getpid());
        fOut = fopen(sFile, "w");
        sFrom[0]=0;
        while (fgets(sLine, MAXLINE, stdin) != NULL)
        {
                fputs(sLine, fOut);
                if (strncmp(sLine, FROM, strlen(FROM)) == 0)
                {
                        fputs(sLine, fLog);
                        for (p = sLine + strlen(FROM); *p && *p != ' '; ++p);
                        *p = '\0';
                        strcpy(sFrom, sLine+strlen(FROM));
                        Remove_nl(sFrom);
                }
                else if (strncmp(sLine, SUBJECT, strlen(SUBJECT)) == 0)
                {
                        fputs(sLine, fLog);
                        bDoIt = (strncasecmp(sLine+strlen(SUBJECT), COMMAND, str
                }
                else if (strlen(sLine) <= 1)
                        break;
        }
        if (sFrom[0]==0)
                bDoIt=0;
        if (bDoIt)
        {
                fclose(fOut);
                fOut = fopen(sFile, "w");
                while (fgets(sLine, MAXLINE, stdin) != NULL)
                        fputs(sLine, fOut);
                fclose(fOut);
                sprisFile);
                system(sTmp);
                fputs(sTmp, fLog);
                fputs("\n", fLog);
                unlink(sFile);
                sprintf(sTmp, "/usr/ucb/mail -s 'Time Stamp Output' '%s' < %s.as
                system(sTmp);
                fputs(sTmp, fLog);
                fputs("\n", fLog);
                sprintf(sTmp, "%s.asc", sFile);
                unlink(sTmp);
                fputs("*** time stamped ***********\n\n", fLog);
        }
        else
        {
                while (fgets(sLine, MAXLINE, stdin) != NULL)
                        fputs(sLine, fOut);
                fclose(fOut);
                while ( (fd=open(MAILLOCK, 0)) != -1)
                {
                        close(fd);
                        sleep(5);
                }
                fd=creat(MAILLOCK, 0600);
                close(fd);
                fOut=fopen(MAILBOX, "a");
                fMail=fopen(sFile, "r");
                while (fgets(sLine, MAXLINE, fMail) != NULL)
                        fputs(sLine, fOut);
                fputs("\n", fOut);
                fclose(fMail);
                fclose(fOut);
                unlink(MAILLOCK);
                unlink(sFile);
                fputs("--- personal mail -----------\n\n", fLog);
        }
        fclose(fLog);
        return(0);
void Remove_nl (char *string)
        int i=0;
        while(string[i]!='\n' && string[i]!=0)
                i++;
        string[i]=0;
PGP Public Key available

@_date: 1994-08-19 01:43:06
@_author: Wei Dai 
@_subject: trusted time stamping 
I thought my idea about having trusted entities digitally sign a document in
order to establish its existence at a particular time was a new idea, but I
just read about it in _Applied Cryptography_.  Anyway, I wrote some C code to
do automatic time stamping with PGP (source code is in the next e-mail).
If you just want to try it, simply send an e-mail to weidai
with the subject "Time Stamp This Mail".  The body of the mail will
be signed with a PGP private key (public key is at the end of this message)
and returned to the sender.  E-mail with any other subject will be piped
to my regular mailbox.
What's the use of this?  Well, here is an interesting application of
time stamping that wasn't covered in _Applied Cryptography_.
Let's say Alice would like to publish an article anonymously but retain the
ability to claim authorship some time later.  She can follow this protocol:
1. Alice signs her article with RSA
2. She encrypts her signed article with IDEA
3. She sends the encrypted article to several trusted time stamping servers
4. She places the signatures she gets back along with the encrypted article
   in a safe place
5. She waits a random length of time
6. She posts the plain article (without encryption or signature) anonymously
7. When Alice wants to claim authorship, she publishes the encrypted article,
   the IDEA key, and the signatures she got back from the time servers
Now, people can be reasonably sure that Alice actually wrote the original
article because the time server signatures prove that she signed the
article before it was made public.  One problem here is that at
least one of the time servers she used must have remained secure until step 7.
Wei Dai
PGP Public Key avaliable
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: 2.3a
-----END PGP PUBLIC KEY BLOCK-----
PGP Public Key available

@_date: 1994-08-19 13:18:30
@_author: Wei Dai 
@_subject: timestamp.c mangled 
timestamp.c was partially mangled, so I am sending it again, this time
using PGP ascii-armor.
PGP Public Key available

@_date: 1994-08-19 13:18:42
@_author: Wei Dai 
@_subject: trusted time stampin 
********** Original       To: TCMAY
 * CARBON *      was       By: WEIDAI
 *  COPY  *   posted:      On: ESKIMO
 **********              Conf: 0009 - Email

@_date: 1994-08-20 17:28:11
@_author: Wei Dai 
@_subject: coming soon: secure digit 
Can you give a more detailed description of the system? The specific
question I have is how exactly does a third party know that a time stamp
is not forged?  What algorithm or protocol does he use?
If there is more than one time stamping service and if they use
different systems, how do the courts know which ones to accept?
Wei Dai
PGP Public Key available

@_date: 1995-01-06 19:12:01
@_author: Wei Dai 
@_subject: A Fire Upon the Deep 
In article <199501052231.OAA11745 tcmay (Timothy C. May) says:
This is quite sensible given that in the Zone universe, you may have no
idea how much computing power your enemies have, so no cryptography
that is only computationally secure can really be trusted.
_A Fire Upon the Deep_ also describes how anarchy might work on a
galactic scale.  For example, Vinge seems to think that arbitration
organizations would be very important in such an anarchy and would
acquire military characteristics.  Issues of trust and reputation
are also treated implicitly.
There was some recent talk about network agent technology on this list.
Vinge mentions almost in passing how an entire planet (or maybe planets)
was taken over by an "intelligent net packet".  Makes me rather nervous
about things like Magic Cap...
One more thing that's marginally related to cypherpunks (hey I really
like this book so I'll take any chance I can to talk about it ;-) is
the idea that the efficiency of distributed computation (and distributed intelligence) depends on high bandwidth and low latency of the communication
medium.  Since anonymity seems to have rather high costs in terms of
bandwidth and latency (compare anonymous e-mail with internet video
conferencing or even with normal e-mail), this implies that
an organization of anonymous agents will not work as efficiently as
a similar orginzation whose members are not concerned about
Wei Dai
PGP encrypted mail welcome.

@_date: 1995-01-07 10:47:56
@_author: Wei Dai 
@_subject: Re: A Fire Upon the Deep 
Anonymous e-mail that goes through a chain of N remailers will cost at
least N times as much bandwidth and have N times as much latency as normal
e-mail.  But e-mail is hardly the state-of-the-art of network
communication, while anonymous e-mail IS the state of the art for
anonymous communication.  How long will it take for the technology of
anonymous video conferencing to develope, for example?  By then, of
course, those who are not concerned with anonymity will probably have
things such as full sensory virtual interaction. Note that I SUPPORT anonymous communication, but its costs of bandwidth and latency may be a real obsticle to developing Cryptoanarchy (of the kind described by Tim May) if most people are not willing to put up with those costs.
Wei Dai
PGP encrypted mail welcome.

@_date: 1995-01-07 12:51:25
@_author: Wei Dai 
@_subject: Re: Latency Costs of Anonymity 
The points Tim makes here are quite good.  However, I'm more concerned with a slightly longer time scale, when people focus less on FILES, but more on CONVERSATIONS and INTERACTIONS.  It is then that latency becomes more problematic.
Can anyone give me an estimate of when truly anonymous video conferencing will become possible?  This is not just to help me make the point, but I'm really wondering.
Wei Dai

@_date: 1995-01-07 16:37:54
@_author: Wei Dai 
@_subject: Re: Latency, bandwidth, and anonymity 
Are there any theoritical tools developed especially for this type of analysis?  If so, can anyone provide some references?
Secrecy will of course have to come before anonymity.  I am eagerly awaiting Voice PGP, but unfortuanately can't make the Demo Day meeting.  Will someone please report the highlights?
So, the situation: high-latency, low-bandwidth e-mail remailers
the goal: low-latency, high-bandwidth interactive A/V type anonymity, but this seems too far away
Perhaps we can tackle the problems of latency and bandwidth seperately.  That is, develop 2 sets of anonymity tools:
1. low-latency, low-bandwidth, for use in textual interactions such as MUD and IRC
2. high-latency, high-bandwidth, for non-interactive A/V use, perhaps anonymous TV broadcasting
I'm not too familiar with DC-nets, but they can probably be used as tool set  (correct me if i'm wrong) How about tool set number 2?
Indeed, Vinge makes use of such a trick in True Names.  If I remember correctly, the technology in the story includes the ability to compress full virtualy reality type interactions down to a few hundred bytes per second! (maybe is was thousands, but either way it seems unlikely) Vinge seems to be a stronger believer of compression.  There is a
similar technology in A Fire Upon the Deep.

@_date: 1995-01-07 17:08:42
@_author: Wei Dai 
@_subject: Re: Latency Costs of Anonymity 
The problem here is that you'll have to do a RSA operation on EACH packet.  Pretty hard on the CPU...
I'm not exactly sure what you mean by "factor-of-N".  I only used "true" to distiguish it from "trivial" anonymity (such as using a pay phone).  Of course, anonymity, like security, can only be relative.
This is all very true.  I guess I'm just lamenting the loss of my ealier,
more naive dream that one day everyone will be anonymous (read
pseudonymous), and that physical and digital identities will be totally
seperate. Wei Dai
Who should really start signing his posts but left his key in another

@_date: 1995-01-07 18:02:18
@_author: Wei Dai 
@_subject: Re: Latency, bandwidth, and anonymity 
Oops, I didn't mean to exhort anyone to actually make the tools, but was
just thinking about the feasibilities.  (I know, "Cypherpunks write code",
not "Cypherpunks convince others to write code." ;) OTOH, I DO think
people with anonymity needs will pay for lower latency and/or higher
bandwidth (right now probably tool set  will have a greater demand,
given the heavy use of MUDs and IRC). In the longer term, anonymous communication is in danger of being used
only by fringe groups if it falls too much behind the non-anonymous kind
in terms of latency and bandwidth (and cost, I guess).  Maybe ONLY drug
dealers, nuclear terrorists, etc., will use anonymous remailers when full
sensory virtual interaction is the must popular way for most people to
communicate and remailers are still the only choice for the
anonymity-conscious.  By then, the remailers themselves will be in
danger of being outlawed, or just close down for lack of business.
I think limited virtual interaction can be available on the Internet in 5 years (in prototype), so I sure hope anonymous A/V is not that far off.
I know, I know, the market will decide...  But second guessing the market can be fun and sometimes profitable.  Just look at all those people trying to make money on the stock market.
Sorry if I'm hammering the subject to death...
Wei Dai

@_date: 1995-01-08 19:27:03
@_author: Wei Dai 
@_subject: Remailer security 
This is why you want to use a remailer chain instead of just one remailer.
Hopefully, not all of the remailers in your chain are subverted by your enemy.  (They may all be subverted, but as long as not by people who cooperate with your enemy you're still ok :-)  Also, make your chains as heterogeneous as possible.  That is, include remailers that use different hardware, operating systems, remailer softwares, are in different countries, are controlled by different organizations, etc., so that one security hole will not compromise your entire chain.
I've kinda evaded the original question, which is about the (average?) security of the individual remailers.  Does anyone have a real answer?
Wei Dai
PGP encrypted mail welcome.  (I realize a PGP signature says this implicitely, but I left my key in another computer.)

@_date: 1995-01-09 00:04:06
@_author: Wei Dai 
@_subject: Re: Vinge's True Email name ? 
A general hint for finding authors' e-mail addresses: figure out where he/she works from the book jacket, use WHOIS to find their domain name, and then finger them or look at their web page to see if they have an e-mail directory.  (Now keep this a secret!  I don't want the internet.masses to find out my e-mail address when I become rich and famous! :-)
I bet Vinge has written for himself a really intelligent filter like the kind he describes in AFUtD.  Of course I wouldn't want to test this.
I guess this is not really related to cypherpunks, except to the general philosophy of making tools to protect oneself, instead of relying on the good will (and intelligence) of others.
Wei Dai

@_date: 1995-01-09 00:56:36
@_author: Wei Dai 
@_subject: Re: Latency, bandwidth, and anonymity 
Video conferencing was just ONE of the applications of high-bandwidth, low-latency anonymous communication.  Maybe it was a bad example.  Here's a couple more:
1.  anonymous distributed computing: suppose Alice wants to help Bob crack a secret key by using both of their computers, but the algorithm entails some heavy exchange of data between them
2.  anonymous remote consulting: Alice is building a nuclear bomb and needs help, so she sends a live video feed of her workshop to Bob (and have the computer blot out her face in real time).  Bob sends Alice an audio only commentary of what Alice is doing wrong.
We tend to focus on the more exotic applications of these tools, but as
mjk pointed out they will have perfectly ordinary uses by people who
simply don't want everyone in the world to be able to know everything
about them. Maybe Alice just wants to call AT&T to ask about their Clipper
phone, and not have everybody realize that and send her a bunch of
propaganda about Voice PGP.  :-) Even now, this may not be as implausible
as it sounds.  What if Alice is using MCI as the long distance carrier,
and MCI happens to be selling Voice PGP? Wei Dai

@_date: 1995-01-12 06:02:40
@_author: Wei Dai 
@_subject: analysis of RemailerNet 
I've been reading through T.C. May's FAQ, and came upon this section about analyzing the RemailerNet.
I think one of the most difficult aspects of analyzing remailers is the large number of variables you have to deal with.  In contrast, when analyzing ciphers things are pretty much static.  The only thing variable you have to worry about is key length.  But think of the factors you have to include in a complete analysis of the RemailerNet:
1.  different methods of attack
        - passive traffic analysis (i.e., packet sniffing)
        - active attacks: including physical attacks, subverting           remailer security, flooding, denial-of-service,
          starting "trap" remailers, etc.
2.  differences at the user level
        - fixed vs random chains vs something in between
        - length of chains
        - numbers of real messages sent
        - numbers of fake (cover) messages sent
        - concerns about latency, bandwidth, and monetary costs
        - acceptibility of risk, and benifits of anonymity
3.  differences at the individual remailer level
        - the mixing mechanism: does batched mailing occur by time or by the
          number of messages in the queue, and is there a rollover pool?
        - security: including vulnerabilities to political,           physical, and electronic attacks
        - usage level
        - price
4.  differences at the RemailerNet level
        - total numbers of remailers
        - average security (or the number of compromised remailers)
        - total number of users
... and I'm sure there are more.  The number of variables and the complex way they're all interrelated make the analysis difficult.  Perhaps a good way to go about this is to construct simplified models which focus on different aspects.  For example, someone pointed out that if you didn't have to worry about active attacks, and the attacker can monitor all the remailers, then you can treat the entire RemailerNet as a single large remailer.  I'm not sure how well this approach would work, since I don't know how easy it would be to integrate the different simplified models into a realistic one.
Anyhow, this might at least give us some insights, so I'll make some attempts in this direction, and post my results.
Just to start things off though, let me try an *extremely*
simple model.
Assume there is just one remailer, it's perfectly secure, and it does 4 batches of remailing at equal intervals each day.  There are one million users, each of whom receives a mail from the remailer once per day.  Alice is sending anonymous mail to Bob through this system, also once per day.  But just to be extra careful, she also sends a cover mail to the remailer at some other time each day, which gets redirected to its /dev/null.
So the situation looks like this on day 1:
            Alice sends     Bob receives     some random user receives
Batch        0                0                   0
Batch        1                1                   0
Batch        0                0                   1
Batch        1                0                   0
Suppose Eve, the traffic analyst, is trying to figure out who Alice is sending mail to.  After the first day, she can eliminate about half of the remailer users from the list of possible targets, because they, like the the random user above,
received a mail even though Alice didn't send one out during the collection period of that batch.  Now, since Eve can eliminate on average half of the list every day, Bob will be the only person left on that list after about (log base 2 of one million) = 20 days.
Suppose Alice sent out some different numbers of cover e-mail:
        # of cover mail     # of days to discover Bob
               0               log base 4 of 1,000,000 = 10
               1               log base 2 of 1,000,000 = 20
               2               log base 4/3 of 1,000,000 = 48
               3               log base 1 of 1,000,000 = infinity!
Hopefully that makes sense...  Comments?
Wei Dai

@_date: 1995-01-12 06:26:07
@_author: Wei Dai 
@_subject: time stamping service (again) 
My PGP based time stamping service is back online.  I took it down a while ago thinking the folks at notary.com (Digital Time-Stamp, Inc.) were going to release their commercial time stamping product soon (it uses a more elegant protocol that
doesn't require trust in the time stamper, but the algorithm
is patented).  But I haven't heard anything from them in a while.
Anyway, it is now running as the following procmail recipe:
:0 w
* ^Subject: Time Stamp This Mail
:0 c w
+clearsig=off) > timestamp.out
:0 a h
($SENDMAIL -t ;rm -f timestamp.lock)
To use it, just send whatever you need time stamped to me with the subject "time stamp this mail".
BTW, can a procmail expert explain to me why the locallockfile mechanism doesn't work with this recipe?  If I use :0 w : as the first line, procmail will happily ignore the locallockfile flag and proceed to munge up timestamp.out, so I have to do the filelocking manually.
Wei Dai

@_date: 1995-01-19 22:43:25
@_author: Wei Dai 
@_subject: Re: The Remailer Crisis 
Can anyone give an overview of the remailer packages that are currently
available?  What features and differences do they have, and where to get

@_date: 1995-01-19 22:52:53
@_author: Wei Dai 
@_subject: traffic analyzing Chaum's digital mix 
I have been thinking about the problem of traffic analysis of a remailer.  More specifically, the problem is how can Eve trace Bob, who is communicating with Alice through an ideal Chaumian digital mix?  (As most of you know, current remailers are missing many of the features of the digital mix Chaum specified in his CACM paper (at ftp://ftp.csua.berkeley.edu/pub/cypherpunks/papers/chaum.digital-mix.gz ), thus making them extremely vulnerable to anyone with non-trivial The simplifying assumptions I use here are:
1.  there is one mix, which is perfectly secure and trustworthy (note     that multiple mixes do not increase untracebility over a single mix if     it is perfectly secure and trustworthy)
2.  anyone can monitor all traffic in and out of the mix, but no one can     link an incoming message with an outgoing one
The basic approach is to use this raw traffic information to calculate a SCORE for each user of the remailer with respect to Alice, where the user with the highest SCORE is the person Alice is most probably communicating with.  The idea is that with a Chaumian mix, every time Alice sends a message to Bob there is always a pattern of Alice sending a message to the mix, followed by Bob receiving a message from the mix during the next batch.  By counting the number of such correlations for each user over a period of time, and taking into account the fact that users who receive more messages from the mix will have higher numbers
of coincidental correlations, a SCORE can be calculated so that it would be a good indication over the long run of the probability that a particular user is communicating with Alice.
For a digital mix that does batching based on a fixed number of incoming messages, the SCORE for a user U can be calculated in the following way:
1.  for each mix batch i, calculate P(i)=lesser(# of messages sent by     Alice, # of messages subsequently received by user U)
2.  after a period of time t, calculate Q=sum(P(i))
3.  calculate the average value of Q of users with similar usage     patterns as user U
4.  SCORE(U) = Q / average(Q)
Now whether or not this approach actually works depends on whether the number of users with SCORE higher than Bob's SCORE converges to 0 as time t increases, and how quickly it converges.  Answering these two questions will require modeling the usage patterns of Alice, Bob, and the mix as a whole.  I'll try to do this for some simple cases in a later
Wei Dai

@_date: 1995-01-20 19:22:33
@_author: Wei Dai 
@_subject: Re: traffic analyzing Chaum's digital mix 
Latency (by which I take to mean some kind of random delay) will probably make the analyst's job harder, but I suspect not by much.  The method of analysis I outlined earlier can be modified to apply to mixes that use random delay instead of batching as the method of mixing.  Instead of adding up the number of times Alice's message to the mix is followed up by a message from the mix to a user, take the sum of the probabilities that each message the user receives is from Alice.
So you would do something like this for each user of the mix:
Each probability can be calculated from the statistical distribution of the delay time, the length of time between the Alice sending the last message to the mix and the user receiving a message from the mix, and the timing and number of other messages sent by the mix around this period of time.
This method is more general than the one I talked about earlier, since it is equivelent to the former method when you apply it to a batching mix (that is, the original Chaumian mix).

@_date: 1995-01-22 19:19:21
@_author: "Wei Dai" 
@_subject: Re:  traffic analyzing Chaum's digital mix 
I found a copy of these proceedings in the library today.  There is a
paper titled "How to break the direct RSA-implementation of MIXes"
by Birgit Pfitzmann and Andreas Pfitzmann.
Here is its abstract:
MIXes are a means of untraceable communication based on a public key
cryptosystem as published by David Chaum in 1981 (CACM 24/2 84-88).
i.e. without composition with other functions (e.g. destroying the
multiplicative structure) we show how the resulting MIXes can be
broken by an active attack which is perfectly feasible in a typical
MIX-environment. if the security requirements of [Chaum's paper] are concretized suitably and if a cryptosystem fulfills them one can implement secure MIXes directly.  However it shows that present security notions for
public key cryptosystems, which do not allow active attacks
do not suffice for a cryptosystem which is used to implement MIXes directly. possible implementations of MIXes and we mention several implementations
which are not broken by any attack we know.
My interpretation is that PGP-based remailers are not susceptible to
the attack described by this paper.  (Of course, they are currently vulnerable to much more trivial ones.)
Wei Dai

@_date: 1995-01-25 16:58:19
@_author: "Wei Dai" 
@_subject: Re: Remailer 
Hmm... this sounds very similar to the results of my analysis which I posted yesterday (Subject: analysis of Chaum's MIX
continued), which I think is slightly more general.
Plugging these numbers into my formula, the "threshold of
tracibility" comes out to be 4 messages.  This is probably due to the fact that I used a normal approximation for the binomial probability (the p in the above formula).
The general conclusion however is the same: unless most users send a lot of dummy mail to each other, a Chaum type mix will not provide very good untracibility.
The other possible way to increase untracibility is to decrease the number of batches per unit time (i.e., increase average latency).  This implies that with a Chaumian mix, there is an unavoidable tradeoff between untracibility, bandwidth (i.e., how much dummy mail has to be sent), and latency.
Wei Dai

@_date: 1995-01-26 15:48:07
@_author: "Wei Dai" 
@_subject: Re: Reordering, not Latency (Was: Re: Remailer) 
Andrew Lowenstern asks:
Given the current state of computer security, this should not be too difficult for an organization such as NSA.  For each remailer, just hack into a computer on its local ethernet and put it into promiscious mode.  Each time an e-mail passes by, have it send the header to some monitoring center using an UDP packet.
Complete monitoring should not be neccessary, having a larger percentage of the traffic just makes the job easier.
Wei Dai
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> Big Bang --> atoms --> complex macromolecules --> biological evolution
--> central nervous systems --> social learning --> symbolic communication
--> computers --> internetworking --> close-coupled automation
--> high-bandwidth brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-01-27 00:00:01
@_author: "Wei Dai" 
@_subject: link encryption and anonymous interactivity (Was: "Subway" remai 
This gives me an idea.  Imagine a server that allows you to open a low bandwidth (let's say around 100 cps, in order to reduce costs)
link-encrypted telnet session with it, and provides you with a number of services, for example a link-encrypted talk session with another user.  You'll need to maintain the link 24 hours a day to defend against statistical analysis, and of course you can chain a number of these servers together in a way similiar to chaining remailers.
This scheme seems to provide untracibility while getting around the latency cost problem of remailers, thus allowing users to talk to each other in real time, anonymously.
Wei Dai
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> Big Bang --> atoms --> complex macromolecules --> biological evolution
--> central nervous systems --> social learning --> symbolic communication
--> computers --> internetworking --> close-coupled automation
--> high-bandwidth brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-01-27 00:17:03
@_author: "Wei Dai" 
@_subject: Traffic monitoring (Was: Reordering, not Latency) 
How would you get access to the trunks?  Aren't they mostly optic fibers now?  Also, since Internet traffic is growing at a geometric rate, the probability of anyone or any organization having the capacity to monitor and process ALL of Internet traffic should be very small and decreasing.  It would be much easier to install sniffers on selected local networks (e.g., those containing remailers or other entities you're interested in).
Wei Dai
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> Big Bang --> atoms --> complex macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> consciousness
--> computers --> internetworking --> close-coupled automation
--> high-bandwidth brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-02-03 21:59:13
@_author: "Wei Dai" 
@_subject: Re:  commercial authecation 
This technology is very clever and bound to be extremely important.  But does anyone else think that the price is a little high?  I mean the marginal cost can't be more than a few seconds of CPU time for each time stamp...
This price tag will temporarily put the time stamp technology out of ubiquitous use, where every piece of e-mail, homework paper, Usenet post, etc., is automaticly time stamped in a cryptographically secure way so that authorship can be asserted and proved.  I think the need for proof of authorship is going to become increasingly important in an increasingly online world, where copying is so effortless, and reputations are based on digital identities.
Wei Dai
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> singularity --> atoms --> macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> homo sapiens
--> digital computers --> internetworking --> close-coupled automation
--> broadband brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-02-06 17:23:00
@_author: "Wei Dai" 
@_subject: a simple explanation of DC-Net 
The DC-Net is not very easy to understand.  I'll try to explain the most
important parts of the concept as simply as I can.
Let's say there are a number of participants in a DC-Net.  Each
participant shares a different one-time pad with each of several other
At most one participant can send one bit through the DC-Net per "round".
How does this work?  For each round i, a participant takes the i-th bit
of all the one-time pads that he has and XORs them together.  If he
doesn't want to send a bit, he just broadcasts the resulting bit to
every other participant.  If he DOES want to send a bit, then he
broadcasts the XOR of that resulting bit and the bit he wants to send.
When everyone has done this, each participant takes all of the bits that
has been broadcasted, and XORs them together.  This last action produces
the output of the DC-Net for the i-th round.
Suppose for the first round nobody wants to send a bit.  Since each one-
time pad is known by 2 participants, the first bit of each pad has been
XORed into the final output twice.  Since anything XORed by anything
twice equals itself, these two XORs cancel each other out.  And since
nothing else has been XORed into the output, the output must equal 0.
If one participant wanted to send a bit, however, then something else
HAS been XORed into the output.  Since all the bits from the one-time
pads cancel out, the output equals the bit he wanted to send.
Wei Dai
P.S.  I realize someone has probably written something like this
already, but I hope this explanation helps someone who is still
puzzled.  If nothing else, it serves as a sanity check on my own
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> singularity --> atoms --> macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> homo sapiens
--> digital computers --> internetworking --> close-coupled automation
--> broadband brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-02-06 19:28:34
@_author: "Wei Dai" 
@_subject: (dis)advantages of DC-Net vs remailers 
I tend to favor remailers + broadcasting + anonymous-return-addresss
over the DC-Net protocol.  Let me list some of their relative advantages and disadvantages.  Please add to these if you can think
of more...
Advantages of DC-Net over remailers
Disadvantages of DC-Net
I think over the long run the last factor will be most important.  In a DC-Net, for each bit one participant wants to send to another, EVERY
OTHER participant must broadcast a bit to ALL participants.  I can imagine a remailer-net with one million users, but I don't see any possibility that a DC-Net can be scaled to that size.
Wei Dai
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> singularity --> atoms --> macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> homo sapiens
--> digital computers --> internetworking --> close-coupled automation
--> broadband brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-02-07 17:32:30
@_author: "Wei Dai" 
@_subject: a new way to do anonymity 
A week ago I made a suggestion for a new protocol for untracibility, but only got one response.  I'll try again, this time more forcefully.  I'm not trying to convince anyone to implement this (though of course you're welcome to!), but just to think about it and give me feedback.
Why is another protocol needed?  Right now we have only two, each of which has its own set of tradeoffs.  To summarize:
While the DC-Net will probably never be widely used, the remailer-net has a fair chance of one day providing a way for many people to send e-mail that not even governments can trace.  However, I don't think this is enough.  Efficient social and business relationships require that people be able to converse to each other in real time.  Cryptoanarchy will not come about if people cannot do this anonymously.  How well can two pseudonymous agents negotiate a contract if each message they send must be delayed several hours?  The protocol I sugguested would have low latency, moderate bandwidth costs, and moderate complexity.  It would be well suited for people to interact anonymously in a textual environment.
Lance pointed out the chain cannot be built quickly.  This is not a problem
if servers connect to each other with relatively wide link-encrypted pipes
and multiplex your connection into these pipes.
In this system, latency would never be more than a few seconds, bandwidth
cost is N*100 cps (point to point), N being the number of links in your chain.
Implementation would probably be harder than remailers, but much easier
than DC-Nets.  The protocol would also provide both sender and receiver
untracibility without any need for broadcasting.
Wei Dai
P.S. I never gave a name for the protocol... let's call it Pipe-net.
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> singularity --> atoms --> macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> homo sapiens
--> digital computers --> internetworking --> close-coupled automation
--> broadband brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-02-08 14:44:03
@_author: "Wei Dai" 
@_subject: RE: a new way to do anonymity 
Now that I've just spent some time compiling and playing with Matt's ESM
program, it seems almost perfectly suited for prototyping Pipe-Net since you can use it to do nested encryption.  All that's needed is to hack it so that it implements link encryption (i.e., send a
constant stream of random data in between keypresses).
This is what the user would do: (LESM for Link Encrypted Session Manager)
lesm -l
lesm -l
login to server 1
lesm -s
lesm -l (or better yet take over a free LESM session already running
login to server 2
lesm -s
lesm -s
I wonder if Matt has the time and interest do this...  If not then I guess I can try, but I've never done real crypto programming before...
Wei Dai

@_date: 1995-02-09 17:50:02
@_author: "Wei Dai" 
@_subject: RE: a new way to do anonymity 
I'm not sure I understand the first question.  My idea was originally based on link encrypted streams.  How can forwarding variable length packets help untracibility?  Wouldn't an attacker just have to match up the sizes of incoming and outgoing packets?  Forwarding fixed length packets, on the other hands, just makes the system a remailer-net (so you'll have to do mixing, etc.).  What am I misunderstanding here?
I just finished hacking ESM to do link encryption.  (see my other post)  Now if someone is willing to run a MUD type program and hook LESM up with it, then we'd have the first prototype of a Wei Dai
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> singularity --> atoms --> macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> homo sapiens
--> digital computers --> internetworking --> close-coupled automation
--> broadband brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-02-09 17:52:22
@_author: "Wei Dai" 
@_subject: RE: a new way to do anonymity 
It seems to me that if a user maintains a 24-hour a day pipe to an uncompromised server, then the method I described earlier against remailers should not work against that user.  Otherwise, some kind of in-out statistical analysis may work.
See Verner Vinge's _True Names_ for a fictional description of a future where real time anonymous interactions are possible.
This is certainly true.  The system Vinge describes is almost a pipe-net.  But he didn't say anything about link encryption, without which the system can be trivially broken.
I haven't responded to the comments you made about the similarity between pipe-net and ATM, mostly because I'm not very familiar with ATM.  But as I understand it, ATM is based on forwarding fixed length cells, whereas pipe-net is based on fixed-bandwidth link encrypted streams.
Spamming, and flow control shouldn't be problems, since all users of a server will connect to it with pipes of the same bandwidth, so it can just accept a certain number and then stop.
Bandwidth limitations will depend on how fast the server CPU can do the encryption and decryption.  With LESM at 100 cps, each connection took 2% of the CPU capacity of a Sun 4-CPU(90Hz) 4/670MP.  Of course, I made no consideration for efficiency when I hacked ESM, so this can probably be decreased quite a bit.
Wei Dai
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> singularity --> atoms --> macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> homo sapiens
--> digital computers --> internetworking --> close-coupled automation
--> broadband brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-02-09 18:43:52
@_author: "Wei Dai" 
@_subject: LESM - Link Encrypted Session Manager (3rd try) 
I tried to distribute LESM to the cypherpunks mailing list twice, and neither of them made it to the nntp.hks.com list archive (my laster posts HAVE).  What is going on here?  This is a second repost.
-----BEGIN PGP SIGNED MESSAGE-----
I finished hacking Matt's ESM to do link encryption yesterday, but for some reason the mail I sent to cypherpunks didn't get echoed back to me, so I'm sending this again.
To install: get ESM and RSAREF, make sure you can compile ESM, then replace the esm.c with my hacked version and recompile.
To use: same as ESM, but there's an extra option "-b bandwidth", the default is 100 cps.
I've attached the modified esm.c here since it doesn't include any crypto code.  To get ESM, write to cfs and state the RSAREF is in ftp://rsa.com/rsaref/
Wei Dai
-------------- Enclosure number 1 ----------------
 * LESM - Link Encrypted Session Manager
 * v0.6a.01
 * Wei Dai
 * 2/8/1995
 *
 * This program is a quick and dirty hack of:
 */
 * ESM - Encrypted Session Manager
 * v0.6a
 * matt blaze
 * January 1995
 */
 * The author of this software is Matt Blaze.
 *              Copyright (c) 1995 by AT&T.
 * Permission to use, copy, and modify this software without fee
 * is hereby granted, provided that this entire notice is included in
 * all copies of any software which is or includes a copy or
 * modification of this software and in all copies of the supporting
 * documentation for such software.
 *
 * This software is subject to United States export controls.
 *
 * THIS SOFTWARE IS BEING PROVIDED "AS IS", WITHOUT ANY EXPRESS OR IMPLIED
 * WARRANTY.  IN PARTICULAR, NEITHER THE AUTHORS NOR AT&T MAKE ANY
 * REPRESENTATION OR WARRANTY OF ANY KIND CONCERNING THE MERCHANTABILITY
 * OF THIS SOFTWARE OR ITS FITNESS FOR ANY PARTICULAR PURPOSE.
 */
 * Some of this file was stolen from the BSD "script" program, which
 * is covered under the following notice:
 *
 * Copyright (c) 1980 Regents of the University of California.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions and the following disclaimer.
 * 2. Redistributions in binary form must reproduce the above copyright
 *    notice, this list of conditions and the following disclaimer in the
 *    documentation and/or other materials provided with the distribution.
 * 3. All advertising materials mentioning features or use of this software
 *    must display the following acknowledgement:
 *	This product includes software developed by the University of
 *	California, Berkeley and its contributors.
 * 4. Neither the name of the University nor the names of its contributors
 *    may be used to endorse or promote products derived from this software
 *    without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE REGENTS AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED.  IN NO EVENT SHALL THE REGENTS OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 */
 lint
char copyright1[] =
" Copyright (c) 1980 Regents of the University of California.\n\
 All rights reserved.\n";
char copyright2[] =
" Copyright (c) 1995 AT&T\nAll rights reserved.\n";
 /* not lint */
    SUN
       "global.h"
 "rsaref.h"
 "esm.h"
char	*shell;
int	master;
int	slave;
int	subchild;
int escape=036; /* ^^ */
int ciphstate=0;
int ciphbyte=0;
int keyed=0;
struct	termios tt;
struct	winsize win;
int	lb;
int	l;
char	line[] = "/dev/ptyXX";
int	aflg;
 REMOTE 0
 LOCAL 1
 CALC 2
int mode=LOCAL;
int paranoid=0;
 SL_START 0
 SL_GOT1 1
 SL_GOT2 2
 SL_GOT3 3
 SL_GOT4 4
 SL_KEYING 5
 SL_CRYPT 6
int sloutstate=SL_START;
char *cmd=NULL;
 TRANS 0
 CMDWAIT 1
 CIPHER 2
 KEYWAIT 3
 IV0 0
 IV1 1
 IV2 2
 IV3 3
 C0  4
 C1  5
int state=TRANS;
int cstate=IV0;
FILE *fpmaster;
struct timeval tvPause={0,10000};
struct timeval tvNoPause={0,0};
unsigned char filler = (unsigned char) 31;
 bwrite(fp,buf,len) (fwrite(buf,len,1,fp))
main(argc, argv)
        struct timeval tv;
                    case 'b':
                    	tvPause.tv_usec=(long)1000000/atol(optarg);
                        break;
      	getmaster();
                while(1)
                {
                        tv=tvNoPause;
                        result=select (FD_SETSIZE,&fds,NULL,NULL,&tv);
                        if (result==1)
                        	doinput();
      	                if (mode==LOCAL && sloutstate==SL_CRYPT && result==0)
                        	doslavein(filler);
                        if (result<0)
                        	break;
                        tv=tvNoPause;
                        result=select (FD_SETSIZE,&fds,NULL,NULL,&tv);
                        if (result==1)
                                dooutput();
                        if (mode==REMOTE && state==CIPHER && result==0)
                        	domasterout(filler);
                        if (result<0)
                        	break;
        	tv=tvPause;
                select (FD_SETSIZE,NULL,NULL,NULL,&tv);
     unsigned char ibuf;
                                if (ch!=filler)
int pubstat=0;
int pubpos=0;
unsigned char pubbyte=0;
int pksize = -1;
     char c;
                                if (ch!=filler)
doshell()         sbuf = tt;
        sbuf.c_iflag &= ~(INLCR|IGNCR|ICRNL|IXON);
        sbuf.c_oflag &= ~OPOST;
        sbuf.c_lflag &= ~(ICANON|ISIG|ECHO);
        sbuf.c_cc[VMIN] = 1;
        sbuf.c_cc[VTIME] = 0;
     FILE *fp;
     unsigned int c;

@_date: 1995-02-10 13:33:34
@_author: "Wei Dai" 
@_subject: law vs technology 
Recently there's been a great deal of discussion on this list
about upcoming legislations (HR666 S314 etc.).  Maybe it's time
to step back a little and look at the bigger picture.  I've
been assuming (perhaps incorrectly) for some time that most
cypherpunks hold a belief somewhat like the following:
There has never been a government that didn't sooner or later
try to reduce the freedom of its subjects and gain more control
over them, and there probably never will be one.  Therefore,
instead of trying to convince our current government not to
try, we'll develop the technology (e.g., remailers and ecash)
that will make it impossible for the government to succeed.
Efforts to influence the government (e.g., lobbying and
propaganda) are important only in so far as to delay its
attempted crackdown long enough for the technology to mature
and come into wide use.
But even if you do not believe the above is true, think about
it this way:  If you have a certain amount of time to spend on
advancing the cause of greater personal privacy (or freedom, or
cryptoanarchy, or whatever), can you do it better by using the
time to learn about cryptography and develop the tools to
protect privacy, or by convincing your government not to invade
your privacy?  I argue that since there are many more people
doing the former (EFF, CPSR, etc) than latter, that you'd be
more effective if you spent the time on the former.
Wei Dai
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> singularity --> atoms --> macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> homo sapiens
--> digital computers --> internetworking --> close-coupled automation
--> broadband brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-02-13 11:10:02
@_author: "Wei Dai" 
@_subject: Re: Is Cyberspace Rich Enough? 
I'm not sure that thousands of remailers will ever exist.  There will be little incentive for people to use small remailers, which, because of their low traffic, add little untracibility per additional unit of latency and monetary costs compared to larger remailers.  Larger remailers will also likely have better reputations for trustworthiness.  The economics seem to indicate that (if a market of remailers is ever established) there will be a small number (less than a hundred) of large remailers that are well used and profitable, and a larger number of small remailers that are nearly never used.
Remailers don't seem to be a good way to access the WWW, which is much more efficient when done interactively.  On the other hand, my proposed Pipe-net would seem to be perfect for this, and other communications that need both untracibility and low latency.
Wei Dai
P.S. People are more likely to respond to things they don't agree with (as I did here).  If you write something and no one responds, it probably means that everyone except the lurkers agree with you, so take it as a good sign.
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> singularity --> atoms --> macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> homo sapiens
--> digital computers --> internetworking --> close-coupled automation
--> broadband brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-02-13 13:07:01
@_author: "Wei Dai" 
@_subject: Re: Is Cyberspace Rich Enough? 
[deleted]
I agree that cyberspace is certainly becoming more complex and
interconnected.  However, just as a complex ecosystem is not necessarily
more stable than a simple one, and a complex cipher is not necessarily
more secure than a simple one, greater complexity in cyberspace does not
necessarily imply that it is less vulnerable to to centralized control.
[more stuff deleted]
But if you wanted to exert greater control over others, you would also
be pushing for increased dimensionality, because that shrinks the world
and moves everyone closer to you.  If you look at history, increased
connectivity has always been necessary for increased central control.
What I am saying is that increased connectivity alone does not
necessarily favor decentralization.  What makes the difference is the
details -- the nature of the connectivity.
I'm not quite so optimistic.  One way to control a distributed system
such as the Internet would be to use a distributed method.  I.e., use
something like the Internet Worm, but a thousand times subtler and more
powerful.  There is no need for them to "stop the Net", just to subvert
a substantial part of it.
Wei Dai
E-mail: Wei Dai    URL: "
=================== Exponential Increase of Complexity ===================
--> singularity --> atoms --> macromolecules --> biological evolution
--> central nervous systems --> symbolic communication --> homo sapiens
--> digital computers --> internetworking --> close-coupled automation
--> broadband brain-to-net connections --> artificial intelligence
--> distributed consciousness --> group minds --> ? ? ?

@_date: 1995-09-06 17:48:44
@_author: Wei Dai 
@_subject: fast modular reduction 
During the Crypto' 95 Rump Session, Josh Benaloh of Microsoft Corp. presented a new modular reduction algorithm that he and I developed.  It is faster than the Montgomery method by about 10 to 15%, and is more general and easier to understand.  The central idea is that it is easy to reduce a number to an equivalent one that's just one "block" (machine word) longer than the modulus, by repeatedly subtracting off the highest block, and adding back something that's equivalent, but smaller.
In the following pseudocode, B is the radix in which the numbers are represented (2^32 for a 32-bit machine), n is the length of modulus in blocks, U is B^(n+1) mod the modulus, X is the number to be reduced, k+1 is the length of X, and Y is the result.
1. Y = X
2. For i from k down to n+1, repeat steps 3 and 4
3.	Y = Y - Y[i] * B^i + Y[i] * U * B^(i-n-1)
4.	If Y >= B^i, then Y = Y - B^i + U * B^(i-n-1)
Tricks can be used to eliminate step 4, and to reduce Y to n blocks using one single precision division, and n more single precision multiplications.  The algorithm will hopefully be written up more completely soon.
Wei Dai

@_date: 1995-09-07 16:47:38
@_author: Wei Dai 
@_subject: Re: fast modular reduction 
I agree with you that the patent hassle is probably not worth the speed increase.  If I came up with the algorithm by myself and on my own time, I certainly would not have filed a patent for it, but that wasn't the case.  I also agree that the patent system should be abolished, but there is nothing I can do about that either.
The speed increase does exist over Montgomery's modular reduction because it uses n*n multiplications and 1 division compared to n*(n+1) multiplications, and the pre- and post-calculations are much simpler.
Division using Karatsuba multiplication does seem to have a better asymptote, but is probably slower for most practical lengths.  Both Lenstra's LIP and Lacy's CryptLib use Montgomery for modular reduction.
The numbers you give are a bit off.  Assuming a 32-bit machine,
n=64 implies a 2048-bit modulus, and a 4096-bit number to be reduced. Also, Karatsuba should use 1/3 (2*64^1.58 / 64^2) the multiplications
rather than 1/5. Wei Dai

@_date: 1995-09-10 15:32:12
@_author: Wei Dai 
@_subject: question about reputation 
In an economy based on positive reputations, how does one acquire a reputation capital?  One way may be to initially perform services at a price below cost, but this has some problems.
For example, Alice starts a anonymous consulting service, and announces that she will answer the first ten queries for free.  Upon hearing this, Mallet immediately starts another consulting service, and announces the same offer.  At this point Mallet can simply forward his customers' queries to Alice and Alice's answers back to his customers.  Thus, he gains reputation at no cost.
On the other hand, this "man-in-the-middle" attack can also work against
conventional True Name based services, but perhaps with less effect.  Has
anyone ever heard of this being done? Is there a better way to acquire a good reputation?
Wei Dai

@_date: 1995-09-10 17:20:39
@_author: Wei Dai 
@_subject: Re: question about reputation 
This scheme doesn't quite work.  (Let's call Amalgameted Bob, to keep
names short.)  Bob can create a new, unlinkable pseudonym and give the same
offer to Carol under the new pseudonym.  Then, Bob acts as Mallet and
passes messages back and forth between Alice and Carol.  At the end of the
10 free questions, Bob terminates its contract with Alice, leaving Alice
with nothing and Bob's pseudonym a certain amount of reputation with
Carol. Fingerprinting may be useful in some situations, but is clearly not a
perfect solution to this problem.  Alice may be able to prove to Mallet's
customers that she originally wrote the answers, but if their
communications with Mallet are private, how does Alice even know who those
customers are?  Also, I'm not too familiar with fingerprinting
technologies, but Mallet may be able to remove the identifying marks by
translating the answers to a different form while preserving the meaning.
Wei Dai

@_date: 1995-10-27 11:40:07
@_author: Wei Dai 
@_subject: idle CPU markets 
With many high speed personal computers on the Internet and the deployment of low transaction cost Internet payment schemes, it seems inevitable that markets for idle CPU cycles and memory will develop.  An interesting problem is to try to predict who this market will benefit, and what the market will be used for.
So far it seems that cryptanalytic problems (e.g. factoring and brute forcing of keys) have the highest marginal value/MIPS among problems amenable to loosely coupled distributed computation.  However, I think it would be wasteful if the demand in idle CPU and memory markets were to be dominated by cryptanalysts since (non-academic) cryptanalysis is basicly a zero-sum game.  When a key is broken, no wealth is created, rather it is transfered from the owner of the key to the cryptanalyst.  What other problems would benefit from easy access to lots of distributed CPU cycles?
Wei Dai

@_date: 1995-10-05 12:01:48
@_author: Wei Dai 
@_subject: subjective names and MITM 
Neither certification hiearchies nor the PGP web-of-trust are very useful
because they try to bind True Names to keys and True Names have many
problems.  People can have duplicate names and can change their names
(what happens if I legally change my name to Bill Clinton and try to get
Verisign to certify my key under that name?), and often we don't care
about someone's True Name. Perhaps it is better to think of names as subjective identifiers, and
public keys as global ids.  That is, a person who has a collection of
public keys gives each of them a name, but different people can name their
keys differently.  Of course the holder of the corresponding private key
can help in the naming process (e.g., "Please call me Wei").  If two
people need to talk about a third party, they can refer to him by an
arbitrary name after establishing a common binding between his key and
that name. In this scheme, the man-in-the-middle problem goes away because you are no longer trying to communicate with a True Name, whose binding with a key can be spoofed, but rather with the key itself.  If the holder of that key chooses to act as a middle-man by relaying messages around, that is his business, and there is really nothing you can do about it.
Wei Dai

@_date: 1995-10-05 17:56:42
@_author: Wei Dai 
@_subject: Re: Certificate proposal 
I think Carl's point is that when you write an e-mail to Carl, you probably don't care that it reaches the "real" Carl Ellison, because you don't have a binding between the name "Carl Ellison" and the physical person.  A binding between a name and a key is useless if there is no binding between the name and the person.  Since this is the case, why not forget about the binding between the name and the key (or turn it into a local one as I suggested in the previous post) and go straight to the binding between the key and the person?
On the other hand, if you do have a binding between the name and the person, then most likely you met Carl at some point in the past and he told you his name was Carl Elison.  In that case it would have been just as easy for him to give you his public key instead.
Wei Dai

@_date: 1995-10-06 00:56:14
@_author: Wei Dai 
@_subject: Re: Certificates, Attributes, Web of Trust 
What is the point of this?  What is to prevent someone from
getting certificates for a million of the most common and/or famous names
as quickly as possible?
Wei Dai

@_date: 1995-10-08 14:20:40
@_author: Wei Dai 
@_subject: anonymous cash without blinding 
With all this talk about Chuam patents, I would like to remind people that blind signatures are not absolutely essential to an anonymous digital cash system.  You can combine a traceable cash system with an anonymous communication system in a fairly obvious way to get a fully (both payer and payee) anonymous cash system.
Suppose a bank is running a digital cash system that works like this: it maintains a database of valid coins, and whenever someone presents it with a valid coin (string of bytes) it erases that coin from its database, and then either gives the person an equivelent amount of paper cash or a newly created coin(s) of the same value.
Now if the bank allows this exchange of old coins for new coins to be done over an anonymous network (e.g., a remailer-net), then the system is anonymous as long as you don't move physical money in or out of the system.
Maintaining anonymity when moving physical money in and out of the system is what blinding helps you to do, but this will be less useful in a fully digital economy where such movement will be infrequent.
Wei Dai

@_date: 1995-10-11 01:07:01
@_author: Wei Dai 
@_subject: Internet, the cracking machine 
Ok, I'll bite.  Let's figure out how many MIPS years it takes to brute force various keylengths (assuming 100 instructions per key):
56: 2e3
64: 6e5
80: 4e10
128: 1e25
Andrew M. Odlyzko in his paper "The Future of Integer Factorization" estimates the computing power of the Internet at 3e7, and the number of
MIPS years to factor a 1024 RSA key to be 3e11.  I think both numbers are
probably off by a factor of 10 - Internet's computing power is probably
closer to 3e8 and MIPS years to factor 1024-bit key may be closer to 3e10. So assuming that you can get the entire Internet to help you, the amount of time it takes for various attacks is:
brute force keys of bit
56: 4 minutes
64: 1 day
80: 130 years
128: 3e16 years
factor RSA keys of bit
512: 20 minutes
768: 50 days
1024: 100 years
2048: 1e11 years
If you are reading this from an archive, divide the brute force numbers by
4**(your current year-1995), and the factoring numbers by 8**(your current
year-1995), for a factor of 2 improvement per year in each of the
following: average CPU power, number of computers on the Internet, and
factoring algorithm. (Note that the above estimates are meant to err on the low side.  I would
be VERY surprised if anyone actually manages to accomplish any of the
above attacks in the amount of time given.)
Wei Dai

@_date: 1995-10-16 01:18:51
@_author: Wei Dai 
@_subject: transaction costs in anonymous markets 
Some people have predicted (advocated?) frictionless capitalism, which will be brought about by the use of digital technology to reduce transaction costs.  However, in anonymous markets these costs may be quite high.  Two main components of transaction cost in an anonymous market will be the cost to maintain anonymity and the cost to evaluate reputations.
Maintaining anonymity requires that communications be done through special untraceable protocols.  The current state-of-art (i.e. RemailerNet) adds several hours of transmition time to each message to achieve effective untraceability.  Contract negotiation, for example, becomes very difficult under these circumstances.  Untraceable communications also use up more computing and communications resources.  Although remailers don't yet charge any money to pass along messages, this is sure to change in the future.  Unless the structure of the Internet is completely redesigned, untraceable messages will always cost more than traceable ones, although I hope this cost difference can be reduced through technical advances.
The second big part of transaction cost in an anonymous market is reputation evaluation.  Of course, normal, everyday transactions require reputations to be evaluated.  However, more effort and cost will be expanded on these evaluations in an anonymous market because the effects of misevaluations will be much more damaging.  Reputations must be constantly reevaluated, as pseodonyms are easily transfered.  Since no good theories of reputation currently exist, these evaluations are difficult to automate.  Perhaps theoretical advances can make these evaluations easier and/or more accurate.  However there does not appear to be any major research effort in this area.
If these costs remain high, but anonymous markets develop regardless, it will be interesting to see how these costs affect the structure of the markets.  Will special protocols for contract negotiations develop to minimize the number of round-trip messages?  Will each market be dominated by a few big entities because people can't keep track of reputations of many smaller players?  But then how will these big entities be organized?
Wei Dai

@_date: 1995-10-21 15:18:21
@_author: Wei Dai 
@_subject: Encrypted TCP Tunneler 
I am writting a program called Encrypted TCP Tunneler, which I hope to
finish in a month or so.  It will allow a secure link to be set up between
an ETT client and an ETT server, using Diffie-Hellman and DSA for
authenticated key exchange, and Blowfish for encryption.  A user will be
able to open a TCP connection to the client and have that connection
transparently tunnel across the secure link to a TCP address on the other
side. I see several uses for this program, such as secure telnet, secure web access, and access to a secure network across an insecure network.  I realize the program will no be as useful when IPv6 becomes widely available, but that may not happen for a while.  Also, this program can be used on top of IP security to give users (as opposed to system admins) more control over their own security.
Please send comments and suggestions.
Wei Dai

@_date: 1995-10-22 00:29:35
@_author: Wei Dai 
@_subject: Re: Encrypted TCP Tunneler 
Thanks for the suggestions.  These features have already been implemented.
WRT to anonymity, I plan to add link encryption after releasing the first I believe that using SOCKS requires changes to the application.  This will not be necessary with ETT, although as a price the user will have to do more work.  It may be possible to write a SOCKS to ETT adapter program.
ETT will allow the server to filter based on both the client's public key and the destination address.  I'm not sure how to implement this yet, but I hope to come up with a filtering scheme that will be general enough to be useful for many applications.
I completely agree with you.  I don't think there will be many free public accessable ETT servers, because of the above reasons.  Most ETT servers will probably be operated for private purposes.  Those that are not should either charge money to cover their expenses and risk, or allow connections to only a small range of addresses or ports.
Wei Dai

@_date: 1995-10-23 02:53:19
@_author: Wei Dai 
@_subject: Re: Encrypted TCP Tunneler 
I saw the announcement for ssh a while ago, but didn't get a copy because
it doesn't run under MS Windows.  I just downloaded a copy today and read
some of the documentation.  It apparently has many of the features I
talked about, plus lots more. However, I probably won't give up ETT yet, because there are some design differences that would make ETT more useful in certain circumstances.  SSH seems to be design mainly as a secure telnet program, with TCP port redirection added on, which suggests (although I'm not sure) that you need to have an user account on the SSH server to connect to it.  It also does not seem to do any filtering of TCP redirection requests.  Chaining would not work well with SSH because of its packet overhead.
I'll try to get SSH working soon, but so far I am very impressed with it.
I am curious, however, about your choice of key exchange and
authentication schemes.  What are the relative advantages of your protocol
over a more straight-forward DH + signature of exchange values?  DH would
provide forward secrecy directly without the need to change the server key
every hour. Wei Dai

@_date: 1995-10-24 14:04:22
@_author: Wei Dai 
@_subject: Re: How can e-cash, even on-line cleared, protect payee identity? 
Using the above protocol, payee anonymity will not be compromised by collusion between the bank and the payer, but the payee and the bank can collude to identify the payer!  (This reverses the situation in normal Chaumian ecash, and of course in certain circumstances may be preferable.)
This collusion can succeed even if Alice (the payer) reblinds the coin she gets from Bob before asking the bank to sign it, because Alice must withdraw the coin after Bob gives it to her and before returning it to Bob.  Bob can ask the bank to record the names of everyone who withdrew money during that period, and after two or three repeated transactions can narrow the list of possible payers down to one person.  (This is reminescent of the time-correlation attack on remailers.)  In the original protocol this isn't possible because Alice can withdraw the money ahead of time.
Wei Dai

@_date: 1995-11-02 14:30:40
@_author: Wei Dai 
@_subject: Re: Rivest on the Design of RC4 
What will the legal status of RC4 be after this talk?  Will RSADSI stop claiming that RC4 is still protected as a trade secret, or will everyone attending the talk be required to sign NDAs?
Wei Dai

@_date: 1995-11-04 19:10:26
@_author: Wei Dai 
@_subject: Crypto++ 1.1 
I am still talking to RSADSI's lawyers, but it's taking a lot longer than I expected.  So in the mean time I've decided to rerelease the Crypto++ library with RC4, RC5, RSA removed, and some calls to RSAREF disabled.  RSADSI said it will not object to this rerelease.  Version 1.1 also has some minor bug fixes.  You can find it at
where ????? is in ftp://ftp.csn.net/mpj/README
For the next version I hope to work out a deal with RSADSI to put some of those files back in.  I'm also planning to add SAFER and perhaps some elliptic curve stuff.  Other suggestions are welcome.
I encourage people to use this library in commercial as well as shareware/freeware products.  You don't have to pay me a cent, but don't forget about the patents.
Wei Dai
P.S. Does anyone know if elliptic curve key agreement protocols are patented?

@_date: 1995-11-05 09:10:47
@_author: Wei Dai 
@_subject: Re: /dev/random - using up entropy? 
I believe PGP uses this approach.  An implementation of it can also be
found in Crypto++ as randpool.cpp.

@_date: 1995-11-13 15:48:34
@_author: Wei Dai 
@_subject: Re: Diffie-Hellman in GF(2^n)? 
Thanks for the reference.  The paper gives a running time of exp(c(n log n)^(1/2)) for discrete log in GF(p) and exp(c*n^(1/3)*(log n)^(2/3)) for discrete log in GF(2^n).  However, this paper was published in 1985. There is now an algorithm to calculate discrete logs in GF(p) in
exp(c*n^(1/3)*(log n)^(2/3)) (see prime.discrete.logs.ps.Z in the same
directory), so perhaps GF(2^n) isn't so bad after all. Wei Dai

@_date: 1995-11-14 05:26:24
@_author: Wei Dai 
@_subject: Re: Diffie-Hellman in GF(2^n)? 
I wrote earlier:
To clarify my earlier post, although both of the latter two algorithms
have a runtime of the form exp(c*n^(1/3)*(log n)^(2/3)), for GF(p)
c=1.922+o(1), for GF(2^n) c=1.405+o(1).  This seems to imply that if GF(2^n) is to be used, n needs to be 2.56*log p to achieve a comparable level of security to using GF(p).  (2.56=1.922^3/1.405^3)
Wei Dai

@_date: 1995-11-17 11:47:12
@_author: Wei Dai 
@_subject: Re: primality code 
You may want to try my Crypto++, which includes, among other things, a bignum package and an implementation of the Rabin-Miller compositeness test.
See  for more information.
Wei Dai

@_date: 1995-11-22 06:00:34
@_author: Wei Dai 
@_subject: towards a theory of reputation 
Many of the topics discussed on this list are economic in nature.  Unfortunately cypherpunks haven't attracted the attention of professional economists who might be willing to apply their analytic tools to these issues.  Reputation is one of these issues that is especially important.  I'm not an economist, so I hope these ramblings do not discourage real economists from tackling reputation as a serious research project.
The first step toward a theory of reputation is defining what reputation is.  The definition should correspond closely enough to our common sense
notion of reputation so that our intuitions about it are not completely useless.  I think a good definition is this: Alice's reputation of Bob is her expectation of the results of future interactions with Bob.  If these interactions are mainly economic in nature, then we can represent Alice's reputation of Bob by a graph with the horizontal axis labeled price and the vertical axis labeled expected utility.  A point (x,y) on the graph means that Alice expects to get y utils in a business transaction where she pays Bob x dollars.  Given this definition, it is natural to say the Bob's reputation is the set of all other people's reputations of Bob.
A reputation system consists of a set of entities, each of whom has a reputation and a method by which he changes his reputation of others.  I believe the most important question for a theory of reputation to answer is what is a good method (reputation algorithm) by which a person changes his reputation of others.  A good reputation algorithm must serve his self-interest; it must not be (too) costly to evaluate; its results must be stable; a reputation system where most people use the algorithm must be stable (i.e., the reputation system must be an evolutionarily stable In a reputation based market, each entity's reputation has three values.  First is the present value of expected future profits, given the reputation (let's call it the operating value).  Note that the entity's reputation allows him to make positive economic profits, because it makes him a price-maker to some extent.  Second is the profit he could make if he threw away his reputation by cheating all of his customers (throw-away value).  Third is the expected cost of recreating an equivalent reputation if he threw away his current one (replacement cost).
Now it is clear that if a reputation's throw-away value ever exceeds its operating value or replacement cost, its owner will, in self-interest, throw away his reputation by cheating his customers.  In a stable reputation system, this should happen very infrequently.  This property may be difficult to achieve, however, because only the reputation's owner knows what its values are, and they may fluctuate widely.  For example the operating value may suddenly decrease when his competitor announces
a major price cut, or the replacement cost may suddenly decrease when he succeeds subverting a respected reputation agency.
One way to answer some of these questions may be to create a model of a reputation system with a simple reputation algorithm and a simplified market, and determine by analysis or simulation whether it has the desirable properties.  I hope someone who has an economist friend can persuade him to do this.
Wei Dai

@_date: 1995-11-22 20:41:12
@_author: Wei Dai 
@_subject: Re: towards a theory of reputation 
Our intuitive notion of reputation combines the issues of reliability and
quality.  In your example, whether you choose the reliable vendor or the
unreliable one depends on whether you are risk-seeking or risk-averse. You must prefer one or the other or be indifferent.  In general how you
make these choices depend on your values and your expectations of what the
vendors will do, which include both expectations of reliability and expectations of quality.
Can you elaborate more on why the analysis is inadequate?  (I know it probably isn't adequate, but why do you think so?)
Right, I'm speaking from the point of view of the analyst when I say
"good", but it also applies to individual participants.  Each person does
what he thinks is in his best interest, but if this turns out to be
unstable for the reputation system as a whole, then it won't last very
long so there is little point in getting involved in the first place.  In
other word, I would not choose to participate in an unstable reputation
system. You are right that there is continuum of strategies, but I assume there is
a discontinuity between completely throwing away your reputation and any
other strategy.  So operating value is the maximum amount of profit you
can make by optimizing among all other strategies except disappearing. When I wrote the original post I was thinking of the classic anonymous marketplace.  But I think it can apply to other types of markets.  Cheating costs can be easily factored into the throw-away value, and an important question for any theory of reputation to answer is how to structure transactions to minimize this value.  Many more assumptions need to be made in modeling a particular reputation system, but I was trying to list some general properties that might apply to all reputation The tit-for-tat program that won both contests uses an extremely simple reputation algorithm -- it expects the next action of the other player to be the same as the last action.  This is an example of what I called a "good" reputation algorithm.  It serves the self-interest of the entities
that use it; it is cheap to use; when widely used the system is stable.
Wei Dai

@_date: 1995-11-22 16:41:31
@_author: Wei Dai 
@_subject: Re: towards a theory of reputation 
I don't understand what you mean by this.  Can you give an example to how to discuss reputation (i.e., the concept of reputation, not a particular reputation) using morally non-neutral language?
When we say the value of some object, we implicitely assume that the quality of the information we used to evaluate the object is good enough that we don't have to deal with uncertainty.  When we speak of reputation however, we explicitely assume that we have less than perfect information and that uncertainties must be dealt with.  We normally speak of value of objects and reputation of entities, because information about objects are usually easier to obtain than information about entities.
Quantification is an abstraction that sometimes allows one to think about a concept more clearly.  You decide whether this is the case for I don't completely understand your second sentence.  Only people who know that Bob exists has a reputation of him, so if only insiders know he exists, his reputation consists of the insiders' reputations of him.
Wei Dai

@_date: 1995-11-27 13:59:37
@_author: Wei Dai 
@_subject: Re: Elliptic curves, current status? 
The IEEE p1363 group's working draft on elliptic curve standard may help you here.  You can find it at ftp://ftp.rsa.com/pub/p1363/draft/ec.ps
One reason for confusion about the speed of elliptic curve cryptosystems is the small number of implementations.  A paper in Crypto 95 claimed that for doing key exchange, an elliptic curve algorithm takes about the same time and has about the same level of security as DH with 512 bit modulus, and that elliptic curve has a speed advantage if greater security is Wei Dai

@_date: 1995-11-28 20:02:03
@_author: Wei Dai 
@_subject: Re: towards a theory of reputation 
It's true that we deal routinely with reputations now.
However there is very little formal analysis of reputation as a concept.  Although our common sense knowledge of reputations seem to serve us fairly well(*), there is no guarantee that it will scale well to an anonymous market where both the number of participants and the importance of reputation are much higher.
* However, the government apparently doesn't think so.  Witness the FDA and the SEC.
We need to have formal algorithms to deal with reputations, and we need to be able to show that they have desirable properties.  This will reduce transaction costs and help bring anonymous markets into the mainstream.  Perhaps more importantly, good reputation algorithms will make agorics computing possible.  There is a very interesting proposal for a network routing system based on microcurrency and positive reputations (see   However it does not say what algorithms will be used to handle reputations.  If the system is actually implemented, its proper functioning will depend as much on the properties of the reputation algorithms used as on the correctness of its Wei Dai

@_date: 1995-11-30 05:17:59
@_author: Wei Dai 
@_subject: Re: Elliptic curves, patent status? 
RSADSI no longer owns the Stanford patents (Hellman-Merkel, Diffie-Hellman) which they used to claim covered all public key cryptography.  Those patents now belong to Cylink, who seems to be less Wei Dai

@_date: 1995-11-10 19:01:29
@_author: Wei Dai 
@_subject: Diffie-Hellman in GF(2^n)? 
Most Diffie-Hellman implementations currently use the multiplicative group
of prime fields.  However, the multiplicative group of finite fields of
characteristic 2 (GF(2^n)) can also be used and should be easier to
implement.  Is there any reason why they should not be used?  Does anyone
know the asymptotic running time of the best algorithm for calculating
discrete logarithms in GF(2^n)? Wei Dai

@_date: 1995-11-23 03:08:12
@_author: Wei Dai 
@_subject: generating provable primes 
Several days ago someone (I forgot who he was) asked about code for primality tests.  I just implemented an algorithm to generate random provable primes that is only about 50% slower than generating probable primes.  It will be in the next version of Crypto++, but I've attached code for the main function in case anyone is interested in the algorithm.  Full description can be found in "Fast Generation of Prime Numbers and Secure Public-Key Cryptographic Parameters" by U.M. Maurer in Journal of Cryptology, Volume 8 Number 3, 1995.  The paper also describes a more complicated algorithm that produces primes with a more uniform There was discussion some days ago about generating strong primes for DH exchange moduli.  Eric Young reported that he spent tens of hours of CPU time to generate a 4096 bit prime p such that (p-1)/2 is also prime.  However, there is really no reason why DH exchange moduli must be of the form 2q+1 where q is a prime.  It should be sufficient that they are of the form rq+1, where q is a large enough prime (say more than 256 bits).  The following algorithm generates a provable prime p=2rq+1, where q is a prime with at least half the length of p.
bignum ProvablePrime(RandomNumberGenerator &rng, unsigned int bits)
bignum::Power2(bits)-1, ODD);
double(rng.GetLong())/0xffffffff - 1);
int)min((unsigned long)primeTable[primeTableSize-1], (unsigned (b.ExponentiateMod(q, p) == 1);

@_date: 1995-12-19 16:56:28
@_author: Wei Dai 
@_subject: wish list for Crypto++? 
I am looking for suggestions for features to include in the next version of Crypto++ (current version is 1.1, you can find it at Major additions already planned/implemented include speed improvements,
Safer (all the variations), and elliptic curve cryptosystems (over prime
fields as well as fields of characteristic 2).  There is also a good
chance that RSA will be added back, but I'm still waiting for the final
word from the RSADSI lawyer. What else do people want to see?
Wei Dai

@_date: 1995-12-28 23:18:44
@_author: Wei Dai 
@_subject: Re: Reputation capital: FIBS case study 
It seems to me the easiest way to solve this problem is to list for each player the number of games he dropped and didn't finish along with his rating and experience.  Why go for elaborate social solutions when a simple technical solution exists?
Wei Dai

@_date: 1995-12-21 15:11:04
@_author: Wei Dai 
@_subject: Re: What ever happened to... Cray Comp/NSA co-development 
The problem is there are still people and organizations that use 512-bit RSA keys.  The DOE recentedly awarded Intel a contract to build a computer with 9072 Pentium Pro processors.  I doubt that it will be used for factoring keys, but if it were, it will be able to factor a 512-bit number in a matter of months.
The boundary delimiting "truly large" problems and merely extremely expensive ones inches up all the time.  Less than a decade ago people thought factoring RSA-129 was a "truly large" problem.
Wei Dai

@_date: 1995-12-05 17:00:39
@_author: Wei Dai 
@_subject: Re: Geodesic Payment Systems? (was Re: Meeting notes from ANSI X.9 Meeting on Electronic Payment) 
I agree that conversion points are good targets for attack.  Therefore
whether conversion services are centralized or distributed will partly
depend on the economy of scale in protection against criminals.  I'm not
sure how much of this economy of scale exists for conversion between
electronic and physical monetary instruments.  But if we're converting
between one eletronic system and another, then cryptographic protocols
reduce the cost of protection to nearly zero for even small organizations. Wei Dai

@_date: 1995-12-06 11:44:11
@_author: Wei Dai 
@_subject: Re: Geodesic Payment Systems? (was Re: Meeting notes from ANSI X.9 Meeting on Electronic Payment) 
I find this argument totally unconvincing.  No risk is unbounded.  The worst thing that can possibly happen is that a nearby star goes supernova and completely destroys the earth.  Yet markets handle this low-probability risk quite well.
The direct cost of a break-the-bank catastrophic failure is bounded by the amount of capital the bank has.  This is because the market will not accept more liabilities (real or forged) from the bank than its capital.  There may be other indirect costs resulting from dislocations, but these should also be proportional to the size of the bank.  Therefore your argument is really against centralization and for diversification and Wei Dai

@_date: 1996-01-10 09:51:07
@_author: Wei Dai 
@_subject: Re: NSA says strong crypto to china?? 
I doubt this will ever happen.  If strong cryptography is ever deployed
worldwide ubiquitously, which is a big if, passive ether sniffing becomes
much harder, but the SIGINT people will likely switch to active attacks. Defense against active attacks is much more difficult than against passive
attacks, and requires a host of technologies besides strong crypto (the
one we're lacking most, I think, is a good software engineering
methodology).  I bet the NSA is doing active research on sniffer viruses
and other automated tools for large scale active attacks. Wei Dai

@_date: 1996-01-21 17:41:27
@_author: Wei Dai 
@_subject: Re: HAVAL (was Re: crypto benchmarks) 
I ended up doing it like this:
for (i=0; i<4; i++)
This allows all the transform functions to fit into L1 cache, but at a cost.  Besides the overhead of the for loop, each macro call now does two extra table lookups (in wi2 and mc2). The net result is a ~100% speedup over the reference implementation.
Also, FYI, the boolean functions used in the reference implementation can be optimized.  Thanks to Deranged Mutant for these:
 f_2(x6, x5, x4, x3, x2, x1, x0)                         \
           ((x2) & ((x1) & ~(x3) ^ (x4) & (x5) ^ (x6) ^ (x0)) ^ \
            (x4) & ((x1) ^ (x5)) ^ (x3) & (x5) ^ (x0))  f_2(x6, x5, x4, x3, x2, x1, x0)                         \
 f_4(x6, x5, x4, x3, x2, x1, x0)                                 \
           ((x4) & ((x5) & ~(x2) ^ (x3) & ~(x6) ^ (x1) ^ (x6) ^ (x0)) ^ \
            (x3) & ((x1) & (x2) ^ (x5) ^ (x6)) ^                        \
            (x2) & (x6) ^ (x0))
 f_4(x6, x5, x4, x3, x2, x1, x0)                                 \
 f_5(x6, x5, x4, x3, x2, x1, x0)             \
           ((x0) & ((x1) & (x2) & (x3) ^ ~(x5)) ^   \
            (x1) & (x4) ^ (x2) & (x5) ^ (x3) & (x6))
 f_5(x6, x5, x4, x3, x2, x1, x0)             \
Wei Dai

@_date: 1996-02-01 22:02:32
@_author: Wei Dai 
@_subject: Re: Revisitting Blum-Macali "digital signatures" 
Let me see if I understand you correctly.  The scheme you describe says to calculate X=(D^2)^(1/4) as the signature and check D^2==X^4 for verification.  You are wondering why you can't just calculate Y=D^(1/2) as the signature and check D==Y^2 for verification.
The problem here is that some D's don't have square roots.  For a Blum integer n, only 1/4 of the numbers between 1 and n-1 have square roots mod n (they are called quadratic residues mod n).  For a D that is a quadratic residue, the X and Y above are equal.  But for a D that is not a quadratic residue, Y can't be calculated.  X can still be calculated in this case, but X^2 != D.
Wei Dai

@_date: 1996-02-06 12:26:49
@_author: Wei Dai 
@_subject: Disperse/Collect version 1.0 
To follow up on a post last year where I suggested that Rabin's information dispersal scheme might be useful for sending large files across unreliable remailer networks, I built a shareware package called Disperse/Collect out of my own Crypto++ library.  Disperse splits up files into redundant pieces and encodes them in base 64.  Collect decodes them and reconstructs the original files.  You can download this software from my home page@
Wei Dai

@_date: 1996-02-14 13:58:39
@_author: Wei Dai 
@_subject: Crypto++ 2.0 beta 
I'm about to release version 2.0 of Crypto++, and I am looking for people to do some beta testing on it.  I'm especially interested in testing for compatibility with different compilers/OSs.  If you are interested, please e-mail me stating that you are a US or Canadian citizen or permanent resident living in US or Canada and that you will not export the software.
Wei Dai
Here's the readme for Crypto++ if you don't know what it is.
Crypto++: a C++ Class Library of Cryptographic Primitives
Version 2.0 beta   2/13/1996
This library includes:
MD5, SHS, HAVAL, DES, IDEA, WAKE, 3-WAY, TEA, SAFER, Blowfish, Diamond2, Diamond2 Lite, Sapphire, Luby-Rackoff, MDC, various modes (CFB, CBC, OFB, counter), DH,  DSA, ElGamal, LUC, Rabin,
BlumGoldwasser, elliptic curve cryptosystems, BBS, gzip compression, Shamir's secret sharing scheme, Rabin's information dispersal scheme, and zero-knowledge prover and verifier for
graph isomorphism.  There are also various miscellanous modules such as base 64 coding and 32-bit CRC.
RSA and RC5 are noticeably absent.  I am still talking to RSA
DSI about adding them back into Crypto++.  I hope version 2.1
will include them.
Crypto++ has been compiled and tested with Borland C++ 4.5, MSVC 4.0, and G++ 2.7.2 on MS-DOS, Windows NT, and a variety of Unix machines.
You are welcome to use it for any purpose without paying me, but see
license.txt for the fine print.
Some short instructions to compile this library:
(you probably need to modify this to suit your environment)

@_date: 1996-02-21 14:04:50
@_author: Wei Dai 
@_subject: ANNOUNCE: Crypto++ 2.0 
Crypto++ 2.0 has just been released.  Please see the attached readme file for a description of Crypto++ and what's new in version 2.0.  More details and download instructions can be found on my homepage at Wei Dai
Crypto++: a C++ Class Library of Cryptographic Primitives
Version 2.0   2/19/1996
This library includes:
MD5, MD5-MAC, SHA, HAVAL, DES, IDEA, WAKE, 3-WAY, TEA, SAFER,
Blowfish, Diamond2, Diamond2 Lite, Sapphire, Luby-Rackoff, MDC, various modes (CFB, CBC, OFB, counter), DH,  DSA, ElGamal, LUC, Rabin, BlumGoldwasser, elliptic curve cryptosystems, BBS, gzip compression, Shamir's secret sharing scheme, Rabin's information dispersal scheme, and zero-knowledge prover and verifier for
graph isomorphism.  There are also various miscellanous modules such as base 64 coding and 32-bit CRC.
RSA and RC5 are noticeably absent.  I am still talking to RSA
DSI about adding them back into Crypto++.  I hope version 2.1
will include them.
Crypto++ has been compiled and tested with Borland C++ 4.5, MSVC 4.0, and G++ 2.7.2 on MS-DOS, Windows NT, and a variety of Unix machines.
You are welcome to use it for any purpose without paying me, but see
license.txt for the fine print.
Some short instructions to compile this library:
(you probably need to modify this to suit your environment)

@_date: 1996-02-22 00:39:41
@_author: Wei Dai 
@_subject: Re: "and two forms of ID" 
You got my position completely backward on this.  I've always supported Carl's arguments in the past on this issue (for example see the tread "subjective names...").  You may be thinking of what I said about the cost of defeating traffic analysis.
The natural state of the Net seems to be a kind of semi-anonymity.  Trying to push it in either direction (complete traceability or anonymity) is costly.
Wei Dai

@_date: 1996-03-05 17:43:28
@_author: Wei Dai 
@_subject: Re: SEAL cipher info requested (something actually list related!) 
I believe it was presented at the first Cambridge security workshop on fast software encryption.
Author:       Cambridge Security Workshop (1993).
Title:        Fast software encryption : Cambridge Security Workshop,
              Cambridge, U.K., December 9-11, 1993 : proceedings / Ross
              Anderson, (ed.).
Pub. Info.:   Berlin ; New York : Springer-Verlag, c1994.
Phy Descript: ix, 221 p. : ill. ; 24 cm.
Notes:        Includes bibliographical referenced and title.
LC Subject:   Computers -- Access-control -- Passwords -- Congresses.
Other Author: Anderson, Ross, 1956-.
Series Info.: Lecture notes in computer science ; 809.

@_date: 1996-03-24 05:54:38
@_author: Wei Dai 
@_subject: Java questions 
There has been a lot of discussion on coderpunks about implementing cryptography in Java.  This got me thinking.  We don't see every C++ compiler using the same back end.  So why is everyone licensing Sun's Java implementation?  As a consequence of
this if there is a bug in Sun's implementation, then that bug exists in every Java implementation.  Imagine a future scenario where a virus/worm takes advantage of a single Java bug and infects 90% of all computers attached to the Internet overnight.
There may not be much we can do about this, but we should at least be more aware of the possibility.
On a more positive note, has anyone thought of writting a remailer server or client in Java?  It would be really nice if we could run or use a remailer by clicking a link on the web.
Wei Dai

@_date: 1996-03-31 13:29:33
@_author: Wei Dai 
@_subject: Re: PGP Crack??? 
Apparently the Cray they are using to crunch the matrix is busy with
higher priority users and they have not been able to squeeze in enough CPU
time.  I was told at the beginning of March that they didn't expect to
finish before late April, but now it looks like the job will take another
two to three months.  Anyone got a spare supercomputer laying around?
Wei Dai

@_date: 1996-04-07 12:40:51
@_author: Wei Dai 
@_subject: Re: e$ seigniorage (and is this the cost of untracability?) 
I think this will depend on how easy it is to withdraw ecash.  If the
client software includes an option of automaticly withdrawing ecash from
the bank when you don't have enough ecash to pay for the current purchase
(thereby reducing the time between withdrawal and deposit to zero), then I
suspect most people will use it, even though (anticipating your next
question) this compromises their untraceability.
The untraceability of ecash does depend on a time delay between withdrawal
and deposit.  It's analogous to the fact that the untraceability of
anonymous e-mail depend on a time delay between sending and receiving.  I
think you're probably right that the interest lost is a price the consumer
must pay for untraceability.
One possible way to get around this is to have ecash issuers pay interest
on ecash.  However it requires ecash to be timestamped and therefore
compromises its untraceability.  (Think of the timestamp as a serial
Wei Dai

@_date: 1996-04-08 00:45:11
@_author: Wei Dai 
@_subject: Re: the cost of untracability? 
I think you're right.  There is no need for the issuer to pay explicit
interest.  The easiest way to eliminate signorage would be to steadily
increase the value of each denomination of ecash.  It would be kind of
like a mutual fund that doesn't pay dividends.  In fact, if the ecash is
backed by a portfolio of investment securities and its value floats with
the value of the portfolio, then it would be almost exactly like a mutual
Of course, as Jonathan Wienke pointed out, the IRS would not be very happy
about this.  Then again, the IRS would not be happy with a lot of the
technology discussed on this list.
Wei Dai

@_date: 1996-04-15 09:14:21
@_author: Wei Dai 
@_subject: Re: carrick, Blowfish & the NSA 
This sounds like an interesting project.  However, I'm having trouble
understanding your goals.  Blowfish is a block cipher.  Why are you using
it to do anything but encryption?  I know there are cryptographic
constructions that allow you to do message digests with block ciphers, but
they are slow and not guaranteed to be as secure as the underlying block
ciphers.  I suggest that instead you use an established message digest algorithm such as SHA.  How are you planning to do timestamps and
signatures?  I presume you'll need some other algorithms besides
Blowfish.  Also, will the software be freeware, shareware, or commercial?
Wei Dai

@_date: 1996-04-15 10:02:13
@_author: Wei Dai 
@_subject: Re: carrick, Blowfish & the NSA 
It doesn't make much sense to condemn an iterated cipher based on attacks
on reduced-round versions.  Any such cipher becomes weak if you use
sufficiently few rounds.  Conversely, many broken ciphers become secure if
you use sufficiently many rounds (in which case they also become too slow
to be useful).  I don't think there are currently any public attacks that
seriously affect the security of Blowfish.
On the other hand, if you ask cryptographers what they would use if they
were not concerned with efficiency, I think most of them would say triple
Wei Dai

@_date: 1996-04-16 09:52:32
@_author: Wei Dai 
@_subject: Re: why compression doesn't perfectly even out entropy 
I think what you mean is that there is no simple way to measure
randomness.  Simple, nice definitions of randomness do exist.  Actually
there are two closely related definitions of randomness.  The first is
entropy, which is a measure of the unpredictability of a random variable.
(A random variable is a set of values with a probability assigned to each
value.  In this case the values are bit strings.)  The second is
algorithmic complexity, which is a measure of the uncompressibility of a
bit string.  Notice that it doesn't make sense to talk about the entropy
of a string or the algorithmic complexity of a random variable.
Unfortunately both of these values are very difficult to measure.
Algorithmic complexity is provably uncomputable, because given a string
you can't tell when you have found the best compression for it.  Entropy
can in principle be determined, but in practice it's hard because you must
have a good probability model of the mechanism that generates the random
What we want to do is calculate the entropy of the output of a physical
random number generator.  Now if we have a probability model of the rng,
then we're home free.  For example, if the rng is tossing a fair coin 64
times, then it's easy to calculate that the entropy is 64 bits.  But what if the rng is too complex to be easily modeled (for example if
it's a human being pounding on the keyboard)?  Algorithmic information
theory says the entropy of a random variable is equal to its expected
algorithmic complexity.  So if we could calculate algorithmic complexity,
then we can estimate the entropy by sampling the output of the rng many
times, calculate the algorithmic complexity of each sample, and take their
average as the estimated entropy.
Unfortunately, we already know that algorithmic complexity is NOT
computable.  The best we can do, and what is already apparently done in
practice, is to find an upper bound (call it x) on the algorithmic
complexity of a string by trying various compression schemes, divide that
number by a constant (say 10), and use x/10 as a conservative estimate of
the algorithmic complexity.
(Tim, I know you already understand all this, but your earlier
explanation wasn't very clear.  I hope this helps those who are still
A year ago, you recommended me a book by the same authors titled _An
Introduction to Kolmogorov Complexity and Its Applications_.  Have the
authors written a new book, or are these the same?
Wei Dai

@_date: 1996-04-27 16:01:44
@_author: Wei Dai 
@_subject: factoring estimates 
The best estimates from before the break of RSA130 is (see The Future of
Integer Factorization by Andrew M. Odlyzko):
bits	MY required	log base 2 of total instructions
428	1000		55
512	3*10^4		60
1024	3*10^11		83
2048	3*10^20		113
The factoring of RSA130 proved that a 432 bit number takes only
500 MIPS-years.  Therefore the above estimates should be divided by 2:
432	500		54
512	1.5*10^4	59
1024	1.5*10^11	82
2048	1.5*10^20	112
Wei Dai

@_date: 1996-05-01 13:42:56
@_author: Wei Dai 
@_subject: no-cost DH? 
Does anyone know more about these no-cost licenses?  I wouldn't mind
getting free DH a year early...
Wei Dai

@_date: 1996-04-24 14:23:16
@_author: Wei Dai 
@_subject: Re: Golden Key Campaign 
You can do signatures with Rabin too.  I have a version of it in
Crypto++ 2.0.  It's been out for a while and RSA hasn't bothered me about
Does anyone want to explain why, given the alternatives, people continue
to use RSA and pay for it?
Wei Dai

@_date: 1996-05-01 18:40:40
@_author: Wei Dai 
@_subject: Re: no-cost DH? 
I found some more information about this on Cylink's web site.  Check out
  I'm surprised not to
have seen more publicity about this, since it seems to be a fairly big
move on Cylink's part.
Apparently Cylink is only licensing their SDK at no cost, not the actual
patents.  Does anyone want to speculate on why they are doing this now?
Wei Dai

@_date: 1996-05-04 14:33:01
@_author: Wei Dai 
@_subject: Re: The Joy of Java 
I agree completely with Victor's analysis.  I usually try to avoid me-too
posts, but I've been meaning to write an explanation of why I haven't
started using Java and am not planning to port my Crypto++ library to
Java, so this saves me the effort.
Wei Dai

@_date: 1996-05-12 17:23:58
@_author: Wei Dai 
@_subject: Crypto++ 2.1 
Crypto++ 2.1 has just been released.  You can find download instructions
on the Crypto++ home page at Crypto++ is a free C++ class library of cryptographic primitives.  Changes
made in version 2.1 include:
    - added Tiger, HMAC, GOST, RIPE-MD160, LUCELG, LUCDIF, XOR-MAC,
      OAEP, PSSR, SHARK
    - added precomputation to DH, ElGamal, DSA, and elliptic curve
      algorithms
    - optimizations in elliptic curves over GF(p)
    - changed Rabin to use OAEP and PSSR
    - changed many classes to allow copy constructors to work correctly
    - improved exception generation and handling
This is likely to be the last major revision of Crypto++.  Future
versions will probably only be released for bug fixes and compliance to
new standards.
Wei Dai
P.S.  A new set of benchmarks done using Crypto++ 2.1 is available at

@_date: 1996-05-18 09:13:05
@_author: Wei Dai 
@_subject: marginal cost of ecash transaction 
That brings up an interesting question.  What is the marginal cost to
MarkTwain of such a one-cent ecash transaction?  If everyone started
sending each other these pennies, will MarkTwain go broke? Wei Dai

@_date: 1996-05-19 02:18:53
@_author: Wei Dai 
@_subject: anonymous companies 
I'll just give one problem: the principal-agent problem.  How do owners of
the company make sure the managers operate the company in their best
Solution: reputation.  If the managers don't do the right things, the
owners arrange so that the managers lose reputation and won't get hired in
the future.  Unfortunately the science of reputation is not so advanced
that we know this will actually work.
Solution: smart contracts.  This is Nick Szabo's idea of building
contractual obligations into cryptographic protocols so that the parties
have no choice but to fullfil them.  But again we don't know whether this
will actually work for this problem.
A company implies a particular kind of persistent structure, with a
hiearchy of owners, managers, and employees.  It is far from clear to me
that this is the most likely organizational form in an anonymous digital
economy.  One possible alternative is to have no persistent organizations. Teams form spontaneously to work on individual projects.  Each individual
member jointly negotiates a contract with every other member, and these
contracts are enforced through some arbitration system. I'm not saying this is somehow better than the anonymous company model. It has just as many problems for which no easy solutions exist.  I'm just
pointing out that the properties of anonymous relationships differ quite
radically from our current ones, and that these differences may be large
enough so that the social and economic structures in such an anonymous
digital world may not merely be analogs of currently common structures. Wei Dai

@_date: 1996-05-18 21:55:34
@_author: Wei Dai 
@_subject: Re: anonymous companies 
I've seen the phrase "open books" used several times in the past on this
list. Can anyone explain what it means or provide some references? Wei Dai

@_date: 1996-05-21 15:05:59
@_author: Wei Dai 
@_subject: encrypted open books 
There is indeed a short section in the Cyphernomicon about encrypted open
books.  Unfortunately it doesn't describe it in detail, and since the
hks.net archive is down, I can't look up Eric Hughes' original e-mail on
the topic.  If anyone has a copy of it in his personal archive, please
repost it.  I'm sure other people would be interested as well.
Here is the section from Cyphernomicon:
 12.16.1. Encrypted open books, or anonymous auditing
           - Eric Hughes has worked on a scheme using a kind of blinding
              to do "encrypted open books," whereby observers can verify
              that a bank is balancing its books without more detailed
              looks at individual accounts. (I have my doubts about
              spoofs, attacks, etc., but such are always to be considered
              in any new protocol.)
           - "Kent Hastings wondered how an offshore bank could provide
              assurances to depositors.  I wondered the same thing a few
              months ago, and started working on what Perry calls the
              anonymous auditing problem.  I have what I consider to be
              the core of a solution.
              ...The following is long.... [TCM Note: Too long to include
              here. I am including just enough to convince readers that
              some new sorts of banking ideas may come out of
              cryptography.]
              "If we use the contents of the encrypted books at the
              organizational boundary points to create suitable legal
              opbligations, we can mostly ignore what goes on inside of
              the mess of random numbers.  That is, even if double books
              were being kept, the legal obligations created should
              suffice to ensure that everything can be unwound if needed.
              This doesn't prevent networks of corrupt businesses from
              going down all at once, but it does allow networks of
              honest businesses to operate with more assurance of
              honesty." [Eric Hughes,  PROTOCOL: Encrypted Open Books,
              1993-08-16]
Wei Dai

@_date: 1996-05-27 09:06:45
@_author: Wei Dai 
@_subject: Re: holographic remailing & the scientologists 
This software already exists.  Take a look at Disperse/Collect at
  Disperse splits a file into n base64
encoded pieces where any k of them can be used to reconstruct the
original.  Collect will search through arbitrary collection of files (for
example the entire news spool) for these pieces and automatically
reconstruct everything that it finds. Wei Dai

@_date: 1996-05-28 22:56:42
@_author: Wei Dai 
@_subject: Re: holographic remailing & the scientologists (fwd) 
Disperse/Collect is a information dispersal program rather than a secret
sharing program.  They are similiar have different purposes.  Here we
want to improve accessibility and reliability without regard to secrecy.
That is, for information dispersal we don't care if information about the
original file is leaked with with each share, whereas secret sharing has
to guarantee that an attacker can find out nothing about the original
secret unless he has at least k shares.
That aside, Disperse/Collect might be better suited for what Vladimir had
in mind because it was explicitly designed for broadcasting files through
Usenet.  The secret sharing programs you mention would not work well
because each share would be as big as the original secret.  (There are
secret sharing schemes with short shares, but I don't think any of those
programs implement the more efficient schemes.)
Wei Dai

@_date: 1996-06-05 15:09:29
@_author: Wei Dai 
@_subject: C++ 
It's true that C++ is large and has many features, some obscure.  But the
fact is most of those features are actually very useful.  I suspect many
experienced C++ programmers do not like Java even though Java looks a lot
like C++ because they are so used to having those features in C++.  Take a
look at Victor's earlier post on this subject.
Portability is certainly one of the big problems of C++.  But it can be
done and should become easier in the future as the compilers standarize. If anyone has trouble compiling Crypto++, please send me a report so I can
help you figure out workarounds.  Also, send bug reports to the compiler
company if you think there are bugs in the compiler.
Wei Dai

@_date: 1996-07-10 14:09:46
@_author: Wei Dai 
@_subject: Re: Contracts, Responsibilities, and Drug-Dispensing 
Interesting threat model... What can one do in the total absense of
physical security?  We've talked about mental cryptography before, but I
think we agreed that it isn't very practical.  Perhaps security through
obscurity is a better solution here, since many parents are less computer
literate than their children.
Perhaps in the future kids will get non-removable tamperproof
microchip implants behind their parents' backs. :)
Wei Dai

@_date: 1996-07-30 12:37:52
@_author: Wei Dai 
@_subject: game theory 
I agree with Tim that game theory is very interesting and a potentialy
useful tool in cryptography.  However, game theory currently has a major
limitation.  An even moderately complex game is likely to have a
very large set of equilibria (possible solutions where none of the players
will deviate from their strategy if they knew the strategy of all other
players).  It takes a lot of work to calculate the equilibria set, and
even if this is done, game theorists are hard pressed to explain or
predict which equilibrium is the actual outcome.
I have not read any of Schelling's work, but the notion of Schelling
points seems to be closely connected to that of equilibria in game theory.
If this is the case, then I don't see how it can be usefully applied to
the complex interactions of an entire society.  It is easy to say that
current social conventions are an equilibrium in some game, but how much
is this worth?  What we would like to know is what is the entire set of
possible equilibria, why we are in one of them (instead of the others),
and how changes in the game (such as introduction of strong crypto) change
that set.  I find it unlikely that game theory will soon advance to such a
state that it will give us the answers to these questions.
Wei Dai
P.S.  Now that I've reread Tim's original messages, I realize that maybe
Schelling points are not really the equilibria of game theory.  If this is
the case, Tim, can you please clarify its actual meaning?  (Perhaps by
quoting a definition from Schelling's book?)
ObCrypto: Here is a simple cryptographic application of game theory.  A
fair exchange protocol allows two parties to reveal valuable secrets to
each other one bit at a time.  Modeled as a game, it goes like this:
There are N (an even number) rounds.  On odd rounds Alice decides whether
to reveal a bit to Bob or to stop the game.  On even rounds Bob decides
whether to reveal a bit to Alice or to stop the game.  The goal is to get
as many bits as possible and secondarily to reveal as few bits as
Now using backwards inductions, we can show that the only subgame perfect
equilibrium of this game is that Alice stops the game in round 1.  The
analysis goes like this: on the last round (if the game goes that far) Bob
will have gotten all of the bits from Alice, so it makes no sense for him
to reveal his last bit to Alice.  On the next to last round, Alice knows
that even if she reveals her bit, she cannot get Bob's last bit, therefore
she would stop on that round.  Therefore Bob would stop on round N-2, and
on it goes.
Wei Dai

@_date: 1996-08-30 07:37:26
@_author: Wei Dai 
@_subject: Re: Elliptic Curve Y**2 = x**3 + a * x**2 + b 
Here's some C++ code for taking modular square roots:
Integer ModularSquareRoot(const Integer &a, const Integer &p)
The Jacobi symbol tells you whether x has a square root mod p:
int Jacobi(const Integer &aIn, const Integer &bIn)
    assert(bIn[0]==1);
    Integer b = bIn, a = aIn%bIn;
    int result = 1;
    while (!!a)
    {
        if (a%4==3 && b%4==3)
            result = -result;
        swap(a, b);
        a %= b;
    }
    return (b==1) ? result : 0;
I don't think so.  Let me know if you do find one.
Wei Dai

@_date: 1996-09-10 10:51:19
@_author: Wei Dai 
@_subject: Re: strengthening remailer protocols 
How about a combination of the two?  Suppose Alice wants to anonymously
post a message and get replies.  She generates a new RSA key, signs her
post with it, and asks readers to send encrypted replies to a server. Then periodicly she sends a one-time reply block to the server to retrieve
the accumulated replies. This would let Alice receive an unbounded number of replies and also give
some protection against the denial-of-service and rubber-hose attacks
Lance described.
Wei Dai

@_date: 1996-09-10 10:37:18
@_author: Wei Dai 
@_subject: papers on anonymous protocols 
I found a couple of papers on anonymous protocols that I haven't seen
mentioned here before.  I'll list them for people who might be interested:
   Cryptographic Defense Against Traffic Analysis by Rackoff and Simon.
   gives a proof of security for a mix-net like protocol.
   A. Pfitzmann, B. Pfitzmann, M. Waidner: ISDN-MIXes - Untraceable
   Communication with Very Small Bandwidth Overhead; Proc. Kommunikation
   in verteilten Systemen, Feb. 1991, Mannheim, Informatik-Fachberichte
   267, Springer-Verlag, Heidelberg 1991, 451-463.
describes a protocol for anonymous telephone calls.
Wei Dai

@_date: 1997-02-03 17:40:54
@_author: Wei Dai 
@_subject: what's in a name? 
I've stayed out of the debate about list moderation so far, but a recent
post from tmcghan reminds me of something I've been
thinking about.  An interesting way to look at what happened is that John
Gilmore owns the name "cypherpunks and has chosen to exercise
that ownership.  Even though those of us who disagree with the way he has
done so are free to leave and set up our own mailing list, it is costly to
do so, and the problem of central name ownership remains.  List
subscribers have made investments that are specific to the name
"cypherpunks and most of the cost of switching to a new list is
in the new investments they would have to (re)make.  The fact is that a
promise of no censorship is not enough incentive for us to do so. I suspect that the hierarchical nature of name ownership on the Internet
today will be an important technological barrier for the establishment of
truly anarchic virtual communities.  Unless this problem is solved, the
closest we'll come is pseudo-anarchies that exist with the tolerance of
beneficent dictators.
Wei Dai

@_date: 1997-02-03 17:01:39
@_author: Wei Dai 
@_subject: what's in a name? 
I've stayed out of the debate about list moderation so far, but a recent
post from tmcghan reminds me of something I've been
thinking about.  An interesting way to look at what happened is that John
Gilmore owns the name "cypherpunks and has chosen to exercise
that ownership.  Even though those of us who disagree with the way he has
done so are free to leave and set up our own mailing list, it is costly to
do so, and the problem of central name ownership remains.  List
subscribers have made investments that are specific to the name
"cypherpunks and most of the cost of switching to a new list is
in the new investments they would have to (re)make.  The fact is that a
promise of no censorship is not enough incentive for us to do so. I suspect that the hierarchical nature of name ownership on the Internet
today will be an important technological barrier for the establishment of
truly anarchic virtual communities.  Unless this problem is solved, the
closest we'll come is pseudo-anarchies that exist with the tolerance of
beneficent dictators.
Wei Dai

@_date: 1997-03-21 17:13:00
@_author: Wei Dai 
@_subject: "why privacy" revisited 
The question "why privacy" has at least two different meanings.  The first
one, "why do you value privacy for yourself" has a fairly obvious answer.
Privacy implies control over one's personal information, and more control
is clearly preferable to less.  But the question also has a second
meaning, "why do you think everyone should have more privacy?"  The answer
to this question is not so obvious.  Just because each individual wants
more privacy for himself, it doesn't follow that everyone will be better
off when everyone has more privacy.
Cypherpunks accept the idea that the widespread deployment of cryptography
will increase privacy for everyone (or at least everyone who owns a
computer and an Internet link).  They also argue that this is a good
thing.  The reason most often cited is that privacy serves as a barrier
for coercion.  But privacy is also a barrier to almost every other kind of
social relationship.  For example, economists recognize that many market
failures/inefficiencies are caused by information asymmetries (i.e., the
fact that in a potential exchange one party has more information about the
exchange than the other.  The canonical example for this is the used car
market.)  Increased privacy would seem to only exacerbate these problems.
What arguments can be made that the benefits of increased privacy outweigh
its costs, considered for society as a whole?

@_date: 1997-03-21 22:20:04
@_author: Wei Dai 
@_subject: Re: "why privacy" revisited 
I think you're answering the third meaning of "why privacy", "why DOES
privacy exist?"  This is a positive rather than a normative question
(which is what I was asking).  I agree with you that most likely privacy
exist because in some sense it is an equilibrium in the game of life.  But
what I'm asking is whether it is a desirable equilibrium, and whether a
new equilibrium involving more privacy is better than what we have now. Certainly no real market is perfectly efficient, but some markets
are relativly more efficient than others, and most markets are more
efficient than alternative forms of economic organization (e.g.,
socialism) so I don't see how you can call "market efficiency" an
illusion.  The inefficiencies I was talking about were relative to the
case where both parties have the same information.
Also, I don't quite understand your first argument.  It seems to suggest
that privacy should exist for no reason in particular.  If this is the
case then it doesn't make sense to argue about the costs/benefits of
privacy. But it is my understanding that most cypherpunks believe more
privacy benefits everyone, and therefore work to making more privacy for
everyone.  What I'm looking for are arguments that support this belief.

@_date: 1997-03-26 01:03:34
@_author: Wei Dai 
@_subject: game theoretic analysis of junk mail 
The junk mail problem (also known as spam) is well known to just about
everyone who receives e-mail.  There has also been many solutions
proposed.  Noticeably, the idea of having e-mail senders include ecash
payments with their mail has come up several times (I believe as the
result of independent discovery).  In order to evaluate the effectiveness
of this proposal, I will construct a game theoretic model of the
interaction between the sender and the recipient of an e-mail, and compare
the solutions with and without the ecash payment option.
The Model
Players: A - Sender, B - Recipient
      A: Send mail?
        /     \
    no /       \ yes
      /         \
    (0,0)    B: Read mail?
               /   \
           no /     \ yes
             /       \
         (0,0)   B: Accept offer?
                    /  \
                no /    \ yes
                  /      \
               (0,-c)  (s,r-c)
Assumptions: - sending the e-mail is costless to the sender
- c (the cost of reading a piece of e-mail) is known to both the sender
and the recipient.  - s and r (the profit of the proposed deal to sender and receiver,
respectively, both assumed to be non-negative) are distributed according
to the probability density function f(s,r).  The sender knows s and r
before sending the e-mail, but the receiver does not learn s and r until
he reads the e-mail. Solution of the game:
To solve this game, we apply the method of backward induction.  In the
last stage of the game, B decides whether to accept A's offer.  Clearly he
always accepts since r-c >= -c.  Therefore, in the next to last stage, B
knows that the expected payoff if he reads the mail is the expected value
of r-c, E(r)-c, so he will read if E(r)-c > 0.  Finally, we come to A's
decision.  If A knows that B will not read, then he is indifferent between
sending and not sending.  However, if we assume that there is a small
probability that B will read and accept irrationally, then we can conclude
that A always sends the mail.
To summerize, if E(r) > c, B always reads the mail and accepts the offer,
otherwise B never reads.  A always sends regardless of the value of the
parameters.  Now we can see the outcome is not socially optimal.  For
example if E(r) < c, both A and B would be better off if A only sends when
The above model is not very realistic.  The most unrealistic assumption is
that the sender knows the exactly value of his offer to the recipient.
However I believe the model captures the essence of the junk mail problem.
Next time I will analyze the proposed solution of adding the option of a
pre-payment.  For those who want to try it themselves, I give the game
tree here:
      A: Send mail?
        /     \
    no /       \ yes
      /         \
    (0,0)    A: Decide pre-payment p
             B: Read mail?
               /   \
           no /     \ yes
             /       \
         (-p,p)   B: Accept offer?
                    /  \
                no /    \ yes
                  /      \
               (-p,p-c)  (s,r-c)

@_date: 1997-03-27 17:19:36
@_author: Wei Dai 
@_subject: junk mail analysis, part 2 
Last time I gave the equilibrium for the junk mail game.  Now I will look
at a modified game that allows the sender to include an ecash deposit with
his email.  (Note that there is a slight change of notation from the game
tree given last time.)       A: Send mail?
        /     \
    no /       \ yes
      /         \
    (0,0)    A: Decide deposit d
             B: Read mail?
               /   \
           no /     \ yes
             /       \
         (-d,d)   B: Accept offer?
                    /  \
                no /    \ yes
                  /      \
               (-d,d-c)  (s,r-c)
We again apply the method of backward induction.  In the last stage B
accepts if r >= d.  Therefore in the next to last stage, B knows that if
he reads, his expected payoff is P(r=d)*E(r-c|r>=d). However, in equilibrium it is not possible that P(r 0 since A is
always better off by offering a deposit of 0 instead of any deposit
greater than r. Therefore B reads if E(r|r>=d)-c >= d.  Now we come to A's
deposit decision.  A knowns that if he offers any d such that r >= d and
E(r|r>=d)-c >= d, B will read and accept.  A is indifferent between any
such d, so he might as well offer the smallest such d if it exists.  If it
doesn't exist, A offers d=0.  Finally A again always sends regardless of
the parameters, since A can get a payoff of at least 0 by sending, and may
do better if there is a small probability of B making a mistake.
We saw that if there exists a d such that r >= d and E(r|r>=d)-c >= d, A
offers the least such d, and B reads and accepts.  Otherwise A offers d=0,
and B does not read.  Interestingly, if E(r) > c, d=0 satisfies r >= d and
E(r|r>=d)-c >= d, so we reach the same outcome as before.  However, if
E(r) < c, the outcome of the new game represents a Pareto-improvement
since for realistic distributions of (s,r)  it seems likely that for all
sufficiently large r there exist d such that r >= d and E(r|r>=d)-c >= d,
and for these values of r both the sender and the receiver do better than
they did in the previous model.  Let's call the smallest such r t. Unfortunately the outcome is still not Pareto-optimal if t > c. This conclusion opens the question of whether a better solution exists.
One possibility is the following (called the pre-payment solution).
      A: Send mail?
        /     \
    no /       \ yes
      /         \
    (0,0)    A: Decide pre-payment p
             B: Read mail?
               /   \
           no /     \ yes
             /       \
         (-p,p)   B: Accept offer?
                    /  \
                no /    \ yes
                  /      \
               (-p,p-c)  (s-p,r+p-c)
If there is enough interest, I'll follow up with a comparison between the
pre-payment solution and the deposit solution.

@_date: 1997-04-08 02:15:12
@_author: Wei Dai 
@_subject: some arguments for privacy 
A couple of weeks ago I asked for some arguments in favor of privacy.  I
pointed out that one person's increased privacy exerts negative
externalities on others by reducing their available information.  I wanted
to know why more privacy might be beneficial to society despite this
consideration.  I didn't really get the answers I wanted, probably because
I wasn't clear about the kind of arguments I had in mind.  Anyway, here I
give some arguments of my own, which I hope offer new perspectives on this
issue. Privacy as Insurance
Suppose you are looking for a job.  It seems reasonable to argue that if
you are a better than average worker, you would be able to get a better
offer if you had less privacy because the potential employers would be
better able to distinguish your abilities from your past history.  On the
other hand less privacy would hurt you if you are a worse than average
worker.  If you don't yet know your own abilities, you would prefer more
privacy as an insurance against your own potential deficiencies.  If that
doesn't seem realistic, consider how the argument might apply to your
children.  This line of reasoning also explains why people are troubled by
genetic screening.  Thus privacy might increase social welfare by
providing a sort of social insurance.
Privacy as Restriction on Signaling
"Signaling" is a term used by game theorists to describe the use of
publicly observable actions to provide information to others about one's
private attributes.  The best example comes from biology, where male
peacocks grow extravagant tails to signal their genetic fitness to
females.  Clearly signals must be costly, otherwise they wouldn't be
convincing. They are often also wasteful, as in the peacock example.  (As
a side note, the deposit solution to the junk mail problem I talked about
some days ago is an example of non-wasteful signaling.)  Privacy reduces
the range of actions one can use as signals.  This would increase social
welfare if the wastefulness of the signals exceed the benefit they provide
in the form of useful information.  Consider a possible future where every
room in every house is wired with a camera that continously broadcasts to
the Internet.  Life would certainly be very uncomfortable in this future,
as every trivial action must be carefully considered in order to preserve
one's reputation.
Possible Benefit of Non-Privacy Limited
This is more of an argument for privacy technology, rather than privacy
per se.  Suppose that privacy-invading technology becomes much cheaper
than privacy-enhancing technology.  Given the arguments above it seems
inevitible that governments will pass laws to restrict the distribution of
certain kinds of information about individuals.  But of course this will
not keep the information out of the hands of those governments themselves
and other resourceful organizations.  Thus any possible benefit of
decreased privacy in the form of market efficiency would be severely
limited since only a few market players would have improved information.
This benefit would be easily outweighted by the harm in the form of
governments' increased coercive power.

@_date: 1997-04-08 18:52:25
@_author: Wei Dai 
@_subject: Re: some arguments for privacy 
What I meant by privacy is somewhat different from your definitions: "the
ability of an individual to control the distribution of information about
himself".  Notice that I said "ability" instead of "right".
Part of what makes privacy so interesting is that the Coase Theorem
doesn't apply.  If you look at the Coase Theorem carefully, it presuposes
the lack of transaction costs, which in turn means that all relevant
information is distributed symmetrically among interested parties.
(Otherwise the cost of inducing some individuals to disclose private
information to others becomes part of the transaction cost.)
Therefore even to invoke the Coase Theorem implies that either there is no
privacy, or for some reason no one chooses to exercise his privacy.
In fact, this is exactly what I meant by the inefficiency of privacy:
not only does the Coase Theorem not apply to privacy itself, it
undermines the Coase Theorem everywhere else by increasing transaction
The rest of your article is very interesting, so please keep going.  I'll
just take this opportunity to point out that the most useful measure of
efficiency is a relative one.  Even the centrally planned economy is
not totally inefficient.  Apparently some CPEs seem quite able to keep its
citizens from starvation, even for years at a time.  The CPE is only
inefficient compared to the market economy.  If for some reason human
beings are inherently unable to organize markets (perhaps because of some
deep-seated cultural bias against putting prices on essentials like food
and children), then the CPE might very well be the best alternative.

@_date: 1997-04-12 02:08:16
@_author: Wei Dai 
@_subject: anonymous credit 
I used to think that the problem of anonymous credit is hopelessly
intractable.  I mean, who would loan money to an anonymous entity that may
disappear at any time without a trace?  Reputation, which is useful for
other types of anonymous cooperation, is not a good solution in this case,
since typically you need to borrow money to invest in reputation.
Recently, I came upon a solution, inspired by an essay by the economist
Steven Landsburg.  I have to admit however, that the solution is fatally
flawed.  But I present it here anyway in the hope that one of you can
offer an improvement that would make the scheme practical.
The idea goes like this.  The government announces a new series of
anonymous zero-coupon treasury bonds that mature in 10 years, backed by a
special lump-sum tax to be collected when the bonds mature.  The proceeds
of the bond auction and the tax are distributed equally among everyone.
So basicly, the government forces everyone to take out a loan on the
credit market and guarantees its collection.  Anyone who does not want the
loan anonymously buys treasury bonds with all of his distribution, holds
them for 10 years, redeems them at maturity and uses the proceeds to pay
off the lump-sum tax.
The fatal flaw, of course, is that there is no reason why the government
would want to help people get anonymous loans.  Can anyone find a way to
fix this?
BTW, if anyone is interested in Steven Landsburg's essays, they are
available at
  I also
highly recommend his book, _The Armchair Economist: Economics and Everyday
"All crypto is economics." - Eric Hughes

@_date: 1997-06-11 08:57:11
@_author: Wei Dai 
@_subject: Re: Untraceable Contract Killings 
I think the novelty of Bell's scheme is that it allows assassination
payments to be pooled from a large number of anonymous payers without
explicit coordination (i.e., the payers do not have to communicate with
each other to work out a contract, etc.).  For killing a neighbor it
doesn't improve upon the simple untraceable contract, but it can make a
big difference when the target has many enemies (Bell gave politicians as
an example).
Now in light of the fact that when the target has many enemies the
assassination becomes a non-excludable public good, it is almost certain
that the scheme cannot actually work in practice.  All of the potential
payers would rather free-ride and let others pay, so the public good ends
up not being "produced".

@_date: 1997-08-07 03:03:55
@_author: Wei Dai 
@_subject: Re: Eternity Uncensorable? 
I suggest using information dispersal to spread risk amongst remailer
operators.  Use Rabin's information dispersal technique to divide up a
document into n shares such that k of them can reconstruct the original,
and post each share via a seperate remailer.  It would be hard for the
government to single out an operator to go after since an individual share
by itself is useless.
If n>k this also increases reliability and resilience of the eternity
service against technical attacks.

@_date: 1997-08-13 05:41:24
@_author: Wei Dai 
@_subject: Re: Eternity Uncensorable? 
The nice thing about information dispersal is that each share is only 1/k
the size of the original.
The point of using information dispersal is not to defend the Eternity
servers, but rather the exit remailers.  Adam's Eternity servers do not
need to be defended because they only act as a gateway between USENET and
the web.  Clients can run Eternity servers on their local machine and
directly access their local USENET spool.

@_date: 1997-09-19 14:01:38
@_author: Wei Dai 
@_subject: sooner or later 
Many of us believe that a crypto ban is inevitable. The only question for
us is whether it'll happen sooner or later. Seen in this perspective, all
that industry and civil liberties lobbies can do is delay the ban. But is
this necessarily a good thing?
Here are some reasons to believe that an ealier ban might be preferable
to cypherpunks.
1. An earlier ban will do less damage to existing infrastructure.
2. A ban can not and will not stop crypto. It will force people to work
around it, but ultimately it will not achieve its goal. We might as well
start working around it sooner.
3. A ban will eventually be lifted, because of the impracticality of GAK,
abuses, wide-spread security problems caused by added complexity or
hackers stealing the master keys, ineffectiveness, sympathetic courts etc.
The sooner it comes into effect, the sooner it goes away.
4. A ban will focus public attention on crypto, especially if it creates
some of the problems mentioned above. This will accelerate deployment of
crypto after the ban is lifted.
In summary, the government is obligated to try and eventually fail to ban
crypto. We might as well let them get it over with.
I'm not suggesting that the professional lobbists stop their efforts (they
shouldn't, if only for appearances sake), but it might be time for the
rest of us to focus our attention on more important matters.

@_date: 1997-09-20 02:33:07
@_author: Wei Dai 
@_subject: Re: sooner or later 
The ban on alcohol went away, why not the ban on drugs?  It won't even
require a constitutional amendment.  Are you being sarcastic or agreeing
with me?
In any case, the analogy between crypto and drugs is interesting. Perhaps
after the ban many people will obtain their crypto and crypto-related
services from organized crime.

@_date: 1997-09-20 03:55:32
@_author: Wei Dai 
@_subject: Re: sooner or later 
I don't think it makes a difference who is in office. The TLAs seem
incredibly adept at converting/subverting politicians who initially
support crypto. They must have known about this ability (and by ability I
don't mean some kind of mind-control machine, but simple persuasiveness) for a long time, but seem to have started excercising it on a large scale
only recently. The pro-crypto lobby is pathetic by comparison. Has it
converted any anti-crypto politician to our side? This is why I think a
crypto ban is inevitable. We simply don't have the resources to defend
against this type of attack directly. A delay is possible, but not
one long enough to make the ban impossible.
As for the residual effects of the ban after it is lifted, I think you are
overestimating them. All (escrowed) crypto built during the ban should be
designed with the lift in mind. When the ban is lifted, everyone will be
able to upgrade simultaneously by simply plugging in non-escrowed crypto
and protocol modules. This can even be done without user-intervention,
similar to auto-upgrade of virus scanning modules. Compatibility betwen
escrowed and non-escrowed crypto can be kept during the upgrade period
with appropriate negotiation protocols.
The residual social effects of the ban is harder to estimate. It's
possible that it will be minimal, for example if digital bearer
instruments are so much more efficient than account based ones that people
will use them despite escrow requirements, then these can be quickly
converted to use non-escrowed crypto after the ban is lifted. But in any
case, I don't see how a short delay will make any difference.

@_date: 1997-09-22 18:27:55
@_author: Wei Dai 
@_subject: encouraging digital pseudonyms 
One of Tim's suggested cypherpunk projects is to encourage the use of
digital pseudonyms (i.e. cryptographically persistent entities not linked
with True Names). I think the main reason why pseudonyms are not used more
widely is the lack of support on client software, especially on the
receiver side. When I see a piece of email sent to the cypherpunks list
from an anonymous remailer, I typically delete it without reading, because
there is no easy way to tell between anynoymous email (which are typically
junk) and pseudonymous email, and there is no easy way to filter by
Of course the long-term solution is to get native pseudonym support on the
client software, but in the mean time there is a fairly simple workaround
if someone wants to volunteer a modest amount of resources. That person
should set up a mailing list that simply resends cypherpunk traffic that
are signed by pseudonyms. To help filtering, the pseudonym's key hash
should be prepended to the subject.
When this is done, those of us who want to can filter out everything sent
by remailers to the cypherpunks mailing list and subscribe to the proposed
service. If enough of us do this, it should motivate anonymous senders to
set up persistent identities. If the trouble of generating new pseudonyms
is not enough to discourage the anonymous junk, the proposed service can
charge ecash or hashcash either per pseudonym or per email.

@_date: 1997-09-24 04:09:32
@_author: Wei Dai 
@_subject: STUMP (Was: encouraging digital pseudonyms) 
It looks pretty good, but the description only says USENET. Can it also be
used on mailing-lists? If so, can someone who have the resources please
run it on the cypherpunks list (just the pseudonym feature please, not the
moderation)? I suggest also putting the PGP key fingerprint into the From: field,
because the user ID can be forged, making it less useful for filtering

@_date: 1998-01-06 17:05:50
@_author: Wei Dai 
@_subject: cypherpunks and guns 
I don't understand why there is so much talk about guns here lately.
Unless someone comes up with a weapon that has some very unusual economic
properties, individuals cannot hope to compete with governments in the
domain of deadly force. If we have to resort to physical violence, we've
already lost!
Think about it: if we can defend ourselves with guns, why would we need

@_date: 1998-01-20 16:00:12
@_author: Wei Dai 
@_subject: PipeNet description 
I just got a couple of requests for information about PipeNet and I
realized that I never did make my final description of it public. The
attached informal write-up was done shortly after Crypto '96 as a result
of discussions with Hal Finney, David Wagner, and Eric Hughes. I haven't
worked on it since then, mostly because the Onion Routing project is doing
similar work and appears to be much better funded (I did send them a copy
of this write-up per their request).
The Model
Consider a network of processors which send messages to each other
asynchronously.  We assume that each node is identified by its public key,
and that links between nodes are secure.  The adversary may control a
fixed subset of the nodes.  However all messages between any two honest
nodes are confidential and always arrive (unmodified) in the order sent
(this can be achieved with a standard transport level security protocol).
The Protocol
The protocol is based on the idea of virtual link encryption.
After an anonymous connection is established, the originating node sends a
constant stream of (constant size) packets to a second node at a fixed
rate. The second node shuffles the packets it receives during a time unit
and forwards them in random order to others.
A connection is a path in the network.  The first node in the path is the
caller, and the last node is the receiver.  The rest are called switches.
Anonymity in this scheme is asymmetric - the caller is anonymous, but not
the receiver.  Each node in the path shares a key with the caller and
knows the nodes immediately in front of and behind it.  Every pair of
adjacent nodes shares a link id.
Each switch in the path therefore has a key and two associated ids.  Call
the id that it shares with the previous node (the one closer to the
caller) type A, and call the other id type B.  For each id, the switch
expects exactly one packet tagged with that id in each time unit.  When it
receives a packet tagged with a type A id, it decrypts that packet with
the associated key, tags it with the corresponding type B id, and forwards
it to the next node.  When it receives a packet tagged with a type B id,
it encrypts the packet with the associated key, tags it with the
corresponding type A id, and forwards it to the previous node.  The
forwarding is always done at the end of the time unit, and the order in
which packets are sent is random.
For each packet going from the caller to the receiver, the caller must
multi-encrypt it with the keys it shares with each of the nodes in the
path, starting with the receiver.  It then sends the packet to the first
switch tagged with the appropriate link id.  Each switch will strip a
layer of encryption and forward the packet to the next node.  For a packet
going from the receiver to the caller, the receiver encrypts it with the
key it shares with the caller and sends it to the last switch in the path.
Each switch will add a layer of encryption and forward the packet to the
previous node.
To establish a connection, the caller (N0) performs the following steps:
1.  Select a node (N1) at random and establish a key (K1) and link id (S1)
with N1.
2.  Select another node (N2) at random.
3.  Request that N1 establish a link id (S2) with N2.
4.  Establish a key (K2) with N2 through N1.
5.  Request that N1 use K1 to decrypt all messages tagged with S1, tag the
decrypted message with S2 and forward them to N2.  Also request that N1
use K1 to encrypt all messages tagged with S2, tag the encrypted messages
with S1 and forward them to N0.
6.  Repeat steps 2 to 4 l-2 times.  (Name the i-th node, key, and id Ni,
Ki, and Si respectively.)
7.  Repeat steps 2 to 4 a final time, but with the receiver node (Nl)
instead of a random node.
We assumed earlier that communications links between honest nodes are
vulnerable to delay attacks.  Therefore we must ensure that link delays do
not reveal traffic information.  Each node expects one packet from each
link id in each time unit.  Extra packets are queued for processing in
later time units.  However, if it does not receive a packet for a link id
in a particular time unit, it stops normal processing of packets for that
time unit and queues all packets.  This ensures that any delay is
propagated through the entire network and cannot be used to trace a
particular connection.
The process of making and breaking connections must also not leak
information.  This can be done by using a protocol analogous to mix-net.
Link forming/destroying requests are queued and performed in batches in a
way similar to queuing and mixing of e-mail in a mix-net.

@_date: 1998-01-23 15:23:41
@_author: Wei Dai 
@_subject: Re: Why no "Banner Ad Eaters"? 
In addition to all of the ad blocking software mentioned on that page,
If you're running the Microsoft Proxy Server, I wrote an ISAPI filter DLL
plugin that can be used for blocking ads based URL regexp matching.  See
 It seems to me that blocking ads is no different from blocking porn. All
of the technology being developed for the latter purpose (PICS for
example) will eventually be used for the former. Filtering technology in
general will advance as the net becomes more diverse and people seek to
protect themselves from unwelcome information.
I think the long-term outlook for content providers is pretty bleak. How
do you make a profit when your copyrights are not enforceable and your ads
are easily filtered?

@_date: 1998-02-19 06:14:33
@_author: Wei Dai 
@_subject: Re: Is spam really a problem? 
The way I see it, the problem with spam isn't that it takes too much
effort to delete them, but that it discourages useful advertisement
through email. Email could be a very efficient way for companies to send
valuable information to potential customers, but the incentives are such
that virtually all unsolicited commercial email are of very low value
and are deleted without being read. If you like game theory, you might want to search the cypherpunks mailing
list archive for a game theoretic analysis of the spam situation.

@_date: 1998-02-16 23:08:16
@_author: Wei Dai 
@_subject: payment mix 
A payment mix is like an email mix, but instead of mixing and remailing
emails, it mixes and repays payments. This would be useful when the
payment system itself does not offer anonymity. A payment mix basicly
turns any traceable payment system into an anonymous one.
Payment mixes could be chained for additional security, just like email
mixes. But by using blind signatures this could also be avoided. In that
case the payment mix would be acting like a mini ecash mint. To illustrate
how it would work, suppose Alice wants to give $1 to Bob.
1. Alice pays $1 to the payment mix using the traceable payment system.
2. In exchange, the payment mix issues Alice $1 in blinded (Chaumian)
3. Alice gives the ecash to Bob.
4. Bob gives the ecash back to the payment mix.
5. The payment mix pays Bob $1 using the traceable payment system.
Notice that because of blinding, in step 4 the payment mix cannot connect
the ecash it gets from Bob to the ecash it issued to Alice.
This is a pretty simple idea, but I don't remember if we talked about it
here already. If blinding is used, a payment mix would basicly BE an ecash
mint, except the cash it issues would be held only momentarily by its
users. Because its total outstanding liability at any given moment would
be fairly low, a payment mix would only have to be minimally trusted.

@_date: 1998-11-27 08:07:43
@_author: Wei Dai 
@_subject: PipeNet 1.1 and b-money 
I've discovered some attacks against the original PipeNet design. The new
protocol, PipeNet 1.1, should fix the weaknesses. PipeNet 1.1 uses layered
sequence numbers and MACs. This prevents a collusion between a receiver
and a subset of switches from tracing the caller by modifying or swaping
packets and then watching for garbage.
A description of PipeNet 1.1 is available at
Also available there is a description of b-money, a new protocol for
monetary exchange and contract enforcement for pseudonyms. Please direct all follow-up discussion of these protocols to cypherpunks.

@_date: 1998-12-06 07:24:18
@_author: Wei Dai 
@_subject: Re: (eternity) eternity using politics rather than economics 
I'm not familiar with the latest eternity designs, but I wonder if they
could be extended to provide a global time ordering between the published
documents? If so perhaps the eternity service can be used to implement
b-money (see  and the
chicken and egg problem would be solved at once.

@_date: 1998-12-07 08:23:22
@_author: Wei Dai 
@_subject: Re: Wei Dei's "b-money" protocol 
Actually this problem has already been accounted for in the protocol. The
amount of b-money you create when you burn some CPU time depends on the
relative cost of CPU time verses a standard basket of goods. As the cost
of computation falls relative to that basket, the amount of CPU time
needed to create a unit of b-money automaticly rises. So the result is
that there should be no inflation with b-money, unless the b-money economy
shrinks or the velocity of b-money increases (because it's not possible to
reduce the b-money money supply). Problems 3-6 can be solved with my payment-mix idea. This is simply a
Chaumian mint where people buy blinded ecash with b-money and then sell it
back a little later under a different pseudonym. Presto your b-money is no
longer linkable. The nice thing about this mint is that you don't have to
trust it very much since it should have very few outstanding obligations
at any one time. What obligations it does have of course can be backed
with b-money.

@_date: 1998-12-08 08:12:21
@_author: Wei Dai 
@_subject: Re: Wei Dei's "b-money" protocol 
If a problem can be solved on a network of computers for free, then by
definition broadcasting the solution to that problem won't create any
money. B-money mints will need to solve problems that can't be
parallelized well on low-bandwidth networks in order to prove that they're
not using free idle time of network computers. I'm not sure if such a
problem class exists, however. I think this problem will probably become
less serious in the future as people discover more productive uses of idle
computer time.
I now tend to think that the government monopoly of force is a net
benefit. If you look at countries where the government doesn't have a
monopoly of force (like Russia) things look pretty bleak.
Anyway, back on topic. The resource waste in creating b-money can be
reduced if we assume that b-money will be created gradually as the b-money
economy expands rather than all at once at the beginning. If we build a
deflation factor into b-money, b-money will be worth more over time and
therefore not as much b-money will be needed to support the operation of
the economy. This can be accomplished by specifying that the standard
basket used to define the creation of b-money grow at a fixed rate over
time. But of course deflation also has costs since it makes comparing
prices across time more difficult. I think b-money will at most be a niche currency/contract enforcement
mechanism, serving those who don't want to or can't use government
sponsored ones. However if it did become mainstream I think there are some
interesting macroeconomic questions here. Will prices really be stable as
they're designed to be? Will there be business cycles? What is the optimum
inflation/deflation rate?

@_date: 1998-12-12 07:18:34
@_author: Wei Dai 
@_subject: Re: alternative b-money creation 
This argument is based on the misconception that people have no reason to
want to accept fiat money. But actually fiat money is valuable because it
performs a service for those who use it, namely the service of a medium of
exchange. It's value derives from the fact that there is positive demand
for a medium of exchange, and the fact that its supply is finite and
controlled by a sufficiently benevolent agency.
Think about it this way. In the case of commodity money, its value comes
partly from the industrial/aesthetic value of the commodity and partly
from the usefulness of the commodity money as a medium of exchange. In the
case of fiat money and b-money, all of its value comes from its usefulness
as a medium of exchange.

@_date: 1998-12-12 09:37:58
@_author: Wei Dai 
@_subject: Re: alternative b-money creation 
What I meant is that the current supply of money (i.e. the total amount of
money in circulation) is finite, not that it can't increase in the future.
And by sufficiently benevolent, I mean people do not expect the government
to print so much money that it becomes totally worthless, at least not in
the short term.
I'm not trying to defend fiat money. After all I proposed b-money as an
alternative exactly because fiat money does have serious problems. But
having no reason for people to accept it is not one of them.
