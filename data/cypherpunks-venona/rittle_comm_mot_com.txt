
@_date: 1994-07-11 13:13:55
@_author: Loren James Rittle 
@_subject: Re: Clipper vs. PGP 
If computer knowledgeable people all became outlaws just because of
their knowledge, we would be living in a rather awful place and time,
now wouldn't we... :-)
The government would not be overthrown, unless unjust laws were "in
force".  I believe that there are many unjust laws and arbitrary regulations
on the books, but I believe widespread encryption being used by everyone
would result in many of them being taken off the books as unenforcable
"moral judgement"-type laws, as opposed to armed revolution occurring.
Of course, this does imply that the citizens of the US still have their
guns to back up a threat to the government...
Even with encryption being used by everyone, the important laws (anything
that effects two or more people in an adverse manner) would be totally
enforcable.  I.e. things like the OJ case would still be solvable (DNA
and fingerprint analysis would still be able to solve crime, the inside man
and post-crime eyewitness accounts will still have great impact in court).
Given the coming digital information age, people will most likely be able to
keep much better personal records: record everything the say and do
with video and audio recorders.  Any crime that effects them would
be solvable with the help of this information.
Geez, given the number of wiretaps current used to solve crimes (very
small in my opinion: under 10000/year for the whole country), I don't
see what the big deal is.
A reference to history (yes, one can lie with history, but since I bought
guns into the equation, I'd like a chance to show why they are important
in the hand of "the common folks"):
Hitler rose to power in Germany after the *previous* government in Germany
collected all the guns from private individuals.  With no guns in the
"common man's" house, no one could stop the madman's facist rule and his
war making.
I believe the following with all my heart:
Guns in the hands of the people is the only thing that keeps government
(ours or any other one in the world) in check.
[BTW, I don't own a gun and was brought up by parents that would never
 own one. :-]
I fear a government out of control far more than I fear a few criminals
out of control.
There is nothing wrong with using PGP or Ripem or TIS/PEM or Mailsafe
[RSA's own product] or ...  Assuming that you are being labeled
as an extreme element just because you use some totally legal software
doesn't make any sense to me at least.
Loren J. Rittle (rittle          Ripem-1.2 MD5OfPublicKey:
Systems Technology Research (IL02/2240)        D2CE4A0F2BABF33AEF10C8C669DD782D
Motorola, Inc.                                 PGP-2.6 Key fingerprint:
(708) 576-7794                                 6810D8AB3029874DD7065BC52067EAFD

@_date: 1994-07-11 16:59:30
@_author: Loren James Rittle 
@_subject: Re: Clipper vs. PGP 
I just noticed that my semi-off-topic mail hit the Cypherpunks list.
Sorry about that --- I was aiming for Aron only.
Please take all of it as opinion.  Had I meant to send it to cypherpunks
or any other public place, it would have been written with more "facts"
to back up the assertions.
Damn, so much for trying to be inconspicuous on the list. :-)
Loren J. Rittle (rittle          Ripem-1.2 MD5OfPublicKey:
Systems Technology Research (IL02/2240)        D2CE4A0F2BABF33AEF10C8C669DD782D
Motorola, Inc.                                 PGP-2.6 Key fingerprint:
(708) 576-7794                                 6810D8AB3029874DD7065BC52067EAFD

@_date: 1994-07-21 19:25:14
@_author: Loren James Rittle 
@_subject: The Clipper Chip Proposal 
Dear Mr. Vice President,
I am glad to hear that the Administration is willing to back down on
some of the highly unfavorable aspects of the Clipper Chip Proposal.
I strongly support mandated encryption key escrow for all government
employees, such as yourself, but none whatsoever on private
individuals or private-sector companies.  You all should be
accountable to the public.  Encryption key escrow of all government
employees' keys would help allow the public to hold rogue government
employees accountable for their inappropriate actions while in office
and hold great power over the public.
Get rid of the idea that would place mandatory key escrow on all
private users of your encryption standard and, in my opinion, you will
go down in history as the first person in government to actually help
make this country *more* free and *more* open.
I also support completely voluntary (i.e. no outside government coercion)
encryption key escrow for all private individuals and private-sector
companies, if they themselves so chose it.  I cannot see why a private
individual would ever want to have their encryption key in escrow, but
the private-sector company could gain many benefits.  As employee turn-
over occurs (by death or disgruntlement), a company would be insured
continued access to its information if it had an escrow plan in place.
Until the, so called, National Security concerns that are often
alluded to, yet never discussed, are bought fully to light on this
matter, it is very hard for me to swallow the real need for key escrow
for private citizens.  Given the low number of legal wiretaps that are
authorized each year, it just doesn't make sense to spend the kind of
money key escrow would require to implement it on the wide scale you
I understand that the White House has already conducted one study on
this issue of National Security as it relates to the key escrow issue.
Why don't you release this study in full instead of starting another
study?  I also understand that you have held up the FOIA request to
have this study released.  Why?  In a free society, it is just as
important to discuss the National Security issue in the open as the
citizen's privacy issue.
I leave you with a quote that describes the situation fairly well
for me:  ``You can have my personal encryption key when you pry it from
my cold, dead hands (and even then you can't have it because it has
been memorized and my brain is now dead).''
Loren J. Rittle (rittle          Ripem-1.2 MD5OfPublicKey:
Systems Technology Research (IL02/2240)        D2CE4A0F2BABF33AEF10C8C669DD782D
Motorola, Inc.                                 PGP-2.6 Key fingerprint:
(708) 576-7794                                 6810D8AB3029874DD7065BC52067EAFD

@_date: 1995-07-14 11:25:25
@_author: Loren James Rittle 
@_subject: List Crash? 
I see the cypherpunks' mailing list lost it's mind again.  It has been
awhile since this happened.
Was it an accident or sabotage?

@_date: 1995-08-16 22:57:09
@_author: Loren James Rittle 
@_subject: Re: Phone call for Mr. Doligez, was Re: SSL challenge -- broken ! 
So can I... :-(
Too bad Damien didn't wait until after the date one could legally
short the stock.  That would have been the perfect time for a media
frenzy on the issue.  The announcement of SSL having been broken is
occuring too soon to be at all useful in the financial sense.  The
media frenzy, if it happens, will now occur well before the 30-day
lock-out on shorting a new issue.  What a shame. !

@_date: 1995-12-14 12:50:13
@_author: Loren James Rittle 
@_subject: Re: Attacking Clipper with timing info? 
Without having the details of the algorithm, I suspect the answer is
'remotely possible, at best'.
However, to extend what I suspect you were getting at:
It would be very interesting to determine if the NSA knew about this
crypto-design problem and put effort into making Clipper chips resistant
to this timing based attack.  Without access to internal documents,
I suspect this would be hard to determine.  We could learn something
about the NSA by studying the Clipper chip (or the follow-on PCMCIA
product containing SKIPJACK, Capstone).
If it could be shown that Clipper chips require a different amount of
time/current to encode/decode traffic, then we could conclude one of
the following:
(A1) The NSA knew about the problem, expected to be able to use the
     behavior as an illegal backdoor and thus did nothing to close it.
(A2) The NSA knew about the problem, expected that no one (including
     themselves) would be able to exploit the behavior, and thus did
     nothing to close it.
(A3) The NSA didn't know about the problem.
Conclusions A1 and A3 would tend to make the NSA look bad.  A2
would be fine, if the NSA expectation was found to be valid.  To
restate, without internal documents, outsiders would have little
ability to determine which conclusion to draw even if differences
in behavior were detected.
If it could be shown that Clipper chips require a fixed amount
of time/current to encode/decode traffic, then we could conclude
one of the following:
(B1) The NSA knew about the issue and compensated for it.
(B2) The NSA didn't know about the issue and got lucky.
I discount B2 as a valid option.  Actually, if the answer was B1,
my respect for the NSA would creep up a notch. :-)

@_date: 1995-12-06 00:54:33
@_author: Loren James Rittle 
@_subject: Untraceability in Mobile Networks 
FYI, at MobiCom '95, an ACM sponsored conference, an interesting paper
entitled, _Untraceability in Mobile Networks_, was presented.  The
authors of the paper are Didier Samfat, Refik Molva and N. Asokan.
For order info contact: acmhelp
ACM ISBN: 0-89791-814-2
ACM Order Number: 533952
As per the ACM rule, ``Abstracting with credit is permitted,'' I
abstract ideas from the paper below.
- From the paper's abstract: ``User mobility is a feature that raises
many new security-related issues and concerns.  One of them is the
disclosure of a mobile user's real identity during the authentication
process, or other procedures specific to mobile networks.  Such
disclosure allows an unauthorized third-party to track the mobile
user's movements and current whereabouts.  Depending on the context,
access to any information related to a mobile user's location without
his consent can be a serious violation of his privacy.''
The paper, along with other ideas of interest to the Cypherpunk,
presents a classification system for arguing about the tradeoff
between user authentication, user privacy (with respect to various
entities in the network), user billing and user conveniences (such as,
``can others find the mobile user through his home agent?'') in mobile
networks.  The rest of the paper uses the classification scheme, which
really is just a convenience way of mapping all the players in the
network to the information they are allowed to ever know about a user
that has an expectation of a certain level of privacy.
The classification scheme models the following useful information
regarding users: the full identity of the user f, the identity of
the user's home domain h, and the identity of the user's current
remote domain r.
The classification scheme has the following players: User U, Home
Domain/Authority H, Remote Domain/Authority R, Legitimate Network
Entities L, and Eavesdroppers E.  They assume U always knows
everything about itself, so they ignore it from the discussion.
Notice that they model no `GAK (Government Access to Key)' or, in this
case, `GAI (Government Access to Identity)' agent.
After laying the groundwork, the authors then set about to discuss the
matrix of known information, according to their classification system,
for various interesting cases:
C1: Hiding User Identity from Eavesdroppers;
C2: Hiding User Identity from Foreign Authorities;
C3: Hiding Relationship Between the User and Authorities;
C4: Hiding the Identity of the Home Authority from Foreign Authorities; and
C5: Hiding User Behavior from Home Authority.
The cases offer more privacy from C1 to C5.  See the paper for the
exact mapping of C[1-5] to the knowledge matrix involving f, h, r
verses H, R, L, E.  The authors, quite correctly, label C5 as in
direct contrast to the intent of a ``big brother'' principle since
``no entity [other than the user] has any information about the
user.''  Attaining C5 in a system would really be the ultimate in user
location/action privacy.  The authors do not discuss the issue, but it
appears to be an open question whether, in light of a conspiracy
involving authorities, whether or not C5 could actually be attained
for a mobile user in a network.  Note: At the other end of the privacy
spectrum is the unlist C0 case.  This correspond exactly to the
classic cellular phone system in that nothing is hidden from
eavesdroppers.  Every relationship box on the knowledge matrix for
case C0 is set to true.
Next, the authors address how the levels of privacy affect and are
affected by other, non-security related, areas of system requirements.
For example, to make the highest levels of privacy work with
cross-authority guaranteed billing, some form of anonymous,
non-repudiable digital cash might be required.
The paper goes on to discuss how GSM, for both voice and packet data
users, and CDPD fail to even completely cover the simplist of privacy
cases, C1!
The authors construct a protocol that provides privacy levels C1 and
C2, then enhance the basic algorithm to provide a hybrid privacy level
somewhere between C4 and C5 (they do not solve all the privacy
problems present when the home and foreign authorities are involved in
a conspiracy --- they do, however, worry about foreign authorities
involved in a local conspiracy amongst themselves).
Finally, the authors give a proof of correctness for the basic
algorithm, an evaluation of its performance and compare their design
to other possible designs.  In sum, this paper is a must read for all
Cypherpunk's interested in the topic of untraceability and user
identification privacy in mobile networks.  To me, the paper appears
to extend the state of the art in several directions since it applies
Chaum's, and other's, ideas to mobile networks, where some tradeoffs
are different from wired, stable networks and some problems are
entirely new.
As a final aside, none of the authors could be present to give the
talk related to the paper, so the advisor of one of the students, Jay
Black of the University of Waterloo, gave the talk.  He mentioned that
he did to not understand why this area of research was important.
Apparently, he has never heard the Cypherpunk's privacy message.
However, he was quite a good sport about presenting the paper.  Later,
in the question period --- a guy, later outed as with the
U. S. government --- raised the same issue in a more hostile tone.
All I can say to the unknown G-Man, ``Are you totally clueless?  This
is a country that was founded upon the principles of anonymous speech
and one's right to privacy.  It is about time that the people restore
these lost freedoms through technology alone, if possible, or on the
political scene, if required.''

@_date: 1996-01-03 17:33:08
@_author: Loren James Rittle 
@_subject: Re: NYT's _Unmuzzling the Internet_ 
Jaron Lanier wrote in the _The New York Times_, January 2, 1996, p. A15:
 ``The other day, I came up with a way to easily evade the
   proposed American restrictions. My simple idea would be to
   create a computer program, dubbed `Unmuzzle,' which would
   deposit incomprehensible fragments of any forbidden
   material in different foreign computers (though maybe not
   Germany's). The contraband communication would only be
   reassembled into a coherent whole when downloaded in the
   home of the user back in the United States, where it would
   become protected speech, as in any other medium.''
Is this the state to which the Internet must evolve to withstand
attack from the possible near-future legislation contained within the
current draft of the Telecommunications Reregulation Bill?  The
Internet technology that was designed to withstand network outages by
routing around the problem must now, perhaps, also be designed to
allow information to be split for storage and transmission to navigate
around mere political insanity.  I know: "Cypherpunks write code!",
but something seems amiss with the technical solution proposed in the
opinion editorial quoted above. Many questions are begged in my mind.
At first, the Jaron proposal sounds like an interesting thought
experiment but a total waste of bandwidth, both CPU and network, to
me.  The unconstitutional Bill must be defeated in Congress, by that
Presidential veto pen that Clinton has become so fond of using
recently or the Court system, if absolutely necessary.  If none of
that happens, then surely technology can be used to route around this
"political" problem.  It just seems like a shame to have to expend
technical effort and valuable network resources to play games to meet
the letter of a law, which would so clearly break the direct spirit of
the Constitution, if signed into Law and later found during a Supreme
Court battle to "pass constitutional muster," as they like to say.
Under my model, which may be different than Jaron's, I assume the raw
data is useless without a recipe, or algorithm, if you prefer.  Jaron
doesn't say how the ``incomprehensible fragments of any forbidden
material'' are known to be joinable and how they are to be joined so I
invented this as the missing glue to discuss his idea in this forum.
I assume a recipe would be a new base item fetchable via a standard
URL.  It would disclose the location of raw data sets, how they should
be joined and the resultant data-type of the information, if the
recipe were to be followed.  In this way, it might be possible to work
a decoder directly into Mosaic/NetScape/HotJava/.  (Perhaps a self-imposed rating could be included
within the recipe as additional information bits.  Or, perhaps the
recipe could be signed by one or more reviewers, which may be trusted
by end-users.  These features are mentioned only as side features,
they do not affect the basic operation to circumvent the letter of the
proposed Law.
Back to the questions begged and partial solutions.
For instance, if one provides, in a distributed fashion, data sets ---
which taken apart are not indecent in anyone's mind since they appear
completely random --- and a recipe to generate information from the
data sets --- which may construct something which might be considered
indecent --- does anyone violate any portion of the insane Indecent
Bill, if passed by Congress and signed into Indecent Law by the
President?  Does the person who set up the information split get in
trouble?  Do the people pulling in recipes and various piece of
random-looking data sets get in trouble?  Do the data set warehousers
get in trouble, even if they could have had no direct way to know the
raw pieces of data that they stored were to something eventually seen
to be indecent when a recipe was followed.  Do the recipe warehousers
get in trouble, since they could have known what might be created if
all data sets were obtained and joined as proscribed by the recipe?
What if end-user client software was taught to do all the steps
required to follow a recipe automatically?  Same as last question,
except the user was explicitly asked before any recipe was followed to
completion?  I think that the Court would be hard-pressed to find a
difference between distribution of something indecent and a recipe
known to create something indecent from raw data. But, what if recipes
were used for everything, not just items thought to be borderline
indecent to totally obscene.  Under this assumption, if it could
be shown that a recipe and raw data warehousers had no knowledge
of each other's contents, they could do no self-policing.  It appears
that raw data warehousers have "no knowledge" of recipe warehousers
as long as the raw data contains no reference to the recipe.  The
recipe warehousers appear to have no such luck since they contain
URLs that point to the raw data chunks required to form coherent
information.  Recipe warehousers could follow the recipe to "check"
Finally, on a different tangent, why do the raw data pieces have to be
stored on different machines in different countries, if by themselves
they are unreadable?  Since I believe it is the recipe, not the
contributing raw data that presents a problem, it seems like this
must be the piece to be stored external to the U.S.
For example, only the recipe need be stored abroad in a nice little
computer in the Netherlands.  Assuming the recipe included only
URL-style pointers to the data sets' distributed location and mixing
method, a recipe should be quite small.  Imagine the Government trying
to explain to a jury that random looking transmissions taken together
in some exotic manner --- as described by a file fetched from outside
the U.S. --- equals some filthy text or image or some other unpopular
political speech.  Using these rules, I could probably find three
passages of text in the 100,000's of pages composing the U.S. Code
that when XOR'd together generate something obscene.
To make the Government's job even harder before a jury, what if the
recipe to be fetched from the foreign country always generated the
First Amendment text when followed directly.  Imagine the Government's
surprise when the Defense later shows a recipe involving the exact
same information sets that, perhaps, yields the text of the First
Amendment, The Indecent Bill itself or another interesting historical
document.  What if certain implementations of software that decode
these recipes could infer another recipe implicitly encoded within the
fetched data sets which were required to follow the explicitly given
recipe.  Since the information required to regenerate the First
Amendment text will have always been pulled, in its entirety, an
external observer must concluded that the receiver might have plainly
followed the directions in the recipe leading to its generation
instead of any hidden inferred recipe for the questionably indecent
text or image.
That sounds like reasonable doubt to me, regardless of the facts of
the case.  The Defense can always argue that the client was just
trying to express the First Amendment in a novel manner, which
happens to be true in more ways than one in this case. :-)
The Jaron proposal does have some major benefits at least as I have
framed the idea.  These need to be mentioned explicitly, in case the
important side goal was too subtle expressed above.  I reverse the
location of the bulk of the data required to store the real
information.  The recipe, which is assumed to be small with respects
to the size of the raw data, is stored in any Internet friendly
location (i.e. most of the world except the U.S. after the CDA
passes) and pulled into the U.S. as required.  The raw data is stored
within the U.S., randomly spread between data set servers.  When
arranged in this manner, the bulk of the data continues to be stored
as it would have been before stupid U.S. regulations took affect.
This final analysis might sound U.S. centric.  It was not meant to be.
I assume that any information replication scheme that might have been
used could continue to be used.  For example, one recipe might exist
for each regional replication that existed.  Hopefully, the recipes
themselves would be replicated in many Internet friendly locations.
I welcome informed legal comments on this modified proposal.

@_date: 1996-02-20 06:56:55
@_author: Loren James Rittle 
@_subject: Re: AT&T Public Policy Research -- hiring for cypherpunks 
You have this today in the form of symbolic addresses mapped to an
IP number via DNS (domain name service).
Under IPng, all this becomes easier to manage in the long run, but
DNS has been around for a long time.  I'd bet that the phone company
stole the idea from the Internet... :-)

@_date: 1996-03-12 18:59:58
@_author: Loren James Rittle 
@_subject: Re: FCC & Internet phones 
Hum, I would set-up the system to `dial direct'.  Maybe I could
give you this one, for systems that allow random-chat modes.
OK, everything after the IP header is encrypted.  I don't even know
which protocol is in use.
OK, everything after the IP header is encrypted.  I don't know
which port is in use.
OK, everything after the IP header is encrypted.  I don't know
which protocol options are in use.
In short, assuming IPSEC, the data stream cannot be easily found.
Slightly different assumptions led to a radically different outcome.

@_date: 1996-05-23 14:10:54
@_author: Loren James Rittle 
@_subject: Re: Long-Lived Remailers 
This will not work.  The original sender must pick the path himself,
if maximum encryption to hide the final destination is to be used.
The properly used cypherpunks-style remailer network provides that as
long as even one remailer in the chain is trustworthy, your secret is
safe.  Under your scheme, if the first remailer is untrustworthy,
everything is blown.  This is because unless the original sender
pick's the path (or at least the last hop explicitly), the final
destination and message must be available to each hop.

@_date: 1996-08-21 07:45:50
@_author: Loren James Rittle 
@_subject: RFC1984 on Cryptographic Technology 
Sender: ietf-announce-request
A new Request for Comments is now available in online RFC libraries.
        RFC 1984:
        Title:      IAB and IESG Statement on Cryptographic Technology
                    and the Internet
        Author:     IAB & IESG
        Date:       August 1996
        Mailbox:    brian fred
        Pages:      5
        Characters: 10,738
        Updates/Obsoletes:  none
        URL:        ftp://ds.internic.net/rfc/rfc1984.txt
The Internet Architecture Board (IAB) and the Internet Engineering
Steering Group (IESG), the bodies which oversee architecture and
standards for the Internet, are concerned by the need for increased
protection of international commercial transactions on the Internet,
and by the need to offer all Internet users an adequate degree of
privacy.  Security mechanisms being developed in the Internet
Engineering Task Force to meet these needs require and depend on the
international use of adequate cryptographic technology.  Ready access
to such technology is therefore a key factor in the future growth of
the Internet as a motor for international commerce and communication.

@_date: 1996-09-13 14:58:15
@_author: Loren James Rittle 
@_subject: Re: [Long] A history of Netscape/MSIE problems 
I have been tracking Netscape stock closely since the IPO.  I can
safely say that Netscape stock didn't suffer one iota when the news
reports of the cypherpunks' attacks hit the papers.  I agree with
Adam, Netscape stock generally rose (err, skyrocketed would be a
better word) the entire time of the cypherpunks incidents.
[Anyone can verify this analysis by comparing the chart at
  with the dates
 of the cypherpunks incidents (all important dates in 1995 by my
 records).]
Netscape's stock price has generally fallen since these incidents, but
this was obviously (if anything is obvious when it comes to matching
stock price swings to real events :-) caused by increased general
market pressure and, quite importantly, the fact that Microsoft was
able to deliver a reasonable product with which to compete with
Netscape in such a timely fashion.  I think even close Microsoft
watchers were surprised by the Microsoft's speed to market with
something quite decent.
In retrospect, none of this surprises me.  The stock's fall from grace
was predicted (at least by myself), just the exact timing for the fall
was far different than I expected.  None of this is to say anything
about a Netscape fall from grace, as a company.  They make great
product, but the skyrocketing stock price after the IPO made no sense
to me.  Anyone that looked closely at the IPO model (early investors
got *huge* chunks of shares at mere pennies/share) and the evolution
of the software market should have been able to plainly see that
$170/share for Netscape (pre-split price hit early Dec 1995 and late
Jan 1996) is insane.
I wonder who bought at $170?

@_date: 1997-05-10 06:46:57
@_author: Loren James Rittle 
@_subject: FreeBSD 2.2.1 on CDROM is shipping out of the U.S.A. with full DES 
I hope it is not premature but people are starting to take advantage
of the wonderful Patel ruling in the Bernstein v U.S. Department of
Justice case.  Cool!
Newsgroups: comp.unix.bsd.freebsd.misc
Organization: Walnut Creek CDROM
