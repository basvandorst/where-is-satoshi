
@_date: 2011-09-13 11:24:35
@_author: kjj 
@_subject: [Bitcoin-development] Difficulty adjustment / time issues 
The first thing I always do when I grab the source for my colo server is patch util.cpp so that GetAdjustedTime() returns GetTime() with no adjustment.  But I'm the kind of guy that buys special GPS receivers because stratum 2 isn't low enough and occasionally checks ebay for caesium fountains.
NTP has been around for long enough now that there is no reason for the client to screw with the clock.  If the client sees different times on the network, it should issue a warning, and if it is off too far, it should give an error and fail to run (and/or peers should reject it).
But that doesn't solve the whole problem, because the block timestamp checking is based on the assumption that the node is looking at the bitcoin clock rather than the, ahem, real clock.  If we change the idea of network time to NTP, we will then need to write (and test!) new block timestamp rules to account for the new assumptions.
I'm not sure that just fixing item 2 is going to stop the attacks found by ArtForz, et al.  Some of the attacks Art pointed out are particularly bad because they change the incentive structure of the system, at least in the short term.  We need to flip that back around ASAP.
Also, this is going to cause problems for at least one pool operator.

@_date: 2011-09-15 07:56:24
@_author: kjj 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
A few non-standard transactions are probably legitimate.  A whole bunch of them are probably not.  I would think that assigning a point or two of badness to a peer sending one is pretty reasonable, with the understanding that we would need to adjust that as the network evolves.

@_date: 2011-09-15 11:04:37
@_author: kjj 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
It is certainly true that standardness is an artificial construct that only has meaning to this particular implementation of the software, but no meaning in the context of the protocol or the system as a whole.
On the other hand, the vast, vast majority of all transactions follow a particular pattern.  If someone gives you one that doesn't match the standard pattern, you might be a little suspicious, but it is no big deal.  But, if they emit dozens or hundreds, it is hardly unreasonable to disconnect them until you figure out what's going on.

@_date: 2011-09-23 12:38:48
@_author: kjj 
@_subject: [Bitcoin-development] Beyond IP transactions: towards a bitcoin 
This may just be me, but this really looks like an incredibly convoluted way to solve a bunch of problems that aren't really problems.  The central issue that I see, is that you assume that there is no out of band channel, as if people were just sending transactions to addresses that came to them in a dream.
I think that this assumption is only true when it doesn't matter.  For example, I have a donation link in my sig on the forums.  I don't care much who sends to it, or why, and I certainly don't need annotations or a refund address.  The rest of the time, payments are sent to addresses that already have sufficient context.
Only one of the advantages listed is actually an advantage.  That is that payments to stale addresses can be stopped.  This isn't much of an advantage though, as someone blindly sending payments (donations, really) to addresses found on backup tapes and web archives without verifying that they are still current kinda deserve what they get.  So it really only stops payments to services that go defunct the same day (more or less).
In the end, I just don't see the value in giving a URL so that I can go ask a server for information that could just as easily have been encoded in the URL directly.
Then again, I'm cynical, and didn't sleep very well last night.  Maybe the next person will think better of it.

@_date: 2013-11-06 22:15:40
@_author: Kyle Jerviss 
@_subject: [Bitcoin-development] we can all relax now 
You are ignoring the gambler's ruin. We do not operate on an infinite timeline.  If you find a big pool willing to try this, please give me enough advance warning to get my popcorn ready.

@_date: 2013-11-06 22:59:28
@_author: Kyle Jerviss 
@_subject: [Bitcoin-development] we can all relax now 
Each block that you solve has a reward.  In practice, some blocks will be orphaned, so the expected reward is slightly less than the nominal reward.  Each second that you delay publishing a block, the expected reward drops somewhat.
On an infinite timeline, the total reward approaches the expected reward.  But reality is discrete, and zero tends to be a brick wall.  If you delay publishing a block, you will get either the nominal reward, or zero, not some fraction in between.  And if your personal random walk involves an excursion through negative land, you may not stick around long enough for it to come back.
Thus, a positive expected value is not sufficient for some strategy to be a good one.

@_date: 2013-11-06 23:24:48
@_author: Kyle Jerviss 
@_subject: [Bitcoin-development] we can all relax now 
What I want is configurable 1/10/100 millisecond ticks, and accurate flow of information.
It doesn't seem necessary to really emulate the whole protocol, nor to be overly concerned with the content of messages, nor to simulate every little housekeeping step or network message.
I'm not looking for a bitcoin-network-in-a-bottle, I just want to see flows.  In the current situation, how often does a miner win if they hold their block until they see another one?  How does that change with various numbers of remote sensors?
Other applications in the future could very well involve transaction spread, double spends, network partitions, transaction replacement, etc.
If the simulation run in question involves blocks, I'd like realistic latencies for blocks.  If it is about transactions, the latencies should be realistic for transactions.
What is realistic for those?  That brings me to...
I'll kick in another 1 BTC for an instrumentation package for the reference client.  Same conditions as before.  A runtime option, disabled by default, that collects data for the simulator.  If this creates an uproar, I'll also accept a compile-time option. Support dumping to a file that can be uploaded to a parser as the bare minimum, and if you are feeling clever, add automatic uploads to a server specified in the conf file, or whatever.  All data should be anonymous, of course.  Local file should be in a format that humans can read (JSON, XML, CSV, etc) so that people can verify that the data is indeed anonymous.
I want stats on peers (number, turnover, latency, in/out, etc), stats on local operations (I/O stats, sigs per second when verifying a block, fraction of sig cache hits when validating, etc) and whatever else might be useful to a simulator.  Each parameter should collect min, max, mean, std. deviation, etc so that the simulator can provide realistic virtual Also, I don't want anyone to think that they need to satisfy me personally to collect on either of these two bounties.  I will pay mine for a product that is generally along the lines I have laid out, if a couple of the core devs (Gavin, Greg, Jeff, sipa, Luke, etc) agree that your work is useful.
