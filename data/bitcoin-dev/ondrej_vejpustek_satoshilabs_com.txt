
@_date: 2018-01-17 12:39:42
@_author: =?UTF-8?Q?Ond=c5=99ej_Vejpustek?= 
@_subject: [bitcoin-dev] Satoshilabs secret shared private key scheme 
The entropy argument is as follows:
There is a rule of thumb which says it is safer plaintext to have low
redundancy, see
 i. e.
it's better to encrypt random or compressed data than natural language.
This rule is based on Shannon's information theory which means that a
breach of the rule usually doesn't induce a vulnerability (there is no
known generic attack). This rule is application of a precautionary
Nevertheless, here are some examples of cryptographic attacks which may
be considered as a consequence of the breach of the rule:
  * Related Message Attack by Coppersmith, Franklin, Patarin, Reiter
- given RSA ciphertext of two plaintexts x and a*x + b, where a, b are
known, it's possible to effectively compute x provided public exponent
is three. From the informaton-theoretic point of view the second message
is redundant, because it's determined by the first one. Which means that
relative redundancy of both messages is at least one half.
  * Stereotyped Messages by Coppersmith
( section 7) -
given RSA ciphertext and (1-1/e) fraction of plaintext (where e is
public exponent), it's possible to effectively compute x. Message is
highly redundant, because only 1/e of the message is unknown. Relative
redundancy of the message is at least (1-1/e).
Consider a few notes:
  * Nowadays there exists more complicated variants of mentioned attacks
which have weaker premisses.
  * There is a considerable similarity between RSA and SSS. Both schemes
are algebraically-based (rather than boolean function based).
  * CRCs (and error-correcting codes generally) introduce redundancy
into the message. Moreover the redundancy is induced by a linear
relationship among message (compare with the premise of the Related
Message Attack).
  * Related Message Attack wouldn't be possible if you had two
plaintexts x and hash(x). The relationship between messages has to be
(algebraically) uncomplicated. From the information-theoretic point of
view the situation is the same, but from the practical point of view it
is completely different.
To sum it up, there is a precautionary principle which tells us not to
increase redundancy of a message unless it is introduced in a
complicated way (for example by a hash function). That's why we use SHA
rather than CRC. One more reason why we stick to the principle is that
there's no randomisation in our scheme (such as padding or
initialisation vector). We understood advantages of error-correctings
codes over hash functions (minimal codewords distance property,
performance) and we considered it thoroughly.
Ond?ej Vejpustek

@_date: 2018-01-18 14:50:41
@_author: =?UTF-8?Q?Ond=c5=99ej_Vejpustek?= 
@_subject: [bitcoin-dev] Satoshilabs secret shared private key scheme 
Thank you for your comments, Gregory and Russell!
Gregory, thank you for you explanation of perfect secrecy, there is no
need for that, however. I'm professional mathematician and cryptographer.
They are based on algebra (group and commutative ring theory), which is
a great similarity. RSA and SHA, for example, are based on completely
distinct parts of mathematics.
identical amounts of information theoretic redundancy
I agree, see my last note in the previous mail. Adding redundancy by a
hash function is more secure than adding redundancy by a linear
relations. Just my opinion.
I see the difference between RSA and SSS you mentioned and I understand
your arguments about perfect secrecy. Just two comments:
  (1) Our proposal doesn't use SSS for the whole secret, but it divides
the secret into bytes and uses SSS for every byte separately. This
scheme is weaker because to reconstruct n-th byte it suffices to have
n-th bytes from k shares.
  (2) SSS is information-theoretic secure if you know k-1 or less
shares, where k is the threshold. But the proof doesn't hold if you know
for example a small part of every share.
impossible attacks, especially at the cost of losing the useful
properties of a real error correcting codes that would provide actual
guarantees against likely errors.
The discussion isn't about mathematics or about security proofs but
about cryptographic scheme design. In our use case you cannot assume
that all premises of security proof theorems (including SSS's perfect
secrecy) hold true (see the comment above).
In my opinion, to make a cryptographic scheme more robust it's better to
stick to general "intuitive" principles. Of course you have to consider
the advantages and disadvantages of this approach. That's why we
disclosed our draft and welcome all comments.
OK then. I was defending the hash in the inner check value.

@_date: 2018-01-18 17:59:09
@_author: =?UTF-8?Q?Ond=c5=99ej_Vejpustek?= 
@_subject: [bitcoin-dev] Satoshilabs secret shared private key scheme 
I don't think that is true. Shared secret is an input of KDF which
should prevent this kind of attack.
Actually, we've been considering something like that. We concluded that
it is to much "rolling your own crypto". Instead of diffusion layer we
decided to apply KDF on the shared secret.

@_date: 2018-01-22 16:00:25
@_author: =?UTF-8?Q?Ond=c5=99ej_Vejpustek?= 
@_subject: [bitcoin-dev] Satoshilabs secret shared private key scheme 
My apologies, I didn't read it carefully. You are absolutely right. Our
scheme doesn't protect against the scenario.
I'm happy to hear it. Nevertheless, I didn't find any standartisation or
implementation of the CMC mode (excluding the paper).
Do you have some experience with other modes (such as HCTR, HEH)?

@_date: 2018-01-23 14:54:48
@_author: =?UTF-8?Q?Ond=c5=99ej_Vejpustek?= 
@_subject: [bitcoin-dev] Satoshilabs secret shared private key scheme 
In addition to the scheme, I found out, that Makwa
( a hashing function which received a
special recognition in the Password Hashing Competition, supports a
delegation. In fact, Makwa is similar to the suggested scheme.
Unfortunately, both schemes have two drawbacks:
  (1) There is no proof that the host computes what he's suppose to do.
  (2) The delegation is far more slower than the normal computation.
According to the Makwa paper
( the delegation is
typically 100 to 1000 slower. So I see little advantage in delegating.
I doubt there is a scheme that suits our needs.
