
@_date: 2014-12-29 09:47:29
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Cartographer 
Can you explain further where limitations and problems were hit?

@_date: 2014-12-29 12:49:45
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Cartographer 
Its a seed. Not the protocol itself.
I think most would agree with me that, Mike, this answer is not just a little over the line, its unacceptable behavior in any collaborative group.
Please be respectful and avoid ad-hominem attacks.

@_date: 2014-11-06 12:09:06
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Running a full node 
There is a stats script running on this node;
more peoples opinions;

@_date: 2014-10-10 21:02:38
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Something people are forgetting about the 
And so far its been near impossible for those others to make distros not modify it.
Firefox is actually a good idea, it made debian stop distributing it.
Best solution is to build good relations with the packagers of distros.
ps. Linux distros distributing GPL licensed apps are required by law to offer the sources of the thing they build and distribute as binary. Which allows you to check the difference with upstream. Most distros therefore have a process in place for this. Even for not FLOSS software like bitcoin core.

@_date: 2014-10-14 09:27:36
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Malleable booleans 
I've ran into this issue in C++ often enough,
a funny example is assigning "2" to a native c++ bool and then you can do a
 if (myBool == true)
 else if (myBool == false)
and neither of them will hit.
What about rejecting a script where a bool is not explicitly zero or one?

@_date: 2014-10-16 09:50:48
@_author: Thomas Zander 
@_subject: [Bitcoin-development] BIP process 
I have been part of both the OSI (NEN) and the OASIS standards committees for a while, working on standards as a technical adviser.
There I learned a lot about how to manage this process, maybe some ideas from such committees can be useful.
The idea that one person owns a BIP makes total sense, (s)he is the only one that should be putting forward the BIP when its mature enough for making it final. Note that this can be already after its been implemented once or twice.
So you have a phase where you have random people propose changes, which should all go in the public mailinglist, and they can be accepted by the owner without discussion.
If anyone that sees that change has an objection to the change, (s)he speaks up and you follow group consensus. This means (and this is actually in an ISO standard ;) that consensus is reached when nobody is left objecting to the At some point the BIP is mature enough to vote on, at the discretion of the owner, and the owner puts it forward and requests a vote. If the above process was handled cleanly there is a very small chance of it being down-voted so an actual vote may not be needed (its hard to decide who gets a vote..).
You obviously need a deadline for this and afterwards you mark the proposal final. Or you close it as "needs more work".

@_date: 2014-10-16 09:38:08
@_author: Thomas Zander 
@_subject: [Bitcoin-development] BIP process 
Other than it being open source, an open platform with no lock-in 'features' and it works with everyone that uses the standards properly.
Naturally, if an old version fails to function with Yahoo, I'm all for finding a different provider. Thats what open platforms, like Mailman, are about.

@_date: 2014-10-19 20:58:02
@_author: Thomas Zander 
@_subject: [Bitcoin-development] BIP process 
I gather that actual code changes to bitcoin-core and naturally all the other clients are already done in another place. Which is likely the reason for your I agree with your stance that more discussion in public is always good.
Lets allow people that work on bitcoin java, or completely other bitcoin based stuff to have a simple way to filter out the topics they are interested in.
Mailinglist handling is pretty trivial in practically all email software, people can equally trivially subscribe to multiple lists as their interests As a long time open source developer, my experience is that more lists has never really caused fragmentation in the way that you fear.

@_date: 2014-10-25 22:28:56
@_author: Thomas Zander 
@_subject: [Bitcoin-development] death by halving 
For the sake of argument, lets assume that somehow (quite unlikely) half the mining equipment gets shut off.
The amount of hashes/second is such that it is currently, lets just say, quite secure against any takeover.
Your document makes a long series of assumptions about how this can turn out bad with each individually is implausible, together are just fiction.
Your research didn't convince me about this being bad somehow. It also completely disregards the equilibriums reached by doing so.

@_date: 2014-10-25 22:43:22
@_author: Thomas Zander 
@_subject: [Bitcoin-development] death by halving 
mining equipment has a much shorter lifetime than 4 years, so the halving makes it easy to base purchases on.
Also, divide by two is the cleanest way to get to zero after a specific amount of divisions.

@_date: 2014-10-28 07:24:07
@_author: Thomas Zander 
@_subject: [Bitcoin-development] DS Deprecation Window 
How does it help the zero-confirmation to not include a payment? Doesn't that just mean that if I send a double spend that neither of the payments will be made? So the thief just got an even bigger incentive to double-spent!
This doesn't addresses the point that Matt brought up.
Your proposal essentially has some side effects that would be disastrous to miners. As detailed by the other two replies on this thread.

@_date: 2014-10-28 23:00:23
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Fwd: death by halving 
Please don't confuse people dismissing your thoughts with dismissing the basic economic considerations. The fact of the matter is that you didn't read the archives where these ideas have been brought forward and discussed, a consensus was reached. (it wasn't so basic afterall)
The fact that people don't want to repeat the discussion just for your sake is not the same as people not listening to those arguments.

@_date: 2014-09-15 09:23:02
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Does anyone have anything at all signed 
Any and all PGP related howtos will tell you that you should not trust or sign a formerly-untrusted PGP (or GPG for that matter) key without seeing that person in real life, verifying their identity etc.
I think that kind of disqualifies pgp for identity purposes wrt Satoshi :-)

@_date: 2014-09-15 16:38:34
@_author: ThomasZander.se 
@_subject: [Bitcoin-development] Does anyone have anything at all signed 
?The reason it is in fact wanking is because pgp tried to solve a problem that can't be solved.
It tried to provide distributed trust to a system of identity, while still depending on the local government (i.e centralized) for the upstream ID...
It's a marriage that has no benefit.
What we really want is (decentralized) identity management that allows me to create a new anonymous ID and use that as something more secure than trusting a behavior pattern to proof it's me.?
Sent on the go. Excuse the brevity.
? Original Message ?
Sent: 15:35 mandag 15. september 2014
I would agree that the in person aspect of the WoT is frustrating, but to dismiss this as "geek wanking" is the pot calling the kettle. The value of in person vetting of identity is undeniable. Just because your risk acceptance is difference doesn't make it wanking. Please go see if you can get any kind of governmental clearance of credential without in-person vetting. Ask them if they accept your behavioral signature. I know there is a lot of PGP hating these days but this comment doesn't necessarily apply to every situation.

@_date: 2014-09-15 17:10:21
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Does anyone have anything at all signed 
The reason it is in fact geek wanking is because pgp tried to solve a problem that can't be solved.
It tried to provide distributed trust to a system of identity, while still depending on the local governments (i.e. centralization) for the upstream ID.
Its a marriage that has no benefits.
What we really want is a (decentralized) identity management that allows me to create a new anonymous ID and use that as something more secure when needed that I have to proof its me.
So for instance I start including a bitcoin public key in my email signature. I don't sign the emails or anything like that, just to establish that everyone has my public key many times in their email archives.
Then when I need to proof its me, I can provide a signature on the content that the requester wants me to sign.
All the overhead of PGP and the WoT is really completely unneeded and just means that less people use it.
Consider this; people create accounts on GitHub or Reddit and those have in fact more value than your pgp key!  Because they got the anonymous part right.

@_date: 2014-09-15 18:07:37
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Does anyone have anything at all signed 
The beauty of publicly archived mailinglists make it impossible to get away with this without detection.
I recall reading the awesome book "The inmates are running the asylum" which states that solutions created by software engineers typically suffer from the flaw of absolutes. (find the part where he describes homo-digitalus for more)
I think this applies to PGP and your objection; in order to make it absolutely correct, you need to introduce loads of things. Signatures, WoT, etc.
PGP&GPG do this. But each change of the normal workflow means you loose about 50% of your audience...
So, my silly example is not perfect. But I bet its good enough for most. In the end the value of the imperfect solution is higher than the perfect one.

@_date: 2015-08-07 18:06:09
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fwd: Block size following technological growth 
You make a logical fallacy;
I would agree that nodes are there for people to stop trusting someone that they have no trust-relationship with.
But your conclusion that low node count is an indication that its hard to run one discards your own point.  You forget the point that running a node is only needed if you don't know anyone you can trust to run it for you.  I'm pretty darn sure that this will have a bigger effect on nodecount than how hard it Or, in other words, without a need to run a node you can't judge the difficulty of why there aren't more running.
This is a very political answer; it doesn't actually say anything since 'unnecessary' is a personal judgment. Everyone will agree with you, but that doesn't mean anything.

@_date: 2015-08-07 18:26:32
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Eli Dourado on "governance" 
On the other hand, things like the Raspberry PI and similar hardware are gaining ground fast. And they can run a node just fine.
I have many friends that run such small hardware for things like Owncloud.org because it is decentralized.  When Bitcoin gets traction with these people, I have no doubt a nice portion of them will run a node for the same reason they are running their private cloud. Trust No One.
Or, in other words, when Bitcoin grows in popularity and more people find it interesting (and we fix longstanding issues in Core), the desktop node that eventually get shut down will be replaced with the next generation hardware of a different kind of Bitcoin user.

@_date: 2015-08-07 19:00:08
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fwd: Block size following technological growth 
You wrote;
You clearly indicated that node count is an indicator of how hard it is to run a node.
Thats like saying something is too expensive because we don't sell enough. It forgets to ask the question of need. Do people want it.
Like in our case the need to run a node in the first place.
And you do the same thing again; you dismiss the need factor.
Most merchants have no need for a node, most miners don't even want to run one anymore. Users don't make a significant amount of payments to care.
Any conclusions with regards to difficulty of running a node based on max-
blocksize is speculation without numbers; the only numbers you have is historical node count, and they don't mean shit because the need has not For instance, merchants are told to trust someone like bitpay.
Historical node-count says nothing. Anyone using it for the blocksize debate is speculating without basis.

@_date: 2015-08-07 23:35:25
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fwd: Block size following technological growth 
I see a pretty big problem if this really is your insight, the need an individual has for running a node is a completely different concept than the need for nodes to exist.  And, really, you are describing miners, not nodes.
good thing is that you seem to agree with me as your continue with;
Thats the 'need' I was talking about.
As we concluded in our previous email, the need to run a node is inversely proportional to the ability (or willingness) to trust others.
And lets face it, practically everyone trusts others with their money today.
That won't really have any influence, economics 101 says that it doesn't work that way.  Lowering the cost on a product won't make it sell more without the people wanting or needing the product.
That is your opinion. At least, I don't see that conclusion supported by I'll defer to Gavins emails that countered this point better.

@_date: 2015-08-07 23:43:32
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fwd: Block size following technological growth 
Pieter, you either misunderstood or misquoted Gavin here.
The tradeoffs Gavin talks about are about trusting your own node or using a centralized system (as the two extremes in a spectrum).
Your answer talks about something completely different. Not sure how your answer fits in this conversation, although, you do seem to use these misunderstandings often to push your own position in a way that to the naive reader it sounds like others agree with you.  Please try to be more concise and on-topic.

@_date: 2015-08-08 00:00:50
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fwd: Block size following technological growth 
Let me quote yourself;
You want to change the basic economics of Bitcoin itself.
If anything is "unnecessary risks", that would be a clear contender.

@_date: 2015-08-08 00:12:12
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
How many clients actually evict transactions from their mempool currently? If the backlog grows infinitely (as a result of more in than out), that would be a problem.
How many wallets re-transmit their transaction when your local full nodes mempool no longer has it? Problem.
What will the backlash be when people here that are pushing for "off-chain-
transactions" fail to produce a properly working alternative, which essentially means we have to say NO to more users. We can't service you, sorry. Please go away.
At this time and this size of bitcoin community, my personal experience (and I've been part of many communities) saying NO to new customers will kill the product totally. Or, if we are lucky, just make an altcoin that quickly becomes the de-facto standard.

@_date: 2015-08-08 08:10:25
@_author: Thomas Zander 
@_subject: [bitcoin-dev] trust 
I'm making this a thread of its own because this is very serious.
The idea that Bitcoins very reason for existence is to avoid trusting anyone but yourself is something I've heard before, and I have to comment because it is a destructive thought. It is very much untrue because we don't live in a black/white world.
If you look at the history of money (500 years is enough) you may know about business being done in the late 1600s in Europe that included essentially a general ledger that every merchant used and had his own copy of (at least their own bits).
Merchant in France used a system that when they bought stock from one company
they didn't give them money, they instead gave them a IOU-style piece of paper.  To break your promise meant to be evicted from their money system.
Which to a merchant in that time is equal to starvation.
The point was NOT to trust no-one, the point was to trust everyone, but keep everyone honest by keeping the ledger open and publicly available.
Bitcoins current model to decentralize and distribute trust has historical precedent and is known to work. It was abandoned when Newton started the mint in London because that allowed international trade. And their system didn't On a tangent;
What we saw with the Internet is growth because of a lack of centralized controller. This does not mean lack of trust in your neighbours. Internet grew because permissionless innovation was allowed. Not by going from one extreme of central trust to the other extreme of no trust.
It flourished just by stepping out of the trust-one party extreme.
What Adam Black and probably some others must understand is that there is a whole spectrum between having a monopoly on trust and every player having their own node.
Bitcoin sole reason for existence is because it is the first every system that has global reach and does not need a central trusted party.
It is, in other words, the first alternative that for the very first time in centuries that allows innovation without permission.
So, this is to black/white. And also wrong.
This thinking will block growth towards the thing you want, and leave you without any toys at all.
For instance it is perfectly all right to have a central player in a poor country that helps millions of unbanked to use Bitcoin as their first international payment system.
I can only try to convince you to change your worldview be explaining some history and concepts you may have missed, if you don't thats fine with me. I do, however, have to ask you to assume people will not like Bitcoin and will not use it because they don't fit your worldview. That will ultimately hurt billions of people.

@_date: 2015-08-08 09:54:51
@_author: Thomas Zander 
@_subject: [bitcoin-dev] trust 
I didn't say off-chain, and gave an example of on-chain usecase with trusted middleman.
So, no, that's not what I meant.
? Original Message ?
Sent: Saturday, 8 August 2015 09:50
If you are saying that some people are happy trusting other people,
and so would be perfectly fine with off-chain use of Bitcoin, then we
agree and I already said that off-chain use case would be a
constructive thing for someone to improve scale and interoperability
of in the post you are replying to. However that use case is not a
strong argument for weakening Bitcoin's security to get to more scale
for that use case.
In a world where we could have scale and decentralisation, then of
course it would be nice to provide people with that outlook more
security than they seem to want. And sometimes people dont understand
why security is useful until it goes wrong, so it would be a useful
thing to do. (Like insurance, your money being seized by paypal out
of the blue etc). And indeed providing security at scale maybe
possible with lightning like protocols that people are working on.

@_date: 2015-08-08 14:37:02
@_author: Thomas Zander 
@_subject: [bitcoin-dev] trust 
I'm so sorry to have to correct you again, and please don't feel bad about misreading my post twice.
Sending something to another Bitcoin on-chain user is really on-chain. Please believe me when I say that I actually understand my own example.

@_date: 2015-08-09 12:32:01
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
I agree problems for space restrictions should be solved, and the sooner the What your statement has as a side-effect is that we will run into problems when the moment of insufficient block space comes *this* year instead of in 5 years.
I can practically guarantee that no proper solutions will be deployed in time for natural growth of usage to reach always 1Mb full blocks.
Having several more years to make such solutions will be very healthy.
Notice that many people here have tried but have been unable to find a relation between max-blocksize and full node-count.
Also, there are pretty good solutions already, like a bootstrap torrent and the headers first. In the upcoming release the actual CPU load should also get better making the actual download much much faster than the 0.9 release.
Or, in other words, these problems have been solved in a large part already, and more is underway.
I don't expect them to be showstoppers when a the network finally allows bigger than 1Mb blocks. Natural growth has shown that blocks won't jump in size significantly in one month anyway. So this scenario still has 6 months or so.

@_date: 2015-08-09 12:42:53
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
The mention you refer to was about the fact that the software doesn't cope well with a continuously growing mempool.
If Bitcoind starts eating more and more memory, I expect lots of people that run it now to turn it off.
I am wondering how you concluded that? The only time we saw full blocks for a considerable amount of time was when we had a spammer, and the only thing
we taught people was to use higher fees.
Actually, we didn't teach people anything, we told wallet developers to do it. Most actual users were completely ignorant of the problem.
Full blocks will then stop being a supported usecase when real humans are trying to buy a beer or a coffee. Waiting for a confirmation won't work either for the vast majority of the current usages of Bitcoin in the real world.
This is false, if you want to double spent you have to do a lot of work and have non-standard software.  For instance sending your newer transaction to a random node will almost always get it rejected because its a double spent. Replace by fee (even safe) is not supported in the vast majority of Bitcoin

@_date: 2015-08-10 10:27:49
@_author: Thomas Zander 
@_subject: [bitcoin-dev] What Lightning Is 
While that is interesting, and I'll surely check it out, I think this list should get a good idea of what the limitations are.
Where does it NOT make sense to use LN, where would it be better to put the transaction directly on the blockchain?
This is what I'd like to know.
Gavins usecase is useful, I'm also wondering about remittances and allowing international payments and global economy (company in Nairobi buys stock from company in Spain).

@_date: 2015-08-10 10:39:02
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Off-chain transactions and miner fees 
I don't buy that argument, you are saying a company will give away profits because of... what? It can?
The reason of it being faster makes no sense, as your example the channel has been open for a month then he really doesn't care it takes 1, 10 or 50 blocks before his transaction is included.  What is 5 hours wait on a month of profit?

@_date: 2015-08-10 23:16:11
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Off-chain transactions and miner fees 
Thats exactly what I argued makes no sense to me.
Why pay for something you don't need? Paying something Just because you have money is really not a good business strategy. I doubt that will happen.

@_date: 2015-08-10 23:43:46
@_author: Thomas Zander 
@_subject: [bitcoin-dev] trust 
yes, and thats fine.
The argument that Adam was making was the other extreme; that Bitcoin was useless the moment he has to trust any 3rd party.
And that is why I started this thread, because that idea that Bitcoin looses its functionality when you deviate from the trust-no-one path, is destructive.
For instance I suggested a week ago that the Chinese firewall (blocksize propagation) problem could maybe be solved by having a chinese miner partially trust some full nodes on Internet hubs. For instance in Amsterdam, one in Stockholm, etc.
And then propagation of a newly mined block would make the miner only sent the header to this server where a full x-MB block is then created by some specialized software that bases it on the mempool of its bitcoind.
Propagation of a Chinese miner then suddenly doesn't care about blocksize when hopping over the chinese firewall. You'd only send a small amount of data, likely around 20Kb for even 8Mb blocks.
A critic would argue its a useless strategy because you'd have to trust the data center operators.
I'd argue that its a risk, for sure, but one that can be mitigated easily by having various datacenters around the world where you'd run your software so you'd be able to check the validity of each.
Risks can only be assessed fairly if people are less black/white in their I love that about Bitcoin, it combines technical specialized thinking with Economics and planning. If you don't have both, you probably end up rejecting the best ideas.
Yes, thats one example. Thanks Jorge!
A similar but relevant example would be like the M-Pesa example.
People that have a phone but not a smart phone can choose to have their private keys stored at a trusted company in their own country. Some payments can be off-chain, but as soon as you deal with people outside of this small community they would be on-chain.
When we are talking about remittances, this means one of the two parties does not have an account at the trusted party and as such this will be an on-chain Same for a farmer in Nairobi buying equipment from a company in Cairo, or a Internet startup in Kampala/Uganda selling services to users in Europe and those users send their payments on-chain.
All of these examples are about the largest group of people in the world; the unbanked. Bitcoin could mean a huge change to these people and I care a lot about this usecase. We need bigger bocks for these usecases as LN will not do anything for them.

@_date: 2015-08-11 00:04:52
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
Everyone in any industry will consider that a bad thing.
There is no doubt that on-chain transactions will grow, absolutely no doubt.
You can direct many people to off-chain systems, but that will not stop growth of on-chain transactions. Bitcoin economy is absolutely tiny and there is a huge amount of growth possible.  It can only grow.
Naturally, that is a usecase.  But not really one that enters my mind. It certainly is not a requirement to have guaranteed time.
The situation is much simpler than that.
We have maybe 0,007% of the world population using Bitcoin once a month. (half a million people).  And I'm being very optimistic with that number...
This should give you an idea of how much growth is possible.
There is no doubt at all that the 1Mb blocks will get full, continuously, if we get to a higher rate of usage. Even with the vast majority of users using Bitcoin off-chain.
As such its not about a guaranteed time-to confirmation. Its about a confirmation before I die.
Its not about transactions being cheap. The fee market is completely irrelevant to the block size. If you think otherwise you are delusional.
The reason it is irrelevant is because when the system starts consistently dropping transactions when user count goes up, and when that happens the Bitcoin network looses value because people don't put value in something that is unreliable.
This is simple economy 101.
Look at history; so many great companies made great products that had more features, but didn't make it because their competition might have been slower to market, but it was actually reliable.

@_date: 2015-08-11 00:12:38
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
Would it be an idea to create a generator of transactions on the test network that a large number of people can run? Using some randomization as well as the actual estimation code would generate some reasonably useful data.
I'd volunteer my node to run that.

@_date: 2015-08-11 00:09:14
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
The actual fee is irrelevant, the amount of transactions is relevant.
Have you ever been to a concert that was far away from public transport? They typically set up bus shuttles, or taxis to get people back into town The result there is always you end up waiting forever and it actually may be easier to just walk instead of wait.
The amount you pay is irrelevant if everyone is paying it. There still is more demand than there is capacity.
At the concert the amount of people will stop after some time, and you'd get your bus. But in the scenarios created here the queues will never stop.
So, no, its not unreliable for cheap free transactions.
Its unreliable for all types of transactions.

@_date: 2015-08-11 07:34:11
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
I'm going to go with this one, since we are seeking common ground and all of this makes sense to me. And I bet to Gavin would agree to this too.
The question I want to ask is this;
How do you expect to get from the current to the situation outlined above?
There are several market forces at work;
* people currently expect near-free payments.
* people currently expect zero-confirmations.
* Bitcoin is seeing a huge amount of uptake, popularity, etc.
* With Greece still in flux, there is a potential enormous spike of usage set to come when (not if) the Euro falls.
I conclude that we need;
* to create and make working solutions like LN, sidechains etc etc etc.
This should allow people to get their fast confirmation time. Who cares its of a different nature, the point is that the coffeeshop owner lets you leave with your coffee. We can sell that.
* To buy ourselves time, LN is not done, Bitpay and friends work on-chain. That won't change for a year at least.
We need to move the max-block size to a substantial bigger size to allow Bitcoin to grow.
Unfortunately for us all, Bitcoin is over-sold. We don't have a sales department but the worth-of-mouth leaves us in a bad situation. And we need to react to make sure the product isn't killed by bad publicity. What Gox didn't manage can certainly happen when people find out that Bitcoin can't currently do any of the things everyone is talking about.
So, while LN is written, rolled out and tested, we need to respond with bigger blocks.  8Mb - 8Gb sounds good to me.
Can everyone win?

@_date: 2015-08-11 08:31:11
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
We currently serve about 0,007% of the world population sending maybe one transaction a month.
This can only go up.
There are about 20 currencies in the world that are unstable and showing early signs of hyperinflation. If even small percentage of these people cash-out and get Bitcoins for their savings you'd have the amount of people using Bitcoin as savings go from maybe half a million to 10 million in the space of a couple of months. Why so fast? Because all the world currencies are linked. Practically all currencies follow the USD, and while that one may stay robust and standing, the linkage has been shown in the past to cause chain-effects.
It is impossible to predict how much uptake Bitcoin will take, but we have seen big rises in price as Cyprus had a bailin and then when Greece first showed bad signs again.
Lets do our due diligence and agree that in the current world economy there are sure signs that people are considering Bitcoin on a big scale. Bigger amount of people holding Bitcoin savings won't make the transaction rate go up very much, but if you have feet on the ground you already see that people go back to barter in countries like Poland, Ireland, Greece etc.
And Bitcoin will be an alternative to good to ignore.  Then transaction rates will go up. Dramatically.
If you are asking for numbers, that is a bit tricky. Again; we are at 0,007%... Thats like a f-ing rounding error in the world economy. You can't reason from that. Its like using a float to do calculations that you should have done in a double and getting weird output.
Bottom line is that a maximum size of 8Mb blocks is not that odd. Because a 20 times increase is very common in a "company" that is about 6 years old.
For instance Android was about that age when it started to get shipped by non-
Google companies. There the increase was substantially bigger and the company backing it was definitely able to change direction faster than the Bitcoin oiltanker can change direction.
On the other side, 3Tb harddrives are sold, which take 8Mb blocks without You can buy broadband in every relevant country that easily supports the bandwidth we need. (remember we won't jump to 8Mb in a day, it will likely take at least 6 months).
We should get the inverted bloom filters stuff (or competing products) working at least on a one-to-one basis so we can solve the propagation time problem.
There frankly is a huge amount of optimization that can be done in that area, we don't even use locality (pingtime) to optimize distribution..
period by focusing some research there.
Another metric to remember; if you follow hackernews (well, the incubator more than the linked articles) you'd be exposed to the thinking of these startups.
Their only criteria is growth. and this is rather substantial growth. Like 150% per month.  Naturally, most of these build on top of html or other existing technologies.  But the point is that exponential growth is expected in any startup.  They typically have a much much more agressive timeline, though. Every month instead of every year.
Having exponential growth in the blockchain is really not odd and even if we have LN or sidechains or the next changetip, this space will be used. And we will still have scarcity.
Remember 8Gb/block still doesn't support VISA/Mastercard.

@_date: 2015-08-11 13:10:48
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
Fully agreed, and I like that a lot as well.
I think remembering the Internet architecture here is viable.
There is a saying that censorship on the internet is seen as a defect and route around. Bitcoin follows the same concept, and arguable is even better at it since transactions don't have to be delivered to the network in real time. It can be shipped by carrier pigeon in the extreme case ;)
Or though smileys over skype chat...
I understand your point, its a good one.
Here is my counter argument; countries (or states) that fail to legally get the bandwidth to do mining, are not an indicator for the success of Bitcoin.
Tor will work fine with a full node (or gnunet, if you want), just make sure you take the transmission delays into account.
And naturally, there is the point that actual end users don't need a full node. The system as a whole will work just fine for people in totalitarian regimes as long as 100% of the world doesn't reach that point.
With various nodes in Sealand (near the UK) and miners in China, the system would still work for users in New York.
Naturally, I was referring to the existing proposal that 8Gb blocks would be reached only in many years. Its a really long way away.
And if you read my previous replies on this thread you can see a more substantial argument which I'll make brief here;
I'm not suggesting we scale the blocksize to accomodate for the next 10 years of growth.
Instead I'm suggesting that we use solutions like Lightning and sidechains and anything people can invent as soon as possible.  But we need bigger blocks as well. Because not any single solution is the answer, we need a combination of There really is no reason to suspect we can't actually increase the blocksize in some months as the first thing we do.

@_date: 2015-08-12 09:54:24
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
Fees rising due to scarcity has nothing to do with the problem. Its a consequence that is irrelevant to me.
Bad situations are roughly divided into two parts;
 * technical
 * marketing.
The technical part is that we already know of several technical solutions we will need when we have a forever growing backlog. Without them, nodes will On top of that, we can expect a lot of new problems we don't know yet.
IT experts are serious when they say that they avoid maxing out a system like the plague.
Marketing wise full blocks means we can only serve 3 transactions a second. Which is beyond trivial. All the banks, nasdaq, countries, businesses etc etc now contemplating using Bitcoin itself will see this as a risk too big to ignore and the 1Mb Bitcoin will loose 99% of its perceived value.
If you want fees to rise, then it should be viable to be used, withing 6 months, for something bigger than the economic size of Iceland. (=random smallest country I know).

@_date: 2015-08-12 10:01:57
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
Since you replied to me;
I have to admit I find that a little depressing.
I put forward about 10 reasons in the last 24 hours and all you remember is something with fees.  Which, thats the funny part, I never wrote as being a problem directly.
I would really like to avoid putting blame. I'd like to avoid the FUD accusation and calling people paranoid, even yourself, sounds rather bad Personally I think its a bad idea to do write the way you do, which is that some people have to prove that bad things will happen if we don't make a certain change. It polarizes the discussion and puts people into camps. People have to choose sides.
I've been reading the blocksize debate for months now and have been wondering why people here are either for or against, it makes no sense to me.
Neither camp is right, and everyone knows this!
Everyone knows that bigger blocks doesn't solve the scalability problem. Everyone knows that you can't get substantial growth using lightning or higher fees in, say, the next 12 months.
please reply to this email;

@_date: 2015-08-12 10:10:45
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
Thats one usage of the form unreliable.
Yes, if people start getting their transactions thrown out because of full blocks or full memory pools, then its unreliable to send stuff.
Much more importantly is the software is unreliable at such loads. Bitcoin core will continue to grow in memory consumption, and eventually crash. Or, worse, crash the system its running on.
We know of some issues in the software with regards to running at > 100% capacity, I'm sure we'll find more when it actually happens.
IT experts are serious when they say that they avoid maxing out a system like the plague.
This, btw, is a good scenario where more centralization ends up happening when blocks are always full and people need to upgrade their client every week to keep up with the bugfixes.

@_date: 2015-08-12 11:23:13
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
No, please don't just say "whatever". Show some respect, please.
If you have the courage to say people are spreading FUD you really should have already exhausted all possible avenues of cooperation.
Now you look like you give up and blame others.
Again, I've been trying really hard to give you answers, straight answers.
It saddens me if you really are giving up trying to understand what people equally enthusiastic about this technology may see that you don't see.
In the evolution of Bitcoin over the next couple of years we need bigger blocks for a lot of different reasons. One of them is that LN isn't here.
The other is that we have known bugs that we have to fix, and that will take time. Time we are running out of.
To buy more time, get bigger blocks now.
Anyway, I dislike your approach, as I said in the previous mail.
Its not about people spreading FUD or sidestepping the question, it is about keeping the discussion civilised.  You are essentially the one that asks;
 "if you are not beating your wife, please prove it to me".
And the you get upset when I try to steer the conversation into less black/white situations...
And, yes, that analogy is apt because you can't prove either.

@_date: 2015-08-12 11:25:46
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
I know, everyone knows.
There is a lot of work that needs to be done to be able to use bitcoind at an forever growing backlog. And since I've been doing software for some decades, I can tell you this won't be done or fixed in 6-12 months.
We probably haven't found the majority of the issues yet.
We need more time and a bigger blocksize gives us more time.

@_date: 2015-08-12 18:24:24
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Fees and the block-finding process 
This "last response" had a very direct answer to your question, why do you think it was dodged?
I wrote; "To buy more time, get bigger blocks now." (quoted from parent-of-
But also said here;
and here;
I have not made any arguments that fall within this section.
I'd like to suggest that number two is not described narrowly enough. This includes everything that we need, ever will need and want in the future...
2) Testing and architectural improvements related to nodes that get more transactions than can be handled for a considerable time.
This includes problems we don't know of yet, since we haven't run under these conditions before.
I quoted one such answer above, would be interested in knowing how you missed it.
Here is another one from 2 hours before that email;
 "All the banks, nasdaq, countries, businesses etc etc
 "now contemplating using Bitcoin itself will see this as a risk too big to
 "ignore and the 1Mb Bitcoin will loose 99% of its perceived value."
source; After repeating some answers you said were missing, it would be nice to know where the connection drops.
Maybe you don't understand what people answer, if so, please ask to explain instead of saying people are dodging the question.  ;)

@_date: 2015-08-12 18:41:36
@_author: Thomas Zander 
@_subject: [bitcoin-dev] A summary list of all concerns related to rising 
I have never heard of "develop-by-concerns"? Is that similar to fire fighting management?
To that I have this reply;
Your question makes sure that the proper answers don't fit.
And that may be why you are getting frustrated because I've given a lot of reasons why a blocksize increase is needed soon, and none of them show up in your list...
And various others; I'm not going to bother pasting URLs, you probably have them already.
Point is, Bitcoin is a growing network, with a growing amount of transactions and we KNOW we will get into problems when the block consistently get full. How do we know? Because of the old guys in this list having the experience that this always happens, because anyone in the IT business can tell you the We have started LN to cope with this growth, but this won't be enough since it just won't handle all usecases and thus the on-chain growth will continue. For instance remittances and cross-border purchases.
We need both LN as well as bigger blocks.

@_date: 2015-08-14 15:48:51
@_author: Thomas Zander 
@_subject: [bitcoin-dev] A summary list of all concerns related to not 
Your usecase only makes sense if we assume that blocks are community property.
This is provably not the case, it has been proven with the recent spam attack, people could just continue sending their payments without issues by just increasing the fee a bit.
As such, the bigger blocks don't immediately get filled, it makes more space for everyone. People abusing it will also have to spend a lot more money (that goes to benefit the network as a whole) to disrupt it.

@_date: 2015-07-16 11:38:54
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Mempool "Expected Byte Stay" policy 
Using the good old saying; results in the past are no indication of the I see a logic error in your thinking.
Your assumption that time is a better indicator is false. Naturally time itself is universal, but blocks are known by wallets too. Its just as good.
This assumption of yours leans heavily on block mining times, and that is
not guaranteed in the future.  Imagine one day half the miners dropping and blocks take much longer for a week or so.  Your assumptions just broke the

@_date: 2015-07-24 10:52:24
@_author: Thomas Zander 
@_subject: [bitcoin-dev] BIP 102 - kick the can down the road to 2MB 
The reference to bandwidth increases makes no sense, the bandwidth in most of the world is already far exceeding the 8Mb limit. Not everyone lives where you live :)
In Germany you buy a 150Mbit connection for a flatrate and a cheap monthly rate, for instance.  Not saying that Germany is where all the miners are, but since 150Mbit allows one to comfortably have 16 megabyte blocks, it is a good example of how far off Luke's calculations are from real-world.
I don't belief your argument to push forward holds.

@_date: 2015-07-24 15:39:08
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Bitcoin Roadmap 2015, 
I assume you mean that they don't have a Bitcoin Core node that is open to incoming connections. Since that is the only thing you can actually test, no?
Most companies are still terrified of accepting incoming connections from the scary Internet. So I'm not entirely surprised by this conclusion.  I would be very surprised if companies don't actually have a node at all.

@_date: 2015-07-29 13:18:59
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure isn't 
This skips over the question why you need a fees market. There really is no reason that for the next 10 to 20 years there is a need for a fees market to incentive miners to mine.  Planning that far ahead is doomed to failure.

@_date: 2015-07-29 13:29:30
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure isn't 
This particular technicality is rather important since it removes the basis of your argument.
More specifically, your 4 points of what you claim Satoshi expected to happen, but didn't were in actual fact not planned, wanted or predicted by Satoshi.
So, you can do name calling if you want, but maybe thats not very productive.
This is an odd statement, we keep on hearing about low bitcoin-core node count and since that is the only alternative, your statement can only be interpreted as saying there really are not a whole lot of users out there..
Is that really what you mean?
What is the point you are trying to make with that?  It seems completely irrelevant to the point of this thread...

@_date: 2015-07-29 14:13:04
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure isn't 
This assumption is proven wrong by history.
Take a look at the RC5 challance, and its related cousins like the folding-at-
home or seti-at-home.
Next to that, there is incentive for running a node. It is that you don't have to trust someone else. This incentive has in business always been a very strong motivator. See how many companies run Outlook on their own intranet instead of using Outlook.com or similarly in the cloud. In my own opinion, its waaay to early to call failure on running nodes. Maybe you want to actually help merchants/chains/individuals run them by making bitcoin-core more useful for them.
What is the reason people don't run it? Well, reddit says its because of the upstream bandwidth not being able to be throttled. What about you try working on that instead of giving up on it?

@_date: 2015-07-30 09:08:17
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure isn't 
There are various decades spanned in that sentence.  Your idea of "short term" is vastly different from mine.

@_date: 2015-07-30 16:03:02
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure isn't 
Like 640kb should be enough for everyone...  Unfortunately the world doesn't like things that can be bigger not getting bigger. ;)
The real advantage of Bitcoin is simpler; its the first system that is not owned and possible to subvert that actually works.
All existing attempts before Bitcoin are companies that try to benefit from being in the middle, to the exclusion of everyone else and to the exclusion of Thats circular arguing.  This didn't actually add anything to the The insight you skip over is that that Bitcoin's advantage, and the concept of distributed computing in general, has is one of ownership and control.
If you want to keep Bitcoin small at 1Mb, do you still reach your goal of being free from ownership and control? With our excellent growth trends; transactions have to go somewhere, they will not use Bitcoin if we don't have space. And that means we loose decentralization, we lose avoidance of ownership of the network and we introduce control.
All your rhetoric is missing this basic point; is holding Bitcoin at 1Mb advancing it, or hurting that basic goal of avoiding ownership?

@_date: 2015-07-30 16:15:01
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure isn't 
I have just been around for 2 years or so, and its interesting to see you two argue and give links to the past conversations.
But do realize that if you argue in public about content that is easy to read by anyone that you have to double check your memory fits the facts.
And I feel you skipped that this time...
Hmm... A DNS record is much much bigger than a single bitcoin transaction has space for.
I don't think you can take his quote out of context. The thread shows that having a full domain-registry DB on chain is what he was explaining doesn't fit with Bitcoin.
So Satoshi just explains that a rich database shouldn't live on the blockchain. Similarly with the quote you made before;
  "Piling every proof-of-work quorum system in the world into one
  dataset doesn't scale."
It just fights the stupid idea of sharing the blockchain space with tons of global databases.
Please re-read the whole thread as it really doesn't support your view that Satoshi argued that somehow decentralization would be protected by limiting the size of the chain.

@_date: 2015-07-30 16:52:40
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure 
What makes you think that when there is such a low availability of transaction space that paying to be included costs you $10, that Bitcoin is not going to be outcompeted and replaced or otherwise regarded as worthless?

@_date: 2015-07-30 18:07:40
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure 
I've been doing system design for about 10 years and I can understand your initial response.
I have to disagree with you, though.  Surely decentralized adds an overhead, but in its place it adds replication, redundancy and very cheap expansion of Remember when we went from single-core CPUs to multi-core (and hyperthreading)? Developers were saying it was useless because all apps were still single-threaded.  And now, 15 years later, there are fantastic frameworks to make this easy.
Same will happen with distributed. Any assumption you wrote above is not inherent in the technology.

@_date: 2015-07-30 19:24:35
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure 
Parallel compiling systems (distcc, icecream, teambuilder).
Git vs subversion (or perforce).
Not a joke; googles search. Not from a user perspective, naturally. But their filesystem and internal databases.
Wait, let me get a link; and since I'm on wikipedia.
Thinking about it; one inherent trait of successful distributed systems is that they are fractal-like. Not one huge mesh, but islands that connect.
Bitcoin core does something similar, but it doesn't really. The 'ping' score for connections is unreliable and its not really used to propagate smartly...

@_date: 2015-07-30 19:42:53
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure 
My brain went a bit to fast (dinner was being served, she made me close the laptop...) and wrote distributed above while the topic is decentralized.
Its not entirely wrong, even; Libraries or approaches that do distributed will be useful for decentralized systems.  ;)

@_date: 2015-07-30 22:20:43
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Block size following technological growth 
Maybe this part could use a bit more rationale, it looks like its a sudden and

@_date: 2015-07-31 08:42:46
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure isn't 
Having different priorities is fine, using your time to block peoples attempts to increase block size is not showing different priorities, it shows conflicting Different priorities means you can trust someone else to do things they care about while you do things you care about.

@_date: 2015-07-31 10:06:37
@_author: Thomas Zander 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure 
Sounds overly complicated...
What about a much simpler solution where the miner has a CPU in a well connected data center. Say, Amsterdam.
He runs bitcoind on there and he, in China or such, connects to it over RPC (and ssl) to get a "block 000f00" accepted signal. Which would be 100 bytes or The miner continues to use his current setup, but with actual validation of the blocks to completely eliminate the risk of mining on orphaned blocks and at the same time remove most of the cost of larger-than-average bandwidth in his country.
A slightly more complicated solution is needed to allow the miner to only send the headers to the bitcoind instance. So he only sends a couple of kb and his datacenter machine does the actual propagation.
If the risk of duplication becomes an issue, setup multiple propagating nodes on different sides of the world.
Bottom line for me is that most of the innovation for making stuff better for miners should be done in miners-specific software. Not in end-user software like bitcoin-core.

@_date: 2015-07-31 11:56:48
@_author: Thomas Zander 
@_subject: [bitcoin-dev] 
Ask yourself; why do miners include transactions at all? What it the incentive if there really is only less than 0.8% of income to be derived from fees?
Miners don't get payed by fees.  They won't need to get payed by fees for decades to come. Maybe you want to re-do your math, it seems off.

@_date: 2015-05-08 13:02:56
@_author: Thomas Zander 
@_subject: [Bitcoin-development] Block Size Increase 
The obvious flaw in this paper is that it talks about a block size in todays (trivial) data-flow economy and compares it with the zero-reward situation decades from now.
Its comparing two things that will never exist at the same time (unless Bitcoin fails).
