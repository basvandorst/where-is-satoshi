
@_date: 2011-08-03 12:04:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] DNS seeds returning gone peers 
This is expected to happen from time to time of course as it's inherently
racy, but there are a *lot* of bad nodes appearing in the DNS seeds.
$ nmap -oG /tmp/x -p 8333 `dig +short bitseed.bitcoin.org.uk
dnsseed.bluematt.me bitseed.xf2.org`
Nmap done: 48 IP addresses (25 hosts up) scanned in 9.80 seconds
$ grep -c 'closed' /tmp/x
So of 48 IPs returned only 19 are actually usable. This is slowing down peer
bringup for the Android apps, which don't currently save the addresses of
last-used peers (yes, I know we should fix this).
I was talking to a friend a few days ago about Bitcoin, he seemed
interested. I'm hoping he might take on DNS seeding as a project. A custom
DNS server that watches the network to find long-lived peers that run the
latest version would be helpful for resolving this kind of thing.

@_date: 2011-08-03 14:00:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] DNS seeds returning gone peers 
Yeah, the limited number of slots doesn't help either. I wonder if the
current settings are too conservative.
Your seed returns quite a few IPs that don't respond to ICMP pings - not
sure what is happening there.
03:01:53 scott:~$ for ip in `dig +short dnsseed.bluematt.me`; do echo -n -e
"Testing $ip:   "; ping -c 1 $ip|grep 'packet loss'; done
Testing 24.7.158.162:   1 packets transmitted, 1 received, 0% packet loss,
time 0ms
*Testing 50.19.225.254:   1 packets transmitted, 0 received, 100% packet
loss, time 0ms
Testing 67.242.10.199:   1 packets transmitted, 0 received, 100% packet
loss, time 0ms
Testing 72.223.56.138:   1 packets transmitted, 0 received, 100% packet
loss, time 0ms
Testing 76.92.171.255:   1 packets transmitted, 0 received, 100% packet
loss, time 0ms
Testing 76.123.10.117:   1 packets transmitted, 0 received, 100% packet
loss, time 0ms
Testing 80.3.173.28:   1 packets transmitted, 0 received, 100% packet loss,
time 0ms
*Testing 80.101.109.52:   1 packets transmitted, 1 received, 0% packet loss,
time 0ms
Testing 93.186.32.117:   1 packets transmitted, 1 received, 0% packet loss,
time 0ms
*Testing 94.19.17.167:   1 packets transmitted, 0 received, 100% packet
loss, time 0ms
*Testing 97.86.39.50:   1 packets transmitted, 1 received, 0% packet loss,
time 0ms
Testing 113.255.177.241:   1 packets transmitted, 1 received, 0% packet
loss, time 0ms
Testing 118.208.226.66:   1 packets transmitted, 1 received, 0% packet loss,
time 0ms
Testing 173.180.141.86:   1 packets transmitted, 1 received, 0% packet loss,
time 0ms
*Testing 174.119.14.66:   1 packets transmitted, 0 received, 100% packet
loss, time 0ms
*Testing 178.18.129.133:   1 packets transmitted, 1 received, 0% packet
loss, time 0ms
*Testing 193.86.163.77:   1 packets transmitted, 0 received, 100% packet
loss, time 0ms
Testing 206.255.99.164:   1 packets transmitted, 0 received, 100% packet
loss, time 0ms
Testing 216.8.180.85:   1 packets transmitted, 0 received, 100% packet loss,
time 0ms
Testing 24.1.117.3:   1 packets transmitted, 0 received, 100% packet loss,
time 0ms*

@_date: 2011-08-03 14:17:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] DNS seeds returning gone peers 
OK, but, <50% show as port open .... maybe a bug in the seed?
05:16:52 scott:~$ nmap -p 8333 `dig +short dnsseed.bluematt.me`
Starting Nmap 5.00 (  ) at 2011-08-03 14:17 CEST
Interesting ports on 83.220.45.22:
PORT     STATE SERVICE
8333/tcp open  unknown
Interesting ports on
PORT     STATE SERVICE
8333/tcp open  unknown
Interesting ports on mackila.com (88.168.105.251):
PORT     STATE SERVICE
8333/tcp open  unknown
Interesting ports on 93-81-112-85.broadband.corbina.ru (93.81.112.85):
PORT     STATE SERVICE
8333/tcp open  unknown
Interesting ports on kons-5f710a2a.pool.mediaWays.net (95.113.10.42):
PORT     STATE SERVICE
8333/tcp open  unknown
Interesting ports on 173-218-216-132.atw.suddenlink.net (173.218.216.132):
PORT     STATE SERVICE
8333/tcp open  unknown
Interesting ports on
PORT     STATE SERVICE
8333/tcp open  unknown
Interesting ports on c-71-229-116-166.hsd1.fl.comcast.net (71.229.116.166):
PORT     STATE    SERVICE
8333/tcp filtered unknown
Interesting ports on c-76-25-209-23.hsd1.co.comcast.net (76.25.209.23):
PORT     STATE SERVICE
8333/tcp open  unknown
Nmap done: 20 IP addresses (9 hosts up) scanned in 3.50 seconds

@_date: 2011-08-03 14:40:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] DNS seeds returning gone peers 
We track DNS disobeyers at Google, as we use it for load balancing (along
with many other large sites).
I'd be kind of surprised if any large/professional ISP disobeyed the TTL
that badly, because it would cause frequent problems reaching popular sites
like anything hosted on Google or Akamai. But randomizing the DNS request
isn't a bad idea.

@_date: 2011-08-03 16:10:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] DNS seeds returning gone peers 
There's no project currently :-)
Starting from Matts code is probably the way to go. It's written in PHP.
Alternatively, you could write a Java app for it, as there are drop-in DNS
serving libraries you could link with BitCoinJ+sqlite. It probably wouldn't
be that hard. You'd want to sort nodes by version, how long they've been
observed to exist, the last polling time, etc.
On Wed, Aug 3, 2011 at 4:00 PM, Rick Wesson

@_date: 2011-08-03 16:39:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] DNS seeds returning gone peers 
- massively increasing all the anti-DoS limits in 0.4, so far they've caused
a lot more damage than they solved.
- broadcasting an "upgrade now" type announcement. The alert system is
intended for informing users when there's a threat to system stability and
that's exactly what has been happening recently.

@_date: 2011-08-04 23:36:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Double spend detection to speed up 
I don't think there are huge objections to every change. You've only
really argued about this with Matt ;)
The vending machine/detecting double spends issue was discussed by
Satoshi in July 2010:
   He mentioned payment processors that could "alert the transaction is bad".
Gregorys idea looks sound to me. It'd be useful, though, to have a NAK
message for transactions anyway (not propagated). It's possible to get
yourself into a situation today where you connect to nodes that refuse
to relay your transaction for some reason (perhaps your peers are
using old fee rules, or you are) but you think the transaction was
relayed. The user is left wondering why the spend didn't confirm.
If nodes sent a message saying "I refuse to process this tx because
" it'd make debugging and testing easier as well.

@_date: 2011-08-05 13:05:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Double spend detection to speed up 
How many connections "should" a node use? We faced this decision in
BitCoinJ recently and I asked the patch writer to reduce the number.
It seems pretty arbitrary to me - if you aren't going to relay, a
single connection should be good enough. Yes, it makes sybil easier,
but if you pick the one node randomly enough it might be ok?
Hmm, I don't recall ever enabling it in my router but it's on and the
Bitcoin support works. UPnP is used by all kinds of common programs
like Skype and Xbox Live.

@_date: 2011-08-11 13:56:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Roadmap/schedules 
*cough* Upgrade alerts.
I don't know if he'll actually do anything. Best assume this
"position" is still open.
I've seen locks that track ordering relative to other locks and assert
when they are locked out of order.
Though it's not inversion related, running ThreadSanitizer might help
find other thread safety issues:

@_date: 2011-08-11 14:11:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Change to multiple executables? 
I don't think Gavin misunderstands how open source works at all. It's
completely normal for project maintainers to say "no" more often than
they say "yes". When I worked on open source for a living this was
part of the natural flow of things.
It's important to understand that ideas which receive "maybe" or "yes
but later" or "no unless you convince me" or "perhaps in a different
way" are not being shot down. These answers are requests for more work
to be done. You *cannot* get emotional about open source contributions
and any veteran will tell you this. Open source maintainers cannot and
do not say yes to every patch or idea that is proposed. I would be
very worried if Gavin did.
Now let's review these ideas:
I think the concept is reasonable but service flags might not be the
best way to do it, for instance, asking for a filtered transaction
feed is useful for lightweight clients so you'd want more precision
that can be fit into service bits.
I already told you this won't help startup time because you have to
connect blocks together in sequence. You can't build up the block
chain backwards unless you don't care about validation at all.
Or just have them send an inv containing them after connect. I don't
remember this one being "shot down".
You mean separate from protocol version, right?
The cost/benefit ratio of this one isn't obvious at all. The resource
requirements for running a full node are large enough that
re-downloading 80 bytes per block is the least of your worries if
you're upgrading.
Feel free to submit a patch to disable checksum validation and see if
Gavin accepts it. It needs to still be calculated at send time for
other implementations.
Sequence numbers are already part of the tx inputs. Or do you mean
they should be part of the whole transaction? If the latter then this
is indeed an idea that will be shot down, it's deliberate that seqnums
are part of the txinputs and it needs to be that way for contracts. It
can't be changed without forking the protocol anyway.
Some of your proposals address problems that need to be solved, but
it's not clear that way is the right way to solve them. Others reflect
either lack of understanding of the system or the fact that you don't
value backwards compatibility whereas other people do.

@_date: 2011-08-11 18:17:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Protocol changes 
This thread is getting off-topic so I changed the subject.
OK. A better way is tx filtering, as discussed here:
   The reason is you want to only get the transactions+merkle branches
relevant to you, otherwise cost is still O(system activity) not O(your
activity) as blocks get bigger, even if you don't download every
Yes, but it's more complex than that.
Some contract protocols require one party in a set to be able to
re-issue transactions without interacting with the other parties. The
reason is that each input can come from a different person. If the
sequence number was a property of the transaction, updating it would
either require all participants to re-sign the transaction, or for the
signatures to not cover the sequence number at all.
With seqnums on the inputs, I can create a newer version of the
transaction by just resigning my input with a higher sequence number.
This is defined by IsNewerThan(). Note that my options here are
limited - I can't create an arbitrarily different version of the
transaction without invalidating all the other input signatures. If I
own all the inputs, no problem. If some are owned by others, what I
can change is defined by the SIGHASH flags. To replace this tx in the
memory pool requires others to re-sign their input with a higher
sequence number than mine - so we establish a kind of chain. Nobody
can rewind the transaction to an earlier point, but anyone can update
it within the parameters established by the SIGHASH flags on the
others signatures.
These features all combine together to allow for particular types of
contracts that take place on the negotiating table of the networks
memory pool. For instance, if you are taking part and then decide you
don't wish to continue, you can set the output that's in the same
position as your input to reassign all the money you put in back to
you, sign the input with SIGHASH_SINGLE and broadcast with nSequence
set to UINT_MAX. Now the transaction is still valid but is a no-op
from your perspective. Note that once you've done this, you've bowed
out of the negotiation completely because you can't replace the
transaction anymore.
You can't change anything about the inputs beyond scripts this way.
The transaction still has to connect to the same outputs as before,
and thus import the same amount of value.

@_date: 2011-08-12 00:02:09
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Protocol changes 
The term "contract" is sort of misleading, but there isn't a better
word for it. Satoshi called them contracts so that's what I call them
The point is to allow for lower trust in certain types of
transactions. For instance, consider Kickstarter. They allow people to
club together to fund the creation of new things, typically indie
movies and games. The problem is you need this trusted middleman to
collect peoples pledges and aggregate them. That adds fees, etc. With
contracts it can be done entirely with software, all the artist/game
programmer would need is to run some software on their website.
Lock time or if every sequence number is UINT_MAX.

@_date: 2011-08-18 17:52:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] From the forums: one-confirmation attack 
There's no way to obtain the memory pools of your peers today, so if
you're newly started up it can happen that you get blocks with unseen
For vectors variant, I wonder if it'd be safe to report the number of
confirmations differently for the duration of a chain split. If you
have a block but a majority of peers relayed a block that split the
chain, subtract 1 from each confirmation reported via RPC.

@_date: 2011-08-26 12:50:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New standard transaction types: time to 
What is the bug, exactly? Perhaps it can be worked around.

@_date: 2011-08-26 13:09:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New standard transaction types: time to 
What are the use cases for this?
arbitrary scripts in a user-facing address. The software has to be
able to present some kind of reasonable user interface given an
address, it has to explain what is going to happen to the users money
and so on. From this perspective, doing pattern matching against some
encoded script template is annoying and inefficient. It'd be better to
just define another type of URI for each kind of transaction you wish
to support. This is doubly true because often to do the more
interesting contracts, you need out of band protocols, so the
"address" would probably specify some information that's not in the
final output script, like a rendezvous point.

@_date: 2011-08-26 13:42:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New standard transaction types: time to 
That said I'm not sure it makes sense for payers to care about the
details of how somebody is protecting their wallets (which is what new
address types means). It's possible for a users software to notice
inbound payments to a regular Bitcoin address and then immediately
respend them to multi-signed outputs. This way key management can be
simpler as you don't need to integrate it with your shopping cart
software or anything like that - you can just do the usual thing of
pre-generating a few hundred thousand addresses, fill up your cart
implementation and go. When a payment is received, your wallet
software can keep an eye on how much unlocked balance it has and start
locking value once it goes over a pre-set amount, or use any other
policy the user might have.
This fits with my belief that we'll eventually move away from senders
attaching tx fees, instead receivers will respend the fee-less
transaction adding whatever fee they believe is appropriate (eg, maybe
it's very low in the case of a buyer with good reputation, or higher
for unknown buyers). It doesn't make a whole lot of sense for buyers
to have to attach more fees just because the merchant is using complex
wallet policies.
Whitelisting the basic CHECKMULTISIG form (assuming it can be made to
work) seems uncontroversial, why not do it today? The forms designed
to make fancier addresses be embeddable inside QRcodes, can come later
if people feel it's necessary. I'm still not convinced it is.
Once malware can't just email wallets to the attacker, or steal the
keys when the user decrypts due to a second factor, the next easiest
attack is to that malware can rewrite addresses on-screen as it sees
fit, forwarding small payments so the user doesn't notice then
stealing a big one. To solve that, Bitcoin addresses need to contain
not only a pubkey[hash] but some kind of endpoint the second factor
can use to verify ownership of the key. It can be discussed later, I
don't think there are many possible designs here so it shouldn't be
too controversial.

@_date: 2011-12-13 11:38:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Version bytes "2.0" 
Why does anyone care what an address looks like?
If the user is seeing an address, that's a usability fail right there. It's
common today because AFAIK nobody finished off the  URL handling support in
the main client for browser integration. It'd be a much better use of time
to finish off that integration and make it easy for people to create links
containing a bitcoin: URL (like with copy/paste of text/html content).

@_date: 2011-12-13 11:55:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fwd: [BIP 15] Aliases 
Fixed addresses like that are a temporary thing during Bitcoins maturation
period. They lead to merchants exposing data they probably don't realize
they're exposing, like their income, which is basically unacceptable for
any payment system.
There's no point trying to optimize a case where:
1) You are in the minority (no phone?)
2) The "perfect experience" leaks private data in such a way that would be
deemed a gross security breach by any serious payment processor.
OK, some thoughts on the general proposal, from the POV of what it'd take
for a large deployment, like for every Gmail or every Facebook user. In
terms of ease of implementation it is ordered HTTPS/HTTP then DNS trailing
by a large margin. Big sites, even small sites, typically have high-speed
load balancing and demuxing already implemented for HTTP[S] and it's
usually easy to add new endpoints. The same is *not* true of DNS, and
whilst coding up a custom DNS server is possible it's definitely a worse
FirstBits seems out of the question for the same privacy reasons as given
above. No banking system worth its salt would let everyone look up other
peoples income.
The simplest approach would be to request a full public key with an HTTPS
request like
   foo at domain ->
If you then want to turn the resulting public key into an address before
creating a transaction you can obviously do that.
BTW the BIP is pretty hard to read. Your spec for the HTTPS proposal is a
big pile of source code. I think it's the same as above, but it's hard to
tell without more effort.

@_date: 2011-12-13 12:07:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Version bytes "2.0" 
It was also chosen for hand-writeability, weirdly enough. That's why it
excludes some confusible characters. But Satoshi didn't really understand
how people would end up using Bitcoin, he originally imagined most
transactions being done directly between pairs of IP addresses.
That's cool. I hope Matts change gets merged soon. Then the issue becomes
how do people find out about this capability? Expecting people to learn how
to hand-craft Bitcoin links won't work. But all modern operating systems
support copy/paste and drag/drop of rich content. Qt probably makes it easy
to expose an UI like this:
   *Pay me*    [Copy to clipboard]
Clicking the link in the UI would pop up an alert saying something like
   "You can drag this link to an email, chat window or editing program."
Dragging it/pushing the copy button would just set the drag/clipboard data
as a bit of text/html content. So then you can just copy/paste into an
email or HTML editor. It wouldn't work for forums that use bbCode, though I
guess there's no particular reason the forum software can't turn into [url=] automatically.

@_date: 2011-12-21 11:12:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Changes for version 0.6 are being pulled 
Thanks for this summary Luke.
Git does not produce very helpful summaries when every commit is a merge.
Is there a way to fix that? You have to guess what a change does based on
the name of the topic branch currently.

@_date: 2011-07-07 17:42:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Suggestion for enhancements to getblock 
Everyone writing an alternative client goes through this thought
process :-) There's no point in doing it, you cannot prove your
transaction is not a double spend. That requires knowledge (ie, an
index) of all transactions.
You have to treat appearing deep in the chain as ipso-facto proof of
validity. Lightweight/SPV clients simply must have that trust, it
cannot be done any other way. See this article:
Currently this is pretty safe due to the crazy speeds. In future when
speeds are likely to be lower, it will be less safe and you'd have to
wait longer or use a trusted node.
I think it'd be better to implement the filtering suggestions that
have been made. It doesn't scale to download the entire memory pool -
a better approach is to give the remote node a filter to match against
transactions then have it only relay those. After setting a filter,
transactions pending and matching would be sent in one big inv and you
can then keep the connection open to learn about new transactions
without needing to "drink from the firehose". Filters can be
probabilistic and set on many different nodes to reduce the privacy

@_date: 2011-07-07 18:44:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Suggestion for enhancements to getblock 
But what is that for? You said it's for a lightweight client to do
that when it receives a transaction, to verify that all the
dependencies are in blocks recursively. But why?
Well, it's more efficient to just verify the merkle branch. But yes.
Why do you need all of them? You just care about the ones sending
coins to you, surely?
IMHO it's fine to introduce new commands. They'll just be ignored by
old clients in any event.

@_date: 2011-07-08 11:41:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin v0.3.24 release candidate 
A quick release would be good. The network is getting really sick:
   I brought up the latest rc3 on plan99.net.
Though it's not relevant for this release, there seems to be some kind
of shutdown issue. I did a "bitcoin stop" and then waited for the log
to indicate successful shutdown. But the parent process didn't quit,
leaving a zombie. I did a kill -9 on the parent to get rid of it, and
then the addr.dat file became corrupted. I had to remove it and the
"database" directory as running the db_recover command didn't work.

@_date: 2011-07-09 14:18:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin v0.3.24 released 
If there haven't been lots of upgrades in a few days, I think it's
time to use the alert function again.

@_date: 2011-07-11 11:33:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] overall bitcoin client code quality 
This essay is old but still relevant, I think:
  Despite that, there are efforts to write a fresh implementation. For
example, BitCoinJ:
  It is not a complete implementation. It's targeting the "simplified
payment verification" mode as a first base, and is mostly intended for
mobile phones today as that's a niche the current codebase can't meet.
In the (very) long run, it may evolve into a full node.
The code was written by Satoshi who is long gone, and I doubt he would
care much for this type of list anyway. He was a do-er rather than a

@_date: 2011-07-13 13:50:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] overall bitcoin client code quality 
For what it's worth,?BitCoinJ has a NetworkParameters abstraction that
does what you suggest (groups all the constants together):
  It exists primarily to make unit testing easier. In the test suite, we
often build small chains and other structures. We do this by using a
NetworkParameters that has the easiest difficulty possible. It means
you can solve blocks in a few attempts, easily fast enough to build
test chains of any length you like.
I suspect that as the test suite expands, a similar abstraction will
be introduced to the Satoshi client.

@_date: 2011-07-30 12:34:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoin DNS addresses 
This was already discussed on the forums, but clear use cases would be helpful.
I originally thought this feature seemed like a no-brainer, but
randomly emailing money to people out of the blue is not a very common
operation. You almost always have contact with them first, if only to
say "hey, I'm going to send you some money", but more commonly to
figure out how much you're going to pay and what for.
Once you have communication, providing an address in-band isn't very
hard, and it has the advantage of always working. Doing anything with
DNS or magic HTTPS endpoints means that 90% of the time, your feature
*will not work* (eg it won't work for any gmail/yahoo/hotmail account)
and users will rapidly learn not to bother trying as they have no way
of knowing if any given address will work or not.
It's not smart UI design to provide users with a feature that will
normally never work, and for which they can't even guess at whether it
What would be better to see is a standardized (probably HTTPS based)
protocol in which a Bitcoin URI could contain a domain name, and then
your client would challenge the domain to sign a nonce with the key
corresponding to the address (or raw pubkey). This means in your
client the payment can be rendered and recorded as a payment to
"foobar.com", which is much more helpful. That protocol could then be
extended to support "user at foobar.com" type challenges so when a
bitcoin: link is provided, the server is challenged to prove ownership
by that user of that public key. It means the details are hidden and
when the feature is present, the UI gets silently better, but there's
never any demand on any users to do anything different. The "copy
Bitcoin address" button in the UI can provide the clipboard with both
text/plain and text/html content so the right one is picked depending
on context.

@_date: 2011-07-30 12:49:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Seeking advice: Encouraging bug-fixing 
I've worked on open source projects for over 10 years now. This
dynamic always exists but I've never seen it seriously kill a project.
 - People who start out with features often stick around and become
core contributors.
 - Unit tests are critical.
Now there's a basic skeleton for unit tests, the bug debt can start to
be paid down by insisting that anyone who touches a piece of code
introduces tests, whether it be for new features or refactorings.
Insist patches won't be accepted without some new tests. In an
untested codebase, adding or improving tests often reveals other bugs
that then get fixed at the same time.
People usually don't want to write tests if there's nothing there
already. So I'd suggest seeding the test suite with a small number of
simple tests for each part (wallet, net, db, etc). Once there are a
few tests already it's easier to get people to add more. It's tempting
to say, well, the wallet or re-org handling or whatever is the most
critical so we'll write lots of tests for that first and do the rest
later, but that's not as conducive to getting people to help.
Most complex projects need some unit testing infrastructure to assist.
For instance, the ability to use mock network connections or minimal
difficulty chains. So if you build up that infrastructure and plant
those seeds, it'll be easier for other people to flesh it out.
Final thought - big test suites take a long time to grow, especially
in codebases developed without them. A good start is a manually
written test plan, that just walks you through the apps features.
Insisting that a patch be signed off as passing the test plan is a
good way to avoid gigantic breakages like the wallet encryption bug
from cold start, cost of slowing down development (nobody likes
doing manual test work over and over).
I don't always follow my own advice on this and usually end up
regretting it ....

@_date: 2011-06-14 18:44:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bumping up against flood control limits again? 
Block sizes have started to get quite large once again. Whilst testing
chain download today I was disconnected due to going over the 10mb
flood control limit. Infuriatingly, I can't reproduce this reliably.
But at 500 blocks an average of 20kb per block will cause this. As we
can see from the block explorer, the average is probably quite close
to that.
The flood control seems like a pretty serious scalability limitation.
I can see a few solutions. One is to raise the limit again. Another is
to raise the limit and simultaneously lower the batch size. 500 blocks
in one message means very large messages no matter how big the flood
control limit is. Going down to 100 or even 50 would hurt chain
download speed quite a bit in high latency environments, but chain
download is already a serious bottleneck.

@_date: 2011-06-19 16:26:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Development priorities 
Probably patches for this bug would also be high priority:
   It should be an easy fix.

@_date: 2011-06-22 15:24:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [PULL] Add scriptPubKey enforced 
Thanks for writing this. It's great to see somebody run with the contracts
Your proposed protocol is simpler than the one I suggested, so I updated the
Contracts wiki page to use it. However your implementation, as pointed out
by Gavin, is too complicated. See my proposal on the wiki here:
  I think you can just use an output script of
  2    3 CHECKMULTISIGVERIFY

@_date: 2011-06-22 15:42:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [PULL] Add scriptPubKey enforced 
Oh, one other thing - as you point out yourself, escrow is only one use case
for multsig transactions. So I suggest you don't use the word in the patch.
Maybe instead call them multisign or multipay transactions.

@_date: 2011-06-22 16:49:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [PULL] Add scriptPubKey enforced 
He didn't. Satoshi told me very little unfortunately. What he did tell
me, I've written up about half of it. I still have high frequency
trading and some details of obscure SIGHASH types to go, but I wanted
to find examples to illustrate them first as Satoshi only gave the
vaguest of outlines.
CHECKMULTISIG allows up to 20 keys, I think. So it'd probably be
better to just have a bit of custom logic that checks if the script is
of the right form.
I suppose they could be added if need be. Template matching opcodes
might come in useful later when clients only want to download
transactions of interest to them.
Given the costs involved with adding new transaction types, I'd go for
allowing any number of signatures up to the max.
I don't understand what this is for. For triggering such a transaction
via the UI, I think establishing a higher level protocol would be
needed. It's a separate step.
For instance, it's not safe to use escrow until you've checked that
the escrow key is owned by who you think it is. Otherwise a buyer
could give you a 2-of-3 transaction where they own both keys. So there
needs to be some kind of protocol (probably HTTP based) where the
buyer communicates to the merchant a list of acceptable escrow
agencies, the merchant intersects with the list of agencies it
accepts, there needs to be a way to request a pubkey from a remote
domain, one side needs to be able to challenge that domain with a
nonce, etc. It's quite complicated and would need to be specced out
independently of supporting multipay transactions.
Yes it's one way to achieve security. Having BitBanks that store your
coins and require you to verify tx acceptance with an external device
is even stronger, because that external device can be guaranteed
virus/clone-proof. Some banks do this today for wire transfers (they
implicitly assume you get the wire details out of band or that no
virus can rewrite wiring instructions to point somewhere else).
But it'll be a while yet before any such company arises. Until then
2-of-2 transactions are probably a good halfway point.

@_date: 2011-06-22 18:02:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [PULL] Add scriptPubKey enforced 
As far as I understand the only reason for hashing the public key is
for typing convenience. Otherwise we'd all just pass raw public keys
around and use the simple form seen in the direct-to-ip case.
But as there'd need to be a higher level protocol on top of the
multipay transactions in order to verify who the other parties are,
there's no need for typing convenience. It'd all be done

@_date: 2011-06-27 22:46:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [ANNOUNCE] BitCoinJ v0.2 
[also sent to bitcoin-development
I'm pleased to announce BitCoinJ v0.2. There have been over 100 commits
since the first release back in March, which have added:
   - Full support for block chain re-orgs, including recognition of dead
   transactions (that will never be included in the chain).
   - Persistence of the block chain using multiple, pluggable stores. A
   BoundedOverheadBlockStore is provided that is suitable for usage on mobile
   devices where low memory usage and instant startup time are requirements.
   - A much larger test suite
   - IRC, DNS  and seed list peer discovery
   - ASN.1 key export
   - Many many bugfixes and minor API improvements.
This release represents the work of many people. In particular I'd like to
   - Andreas Schildbach
   - Miron Cuperman
   - Gary Rowe
   - Thilo Planz
   - Micheal Swiggs
   - Noa Resare
   - John Sample
   - Xiaofeng Guo

@_date: 2011-06-27 23:04:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [ANNOUNCE] BitCoinSharp 
This evening I'd also like to announce the BitCoinSharp project by
Nathan Baulch. It's big enough to deserve its own email, IMHO.
Nathan has done a complete port of BitCoinJ into C thus opening the
world of Bitcoin up to .NET developers everywhere.
You can browse the code here:
  Visual Studio SLN files are provided to help you get started. The
PingService example is a good place to start reading:
  I'm hopeful that we've now covered nearly all the bases in terms of
languages and platforms. Everyone should be able to write interesting
Bitcoin apps no matter what their background or preferred toolchain.

@_date: 2011-06-28 08:35:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fwd: Live mtgox.com trade matching bug. 
Hi Doug,
Could we keep the Mt Gox related stuff off bitcoin-development please?
It's not related to the core software.

@_date: 2011-06-28 11:52:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fwd: Live mtgox.com trade matching bug. 
It's closed source, so nobody here can do anything about it (unlike
other software discussed here).

@_date: 2011-11-05 15:32:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Lock protocol version numbers 
BitCoinJ already sets the subver field to its name and version.

@_date: 2011-11-12 17:58:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] multisig, 
Please don't create BIPs that don't have any actual implementation behind
them. Design discussion is fine but the mailing list works for that.
If I were going to implement escrow transactions in BitCoinJ it would not
matter what was written here. I'd just implement the design I thought made
sense. If that design was later adopted by others it can be documented and
agreed upon in a BIP, just like a regular RFC.
For what it's worth I would not attempt to send half-valid escrow
transactions through the p2p network, not even using the overlay networks
the protocol already supports. A correct escrow protocol requires the
seller to challenge the dispute mediator with the public key to be sure
they actually own it, and the simplest way to do that is to leverage the
existing DNS/EV-SSL infrastructure with a "sign this nonce" HTTP request.
BIPs should not be a place for people to come up with armchair designs,
because a design with no corresponding implementation is likely to be full
of problems. Let's revisit this once I can install some software on my
laptop, my server, and a friends server, and do a 3-way mediated
transaction between them.

@_date: 2011-11-12 18:16:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] multisig, 
BIPs are either "standards track" (affects everyone, represents consensus),
"informational" (ie basically just summarizing the authors viewpoints on
things) or "process".
My point is you can't have a credible standards track BIP until something
has been implemented end to end. I don't think it's a good plan to design
these things in isolation. You'll end up with bizarre user experiences
because of technical decisions taken months earlier that are now hard to
reverse. A working end to end implementation gives you the confidence to
say, yes, this is how it should work, because here's the demo and you can
see it works very well and the code is clean.
If your BIP is informational then no problems, but I don't think there's
much point in informational BIPs to be honest - it's easier to just write
an email or forum post summarizing your views on things. If you find it a
useful framework to write your thoughts in that's OK, but don't expect
implementors to follow what's written there just because it's a BIP. It
carries no more weight than any other document would.

@_date: 2011-11-12 18:38:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] multisig, 
Sure, of course, as long as it's clearly labelled as just your thoughts, no
For dispute mediation the way I'd start is playing around with some UI
design stuff and a toy protocol underneath. Once the process is smooth from
the users POV (no seeing binary blobs disguised as text) then it should
become clearer what steps the protocol needs and what order they need to
come in.
Specific feedback on this format - as far as I can tell the format
represents a subset of the regular bitcoin transaction format? Couldn't you
just serialize a Bitcoin CTransaction structure with the txins containing
the output scripts?

@_date: 2011-11-12 20:31:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [RFC] BIP 14 - Protocol Version and User 
Looks pretty reasonable to me. If Gavin changes the mainline client to use
this format I'll change BitcoinJ as well. It'll need a bit of API work so
clients are sure to set it up properly.

@_date: 2011-11-25 15:38:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [ANNOUNCE] BitCoinJ 0.3 
============================== START ==============================
Perhaps a bit off-topic for this list, maybe there should be a
software/services announcements list? Anyway ...
I'm happy to announce version 0.3 of the leading Java implementation of the
Bitcoin protocol. BitCoinJ is a widely used library that forms the
foundation of projects as diverse as the Android Bitcoin
the p2p network status graphs ,
, PoolServerJ  and more.
You can get it either from our Maven
repositoryor the
section  of the website.
New in this release:
   - Many bugfixes, robustness and test suite improvements.
   - Major optimizations to reduce parsing overhead, most protocol messages
   are now parsed on demand.
   - A new PeerGroup API that handles the management of multiple peer
   connections.
   - Switched to using Maven for the build process, removed the bundled
   Bouncy Castle as a result. You can now depend on BitCoinJ using Maven if
   you don't need any special patches.
   - A bunch of new APIs to make writing Bitcoin apps easier.
This release would not have been possible without the major contributions
*Steve Coughlan*, who contributed many parsing improvements and
*Miron Cuperman*, who did significant work on the PeerGroup API
*Andreas Schildbach*, developer of the Android wallet, who as always
reported many bugs and useful suggestions for improvement
*Gary Rowe and Jonny Hegheim*, who set up the continuous build and Maven
What's next? The next release will focus on "more of the same", that is,
fixing bugs and filling out missing features so projects using the library
don't feel any need to patch their local copy of the library. By popular
request we'll be switching from Subversion to git. We'll also introduce a
stable wallet format that isn't dependent on Java serialization, and
timestamp key creation to resolve some issues with clients that ship block
chain copies. And finally of course, whatever is contributed by the

@_date: 2011-10-05 17:17:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Transaction Delivery and Storage 
I imagine a lot of the things on the contracts page will be implemented by
specialized software that interacts with the Bitcoin network directly.
Transactions would then be moved around, for example, by having clients do
HTTP POSTs of protocol buffers to servers that are listening and know how to
interpret the received messages.

@_date: 2011-10-10 11:22:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Help wanted: translations 
What will you be using instead? Isn't bitcoind a requirement for running a

@_date: 2011-10-10 15:18:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Help wanted: translations 
Ah, I see. Sounds a bit like the direction Steve is going with poolserverj.
So your custom software would handle incrementing the extraNonce,
recalculating the merkle tree/root, and so on?

@_date: 2011-10-24 18:25:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Determine input addresses of a transaction 
I think this would solve one of the other issues I raised about the green
address idea .... you can have some kind of trust aggregator sign the
transactions. Merchants like MtGox that send would create a transaction,
export it, upload it to the trusted authority which can just check IP
address or something to verify it's really coming from MtGox, then sign it
and broadcast it.

@_date: 2011-10-25 12:42:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Determine input addresses of a transaction 
Sure. Or just "a key". It wouldn't have to be an actual key used in
the block chain.
It won't break the IsStandard checks, if that's what you mean. You can
put any data you like into a scriptSig. In practice only data is
useful, there's no purpose in having an actual script there (or at
least, I wasn't able to find one yet).
You could easily change the bitcoin code to detect such transactions -
just look for scriptSigs that have 3 items instead of two, where the
3rd item is the right size to be a signature.
Heh, if that's a reference to my feedback, I definitely wouldn't
describe such a feature as "evil", that's rather strong :-)

@_date: 2011-10-25 12:49:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Detecting OP_EVAL scriptPubKeys that are to 
scriptPubKeys that use OP_EVAL contain a hash of a script. If I
understand correctly, that means to detect a transaction in a block
that is relevant to your wallet, that means you need to pre-calculate
every possible hash that might appear.
For the case of a single payment, that's not a problem. It means for
each key you now have to check for:
 - raw key
 - key hash
 - hash of script that contains key hash
 - hash of script that contains raw key
which isn't so bad.
What is the complexity like when multi-signing comes into the picture?
I *think* it's not an issue for the use cases currently envisioned,
but being unable to "see into" a script could complicate things later.
Specifically: for a wallet protection service, you have to make sure
the WPS keys are matched 1:1 with your own private keys. You must
never mix them up otherwise you have to check the block chain for the
cross-product. Deterministic wallets are one way to achieve that
without compromising privacy.
For escrow contracts, using OP_EVAL means you cannot detect them
unless the sender has told you the pubkey they are going to use,
because otherwise you can't recreate the hashed script. Escrow
protocols require some out of band communication anyway in order to
set up the escrow key, so this isn't inherently a problem.
Are there any use cases where you will want to recognize transactions
to you, where you can't predict the full script contents?

@_date: 2011-09-05 14:04:49
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Adding a pong message to the protocol 
I haven't written a patch for this, I might do so if there's
sufficient interest.
Nodes that are under heavy load exhibit extremely high latency, this
makes downloading the block chain from a node that is itself
downloading the block chain basically useless as it takes 30-60
seconds for the node to respond to clients.
It could be fixed by making nodes not accept connections/advertise
until they feel sure they have the best chain, but a more general fix
is to add a "pong" which is returned by "ping". It could contain some
useful stats about the node for network crawlers, but most importantly
timing the delta between ping and pong would let you order nodes by
responsiveness. Currently if you want to do this, it has to be
indirect, using some message that is guarantee to yield a known
Because old clients ignore messages they don't understand, adding the
pong response would be easy and backwards compatible. Making nodes
prefer responsive servers might need a bit of care to avoid sloshing
load around too much.

@_date: 2011-09-05 16:32:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Adding a pong message to the protocol 
They can't always judge it, eg if the link between you and that peer
is saturated then you may have connectivity, but it may be very slow
yet appear fast to the node itself.
This really has two parts:
(1) Making it easy to determine latency
(2) Using that data to make better connection decisions
Adding a pong message is fairly trivial and can help solve (1). For
instance we can start building latency histograms of nodes to see how
performant the network is, without risking any issues. Then that data
can be used to inform simulations of what happens if the measurements
are used by the node software. It also lets us experiment with less
critical software like Android clients.

@_date: 2011-09-06 14:49:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Building a node crawler to map network 
Actually Steve, take a look at the bitcoinj mailing list today. Somebody has
already built this and has it running. It's accumulating data at the moment,
they'll announce it more widely soon. But I think there's no need to
duplicate work.

@_date: 2011-09-06 15:31:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Building a node crawler to map network 
Patches to BitCoinJ are always welcome :-)
If you'd rather do your own thing, you could experiment with writing a proxy
that sits in front of bitcoind and multiplexes connections. Gavin is
concerned about socket exhaustion as users move to lightweight clients.
Multiplexing proxies are a battle-tested technique for reducing the strain
of this type of thing. BitCoinJ uses thread-per-connection so wouldn't do a
good job of that right now, but allowing it to use a mix of async io and
multi-threading would be a nice improvement. It'd need some changes to
bitcoind as well for a really good effort, to allow for IPs to be forwarded.
I'm happy to discuss it more with you over on the bitcoinj list if wanted.

@_date: 2011-09-06 16:52:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Building a node crawler to map network 
bitcoind already uses asynchronous IO. That's not the problem.
The issue came up in a conversation about scalability. If Bitcoins
popularity continues to grow, users are very likely to migrate away from
running full verifying nodes to lightweight clients, either a different mode
of the Satoshi client or different implementations like the Android Wallet
or MultiBit.
Lightweight clients cannot verify thus should not relay. And they'll be run
by users who just want to send/receive coins from time to time, so don't
leave the programs running 24/7. The result could be running out of sockets
(like we have had problems with recently). It's especially true because
lightweight clients cannot check transactions for themselves. If they want
to show transactions appearing immediately (and they do), they have to use
"heard from lots of nodes" as a proxy for validity. So lightweight clients
are likely to be socket intensive.
We could solve this by just hoping that lots of people run full nodes. The
problem is that a full node is quite an intensive thing already, it uses
lots of CPU and disk seeks, and will just get more expensive in future. And
as transaction traffic increases, that leaves less CPU time available to
service thousands of connected clients. The ROI of bringing up a new node
decreases at the same time as the userbase increases.
One traditional approach to solving this is frontend proxies. Jabber.com/org
used this technique many years ago, and Google has also used it to scale up the
section 3.1). It's effective because often maintaining connections to
thousands of clients doesn't involve much brainwork, just shifting bytes
around. This is especially true of Bitcoin. So if somebody is running a full
node already they could increase their client capacity by just bringing up a
frontend proxy and having it handle things like outbound tx
broadcasts/deduping inbound broadcasts, connection setup, relaying recently
found blocks etc. A well written proxy could probably support tens of
thousands of simultaneous clients which frees up the bitcoinds time for
verification and wallet manipulation.

@_date: 2011-09-08 11:29:25
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoind multiplexing proxy - 
It's probably best to keep this discussion on just one mailing list. It's
confusing to have duplicate threads in different places. People will end up
making the same points.
To repeat what I posted elsewhere, for now I'd just start with the simplest
possible approach:
- Ignore version skew for now (disconnect older clients)
- Don't send received transactions/blocks to the bitcoind. Let it hear about
them from its own p2p connections. That way you will always receive all
valid transactions/blocks which you can then relay/cache/drop inbound
- Parse/handle inv/getblocks/getheaders requests so clients that connect and
catch up with the chain don't place any load on the bitcoind. If a client
requests data the proxy doesn't have in RAM, it can go fetch it from the
underlying bitcoind.
If you can make v1 work and demonstrate actual scalability improvements,
then you can always go back and make it smarter in v2.

@_date: 2011-09-08 18:51:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Alert System 
Alert system should be upgraded to pop up a dialog box every 30 minutes
whilst you're using the software.
Bitcoin is one of the few pieces of software I use that has no concept of
automatic updates or even notifications at all. Yet the network badly relies
on people upgrading for stability, scalability and to enable new features.
If the alert system goes away, it'd just end up being replaced by polling
something over HTTP, which is less decentralized than before. Having zero
way to communicate upgrades to end-users is a non-starter for anything
serious about mass market penetration.

@_date: 2011-09-15 13:45:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
Probabilistic disconnections could make it quite hard to debug protocol
implementations and increases the risk of flaky behaviour in the wild
significantly. I don't see why a simpler solution isn't better.
The most likely failure mode of this is not an attack but the same as
previous breakages - scaling or legitimate version skew that causes problems
as the network evolves.
Agree with Luke that non-standard transactions should not be considered an
If you stay with the scoring system I'd be tempted to have a flag (defaults
to 100) that sets a minimum threshold for the badness scores and ignores any
below that. Attacks based on sending transactions that aren't syntactically
valid don't seem likely to me, this isn't a good way to DoS somebody because
discarding them is so cheap. If it turns out later there is a problem,
people under attack could flip the flag until a new version is released.
The formula for the DoS score in the case of invalid signatures/merkle roots
seem unnecessarily elaborate. An invalid signature should never occur and
could always result in immediate disconnection.
Treating a block with too many sigops as invalid means legitimate relayers
might be treated as an attacker if/when the constant changes in future. I'd
suggest not treating this as an attacking situation at all.
Why use a mutable field with a const setter?
Unit tests that rely on sleeps like this can be flaky because the OS delay
isn't always precise, not to mention slow/irritating to run. It's better if
tests can override the clock, eg, if GetTime() did something like
   if (nMockTime) { return nMockTime} else { ... }
then unit tests could reliably modify and advance the clock in a
fast/efficient manner.

@_date: 2011-09-15 18:21:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
The issue is, what if I'm not trying to DoS you, but something went wrong?
Only clear to the node owner. Not the sender, who may in a better
position to debug.
It's pretty common for protocols to return useful errors even in DoS
conditions. Eg, http servers will often return 503 Service Unavailable
in overload conditions. Google actually sends a redirect telling you
why you got blocked.

@_date: 2011-09-30 09:25:49
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Multisignature transations 
Does this mean dispute mediation (2-of-3) will not be supported? I thought
the plan was also to allow CHECKMULTISIG for smallish numbers of keys.

@_date: 2012-04-11 17:32:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 31 
Jeff asked for a BIP for the pong message, so here it is:

@_date: 2012-04-13 12:04:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin TX fill-or-kill deterministic 
It sounds OK as long as you exclude nLockTimed transactions.
That said, if you broadcast a transaction that does not meet the fee
rules, you should be able to notice that it wasn't accepted by your
peers immediately. Today it's painful because the protocol isn't very
chatty - in bitcoinj I plan to do this by announcing to half the
connected peers and waiting to see if the transaction comes back on
the other half. Getting a response from a peer that the TX was dropped
for reasons {x,y,z} is a better design but needs another protocol
So having transactions expire would address the case where somebody
broadcasts a transaction that successfully propagates across the
network, but then isn't actually accepted by miners for some reason.
For instance due to a change in the default fee schedules. That risk
can be mitigated somewhat by being careful about such changes (timed
phase ins set multiple months out so people have time to upgrade,
alerts announcing it, etc).
I'm not sure we should be encouraging users to attach fees to
transactions though. Even if you can replace a transaction after a
couple of days, the user experience of trying to get the fee "right"
is atrocious. I don't think any sensible merchant will actually be
willing to put their customers through this nonsense. If somebody
broadcasts a transaction that successfully propagates across a big
chunk of the network but then gets stuck due to lacking sufficient
fees, the best fix is for the merchant to broadcast another
transaction that spends the first and increases the fees on it that
way. After this happens a few times, if I was a merchant I'd be
tempted to just ask buyers to submit the TX to me directly and I'll
handle keeping up with what miners currently charge and attaching
fees. I don't want my customers to have to think about this and have
trades spuriously fail when they forget.
That design requires a minor change to how fees are calculated inside
the memory pool, to include fees on un-included dependencies. But that
seems fairly uncontroversial to me. It's best for users, merchants and
miners to not leave chains of transactions in limbo when together
their fees add up to the minimum required amount.

@_date: 2012-04-14 17:13:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin TX fill-or-kill deterministic 
I think this is something we can explore over the coming years. I
favor having people commonly pass transactions around outside the
broadcast network with the transactions and their dependencies being
broadcast only when there's a lack of trust between recipient and
sender. The block chain is an optional service after all.
Yes, though it's worth remembering that the original Bitcoin design
did have participants communicate directly. When I talked with Satoshi
in 2009 he saw the pay-to-IP-address mode imagined as the normal way
to make payments, with pay-to-address being used as a kind of backup
for when the recipient was offline.
In the end that's not how things evolved, but it the pendulum could
easily swing back the other way.

@_date: 2012-08-13 15:15:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP: Custom Services 
I think it's pretty reasonable, although people will want to use node
flags to get into the addr broadcasts anyway.
That said, I suspect (based on previous discussions) that there would
be quite some pushback against putting extra functionality into the
core Bitcoin network. Most likely people will re-use the code with
different peer discovery seeds and bootstrap similar but unrelated P2P
networks for doing new applications.
For instance, what if we want to do the language translation app I've
talked about a few times before? You need a way to floodfill broadcast
invalid transactions to interested parties. The pubsub mechanism in
the Bitcoin protocol was an interesting way to do that, but I think it
got removed. To broadcast to interested nodes now, you'd have to find
them via addr broadcasts and then connect directly. And if you're
going to do that, you may as well just form an entirely independent
More elaboration of the use cases might therefore be useful.

@_date: 2012-08-15 12:07:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bloom Filter Implementation 
This is great, thanks!
A few remarks:
If you have to update the filter after every block, IBD will require a
round-trip after every single block download instead of doing bulk
requests with getblocks. That sounds like it'd kill any performance
gains won by the feature. There needs to be a way to do bulk getblocks
on hundreds/thousands of blocks at a time and then have the data
stream in. Perhaps the server node can update the filter for you, as
the rules are deterministic?
As you know the remote end will request the transactions given their
hashes anyway, why not save the bandwidth for the hashes and the
network round-trip by just providing the transactions immediately in
the block? I was imagining something like:
class CLiteMerkleTx : public CTransaction {
  std::vector vBranch;
  int nIndex;
class CMerkleBlock {
    int nVersion;
    uint256 hashPrevBlock;
    uint256 hashMerkleRoot;
    unsigned int nTime;
    unsigned int nBits;
    unsigned int nNonce;
    std::vector vMatchedTxns;

@_date: 2012-08-17 14:27:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 35: add mempool message 
I think MSG_TX is fine. Simply sending an inv to the other node at startup
would work, but it's better to request it explicitly as it will let the
connecting peer configure a bloom filter before requesting mempool
contents. It's already too heavy for mobile clients to download the entire
mempool contents at startup so I probably wouldn't implement/activate
support for this on the bitcoinj side until bloom filtering is done, and
then this BIP would have to be updated to reflect that the response from
mempool is filtered.

@_date: 2012-08-22 10:10:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Full Disclosure: CVE-2012-2459 (block 
Thank you for practicing responsible disclosure.
Now the vulnerability is out in the open, could the code please be updated
to contain the information here, but in the comments? Gavins commit merely
mentions there is a DoS attack without discussing further what it involves,
also, the vulnerability of the merkle hash function should ideally be noted
inside it.

@_date: 2012-12-03 16:00:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Chain dust mitigation: Demurrage based 
Because people are making 1 satoshi bets, or is this part of their
messaging system?
Pieter is right, getting consensus behind your proposal is too hard
and it's not likely to ever happen (I wouldn't support it, for one).
Outputs that never get spent are simply using disk space, the working
set is really defined by the coins that are moving. Disk space is
cheap. So this problem doesn't feel that urgent to me. Now if people
were routinely spending those 1 satoshi outputs, it'd be less great as
it'd increase the working set size.
I suspect some of these coins can be cleared over time by adjusting
wallets to consolidate outputs into the change outputs when a
transaction that has spare space before reaching the next size/fee
level takes place.

@_date: 2012-12-03 16:09:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Chain dust mitigation: Demurrage based 
Every losing play? That's ... not excellent.
Well, this why the payment protocol spec has a way for merchants to
reply to customers with text instead of outputs.

@_date: 2012-12-03 16:30:01
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Chain dust mitigation: Demurrage based 
It's cool that Armory already does this. I never had time to implement
good coin selection for bitcoinj :(
Just a couple of points: as this is primarily a side effect of
SatoshiDice, and a successful payment protocol will stop them doing
it, code put in place to do temporary cleanup now probably won't
seriously affect peoples privacy over the long term. Most people
aren't going to end up with lots of tiny outputs.
Second thing, it's best to carefully separate "anonymity" from
"privacy". Privacy is supposed to be a feature of the system (it says
so in Satoshis paper) because people demand it. If I loan a tenner to
my friend and he is able to find out what I earned last month, then
that trade was neither anonymous nor private. In this case I want
privacy but anonymity isn't useful. Mixing up anonymity with privacy
is not only a public relations problem, but can lead to confusion from
users when they, eg, try and buy Bitcoins from an exchange and are
asked to provide ID proofs.

@_date: 2012-12-03 22:28:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
There are lots of successful binary protocols: TCP, IP, PNG, JPEG,
MP3, DNS, SSH, SSL, the Bitcoin protocol itself. What's more some
other protocols that are text based have suffered serious problems due
to that choice. Witness the absurd design of SMTP that means you can't
start a paragraph with the word From because that's a new-message
marker! Or the fact that file attachments grow by 33% when you send
them. Or the various exploits that can exist in web servers thanks to
header splitting attacks.
Trying to represent something binary as text doesn't make any sense.
If you look at these data structures they consist of keys, signatures,
hashes, certificates and other fundamentally binary things. You'd just
end up base64 encoding everything anyway, at which point all you've
done is design an inefficient binary protocol that masquerades as
text. The disadvantages of both with the advantages of neither.
Protocol buffers have a text form that you can print to and parse
from, if you so wish, though I only normally see people use that
support for debug prints and sometimes because they want to load
hand-written config files directly into protobuf generated objects.

@_date: 2012-12-04 18:06:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
I think that's OK. However, you should only be getting the version you
expect because when you request an invoice, your client should be
telling the merchant what protocol version you implement.
Does it make sense to have this spec not include the details of
bootstrapping? It's not complicated - we extend the URI spec in a
backwards compatible way:
   bitcoin:1AbCdEfG?value=10.0&label=Pay%20for%20Foo&invoice=
When a compatible client sees the invoice param, it ignores the rest
of the URI and downloads the URL
A server on merchant.com sees that the client expects a version 1.0
invoice and vends it. If ver=2.0 or whatever, it knows it can use 2.0
features. If extensions are supported, add new query params.
We should define a simple mechanism for extending the protocol now, so
people who want to make proprietary extensions don't conflict. The
simplest is to just say, if you want to add new fields to an Invoice
message, please update a wiki page with the tag numbers you're going
to use, and start from number X. Protobufs have a simple way to
formalize this in the language:
   message Invoice {
  extensions 1000 to max;
The point of this is to allow you to define new parts of the messages
in separate .proto files. It's only a minor convenience but it means
if you want to use, say, two extensions that weren't yet folded into
the main spec, you can more easily do so without having to do a manual
merge of the message definitions together.
For instance, if you wanted to extend the protocol to support
specification of recurring billing, you could make a file called
recurring-invoices.proto containing:
message Recurrences {
  required uint32 every_seconds = 1;
  optional uint32 start_time = 2;
extend Invoice {
  optional Recurrences recurrences = 1005;
then you update the wiki page to claim tag number 1005 and apps can
easily use your new features. If/when the feature gets standardized
via a BIP, the core .proto definition can be extended to include these
messages and the extensions can go away.

@_date: 2012-12-04 18:46:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Roadmap to getting users onto SPV clients 
At the moment if you visit bitcoin.org then you're recommended to
download the full client. I think we all agree that at some point we
need to start presenting users with something more like this:
To get started, download wallet apps A or B.
If you'd like to contribute your computing resources to the Bitcoin
network and have a fast computer with an unfiltered internet
connection, download:
   - for desktop machines, Bitcoin-Qt
   - for servers, bitcoind
Obviously not that exact wording.
I personally feel it's a bit early for this, but it's true that users
are being turned away by the fact that they're pointed to Bitcoin-Qt
by default, so having some kind of roadmap or plan for changing that
would be good.
I think MultiBit is maturing into a client that I'd feel comfortable
recommending to end users who take the fast-start path, though it
still has a few serious lacks (encrypted wallets aren't released yet,
bloom filters will help performance a lot, needs to catch up with some
newer features). But there doesn't have to be a one true client.
The alternative, I guess, is to make Bitcoin-Qt have an SPV mode. I'm
not convinced this is the best use of time, but if somebody steps up
to do it, that could also work. MultiBit has some unique features that
are quite useful like integrating charting and exchange rate feeds.
What does everyone think on this?

@_date: 2012-12-04 21:58:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Roadmap to getting users onto SPV clients 
Hardly. I don't have any particular timeline in mind. But I disagree
we have "forever". New ideas have a certain time window to take off
and become credible. If they never overcome their problems in that
time window, eventually people just give up and move on. Does anyone
take desktop Linux seriously anymore? No. "The year of desktop Linux"
is a joke. People took it seriously in 2001 but despite great progress
since, the excitement and attention has gone. There were steady
improvements over the last 10 years but nobody is creating desktop
Linux startups anymore - Bitcoin shouldn't go the same way.
It's unclear we need to have every man and his dog run a full node.
Tor is a successful P2P network where the number of users vastly
outstrips the number of nodes, and exit nodes in particular are a
scarce resource run by people who know what they're doing and commit
to it.
The Tor guys could have said "every node should be an exit if
possible", but that would have been a short term optimization at the
cost of long term stability, and anyway doesn't seem to have been
necessary so far. Even with no incentives, they were able to obtain
the resources they need.
So why should Bitcoin be different? If there are a million users
supported by 50,000 full nodes, that wouldn't sound unhealthy to me.
We can easily send a clear and consistent "this is important, please
help" message without complicated auto-upgrade/downgrade schemes that
risk annoying users.

@_date: 2012-12-05 11:43:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Roadmap to getting users onto SPV clients 
I think the real thing we need full nodes for is "sockets" where by
socket I mean "resources needed to serve another node".
Last year we actually ran out of sockets and it took forever for new
nodes to connect because so many existing nodes were full. We don't
want to be in that situation again. So we need full nodes, nobody
disputes that.
The question is, if you have a node on your average desktop machine
that gets switched off at night, has a stupid virus scanner that
insists on checking every database write, has users who go from a bit
of light word processing to watching HD video and expect no stutters
or slowdowns - how valuable is such a node, really? Also has to be
weighed against the risk of eventual user frustration when they
discover Bitcoin is slowing their computer down and go around telling
their friends how much it sucks.
Ultraprune+LevelDB+other optimizations are great. They aren't game
changers for two reasons:
1) Eventually network traffic should increase to use up the additional
performance unlocked by optimizations
2) Users demand instant on not just at first start, but any time they
open their wallet. I don't think it ever makes sense for a regular end
user to have their wallet integrated with a full node because it means
if you get an email saying "oh hey I sent you the money" and you start
your wallet so you can see it/spend it, you still have to wait a while
until it catches up from whenever it was last quit. I've done this a
bunch of times and it really sucks to wait.
The only time it makes sense to have a wallet integrated with a full
node is if that node never shuts down, ie, it's a merchant node.
If a casual user has to be using an SPV wallet all the time no matter
what, then it's not a big leap to simply have both an SPV client and a
full node running in parallel for users who want to support the
network. And how do we recruit such users? Well I've got nothing
against light wallets noticing that the system seems to have high
uptime, external connectivity etc and putting a notice on the screen
asking users to take part. For Windows users you could have a
one-click install that sets up a background service (I think .NET
OneClick makes this possible), so getting a full node is totally easy
and transparent.
Going back to the Tor analogy, whilst I agree with Gregorys arguments
that they aren't quite the same, the Tor guys have wanted to
automatically opt users in to being relays for a while. But the
technical complexity of doing it well is really high. It's still on
their wishlist even though Tor is quite old. A good first base to
reach is simply having accurate recommendations. If users start
complaining that they were asked to run a full node but when they did,
performance suffered unacceptably, then we know we need better
heuristics before automatically opting users in.

@_date: 2012-12-06 09:53:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Escrow/multisig is complicated enough to wait for another day. But
certainly having a payment protocol is an important step towards it

@_date: 2012-12-06 18:55:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Re: the newest spec. Rather than make the signature over the
"concatenation of", why not just make it a signature over the
serialized protobuf minus the signature field (as I did in my demo
code). Otherwise it seems like we'd need more code than really
necessary. We can state explicitly tags must be ordered if you want,
even though all implementations should do that already.
Yeah, that sounds reasonable. Not that we should really design it now,
but let's use the term "mediation" rather than "escrow", which has
connotations of depositing funds with the escrow service.
I think it's best to see the existing payment messages as structures
that'll get filled out with more features over time. So rather than
have a separate EscrowProposal message, you would integrate it with
payment requests. Older clients that don't understand mediation would
just ignore the extra data they don't recognize.
message PaymentRequest {
   ....
  // One per mediator acceptable to the seller.
  repeated MediationProposal mediation_data = 10;
message MediationProposal {
  required SignedMediatorIdentity identity = 2;
  // Opaque bytes that the mediator can be asked to turn into a human
readable description
  // of how disputes will be mediated. The merchant sets this to
describe whatever policy it
  // is willing to go along with, so policies may be arbitrarily complicated.
  required bytes policy = 3;
message SignedMediatorIdentity {
  required MediatorIdentity identity = 1;
  // If the identity data is signed ...
  optional string pki_type = 2;
  optional bytes pki_data = 3;
  optional bytes pki_signature = 4;
message MediatorIdentity {
  // Name of the mediator to be displayed to the user.
  required string friendly_name = 1;
  // PNG image that can be used to represent the mediator to the user.
  optional bytes logo = 2;
  // Some text shown to the user under the name explaining the
mediators policies, why they should be chosen, etc.
  optional string blurb = 3;
  // An HTTP URL where a mediator can be reached to do things like
prove ownership of pubkeys, initiate the protocols, etc.
  required string contact_url = 4;
... etc ....
So the user experience would be that when a payment request is received:
- older clients ignore the mediation_data field and do a direct
payment as normal
- newer clients ask the user to pick a mediator (if they want to) and
if mediation is requested, the PaymentRequest is then discarded and
the next step of the mediation protocol begins.
The old request has to be discarded because the outputs would have
been written on the assumption of no mediation being in use (for
backwards compatibility).
Anyway, though I'm awfully guilty, let's not get off track. Just that
this is how I imagined new payment features being done - as new
extensions to the payment protocol, which would be a living document
amended by BIPs.

@_date: 2012-12-07 12:01:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Yet more comments (I guess at some point we need to stick a fork in it
- or at least move on to implementing a prototype version).
Maybe don't require the payment URI to be HTTPS. If you want to pay a
Tor hidden service then HTTPS just adds unnecessary complexity. Just
recommend to merchants that they use an encrypted connection and leave
it at that.
Though it's not strictly necessary, it'd be nice to have defined
behavior for if you want to pay more than the requested amount, for a
tip. Perhaps rather than "zero value outputs will be ignored" say, "if
some outputs have value and others don't, the user will be given the
option of overpaying and the extra money will be split evenly between
the zero valued outputs". That way a waitress can have the phone add a
zero-valued output to her own wallet and that would prompt the wallet
software to display some convenient UI for adding on 10% or whatever.
receiptURI -> receipt_url ? technically it has to be resolvable so
"uri" isn't quite right.
"Display the proposed Outputs in as human-friendly a form as possible"
.... ??? Surely you'd just display the total amount requested? I don't
think it ever makes sense to try and display outputs to the user
Re: the UI TODO - agreed but let's take it out of the BIP and maybe
make it an alternative document. Or just replace it with a
recommendation that "the user interface should be designed to ensure
users understand the difference between an unsigned and signed payment
request, for best practices see "
serialized_paymentrequest -> serialized_payment_request? Otherwise
languages that use CamelCase will look odd ....
The question of root CAs still needs resolution. I stick with my
recommendation to support all CAs that browsers support. Obviously,
it's better for a merchant to obtain an EV cert than a domain
verification cert - the UI can reflect the higher level of
I doubt there's a need to specify a max number of certs in a chain.
But if you want to, go for something high, like 256. There's no point
in trying to put DoS mitigations into something like this, for the
same reason HTML doesn't impose a maximum page size. It's in the
message builders interest to ensure it gets read by all users.
Crashing their clients doesn't achieve anything as long as the crash
isn't exploitable.

@_date: 2012-12-07 17:27:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Yes, but at the cost of privacy. Generators of payment requests always
have the option of just adding a single output and being done with it.
But in future they'll probably want to keep their income in unlinkable
chunks of a size that's up to them, and multi-outputs are needed for
this (the idea being, the users wallet tries to keep a
close-as-possible match between the requested outputs and their own).
OK, let's punt on tipping for now.
I see. If I were to implement a wallet I'd just display nothing
(except the size of the request). Showing an address doesn't really
help the user in any way.
The hoops only actually apply for EV certs though, they aren't
required to do that verification for DV certs.
The main reason to use the browser root CAs is that merchants are
guaranteed to be able to re-use their existing certs. Otherwise they
might have to buy new ones, which would be annoying.

@_date: 2012-12-17 10:19:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Can we please drop the binary vs text issue? We have been around it
millions of times already. There are no compelling arguments to use
text here and several obvious problems with it. If you think you've
found a good argument to use JSON, please research protocol buffers
more thoroughly and see if it changes your mind.

@_date: 2012-12-20 18:43:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Thanks for the thoughts. For those who don't know, Stephen works for BitPay.
The term "merchant" is just being used to mean the entity requesting
the payment. I'm hopeful that in future mobile wallets will be
creating these messages where today they'd make URLs and QRcodes. So
it's definitely intended for person to person payments too.
Nothing stops you converting them into whatever form you want on the
server side. If you don't care about the signature checking then it's
no problem to use a server. If you do then you'd need to ship all the
code for verifying signatures that to the client anyway, at which
point a small protobuf parser is hardly a deal killer.
They can send an unsigned payment request. Note that if you mail it as
an attachment from a competent, up to date email provider then the
attachment isn't really unsigned. The whole thing is covered by the
emails DKIM signature which is applied transparently by the ESP. If
the signature fails to verify then the mail client can show that or
treat the mail differently (as Gmail does). This is easy to use for
the end user - they don't have to think about cryptography or PKI. As
long as their email account is secure then they can send signed mails
asserting to their identity.
Useful feedback, thanks. Still, there may be other types of merchants
for whom it's useful, and many users won't change their wallet. It
certainly simplifies things if you can present the refund address and
give a one-click option to use it. If the user wants to use a
different address, then they can go onto the slow/complicated path.
This current spec deliberately punts on the topic of identifying end
users. It's a difficult problem. Whereas many merchants have SSL
certs, most end users don't have published keys in any useful form. By
far the easiest way for 99% of people to generate a signed message is
to send email that's signed by DKIM (from gmail, hotmail, yahoo, other
providers etc). Then it's all transparent and behind the scenes. Their
identity is their email address.
So for BitPays scenario, you could require an email to be sent by the
end user containing new instructions. Your MTA can show you whether
the mail is correctly DKIM signed or not when deciding whether to
follow the instructions.
Yeah, I like the term "check"/"cheque" for that concept of a reversible payment.
It's still a good idea to use one for privacy reasons. The merchant
data is there so you can stuff whatever state you want into it. So
it's like cookies. You don't have to keep state on the server side.
Just encrypt/sign it, put it in the invoice, and when you get a
payment message back there's no need to do database lookups or
anything, you can just do some crypto and know who is submitting it.
What's wrong with it? Isn't your proposal more complex? I don't see
why it's better than just embedding it.
There's no Receipt message, a SignedPaymentRequest + transactions that
pay to the requested outputs are together the proof of payment.
Re a new URI scheme. Interesting idea, thanks for the suggestion. It
seemed like it'd be easier for merchants to integrate if a single
linked worked for all wallet implementations/versions. But I guess we
could do both schemes, even.

@_date: 2012-12-27 16:28:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Has anyone compiled under MacOS 10.8? 
============================== START ==============================
The problem mysteriously resurfaced. The magic incantation this time is to add:
unix:*-g++*: QMAKE_CXXFLAGS += -fpermissive
to the top. I suspect this may be related to how I am using qmake. To
make it spit out a real makefile instead of an xcode project, I have
to run it like "gmake -spec macx-g++", which perhaps ends up making
gcc stricter than it's supposed to be.

@_date: 2012-01-06 00:30:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] does "stubbing" off Merkle trees reduce 
This thread is discussing two unrelated things.
Your first email asked about transaction pruning ("stubbing"). You're
correct. This doesn't do anything for initial chain download bandwidth or
time. In fact it makes it slower because you have the overhead of deleting
the old transactions. It exists purely to save disk space.
Christians reply is about simplified payment verification (SPV) mode. It is
unrelated to transaction pruning. SPV clients can download only the chain
headers with no bodies all the way from the genesis block until the
creation time of their youngest key. This does reduce initial setup time
and in fact is now implemented in BitCoinJ, but it's still linear in the
length of Bitcoins life, so that's ultimately unsustainable. You need a
regular series of checkpoints signed by a trusted developer and a circular
block store to have truly bounded overheads. The merkle tree is still
useful because it allows for SPV clients to receive only the transactions
of interest yet have nearly the same assurances that downloading full
blocks would give - remote nodes can now hide transactions from you (dos)
but not invent new ones.
SPV clients do not use "number of blocks on top" as a way to decide
validity. They look for the best chain they can find, same as a regular
node does. As Satoshis paper says, if an SPV node has access to the P2P
network and is also talking to you, you can defraud it for as long as you
can dominate the networks hash power (51% attack) because you can create a
harder chain than everyone else can. However your invalid blocks won't be
accepted by the rest of the network regardless of how many there are or how
much work they represent, so as soon as you stop dominating the network the
correct chain will catch up and replace yours, resulting in the fraud being
detected and shown to the SPV user.

@_date: 2012-01-23 18:50:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] ECC Signature Issue 
BitCoinJ does not verify signatures (it is an SPV implementation), so
I'm not sure what you mean by this. Are you using old code? There used
to be some stuff that checked signatures but it was removed some time

@_date: 2012-07-09 20:30:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Random order for clients page 
It's easy to say, this page is controversial, so let's get rid of it.
However that starts the project down the road of being dominated by
our internal politics rather than what actually makes sense from the
end users perspective. That route spells doom for any product. You can
always tell when a UI or product is the result of internal politics,
whether it be the difficulty of plug-n-play hardware on Linux (no
driver api) to how Microsoft is incapable of producing anything that
isn't built on Windows. Gmail labs is another example of this.
It makes sense that if I go to bitcoin.org, I am educated about the
system and what is available for it. It doesn't make any sense to have
some stuff on the main site and other stuff on a wiki (which may get
randomly vandalized and looks less professional), based on how
"controversial" some developers find it.
FWIW I am dead set against anyone randomly changing the website
without a pull request and such changes should be reverted and
resubmitted through the proper channels. I don't perceive much value
in randomization or trying to make this page "fair". If anything, we
need to pick somebody (one person) who has a strong focus on regular
people and their needs, then just make them the sole committer to the
website. That way disputes can be resolved by them making a decision,
instead of ridiculous edit wars.

@_date: 2012-07-10 00:37:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Random order for clients page 
Probably because their listing is even more useless than any of the
proposals that were presented here. Thank goodness it didn't end up
like that. Their table doesn't even attempt to list features or
differentiating aspects of each client.
I think the XMPP guys have pretty much given up on directly marketing
the system to end users.
Fortunately reasonable clients don't appear/disappear/change that often.
I think by "users" you mean, geeks who understand wiki syntax. Because
that's what it'll end up trending towards. I don't believe a wiki
would reflect the needs of your average person. It's still better to
have these arguments here and try to find a user-focussed consensus
than hope one will converge from a wiki.
Inability to agree on columns isn't why the page looks like that. I
know because I'm the one who argued for the current design.
It looks like that because feature matrices aren't especially helpful
for newbies to make a decision, especially when the "features" in
question were often things like how they handled the block chain or
which protocol standards they support, ie, things only of interest to
It's much easier to communicate the differences to people with a short
piece of text, and maybe if there is no obvious way to explain why
you'd want to use a given client, that's a good sign it's not worth
listing there. Otherwise you end up like xmpp.org.
It's true that bitcoin.org needs to be conservative. That said, I'd
like there to be sections for them too, actually. I agree that risk
isn't purely about how it's implemented and that whilst we might like
to push particular ideologies around protocols or code licensing, that
isn't especially relevant to end users who have different priorities.
Track record counts for a lot as well.

@_date: 2012-07-15 14:39:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Accepting broken QRcodes 
Hi bitcoin-development,
blockchain.info generates non-BIP-compliant URIs in its QRcodes, as
does its iPhone app. They are of the form bitcoin://address not
I asked Ben to fix this (social networks don't parse QRcodes after
all), but after explaining that social networks don't parse URLs
without :// in them, he stopped responding to my emails. So I've gone
ahead and added support for reading these types of URLs to bitcoinj,
in the interests of "just works" interoperability.
This mail is just a heads up in case anyone else wants to do the same
thing. Hopefully at some point, Ben will stop generating such QRcodes
and we can remove these hacks and get back to BIP compliance.

@_date: 2012-07-21 13:45:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New P2P commands for diagnostics, 
One thing that occurred to me recently is that it'd be useful if
filters could contain exact matches as well as Bloom filters.
Specifically I'm thinking of things like my bond network proposal
where some outputs may be marked as special using script fragments
like "BOND"  2DROP.
This would allow systems that are only interested in data and
transactions relevant to bonds to exact-filter the chain on that
marker, and then when a transaction is discovered, add the hash of
that transaction to a parallel Bloom filter, ensuring you can see any
transactions that connect to it.
The spec as provided by Jeff doesn't specify how filters are matched
against transactions. I propose the following algorithm:
For each TX:
- Check if the hash of the tx itself matches the filter
- For each input:
  - For each script data element check if it is found in the filter
  - Check if the COutPoint.hash value is in the filter (let's you
select txns that connect to arbitrary txns of interest)
- For each output
  - For each script data element check if it is found in the filter

@_date: 2012-07-21 20:49:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] LevelDB benchmarking 
Stefan went and finished off this work by bringing it up on Windows,
so now there's a pull req for it:

@_date: 2012-07-24 09:58:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Reconsidering block version number use 
I don't understand why more nonce bits are necessary. Is it really
impossible for a multi-core CPU to keep up with the merkle root
re-calculation and keep an ASIC miner fed, or is this working around a
performance bottleneck somewhere else?

@_date: 2012-07-24 10:16:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New P2P commands for diagnostics, 
Ultra-lightweight clients like Electrum or smart cards have a
fundamentally different security model to SPV clients, which mean they
cannot connect directly to the P2P network no matter what commands or
db indexes are added.
This seems to be a common point of confusion. Andreas brought up
something similar in a chat yesterday.
To connect to the P2P network, you MUST understand how to walk the
block chain and handle re-orgs. This is not optional. The reason is
that you are connected to random arbitrary nodes who can and maybe
will lie to you. The block chain is a self-proving data structure, a
node cannot lie about it or make you believe garbage unless they can
outrun the rest of the miners combined.
If all you're doing is asking a remote node to tell you about what
coins are available, that node can simply say "guess what, you're a
millionaire!" and you have no way to discover it's wrong. This can be
dangerous in the case where you think you've received a payment but
actually did not, eg, because your internet connection got tampered
with in some way. SPV clients have the same issue for zero-confirmed
transactions, but once you see confirmations at high speeds you can be
pretty sure the network accepted the transaction. For clients that
don't understand the block chain confirmations don't have any meaning.
That's why Electrum requires a trusted server and connects to it via SSL.
It doesn't matter. CPU wise Bloom filtering of blocks is very cheap
and can be trivially parallelised in the unlikely event it's
necessary. The expensive part of serving a Bloom filtered chain to an
SPV client is simply moving the disk head into the right position and
waiting for the platter to rotate. Blocks are stored sequentially and
modern hard disks transfer data once positioned at gigabit speeds so
requesting 1 or 2000 blocks is not significantly different.

@_date: 2012-07-24 10:22:25
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Reconsidering block version number use 
My point is that stuffing nonces into whatever spaces we can find to
eke out a bit more scalability in pools seems like a very short term
fix with potentially very long term consequences.
Although it may sound harsh, if your pool is struggling to keep up
with calculating merkle roots (which is cheap!) then it's time to
either upgrade your pool or for some of those users to migrate to
p2pool and handle creation of work themselves. Trying to squash more
nonce bits out of fields that were never meant for that seems like a
bad precedent with no real motivation beyond making running
centralized pools a bit cheaper.
What I'm interested in is, can a powerful server-class machine really
not keep up with work generation for things like the BitForce SC
devices? How many devices would you need to exhaust the ability to
generate work for them? You'll need powerful machines just to run a
node at all sooner or later.

@_date: 2012-07-24 11:18:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Scalability issues 
As you presumably already know, the reference client doesn't attempt
to parallelise most operations at all. Chain download is entirely
single threaded.

@_date: 2012-07-26 13:27:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin script opcode counts 
I'm interested to see what scripts were using OP_DEPTH and
OP_CODESEPARATOR, as the latter appears to be useless to my eyes.
Could you give some tx ids which use unusual opcodes?

@_date: 2012-07-29 12:17:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Signing release binaries 
MacOS X 10.8 makes application signing borderline mandatory, in that
you cannot run unsigned apps unless you tweak your settings via the
control panel. You must sign with a certificate issued by Apple via
their "identified developer" program.
Windows allows but does not require signing. However, anti-virus
systems tend to use signers with good reputation as a whitelisting
signal. Signing Bitcoin releases makes sense because it may lead to,
at minimum, higher performance if AV engines ignore file reads/writes
by Bitcoin. And it can also shield us from false positives. You only
need to see the mess that the mining tools world has become to
understand why this is important.
As I don't take part in the release process, I can't help out with
this directly, but I believe it's important and would be willing to
throw some money in towards buying the signing certs for both
platforms. I guess Gavin would be the final signer.

@_date: 2012-06-03 16:17:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Full Clients in the future - Blockchain 
Yeah, for actually storing transactions the approach Satoshi uses of
relying on a database engine makes sense and is what the code already does,
so I'm not sure why this is a problem.
The real problem with Satoshis code for scaling down to smaller devices
(and one day desktops too) is the need to store all the chain headers in
RAM. BitcoinJ avoids this but just creates more problems for itself in
other places, partly because we also try to avoid a database engine
(read/write traffic on phones can be insanely expensive, especially on
older ones, and so sqlite is known to be a serious cause of performance
pain on android apps).

@_date: 2012-06-11 01:06:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bootstrapping full nodes post-pruning 
Apologies if this has been discussed elsewhere. I don't recall us ever
reaching a solid conclusion on it.
A node that has pruned its block chain cannot serve the chain to new
nodes. So there are three options for bootstrapping a newly installed
1) Have some kind of special archival nodes that never prune
(advertised via the services field?). Encourage people to run them,
2) Ship a post-pruning block chain and tx index with the client
downloads, so the client starts up already bootstrapped.
3) Some combination of both. It's safe to assume some people will keep
unpruned chains around no matter what. But for many users (2) is
easiest and archival nodes would be put under less load if they were
used only by users who wish to fully bootstrap from only the code.
I remember some people, Greg in particular, who were not a fan of
approach (2) at all, though it has the benefit of speeding startup for
new users as there's no indexing overhead.

@_date: 2012-06-11 22:36:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bootstrapping full nodes post-pruning 
Yeah, that sounds reasonable. I mean, I can't see why pruning would
not be deterministic. So if you download a binary that contains a
pre-indexed and pruned chain up to block 180,000 or whatever, you
should be able to blow away the data files and run with
"-syncto=180000 -prune", then check the hashes of the newly created
files vs what you downloaded.
Unless BDB has some weird behaviour in it, that shouldn't require any
additional effort, and anyone could set up a cron job to verify the
downloads match what is expected.
Even if a more complex scheme is used whereby commitments are in the
block chain, somebody still has to verify the binaries match the
source. If that isn't true, the software could do anything and you'd
never know.

@_date: 2012-06-11 22:48:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bootstrapping full nodes post-pruning 
That's true. Though if you prune up to the last checkpoint, orphans
before that point can be safely thrown away.
I wonder if swapping out bdb for LevelDB might make sense at some
point. I'm not sure how deterministic that is either though :)

@_date: 2012-06-14 13:52:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New P2P commands for diagnostics, 
Why not combine these two?
Need to specify the format of how these arrive. It means that when a
new block is found instead of inv<->getdata<->block we'd see something
like  inv<->getdata<->merkleblock where a "merkleblock" structure is a
header + list of transactions + list of merkle branches linking them
to the root. I think CMerkleTx already knows how to serialize this,
but it redundantly includes the block hash which would not be
necessary for a merkleblock message.

@_date: 2012-06-15 13:29:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Near-term scalability 
I had to hit the sack last night as it was 2am CET, but I'd like to
sum up the discussion we had on IRC about scalability and SatoshiDice
in particular.
I think we all agreed on the following:
- Having senders/buyers pay no fees is psychologically desirable even
though we all understand that eventually, somebody, somewhere will be
paying fees to use Bitcoin
- In the ideal world Bitcoin would scale perfectly and there would be
no need for there to be some "winners" and some "losers" when it comes
to confirmation time.
There was discussion of some one-off changes to address the current
situation, namely de-ranking transactions that re-use addresses. Gavin
and myself were not keen on this idea, primarily because it just
avoids the real problem and Bitcoin already has a good way to
prioritize transactions via the fees mechanism itself. The real issue
is that SatoshiDice does indeed pay fees and generates a lot of
transactions, pushing more traditional traffic out due to artificial
The following set of proposals were discussed:
(1) Change the mining code to group transactions together with their
mempool dependencies and then calculate all fees as a group. A tx with
a fee of 1 BTC that depends on 5 txns with zero fees would result in
all 6 transactions being considered to have a fee of 1BTC and
therefore become prioritized for inclusion. This allows a transition
to "receiver pays" model for fees. There are many advantages. One is
that it actually makes sense ... it's always the receiver who wants
confirmations because it's the receiver that fears double spends.
Senders never do. What's more, whilst Bitcoin is designed to operate
on a zero-trust model in the real world trust often exists and it can
be used to optimize by passing groups of transactions around with
their dependencies, until that group passes a trust boundary and gets
broadcast with a send-to-self tx to add fees. Another advantage is it
simplifies usage for end users who primarily buy rather than sell,
because it avoids the need to guess at fees, one of the most
problematic parts of Bitcoins design now.
The disadvantages are that it can result in extra transactions that
exist only for adding fees, and it requires a more modern payment
protocol than the direct-IP protocol Satoshi designed.
It would help address the current situation by avoiding angry users
who want to buy things, but don't know what fee to set and so their
transactions get stuck.
(2) SatoshiDice should use the same fee algorithms as Bitcoin-Qt to
avoid paying excessive fees and queue-jumping. Guess that's on my
(3) Scalability improvements seem like a no brainer to everyone, it's
just a case of how complicated they are.
(4) Making the block size limit float is better than picking a new
arbitrary threshold.
On the forums Matt stated that block chain pruning was a no-go because
"it makes bitcoin more centralized". I think we've thrashed this one
out sufficiently well by now that there should be a united opinion on
it. There are technical ways to implement it such that there is no
change of trust requirements. All the other issues (finding archival
nodes, etc) can be again addressed with sufficient programming.
For the case of huge blocks slowing down end user syncing and wasting
their resources, SPV clients like MultiBit and Android Wallet already
exist and will get better with time. If Jeff implements the bloom
filtering p2p commands I'll make bitcoinj use them and that'll knock
out excessive bandwidth usage and parse overheads from end users who
are on these clients. At some point Bitcoin-Qt can have a dual mode,
but who knows when that'll get implemented.
Does that all sound reasonable?

@_date: 2012-06-15 13:52:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New P2P commands for diagnostics, 
Thinking about it some more and re-reading the Scalability wiki page,
I remembered that a nice bandwidth optimization to the protocol is to
distribute blocks as header+list of tx hashes. If a node has already
seen that tx before (eg, it's in the mempool) there is no need to send
it again.
With the new command to download the contents of the mempool on
startup, this means that blocks could potentially propagate across the
network faster as download time is taken out of the equation, and
indeed, with the signature cache the hard work of verifying is already
done. So this could also help reduce orphan blocks and spurious chain
Are you planning on implementing any of this Jeff? I think we have the
opportunity to kill a few birds with one or two stones.

@_date: 2012-06-15 15:23:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New P2P commands for diagnostics, 
If that's the case then the negotiation protocol needs to be specified
too. It seems heavy though. If a node is getting overloaded it could
just disconnect intensive peers or refuse new connections.

@_date: 2012-06-15 15:34:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Near-term scalability 
Just to be clear, I think this solution is a hack and don't support it
because it's yet another change of network rules. Some random people
will get whacked because of a heuristic "rule of thumb".
If it's implemented, SD could/would switch to fresh addresses and
nothing would have been achieved except making an already complex
system more complex.
I disagree with the notion that you need "less important than free".
If you care about the confirmation time of a transaction that was sent
to you and you need space in a limited resource, you can pay for it.
It's an auction like any other. Besides, the idea that transactions
are free today is just a psychological trick befitting governments but
not us - transactions are funded by aggressive hyperinflation. I would
never describe Bitcoin as a free system and I suggest nobody else does
If grouped fee calculations are implemented, we can keep the nice
property that the person who cares about double spending risk pays the
fees, and if you assume most transactions are hub-and-spoke from
buyers to merchants, rather than a pure p2p graph, in practice it'll
work out to seeming free most of the time even if seen globally it
doesn't make much difference.
I'm not sure why. If you want to audit everything from scratch, after
checking the code you could just blow away the included files and then
"-connect=archive.bitcoin.org" or something like that. After
rebuilding the chain from scratch, check the databases for consistency
with the included data.
It reduces the number of nodes with full copies of the block chain,
yes, but as long as there's at least one copy of the old data in an
accessible location new nodes can still bootstrap just fine.
I'm sure we can find organizations willing to host full chains for
people who want to rebuild their databases from scratch, given how
cheap disk space is.
Yes, but old nodes probably have a copy of the chain already, so it
wouldn't affect them. New blocks would still be fully distributed,
The only case where it'd cause issues is if you install a fresh copy
of a very old node. Not a common occurrence, and those nodes will have
to wait until they find an archival node announcing itself. Those
nodes could be made to announce more frequently than normal, if need

@_date: 2012-06-15 15:43:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New P2P commands for diagnostics, 
Matts point that a branch-per-transaction may duplicate data is well
made, that said, I suspect a format that tries to fix this would be
much more complicated.
How about see this project as a three part change?
First step - add the mempool command and make nodes sync up their
mempools on startup.
Second step - if protocol version >= X, the "block" message consists
of a header + num transactions + vector  instead of the full
transactions themselves.
On receiving such a block, we go look to see which transactions we're
missing from the mempool and request them with getdata. Each time we
receive a tx message we check to see if it was one we were missing
from a block. Once all transactions in the block message are in
memory, we go ahead and assemble the block, then verify as per normal.
This should speed up block propagation. Miners have an incentive to
upgrade because it should reduce wasted work.
Third step - new message, getmerkletx takes a vector and returns
a merkletx message: "merkle branch missing the root + transaction data
itself" for each requested transaction. The filtering commands are
added, so the block message now only lists transaction hashes that
match the filter which can then be requested with getmerkletx.

@_date: 2012-06-16 09:55:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Near-term scalability 
[resend, sorry gavin]
I think these ideas all make a ton of sense, some have been floating
around for a while in various forms but it's good to draw them
together coherently.
Is more incentive needed? If you have tons of tiny outputs you already
have incentives to merge them because otherwise your txns will become
large and the fees needed to overcome the DoS limits and gain priority
will rise.
The code to do it is a bit irritating as you really want to de-frag
wallets in the background when the user is not likely to need the
outputs quickly, and I suspect over time transaction volumes will
become diurnal so it'd be cheaper to do that at night time, but it's
all possible.
Peers could provide first-seen timestamps for transactions when
announced or when downloaded with Jeffs proposed command, but the
timestamps are not necessarily trustable. Not sure if that'd open up
new attacks.
SPV clients can do it by getdata-ing on the relevant inputs, but it's
very bandwidth intensive just to guesstimate fees.
That's reasonable. I don't believe this case is worth worrying about
right now. For the common cases of
a) Customer buys from merchant (runs full node)
b) Trusted person sends money to trusting person (does not need confirms)
it wouldn't matter after the changes to the block creation code. It's
only really an issue when a user running an SPV client wishes to
accept money from somebody they do not trust, and they want it to
confirm quick-ish (within an hour), but can tolerate delays up to
that. I think this is likely to be rare.
Much more common is that you want to accept the payment immediately,
which is an oft discussed but different problem.

@_date: 2012-06-16 10:25:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New P2P commands for diagnostics, 
The bottleneck for the android Bitcoin Wallet app is rapidly becoming
bandwidth and parse time.

@_date: 2012-06-16 10:27:09
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New P2P commands for diagnostics, 
I don't think the bloom filter settings have any impact on server-side
load ... a node still has to check every transaction against the
filter regardless of how that filter is configured, which means the
same amount of disk io and processing.
How can you reduce load on a peer by negotiating different filter settings?

@_date: 2012-06-16 10:30:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SatoshiDice and Near-term scalability 
Joseph is quite accommodating and doesn't want to hurt the network.
That said "asking him to stop" seems like the worst possible solution
possible. His site is quite reasonable.
I think if I fix bitcoinj to have smarter fee code he might stop
attaching a small fee to every TX, but I'm not sure.

@_date: 2012-06-17 13:01:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] After compressed pubkeys: hybrid pubkeys 
So what's the actual difference in format? Is there any at all, or
it's just the first number that's different?

@_date: 2012-06-18 20:41:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] LevelDB benchmarking 
I switched the transaction database to use the Google LevelDB library,
which is a refactored out part of BigTable.
Here are my results. All tests are done on this hard disk:
  which has an average 8.9msec seek time. It is a 6 core Ubuntu machine.
I used -loadblock on a chain with with 185127 blocks in it, so it has
lots of SatoshiDice traffic.
8.9 ms (average) seek time
real	96m6.836s
user	49m55.220s
sys	2m29.850s
Throughput usually 4-5MB/sec according to iotop, pauses of 8-10
seconds for ?Flushing wallet ...?. 611mb of blkindex.dat
Throughput, 12-17mb/sec
real	42m51.508s
user	11m52.700s
sys	2m36.590s
Disabling EC verification halves running time.
(I ran the wrong time command here, hence the different format)
3184.73user 181.02system 51:20.81elapsed 109%CPU (0avgtext+0avgdata
1104inputs+125851776outputs (293569major+37436202minor)pagefaults 0swaps
So, 50 minutes. Throughput often in range of 20-30mb/sec. 397MB of data files.
real	50m52.740s
user	53m38.870s
sys	3m4.990s
424mb of data files
No change.
real	50m53.054s
user	53m26.910s
sys	3m10.720s
No change. The reason is, signature checking is the bottleneck not IO.
real	12m58.998s
user	11m42.330s
sys	2m5.670s
12 minutes vs 42 minutes for BDB on the same benchmark.
Conclusion: LevelDB is a clear win, taking a sync in the absence of
network delays from 95 minutes to 50, at which point signature
checking becomes the bottleneck. It is nearly 4x as fast when
signature checks are not done (ie, when receiving a block containing
only mempool transactions you already verified).

@_date: 2012-06-19 11:05:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] LevelDB benchmarking 
Maybe ... looking again I think I may be wrong about being IO bound in
the last benchmark. The core running the main Bitcoin thread is still
pegged and the LevelDB background thread is only spending around 20%
of its time in iowait. An oprofile shows most of the time being spent
inside a std::map.
OK, to make progress on this work I need a few decisions (Gavin?)
1) Shall we do it?
2) LevelDB is obscure, new and has a very minimalist build system. It
supports "make" but not "make install", for example, and is unlikely
to be packaged. It's also not very large. I suggest we just check the
source into the main Bitcoin tree and link it statically rather than
complicate the build.
3) As the DB format would change and a slow migration period
necessary, any other tweaks to db format we could make at the same
time? Right now the key/values are the same as before, though using
satoshi serialization for everything is a bit odd.
We'd need UI for migration as well.

@_date: 2012-06-19 18:06:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] LevelDB benchmarking 
Primarily that block verification and therefore propagation is too
slow because it's very CPU and IO intensive. The CPU work can be
multi-threaded. The IO work, not as much. As Bitcoin grows we need to
scale the nodes. Eventually there may be multi-machine nodes, but for
now we can buy more time by making the existing nodes faster.
I don't see this as a replacement for moving users to SPV clients.
Obviously, otherwise I would not be writing one ;)
I have no experience with how robust LevelDB is. It has an API call to
try and repair the database and I know from experience that BigTable
is pretty solid. But that doesn't mean LevelDB is.
The code is a lot simpler for sure.
It was refactored out of BigTable and made standalone for usage in
Chrome. Therefore it's as portable as Chrome is. Mac/Windows/Linux
should all work. Solaris, I believe, may need 64 bit binaries to avoid
low FD limits.
Yes: First look at the code is here, but it's not ready for a pull req yet,
and I'll force push over it a few times to get it into shape. So don't
It has misc other changes I made whilst profiling, isn't well
commented enough, etc.

@_date: 2012-06-20 11:44:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] LevelDB benchmarking 
Thanks, I didn't realize BitcoinJS used LevelDB already.
Just one minor thing - LevelDB was definitely designed for servers, as
it comes from BigTable. It happens to be used in Chrome today, and
that was the motivation for open sourcing it, but that's not where the
design came from.
If anything it's going to get less and less optimal for desktops and
laptops over time because they're moving towards SSDs, where the
minimal-seeks design of LevelDB doesn't necessarily help. Servers are
moving too of course but I anticipate most Bitcoin nodes on servers to
be HDD based for the forseeable future.
Also, Satoshis code does use ordered access/iteration in at least one
place, where it looks up the "owner transactions" of a tx. I'm not
totally sure what that code is used for, but it's there. Whether it's
actually the best way to solve the problem is another question :-)

@_date: 2012-06-20 11:53:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] LevelDB benchmarking 
There's an interesting post here about block propagation times:
Looks like the regular network is reliably 0-60 seconds behind p2pool
in propagating new blocks.
So optimizing IO load (and after that, threading tx verification)
seems like an important win. Lukes preview functionality would also be

@_date: 2012-06-20 14:41:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] LevelDB benchmarking 
Great, in that case Stefan is right and I'll delete that code when I
next work on the patch.

@_date: 2012-06-24 14:45:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Enforcing inflation rules for SPV clients 
I've been having a discussion with d'aniel from the forums?about how
to handle the possibility of a majority-miner conspiracy to raise
inflation, if most economic actors use SPV clients.
Because of how blocks are formatted you cannot check the coinbase of a
transaction without knowing the fees in the block, and the fees can
only be calculated if you have all the input transactions for every
transaction in that block. Because the attack scenario is an attempted
takeover of the economy by miners, attempting to put hints into the
blocks won't work - we have to assume the hardest chain is in fact
wrong according to the rules signed up to by the Bitcoin user.
The most obvious goal for a cartel of miners is to change the
inflation formula, either for purely selfish reasons (they want more
money than can be obtained by fees) or due to coercion by
governments/central banks who still subscribe to the "inflation is
good" idea.
Whilst "good" nodes (still on the old ruleset) won't relay blocks that
violate the rules no matter how hard they are, in a situation where an
SPV client DOES hear about the bad best chain, it would switch to it
automatically. And who knows how the network might look in future -
perhaps most nodes would end up run by miners, or other entities that
upgrade to the new ruleset for other reasons.
d'aniel made a good proposal - having good nodes broadcast
announcements when they detect a rule that breaks the rules, along
with a proof that it did so. Checking the proof might be very
expensive, but it would only have to be done for split points,
limiting the potential for DoS. If a node announces that it has a
weaker chain and that the split point is a rule-breaker, the SPV
client would download the headers for the side chain to verify the
split, then download all the transactions in the split block along
with all their inputs, and the merkle branches linking the inputs to
the associated block headers. In this way the fee can be calculated,
the inflation formula applied and the coinbase value checked.
If the block is indeed found to be a rule-breaker, it'd be blacklisted
and chains from that point forward ignored.
Miners may decide to allow themselves to create money with
non-index-zero transactions to work around this. In that case the good
node can announce that a given tx in the rule-breaker block is
invalid. The SPV node would then challenge nodes announcing the longer
chain to provide the inputs for the bad tx all the way back to a
pre-split coinbase.
Doing these checks would be rather time consuming with huge blocks,
but it's a last resort only. In the absence of bugs, the mere presence
of the mechanism should ensure it never has to be used.

@_date: 2012-06-25 10:42:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Enforcing inflation rules for SPV clients 
It was a private conversation for some reason.
Ah OK. I wasn't paying much attention to those threads.

@_date: 2012-06-25 10:44:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Enforcing inflation rules for SPV clients 
Yeah. I am still unsure that this really holds. Bitcoin moves fast,
but even so, unless there are a few more SatoshiDice-like events and
the way people use transactions changes dramatically we're a long way
from gigabyte sized blocks.  And once we get there, technology will
probably have improved to the point where it doesn't seem like a big
deal anymore.
Of course we have debated this many times already. Maybe again at the
next meetup :-)

@_date: 2012-06-25 18:32:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] LevelDB benchmarking 
I've added some more commits:
It's still not ready for a pull req but is a lot closer:
1) Auto-migration is there but not well tested enough (I only tested
with empty wallets).
2) Migration progress UI is there so you have something to watch for
the few minutes it takes. Script execution is disabled during
3) LevelDB source is checked in to the main tree, bitcoin-qt.pro
updated to use it
4) LevelDB is conditionally compiled so if there's some unexpected
issue or regression on some platform it can be switched back to BDB
Still to go:
1) More testing, eg, with actual wallets :-)
2) Update the non-Qt makefiles
3) On Windows it's currently de-activated due to some missing files
from leveldb + I didn't test it
If you want to help out, some testing and makefile work would be
useful. I may not get a chance to work on this again until next week.

@_date: 2012-03-09 15:50:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [ANNOUNCE] BitCoinJ 0.4 
I'm pleased to announce the release of BitCoinJ 0.4, the leading Java
implementation of the Bitcoin protocol. BitCoinJ implements simplified
payment verification, a lightweight mode in which no central server or
authority is needed but the resource requirements are still low enough to
be usable on smartphones.
This version of the library is used in the new releases of Android Wallet
and MultiBit.
New in this release    - Ability to use "getheaders" to quickly catch up new users to the head
   of the chain. This is a big performance win.
   - ECKeys no longer require the private part, allowing for "watching
   wallets" that cannot spend, but still gather and track the transactions
   associated with the public keys.
   - A new API that implements transaction confidences. Get a quick summary
   or detailed information about how much confidence you can have that a given
   transaction won't be reversed.
   - A new DerbyBlockStore that stores block headers and related data in
   the Apache Derby relational database.
   - Protocol buffers are now a supported serialization format for the
   wallet. This means BitCoinJ based protobuf wallets can be read and
   manipulated by any language/platform with a protobufs implementation, which
   is most of them. There are extension points in the format to allow third
   parties to add new features.
   - Various new event listeners that help you learn when the state of the
   wallet or transactions change.
   - Support for post February 20th version handshakes (most library users
   already got this fix via backports)
   - All event listeners are now allowed to remove themselves during their
   own execution.
   - New APIs that allow you to create offline transactions and then
   broadcast them at a later point. Pending relevant transactions are recorded
   and announced to all newly connected nodes, ensuring a transaction won't
   "get lost" if there was flaky network connectivity at the time of creation.
   Pending transactions are supported much better in this release than in
   previous releases.
   - Wallet now can now take an invalid transaction and complete it by
   adding sufficient inputs and a change output. This enables the creation of
   multi-sends, as well as making experimentation with contracts easier.
   - Support for BIP 14: apps can now set their own "user agent" which will
   be put in the subVer field along with the library version.
   - Updated DNS seeds list.
   - A new WalletTool program for command line usage, and a ToyWallet app
   showing how to set everything up.
   - Support parsing and checking of alert messages.
   - New articles explaining how to use the library:
      - Working with
      - Working with the
   - The usual assortment of bugfixes, new APIs, robustness and test suite
   improvements.
Thanks to everyone who contributed to this release, in particular Andreas
Schildbach, Miron Cuperman, Roman Maneleil, Chris Rico and Vasile Rotaru.
In the next release cycle, I'll be focusing on the following areas:
   1. Real support for transaction fee calculations (most users apply a
   custom patch for this today)
   2. A better block chain API
   3. Have the library manage save points for the wallet itself
   4. Further chain download time optimizations
   5. More support for moving apps onto "work done" as a confidence
   measurement
Of course contributors are welcome to work on whatever they want.

@_date: 2012-03-13 19:06:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Adding a pong message 
adds a "pong" message that
echoes back a 64 bit nonce contained in the ping, if the protocol
version is new enough.
The goal of this is to make it easier for clients, especially mobile
clients, to quickly check if a connection is stale, and also to see if
a remote node is overloaded so we can avoid talking to it. A common
case where this happens is if the remote node is itself downloading
the block chain or doing something equally intensive.
Any objections?

@_date: 2012-03-13 23:29:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Adding a pong message 
TCP keep-alives aren't reliably implemented.
I've got reports that sometimes we struggle to keep connection to the
network on mobile, eg, because we roam into an area with poor
connectivity but not poor enough for the network stack to drop access
entirely. Being able to quickly check if the connection is really
there with some kind of bounded, app layer deadline is probably useful
and besides, it's cheap.

@_date: 2012-05-02 15:22:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] new bitcoin.org clients page 
We're debating the descriptions on the thread. I provided rewritten
descriptions that try and keep with the "theme per client" goal, whilst
being less technical.
I think it's unclear how best to run this page. It's clear we need one
though. If everyone can just submit whatever they like then we'll end up
with 4 or 5 "pick me! pick me!" type descriptions, which avoids a lot of
arguing but doesn't really help our users make a decision. If we have a
Benign Dictator model we might end up with descriptions that are wrong or
don't highlight the strengths / weaknesses of each client properly.
So although it's messy I think the right path is probably the middle one -
have some descriptions that try to be neutral, then improve them based on
feedback from users and developers. They need to be flexible and evolve
over time as the clients evolve too. At some point every client will
support deterministic wallets so "easy backups" won't be worth mentioning
any more, but there'll be new distinguishing features. And we all need to
try and be honest about our own work.
Here is the current content. Like I said, the descriptions are *not* set in
stone at all.
Bitcoin-Qt The original software written by Satoshi Nakamoto, the project's founder.
If you aren't sure which program to pick, this is a good bet. This
application is a peer-to-peer client that builds the backbone of the
Bitcoin network. It is suited for enthusiasts, merchants, miners,
developers and people who want to help support the project. People who run
Bitcoin-Qt are first class network citizens and have the highest levels of
security, privacy and stability. However, it can be very resource intensive
and you should be willing to leave it running in the background so other
computers can connect to yours. If your computer is low powered or you
aren't willing to tolerate a 24-hour+ initial start time, you should
consider other clients. Cutting edge features tend to be implemented in
other clients first.
Website: bitcoin.org
MultiBit MultiBit's primary focus is being fast and easy to use, even for people
with no technical knowledge. It has a YouTube channel to help you learn the
software, and includes helpful features such as an exchange rate ticker.
MultiBit supports many languages such as German, Spanish and Greek.
MultiBit synchronizes with the network much faster than Bitcoin-Qt and
should be ready for you to use within a few minutes. This is a good choice
for non technical users who want an easy to use experience, especially if
you use a Mac.
Website: multibit.org
Armory Armory focuses on advanced wallet management features, such as the ability
to construct transactions whilst disconnected from the internet. It
operates in conjunction with a Bitcoin-Qt install. It requires a large
amount of RAM to operate and if you use Windows, it requires a 64 bit
version. It is a good choice for tech-savvy enthusiasts or merchants who
want to try out cutting edge ideas in the Bitcoin world. Armory was partly
funded by a community donation drive which raised over $4000.
Website: bitcoinarmory.com
Electrum Electrum's focus is speed, with low resource usage and making wallet
backups easy. It operates in conjunction with remote servers that handle
the most complicated parts of the Bitcoin system, which is why it's fast.
However, by running this client you don't contribute your computer's
resources to the core network, and the remote servers that help give it
good performance have the ability to see all your transactions and tie them
together. Whilst you need provide no personal information to use Electrum
(as is true for all Bitcoin clients), this means the privacy level is lower
than for other clients. Merchants are recommended to use other p2p clients.
Electrum is not quite user friendly yet - currently it is more suited for
tech-saavy individuals.
Website: ecdsa.org/electrum

@_date: 2012-05-02 15:32:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] new bitcoin.org clients page 
OK, I haven't tried a full block chain sync for a while. If it's only a
couple of hours that's great. Let's change that.

@_date: 2012-05-16 18:46:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 33 - Stratized Nodes 
Thanks for getting this started.
With regards to the specific proposal, I don't believe it's the best option
and still plan to eventually implement the original design outlined more
than a year ago in this thread:
  Namely that you use a new protocol command to set a Bloom filter on a
connection. Only transactions matching that filter will appear in relayed
inventory. Blocks that are requested will arrive as a header plus
transaction/merkle branch pairs. Clients are expected to maintain and track
the block chain as per usual, but instead of downloading the whole chain
and then dropping the irrelevant transactions, that filtering is done
server side. By strengthening or weakening the Bloom filters you can choose
your preferred point on the privacy/bandwidth-usage spectrum. It is a
fairly simple change to the Satoshi and BitcoinJ codebases but still allows
clients to gain confidence in their balance by examining the chain, and
this is true even in the presence of a hijacked internet connection (you
can't trust pending transactions that way, but you can still trust
confirmed transactions).
The filters would be applied to each data block in each script rather than
having a specific knowledge of addresses. In this way you can select for
things like multisig outputs or outputs which don't use addresses / pubkeys
to authenticate.
I could write a BIP for this alternative protocol if somebody else wants to
implement it. I was going to wait until I had time to do both BIP and
implementation, but I think some simple optimizations to BitcoinJ can keep
its performance good enough for the short term.

@_date: 2012-05-30 17:58:45
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [ANNOUNCE] BitCoinJ 0.5 released 
============================== START ==============================
I'm pleased to announce the release of BitCoinJ 0.5, the library that
powers Android Wallet, SatoshiDice, Bitcoin Status, the server side part of
BCCAPI and much more.
This release focusses on bug fixes, making the build more standard and
completing the transition to the protobuf wallet format. It also includes
the first preview of the native API, allowing you to access bitcoinj from
C++/Objective-C++ using a straightforward, intuitive mapping from the Java
API. Much easier than JNI and no JVM is required, just the libgcj support
library. Examples of a native Cocoa app for OS X and a command line hello
world app are included. Because it's not fully finished/documented yet,
this work is available on a branch rather than in the main release.
We now have a Google+ page where we'll post announcements and developer
tips/ideas: New in this release:
   - Address.getParameters() and Address.getParametersFromAddress() let you
   figure out for what network the address is for (test, production, etc).
   BitcoinURI no longer requires a NetworkParameters for the same reason.
   - Updated to latest bouncy castle version, remove the need for the
   Android artifact by using the SpongyCastle build
   - Receives pending transactions much faster than before
   - Update to the testnet2 rules
   - Wallets now store the current chain head
   - wallet-tool can now create and broadcast transactions from the command
   line
   - Wallets will now be auto-migrated to protobuf format if they were
   previously serialized Java objects
   - Now uses the standard Maven directory layout
   - Many important bugfixes
I'd like to thank Jim Burton, Miron Cuperman, Andreas Schildbach and Gary
Young for their contributions to this release.
You can get it from the download page on

@_date: 2012-11-08 10:19:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] IRC meeting agenda, 18:00 UTC Thursday 
I won't be able to make it this time.  My feeling is IRC is a good place to
bounce ideas around when time and people happen to be available, but having
meetings there will inevitably lead to decision making that's better done
in a slower manner via email.
   BIP process: are we happy with how it is working? What can we do to improve
Needing some kind of process to allocate a number is over the top. I
skipped this for the bloom filtering BIP. We should take off the part of
the {{BIP}} template that says "don't just pick a number and add a bip" -
that's exactly what people should do. I'm not sure there's any need for an
editing role either.
    Is it time to feature-freeze 0.8
I'd like more time to get the bloom filtering work in. It'll be easier to
promote the 0.8 release if we can sell it as "important
scalability/performance improvement for the network, upgrade to help
Bitcoin keep growing", as whilst there's no real auto update or organized
people who religiously update promotion is very important. I think
ultraprune + bloom filtering is the two major scalability improvements we
have right now.

@_date: 2012-11-16 18:44:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Electrum security model concerns 
BTW have you checked the code? I took a quick look and didn't see things I
was expecting to see. In particular I couldn't find any code that manages
wallet state in the presence of re-orgs. It appears to check that
transactions appeared in the block chain, but if there's a chain switch
it's not clear to me the wallet will be in the right state.
I saw a message from Thomas on his thread saying something like "can't
spend coins bug happens when there's a re-org and the server gives you the
wrong histories, to fix it reset your wallet and switch to a new server"
.... which to me rather implies there's no re-org handling at all.
If Electrum does end up doing all SPV work correctly, how is it different
to MultiBit? Just the deterministic wallet seeding?

@_date: 2012-11-26 16:05:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Has anyone compiled under MacOS 10.8? 
It appears that something about Boost doesn't play nicely with the default
build instructions (possibly the switch to clang++?).
I will dig in eventually but for now, if anyone has a recipe that fixes
things, let me know.

@_date: 2012-11-27 00:02:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Obviously this LGTM :)
Minor caveat, IMHO we should support all CAs used by the popular
browsers. This ensures no merchant ever finds that their SSL cert they
already own is OK for the web but not for Bitcoin. I don't see a need
to be stricter here, given all it achieves is signing some data in a
way linked with a domain name.
X.509 is pretty baroque indeed, for our use cases it'd not be hard to
do better. In particular, the inability to delegate properly rather
defeats the benefits of chained certificates. For the payment
processor case what you really want to do is take your keys, then
issue a new cert that is specific to signing Bitcoin transactions and
give that to the payment processor secure in the knowledge that they
cannot MITM your secure connections. Unfortunately X.509 wasn't
designed for the web and thus certificates you buy are marked such
that they are not allowed to sign for other certs (due to lack of real
namespace support).
This leads to the idea of redefining the cert chain part of the
protocol like this:
  repeated bytes x509_chain = 1;
  message Certificate {
    enum Type {
      X509 = 1;
    }
    required Type type = 1;
    required bytes data = 2;
  }
  repeated Certificate cert_chain = 1;
Then if later we want to introduce our own minimal certificate formats
which include features we want, we can add new enum types to do so.
Note that if an old client encounters an invoice with a cert type it
doesn't recognize, it will abort parsing of the message entirely. So
the request to download the invoice should probably include a protocol
version number of some kind so the server knows when it's safe to use
new invoice features.

@_date: 2012-11-27 00:16:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
They could be included as well of course, but from a seller
perspective the most important thing is consistency. You have to be
able to predict what CAs the user has, otherwise your invoice would
appear in the UI as unverified and is subject to manipulation by
viruses, etc.
So using the OS cert store would effectively restrict merchants to the
intersection of what ships in all the operating systems their users
use, which could be unnecessarily restrictive. As far as I know, every
browser has its own cert store for that reason.

@_date: 2012-11-27 00:27:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
The point of using signed invoices as virus protection isn't to change
what the user sees on the infected host. The point is the invoice can
be relayed to a second device that isn't also compromised which then
independently renders a payment confirmation screen (like your mobile
phone), and it has an identifier in it that's useful to people, like
bitmit.net instead of an address.
If it was just showing you a Bitcoin address, that doesn't mean
anything to you so a virus on your PC could wait until you want to
make a large payment somewhere and swap out the address in use. You'd
never know it was the wrong address and you'd happily confirm on your
second device.
For this to work, the seller has to be able to predict what certs you
have in all your devices. If it's up to the OS vendors then it's hard
to know and in practice all that'll happen is somebody will compile a
list of CAs that are "known good" (ie, present in all deployed mobile
and desktop OS') and that'll be the minimal cert list. No different to
if it was hard-coded in the spec.
Nothing says your wallet software can't provide cert management UI
like browsers do.
In practice I have a feeling that cert management UI is one of the
least used parts of a browser. I've used browsers for years and the
only time I've ever had to go into those screens was to manage
installation/removal of self signed certs used by various
organizations. I never manually revoked a root authority. When it was
necessary due to breaches (Comodo/DigiNotar) the browser makers
revoked them for me.

@_date: 2012-11-27 01:26:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Yeah, alternatives to X.509 chains don't interest me right now except
in the sense that they should be cleanly implementable with future
So if you care about DANE or DNSSEC or custom PKI infrastructures or
whatever, rather than proposing them as replacements here (DOA), just
figure out how you would extend the protocol in Gavins mail in a
future extension. If you can't see a clean way to do it then let's
discuss that. If you can think of a way to do it then let's table it.
Better replacements can come in later BIPs.

@_date: 2012-11-27 09:44:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Luke-Jr - common subset of what operating systems ship is fine for me
as long as people do due diligence around mobile OS' here. It seems
easier to me to just grab a list from a popular browser, on the
grounds that SSL is mostly used by them so nobody is going to buy an
SSL cert rejected by IE/Firefox/Chrome/etc. But intersecting OS lists
is effectively the same.
For my own clients I'd just ship my own copy of the canonical CA certs
regardless, because integrating with each operating systems
proprietary crypto APIs is a lot of work vs just loading a pem file
into OpenSSL. If there are a lot of people who want to use the OS cert
management UIs then I guess that can be a point wallet clients compete
But it would result in implementations that do not meet the requirements.
Yes, X.509 has problems. It's in the proposal because we can get the
effect we want (verifiable domain names in the UI) in about 50 lines
of code, today, with the id-verified keys people actually have already
As Gavin says, we can add optional fields later to extend the protocol
in a backwards compatible way.

@_date: 2012-11-27 11:23:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
I think this is a problem with confusing terminology rather then the
spec itself.
The original formulation had a receipt being something generated
purely by the buyer. The signed Invoice message  + the Bitcoin
transactions paying to the outputs + the merkle branches showing
acceptance by the network *is* the receipt.
The SignedReceipt message is useful in the sense that it shows
confirmation by the merchant, but if you don't get one, you can still
prove you paid the invoice. So from this perspective perhaps
SignedReceipt should be renamed to Acceptance or something like that,
and then the spec should call out that a signed invoice plus accepted
Bitcoin transactions is mathematically a proof of purchase.

@_date: 2012-11-27 13:03:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
No, the point of using X509 certs is to get a verified identity (a
domain name) on the receipt, this is needed for multi-factor
authentication. You can't do that without some kind of third party
asserting to an identity.

@_date: 2012-11-27 18:14:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
That's pretty much what we have today - in future other schemes can be
proposed as extensions. Protocol buffers are easily extended, they
ignore unknown fields. Then you'd wait and see what the invoice
request looked like and produce an invoice with the right security
It's not obvious to me, incidentally. The web of trust has been
dead-on-arrival since it was first proposed, and for good reasons.
SSL/X.509, for better or worse, has significant usage.
Your case of a small business is a perfect example of people who won't
be using GPG. If they don't want to buy an SSL cert, they can just as
well put a reference number in the memo field or a "Hey Bob, here is
the bill we discussed". The payer does not get the multi-factor auth
protection so if their computer has a virus, they may be hosed. But
that's good incentive for sellers to get verified. Some CA authorities
do it for free these days.

@_date: 2012-11-27 19:16:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
OK, I see. I guess that could be a reasonable fallback for the case
where you have a secure channel.
Yes, exactly. It's about paying who you think you're paying (when you
confirm on a second uncompromised device).

@_date: 2012-11-28 11:43:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
The current spec is ambiguous in the case of what to do if the invoice
contains one output of a fixed amount and one or more outputs of an
unspecified amount. Should the user be prompted once per output? That
seems suboptimal. Prompted once for a value that's then randomly
distributed between all open-value outputs? It seems this ability of
the protocol is somewhat more complex than it appears. The ability to
have open outputs is nice for tips though.
You could consider moving pki_type and pki_data into a separate
message and making both fields required, then making the pki message
optional. Otherwise you can have pki_type set but no data or
vice-versa. It doesn't make much difference in the end, just slightly
improves the automatic sanity checks produced by the proto compiler.
w.r.t SIGHASH_ANYONECANPAY. I think it's best not to use this
routinely as it relaxes the signature checks in ways that may open
non-obvious holes when combined with other features. I thought we
pretty much had consensus on recursively calculating fees including
dependents in the memory pool?
Peter is correct that there are a few degrees of freedom in protobuf
serialization, though far fewer than with JSON. I'd like to think
upstream would be open to resolving these ambiguities.
Re-serialization of an Invoice message in the Payment message is a
potential source of mistakes. There's no need to ever concatenate
these messages and alternative implementations that don't order
serialized fields by tag number are missing an important optimization,
so they could be fixed. The main issue is treatment of unknown fields.
If/when the Invoice message is extended with other fields that are
round-tripped through an old client, the data may get lost. JSON
doesn't help resolve that either, of course. There are a few
1) Change the type of the Invoice field in Payment to be "bytes" and
set it to be the hash of the originally received binary Invoice
message. Downside, requires merchants to track all outstanding
2) Ask protobufs upstream to modify the spec/implementations so
ordering of unknown fields is specified. The Python implementation
could be extended to support them so Python implementors don't end up
with accidental message downgrades.
3) Language of the spec could be changed to explicitly state that the
received Invoice may not be binary-identical to the one that was sent,
in the case of a client that incorrectly downgrades the message. Thus
you'd be expected to check what the Invoice was using merchant_data
which is opaque and could just be, eg, a database key on your own end.
4) Instead of submitting the entire Invoice back to the merchant, just
the merchant_data could be in the Payment message.
Of the four options I prefer the last. What is the use case for
resubmitting the entire invoice anyway? Even if protobufs are improved
so handling of round-tripping new messages through old [Python]
clients is more rigorous, some implementors will probably convert the
protobuf objects into some internal forms for whatever reason (or
serialize them to a database, etc) and they're very likely to mess up
the handling of unknown fields when they do it.

@_date: 2012-11-28 12:26:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [ANNOUNCE] picocoin and libccoin -- 
Cool, will check it out soon.
FYI, Windows has quite good sandboxing support. You could implement
the same thing later with Win32 if you want.

@_date: 2012-11-29 18:31:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
There are several reasons for this:
1) P2P network sockets are a limited resource and bringing up
connections to the network, whilst somewhat fast today, is not
guaranteed to be fast in future. Passing transactions to the merchant
for broadcast reduces the load on the P2P nodes because lots of thin
clients aren't any longer connecting and disconnecting when sending.
They only need to talk to the network when the user has received
2) Some users may not have network connectivity at all. For example,
this happens quite often whilst traveling at Bitcoin conferences ;)
The solution, which Andreas and I prototyped in Berlin together, is
for the buyer to communicate only with the seller which can be done
over Bluetooth or WiFi Direct or some other mobile radio protocol.
Again, send only, but for the common case where you load up your
wallet before setting out and then buy things, it works OK.
4) A longer term reason - in time, people may choose to not broadcast
transactions at all in some cases. I think how network speed will be
funded post-inflation is still an open question. Assuming the simplest
arrangement where users pay fees, getting transactions into the chain
has a cost. In cases where you trust the sender to not double spend on
you, you may keep a fee-less transaction around "in your pocket". Then
when it's your turn to pay, you use some unconfirmed transactions to
do so. People pass around longer and longer chains of un-broadcast
transactions until a payment crosses a trust boundary, at which point
the receiver adds on their own transaction that spends back to himself
but with a fee, and broadcasts them all together as a unit. In this
way only people who genuinely need to fear double spends pay for

@_date: 2012-11-29 21:34:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Has anyone compiled under MacOS 10.8? 
============================== START ==============================
I found that the problem is the version of the Qt SDK I used didn't
like the new MacOS version. Re-installing Qt fixed it.

@_date: 2012-10-02 18:38:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment protocol thoughts 
I've been thinking about the requirements for a payment protocol
lately. It seems we have consensus that we need one of these. Pieter
has a gist on the topic here: IMHO we'll want to move away from "send X BTC to address Y" and more
towards "upload to me transactions that send X BTC to outputs
A,B....F,G". In this context by output I mean the obvious
interpretation of script+value.
The reasons are privacy and security. Privacy: you don't want people
to find out if you have an unexpectedly large balance (from the block
chain). Example worst case scenarios
- in a hypothetical Bitcoin-using country, as most people receive
income exactly once a month from their employer, you could potentially
find out other peoples salaries. Drama ensues.
- business partners could find out their counterparty has an
unexpectedly good financial position, messing up negotiations
- some of the outputs could be in a hot wallet, others in cold
wallets, helping you maintain correct balances between them in real
- the outputs can be multi-sig scripts
Wallets would then craft a series of transactions to try and somewhat
balance the size of inputs vs outputs. Because they are separate
transactions and all the keys are fresh, there's no way to link them
together into a single payment, especially not if they're broadcast in
random order with some jitter.
The upside of this is better privacy. The downside is obviously more
transactions and therefore more overhead. In theory the sum of tx
outputs would end up converging to a reasonable "coin size" for the
recipients, eg, businesses might be happy to receive a lot of money in
a single output, individuals less, children or very poor people maybe
much less.
Let's call payment requests invoices. Here is a brainstorm on other
features that may be desirable. I'm not suggesting they're all in v1,
just that we think about them a bit to ensure we don't paint ourselves
into a corner.
- Optional list of {signature, certificate} pairs. SSL certs can be
embedded into the payment request file itself so they can be checked
instantly for wallets that want to show a verified identity, but you
can also provide other certificates issued outside the regular SSL CA
system. For example maybe MtGox issues you a "trusted vendor"
certificate. Maybe the better business bureau issues you a cert, etc.
- Optional expiry time (from sipas gist) so outputs that were never
sent to can be recycled
- Upload target (URI), where to send the created transactions
- Optional message and branding image/icon that a wallet can display
to make the transaction history a bit prettier
- Opaque token that the wallet is supposed to copy into the payment.
The merchant can use to link invoice with payment. It's technically
redundant, the output set would identify the invoice too, as could a
token in the upload target URL, but it may be simpler for some
merchant implementations
- Ability to specify payment amount[s] in terms of other currencies.
If the amount is specified statically it can just be recorded in the
wallet for informational purposes. If there's a URL provided also, it
is an endpoint where quotes can be obtained. This allows merchants to
make long-lived invoices which are protected against FX volatility.
Downside: complicates wallets. Upsides: invoices can be kept around
for longer.
- Web/human-usable URL for the order so users can, eg, send messages
to the merchant specific to an order, post a review of the merchant,
- Support for setting up 2-of-3 dispute mediation. Invoices should be
able to name a list of acceptable mediators and the wallet software
can intersect this with a list of mediators acceptable to the user, to
find one that works best. The whole mechanism by which merchants and
users agree on mediators isn't designed yet but we can at least think
about it now. It may be there's a simple design everyone agrees on
- Support for requesting recurring payments. Eg, I should be able to
provide N sets of M outputs, one set for each payment with a payment
schedule. Wallets can then ensure they run at the appropriate times to
keep up the subscription.
- Suggested tip/service charge. Wallet would give a simple UI to
adjust this up/down by X percentage points
- Request to sign inputs with SIGHASH_ANYONECANPAY, allowing the
payment to be a pledge for an assurance contract
- Ability to specify minimum confirmation level of coins that will be
spent. Some merchants may be OK with you immediately re-spending
unconfirmed coins. Other merchants will care more and might want you
to take on the burden of getting your transactions into the chain.
On the payment upload side:
- An optional signature under a stable user key that lets users
optionally link their payments across merchants. In this way a user
can build cross-market reputation which may help them in future, by
relaxing confirmation requirements or reducing the chance of being
asked to enter dispute mediation. Needs more thought.
- Optionally, an invoice for a refund if the merchant chooses to
refund the money in the absence of dispute mediation.
- A list of Bitcoin transactions that make payments to the outputs
requested in the invoice
- The opaque token provided in the invoice
Re: format. I would (surprise) strongly suggest protocol buffers over
JSON. I cannot think of any justification for using JSON (for
anything) but especially not for data structures that mostly contain
binary data like hashes or keys. Protobufs are easier to work with in
code, have a more efficient encoding, can be printed/parsed from ASCII
if you need to (eg for debugging purposes) and have fewer sharp edges
than JSON does.

@_date: 2012-10-03 00:44:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment protocol thoughts 
I think it's worth pondering the different things we may want in
future, even if that future is quite far out, just to ensure we have a
robust design that won't box us in later. Brainstorming feature ideas
now doesn't commit anyone to implementing them, but it may help
improve the final v1 design.
A simple way to solve this problem is just use the SSL identity of the
server that is taking part in the protocol, but it's not much harder
to embed a signature + cert chain into the invoice itself. And once
you're doing that, allowing several different sigs/cert chains is
pretty easy. It means you keep the design open to cases where SSL may
not be appropriate. Eg, you could create invoices signed by your
web-of-trust identity, or some non-SSL Bitcoin specific verification
None of those things have to actually be implemented, but by
considering them now we can make the protocol more future prooof.
A signed invoice + the blockchain transactions does this, BUT with a
major caveat: if you have not set up dispute mediation, there is
nobody to prove faultlessness to.
So I'm not sure this would be very useful. Supporting real dispute
mediation seems more practical, but also more work.
This would be nice, I think invoices could be wrapped by another
protocol that handles it. I'm not sure it needs to be a part of the
core payment protocol. There are lots of different ways to implement
this and I'm not sure there's agreement on what it should look like -
somebody needs to build a "proprietary" implementation first.

@_date: 2012-10-08 13:52:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Electrum security model concerns 
That page was old, it stated that pending transactions aren't provided
to the app which hasn't been true for a long time.
I've rewritten and extended it. You may still not like what it says ;)
but it should at least be more thorough now. It also links to the ETH
Re: Electrum. In fairness the electrum page is designed for end users
and the bitcoinj page is designed for app developers. As far as I
know, there are no bitcoinj based clients that try to explain
transaction confidence to end users.
I don't think it's worth worrying about this too much right now. In
future the software end users and merchants use will diverge
significantly. At that time it'll be easier to tailor the
documentation to each user demographic. And I think Electrum type
services will go away once we do more optimizations like bloom
filtering and better peer selection logic, as the speed of SPV clients
will be comparable to Electrum/BCCAPI type clients but without the
need for a specific server operator.

@_date: 2012-10-10 13:19:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Electrum security model concerns 
Well, I suggest taking it up with Thomas directly. A thread here won't do much.
I'm hoping that MultiBit Merchant will provide something similar based
on bcj, ie, you don't have to actually be a Java developer to use it,
it can just talk to your app via POSTs and GETs.
WRT deterministic wallets, yes, right now that's indeed a competitive
advantage of Electrum. So much code to write, so little time.
Yes indeed. This also gives [hacked] server operators a way to steal
money from users without private keys, they can get clients to create
some very high fee transactions and then provide them directly to a
miner who promises to cut them in (or they can mine themselves, of
I thought it used SSL. Maybe I'm thinking of BCCAPI which is a similar approach.
I think communicating transaction confidence to users is something of
an open UI design problem right now. I agree that hiding it entirely
seems suboptimal, but in reality explaining what the risks are for a
given number confirmations is difficult. Given the lack of actually
reported double-spends against unconfirmed transactions, I can
understand this choice, even if I wouldn't recommend it.
Well, I pushed for English-text explanations of clients on bitcoin.org
rather than a feature matrix, for this kind of reason :) Unfortunately
the current texts are too small to really give a detailed explanation
of the security models involved. It may be worth adding one-liners
that link to a page explaining different security models (full, SPV,
One thing I'm really hoping we can find and get agreement on is
somebody clueful and trustworthy to work on the bitcoin.org website.
Bitcoin, the project, needs a stronger voice than it currently has,
partly to speak about such issues. For instance, an FAQ that isn't on
the wiki would be good. And a simple "Welcome to Bitcoin" flow on the
bitcoin.org website that guides people to appropriate clients, teaches
them the security basics, etc, would be excellent.

@_date: 2012-10-10 17:55:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Electrum security model concerns 
Forum private message may work better.
Yeah, but that's only an issue if it ends up being an intractable
disagreement between the people who are reviewing changes to the core
site. The clients page itself was contentious but we still arrived at
something reasonably professional looking and moved on.
I don't think it should be removed. At most the description should be
updated to point to a discussion of the tradeoffs of that class of
apps (same for BitcoinSpinner).

@_date: 2012-10-15 00:49:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Hosting of compiled bitcoin client 
The laws in question are OFAC sanctions:
The specific acts that enable this are varied. In theory they apply to
any US citizen or resident. The issue is not cryptography, it's "trade
with sanctioned countries", period, where making files available to
download is considered trade.
For Bitcoin to be available in these places, the sites and download
mirrors would need to be hosted outside the USA by non-citizens. EU
sanctions are primarily financial at this time, as far as I know there
are no attempts to prevent people from serving data to Iran.
Example of places where there are no sanctions in effect: Switzerland.
Unfortunately datacenter space in Zurich is quite expensive (as is
everything here).
I would not ever describe OFAC as "effective law". The SDN list has
repeatedly been found unconstitutional, representing as it does a
complete evasion of the judicial system. If you end up on the
sanctions list no evidence is required, no process is followed and no
appeals are possible. The list itself assumes names are globally

@_date: 2012-10-24 17:56:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
I've written a draft BIP describing the bloom filtering protocol
extension developed by myself and Matt.
(yes I know there's some kind of process around getting allocated a
number - it seems overkill for this).
Please read it and let me know if there are any missing details or
things which sound wrong.
Design-wise, it occurred to me as I wrote the BIP that the method of
delaying reception of invs is a bit ad-hoc. It may be better to have a
bloom filter be sent in the version message itself. On the other hand,
having a flag to delay invs means that the filter can be calculated in
parallel to bringing up the network connections. Whilst actually
making a Bloom filter is fast, with deterministic wallets you may need
to do a lot of calculations to find the keys to scan for.

@_date: 2012-10-24 18:35:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
Copy/paste error in the does :(
about the output script in its entirety?
It's an informal way to say data elements. If you insert a key then it
matches both single and multi sig outputs regardless of location.
We think probably not.

@_date: 2012-10-24 21:10:49
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
Bitcoin already keeps track of which nodes have seen what to avoid
redundant inv announcements.
I think if you are approaching most transactions in a block matching the
filter then you would just request full blocks and do all the filtering
client side

@_date: 2012-10-24 22:58:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
It would be slightly worse than shipping a full block but not seriously so.
If you just want to saturate bandwidth or disk IOPS you could probably
just request random blocks over and over again.

@_date: 2012-10-26 16:01:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
Well, yes, that is basically the implementation complexity argument :)
Engineering time isn't free.
I don't feel I understand the effort required to do some kind of
partial tree encoding. Having a kind of custom compression whereby
branches are represented as varint indexes into a dictionary, I can
feel how much work that involves and maybe I can make time over the
next few weeks to implement it. Has anyone got example code for
representing partial Merkle trees?
If you just want to waste bandwidth of nodes you can connect to nodes
and repeatedly download blocks, or fill the network with fake nodes
that spam random generated transactions to whoever connects. I don't
see how to avoid that  so it seems odd to worry about a much more
complicated attack.

@_date: 2012-10-26 16:21:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
And this gets you what?
Users who have active wallets will have their bandwidth wasted for as
long as you keep up the attack. Once you stop active wallets won't be
rescanning that part of the chain and new users won't be scanning it
either, as they skip blocks before their earliest key time using
getheaders. So basically you can waste the bandwidth of active users
for a while, by spamming transactions. This is not a new attack.
Anyway, it's trivial to DoS the entire Bitcoin network today. It
hasn't ever happened. Maybe one day it will, but the only rationale
people can come up with for such an attack beyond random griefing is
governments, and complexity attacks are really not their style. Much
easier to just pass a law.
I'm not saying DoS should be ignored, but I do feel there are limits
to how far down that rabbithole it's worth going.

@_date: 2012-09-13 10:42:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Segmented Block Relaying BIP draft. 
For what it's worth I disagree with Gregory on nearly all these
points, so don't take it as some kind of consensus from the Bitcoin
community ;)
Matts change is reasonable but I think we all agree it has minimal
impact at the moment relative to other things, so something even more
complex than that seems like a non-starter. Bloom filtering is a lot
more important.

@_date: 2012-09-22 13:04:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Atomic coin swapping? 
Perhaps I missing something obvious about the definition of coloured coins,
but this appears to be very simple. Just create a transaction that
transfers 300 coins and have an unsigned input connected to the coloured
output. send to the owner of the coloured output, they sign it and

@_date: 2012-09-22 19:05:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Atomic coin swapping? 
As it states in the source code, signatures cannot sign themselves.  If
scriptSigs were included in the data that is being signed, the act of
inserting the newly calculated signature for one input would break the
signatures for all the others.

@_date: 2012-09-23 14:12:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Large backlog of transactions building up? 
Has anyone got long term longs that contain the pool size and timestamps?
Unfortunately I forgot to enable timestamps in the logs for my own
nodes (the privacy benefit of disabling this by default is
questionable, imho). But just looking at the general trends and
cross-checking against my own memory it definitely seems that there
are more and more pending transactions that don't get cleared into
One of my nodes now routinely has 4000 transactions in the mempool.
Blocks typically clear only a few hundred at most, which is what you'd
expect given current transaction rates (around 300 per ten minute
interval). So what are the other pending transactions doing and why
aren't they getting drained out of the mempool?

@_date: 2012-09-23 23:54:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Large backlog of transactions building up? 
Nodes repeat wallet transactions and any previous transactions that
are not yet included in the chain (see
CWalletTx::RelayWalletTransaction). So I don't think it's an issue.
(ok, bitcoinj clients don't do that, they just announce their own transactions)

@_date: 2012-09-24 15:35:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.6 now available 
I'm pleased to announce the release of version 0.6 of bitcoinj, the leading
Java implementation of Bitcoin. You can download the source from Google
Code, or use the release-0.6 branch from git. Our Nexus repository will be
updated soon.
This release focuses on improved compliance with the protocol, improved and
more scalable network handling, a more flexible send API, other misc API
improvements and of course, a large pile of bug fixes. You should upgrade
your software to use bitcoinj 0.6 as soon as possible, if only to benefit
from the fixes - the API changes are minimal so it should be easy.
In more detail:
   - Thanks to Jim Burton, the wallet now stores the depth and work done
   for all transactions, and coinbase transactions are now processed
   correctly. The ability to handle pubkey-only outputs was added, so these
   are now spendable. Migration from 0.5 wallets that don't store this is
   supported, but only for depth, by using
   WalletProtobufSerializer.setChainHeight().
   - Made some more APIs documented and public.
   - Improved block chain download handling.
   - Added compatibility with the broken URIs generated by blockchain.info,
   meaning that the iPhone app and Android apps can now read each others
   QRcodes.
   - Wallets can now auto-save themselves, taking the hassle of managing
   wallet persistence away from your app. See the javadocs for
   Wallet.autoSaveToFile() for information on this.
   - The network layer was rewritten on top of Netty to be more robust,
   more scalable and to remove flakyness in the unit tests. Thanks to Miron
   Cuperman for this work.
   - Thanks to Matt Corallo the ping/pong protocol is now supported. Also
   various protocol conformance issues and other misc bugs were resolved.
   - WalletTool now has a RAW_DUMP option that prints the raw protocol
   buffer form as text.
   - You can now explicitly set fees on a created transaction using the fee
   member of SendRequest. Please note that the correct fees for a
   transaction are still not auto-calculated or minimized. This will come in a
   future release.
   - Many bug fixes.
API changes:
   - TransactionConfidence.OVERRIDDEN_BY_DOUBLE_SPEND is now called DEAD
   - PeerGroup.broadcastTransaction now returns a Guava ListenableFuture (which
   is a subclass of Future, so it's compatible). The future completes when the
   transaction has been heard back from the network, instead of just being
   written out.
   - Wallet.sendCoins() now returns a SendResult that contains both the
   transaction, and the future returned by PeerGroup.broadcastTransaction(),
   so it will no longer block. As a result sendCoinsAsync() has been
   removed.
   - Various send methods on Wallet now take a SendRequest object that lets
   you customize the created transactions. The methods that let you explicitly
   set the change address are removed, you should set the changeAddress member
   of the SendRequest instead.

@_date: 2013-04-04 10:11:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoin pull requests 
My general hope/vague plan for bitcoinj based wallets is to get them all on
to automatic updates with threshold signatures. Combined with regular
audits of the initial downloads for new users, that should give a pretty
safe result that is immune to a developer going rogue.

@_date: 2013-04-04 11:04:22
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoin pull requests 
By the way, I have a download of the Bitcoin-Qt client and signature
verification running in a cron job.

@_date: 2013-04-05 11:48:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] A mining pool at 46% 
51% isn't a magic number - it's possible to do double spends against
confirmed transactions before that. If Michael wanted to do so, with the
current setup he could, and that's obviously rather different to how
Satoshi envisioned mining working.
However, you're somewhat right in the sense that it's a self-defeating
attack. If the pool owner went bad, he could pull it off once, but the act
of doing so would leave a permanent record and many of the people mining on
his pool would leave. As he doesn't own the actual mining hardware, he then
wouldn't be able to do it again.
There are also other mining protocols that allow people to pool together,
without p2pool and without the pool operator being able to centrally pick
which transactions go into the block. However I'm not sure they're widely
deployed at the moment. It'd be better if people didn't cluster around big
mining pools, but I think p2pool still has a lot of problems dealing with
FPGA/ASIC hardware and it hasn't been growing for a long time.
On Fri, Apr 5, 2013 at 11:30 AM, Melvin Carvalho

@_date: 2013-04-06 13:21:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Integration testing for BitCoin 
In bitcoinj we desperately need integration tests to exercise the wallet
code, and I think if it was done well the tests would be applicable to
bitcoind as well. There have been a series of bugs in bitcoinj that boiled
down to "the unit tests were not realistic enough", either because they
stopped simulating too early or they weren't combining multiple different
things together in the same ways as happens on the real network. Sometimes
timing was an issue too.
Examples of what I mean - ensure that re-orgs are handled correctly and
update the wallet properly in every case, etc.
Something else that would be really useful, a standalone tool that
stress-tests the system. If we had a tool that randomly generated chains of
transactions we might have caught the bdb lock limit bug earlier. You could
write such a tool using bitcoinj easily, or the raw transaction APIs on

@_date: 2013-04-09 12:42:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] On-going data spam 
OK, as the start of that conversation is now on the list, I might as well
post the other thoughts we had. Or at least that I had :)
It's tempting to see this kind of abuse through the lens of fees, because
we only have a few hammers and so everything looks like a kind of nail. The
problem is the moment you try to define "abuse" economically you end up
excluding legitimate and beneficial uses as well. Maybe Peters patch for
uneconomical outputs is different because of how it works. But mostly it's
true. In this case, fees would never work - Peter said the guy who uploaded
Wikileaks paid something like $500 to do it. I guess by now it's more like
$600-$700. It's hard for regular end users to compete with that kind of
wild-eyed dedication to "the cause".
The root problem here is people believe the block chain is a data structure
that will live forever and be served by everyone for free, in perpetuity,
and is thus the perfect place for "uncensorable" stuff. That's a reasonable
assumption given how Bitcoin works today. But there's no reason it will be
true in the long run (I know this can be an unpopular viewpoint).
Firstly, legal issues - I think it's very unlikely any sane court would
care about illegal stuff in the block chain given you need special tools to
extract it (mens rea). Besides, I guess most end users will end up on SPV
clients as they mature. So these users already don't have a copy of the
entire block chain. I don't worry too much about this.
Secondly, the need to host blocks forever. In future, many (most?) full
nodes will be pruning, and won't actually store old blocks at all. They'll
just have the utxo database, some undo blocks and some number of old blocks
for serving, probably whatever fits in the amount of disk space the user is
willing to allocate. But very old blocks will have been deleted.
This leads to the question of what incentives people have to not prune. The
obvious incentive is money - charge for access to older parts of the chain.
The fewer people that host it, the more you can charge. In the worst case
scenario where, you know, only 10 different organizations store a copy of
the chain, it might mean that bootstrapping a new node in a trust-less
manner is expensive. But I really doubt it'd ever get so few. Serving large
static datasets just isn't that expensive. Also, you don't actually need to
replay from the genesis block to bring up a new code, you can copy the UTXO
database from somewhere else. By comparing the databases of lots of
different nodes together, the chances of you being in a matrix-like sybil
world can be reduced to "beyond reasonable doubt". Maybe nodes would charge
for copies of their database too, but ideally there are lots of nodes and
so the charge for that should be so close to zero as makes no odds - you
can trivially undercut someone by buying access to the dataset and then
reselling it for a bit less, so the price should converge on the actual
cost of providing the service. Which will be very cheap.
There was one last thought I had, which is that if there's a shorter team
need to discourage this kind of thing we can use a network/bandwith related
hack by changing the protocol. Nodes can serve up blocks encrypted under a
random key. You only get the key when you finish the download. A blacklist
can apply to Bloom filtering such that transactions which are known to be
"abusive" require you to fully download the block rather than select the
transactions with a filter. This means that people can still access the
data in the chain, but the older it gets the slower and more bandwidth
intensive it becomes. Stuffing Wikileaks into the chain sounds good when a
20 line Python script can extract it "instantly". If someone who wants the
files has to download gigabytes of padding around it first, suddenly
hosting it on a Tor hidden service becomes more attractive.

@_date: 2013-04-09 16:14:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] On-going data spam 
This is already the case and always has been.
If you're volunteering to store and serve the chain no matter what it
contains, indefinitely, then you're free to have a no blacklists policy and
serve up data transactions for no cost. Otherwise, other people will do
whatever they want.

@_date: 2013-04-09 16:53:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] On-going data spam 
I think that patch is ok as it doesn't really have any fixed concept of
what is uneconomical. But I haven't thought about it much. As Gavin says,
there's an obvious backwards compatibility problem there. It should
probably wait until the payment protocol work is done, so the major user of
micropayments-as-messages  can migrate off them.

@_date: 2013-04-09 21:43:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] On-going data spam 
AV software changes all the time, I definitely recall cases where AV got
interested in, eg, web browser caches and ended up corrupting things. But
that might be because it knew the files were written by a web browser.
Lightly frying the contents has the disadvantage of no mmap and no
sendfile() in future. Perhaps an idea to stash in our back pockets if it
turns out to be needed later.

@_date: 2013-04-09 23:03:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.8 
I'm happy to announce the release of bitcoinj 0.8, a Java library for
writing Bitcoin applications. Both simplified and full verification are
supported. BitcoinJ has been used to create everything from end-user wallet
apps to network crawlers to SatoshiDice.
To get bitcoinj 0.8, check out our source from git and then run *git fetch
--all; git checkout **cbbb1a2bf4d1*. This will place you on the 0.8 release
in a secure manner. This message was written on Tuesday 9th April 2013 and
is signed with the following key, which will be used in all release
announcements in future: 16vSNFP5Acsa6RBbjEA7QYCCRDRGXRFH4m.
Signature for previous
paragraph: H8itldUGHHt8jXmFwRX/gASXrhG1a/k0VG0vwFMjQCAWDpxgA17ODfSPFNgAOPDnPmT1gLLUlHsEqwXHBoj+JMU=
You can also verify the google.com DKIM signature on the official
I'm especially happy about this release because for the first time, we have
an SPV implementation that is competitive performance-wise with more
centralised solutions that rely on custom servers. Wallets based on
bitcoinj 0.8 complete first time setup for new users in only a few seconds,
eliminating the last source of significant delays. Every operation except
key import now completes more or less immediately.
*New in this release*
   - Thanks to Jim Burton, encryption of private keys in the wallet is now
   supported. Keys are encrypted using an AES key derived using scrypt.
   - A new SPVBlockStore provides dramatically better performance and
   bounded disk usage by storing block headers in an mmapped ring buffer. This
   makes syncing headers for new chains/wallets network limited instead of
   disk io limited.
   - A new tool is provided to create lists of block header checkpoints
   that can then be used to initialize a new block store. This allows most
   headers to not be downloaded when initializing a new chain/wallet, making
   first-run of new wallets much faster.
   - Bloom-filtering capable nodes are now queried for transactions at
   startup, meaning you can receive payments that weren't confirmed yet even
   if your wallet wasn't running at the time.
   - Many static analysis warnings have been cleared.
   - All event listeners except transaction confidence listeners now run
   unlocked and core objects have been converted to use cycle detecting locks.
   Multiple lock inversions were fixed.
   - DNS seeds are now supported for testnet.
   - PeerEventListener now lets you catch and process exceptions thrown
   during peer message processing. This is useful for reporting crashes that
   don't take out your entire app, but just result in disconnection of a peer.
   - Matt Corallo's bitcoind comparison tool was merged in. It runs a large
   set of regression tests that compares the behaviour of bitcoinj in full
   verification mode against bitcoind.
   - The vast bulk of the changes in this release are bug fixes,
   optimizations and minor API improvements. They are too numerous to list
   here, please refer to the commit logs for details.
*API changes:*
   - Event listeners were previously locked before being called, and the
   object being listened to was also locked. This is no longer true - your
   event listeners must be thread safe and the objects that triggered the
   event may be changing in parallel.
   - IrcDiscovery is now deprecated, as LFnet has gone offline and DNS
   seeding can be used for both test and production networks. The code is
   still there in case you want to use IRC bootstrapping for a private
   experimental network.
   - BoundedOverheadBlockStore is now deprecated. It was replaced by
   SPVBlockStore. The file format has changed, so BOBS will stick around
   for a while so users can be upgraded.
   - The Derby based block store has been deleted. It only supported SPV
   mode and wasn't used much.
   - The static NetworkParameters methods now vend singleton objects.
   - WalletEventListener.onCoinsSent is no longer run when a transaction
   sends to self but the balance doesn't change.
*Known issues:*
   - Transaction confidence listeners are still run with the wallet lock
   held, which means it's possible to trigger unexpected lock inversions by
   doing certain things inside them. Also, confidence listeners sometimes run
   in places where the wallet code is not fully re-entrant, meaning that
   modifying the wallet whilst inside a confidence listener may cause
   problems. A simple fix is to run your listener code in a separate thread. A
   future release will fix this by ensuring that listeners only ever run at
   the end of wallet mutating operations and with the wallet unlocked. Core
   objects will also switch to using non-reentrant locks so unexpected
   reentrancy deadlocks early and reliably.
   - If multiple peers disconnect simultaneously it's possible for the
   system to deadlock due to Netty allowing uncontrolled reentrancy when
   sending outbound messages (issue
   ).
   - The Wallet expects that it can store all transactions in memory
   (including spent transactions), eg, for rendering in lists and availability
   during re-orgs. On highly constrained devices like old Android phones it is
   possible to run out of RAM if a wallet gets very large.
   - There are some bugs that can cause the wallet to get into an
   inconsistent state in various rare situations. The wallets can be fixed by
   replaying them. These bugs will be addressed as the next highest priority.
There is a further list of limitations and issues available on the wiki

@_date: 2013-04-10 12:02:09
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.8 
The key in the message was used in my last announcement, so that
establishes continuity there.
But regardless, all mails I send are signed automatically by Gmail using
either the gmail.com consumer key (for my posts to this list) or the
google.com corporate key (for my posts to the bitcoinj lists), see
dkim.orgfor more details on this. Whilst this is not signing in the
GPG web of
trust sense, realistically the Gmail DKIM keys are much safer than any key
I could create/maintain, and my ability to sign mail as hearn at google.com is
controlled by hardware second factors and various other rather intense
security systems I can't discuss.
I've considered just not having the additional Bitcoin-key based signatures
at all, but it would help keep continuity in the case that I leave Google
or if there's a DKIM key rotation.

@_date: 2013-04-16 19:39:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
This was previously discussed on the forums a bunch of times, but in
particular here:
  BTW, I don't think all this has to be solved to re-activate replacement on
testnet. It's useful for people to be able to develop apps that use this
feature, indeed, it helps build the case for re-activating it on the main
network after the necessary work is done. Otherwise there'll inevitably be
people who say "why re-activate something even though we think it's safe
when there are no use cases for it". Letting people develop and deploy
interesting prototypes in parallel solves that catch-22.
  ---
Refresher: since the first release Bitcoin has had the ability to replace
transactions that sit in the memory pool if the transaction is non-final,
the inputs are the same and the replacement is newer than the replacee.
Being non-final means not having reached the nLockTime threshold, and
having at least one input with a sequence number < UINT_MAX. Around the
time of the bugs in various opcodes being found, Satoshi disabled the
feature because nothing was using it - it was something he'd planned for
the future, it had no utility in the Bitcoin of 2010.
The purpose of tx replacement is to implement high frequency trading,
according to material Satoshi sent me when I asked him what it was all for
(I wanted to know why sequence numbers were a property of inputs not the
It's very important to understand that this does *NOT* mean high-frequency
from the networks perspective. In normal operation, tx replacement is not
actually intended to be used at all. Sort of like double-spending
protection, it's a code path that's only meant to be triggered when one or
the other party is maliciously trying to roll back a negotiated contract.
And when a party is trying to do that, you don't need lots of replacements.
A single replacement is enough.
To see why this is the case please review the micropayment channel protocol
This isn't the only use of contractual HFT in Bitcoin, it's a deliberately
simplified and stripped down example (eg, that only uses two parties). The
example Satoshi gave me was more abstract and actually had N parties in it
- it left me puzzled for a while and struggling to see practical
application. The "billing for a metered resource" use case is easier to
Now the obvious problem is that even though the feature is only intended to
be used occasionally or never, nothing in the existing code stops you using
it as fast as possible and exhausting nodes CPU time and bandwidth.
What's more, solving this is not as easy as it looks. Most proposed
solutions will not work:
1) Requiring higher fees for each replacement means that a channel/contract
has to be torn down and rebuilt much, much faster than before because
otherwise the amount of money lost to fees quickly becomes the entire size
of the channel (or you can't update it very often). Remember, you'd have to
increase the fee for each replacement regardless of whether it's presented
to the network or not. As the whole point of the setup is to avoid putting
lots of transactions on the network, anything that pushes you back towards
doing that undermines the entire utility of the system.
2) Refusing to update the transaction after certain thresholds are reached,
having cooldown periods, etc also won't work because the replacement
mechanism is there to protect each counter-party in the HFT contract.
Simply converting a DoS on the network to a DoS on the participants means
one malicious party can break the mechanism that protects all the others by
broadcasting the initial set of updates all at once and deliberately
tripping the thresholds.
OK, let's take a step back. What is the purpose of abusing this feature?
It's to mount a denial of service attack - either against the entire
Bitcoin network, or against the other participants in the contract. But
someone, somewhere has to be denied service, otherwise the attack is
We can exploit this fact by realising that typically anti-DoS is a
prioritisation problem. It doesn't usually matter if you serve some abusive
traffic if all legitimate traffic gets served first because it removes the
denial of service from the attack, and usually there are lots of ways to
attack someone with methods that don't work - real world experience
indicates that people don't pointlessly mount attacks over and over again
if there's nothing to be gained by doing so.
So we can do the following - multi-thread verification of transactions that
are trying to enter the memory pool, and order them such that high priority
transactions are verified first, low priority next, and then replacements
of transactions sorted by age of last replacement. Same thing for relaying
- faced with getdatas, service the new transactions first, replacements
with whatever is left over. Drop whatever doesn't make it into the nodes
available resources.
Handling DoS as a prioritisation problem has a number of advantages, most
obviously not introducing new hard coded magic numbers that may or may not
stay up to date with changing conditions.
This setup means someone can force CPU/bandwidth usage to whatever the node
operators have configured as their max allowed across the network for a
while, but doing so won't actually disrupt normal transactions. It'll just
result in the replacements getting dropped. It slightly increases the risk
of a malicious counter-party in an HFT contract trying to take advantage of
the saturation to themselves execute an attack on the contract, but I doubt
it'd be a problem in practice -  you'd need to write your software to be
able to perform such an attack, most of the time it wouldn't work, and if
people saturate the network with low priority easily dropped transactions
so that it would work then nodes/apps could just warn users not to take
advantage of the feature whilst the flood is in progress.
I know that some people will object to such a design on principle, but I
think this is a good balance - the only attacks that exist aren't
profitable and the worst case outcome in the face of continual profitless
abuse is we switch the feature off and end up no worse off than today.
I haven't touched on the topic of cartels of malicious miners or other
topics, just DoS. This email is long enough already and handling malicious
miners (if necessary) can be done at the application protocol level, it
doesn't need any changes to the core tx replacement / locktime mechanism.

@_date: 2013-04-17 11:19:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
I'm using the term "high frequency trading" because Satoshi did. Like the
way he used the word "contract" it is perhaps a bit misleading, but we lack
anything better to describe this new concept.
Today HFT typically means companies that submits tons of micro-trades to
centralised asset exchanges to try and exploit statistically expected
correlations. HFT using tx replacement has nothing to do this with - it is
instead a way that N parties can negotiate amongst themselves as fast as
they can compute and verify signatures.
Here is how Satoshi explained it to me, in his words:
An unrecorded open transaction can keep being replaced until nLockTime.  It
may contain payments by multiple parties.  Each input owner signs their
input.  For a new version to be written, each must sign a higher sequence
number (see IsNewerThan).  By signing, an input owner says "I agree to put
my money in, if everyone puts their money in and the outputs are this."
 There are other options in SignatureHash such as SIGHASH_SINGLE which
means "I agree, as long as this one output (i.e. mine) is what I want, I
don't care what you do with the other outputs.".  If that's written with a
high nSequenceNumber, the party can bow out of the negotiation except for
that one stipulation, or sign SIGHASH_NONE and bow out completely.
The parties could create a pre-agreed default option by creating a higher
nSequenceNumber tx using OP_CHECKMULTISIG that requires a subset of parties
to sign to complete the signature.  The parties hold this tx in reserve and
if need be, pass it around until it has enough signatures.
One use of nLockTime is high frequency trades between a set of parties.
 They can keep updating a tx by unanimous agreement.  The party giving
money would be the first to sign the next version.  If one party stops
agreeing to changes, then the last state will be recorded at nLockTime.  If
desired, a default transaction can be prepared after each version so n-1
parties can push an unresponsive party out.  Intermediate transactions do
not need to be broadcast.  Only the final outcome gets recorded by the
network.  Just before nLockTime, the parties and a few witness nodes
broadcast the highest sequence tx they saw.

@_date: 2013-04-17 11:48:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
When this system was first being discussed, Gavin was concerned that miner
incentives were to ignore replacements because it meant extra work and the
replacement might have equal or lower fees than before (or indeed, no
fees). He proposed two solutions: one is to progressively raise the fee on
each replacement. The other is to specify lock time in terms of blocks and
then step it backwards once for each replacement, thus ensuring that by
replacing the transaction you get to claim any attached fee earlier.
It should be apparent that both solutions can be implemented by whichever
application is running the contract - the core Bitcoin network and software
is agnostic either way.
Now, Gavin and I disagreed on whether this would actually be necessary. As
I already pointed out, both solutions seriously reduce the utility of HFT
because they limit how often you can update the contract. Instead of an
online game billing you per second, maybe it can only do it per minute or
per 10 minutes with the lock time solution because otherwise you run out of
blocks, and with ever-increasing fees perhaps the contract becomes too
expensive to justify after a while.
So it'd be nice if this ended up not being necessary. Experience indicates
that rational miners typically don't pursue a short-termist
profit-at-any-cost agenda - free transactions have always been included in
blocks, miners include transactions even though you could avoid a lot of
complexity by just not including any at all, etc. Some miners like BTC
Guild have actually sacrificed significant amounts of money for the good of
the system. You can see this in terms of rational self interest - miners
earn Bitcoins thus it's in their interest for Bitcoins to be as useful as
possible, as that is what gives them value. Or you can see it in terms of
ideologically-driven altruism. Or both.
If I were to implement an application that used tx replacement, I would
probably start with replacements that don't change the fees and don't count
down the lock time field. We can then observe whether miners bother
changing their software to behave differently, or whether the inherent
utility of the application is enough to convince them to play by the
default rules. Ideally at least one application made possible by this
feature is a "killer app" - something so useful / unique / compelling that
people want to obtain Bitcoin just to use it. If someone can find such an
app, then rational miners should want tx replacement to work as reliably as
possible because it boosts the value of their earnings.
There are some other misc details - reactivation requires that we bump the
protocol version and start relaying non-final transactions to new nodes
again. Those nodes should relay replacements but not let them enter wallets
unless/until the wallet software itself can handle them better, for
instance, by communicating via APIs anticipated confirmation times. This is
something for individual wallet APIs to handle on their own, and just
ignoring non-final transactions is a perfectly workable approach for

@_date: 2013-04-18 10:32:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
When did I say DoS was unimportant? I just wrote a giant email explaining
how it can be resolved.
I think it's worth pointing out that Bitcoin was launched with no DoS
protection at all, and it's still here. There are still obvious DoS bugs
being fixed with every release. So yes, it's important to robustify the
code, but not to the extent of not having any features. If Satoshi had
taken that perspective Bitcoin might not exist at all. We can have our cake
and eat it.
RE: shutting down services dependent on replacement. No, good users of
replacement would still end up taking priority over the constantly churning
DoS replacements. The most you can shut down is one contract. Obviously, if
there's no form of tx replacement at all then the "tried and doesn't work"
state is the same as "never tried", which doesn't seem like a win.
The testnet is trivially DoSable today by anyone who cares to do so, there
are hardly any nodes and most people get coins from the faucet. Look at how
quickly people got upset when somebody drained it. As Jeff has pointed out,
there could theoretically be a "nextnet" but the overhead of setting one up
doesn't seem worth it. If somebody wanted to troll developers they could
easily DoS testnet and nextnet simultaneously with bandwidth to spare.
Yes, I noticed it a few days ago when making some notes, but figured I
would indeed make an prototype implementation and then just put all the
details and latest protocols on the wiki at once. As nobody indeed noticed
the bug for years apparently nobody else is working on this so it didn't
seem urgent to update.
Your proposed alternative doesn't seem any different DoS wise. Someone can
still broadcast a long series of incrementally different transactions and
have miners replace them. So you still need prioritisation of work. It's
useful anyway for other reasons. And as you point out yourself, it's still
susceptible to the problem that you end up running out of money because
it's all been spent on fees.
BTW $500 is rather low for the amount of work required. If you added a zero
onto that there might be more takers.

@_date: 2013-04-18 11:28:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
It's possible, but let's do some back of the envelope calculations to look
at how quickly such an attack can exhaust itself.
Consider a contract that has a time window of 12 hours and is adjusted once
per second for that duration. That's 43,200 adjustments. It sounds sort of
ballpark-ish for micropayments. If you end up losing 1 seconds worth of
service, well, probably that's no big deal. As the contract reaches its
nLockTime, the attacker starts broadcasting all of the adjustments in
sequence in the hope that an earlier version will be being processed as the
lock time expires and a block is solved, so the latest version (the one
that gives him the least money) ends up not being included in the chain.
The input is a multi-signature transaction, so to process every single
adjustment created would take 86,400 signature verifications. With the
sipaspeed patches it seems ECDSA can be processed on modern cores at
something like 20,000 signatures per second. So it'd take a bit over 4
seconds to process all of them (cpu time).
That gives the attacker a less than 4 second window in which to try and
roll back the contract to an earlier time before he reaches the last
version and things are as they should be. Given that a block is solved on
average every 10 minutes, you'd have to get very lucky indeed to succeed
with such an attack. It's probably easier to try and find a corrupt miner
who is willing to bend the rules for you.
Let's include bandwidth. Say the contract (multi-sig input + the outputs)
is about 700 bytes. 43,200 transactions is then about 29 megabytes of data.
On a fairly normal 10mbit connection that would take about 23 seconds to
transfer. Of course the real number is a bit higher because of latency
introduced by the inv/tx round-tripping. So the time window of the attack
is dominated by bandwidth but it's still quite small compared to the block
solving window.
It's *easily* DoSable, not trivially.
What I meant is - find some open DNS resolvers, start firing packets at
testnet nodes, done. You don't have to do protocol level attacks to just
render nodes useless.
Ah, I think it actually is possible and this is an intriguing idea. Each
input has its own sequence number. Look at the definition of IsNewerThan()
- to make a newer version you increment your inputs sequence number in a
particular manner whilst leaving the others alone.
Having a single multi-sig input means you can't do that because both
parties co-operate to update the single input, but schemes that use
multiple inputs do seem posible.
As I said at the bottom of my second mail, it means making non-final
transactions relayable again, but only to nodes that advertise a high
enough version number. Those nodes are expected to do something intelligent
with them, like just not put them in the wallet (unless the user has opted
in and ticked the "i know what i'm doing" box, perhaps).
Well, it depends on your use case - you need to cast the (fixed) algorithm
into a network protocol, manage the interactions between the parties,
monitor the network for malicious broadcasts so you can replace them, fix
the code so the wallets don't accept non-final transactions except when
taking part in your contract, etc. If you do it all with Bitcoin-Qt it's
easier but then your app can't easily run in places that can't afford a few
hundred megs of ram (like wifi hotspots). The devil is in the details.

@_date: 2013-04-18 11:34:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
Sorry brainfart, s/cores/cpus/. I think the 20k/sec was with full usage of
a hyperthreaded quad core CPU.

@_date: 2013-04-18 11:32:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
Good point - transactions can be ordered by highest version seen before
they're signature checked. Even without that improvement it's still rather
tricky to win the race though.
I'm intending on making a prototype for myself at some point soon, probably
in bitcoinj. I've been making notes and writing some initial code - I did
successfully replace a transation on my own little testnet, then I figured
I'd submit the patch so it's easier for others to play with it. But I
haven't got the whole thing working end to end yet.

@_date: 2013-04-18 12:19:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
Indeed, as I mentioned in my first mail, nodes can be told how much
bandwidth they're allowed to use and then prioritize within that, so I
don't see any way convergence can fail. And regardless, I used 10mbit for
the calculations, that isn't exactly unlimited. My home internet connection
is better than that. It's just an arbitrary choice that lets us get a feel
for the numbers. We can see that even with a lot of replacements, an
attacker would have a hard time matching up his flood with when a block is
actually solved.
On the wider point - how many people DoS things with their own bandwidth?
The point of DNS reflection and/or botnets is you use other peoples
bandwidth. The attacks on Mt Gox are supposedly 80 gigabit+, which is
enough to take out all of the main network simultaneously. We can't do
anything about that. So I agree we should work to avoid opening up new DoS
attacks, but we should also be realistic about what can be accomplished.
The kind of people trying to manipulate Mt Gox could nuke the entire P2P
network off the face of the internet with the flick of a switch, presumably
the reason they aren't doing that it would to use Satoshi's phrasing
"undermine the validity of their own wealth".
non-standard test to give a window of, say, 3 blocks, would be fine I
Sure. I think Gavin wants some kind of wider memory pool limiter policy
which would encompass such a thing already.

@_date: 2013-04-22 13:07:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
Yes, this is an excellent observation. Thanks Jeremy and Peter. It's much
less general than full blown tx replacement+lock times, but for the case of
a channel between two people that only ever increases in one direction, it
can work. Thanks. I will try implementing this myself for testing on the
main network.

@_date: 2013-04-24 09:42:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP21 bitcoin URIs and HTML5 
HTML5 allows web apps to register themselves for handling URI schemes, such
as the bitcoin: URI that is already in use and being extended as part of
the payment protocol.
The bad news is that for security reasons there is a whitelist of
acceptable schemes in the spec:
The good news is that yesterday I talked to Hixie about it and he added
bitcoin to the whitelist:
I'm currently finding out what the process is for browser makers to notice
the change (perhaps they watch the spec commit history and nothing needs to
be done), but within a few months most users should have browsers that can
accept bitcoin as a web-app handleable protocol scheme. I suppose IE10
users may be the laggards, but I guess we can live with that for now.
Ian pointed out some errors in the BIP21 spec. What's the process for
amending the BIP? Do we need to create a new one and mark the old one as
replaced, or can we just fix it in place given the relatively exotic nature
of most of the issues? Here's his feedback:
- BNF doesn't say what it's character set is (presumably it's Unicode)
 - "bitcoinparams" production doesn't define the separator, so in theory
the syntax is ...?label=foomessage=fooother=foo (rather than
...?label=foo&message=foo etc)
- the syntax allows ?amount=FOO&amount=1.1 as far as I can tell, since
"otherparam" matches any name followed by any value, including "amount"
followed by a bogus value.
- "pchar" is referenced without definition.
- the "simpler" syntax is just wrong (it would result in
bitcoin:address?amount=1?label=FOO rather
than bitcoin:address?amount=1&label=FOO)
BTW the IETF URL specs are being obsoleted by at least for Web purposes. In that case matters.

@_date: 2013-04-25 11:08:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cold Signing Payment Requests 
(for background: I did a lot of the design work with Gavin on the payment
protocol and suggested/prototyped using x.509 in the way we do).
So, I'm not a fan of weird hacks involving non-existent domain names.
There's a clean way to implement this and we decided to punt on it for v1
in order to get something shippable, but if you're volunteering ... :) then
indeed having a custom cert type that chains onto the end is the way to go.
It doesn't have to be X.509. It can just be a regular protocol buffer. Even
if we re-used X.509 it wouldn't be accepted by OpenSSL or any other SSL
stack, so it wouldn't buy us anything and it's not like ASN.1 is easy to
work with. Chaining an additional Bitcoin-specific cert onto the end also
solves the problem of delegation ... a lot of merchants are using BitPay
but probably don't want to share their SSL private keys with a third party.
That means today the payments would show up as paid to BitPay Inc which is
misleading and weird, they're just an intermediary. So if the merchant can
run a simple command line tool that you point to the private key, and it
spits out a signed protobuf that contains a new (ecdsa) public key and
saves the private key to a file, then you can send that cert and key off to
your payment processor. The identity is still taken from your CA cert but
the actual signing keys used are different.
Another use case - a company has a lot of roving sales agents, like in a
supermarket or waiters at a restaurant. The company wants the agents to be
able to sign with their corporate EV identity but the agents are not highly
trusted. So they can be issued a 24-hour expiring Bitcoin-specific cert at
the start of each working day and then they sign payment requests with that.

@_date: 2013-04-25 12:05:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cold Signing Payment Requests 
What you wrote doesn't make any sense to me, sorry.
Yes, SSL private keys are kept online. That's irrelevant - the goal of all
this is not to protect against web server compromise. That's a pointless
goal to try and solve right now, because the SSL PKI cannot handle
compromised web servers and so neither can we (with v1 of the payments
The goal of this is to allow delegation of signing authority without giving
the delegate the SSL private key.

@_date: 2013-04-25 12:45:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cold Signing Payment Requests 
Yes, but my point is if the SSL key lives on the web server, and there are
CAs that issue you certs based on control of a web server at the given
domain name (there are), then you can simply issue yourself a new SSL cert
with whatever data in it you want and pose as the merchant.
So I don't see how you can have a payment request signing key that's safer
than an SSL key. As Jeremy notes, CAs will not issue you intermediate
certificates. Perhaps if one existed that would do the necessary things for
a reasonable price you could indeed give yourself an offline intermediate
cert and then use that to sign one cert for SSL and another for payment
request signing, but as far as anyone is aware no such CA exists.
The interesting case is where the thing signing payment requests is less
trusted than the web server. The scenario you're trying to solve is the
inverse - the payment request signing process is more trusted than the web
server. But unless/until the CA landscape changes we don't have a way to
implement that.

@_date: 2013-04-25 12:52:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cold Signing Payment Requests 
Re-reading what I wrote, it's not really clear.
Even if possible, the intermediate cert setup still wouldn't work for most
merchants but I didn't make that clear. It might work for EV certs. For
most sites that are just DV there's nothing you can do because CA
verification is just "do you control this domain name". So if your web
server is compromised it's game over. They can issue themselves a new cert,
and what's more, unless wallets are checking revocation lists you can't
stop them signing as you until their certificate expires.
The process for getting an EV cert is harder and there, an offline
restricted intermediate cert might make more sense because you could have a
compromised SSL key whilst not having a compromised identity, but it's
still not possible with todays CA policies.

@_date: 2013-04-25 16:31:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cold Signing Payment Requests 
I didn't see your other replies but got this one.
The assumption you made by doing that is that people can obtain your PGP
key. This leads to the question of how someone knows what your key is or
that you signed the list in the first place. The most obvious way is to go
to  and click "My PGP key" -> but we already
failed at this point if your web server was hacked. I'd have to learn about
your cryptographic identity via some other secure channel, but usually that
doesn't exist.
Being able to survive web server hacks is intuitively attractive because
web servers tend to be so insecure. But unfortunately there doesn't seem to
be any good way to do this with todays infrastructure because for most
businesses, their website *is* their identity, and if a hacker controls
that they it's very hard for anyone (including CAs) to know that something
has gone wrong.
I think there are some simple mitigations we can use in the short term.
One is that wallets could count how many times you paid to addresses signed
by a particular cert. If you're a repeat customer and your wallet says "You
have never paid this recipient before" instead of "You have paid this
recipient 4 times" then you might be suspicious. Someone pointed out to me
that the current payment protocol has nothing to say on phishing using
confusible domains - this could help with that too, and it's easy to
implement. Of course it means you get reset whenever your certificate
expires and has to be renewed, and crying wolf is often worse than doing
nothing at all. So that's an issue.
With time there might be more complex solutions available, like extensions
to X.509/CA infrastructure (if bitcoin stays growing and popular). Also,
alternative PKIs like DNSSEC or the ePassport PKI might be useful. In your
case Mike you aren't really a company, you're trading under your own name,
so signing the key list under your legal identity is really the best
solution. It's just not easily available right now.

@_date: 2013-04-28 18:29:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Service bits for pruned nodes 
I'd imagined that nodes would be able to pick their own ranges to keep
rather than have fixed chosen intervals. "Everything or two weeks" is
rather restrictive - presumably node operators are constrained by physical
disk space, which means the quantity of blocks they would want to keep can
vary with sizes of blocks, cost of storage, etc.
Adding new fields to the addr message and relaying those fields to newer
nodes means every node could advertise the height at which it pruned. I
know it means a longer time before the data is available everywhere vs
service bits, but it seems like most nodes won't be pruning right away
anyway. There's plenty of time for upgrades. If an old node connected to a
new node and getdata-d blocks that had been pruned, immediate disconnection
should make the old node go find a different one. It means the combination
of old node+not run for a long time might take a while before it can find a
node that has what it wants, but that doesn't seem like a big deal.
What is the use case for NODE_VALIDATE? Nodes that throw away blocks almost
immediately? Why would a node do that?

@_date: 2013-04-28 18:57:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Service bits for pruned nodes 
That's true. It can be perhaps be represented as "I keep the last N blocks"
and then most likely for any given node the policy doesn't change all that
fast, so if you know the best chain height you can calculate which nodes
have what.
Well, old nodes would ignore it and new nodes wouldn't need it?
Maybe so, with a "last N blocks" in addr messages though such nodes could
just set their advertised history to zero and not have to deal with serving
blocks to nodes.
If you have a node that serves the chain but doesn't validate it, how does
it know what the best chain is? Just whatever the hardest is?

@_date: 2013-04-30 11:17:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cold Signing Payment Requests 
It's a real threat, albeit an exotic one. The threat model is a malware
compromised host, with a wallet (possibly a low power hardware wallet like
a Trezor) that can understand the payment protocol and sign transactions,
but maybe not do a whole lot more than that. For instance, probably it
cannot do HTTPS connections itself. So a virus on the host could swap the
refund address for one that is owned by the attacker, and then try to make
the merchant issue an automatic refund, thus bouncing the funds back off
the merchant to the them.
If there are merchants that offer large, automatic refunds, it could be an
issue. I'm not sure how common that might be in reality. Steven or Tony
would know. Timo's protocol is an interesting solution, but again, at this
point the feature set for v1 is pretty much locked down.

@_date: 2013-08-06 13:09:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Preparing for the Cryptopocalypse 
I believe post-QC schemes based on Regev's LWE assumption are getting
competitive with more traditional schemes. A paper from 2010 says they were
able to get to around the same as large RSA key sizes (2048 bits), which is
much worse than ECC but not entirely infeasible. Especially given that
barring some breakthrough, by the time QC is a real problem we'll have
gigabit wifi and 32 core devices with a terabyte of storage embedded in our
hands :)

@_date: 2013-08-07 10:41:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Safe auto-updating 
As you're Mac specific you could just use a modified Sparkle or something
like that. Even if you want to use a stock Sparkle, I have some code that
does threshold RSA. My intention was to use it for the Android wallet but I
never found the time. I can send you a copy if you want. But it's easier
and more robust to modify the update framework. Threshold RSA would only be
interesting if you wanted to use the Mac app store, for example.

@_date: 2013-08-07 23:17:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
bitcoinj separates the concept of committing a tx to the wallet from
broadcasting it. However by default transactions that weren't seen in the
chain yet will be announced when a new peer is connected to. It'd take
extra code to suppress that, and it's unclear to me why that's useful. I
agree with Pieter that it should be the merchants responsibility to get the
tx out there, but having the client do the broadcast as well can't really
hurt (except perhaps some privacy impact).

@_date: 2013-08-07 23:44:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
How would such wallets get transactions into their wallet in the first
The P2P protocol is really the simplest part of implementing a wallet, IMO.
I don't really have a strong opinion either way, but doing more work to
prevent transactions being announced to the network feels weird.

@_date: 2013-08-09 13:43:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Idea for new payment protocol PKI 
This is just me making notes for myself, I'm not seriously suggesting this
be implemented any time soon.
Mozilla Persona is an infrastructure for web based single sign on. It works
by having email providers sign temporary certificates for their users,
whose browsers then sign server-provided challenges to prove their email
Because an SSO system is a classic chicken/egg setup, they run various
fallback services that allow anyone with an email address to take part.
They also integrate with the Google/Yahoo SSO systems as well. The
intention being that they do this until Persona becomes big enough to
matter, and then they can remove the centralised struts and the system
becomes transparently decentralised.
In other words, they seem to do a lot of things right.
Of course you can already sign payments using an X.509 cert issued to an
email address with v1 of the payment protocol, so technically no new PKI is
needed. But the benefit of leveraging Persona would be convenience - you
can get yourself a Persona cert and use it to sign in to websites with a
single click, and the user experience is smart and professional. CAs in
contrast are designed for web site admins really so the experience of
getting a cert for an email address is rather variable and more heavyweight.
Unfortunately Persona does not use X.509. It uses a custom thing based on
JSON. However, under the hood it's just assertions signed by RSA keys, so
an implementation is likely to be quite easy. From the users perspective,
their wallet app would embed a browser and drive it as if it were signing
into a website, but stop after the user is signed into Persona and a user
cert has been provisioned. It can then sign payment requests automatically.
For many users, it'd be just one click, which is pretty neat.

@_date: 2013-08-09 13:48:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SPV client in pure JavaScript? 
JavaScript is turing complete so of course it can be done. The real
question you're asking is, can it be done in a web app? I think the answer
is I think "no" because web apps aren't allowed to make raw TCP socket
Now there may be a way around that by using browser-specific things like
extensions or "installable apps" which give your code greater access
permissions. This approach means you essentially use Chrome as your app
platform instead of a JVM, the assumption presumably being that more users
have Chrome than a JVM. The flip side is that users who don't would
probably balk at the idea of installing an entire browser in order to run a
wallet app, whereas a JVM can be bundled and the resulting app acts like
any other. I don't know of a convenient way to "statically link" Chrome
into a regular-looking application.
I personally wouldn't find such a design compelling. Whilst Java isn't
exactly a great language, JavaScript is significantly worse in virtually
all aspects. I don't understand why anyone would want to use JavaScript
outside the browser - you get less safety, less performance, fewer
features, less mature tools and so on. If the end result is an installable
app like any other, all you did is cripple yourself vs the competition
that's using languages/platforms designed for it.

@_date: 2013-08-09 14:08:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Idea for new payment protocol PKI 
When Persona is supported by all the key players in a transaction Mozilla
doesn't get anything, do they? You can easily run your own IDP on a
personal server if you're the kind of person who likes to do that, then run
Firefox so you have a native implementation and the Mozilla servers aren't
involved. The keys never leave your computers.
Whilst X.509 certs can indeed be issued for any arbitrary string, you still
need a CA that will do it for you, and that's typically not so trivial. CAs
aren't meant for widespread end user adoption, really, whereas Persona is.
I don't think Persona is any more or less centralised than other PKIs,
really, just easier to use. Ultimately the string you're verifying is a
user at host pair, so the host is centralised via DNS and to verify the
assertions it vends, you must use SSL to connect to it, so under the hood
the regular SSL PKI is still there.

@_date: 2013-08-09 14:10:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SPV client in pure JavaScript? 
Code that runs inside NativeClient has the same access level as JavaScript
does. It's just a way to do things faster.
Distribution as a Chrome app via the Chrome store is a fine approach, as
long as people understand it's just an app platform like any other. It has
pros and cons that must be weighed up. For instance, Chrome for mobile
doesn't really do apps, at least not at the moment. Also, you're still
limited by what APIs Chrome exposes, which are a strict subset of what a
real OS provides.

@_date: 2013-08-09 14:14:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SPV client in pure JavaScript? 
Oh, I forgot to make it clear - Chrome apps/extensions can make raw TCP
socket connections:
   You would do it as a packaged app:
  because then they're a
lot more similar to native apps (they get their own windows, run offline,
But these aren't standard APIs. They're all Chrome extensions. I doubt
HTML5 will support USB access anytime soon, for instance, but packaged apps

@_date: 2013-08-09 21:58:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Optional "wallet-linkable" address format 
Payment protocol is locked down for v1 already. But did you read it? It
doesn't use addresses anywhere. Payments are specified in terms of a list
of outputs which can contain any script. Of course it could be a
pay-to-address script, but pay-to-address uses more bytes in the chain and
there isn't any typeability benefit.
The multiplication trick for deterministic keys is a nice one and worth
doing, but it has to be a v2 feature by this point. It's more important to
get v1 widely implemented and deployed first.

@_date: 2013-08-09 22:35:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Optional "wallet-linkable" address format 
It's BIP specified and implemented in Bitcoin-Qt so now is the time to
start :) I'm hoping that most wallets can announce support near
simultaneously ....

@_date: 2013-08-11 18:28:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Android key rotation 
Hash: SHA512
I hope you are having a pleasant weekend. A few days ago we learned
that the Android implementation of the Java SecureRandom class
contains multiple severe vulnerabilities. As a result all private keys
generated on Android phones/tablets are weak and some signatures have
been observed to have colliding R values, allowing the private key to
be solved and money to be stolen.
The public security alert is here:
I will shortly post in the bitcointalk forums as well.
An update for the Bitcoin Wallet app has been prepared that bypasses
the system SecureRandom implementation and reads directly from
All unspent outputs in the wallet are then respent to this new key.
The process is automatic and does not involve user intervention.
Andreas can control the process via a percentage throttle, which we
will use to slow things down if the memory pool load gets too high.
A fixed APK is available here:
Andreas plans to release this to beta either today or tomorrow. Once
some reasonable population of users has completed testing the
automated re-keying process, it will be released via the Play Store.
All users will get a notification informing them of the new version
and some will be upgraded automatically.
Other wallet maintainers have also been notified and are working on
similar updates.
- -mike

@_date: 2013-08-14 14:26:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.10 
I'm pleased to announce version 0.10 of bitcoinj, a Java library for
writing Bitcoin applications. BitcoinJ has been used to create everything
from end-user wallet apps to network crawlers to SatoshiDice.
To learn how to obtain bitcoinj 0.10, please see the following page:
   The v0.10 release is signed by Andreas Schildbach's GPG key. The git hash
of the release is 777e6781d789. This paragraph is signed by the same
Bitcoin key as with previous releases (check their release announcements to
establish continuity).
Signature: H9Nl7FPnmrUOmjhUZ0+xB4YW3q5F5gIkGdvllsDWmWYvOkNQHAE9jZE0I/qE1VfLPeMV+Rzo7geTB43uDSFSMek=
*New in this release*
   - An implementation of *micropayment channels* was added. There have
   been many bugfixes and improvements since the first announcement. This
   feature allows you to set up a 1:1 payment relationship with a remote
   server and after a short setup process send very tiny payments, very
   rapidly. It's suitable for metered billing applications. An article,
   "Working with micropayments" explains how to use it. This work was a joint
   effort between Matt and myself.
   - A simple sublibrary has been added that provides async IO based
   client/server classes that transmit length prefixed protocol buffers.
   - Thanks to Matija Mazi, some classes have been added that implement *the
   BIP 32 deterministic wallet algorithm*. Note that these classes are not
   yet used elsewhere in the system and full deterministic wallet support is
   therefore not available, however, a low level API is available for
   experimentation. That API is very likely to change in future releases so
   don't get too attached to it.
   - Thanks to Gary Rowe, we have integrated *a new Maven plugin* that
   checks the SHA1 hashes of downloaded dependencies against a hard-coded
   list. This means that even if an upstream Maven repository or developer
   were to be compromised, library dependencies could not be switched out for
   corrupted versions without someone noticing. For 0.10 the dependency hashes
   were just initialised based on what was already downloaded. In future,
   reproducible builds of upstream dependencies and auditing of changes would
   provide better security. You can and should use Gary's
plugin in
   your own projects to defend against a possible compromise of the bitcoinj
   repository.
   - *Callback handling* has been much improved. Each event listener can
   have an Executor specified which takes responsibility for running the
   callback. If you don't specify one they run by default on a single
   background thread, the "user thread", instead of the origin framework
   threads. This means your callbacks no longer need to be thread safe as
   they're always run serially. You can also change the default executor if
   you would like to control the thread on which callbacks run, for example to
   marshal them into your GUI toolkit thread automatically. This fixes some of
   the most painful parts of the pre-0.10 API, for instance that transaction
   confidence listeners were not allowed to re-enter the library.
   - *Exception handling* has also improved. You can assign a global
   Thread.UncaughtExceptionHandler which receives any exceptions thrown on
   the user thread (i.e. by your own event listeners), as well as any internal
   exceptions thrown by network threads (like inability to parse a message
   sent by a remote peer). Because your listeners now run on a separate thread
   by default, you can no longer accidentally cause internal data corruption
   or prevent other callbacks from running by leaking exceptions out of your
   callbacks; a subtle knife-edge in the previous API.
   - Support for *automatic wallet key rotation* has been added.
   - We now require Bloom-capable (0.8+) peers by default and will
   disconnect from older nodes. This avoids accidental bandwidth saturation on
   mobile devices.
   - The wallet now accepts timelocked transactions if it created them
   itself.
   - The wallet can be told to empty itself out, in which case the fee will
   be subtracted from the total amount instead of added. This simplifies the
   common case of wanting to send your entire balance whilst still including a
   fee.
   - Some JNI peers for event listeners were added. Auto-generated JNI
   bindings are experimental and not yet merged in to the mainline codebase:
   for now they are available as part of a separate project on github. This
   work allows you to access the bitcoinj API using relatively natural looking
   C++ code and an embedded JVM.
   - You can now register custom PeerFilterProvider implementors to add
   things to Bloom filters that aren't necessarily in wallets.
   - We have begun adding nullity annotations to the API. Combined with a
   strong static analysis engine like FindBugs or the IntelliJ Inspector, you
   can find cases where you aren't handling possible null pointers. Note that
   you should configure your static analysis system to understand the Guava
   Preconditions assertions, as otherwise you will get false positives.
   - You can now control how much information Wallet toString() dumps
   contain more precisely. Extensions can contribute to a wallets debug dump
   as well, and transaction data is now optional.
   - Documentation: The getting started tutorial and PingService example
   were rewritten. New articles were added that cover optimising chain sync
   and using the library from non-Java languages. Existing articles were also
   extended and refreshed.
   - Many bug fixes and new methods. You should upgrade as soon as possible
   to get the bug fixes, in particular, one that could cause transactions
   inside the same block to be incorrectly re-ordered when using Bloom
   filtering (which can affect the wallet). The library code now has more
   internal annotations to help static analysis engines, and several bugs were
   fixed as a result of that.
*API Changes*
   - The ScriptBuilder class now takes TransactionSignature objects, these
   wrap a raw ECDSA signature and the SIGHASH flags together, with utility
   methods to work with them.
   - The Locks class has been renamed to Threading. The thread on which
   callbacks run has been changed, see above.
   - The WalletEventListener.onKeyAdded method became onKeysAdded and now
   takes a list, to make processing of bulk adds more efficient.
   - BitcoinURIParseException is now checked so you can't forget to handle
   bogus URIs.
   - The Wallet.toString(..) method has additional parameters now so you
   can control what is included in the dump.
*Known issues*
Please see the limitations and missing
features page.
This page has been fleshed out since the last release with common issues
and missing features. A few issues were also fixed and removed.

@_date: 2013-08-15 10:09:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Version 0.9 goals 
Sounds awesome!
Pieter told me at lunch that headers first cut sync time to 45 minutes for
him, which is another amazing improvement from the master of optimisations.
Pieter, Matt and I also agreed that for maximum impact we should really try
to ship payment protocol support in at least two clients simultaneously and
ideally with a big merchant signed up too - to send a powerful message that
we really mean it. Someone volunteered last week to do it for bitcoinj and
if he doesn't pull through, I have some old code from EOY 2012 that I could
update to the latest spec and ship at least some basic support. I'd hope
that we can get Bitcoin Wallet or MultiBit updates out once bcj has support
pretty fast.
Also, Jeff said that BitPay want to be a leader in support for the
protocol. So let's try and co-ordinate release dates so we can make a bit
of a splash and grab the ecosystems attention.
Sounds brilliant. It'll be nice to see the pull request queue drain. Any
ideas what the non-0.9 code will be? Fee rework? DoS work?

@_date: 2013-08-15 11:02:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Version 0.9 goals 
Yup, that's always been the plan :-)
Any idea how much work it is, and would it be a v1 feature of the Trezor or
added later via firmware update?

@_date: 2013-08-15 17:22:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Version 0.9 goals 
Yeah, OK. Let's see how much progress Gary makes. Supporting HD wallets is
the trickiest part and I don't know how much time I will have - the Android
RNG issue and getting bcj 0.10 released have sucked up a lot of my time
lately and I need to refocus on other things for a bit. But between the guy
who volunteered to do payment protocol, and Gary doing TrezorJ, and Matija
already having done the core algorithms, I'm hoping the only parts I'll
have to do are integrating the HD code with the core wallet code. Possibly
if we're running out of time I can do a real basic HD wallet implementation
that only iterates a key once and doesn't generate new keys for each
transaction, as that's really the trickiest part (because of the need for
lookahead/behind and memory bloat on phones).

@_date: 2013-08-16 13:32:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 32.5 
I filed a bug in the bitcoinj tracker for this a few days ago referencing
rfc 6967, but that RFC is very complicated and I'm not sure it's really
necessary to go that far. H(sighash||key) is easy to implement and I feel I
understand it better.
In our case it wouldn't have helped anyway - if anything it would just
delayed discovery of the underlying weakness. The same RNG is typically
used to generate both keys and signatures today. However in future it may
be the case that people put more effort into generating a really random key
because they only have to do it once, and then the signing RNG would be
Your concern about hardware devices leaking private key bits via a side
channel is also well made, although I think you have to find some way to
establish trust in these devices anyway as sniffing all their IO traffic
and analysing it is really hard (plus it inverts the threat model - if you
trust your computer and not your hardware wallet, why do you have a
hardware wallet?)
The other advantage is that deterministic keys and signatures together mean
two instances of the same wallet generate identical transactions given an
identical sequence of commands. This could help keep wallets in sync. For
example we had a few users who got confused because they had cloned their
Android wallets across devices (NOT SUPPORTED!) and then one device updated
first, did key rotation, and then the other device showed a transaction
that sent all their money to a new address it knew nothing about. If they
didn't realise the other device had updated this looked identical to theft!
I don't think fractional BIP numbers are the way to go :) but a new BIP
that standardised a way to select K would, if reviewed, be something I'd

@_date: 2013-08-16 14:11:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Gavin's post-0.9 TODO list... 
Cool. Maybe it's time for another development update on the foundation blog?

@_date: 2013-08-16 14:24:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Gavin's post-0.9 TODO list... 
The only other thing I'd like to see there is the start of a new anti-DoS
framework. I think once the outline is in place other people will be able
to fill it in appropriately. But the current framework has to be left
If I had to choose one thing to evict to make time for that, it'd be the
whitepapers. At the moment we still have plenty of headroom in block sizes,
even post April. It can probably be safely delayed for a while.

@_date: 2013-08-16 15:46:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Gavin's post-0.9 TODO list... 
A ban-subnet RPC would be a reasonable addition, but obviously DoS
attackers that are IP or bandwidth constrained are really just script
kiddies. Also anything that involves every node operator doing manual
intervention rather works against decentralisation and having a big
network. That's why I keep pushing for automated heuristic driven

@_date: 2013-08-16 16:36:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Gavin's post-0.9 TODO list... 
That change was made in response to user complaints. Heck we get complaints
about battery life and bandwidth impact even with Bloom filtering. We can't
just randomly start using peoples bandwidth for relaying blocks, especially
as I guess most SPV nodes are behind NAT.
If Gavin is right and the future is dominated by mobiles and tablets, then
it will require a change of thinking in how P2P networks work. I think
there are plenty of people with private servers who would be willing to run
nodes though. I'm not too worried about this.

@_date: 2013-08-16 17:11:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Gavin's post-0.9 TODO list... 
Not sure - it could be investigated. I think UPNP is an entirely
userspace-implementable protocol, so in theory it could be done by a
userspace library (even libminiupnp - java is not a requirement on android)
I suspect you mean "I think lots of people do that". I'm not so sure. We
could potentially run an experiment in the Android app to measure how many
users are in a position to contribute back, but just because you have wifi
doesn't mean you can reconfigure it using UPnP. That helps a lot in home
networks, but at the office it doesn't help.
I'm wary of a ton of work being put in to achieve not very much here.
Satoshi's original vision was always that millions of users were supported
by 100,000 or so nodes. I don't think that's unreasonable over the long
Besides, prioritisation isn't very hard. Nodes can just hand clients a
signed timestamp which they remember. When re-connecting, the signed
timestamp is handed back to the node and it gives priority to those with
old timestamps. No state is required on the node side. Signing and checking
can be passed onto the general ECDSA thread pool that works its way through
pending signature operations, they'd be prioritised lower than checking

@_date: 2013-08-16 17:13:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Gavin's post-0.9 TODO list... 
Oops, hit send too early.
Besides, prioritisation isn't very hard. Nodes can just hand clients a
The other nice thing about this approach, besides being stateless on the
server side, is that it's up to the client whether or not they present the
cookie. So the node can say "if you don't present your cookie I'm going to
disconnect you" but when the node has sufficient resources, it'd just not
request this and the client remains anonymous. If the client thinks the
server is calling its bluff, it can just wait and see if it really does get
disconnected and if so, present the cookie up front next time.

@_date: 2013-08-17 14:35:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Gavin's post-0.9 TODO list... 
There shouldn't be a "smaller subset of Bloom filtering nodes" because the
idea of making it optional is a stupid one.
If you're worried about DoS, come up with real fixes instead of trying to
break features that work.

@_date: 2013-08-19 00:00:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] NODE_BLOOM BIP 
The original Bloom filtering spec did not make this feature optional for
the same reason gzip isn't an optional part of the PNG specification. I see
no reason to revisit that. It's definitely not the case that making every
possible feature optional is smart design, often it's the opposite.
If in future there are nodes that for some reason can't technically support
this feature, then there'd be a stronger rationale for something like this.
However no such nodes exist, nor are they likely to in future given that
it's a simple feature to implement.
For these reason I oppose this BIP.

@_date: 2013-08-19 11:16:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Gavin's post-0.9 TODO list... 
On Mon, Aug 19, 2013 at 5:09 AM, John Dillon
Unconfirmed transactions that are received show up as unspendable and in
most wallets they have a little graphic that changes as more peers announce
the tx. So if a peer sent non-existent transactions then they'd allow show
up as seen by only one peer, which would look different to how normal
broadcast transactions show up.
Whether users really notice this graphic or understand what it means is
debatable, of course, but all Bitcoin wallets have that problem. I've yet
to see any that would successfully communicate the notion of confidence to
new, untrained users. That's why the default is to not let you spend
unconfirmed transactions, unless they were created by yourself (you're
allowed to spend change).
bitcoinj does not attempt to handle DoS attacks by malicious remote peers
today, because such an attack has never been observed, has no obvious
profit motive and as you don't get to choose which nodes the wallets
connect to it'd be difficult to pull off. Unless you control the users
internet connection of course, but that's a well known caveat which is
documented on the website.

@_date: 2013-08-19 11:29:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bloom io attack effectiveness 
Well, I'm glad we're making progress towards this kind of model :)
If I had to write a scoring function for node importance, I'd start by
making nodes I connected to more important than nodes that connected to me.
That should prevent the kind of attacks you're talking about. You can then
score within those subsets with greater subtlety, like using how long the
connection has been active (or extending that with signed timestamps).
This doesn't have any in-built bias against SPV nodes, which is probably
very hard to technically implement anyway. But it encodes the intuitive
notion that nodes I selected myself are less likely to be DoS attackers
than nodes which connected to me.
But the trick is to implement the prioritisation code. The usual way to do
this is to have a thread pool that pops requests off a queue. You can
either have multiple queues for different priority bands, or code that
locks the queue and re-orders it when something new is added. I tend to
find the multiple queues approach simpler, especially, it's simpler to
export statistics about that via RPC that make it easy to understand what's
going on underneath the hood.
So IMHO a patch to address I/O exhaustion should look something like this:
   1. Add a thread pool of 2-3 threads (to give the kernel room to overlap
   IO) which take in CBlock load requests and then do the load/parse/filter in
   the background.
   2. Each thread starts by blocking on a counting semaphore which
   represents the total number of requests.
   3. The network thread message loop is adjusted so it can receive some
   kind of futures/callbacks/closure object (I guess Boost provides this,
   alternatively we could switch to using C++11). The closures should also
   have the score of the node they were created for (note: score not a CNode*
   as that complicates memory management).
   4. At the start of the network loop a thread-local (or global) variable
   is set that contains the nodes current score, which is just an n-of-m score
   where M is the total number of connected nodes and N is the ranked
   importance. At that point any code that needs to prioritise nodes off
   against each other can just check that variable whilst doing work. The
   network loop looks at which file descriptors are select()able and their
   scores, which closures are pending execution and their scores, then decides
   whether to handle new network data or run a closure. If there is a draw
   between the scores, closures take priority to reduce memory pressure and
   lower latency.
   5. Handling of "getdata" then ends up calling a function that requests a
   load of a block from disk, and runs a closure when it's finished. The
   closure inherits the nodes current score, of course, so when the block load
   is completed execution of the rest of the getdata handling takes priority
   over handling new traffic from network nodes. When the closure executes, it
   writes the loaded/filtered data out over the network socket and deletes
The function that takes a CBlockIndex and yields a future or
closure or whatever would internally lock the job queue(s), add the new
task and then do a stable sort of the queue using the scoring function,
which in this case would simply use the node score as the job score.
It's a fair amount of work, but should ensure that "good" nodes outcompete
"bad" nodes for disk IO. Any other disk IO operations can be done in the
same way. Note that the bulk of LevelDB write work is already handled on a
background thread. The foreground thread only writes a log entry to disk
and updates some in-memory data structures.

@_date: 2013-08-20 12:05:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
I think the confidence of the tx is not really the users concern anyway.
They wrote it so they know it's valid. If the merchant disagrees for some
reason then the user can find out, out of band when the goods/services are
not delivered.

@_date: 2013-08-22 15:33:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: remove "getwork" RPC from 
That would be annoying for testing. Regtest mode allows you to create a new
block by just running "setgenerate true" (it switches itself off after
creating a block). If you had to set up a complicated set of separate
programs just to do regtest mode that'd be a step backwards, IMO.

@_date: 2013-12-01 12:51:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Lately I was pondering how to make floating fees and SPV wallets work well
I propose the following plan:
1) 0.9 ships with something dead simple, like a command to query what a
node estimates and then clients just take the average, or cross-check a
centralised estimate against the P2P network. It's fast to implement and
simple, but not very secure or decentralised. However it will allow the
feature to launch on some kind of reasonable timeframe.
2) We bump the protocol version and the tx message now gets an optional
protobuf buffer stuck on the end. The first thing put in this protobuf is a
list of the values of the inputs. Using this data, the fee paid by a
transaction can be calculated. In step 2 the data is unauthenticated.
3) Some SPV wallets already set themselves up so that they sync with the
network in the background, e.g. the Android wallet syncs at least every 24
hours. This should become more common, using scheduler capabilities built
into most operating systems. When the wallet syncs with the network, it
sets a deliberately very noisy Bloom filter on its peers and waits around
for 30-60 seconds or so. The wallet observes some of the broadcasts taking
place and records the hashes and associated fees that were paid to disk.
Next time it syncs, it includes the observed hashes into the Bloom filter
used to download the chain, and thus learns how quickly they confirmed. It
can calculate its own fee estimate from that.
4) Finally, when we next hard fork, we make v2 transactions include the
output value in the signature, same as the output script (this proposal has
been on the forums for a while now). That allows the fee data added in step
2 to be cross-checked against the signatures on the inputs, thus
authenticating it.
I think this is a small and easy set of steps that would make it quite hard
to attack - malicious nodes could make it appear that some transactions
never confirmed thus seeming to force the price up, but it's easy to simply
exclude transactions which never confirm at all from the calculations. Plus
of course you can cross-check nodes against each other to try and catch
nodes that are failing to match transactions properly.
One obvious concern is what to do if nodes don't converge on very similar
estimates. Wallets will always want to pay the lowest fee possible, so that
means they'll always be riding the very edge of what's acceptable, opening
up tx propagation to random flaky failures if fee estimates change whilst a
transaction is in progress, or if some nodes don't calculate the same
estimates as others.
If a wallet gets a reject message for a tx that has a fee that are by its
own estimates acceptable, what should it do? What if only some nodes report
that and others don't?

@_date: 2013-12-01 14:41:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Unfortunately there are risks to that approach. The most obvious one is that nodes could keep sending reject messages to get wallets to attach ridiculously high fees. If half a wallets peers do this and the other half don?t, then effectively the wallet will double spend against itself. The bad nodes can keep the fat transaction and send it directly to a corrupt miner, no broadcast. If some other miner includes the original normal transaction, no problem, just take it out of the current block. If the corrupt miner finds the current block, they get to claim huge fee premiums.
Quite apart from the problem of malicious nodes/miners, how would you represent this in the wallet GUI? Current wallets are designed on the assumption that 1 payment == 1 transaction == 1 paid fee. If a single payment could have several different fees, and there?s no way to know which you will actually pay until later, then complexity would explode. Even the notion of balance would become even more complicated than it already is.
So I really don?t like the idea of creating different transactions depending on error messages from remote nodes. The only time when it could make sense is if *all* nodes reject a transaction. Then (assuming no MITM) you can assume the first transaction can be thrown away and a new attempt made.
But if you think about what the UI flows for that would look like - it?s just a mess.
There are other risks to fee estimation. Let?s say wallet authors create transactions with exactly the estimated fee needed to get into the next block. But due to mempool skew, estimates vary, and so those transactions don?t propagate cleanly everywhere. Now we have two problems:
1) Unpredictable failure to enter the mempools can lead to double spending and slow confirmations
2) Wallet authors may be tempted to ensure that doesn?t happen by taking the estimate, adding 10% and using that. But then if a bunch of popular wallets all do the same thing, the estimation algorithm might get confused and decide that as everyone seems to be attaching a fee of X+10%, the correct estimate for what fee to attach is X+10%. Then wallets would immediate raise their attached fees again and you?d enter into a infinite upward spiral.
The more I think about this, the more complicated it gets.
It?s tempting to try and just push all the complexity onto the merchant side, but one of the best things about Bitcoin is there isn?t any strong notion of ?merchant? - that?s inherent to being peer to peer. So just hand-waving and saying sellers will deal with complicated fee processes is just a punt.

@_date: 2013-12-01 18:19:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
What would the new messages say?
We need to get away from the notion of senders attaching fees anyway. This is the wrong way around because it?s the recipient who cares about double spending risk, not the sender. That?s why merchants keep running into issues with people attaching zero fees. Of course they attach zero fees. They know they aren?t going to double spend. It?s the merchant who cares about getting the security against that.
The UI for sending money should end up dead simple - no mention of fees anywhere, IMO.
The UI for receiving money could be a bit more complicated but even then - I think if ordinary people using smartphone wallets are having to think about how quickly they want their transaction to confirm and adjust fees, etc on the receiving side then we?re getting dangerously close to the usability failure zone.
Unfortunately we lack the protocol pieces to get the right UI here :( Someone needs to sit down and figure out what the UI *should* look like, in the ideal world, and then work backwards to figure out what needs to be done to get us there.
Disagree. There should never be any cases in which a transaction doesn?t confirm. Period. I know there have been bugs with bitcoinj that could cause this in the past, but they were bugs and they got fixed/will get fixed.
Settlement failure is just unacceptable and building a UI around the possibility will just encourage people to think of it as normal, when it should not be so.

@_date: 2013-12-01 18:52:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
That seems reasonable.
The other message should be implementable today, I think? If numBroadcastPeers > 0 post 0.10.3 then you know the tx made it out to the internet.
Unfortunately if nodes start to diverge a lot in terms of what they will accept, then ?transmitted? is no longer a clean binary yes/no thing. Guess we?ll have to jump that hurdle when we come to it.
The payment protocol at least would need some notion of fee, or possibly (better?) the ability for a recipient to specify some inputs as well as some outputs.
Originally I think we were hoping for child-pays-for-parent. I guess that needs someone to sit down and focus on it for a while, assuming we still think that?s a good idea.

@_date: 2013-12-01 19:18:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
I agree in the general case, but I was talking about the mobile wallet case specifically (i.e. people who are sending money between themselves or making small purchases of physical things). I think Bitcoin should be able to scale to handle these sorts of ordinary every-day transactions. Where I?d expect to see transactions falling off the edge is in more specialised cases like very small single micropayments, or ?optional? internal transactions like mixing/re/defragmentation of wallets that don?t correspond to an actual payment. Those sorts of transactions would I guess be the first to go when faced with a sudden capacity crunch, but they wouldn?t show up in a mobile wallet UI anyway.
I know the existing code is, but is that fundamentally the case or just how the code has been written? I haven?t looked at this issue much but I know you?ve worked on it, so I?m curious to learn about why it?s inefficient and whether there are any fixes possible.

@_date: 2013-12-02 15:33:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Right, as I said earlier:
"The payment protocol at least would need some notion of fee, or possibly
(better?) the ability for a recipient to specify some inputs as well as
some outputs."
Having thought about it a bit more, I think it's better to just have a fee
field that lets the receiver request the sender to attach the given fee.
The outputs would have less value associated with them, so effectively the
seller folds the fee into the price. If the seller is charging a round
price like 1 mBTC, the user sees "1 mBTC" as the price, even if behind the
scenes the created tx only sends 0.99999 BTC
Allowing specification of inputs seems to add too much complexity in other
cases, like when value isn't specified at all.

@_date: 2013-12-02 15:44:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
PPv1 doesn't have any notion of fee unfortunately. I suppose it could be
added easily, but we also need to launch the existing feature set.
There's code pending review to implement PPv1 in bitcoinj, unfortunately
it's currently not passing unit tests and the author can't figure out why.
I didn't have time to debug it yet myself. I'm hopeful we can get it
working and merged by EOY.
It may be time to start talking about timelines for 0.9. I am wondering if
floating fees should be broken out of the 0.9 release and launched in a
quick 0.10 followup - if that were to be done then I think 0.9 could go to
beta relatively soon, like early next year. There have been a lot of
improvements already and it'd be a shame to block them all further.

@_date: 2013-12-03 11:06:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Let's just use a normal/low tag number. The extensions mechanism is great
for people who want to extend the protocol outside the core development
process. It'd be weird if nobody ever used the low numbers again though.
Tag numbers are varint encoded so using smaller ones does have a minor
efficiency benefit, it's not just aesthetics :)
Hmmm. Why "allow"? Should it not be called min_fee instead? Wallets would
have to attach at least that much in fees, right?
Also, why describe it as reducing the amount paid? Which output would be
reduced in value? Why not just have it be added to the total value
displayed to the user and the outputs are left alone/not reduced.
I like the idea but it seems this gets us back to the original problem -
senders don't care about confirmations, ever, not even if they make an
annoying set of transactions. The protocol allows users to submit
transactions directly to receivers, I guess, if the receiver does not like
the transactions they get they could potentially reject the payment. But
I'd hope that's really rare.
Sweet, thanks!

@_date: 2013-12-03 11:45:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Senders have no interest in ever attaching any kind of fee, which is one
reason we explored child-pays-for-parent for a while. It's not the sender
who cares about double spending risk. Left to their own devices, all
senders would always attach no fee at all (or rather: whatever the min was
to get the transaction relayed to the merchant).
However, receivers do want a fee attached, and ideally we would do this
without redundant transactions. Hence, receivers asking senders to attach a
fee and effectively folding it into the price that is paid. That is, if you
go into a restaurant and the menu says "Burger: 10mBTC" then when you come
to pay, what you see on your phone screen is 10mBTC. The fact that actually
the shop with receiver 9.9mBTC and the tx fee is 0.1mBTC is hidden in the
user interface - creating a situation like many others, where receivers eat
a transaction cost. For instance in Europe sales taxes are included in the
price, not attached separately later.
There's no need to trust the vendor. If a vendor asks for a ridiculously
high tx fee, it will just surface as uncompetitively priced goods/services.
Buyers will go elsewhere.
That's what fee estimation does, essentially, minus the encoding into
blocks. Once you start getting miners telling people what fees are directly
you run into cases where they might try to lie about their behaviour or
otherwise influence the average. Querying all nodes avoids that problem.

@_date: 2013-12-03 12:29:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Wouldn't the idea be that the user always sees 10mBTC no matter what, but
the receiver may receive less if the user decides to pay with a huge
It may be acceptable that receivers don't always receive exactly what they
requested, at least for person-to-business transactions.  For
person-to-person transactions of course any fee at all is confusing because
you intuitively expect that if you send 1 mBTC, then 1 mBTC will arrive the
other end. I wonder if we'll end up in a world where buying things from
shops involves paying fees, and (more occasional?) person-to-person
transactions tend to be free and people just understand that the money
isn't going to be spendable for a while. Or alternatively that wallets let
you override the safeguards on spending unconfirmed coins when the user is
sure that they trust the sender.

@_date: 2013-12-03 12:46:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
A merchant can always refuse the payment and refund it if that's a
practical problem. I doubt it would be though. If a user is trying to buy
something from the merchant, they will want it to work, and it'll be up to
the developers of the wallet they're using to ensure it never does anything
obnoxious or unacceptable that would result in people hating to receive
money from that app.
Sure. I think there will be experimentation in this regard.

@_date: 2013-12-03 14:20:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Lots and lots of people are psychologically trained to expect that they pay
the sticker price for things. Yes in recent times some places have started
to show additional fees for using credit cards, but only as a way to try
and push people onto cheaper forms of payment, not because customers love
surcharges. It's for that reason that many merchants don't do this, even
when they could - I pay for things with Maestro Debit all the time and I
don't think I've ever seen a surcharge. That system obviously has costs,
but they're included.
This is just a basic cultural thing - when I buy something from a shop, the
social expectation is that the seller should be grateful for receiving my
money. "The customer is always right". When I send money to a friend, the
social expectation is different. If my friend said, hey Mike, could you
send me that 10 bucks you owe me from last weekend and what he receives is
less than 10 bucks, he would probably feel annoyed - if I owe him 10 bucks
then I owe him 10 bucks and it's my job the cover the fees. That's why
PayPal makes sender pay fees in that case.
Maybe we need new terminology for this. *Interior fees* for included in the
price/receiver pays and *exterior fees* for excluded from the price/sender
Fees are only confusing because existing clients do a terrible job of
Have you thought through the UI for that in detail? How exactly are you
going to explain the fee structure? Let the user pick the number of blocks
they need to wait for? What's a block? Why should I care? Why shouldn't I
just set the slider all the way to the other end and pay no fees at all? Is
the merchant going to refuse to take my payment? Gavin just said that's not
possible with Bitcoin-Qt. I'm thinking for bitcoinj I might go in a
slightly different direction and not broadcast payments submitted via the
payment protocol (and definitely not have one wire tx pay multiple payment
requests simultaneously, at least not for consumer wallets).

@_date: 2013-12-03 14:54:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Heh. People feel rises in sales tax elsewhere too. When VAT rises merchants
all raise their prices, they don't normally swallow it (or if they do, they
make a big fuss over how awesome they are).
The US system is a complete pain in the ass. You never know how much money
you actually need to pay for anything unless you happen to know the local
rate and do the multiplication in your head. There's a reason this system
is not used in big chunks of the world economy.
I would love to know how to do it. If you have an intuitive GUI in mind
please show us so other wallet authors can copy it :)

@_date: 2013-12-04 11:40:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
I think this US/other cultural issue is complicating things more than we
I am trying to imagine in my head how all this will work and what it will
look like with allow_fee, and I just can't see it. Merchants want customers
to pay the sticker price, deviance from that social norm is extremely rare
even after the credit card company contracts that required it have been
invalidated. The only time it happens to me is when buying flight tickets
with credit cards: but it's only for that method, other payment methods are
still treated as "free" a.k.a interior fees.
If you walk into a physical shop and try to pay a large bill with bags of
pennies, the merchant won't enter into a complicated agreement where they
agree to split the cost of processing with you. They will just reject the
payment out of hand and tell you to get real. It has to be that way because
otherwise the shop would carry the cost of counting all the pennies and
hauling them around, not the buyer (who "knows" he put the right number of
pennies in the bags).
As a buyer, I do not care about whether my transaction will confirm. If I
try to pay with dust, there is no incentive for me to attach a higher fee
than allow_fee to make that confirm, especially if the merchant has no way
to reject the payment. What's more, as Jeremy points out, no clean fail
mechanism means large piles of manual work and lots of disputes due to
payments not clearing before the exchange rate shifts and other things like
Trying to make the success of payment confirmation a two-person dance seems
to have so many edge cases it makes my head hurt. For most pay-to-merchant
cases, it has to be the receivers job to get a transaction confirmed, and
if the sender doesn't follow the instructions a payment should hard fail
and require trying again. If Bitcoin-Qt can't handle that today, that does
seem like a problem.
In the case of a transaction with too-low fee, either the payer can
You can't do that. When a tx doesn't have the right fee attached you're out
of luck today, except for the fact that some pools run with a custom child
pays for parent patch. So respending it would bump priority for some miners
and not others.

@_date: 2013-12-04 12:09:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Please don't try and drag this thread off topic. What I said is factually
correct. If you want to (again) try and convince people things should work
differently, start another thread for that.

@_date: 2013-12-04 14:48:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
The original proposal I started this thread with hasn't even received
comments - presumably it's uncontroversial. The other discussions are about
how to handle fees in requests that use the payment protocol, which isn't
currently used anywhere so doing things differently isn't possible.
On the other hand you have been talking about a fundamental change to the
behaviour of how all Bitcoin nodes operate, which is off topic for this
If you have something specific to say about how floating fees should be
managed by SPV wallets or how fees should be negotiated when the payment
protocol is in use, this thread is appropriate. Otherwise please take it

@_date: 2013-12-08 21:28:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Dedicated server for bitcoin.org, 
Issues that would need to be resolved:
1) Who pays for it? Most obvious answer: Foundation. However there's
currently a fairly clear line between the foundation website and the
bitcoin.org website. I personally am fine with the bitcoin foundation
funding the website, it's a lot closer to the bitcoin community than
github. But some people might care. So next step would be to contact the
Foundation board and see if they're willing to fund it.
2) Anti-DoS? I assume github handles this at the moment, though I doubt
there's anything to be gained from DoSing the informational website
3) Where does the server go? Ideally, a hosting provider that accepts
Bitcoin of course!
4) Who admins it?
5) Who controls DNS for it?
Right now I think Sirius still owns DNS for bitcoin.org which is nonsense.
He needs to pass it on to someone who is actually still involved with the
project. Again, the most obvious neutral candidate would be the Foundation.
So I think it's a good idea but there's a fair amount of work here. The
primary upside I see is that it opens the potential for adding
interactive/server-side code in future if we decide that would be useful.

@_date: 2013-12-09 00:03:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Dedicated server for bitcoin.org, 
It's done that way because it was originally registered by Satoshi. It's
now controlled by Sirius, who doesn't really take part in the project
I bring this up because of the recent bitcointalk fiasco. AFAIK the domains
are registered and controlled in the same way. It's likely that the current
registrar isn't very secure.

@_date: 2013-12-12 08:03:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Merge avoidance and P2P connection encryption 
I wrote an article intended for a broad/non-developer audience on a few
Bitcoin privacy topics:
- P2P connection encryption
- Address re-use/payment protocol
- CoinJoin and merge avoidance
I don't think there's anything much new here for people who were involved
with the BIP70 design discussions, but it may prove a useful resource when
talking about privacy features in the payment protocol. Specifically the
ability to request multiple outputs and submit multiple transactions that
satisfy them. The article elaborates on how to use that feature to achieve
some useful privacy outcomes.
I also analyze what using SSL for P2P connections would buy us and what it

@_date: 2013-12-12 10:24:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Merge avoidance and P2P connection 
I think the right way to integrate BIP32 and BIP70 would be to specify
output scripts as normal for backwards compatibility, and then allow each
output to have an additional xpubkey and iteration count field. The
iteration counts could be unsigned.
Unfortunately to add data that isn't signed requires a backwards
incompatible change to the protocol :( There isn't currently any area that
isn't covered by the signature. We would have to add one, and then have a
matching array of iteration counts for each xpubkey that was specified in
the output.
I wonder if we should make a last minute change to BIP70 before wallets
have shipped and merchant support starts, something like
message PaymentRequest {
  optional byte unsigned_data = 6;
that would be deleted like the signature is before reserialization.

@_date: 2013-12-13 09:26:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Merge avoidance and P2P connection 
I'm thinking about a use case I hope will become common next year -
pastebin style hosting sites for payment requests. Like, if I as a regular
end user wish to use the payment protocol, I could just upload a (possibly
signed) payment request to:
or whatever, and then payr.com can take care of incrementing the iteration
count on each download of my file. That's why it's useful for it to be
Absolutely. The two use cases can both be supported. You could give
iteration ranges, for instance, if you want to specify expiry in terms of
number of payments rather than time.

@_date: 2013-12-13 13:49:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Merge avoidance and P2P connection 
But how does that show up in the user interface? I don't know how you would
explain what the signature means or implies, or what you do if the
signature is broken/missing.
The only thing that a maliciously modified iteration count can do is cause
money to be sent to an address that's beyond the recipients gap limit,
meaning they won't receive it (unless they reconfigure their software and
rescan). But you can't steal money that way.

@_date: 2013-12-16 19:26:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fees UI warning 
Jim seems to be planning some parallel development to what I'm doing, but
HD wallets and stopping address re-use is the current feature I'm working
on for bitcoinj. Only code review and merging takes higher priority at the
moment. So I think we might be able to stop re-using addresses at least on
devices with sufficient memory some time in Q1

@_date: 2013-12-16 19:28:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fees UI warning 
Most good wallets have UI's designed to be safe. Unfortunately this guy was
using brainwallet.org which is by no means a "good" wallet in that sense
(it's not really even a wallet app at all)
I think most of us have expressed displeasure at the existence of this site
before, and I once even asked the guy to stop running it, but he refused.
It's an extremely sharp tool which makes it easy to cut yourself, except it
doesn't look dangerous, it looks like ordinary software designed for
ordinary people.
I don't know how to solve this. Badly designed software that looks
appealing will always be a danger.

@_date: 2013-12-24 18:15:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Peer Discovery and Overlay 
Thanks Warren! That's great. It's also a prerequisite for chain pruning, so
it's not only about decentralisation but also scalability.
Looking forward to reviewing and merging that.

@_date: 2013-12-27 18:05:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Testnet block explorer 
For a long time the only block explorer for testnet has been the original
blockexplorer.com, which is unfortunately often broken / behind / slow and
not really maintained any more.
There is now a new one, here:
There's also a REST/JSON API for it.
Please note one curiosity of this block explorer is that the coinbase tx
doesn't necessarily come first in the listing (it's sorted by "time
received", see).
Other interesting thing to note: this site is built using bitcoinj. The
author can be contacted on IRC sometimes using the nick damethos.

@_date: 2013-12-28 14:46:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Access to Mempool 
The "mempool" command allows nodes to request the contents of a peers
memory pool, yes.
It is currently used by SPV clients to find transactions that were
broadcast before they were started up (but not yet confirmed).
0.9 has code to save the mempool to disk.
Er, you mean, distinguishing features beyond the nodes IP address?
The contents of the mempool may vary depending on when the node was started
and what it saw at what times. I guess it's distinguishing in a way, but
not in any important way. Nodes are not intended to be completely
indistinguishable, just indistinguishable enough that it doesn't matter
which you connect to.
I don't think so, unless there are quirks to do with sendrawtransaction
RPCs or strangely crafted wallet spends. Normally if a tx is in the mempool
it will be relayed.
I don't know of any such place, but I'm sure people have compiled tables

@_date: 2013-12-28 18:56:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fees / prio to be confirmed within .... 
(nb: Gavin is on vacation at the moment, I post this now just to give food
for thought over the holidays).
I patched my bitcoind to use a modified version of Gavin's fee estimation
framework. Here is what it's currently estimating. This shows number of
samples taken for fee-paying transactions and free transactions (where
confirmation requires priority), along with the median fee paid and then
the 10th percentile fee paid, and median priority for the free transactions
(no 10th percentile there). -1 means missing data, of course. Max 1000
2013-12-28 18:34:42 estimates: for confirming within 0 blocks based on
1000/383 samples, fee=38759.7/16155.1 (10%) per kilobyte, prio=8.41811e+08
2013-12-28 18:34:42 estimates: for confirming within 1 blocks based on
1000/202 samples, fee=26738/16155.1 (10%) per kilobyte, prio=2.91473e+08
2013-12-28 18:34:42 estimates: for confirming within 2 blocks based on
298/115 samples, fee=22831.1/10341.3 (10%) per kilobyte, prio=3.18117e+08
2013-12-28 18:34:42 estimates: for confirming within 3 blocks based on
115/88 samples, fee=22831.1/8810.57 (10%) per kilobyte, prio=2.53442e+08
2013-12-28 18:34:42 estimates: for confirming within 4 blocks based on
17/26 samples, fee=14992.5/2759.38 (10%) per kilobyte, prio=2.99917e+08
2013-12-28 18:34:42 estimates: for confirming within 5 blocks based on 1/12
samples, fee=7468.26/7468.26 (10%) per kilobyte, prio=4.12797e+08
2013-12-28 18:34:42 estimates: for confirming within 6 blocks based on 1/9
samples, fee=8071.03/8071.03 (10%) per kilobyte, prio=1.32007e+08
2013-12-28 18:34:42 estimates: for confirming within 7 blocks based on 5/22
samples, fee=3018.41/1.91939 (10%) per kilobyte, prio=9.60733e+07
2013-12-28 18:34:42 estimates: for confirming within 8 blocks based on 0/9
samples, fee=-1/-1 (10%) per kilobyte, prio=1.22123e+08
2013-12-28 18:34:42 estimates: for confirming within 9 blocks based on 0/8
samples, fee=-1/-1 (10%) per kilobyte, prio=6.42686e+07
2013-12-28 18:34:42 estimates: for confirming within 10 blocks based on 0/3
samples, fee=-1/-1 (10%) per kilobyte, prio=6.72846e+06
2013-12-28 18:34:42 estimates: for confirming within 11 blocks based on 0/9
samples, fee=-1/-1 (10%) per kilobyte, prio=5.42872e+08
2013-12-28 18:34:42 estimates: for confirming within 12 blocks based on 0/1
samples, fee=-1/-1 (10%) per kilobyte, prio=1.13419e+07
2013-12-28 18:34:42 estimates: for confirming within 13 blocks based on 0/3
samples, fee=-1/-1 (10%) per kilobyte, prio=4.57343e+08
2013-12-28 18:34:42 estimates: for confirming within 18 blocks based on 0/2
samples, fee=-1/-1 (10%) per kilobyte, prio=5.51321e+08
2013-12-28 18:34:42 estimates: for confirming within 20 blocks based on 0/3
samples, fee=-1/-1 (10%) per kilobyte, prio=4.41654e+08
2013-12-28 18:34:42 estimates: for confirming within 22 blocks based on 0/4
samples, fee=-1/-1 (10%) per kilobyte, prio=4.04413e+08
2013-12-28 18:34:42 estimates: for confirming within 23 blocks based on 0/4
samples, fee=-1/-1 (10%) per kilobyte, prio=5.02467e+08
2013-12-28 18:34:42 estimates: for confirming within 24 blocks based on 0/1
samples, fee=-1/-1 (10%) per kilobyte, prio=2.76975e+08
2013-12-28 18:34:42 estimates: for confirming within 25 blocks based on 0/1
samples, fee=-1/-1 (10%) per kilobyte, prio=2.90481e+08
2013-12-28 18:34:42 estimates: for confirming within 27 blocks based on 0/3
samples, fee=-1/-1 (10%) per kilobyte, prio=3.49409e+08
2013-12-28 18:34:42 estimates: for confirming within 28 blocks based on 0/1
samples, fee=-1/-1 (10%) per kilobyte, prio=1.35682e+09
2013-12-28 18:34:42 estimates: for confirming within 31 blocks based on 0/2
samples, fee=-1/-1 (10%) per kilobyte, prio=2.17966e+08
2013-12-28 18:34:42 estimates: for confirming within 36 blocks based on 1/0
samples, fee=8103.73/8103.73 (10%) per kilobyte, prio=-1
2013-12-28 18:34:42 estimates: for confirming within 47 blocks based on 1/0
samples, fee=608.273/608.273 (10%) per kilobyte, prio=-1
2013-12-28 18:34:42 estimates: for confirming within 48 blocks based on 1/0
samples, fee=11415.5/11415.5 (10%) per kilobyte, prio=-1
2013-12-28 18:34:42 estimates: for confirming within 51 blocks based on 0/1
samples, fee=-1/-1 (10%) per kilobyte, prio=1.01951e+09
2013-12-28 18:34:42 estimates: for confirming within 55 blocks based on 1/0
samples, fee=3891.05/3891.05 (10%) per kilobyte, prio=-1

@_date: 2013-12-31 13:59:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Dedicated server for bitcoin.org, 
Given that hardly anyone checks the signatures, it's fair to say downloads
aren't protected by anything at the moment. SSL for downloads can only
raise the bar, never lower it, and if the NSA want to kick off the process
of revoking some of the big CA's then I'm game (assuming anyone detects it
of course) :)
Anyway, nobody is dragging feet, the problem is right now we get what is
effectively a huge free subsidy from github and SourceForge for site
hosting. The cost is no SSL. So getting SSL would require that "we" pay for
it ourselves, but the primary method we have for funding public
goods/infrastructure (the Foundation) which is the subject of various
conspiracy theories. Jeremy has made a generous offer further up the
thread, the issue being I guess none of us know how much traffic we
actually get :( I remember suggesting that we whack Google Analytics or
some other statistics package on when the new website design was done and
that was rejected for similar reasons ("organisations are bad").
So we are in a position where we get a subsidy of large but unknown size
from various existing US corporations, but moving to different ones is
controversial, hence no progress :)

@_date: 2013-12-31 14:23:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Dedicated server for bitcoin.org, 
Oh, it did? When was that? I must have missed this excitement :)
Any idea how much load it had?
Perhaps I wasn't clear on the point I was making Drak's threat model
Well, that depends. If you watch Applebaums talk he is pushing TLS pretty
hard, and saying that based on the access to the source docs some of their
MITM attacks can't beat TLS. It appears that they have the capability to do
bulk MITM and rewrite of downloads as Drak says but *not* when TLS is
present, that would force more targeted attacks. So to me that implies that
TLS does raise the bar and is worth doing.
However if we can't find a server that won't melt under the load, then
that'd be an issue. We could consider hosting downloads on AppEngine or
something else that can handle both high load and TLS.

@_date: 2013-02-06 17:33:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
Can somebody please unlock the BIP wiki page? I don't know why it was
locked but it's stale.

@_date: 2013-02-13 11:00:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] RFC: empty scriptPubKeys and OP_RETURN 
It was fixed by Satoshi long ago, back when we used CVS I think.
The problem was how scripts were executed. They were concatenated together
and then run as a single unit. The now obsolete OP_CODESEPARATOR was put
between them to control what was hashed and what wasn't.
The obvious problem with that arrangement being that scriptSig ran first
(it has to, to push the signatures onto the stack), so nothing stopped you
setting a scriptSig to OP_RETURN and making the script evaluate to true,
always. A pretty amazing oversight given the thought and care that went
into Bitcoin generally, and its robustness since then.
The fix was to move to the current system whereby the two scripts are
executed independently but sharing a stack, and it's only the return value
of the scriptPubKey that matters.
The scripting system always struck me as a rather late addition to the
design. Satoshi admitted as much when he said that he added it after
encountering an explosion of special cases as he designed various types of
contracts. The fact that there's an obvious bug in CHECKMULTISIG is more
evidence of this part being a general rush job, along with Satoshis
willingness to disable much of its functionality later with the IsStandard
checks. Also the design of CHECKSIG is an obvious retrofit, it would have
made far more sense to decompose it, and we never found a use case for 99%
of the opcodes despite having successfully designed (redesigned?) all the
contract types he ever mentioned.

@_date: 2013-02-19 23:26:21
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.7 released 
I'm pleased to announce the release of version 0.7 of the bitcoinj Java
library for working with Bitcoin. Bitcoinj forms the foundation of
MultiBit, Bitcoin Wallet for Android, SatoshiDice and more.
To get bitcoinj 0.7, check out our source from git and then run *git reset
--hard a9bd8631b904*. This will place you on the 0.7 release in a secure
manner. This paragraph was written on Tuesday 19th February 2013 and is
signed with the following key, which will be used in all release
announcements in future: 16vSNFP5Acsa6RBbjEA7QYCCRDRGXRFH4m.
Signature for the last
paragraph: IMvY1FsQobjU2t83ztQL3CTA+V+7WWKBFwMC+UWKCOMyTKA+73iSsFnCHdbFjAOEFMQH/NvJMTgGeVCSV/F9hfs=
If you want to, you can check that the original announcement mail sent to
bitcoinj at googlegroups.com is correctly signed with the google.com DKIM key,
to establish a full chain of trust.
*Release notes*
   - Thanks to Matt Corallo, we now support a* fully verifying mode* in
   addition to simplified verification. This is a tremendous amount of work
   that wouldn't have happened without Matt! Right now, we strongly discourage
   anyone from using it for mining (which is not supported out of the box
   anyway). Use it in a production environment only if you know what you're
   doing and are willing to risk losing money. If you do use it, let us know
   so we can contact you when problems are discovered. Read the documentation
   carefully before you begin.
   - Also thanks to Matt, *Bloom filtering* is now implemented and
   activated by default. When bitcoinj connects to a peer that supports Bloom
   filtering, only transactions relevant to the wallet will be downloaded
   which makes bandwidth usage scale with the size of your wallet, not global
   system activity. A configurable false positive ratio allows you to trade
   off bandwidth vs privacy. App developers don't need to do anything to take
   advantage of this, it is enabled automatically.
   - PeerGroup now pings its peers and calculates moving averages of the
   ping times. Ping time, versions and block heights are taken into account
   when selecting the peer to download the chain from.
   - You can now customize which outputs the wallet uses to create spends.
   The new default coin selector object allows you to spend unconfirmed change
   as long as it's been seen propagating across the network, addressing a
   common end-user pain point in wallet apps.
   - Optimized networking code for faster startup.
   - A new PeerMonitor example app shows how to put properties of connected
   peers into a GUI.
   - The Wallet is now decoupled from the BlockChain using the new
   BlockChainListener interface. This will simplify the development of some
   apps that want to process transactions but not maintain an actual wallet.
   - The dependencies of broadcast transactions are now downloaded and risk
   analyzed. At the moment they are only being checked for having a timelock.
   In future we may also analyze tree depth. The goal is to make certain kinds
   of protocol abuse harder. Wallets will reject timelocked transactions by
   default, this can be overridden via a property.
   - You can now create timelocked transactions with
WalletTool? if
   you want to.
   - Compressed public keys are now used by default.
   - Support testnet3
   - Support bitcoin-qt compatible message signing and verification.
   - ECDSA key recovery is now implemented and allows you to obtain the
   public key from an extended signature. If the signature is not extended
   then there are multiple key possibilities returned.
   - Many bugfixes and minor improvements
API changes:
   - ECKey.sign() now takes a Sha256Hash as an argument and returns an
   ECDSASignature object in response. To get DER encoded signatures, use
   the encodeToDER() method of ECDSASignature.
   - ECKey.publicKeyFromPrivate now takes an additional compressed
   parameter.
   - PeerGroup.start()/PeerGroup.shutDown() now run asynchronously and
   return futures you can use to wait for them. You cannot restart a
   PeerGroup once it has been shut down any more.
Thanks to Matt Corallo (a.k.a. BlueMatt) for his huge contributions to this
As always, thanks to Andreas Schildbach for his thorough testing, ideas and
high volume of quality bug reports. Also thanks to Jim Burton for the same
Finally thanks to Ben (piuk) of blockchain.info for funding the ECDSA key
recovery feature.

@_date: 2013-02-20 13:44:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
I paid the new anti-spam deposit and updated the BIP 37 page to the latest
version of the protocol, then marked it as accepted. High fives all round,
but especially to Matt for doing the heavy lifting on this feature.

@_date: 2013-01-10 16:21:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
Here's a quick update on where we're up to.
Thanks to Matts excellent work, I was able to test his bitcoinj and
bitcoin-qt work together today. There are a few minor tweaks needed,
but I feel like we're maybe a week away from having all the code in a
mergeable state. Here is the remaining work:
- There are a couple of bugfixes needed on the bitcoinj side: the
fallback to downloading full blocks is problematic and needs to be
deleted, there's an API change we want
- Adjust the default FP rate requested by BCJ to be 0.0001, this is
appropriate for the latest blocks in the chain and yields 0-5 false
positives per block
- Introduce a new part to the filter protocol that allows clients to
control auto-expansion. This turned out to be very volatile, we saw
jumps from 0-3 FPs per block to 500 in the space of 1 block, perhaps
if a SatoshiDice transaction got into the filter. A simple yes/no flag
can suffice for now, but a better solution would be for the client to
submit templates for output scripts that would trigger auto-adding the
matched outpoint - autoexpansion is only needed in the case where the
input script doesn't contain any predictable data. For pay-to-address
and P2SH it does, so expansion doesn't help. Matt said he'd hopefully
try to look at this soon.
With auto-expansion disabled, the FP rate adjusted and a bugfix on the
bcj side I was able to sync a wallet using a bloom filtered chain.
Although it's tight, I think this work should go into 0.8 - it'll be
much more compelling to advertise it this way, we can say "Upgrade to
0.8 and help network performance for everyone". And in the case that
we discover a showstopper problem, we just don't deploy the code that
uses the new messages into clients.

@_date: 2013-01-11 15:11:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
I did some very rough initial performance tests.
Syncing from a local peer gives me about 50 blocks per second in the
later parts of the chain (post SD), which is about a 10-20x speedup
over what I could do before. This is on a MacBook Pro. But at those
points it's clearly bottlenecked by bitcoind which has saturated its
CPU core. This makes sense - the filtering is much more server than
client intensive because every transaction in every block has to be
loaded and checked.
I think filtering can be fairly well parallelized on the server side.
So the current 10-20x speedup could potentially be larger if the
server becomes more efficient at scanning and filtering blocks. It's
still a very nice win for now, especially bandwidth wise. And if Matt
makes the mempool command filtered it solves a common usability
problem as well.
Once we get this code in, merged and rolled out I think what we need
for bloom v2 is clear:
 - Multi-thread the filtering process in bitcoind so transactions can
be checked in parallel. A 4-core server would then get 4x faster at
filtering blocks and assuming it's not too busy doing other stuff we
could maybe sync at more like 200 blocks per second, which is cool ...
more than a days worth of history for each second of syncing.
 - Make the client smarter so the FP rate is adapted during the sync
process. An FP rate that makes sense post-SD results in no false
positives pre-SD, more or less.
 - Make the client shard its wallet keys over multiple peers, for
better privacy.
 - Make the client suck down filtered blocks in parallel from multiple
peers, for better speed.
As it seems the bottleneck for chain sync is now CPU time, the latter
point may be the most important from a practical perspective.

@_date: 2013-01-11 15:13:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
Oh, one last stat - syncing the entire chain with a wallet containing
two keys and a 0.0001 FP rate (one or two FPs every 5 blocks or so)
resulted in a download of about 46mb of data.

@_date: 2013-01-16 11:43:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
Matts latest code has been tested by Andreas and seems to work
correctly. He had to extend the client a bit to refresh the filter
every 25k blocks because even with the extra flag, eventually the
filter degrades into uselessness, but it did still improve the
situation quite a bit.
Because it's unit tested, been reviewed by me several times, has an
interoperable implementation that has also been tested by Andreas in a
build of his smartphone app,  I'm going to ACK the current code and
request that it be merged in to 0.8. What do you say Gavin?
The next step after that would be profiling. It's a big performance
improvement for SPV clients already, but not as much as I anticipated.
I suspect there's a simple bottleneck or missed optimization
somewhere. But that can obviously come post-0.8

@_date: 2013-01-18 17:38:45
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
I'm thinking we should actually make the change we talked about before
and have the filtered block sent before the transaction data.
For one, it's not intuitive (API wise) that you'd get a callback
saying "new pending tx" immediately before another callback saying "tx
was confirmed", but that's what the current setup makes most natural.
To fix it we'd have to notice that a tx message wasn't requested by
us, buffer it, and wait for the corresponding filteredblock message.
It seems cleaner to receive a filteredblock and then for any tx that
matches it, attach it to the FilteredBlock object and wait until it is
full up, then pass it to the wallet code all at once.
Another issue is that to risk analyze unconfirmed transactions you
really have to download all dependencies. That has to be triggered by
seeing an unconfirmed transaction. It's dumb to start this process for
a tx that is actually in the chain, so you need to have some notion of
whether it came from a filtered block anyway. I only realized this
I think when we discussed this before, the justification for having it
work the current way was that it was simpler to integrate with the SPV
client code if it was done this way around. But I don't think it's
really simpler. There are enough odd side effects of doing it this
way, that I feel it'd be better to tweak the protocol now whilst we
have the chance.

@_date: 2013-01-30 12:09:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
Andreas has uploaded Android builds that use the new bloom filtering and
peer selection code (also, dependency analysis of transactions).
The performance gain is very cool. The app feels dramatically faster to
start up and sync. Because the app syncs on charge when I opened it around
lunchtime it had only 7 hours of data to sync (42 blocks) and it brought up
6 peer connections, found a 0.7.99 node and synced all in <2 seconds. That
was on wifi.
The next lowest hanging perf fruit is almost certainly to optimize disk
accesses. Flash on Android devices seems to be much slower than laptop
flash storage, and current bitcoinj is very inefficient in how it writes
(one write per block header!). This matters a lot when doing fast catchup
for first time users.
The BIP is now a little bit stale, but only slightly.

@_date: 2013-01-30 12:13:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
============================== START ==============================
Sorry, to clarify, these are test builds available here:
It's not on the Play store yet. It probably makes sense to release after
some more testing and after Bitcoin 0.8 comes out, as otherwise there's a
risk that 0.7 snapshot nodes will get overloaded.

@_date: 2013-07-09 12:36:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
Modern Java versions let you bundle the app with a stripped down JVM. I
don't know if Jim does that, but I think it's an obvious step towards
making MultiBit friendlier and easier to use.
BTW I believe most secure browsers (Chrome, Firefox) have banned the applet
plugin or severely restrained it anyway. So even if you install the JVM and
plugin together there is not an issue.
On Tue, Jul 9, 2013 at 3:20 AM, Caleb James DeLisle <

@_date: 2013-07-09 13:04:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
How many downloads/day do we see currently? I think you said it's on the
order of a few thousand, so nowhere near 30k I'd guess. Anyway I can mirror
it if we need to.
The JavaFX packager is supposed to delete parts of the JVM that aren't
used. Is the 30-40mb figure based on using that tool or something else?
Note that you don't need to use the JFX widget toolkit to use the bundler
We could also invest in a copy of JET, which does native compilation down
to self contained Windows binaries. It might create smaller bundles. But,
it's a proprietary tool and I don't know how reproducible its outputs are.
For the auto update, is there an existing auto update framework that we can
modify to support threshold signed updates? I'm sure such a thing must
exist. The updates would download in the background and then the app can
just ask the user to restart it once the update is locally available, as
Chrome does.

@_date: 2013-07-09 13:18:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
By the way, the Java Web Start system has improved a lot in recent versions
as well. I just tried running  and this was the
   - It told me my Java was insecure and that I should download the latest
   version (hah). It had three buttons, one saying "Update", one saying "Block
   content in browser" and one saying "Later". So it seems Java learned how to
   disable its plugin by itself anyway. I think on non-Linux platforms it
   probably knows how to update itself as well these days.
   - As it happens I don't care right now because jfxtras is a source I
   trust, so I clicked later and it popped up a permission screen saying the
   author was unknown, could damage my computer, etc. Actually, Jim has a code
   signing cert so this would show his identity at that point.
   - Clicked run. The app downloaded in a few seconds and was running.
   - JavaWS keeps the app up to date for you at that point.
It's triggered by downloading and opening a .jnlp file, so - same security
boundaries as a regular app download, except you download metadata for the
runtime instead of the whole app at once.
It might be worth providing a JNLP option on the multibit webpage as well,
as although I wouldn't let the applet plugin in my browser, once I made an
explicit decision to go to multibit.org and trust James Burton with my
money, the JWS experience at that point is pretty good. Until we have our
own auto update engine it's better than nothing.

@_date: 2013-07-09 16:28:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
SourceForge has a horrible UI and blocks some countries. It also exposes us
to a large and potentially hackable mirror network. Whilst we're not
bandwidth constrained on our own servers, let's try and keep using them.

@_date: 2013-07-09 17:27:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
That's true - we could serve new users off our own servers and auto updates
off SF.net mirrors, potentially.

@_date: 2013-07-09 18:44:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
That's good to know. Still, at the moment we'd need to dramatically
increase the download size and increase Bitcoin usage by 10x to hit our
limits. It'd be a good problem to have.
On Tue, Jul 9, 2013 at 5:51 PM, Johnathan Corgan

@_date: 2013-07-15 15:19:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Introducing BitcoinKit.framework 
That's great! I'm all for more wallets, especially user friendly UIs.
However being based on bitcoind means it will take a very long time to
synchronize for new users. We know a lot of users drop out. The best fix
for this is SPV mode. Do you have any plans in this direction?
So far, the only SPV mode implementation I know about is bitcoinj. I am
experimenting with trans-piling bitcoinj to C++ to make it usable from
Objective-C++ exactly with your use case in mind.

@_date: 2013-07-15 17:48:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Introducing BitcoinKit.framework 
Oracle provide an OSX JVM and will do so for the forseeable future, it's
also open source, so the community could carry on if they stopped. The
primary problem with the Oracle JVM is lack of retina support for Swing,
but if you'd write a Cocoa UI yourself then it doesn't matter of course as
Java won't handle any GUI stuff. Retina support for JavaFX2 (the
current-gen gui toolkit) is available in Java 8 so it's definitely being
actively developed, it's not abandoned or anything.
So the question then becomes, which is better:
a) Take bitcoinj completely out of the Java world via native compilation or
transpilation to C++
b) Embed the JVM and link the two worlds together?
(b) is much less ambitious, especially if you're OK with writing a bit of
Java code to keep the interface thin. Basically the Java side calls into
your app when interesting user-visible things happen, like new transactions
appearing, then your GUI can call into the java side to send money. There
are auto-translators that make the glue work easy, like
 You probably wouldn't want to expose
the entire bitcoinj API that way because it's very large, but the code
needed to bring up a wallet app is very small. I knocked one up this
weekend in about one evenings worth of coding, completed with nice
animations. The interfaces you'd need are basically some Objective-C++
methods that receive information from the Bitcoin side, like the balance
having changed, a list of transactions, etc, and then a callback into the
Java side to send money. If you look at the javacpp site you can see
example code for making calls both ways.
If I were in your shoes, I'd go for (b) because it is the most well trodden
path and will let you achieve the best user visible results quickly. The
JVM can be bundled with your app and stripped down if you're worried about
download size.
If it's unclear how the code would look, let me know and I'll try and knock
up a really simple prototype.
There's also (a). I'm investigating transpilation for a few reasons, one of
which is to do with a private project. I'm working with the author of j2c:
 It's a rather
sophisticated transpiler that converts Java to clean, readable C++11 that
looks much like code a human would write. It's complete enough to transpile
the entire standard Java class library, including all the GUI toolkits and
other things - so, pretty amazing piece of code. However it's incomplete
because where the Java code calls native methods (that would be provided by
the JVM) it just spits out stubs you're expected to fill out yourself, for
starting threads and so on. As there's no JVM it's just like using a C++
library that is missing a "portability layer".
I'm working on this myself and don't really need much help at the moment,
I'm just making steady progress towards getting something up and running. I
can let you know once I reach some interesting milestones. The point of
this is that whilst you don't need access to most of the API to write a
wallet app, I'd like to make every kind of app easy from C++, not just GUI
wallets. Then the compile-to-C++ approach is much more appealing, even
though it's also more work.

@_date: 2013-07-15 22:08:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Introducing BitcoinKit.framework 
You can cut down the JVM to be a few megabytes if you're aggressive about
it. But for a desktop app I'm not sure it's really necessary these days. A
few megabytes used to make a noticeable difference to success rates but
bandwidth improved a lot since then.
Portability to android is a given, it's already Java based. IOS is a non
starter until apple is convinced to allow wallet apps into the App store,
language is not the issue there.
There is no point manually rewriting bitcoinj to c++ when j2c does such a
great job already. You would want to at last start from what it generates
even if you fork from there.

@_date: 2013-07-16 11:21:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Introducing BitcoinKit.framework 
I'm a bit confused I'm afraid. bitcoinj already runs SPV wallets on Android
on top of Dalvik. In fact that's what it's designed for. The NDK is not
necessary to work with Bitcoin at any point.
There's an example of what it looks like here:
If you're serious about playing with j2c let me know. It's an amazing piece
of work BUT it was written for fun, and as such isn't really documented at
all. It took me a little while to figure out how to make it work properly.
I'm now fixing bugs in it and making various improvements along with
filling out the native stubs (a.k.a. portability layer). If you want to
catch up to where I'm at, I can send you some notes because otherwise you
might waste a lot of time on blind alleys.
The main things be aware of so far are:
   - Lots of explicit null pointer checks are generated. The reason is that
   the output is meant to be entirely portable, so Jacek doesn't want to rely
   on platform specific stuff like signals or SEH. Simplest solution is just
   to disable npc() generation entirely because normal C++ libraries just
   segfault if a null pointer gets in the wrong place, they don't throw
   exceptions. Losing the Java behaviour would not be a downgrade for people
   used to C++.
   - Array accesses don't seem to be properly bounds-checked. That's a part
   of the Java security model - bitcoinj is written on the assumption that
   buffer and heap overflows aren't possible because they're caught by the
   runtime. If those checks go missing then it'd likely become possible to
   hack your program by exploiting buffer overflows. So that needs to be fixed.
   - Generated code doesn't use the STL of course, it can't because the
   Java library has more features than the STL. However as the way j2c works
   is you transpile your code alongside a copy of the (open source) Java class
   library, you can go in and modify the generated code for java::lang::String
   or java::util::List and so on to add helper methods for converting to
   various other forms. On Linux you'd have implicit c'tors to go back and
   forth between std::string, on MacOS X you'd have conversions for NSString,
   you could add code for QStrings or raw C strings too. Once the code has
   been generated you can extend or patch it to make the API more convenient.
   - Obviously, the resulting code requires the Boehm GC because there are
   no explicit delete calls anywhere. This is a safety feature though, it
   avoids use-after-free and double-free bugs that can create security holes.
   - The code generator doesn't do dependency tracing, so you end up with
   generated code that isn't used anywhere. It's up to the linker to do a dead
   code elimination pass. Otherwise the resulting binaries can be huge.

@_date: 2013-07-16 11:51:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Introducing BitcoinKit.framework 
Let's re-add the list as this is a topic of general interest.
Making bitcoind/Bitcoin-Qt support SPV mode was the original plan some
years ago, Satoshi even sent me some code he wrote that did the first
parts, but it was incomplete.
At the time, I decided to do a separate implementation for a few different
reasons. One is that my understanding of his code wasn't so good back then
and I lacked confidence to change it. Especially as there were no unit
tests back then (and still aren't any for most of it), making invasive
changes to the core validation code was and is highly risky. A separate
code base seemed to reduce the risk a lot.
Another reason is that Satoshi encouraged me to write a simple
re-implementation that people could learn from. And I wanted a documented,
object oriented API that people could use to build a variety of apps.
Yet another reason was bitcoind is security critical code that scrapes
complex data structures from untrusted sources on the internet, and it's
written in an unmanaged language. Ordinarily this would be a recipe for
disaster as a single overflow or memory management error could lead to
hacking and theft on a massive scale. It's like taking a chainsaw and using
it to carve an ice sculpture. Satoshi, incredibly, pulled it off, mostly by
using advanced C++ features that made his code hard to read for many people
and by being very, very careful. I was not convinced I could do such a good
job and was worried about accidentally introducing vulnerabilities.
A final reason is that it was clear that the bitcoind codebase would need
serious changes for mobiles, beyond that required for ordinary SPV support.
For example, Satoshi's code assumes it has access to block headers via a
std::map and that assumption is made in a lot of places. On Android phones,
you can't fit all the block headers in RAM. bitcoinj uses a circular ring
buffer of the last N thousand headers for this reason. It's quite different
to how bitcoind works.
All that said, it was a ton of work and it's still unclear that it was the
right call.
Anyway, your situation is a little different. Firstly you don't care about
mobiles, your app is intended for desktops. So the changes required are
less invasive. Also, there are more unit tests and more people with a good
understanding of the code these days, so perhaps the risk of introducing
bugs is lower. And these days we have some nice APIs for building apps so
that need is already met.
If you wanted to implement SPV mode in bitcoind, Gavin or I could send you
Satoshi's old patch although of course it is no longer usable. It would
indicate the basic cut lines though.

@_date: 2013-07-16 17:09:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SPV bitcoind? (was: Introducing 
You'd want to create and get merged patches in the following order:
1) Be able to store just block headers in the blkXXXX.dat files instead of
full block contents. At this point you are still *downloading* full blocks,
but they are not being stored. The contents are still sent to the wallet
for extracting relevant transactions though (see SyncWithWallets).  You
also need to disable listening and addr announcements to the P2P network at
this point. You need to be able to re-org and do all the usual things
without storing block contents. You also need to short-circuit the leveldbs
so they aren't created or used. All that needs to be unit tested. You need
to also rewrite the mempool logic so it throws out irrelevant transactions.
The RPC interface needs to adjust itself so you can't try to start mining,
query the utxo set, etc.
At this point you have an SPV node, albeit one that still downloads the
entire block chain. However total disk storage used will be much lower.
Getting this written and reviewed is a big chunk of work but is the hardest
part. Once it's done you can breath easy.
2) Next step, use getheaders to catch up with the chain until the
min(wallet birthdays) is reached. You can see in Satoshi's patch where he
adds support for receiving "headers" messages. Because key times are
recorded as dates and you don't know the dates of blocks in advance, you
need to download headers until you see one that goes past the key birthday
minus some slack period, then throw out the headers you downloaded and
switch to downloading full blocks again from that point onwards.
3) Next step, implement client side support for Bloom filtering. Switch
from downloading full blocks to filteredblocks, verify the Merkle branches
then apply them to the wallet. Watch out for accidental re-orderings of
transactions here from block order (e.g. if you accidentally insert them
into a std::map or other unordered collection it can lead to bugs). Come up
with some way to decide on a FP rate. Probably you want a fairly high FP
rate for desktop wallets.
4) Next step (optional), implement monitoring of broadcast propagation for
transactions that are received. SPV clients cannot verify unconfirmed
transactions so you can either just give up entirely and accept any old
garbage, or assume a non-MITMd internet connection and use network
propagation as a rough proxy for "likely to be valid and mined upon".
4) Optimize!
How much you need to optimize really depends on a lot of things. I found
that to be competitive with Electrum/blockchain.info I had to do a ton of
optimizations including very aggressive checkpointing so new users don't
have to download more than a month or twos worth of headers, as downloading
all the headers was becoming a bottleneck. You'd need to download about
16mb+ of data at the moment to grab all the headers and on a weakass mobile
phone with a weak Dalvik VM and 3G internet this was way too much. I also
had to spend some time profiling to ensure we weren't accidentally
thrashing the UI due to too-fast updates, we weren't bottlenecking on
updating last seen block data in the wallet, we weren't accidentally
de/reserializing messages redundantly etc.
After about 3-4 evenings of non-stop profiling and optimising I ended up
with a relatively flat profile whilst doing initial catchup and chain sync.
On a desktop I bet you can get away with much less optimisation because
your CPUs, network and disk tend to be much stronger.

@_date: 2013-07-17 14:29:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SPV bitcoind? (was: Introducing 
Partial UTXO sets is a neat idea. Unfortunately my intuition is that many
SPV wallets only remain open for <1 minute at a time because the user wants
to see they received money, or to send it. It'd be neat to get some
telemetry from the Android wallet for this - I will ask Andreas to let
users opt in to usage statistics.
So for anti-DoS I think smart prioritisation heuristics are the way to go
again. Perhaps by letting clients have an "identity" that they provide to a
node when it's load shedding. Clients that have been seen before, have a
track record of not being abusive etc get priority and new clients that
were never seen before get dropped. Coming up with a way to do that whilst
preserving privacy sounds like an interesting cryptographic challenge.

@_date: 2013-07-17 15:56:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SPV bitcoind? (was: Introducing 
Which is why it's still vital that any "important" node in the economy uses
full validation.
A majority miner coalition could change the block reward and award
themselves money which SPV clients would accept, however, the moment
somebody tried to cash that money out via an exchange, or use it to
purchase something from an online shop, or just see if it propagated across
the P2P network effectively, they'd notice something had gone wrong. Of
course it'd be in the news long before this happened ....
SPV is really meant for nodes that go away and come back a lot, i.e. end
user wallets. If you're a merchant it'd be dumb to run one unless you're on
such a tight budget that your server resembles a powerful tablet.

@_date: 2013-07-17 21:32:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SPV bitcoind? 
Yeah, what I meant is, it'd be useful to know the average amount of time
that the app was holding connections open for.
On Wed, Jul 17, 2013 at 4:32 PM, Andreas Schildbach

@_date: 2013-07-18 10:19:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SPV bitcoind? (was: Introducing 
ultraprune made a huge difference. I think it's very likely that this claim
is no longer true. Bitcoin got a lot more optimised since you first did

@_date: 2013-07-18 15:38:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] SPV bitcoind? (was: Introducing 
This must be a new use of the word "abuse" I haven't come across before :)
At any rate, some of these assumptions are incorrect. Botnets of
compromised web servers are quite common, and asymmetry in node resources
is obviously biased against the kinds of devices people increasingly have
(phones, tablets) where extremely limited memory bandwidth is common and
apps routinely have just 16 or 32mb of memory to do everything including
the GUI.
A good anti-DoS strategy looks much the same as a good load shedding
strategy. There's little reason to treat them separately. Perhaps instead
of talking about DoS we should instead talk about what happens if Bitcoin
suddenly gets too popular. Now there are suddenly lots of good users all
wanting to use the network, and not enough nodes to support them all. What
do we do?
Some rules seem obvious - try to prioritise existing users over new users,
old coins over new coins (dPriority already does this) etc. If you run out
of TCP sockets prefer to disconnect recent connections (probably new users)
to long lived connections (probably high powered backbone peers). If you
run out of disk seeks prefer processing new blocks to serving old parts of
the chain, etc.

@_date: 2013-07-16 12:59:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Introducing BitcoinKit.framework 
I think that's a great approach. Here is the patch Satoshi sent me back in
2010. All the code has changed since but it can be a source of inspiration.
*The simplified payment verification in the paper imagined you would
receive transactions directly, as with sending to IP address which nobody
uses, or a node would index all transactions by public key and you could
download them like downloading mail from a mail server.
Instead, I think client-only nodes should receive full blocks so they can
scan them for their own transactions.  They don't need to store them or
index them.  For the initial download, they only need to download headers,
since there couldn't be any payments before the first time the program was
run (a header download command was added in 0.3.18).  From then on, they
download full blocks (but only store the headers).
Code for client-only mode is mostly implemented.  There's a feature branch
on github with it, also I'm attaching the patch to this message.
Here's some more about it:
"Here's my client-mode implementation so far.  Client-only mode only
records block headers and doesn't use the tx index.  It can't generate, but
it can still send and receive transactions.  It's not fully finished for
use by end-users, but it doesn't matter because it's a complete no-op if
fClient is not enabled.  At this point it's mainly documentation showing
the cut-lines for client-only re-implementers.
With fClient=true, I've only tested the header-only initial download.
A little background.  CBlockIndex contains all the information of the block
header, so to operate with headers only, I just maintain the CBlockIndex
structure as usual.  The nFile/nBlockPos are null, since the full block is
not recorded on disk.
The code to gracefully switch between client-mode on/off without deleting
blk*.dat in between is not implemented yet.  It would mostly be a matter of
having non-client LoadBlockIndex ignore block index entries with null block
pos.  That would make it re-download those as full blocks.  Switching back
to client-mode is no problem, it doesn't mind if the full blocks are there.
If the initial block download becomes too long, we'll want client mode as
an option so new users can get running quickly.  With graceful switch-off
of client mode, they can later turn off client mode and have it download
the full blocks if they want to start generating.  They should rather just
use a getwork miner to join a pool instead.
Client-only re-implementations would not need to implement EvalScript at
all, or at most just implement the five ops used by the standard
transaction templates."
diff -u old\db.cpp new\db.cpp
--- old\db.cpp  Sat Dec 18 18:35:59 2010
+++ new\db.cpp  Sun Dec 19 20:53:59 2010
 -464,29 +464,32      ReadBestInvalidWork(bnBestInvalidWork);
     // Verify blocks in the best chain
-    CBlockIndex* pindexFork = NULL;
-    for (CBlockIndex* pindex = pindexBest; pindex && pindex->pprev; pindex
= pindex->pprev)
+    if (!fClient)
     {
-        if (pindex->nHeight < nBestHeight-2500 &&
-            break;
-        CBlock block;
-        if (!block.ReadFromDisk(pindex))
-            return error("LoadBlockIndex() : block.ReadFromDisk failed");
-        if (!block.CheckBlock())
+        CBlockIndex* pindexFork = NULL;
+        for (CBlockIndex* pindex = pindexBest; pindex && pindex->pprev;
pindex = pindex->pprev)
         {
-            printf("LoadBlockIndex() : *** found bad block at %d,
hash=%s\n", pindex->nHeight, pindex->GetBlockHash().ToString().c_str());
-            pindexFork = pindex->pprev;
+            if (pindex->nHeight < nBestHeight-2500 &&
+                break;
+            CBlock block;
+            if (!block.ReadFromDisk(pindex))
+                return error("LoadBlockIndex() : block.ReadFromDisk
+            if (!block.CheckBlock())
+            {
+                printf("LoadBlockIndex() : *** found bad block at %d,
hash=%s\n", pindex->nHeight, pindex->GetBlockHash().ToString().c_str());
+                pindexFork = pindex->pprev;
+            }
+        }
+        if (pindexFork)
+        {
+            // Reorg back to the fork
+            printf("LoadBlockIndex() : *** moving best chain pointer back
to block %d\n", pindexFork->nHeight);
+            CBlock block;
+            if (!block.ReadFromDisk(pindexFork))
+                return error("LoadBlockIndex() : block.ReadFromDisk
+            CTxDB txdb;
+            block.SetBestChain(txdb, pindexFork);
         }
-    }
-    if (pindexFork)
-    {
-        // Reorg back to the fork
-        printf("LoadBlockIndex() : *** moving best chain pointer back to
block %d\n", pindexFork->nHeight);
-        CBlock block;
-        if (!block.ReadFromDisk(pindexFork))
-            return error("LoadBlockIndex() : block.ReadFromDisk failed");
-        CTxDB txdb;
-        block.SetBestChain(txdb, pindexFork);
     }
     return true;
diff -u old\main.cpp new\main.cpp
--- old\main.cpp        Sat Dec 18 18:35:59 2010
+++ new\main.cpp        Sun Dec 19 20:53:59 2010
 -637,6 +637,9      if (!IsStandard())
         return error("AcceptToMemoryPool() : nonstandard transaction
+    if (fClient)
+        return true;
     // Do we already have it?
     uint256 hash = GetHash();
     CRITICAL_BLOCK(cs_mapTransactions)
 -1308,23 +1311,26      if (!CheckBlock())
         return false;
-    //// issue here: it doesn't know the version
-    unsigned int nTxPos = pindex->nBlockPos + ::GetSerializeSize(CBlock(),
SER_DISK) - 1 + GetSizeOfCompactSize(vtx.size());
-    map mapUnused;
-    int64 nFees = 0;
-    foreach(CTransaction& tx, vtx)
+    if (!fClient)
     {
-        CDiskTxPos posThisTx(pindex->nFile, pindex->nBlockPos, nTxPos);
-        nTxPos += ::GetSerializeSize(tx, SER_DISK);
+        //// issue here: it doesn't know the version
+        unsigned int nTxPos = pindex->nBlockPos +
::GetSerializeSize(CBlock(), SER_DISK) - 1 + GetSizeOfCompactSize(vtx.size(
+        map mapUnused;
+        int64 nFees = 0;
+        foreach(CTransaction& tx, vtx)
+        {
+            CDiskTxPos posThisTx(pindex->nFile, pindex->nBlockPos, nTxPos);
+            nTxPos += ::GetSerializeSize(tx, SER_DISK);
-        if (!tx.ConnectInputs(txdb, mapUnused, posThisTx, pindex, nFees,
true, false))
+            if (!tx.ConnectInputs(txdb, mapUnused, posThisTx, pindex,
nFees, true, false))
+                return false;
+        }
+        if (vtx[0].GetValueOut() > GetBlockValue(pindex->nHeight, nFees))
             return false;
     }
-    if (vtx[0].GetValueOut() > GetBlockValue(pindex->nHeight, nFees))
-        return false;
     // Update block index on disk without changing it in memory.
     // The memory index structure will be changed after the db commits.
     if (pindex->pprev)
 -1378,7 +1384,7      foreach(CBlockIndex* pindex, vDisconnect)
     {
         CBlock block;
-        if (!block.ReadFromDisk(pindex))
+        if (!block.ReadFromDisk(pindex, !fClient))
             return error("Reorganize() : ReadFromDisk for disconnect
         if (!block.DisconnectBlock(txdb, pindex))
             return error("Reorganize() : DisconnectBlock failed");
 -1395,7 +1401,7      {
         CBlockIndex* pindex = vConnect[i];
         CBlock block;
-        if (!block.ReadFromDisk(pindex))
+        if (!block.ReadFromDisk(pindex, !fClient))
             return error("Reorganize() : ReadFromDisk for connect failed");
         if (!block.ConnectBlock(txdb, pindex))
         {
 -1526,7 +1532,7      txdb.Close();
-    if (pindexNew == pindexBest)
+    if (!fClient && pindexNew == pindexBest)
     {
         // Notify UI to display prev block's coinbase if it was ours
         static uint256 hashPrevBestCoinBase;
 -1547,10 +1553,6      // These are checks that are independent of context
     // that can be verified before saving an orphan block.
-    // Size limits
-    if (vtx.empty() || vtx.size() > MAX_BLOCK_SIZE ||
::GetSerializeSize(*this, SER_NETWORK) > MAX_BLOCK_SIZE)
-        return error("CheckBlock() : size limits failed");
     // Check proof of work matches claimed amount
     if (!CheckProofOfWork(GetHash(), nBits))
         return error("CheckBlock() : proof of work failed");
 -1559,6 +1561,13      if (GetBlockTime() > GetAdjustedTime() + 2 * 60 * 60)
         return error("CheckBlock() : block timestamp too far in the
+    if (fClient && vtx.empty())
+        return true;
+    // Size limits
+    if (vtx.empty() || vtx.size() > MAX_BLOCK_SIZE ||
::GetSerializeSize(*this, SER_NETWORK) > MAX_BLOCK_SIZE)
+        return error("CheckBlock() : size limits failed");
     // First transaction must be coinbase, the rest must not be
     if (vtx.empty() || !vtx[0].IsCoinBase())
         return error("CheckBlock() : first tx is not coinbase");
 -1623,13 +1632,14          return error("AcceptBlock() : out of disk space");
     unsigned int nFile = -1;
     unsigned int nBlockPos = 0;
-    if (!WriteToDisk(nFile, nBlockPos))
-        return error("AcceptBlock() : WriteToDisk failed");
+    if (!fClient)
+        if (!WriteToDisk(nFile, nBlockPos))
+            return error("AcceptBlock() : WriteToDisk failed");
     if (!AddToBlockIndex(nFile, nBlockPos))
         return error("AcceptBlock() : AddToBlockIndex failed");
     // Relay inventory, but don't relay old inventory during initial block
-    if (hashBestChain == hash)
+    if (!fClient && hashBestChain == hash)
         CRITICAL_BLOCK(cs_vNodes)
             foreach(CNode* pnode, vNodes)
                 if (nBestHeight > (pnode->nStartingHeight != -1 ?
pnode->nStartingHeight - 2000 : 55000))
 -2405,6 +2415,8          {
             if (fShutdown)
                 return true;
+            if (fClient && inv.type == MSG_TX)
+                continue;
             pfrom->AddInventoryKnown(inv);
             bool fAlreadyHave = AlreadyHave(txdb, inv);
 -2441,6 +2453,9              if (inv.type == MSG_BLOCK)
             {
+                if (fClient)
+                    return true;
                 // Send block from disk
                 map::iterator mi =
                 if (mi != mapBlockIndex.end())
 -2486,6 +2501,8      else if (strCommand == "getblocks")
     {
+        if (fClient)
+            return true;
         CBlockLocator locator;
         uint256 hashStop;
         vRecv >> locator >> hashStop;
 -2556,6 +2573,8      else if (strCommand == "tx")
     {
+        if (fClient)
+            return true;
         vector vWorkQueue;
         CDataStream vMsg(vRecv);
         CTransaction tx;
 -2620,6 +2639,33          if (ProcessBlock(pfrom, ))
             mapAlreadyAskedFor.erase(inv);
+    }
+    else if (strCommand == "headers")
+    {
+        if (!fClient)
+            return true;
+        vector vHeaders;
+        vRecv >> vHeaders;
+        uint256 hashBestBefore = hashBestChain;
+        foreach(CBlock& block, vHeaders)
+        {
+            block.vtx.clear();
+            printf("received header %s\n", block.GetHash().ToString().
+            CInv inv(MSG_BLOCK, block.GetHash());
+            pfrom->AddInventoryKnown(inv);
+            if (ProcessBlock(pfrom, ))
+                mapAlreadyAskedFor.erase(inv);
+        }
+        // Request next batch
+        if (hashBestChain != hashBestBefore)
+            pfrom->PushGetBlocks(pindexBest, uint256(0));
     }

@_date: 2013-07-21 19:20:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Introducing BitcoinKit.framework 
Actually bitcoinj typically doesn't download all the headers (just from the
last checkpoint) and it throws away headers that are very old. By now
there's quite a lot of difference in how they manage things and I guess it
will diverge from bitcoind even more in future. For instance we're going to
start only storing relevant outputs in the wallet and doing other things to
try and save memory. Some people managed to get themselves wallets that
don't actually fit in ram :(

@_date: 2013-07-22 15:08:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Introducing BitcoinKit.framework 
As an FYI, I've sent Wendell and co some example code for how to use CPPJVM
to use bitcoinj from native code. A rather rough Hello World app looks like
So, fairly C++ like.
Further discussion of this should take place on the bitcoinj mailing list.

@_date: 2013-07-22 15:14:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [RFC] Proposal: Base58 encoded HD Wallet 
This isn't usable for SPV wallets unless it has a birthday in it. Otherwise
you either need to scan the entire chain (slow) or find a fully indexed
copy of the block chain (expensive, more centralised). Just add a UNIX time
as an extra 4 bytes, or if you want to save a few characters then use a
uint16 that represents "days since birth of this specification".

@_date: 2013-07-23 22:01:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Linux packaging letter 
Some of us have put together an open letter to the Linux packaging
community, outlining why Bitcoin is different to other programs and asking
them to not patch or modify the upstream sources.
Please consider signing it if you agree (I think the wording by now is
fine, so don't edit the contents - use the comment feature if you want to
The trigger for this is the discovery that Debian bitcoind's got split out
of the consensus some time in April, for reasons that nobody yet figured
out but is presumably related to a patch (eg it uses system leveldb).

@_date: 2013-07-23 22:32:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Linux packaging letter 
Yes. Someone decided to actually delete the people who had signed so far
and replace it with a request for PGP signing - no. Not everyone even uses
PGP, which is overkill for this anyway.
I'm going to roll the document back and lock it. Sorry, I had hoped people
would respect my request to not fiddle with the content, which they did not
If you'd like to have your name on it, let me know or post here and I'll
add it.

@_date: 2013-07-24 10:28:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Linux packaging letter 
Yeah, if anyone wants to make the letter more digestable please do propose
an alternative, although by this point it's probably not worth it as people
have already signed.
FWIW, Gregory is right that my original draft was much more brusque. The
pain in the packaging relationship travels both ways. I have in the past
wasted a lot of time due to bogus packaging applied by non-expert packagers
that broke things. In fact the project I was a part of adopted a policy of
automatically closing bug reports from people who were using distributor
packages (any distro) because the quality was so inconsistent and so many
subtle bugs were introduced.
If packagers hear upstreams cry about packaging a lot, I think you should
keep an open mind that some of them probably know what they're talking
about. We really shouldn't have to beg and cajole here. Saying "we have our
reasons and we want you to stop" should be enough.

@_date: 2013-07-30 10:40:45
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BitMail - p2p Email 0.1. beta 
For people who are interested in such technologies, I recommend looking at
It is written by Adam Langley, so it comes with some serious credentials
behind it. It provides asynchronous email-like messaging that's forward
secure, resistant to traffic analysis and the whole thing runs over Tor.
Messages are stored for a week and are strictly limited in size. There's no
spam because nobody has an address - instead you have to grant someone the
ability to message you by giving them a small file. So, not really intended
as an email competitor convenience wise, but it has many interesting ideas
and a reasonable GUI.
As a testament to the seriousness with which Pond takes forward security,
it can use the NVRAM in a TPM chip to reliably destroy keys for data that
an SSD device might have otherwise made un-erasable.
The main downside - it's written in Go :)

@_date: 2013-07-30 14:12:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BitMail - p2p Email 0.1. beta 
The TPM is a piece of secure* hardware that provides various cryptographic
services to the host system. It is important to understand that it is not a
crypto accelerator. It is a place to store keys and small pieces of data
(like hashes, counters) where it's difficult for someone to extract them
even if they have physical access.
The TPM is designed to support trusted computing, a rather splendid set of
extensions to the x86 architecture that let you do remote attestation,
software sealing and other things. Or at least it would be splendid if it
had been really finished off and pushed to completion by the designers.
Unfortunately due to various political issues it exists in a
quasi-finished, semi-broken state which only experts can use. Without a
doubt you have never run any software in a TC environment.
As part of that role, the TPM provides some permanent storage in the form
of NVRAM. Because the TPM is designed to be as cheap as possible, it has a
limited number of write cycles. Normally you're meant to store Intel TXT
launch control policies and sealed keys there, but Pond uses it in a
different way by storing keys there that it encrypts local data with. By
erasing the key in the TPM chips memory area, the data on disk is
effectively destroyed too.
This is useful because modern "disks" are often SSD drives, or physical
metal disks that use log structured file systems. Because flash memory has
a limited number of write cycles per cell, internally SSDs have firmware
that remap writes from logical addresses to different physical addresses,
the goal is to avoid wearing down the drive and extend its useful life.
Normally it doesn't matter, but if you want to delete data such that it's
really really gone, it obviously poses a problem. Using TPM NVRAM solves
it, albiet, at a high usability cost.
*note: actual tamper resistance of real-world TPM chips is not something
that seems to have been studied much

@_date: 2013-07-30 14:41:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Tor and Bitcoin 
Various ideas are possible:
* Use the Tor SOCKS proxy in such a way that it creates a guaranteed
independent circuit to a different exit node each time you connect. This
gets you back to the slightly stronger clearnet heuristic of "if I saw a
bunch of peers announce my tx, then it's probably valid". I don't know if
this is possible.
* Have a set of hard-coded long term stable hidden peers, that are run by
known community members who are not going to collaborate to defraud people.
Of course if they're run by people who are well known that rather defeats
the point of them being hidden, but you benefit from the fact that the
.onion names double as authentication tokens.
* Talk the Tor protocol directly and have the app explicitly pick its own
diverse set of exit nodes, one per p2p connection. This is likely to be
complicated. Last time I looked Tor doesn't provide any kind of library or
I agree that it's a kind of theoretical attack right now, but then again,
I'm not aware of any countries that block Bitcoin either. The thing with
Thailand seems like it might be the result of some confusion over who
exactly can make laws in that country. I'd be more concerned about
Argentina, but we're a long way from ISPs searching for people to arrest by
looking for port 8333.
Supporting SOCKS (really: blocking sockets) would be a good thing anyway.
Using blocking sockets also means we'd get SSL support, so if at some point
Bitcoin nodes start supporting SSL we'd be able to use it more easily.

@_date: 2013-07-31 00:17:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [bitcoin-list] BitMail - p2p Email 0.1. 
TPMs have come as standard with nearly all computers (except Macs, doh) for
a long time. They certainly don't cost $100. More like a few dollars at
most. That's why they're so slow.

@_date: 2013-07-31 10:59:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
Woo, huzzah :-)
Now the BIP draft is available and we know it all hangs together, I'm
hoping to (re)start implementation work in bitcoinj in the next month or
two. I'm currently trying to figure out which is more important,
deterministic wallets or payment protocol, but I think right now the
payment protocol would be easier to do and would benefit more from a second
implementation. HD wallets have already been shown interoperable.
Comments on BIP 70:
   "PaymentRequest messages larger than 50,000 bytes should be rejected by
the merchant's server, to mitigate denial-of-service attacks."
Do you mean "users wallet" here?
You could note in the motivation section two more motivations:
1) That the protocol can be a foundation on which other features are built
2) That it is required to assist hardware wallets when there is a virus on
the system
Perhaps note in the BIP that the merchant should not assume the
merchant_data field is trustworthy - malicious buyers could rewrite it as
they see fit. Point out that a good way to use this is to serialize server
state, signed by a merchant-only key, in the same way one might use an HTTP
   "PaymentDetails.payment_url must be secure against man-in-the-middle
attacks that might alter Payment.refund_to (if using HTTP, it must be
This says "must", but what should a client do here if the payment URL is
not HTTPS? I suggest weakening this to "should", as sometimes TLS is
redundant (e.g. if you're sending to a Tor hidden service).
The PaymentACK message contains a copy of Payment, but the BIP doesn't say
what to do with it. I assume this means a client is free to ignore it and
rely on TCP state to figure out the payment/ack connection instead? It may
be worth noting that explicitly.
In the certificates section, you could observe that "validation" means
"verification that it correctly chains to a trusted root authority, where
trusted roots may be obtained from the operating system. If there is no
operating system, the Mozilla root store is recommended".
All the rest LGTM.

@_date: 2013-07-31 11:08:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [bitcoin-list] BitMail - p2p Email 0.1. 
"Support" for a TPM is a rather tricky thing.
By itself the TPM is independent of any CPU. However, it's also not very
useful (though for Pond's use case, it works).
The TPM gets much more useful when it's integrated with features on the
motherboard, BIOS, CPU, northbridge, IOMMU etc. Then you have a full blown
TCG-compliant TC environment, which is useful for many things. Actually it
was never very useful for DRM - that was only one theoretical possibility
that was never implemented and even if it had been, TC is to DRM much as
cryptography is to DRM. So the FUD was just that: fear, uncertainty and
doubt which probably crippled a highly useful cryptographic security tool
for good. One of the more shameful periods of the tech industries history,
if you ask me.

@_date: 2013-07-31 17:54:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [bitcoin-list] BitMail - p2p Email 0.1. 
Sorry, I just noticed that this thread was CCd to the announce list not the
development list (why is it open access?)
It's offtopic anyway. Let's continue this discussion in private if anyone
wants to.

@_date: 2013-06-06 11:03:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Revocability with known trusted escrow 
That's not how I read it, I don't see how one could argue that irreversible
transactions are a money laundering tool. Credit card transactions aren't
completely reversible either, you have to either claim that the card was
stolen or that the merchant didn't deliver. If you charge back routinely,
then the card companies are supposed to crack down on you. Though I don't
know if that really happens.
I think we should expect the head of FinCEN to argue that more or less
anything can be seen as money laundering. She directly and personally
profits from expansion of the notion of money laundering. That doesn't mean
other people have to agree.
I think we need 2-of-3 dispute mediation and have thought that for a long
time, indeed, Satoshi's paper says so:
It doesn't require any core protocol changes but it does require deployment
of the payment protocol first, as that's the foundation on which we can add
lots of other useful features like that. And then it needs a whole lot of
work to define how you open a dispute from your wallet, how you find
mutually agreeable mediators, etc. Having reversible payments in which one
of the trading parties gets to decide whether to reverse seems pointless to
me. If the buyer decides it's simply equivalent to post pay, and if the
seller decides then it's just a refund, which the payment protocol already

@_date: 2013-06-17 23:19:21
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.9 
I'm pleased to announce the release of bitcoinj 0.9, a Java library for
working with the Bitcoin protocol. Both simplified and full verification
are supported. BitcoinJ has been used to create everything from end-user
wallet apps to network crawlers to SatoshiDice.
To get bitcoinj 0.9, check out our source from git and then run *git fetch
--all; git checkout **67b187c4c4c4*. This will place you on the 0.9 branch
in a secure manner. The roots of trust are the announcement sent to
bitcoinj-announce (which is signed by the google.comDKIM key) and the Maven
page of the bitcoinj website. This paragraph is signed with the same key as
the previous releases (16vSNFP5Acsa6RBbjEA7QYCCRDRGXRFH4m). In addition,
the 0.9 release is signed by Andreas Schildbach (GPG key id 0x8B877A60,
accessible via  and can be
verified with *git tag -v 0.9* once you have his key.
Signature for the last paragraph:
 IEVMFkGVfE5Q7mezpNc2srdMXMkE66AEW2g7AtWa2KGa2PcK5ehqGbKPOWaL2oftcN/939VHWViMLnCKGrS3E9g=
We have a new article in the documentation library, Working with
 It shows how to create and use multi-signature transactions, signed by
different parties, using a simple API.
*New in this release*
   - Thanks to Matt Corallo, we now have a basic *fee solver* that will
   attach the correct (minimum) fee per kilobyte to a created transaction
   using the 0.8.2+ fee rules. Note that there's no attempt to minimize the
   size of a calculated transaction and thus fee, but some other optimisations
   are applied. By default bitcoinj will always attach a fee, to learn how to
   customise this refer to the article *Working with the wallet*.
   - The wallet's re-org handling code was rewritten and simplified.
   - A new class, WalletAppKit, simplifies the process of instantiating all
   the objects and files that are needed to run a basic app that can
   send/receive money.
   - Add optional support for Pieter Wiulle's native secp256k1
   implementation, which is significantly faster than Bouncy Castle.
   - Improvements to coin selection in the wallet.
   - Many new functions and minor API improvements, for instance, it's now
   easier to tell the wallet to allow spending of unconfirmed coins.
   - A new ScriptBuilder class simplifies the process of constructing
   various kinds of scripts.
   - A new block importer tool can parse bitcoind block files and process
   them, which is faster than streaming them over a network connection.
   - Support for the regtest mode added by the C++ side pull req 2632. This
   makes app development and testing easier by eliminating the need to wait
   for a block.
   - Many bug fixes and testing improvements.
*API changes*
   - NetworkParameters has now been refactored into separate classes.
   - Wallet extensions have been tweaked, please refer to the javadocs for
   details.
   - Many other minor additions and changes that are mostly backwards
   compatible.
*Known issues*
Please see the limitations and missing features
page on
our website.

@_date: 2013-06-18 21:48:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version message 
It's not a bug (although there was recently a change to make bitcoind/qt
always send this field anyway).
I don't know where Amir is going with BIP 60. Version messages have always
been variable length. There's nothing inherent in the Bitcoin protocol that
says all messages are fixed length, indeed, tx messages are allowed to have
arbitrary data appended after them that gets relayed.

@_date: 2013-06-19 11:39:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version message 
It has to be optional because old clients don't send it, obviously.
Why is this even an issue? There's no problem with variable length messages
in any codebase that I'm aware of. Is this solving some actual problem?

@_date: 2013-06-19 12:43:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version message 
Bitcoin-Qt on master does send it now although it doesn't affect anything,
but as old pre-filtering versions will continue to exist, you'll always
have to be able to deserialize version messages without it.
Bitcoin version messages have always had variable length, look at how the
code is written in main.cpp. If you didn't experience issues until now all
it means is that no sufficiently old nodes were talking to yours.
The standard does not say it should appear. Read it again - BIP 37 says
about the new version message field:
If false then broadcast transactions will not be announced until a
filter{load,add,clear} command is received. *If missing or true*, no change
in protocol behaviour occurs.

@_date: 2013-06-19 15:20:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version message 
If you want to criticise the Bitcoin protocol for sloppyness, the variable
length of some messages isn't where I'd start.
Note that ping has the same issue, its length has changed over time to
include the nonce.
If your parser can't handle that kind of thing, you need to fix it. The
protocol has always worked that way.

@_date: 2013-06-20 09:10:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version message 
The protocol version was bumped when Bloom filtering was added so there's
not much point bumping it again - you have to handle the old clients no
matter what. Nobody brought this up as an issue when the BIP or code was
first written and as you can see from main.cpp, it was done this way to be
consistent with how other version fields are handled:
        if (!vRecv.empty())
            vRecv >> addrFrom >> nNonce;
        if (!vRecv.empty())
            vRecv >> pfrom->strSubVer;
        if (!vRecv.empty())
            vRecv >> pfrom->nStartingHeight;
        if (!vRecv.empty())
            vRecv >> pfrom->fRelayTxes; // set to true after we get the
first filter* message
The existence of the nStartingHeight field for instance depends on the
message length and not anything else.
Anyway, are you really asking for the protocol to be changed to work around
an issue specific to how you wrote your parsing code? This is the first
time anyone has suggested this minor detail is a problem. It doesn't
present any issues for the C++ code or bitcoinj where message objects know
their own length at parse time.

@_date: 2013-06-20 09:32:22
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Optional "wallet-linkable" address format 
Agree with Jeremy and once the payment protocol work is further along I'd
like to see us define an extension that lets you send payment requests
containing public keys+chain codes, so further payments can be made
push-style with no recipient interaction (e.g. for repeated billing). How
apps choose to arrange their chains internally seems like an area for
experimentation. I definitely want to implement HD wallets in bitcoinj to
allow this and if that means not using the same tree structure as in the
BIP then so be it.

@_date: 2013-06-20 09:36:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version 
Sure but why not do that when there's an actual new field to add? Does
anyone have a proposal for a feature that needs a new version field at the
moment? There's no point changing the protocol now unless there's actually
a new field to add.
Anyway I still don't see why anyone cares about this issue. The Bitcoin
protocol does not and never has required that all messages have a fixed
number of fields per version. Any parser written on the assumption it did
was just buggy. Look at how tx messages are relayed for the most obvious
example of that pattern in action - it's actually the raw byte stream
that's stored and relayed to ensure that fields added in new versions
aren't dropped during round-tripping. Old versions are supposed to preserve
fields from the future.

@_date: 2013-06-20 10:31:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version 
You can't eliminate the complexity (yet), otherwise you wouldn't be able to
talk to old nodes. You'll have to wait until versions prior to a particular
version are hard-forked off and can be safely dropped at connect time.
That said the reason I'm being so grumpy about this is that compared to the
complexity in the rest of the system, this is such a trivial and minor
detail. It's hardly even worth thinking about. I mean, we have a scripting
language full of opcodes nobody ever figured out how to use and the
protocol uses a mixture of byte orders, so an optional field in the version
message is really not such a big deal :)

@_date: 2013-06-20 11:17:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version 
There's no problem, but there's no benefit either. It also locks us in to a
potentially problematic guarantee - what if in future we want to have, say,
two optional new pieces of data in two different messages. We don't want to
require that if version > X then you have to implement all features up to
and including that point.
Essentially the number of fields in a message is like a little version
number, just for that message. It adds flexibility to keep it that way, and
there's no downside, seeing as that bridge was already crossed and people
with parsers that can't handle it need to fix their code anyway.
So I have a slight preference for keeping things the way they are, it keeps
things flexible for future and costs nothing.

@_date: 2013-06-20 12:50:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version 
Sure, the issue isn't running out of integers, it's that you have to handle
the case of truncated messages whether you like it or not so it doesn't add
any simplicity. Even if Bitcoin-Qt starts only sending the new field with a
new version number, there are tens of thousands of bitcoinj based wallets
out there now that send the current version number and the fRelayTx field
as well, so you cannot assume anything about whether the field will exist
or not based on the version number regardless of what is changed on the C++
side. Assuming you care about your code being able to serve Bloom-filtering
clients of course.
With regards to relying on quirks, etc, this is the old "is the protocol
defined by Satoshi's code" debate again ... as I said, version messages
have always had a variable number of fields. You didn't notice before
because it was a long time since any fields were added. Perhaps it's indeed
not ideal, perhaps if Bitcoin was designed in 2013 it'd be using protobufs
or some other pre-packaged serialization system. But it is what it is.

@_date: 2013-06-20 12:58:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Missing fRelayTxes in version 
As I said, there's no benefit. Even if we do that on the C++ side, you
still have to handle connections from bitcoinj clients which will send the
field with the old version number. You can't assume they'll all be updated
simultaneously, even though both the Android app and MultiBit do have
update notifications these days and eventually old versions will presumably
Re: flexibility. Let's say version V+1 adds a complicated new set of data
to some messages. Not every client wants or needs the feature enabled by
Now version V+2 adds a simple extension to a basic message that everyone
To get the latter feature, all clients now have to support the first
feature as well because the version number is monotonic.
OK, we can use a service bit to handle these cases, if we anticipate that
not all clients will want the first feature. But then again, we can also
use the presence of the additional data as the ground truth instead of
duplicating that fact. I don't really mind either way. It just seems that
parsing always requires you to be able to handle truncated messages anyway
(without asserting or crashing), because a bogus client can always send you
partial data. So I don't see what effort is saved.

@_date: 2013-06-21 10:20:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] CTxIn::nSequence 
Indeed, and for a higher level answer, see here:
On Fri, Jun 21, 2013 at 6:03 AM, Patrick Strateman

@_date: 2013-06-28 11:05:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
Yes. There were a number of lock cycles that didn't cause issues so
much when traffic was lower and as Bitcoin got more popular it became
a critical problem. I redid a lot of the concurrency to fix that, and
now all the core locks are cycle detecting so regressions should be
detected fairly fast. I'm still making changes to the concurrency
design but mostly to improve the API at this point, not fix bugs.
There is one deadlock I'm still aware of, thanks to Netty. However
it's very rare and was only reported by someone who kept a server
running for many days in a row. We want to junk Netty soon anyway.
It's a network library but it doesn't really add much value for our
use case and it turned out to have some serious design issues
Yeah. That's not the primary privacy issue with bitcoinj though. I'm
much, much more concerned about leaks via the block chain than the
network layer. Especially as Tor is basically a giant man in the
middle, without any kind of authentication you can easily end up
connected to a sybil network without any idea. I'd be surprised if Tor
usage was very high amongst Bitcoin users.
It does actually, but the iconography is not very clear. I'm not
convinced any users really care about the difference between two and
three blocks these days. Maybe exchanges and other security-critical
applications do, but I doubt desktop users do.
It's not a library limitation anyway, it's a case of how best to
present information to a user who is not familiar with how Bitcoin
works. "Safe" and "Not safe" is still a rather misleading distinction
given the general absence of double spends against mempool
transactions, but it's still a lot more meaningful than "2 confirms"
vs "3 confirms", something that would just make a new user ask what
the heck a confirm is.

@_date: 2013-06-28 11:10:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
I'm hoping that if we start promoting alternative wallets their dev
communities will get larger. Most bitcoinj code is peer reviewed, but
not to the same extent that Bitcoin-Qt is.
We're obviously not going to stop promoting Bitcoin-Qt as well. I
think the distinction should be:
 * Want to get started fast? Grab MultiBit and you'll be under way in
a couple of minutes.
 * Want to help out the Bitcoin network? Leave your computer switched
on all the time and run Bitcoin-Qt instead. It will donate some of
your computers resources to running the Bitcoin system.
The MultiBit interface is OK but all desktop wallets could use some
love from a friendly UI designer.

@_date: 2013-06-28 12:20:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
I suspect what you saw is mining nodes restarting and clearing their
mempools out rather than an explicit policy of replace by fee.
On Fri, Jun 28, 2013 at 12:09 PM, John Dillon

@_date: 2013-06-30 13:42:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
Sounds like we have consensus, Saivann, shall we do it?
I'm also going to ask Theymos again to relax the newbie restrictions
for the alt client forums. It's probably too hard to get support at
the moment and "email jim" doesn't scale at all.

@_date: 2013-03-07 18:42:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Large-blocks and censorship 
To summarize your post - it's another go at arguing for strongly
limited block sizes, this time on the grounds that large blocks make
it easier for $AUTHORITY to censor transactions? Is that right?

@_date: 2013-03-07 22:19:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Large-blocks and censorship 
As an aside, there's a paper coming out in perhaps a few months that
describes a new way to provide Chaum-style privacy integrated with
Bitcoin, but without the use of blinding and without any need for
banks. It's quite smart, I was reviewing the paper this week.
Unfortunately the technique is too slow and too complicated to
actually integrate, but you'd probably get a kick out of it. It's
based on zero knowledge proofs. You can talk to Ian Miers if you like,
perhaps he'll send you a copy for review.
Back on topic.
This idea is not new. I proposed the idea of regulating miners to
freeze certain outputs two years ago:
   I concluded that it was not a real risk because both mining and
transactions can be done anonymously.
Your argument rests on the assumption that you can't mine large blocks
anonymously because Tor doesn't scale. Even if we go along with the
idea that Tor is the only way to escape regulation (it's not), you
should maybe take up its inability to move data sufficiently fast with
the developers. Given that they routinely push two gigabits/second
today, with an entirely volunteer run network, I think they'll be
surprised to learn that their project is doomed to never be usable by

@_date: 2013-03-11 17:54:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Blocking uneconomical UTXO creation 
Why does demurrage even still come up? The base rules of Bitcoin will
not be changing in such a fundamental way.
With regards to trying to minimize the size of the UTXO set, this
again feels like a solution in search of a problem. Even with SD
abusing micropayments as messages, it's only a few hundred megabytes
today. That fits in RAM, let alone disk. If one day people do get
concerned about the working set size, miners can independently set
their own policies for what they confirm, for instance maybe they just
bump the priority of any transaction that has fewer outputs than
inputs. An IsStandard() rule now that tries to ban micropayments will
just risk hurting interesting applications for no real benefit. It's
like trying to anticipate and fix problems we might face in 2020.
There are lots of less invasive changes for improving scalability,
like making transaction validation multi-threaded in every case,
transmitting merkle blocks instead of full blocks, moving blocking
disk IO off the main loop so nodes don't go unresponsive when somebody
downloads the chain from them, and finishing the payment protocol work
so there's less incentive to replicate the SD "transactions as
messages" design.

@_date: 2013-03-11 23:19:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Blocking uneconomical UTXO creation 
Firstly, the UTXO set is a LevelDB, it's not stored in memory. Outputs
that never get spent are not in the working set by definition, after a
while they just end up in the bottom levels and hardly ever get
accessed. If need be we can always help LevelDB out a bit by moving
outputs that we suspect are unlikely to get spent into a separate
database, but I doubt it's needed.
Secondly, if an output can be proven unspendable it can be pruned
immediately. We already reached consensus on adding some standard
template using OP_RETURN that results in insta-pruning. So people who
want to create unspendable outputs can do so with the only side-effect
being long term chain storage. It would be effectively "free" to
pruning nodes.
So the issue is not really with unspendable outputs but with low-value
spendable outputs. Wallets with lots of tiny outputs end up generating
large transactions that take a long time to verify, in situations
where the network redlines those transactions would end up at the
bottom of the priority queue and might take longer to confirm. So
wallet apps already have incentives to try and find a good balance in
output sizes and defragment themselves if their average output gets
too low in value, eg, by send-to-self transactions at night.

@_date: 2013-03-11 23:39:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Blocking uneconomical UTXO creation 
RAM is used as a database cache.
But regardless, what kind of attack are you thinking of? Using up all
available disk seeks by sending a node a lot of fake transactions that
connect to unspent outputs, but have invalid transactions? You'll get
yourself disconnected and the IP banned even with todays code.
It's much easier to hose a node by just asking it to send you the
block chain. Watch your own node when something is syncing the chain
from it. Ping times go through the roof because there's only one
network thread. If you're worried about DoS attacks on Bitcoin, it'd
be better to fix that first.

@_date: 2013-03-12 10:10:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Warning: many 0.7 nodes break on large 
Just so we're all on the same page, can someone confirm my
understanding  - are any of the following statements untrue?
BDB ran out of locks.
However, only on some 0.7 nodes. Others, perhaps nodes using different
flags, managed it.
We have processed 1mb sized blocks on the testnet.
Therefore it isn't presently clear why that particular block caused
lock exhaustion when other larger blocks have not.
The reason for increasing the soft limit is still present (we have run
out of space).
Therefore transactions are likely to start stacking up in the memory
pool again very shortly, as they did last week.
There are no bounds on the memory pool size. If too many transactions
enter the pool then nodes will start to die with OOM failures.
Therefore it is possible that we have a very limited amount of time
until nodes start dying en-masse.
Even if nodes do not die, users have no way to find out what the
current highest fees/bids for block space are, nor any way to change
the fee on sent transactions.
Therefore Bitcoin will shortly start to break for the majority of
users who don't have a deep understanding of the system.
If all the above statements are true, we appear to be painted into a
corner - can't roll forward and can't roll back, with very limited
time to come up with a solution. I see only a small number of
1) Start aggressively trying to block or down-prioritize SatoshiDice
transactions at the network level, to buy time and try to avoid
mempool exhaustion. I don't know a good way to do this, although it
appears that virtually all their traffic is actually coming via
blockchain.infos My Wallet service. During their last outage block
sizes seemed to drop to around 50kb. Alternatively, ask SD to
temporarily suspend their service (this seems like a long shot).
2) Perform a crash hard fork as soon as possible, probably with no
changes in it except a new block size limit. Question - try to lift
the 1mb limit at the same time, or not?

@_date: 2013-03-12 11:10:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Warning: many 0.7 nodes break on large 
However, most nodes are not running in such a loop today. Probably
almost no nodes are.
I suppose you could consider mass node death to be more benign than a
hard fork, but both are pretty damn serious and warrant immediate
action. Otherwise we're going to see the number of nodes drop sharply
over the coming days as unattended nodes die and then don't get

@_date: 2013-03-12 13:11:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Warning: many 0.7 nodes break on large 
I'm not even sure I'd say the upgrade "went wrong". The problem if
anything is the upgrade didn't happen fast enough. If we had run out
of block space a few months from now, or if miners/merchants/exchanges
had upgraded faster, it'd have made more sense to just roll forward
and tolerate the loss of the older clients.
This really reinforces the importance of keeping nodes up to date.

@_date: 2013-05-02 14:53:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP21 bitcoin URIs and HTML5 
Chrome has whitelisted bitcoin: URIs for web apps, and Firefox it turns out
doesn't use whitelisting at all, so it already works there.
I'm hoping this means web wallet developers won't be put off from
supporting the payment protocol (that risk is the reason I started this
The next step is to file bugs against WebKit (for Safari/iOS/misc other
platforms), and IE, though I don't know if Microsoft uses open bug trackers

@_date: 2013-05-03 16:06:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Service bits for pruned nodes 
That's true, but we can extend the DNS seeding protocol a little bit - you
could query .dnsseed.whatever.com and the DNS server
then only returns nodes it knows matches your requirement.
This might complicate existing seeds a bit, and it's a bit of a hack, but
protocol-wise it's still possible. Of course if you want to add more
dimensions it gets uglier fast.

@_date: 2013-05-03 17:02:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Service bits for pruned nodes 
Don't the seeds already set small times? I'm not sure we want these
responses to be cacheable, otherwise there's a risk of a wall of traffic
suddenly showing up at one set of nodes if a large ISP caches a response.
(yes yes, I know, SPV node should be remembering addr broadcasts and such).

@_date: 2013-05-06 10:19:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Service bits for pruned nodes 
You are welcome to optimise P2P addr broadcasts or develop better bootstrap
On Sun, May 5, 2013 at 3:12 PM, John Dillon

@_date: 2013-05-06 16:58:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Discovery/addr packets (was: Service bits for 
Subject change to reflect that this is off-topic for the old thread.
Eventually, I think it makes sense to move to a system where you get seeds
This obviously makes no difference from a security perspective. If a DNS
seed is compromised it can feed you nodes that just connect you back to the
sybil. If you seed from DNS then that's your root of trust.
The problem with moving away from DNS seeding for bitcoinj clients at least
is that SPV clients are very sensitive to startup time. It isn't OK to
spend two minutes trying to connect to lots of long-dead IP addresses if
you're wanting to pay your bill in a restaurant. That means either you have
to spin up a lot of TCP connections in parallel, which I know from bitter
experience can cause problems with some crappy wifi routers (they think
it's a synflood), or you get a known fresh source of IPs like a DNS seed
response and then later on bring up connections to the P2P network from
Implementing the latter is complicated - you have to partition your nodes
so the seed peers are separated from the peers you found via addr
broadcasts and seeded peers can't pollute your addr-found peers unless it's
your first run.
I've actually not experimented with this for a while. I'm hoping that by
the time this gets to the top of my todo list, network nodes will be stable
enough that actually you can always obtain at least one or two connections
if you try (say) 30 at once. But I have no idea if we're at that stage yet.

@_date: 2013-05-06 18:34:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Discovery/addr packets (was: Service bits 
I haven't seen that - remote nodes don't have any special code that
knows what kind of client is connecting, so if you're seeing delays I
suspect the issue is elsewhere. For example a seed that is serving
peers which are overloaded, or the general delays inherent to bringing
up a 3G data link from idle (this can take many seconds all by
I took out Jeffs seed a few weeks ago in git master because it was
often serving nodes that were full, so that should speed things up a
bit. The other seeds all run dynamic crawlers.
There are lots other ways to optimise performance beyond having fresh
seeds, for example, the Android app can (and probably will in future)
support putting Bluetooth MAC addresses in the URLs it serves via
QRcode/NFC. We prototyped it before but didn't finish. That means that
the sending side can provide the receiving side with a transaction via
a local Bluetooth socket, which eliminates the need to wait for P2P
bringup on the send side. In a typical merchant scenario the receive
side is more likely to have WiFi access and is more likely to be
talking to the network frequently, so its list of IPs gathered from
addr packets would be fresher, and it can do P2P bringup whilst the
user is confirming/signing/uploading on the sending side. Overlapping
the two buys precious seconds.

@_date: 2013-05-06 18:47:22
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Discovery/addr packets (was: Service bits 
Yes, I'd like to do this. The threat isn't really ISPs which are
mostly trustable (the worst they normally do outside of places like
China is dick about with ads), the big threat is people who use
untrusted WiFi without realising and end up thinking they received
money when actually they were just connected to a hotspot running in
the attackers pocket. I'm rather expecting that kind of thing to
happen in future.
I think we can converge on the best solution with several iterations:
Iteration 1) Make it clear in the UI that if the phone is connected to
WiFi, payments from untrusted people should not be accepted. Currently
the Android app merely says the money won't be spendable for a few
minutes. It needs to communicate the "may not exist" aspect more
clearly. If you're connected via a cell tower, the existing wording is
fine - it's very unlikely your telco is trying to scam you in a
person-to-person transaction, traffic is encrypted and 3G+ connections
authenticate the network so you can't be MITMd except by your telco.
Assuming you have a good list of IPs, of course.
Iteration 2) Give nodes keys that appear in addr broadcasts and seed
data (whether it be via https or otherwise), and have each node keep a
running hash of all messages sent on a connection so far. Add a new
protocol message that asks the node to sign the current accumulated
hash. Not all messages really need to be signed, eg asking for
signatures of blocks is sort of pointless at high difficulty levels
because the structures are self proving and a simple watchdog timer
that looks for unusually slow progress is probably enough. If the
client keeps the same accumulated hash then when you encounter
something you care about the accuracy of, you can ask for a signature
over all traffic so far.
Iteration 3) Do something about end to end encryption, just delegate
everything to Tor, or find some other way to obfuscate the origin of a
transaction (a mini onion network for example).
Last time I looked, Tor wasn't really usable in library form and
connecting to hidden services is really slow. So it'd be an issue to
just re-use it out of the box, I think.

@_date: 2013-05-07 11:00:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Discovery/addr packets (was: Service bits 
Yeah. Or just scam you at all. It's hard to imagine an organisation as
a big as a mobile carrier engaging in financial scamming (roaming fees
I've said this before, but I think it's worth repeating. The
double-spend protection the block chain gives you has a sweet spot
where it's really, really valuable (essential even) and then there are
lots of kinds of transactions on either side of that sweet spot that
don't really benefit from it.
Obvious/trivial case where you don't need a block chain - Facebook
buys Instagram for a gajillion coins. The legal system is plenty good
enough to ensure the payments are honoured. Another example, when my
employer pays me my salary. They aren't going to double spend this
except through some horrible accident that we can get sorted out some
other way.
Another case, very small payments. This is Satoshi's bag of crisps
example. If the cost/complexity of double spending is higher than what
the payment is worth, again, you don't really need the block chain.
That's why it's worth optimising unconfirmed transactions to be harder
to double spend, it optimises (pushes up) that lower bar.
Place where you really want the chain - largeish sums of money are
moving around, but not large enough to justify expensive
cross-jurisdictional legal action, or where the cost of identity
verification and all the associated paperwork is just too high. I
guess most online transactions fall into this bucket today.

@_date: 2013-05-07 11:17:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] limits of network hacking/netsplits (was: 
Security theater indeed - even if people check the signatures, where
did they get the identities of the signers/developers from?  Oh right,
the same website that served them the binary.
The signatures are useful for verifying the integrity of our mirrors.
The verify-bitcoin.sh script does this. Unfortunately it's not good
enough. I run it daily and from time to time it fails and says the
hashes don't match, which I assume means we may have a corrupted
mirror somewhere or the script itself is flaky. But the output is too
sparse to investigate. I modified it to print more data and am waiting
for it to fail again, unfortunately, I can't make it fail on demand.
Anyway. I've been thinking about this problem a fair bit. It's easier
to solve on some platforms than on others.
On Android, the Bitcoin Wallet app is protected by a few things:
1) Once installed, the device will only accept updates that were
signed by the same key as the original. So the auto update mechanism
is secure (including I believe against an attack by the store
operator, which is usually Google).
2) It appears at the top of the Play Store when you search for
"Bitcoin". Unfortunately the Store is somewhat gameable at the moment,
but that's getting fixed and more importantly over the long term, app
store operators have the right incentives to crack down on gaming of
search results. This combined with the reviews, ratings and social
recommendations of real users provides a series of signals that are
hard for an attacker/phisher to replicate. You can say to someone "Go
get the app called Bitcoin Wallet by Andreas Schildbach from the
store" and the chances they get the right thing, signed by the right
person, are very high.
3) I never got around to trying it, but the threshold RSA library I
obtained is theoretically capable of splitting the RSA keys used to
protect updates. I've talked to Andreas about this a little bit, and I
think he's open to the idea of splitting the Android signing key so it
requires a quorum of developers to release an update. This is Shoup
threshold RSA, not a Shamir secret share of the key bits.
4) The OS sandboxes apps from each other. That sandbox doesn't have a
great track record outside of Google-controlled devices because OEMs
and carriers don't have the right incentives to actually ship OS
security updates, but it's still a lot better than nothing and
hopefully over time these issues will get resolved.
All together this means users on phones and tablets have a somewhat
convincing security solution that fights against phishing and malware.
On MacOS X the binaries are signed under the legal identity of the
Bitcoin Foundation. Jim has started signing MultiBit with his legal
identity too (this is required to make Gatekeeper happy on recent
versions of MacOS). Unsigned binaries will not run by default on 10.8,
but anyone with a developer certificate can sign any binary. So whilst
a hacked bitcoin.org or a phishing site can distribute malware, at
least on OS X 10.8 it will require the user to override the built in
security systems, or it will require the malware author to steal a
developer certificate - probably not very hard but definitely raises
the bar.
On Windows antivirus companies operate what is effectively a form of
binary whitelisting. The new MultiBit release triggered AV warnings
for a few days until it got enough reputation to stop triggering. The
goal of these systems is to fight polymorphic viruses and they
understand code signing. If you reliably sign your binaries, positive
binary reputation accrues to your signing identity and not the binary
itself, so you can release updates and not get harassed.
On Linux we're actually the most exposed. It has by far the worst
situation of all - a culture in which man-in-the-middle attacks by
package maintainers are not only common but actively encouraged. The
Debian OpenSSL fiasco showed the critical danger this can place people
in. I believe we should have a health warning on the website telling
people to only get binaries from us unless they are on a distribution
that we are verifying doesn't apply any patches. But that's a ton of
work and I long ago burned out on the politics of Linux software

@_date: 2013-05-07 14:04:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] limits of network hacking/netsplits (was: 
Yes, it would be nice to have SSL but that requires finding
alternative file hosting.
Unfortunately we don't have any choice in what to use. There's no way
on Android to change the signing key after deployment, so we can
either split the existing key or do nothing.
There is a quorum-of-developers signing system using gitian and
reproducible builds, but as noted by Gregory, the problem is that
people don't check the signatures (even ignoring the web of trust
aspect which raises the complexity much higher). This sort of thing
works best when combined with an auto update engine or other kind of
software distribution platform.

@_date: 2013-05-09 17:40:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] 32 vs 64-bit timestamp fields 
2038 issues only apply to use of signed timestamps, I thought we treat
this field as unsigned? Is it really a big deal?

@_date: 2013-05-14 10:25:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] merged mining hashcash & bitcoin (Re: 
This is the fidelity bond/anonymous passport idea that has been kicked
around in the forums quite a few times. I mentioned it on the tor-talk once
as a solution to the problem that you cannot create Google accounts via Tor
without a phone number. It's a good idea but not new. I have encouraged
people to implement a server that does it and then some integration for
MediaWiki, Wordpress or phpBB, as they're both quite common software that
gets a lot of spam and abuse. For instance we could use it on our own wiki
instead of paying the wiki operator (does anyone know what happens to those
funds by the way?).
You don't need GPG or anything like that - the transactions that spend to
fees also contain pubkeys in the inputs, which you own the private keys
for. So you can sign a challenge nonce from the server to prove ownership
of the "passport"/fidelity bond.

@_date: 2013-05-15 19:22:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] blind symmetric commitment for stronger 
Conceptually it sounds a lot like ZeroCoin (not in implementation)?
I'm not really convinced miner cartels that try to exclude transactions are
likely to be a big deal, but such schemes could I suppose be kept in a back
pocket in case one day I'm proven wrong.

@_date: 2013-05-16 12:35:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Modularizing Bitcoin 
I'm all for funding of Bitcoin development, but I suggest talking to Gavin
to find out what efforts would be the biggest win right now. I don't see
why separating wallet code from the main Bitcoin process would increase
node count, as the cost of running the node is almost all in keeping up
with transaction traffic and time spent in the wallet is likely to dominate
only for large merchants or exchanges.
That said, you can already do this today - just run an SPV wallet like
bitcoinj connected to your personal node. The wallet code in bitcoind won't
be used for anything.
There are lots of things that can be done, but the best way to approach
this is to get tightly written technical requirements from people in the
know, and then contract with developers. Bounty style development has the
risk of uncoordinated development that duplicates work and puts pressure on
Gavin or other maintainers to accept shoddy code due to the "first past the
post" winning criteria. Finding developers you trust and contracting with
them for well specified improvements minimises risk for everyone.

@_date: 2013-05-20 20:27:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Double Spend Notification 
Indeed, that has been proposed but it's a dumb idea and I'm very sceptical
it will go anywhere.  Certainly no decision was made. The arguments for it
are based on some quite faulty thinking about economics. Double spend
notifications have been proposed a long time ago, I believe Matt has
indicated some interest in implementing them and that is the right way to

@_date: 2013-05-20 20:30:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] UUID to identify chains (payment protocol 
Bitcoinj already has such chain id's and we use standard Java style reverse
DNS names: org.bitcoin.main, etc. If we want a more global naming system
that seems like a good compromise between uniqueness and readability.

@_date: 2013-11-02 17:26:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Message Signing based authentication 
Guys, identity systems for the web are off-topic for this list. Other than
the anonymous passports/SINs/fidelity bond ideas, Bitcoin doesn't have any
relevance to it.
No, it wouldn't. You can log a user in using SSL and then redirect the user
back to an encrypted page, using cookies for the rest of the session.
Please don't clutter up this list with conspiracy theories. The brutal
reality is that identity is a hard problem.

@_date: 2013-11-02 17:26:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Message Signing based authentication 
user back to an encrypted page
sorry, I meant unencrypted page of course

@_date: 2013-11-04 12:26:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Auto-generated miner backbone 
W.R.T. this paper and the oft-discussed miner backbone,
  I'm wondering about an alternative protocol change that perhaps has less
subtle implications than their suggested change. Rather than address the
problem by assuming the network is full of sybil nodes and changing the
rules for selecting the chain to build on, how about if we wrote code to
automatically build a miner backbone by having IP addresses of nodes
embedded into coinbases, then having any bitcoind that is creating work
automatically connect to IPs that appeared in enough recent blocks?
This would have the effect of automatically linking all the major pools
together, with no administration overhead.
For bonus points, the IPs could be IPv6 and then the trick we use to pack
hidden services into IPv6 address space would allow nodes to be reached via
Tor. This might be useful in the case of pools that don't to reveal the
location of their bitcoin node[s], like for anti-DoS reasons.
It feels like this should be achievable with a few days of solid coding and
a couple of new command line flags, and the impact is much easier to reason
about than a fundamental rule change like the one proposed by the paper.

@_date: 2013-11-04 13:00:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Auto-generated miner backbone 
Ah yes, good point.
They could already create such a setup, but we don't observe it in practice.
Given that IP address data is inherently transient, perhaps a better
solution is to define a short hash in the coinbase that commits to extra
data that is relayed along with block data (e.g. appended to the block
message). It can then be stored temporarily in the block db and erased
after some time, like a few months. It would therefore not really be a part
of the chain, but could be extended as we see fit with any other
semi-transient data required. A new "getextra" message would let nodes
query for it.
The hash can be short because it doesn't have to survive brute forcing
attacks longer than the expected validity period of the transient data
anyway. 80 bits would probably be overkill.

@_date: 2013-11-04 13:03:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Auto-generated miner backbone 
Disagree. Unless I'm misunderstanding what they propose, their suggested
change would mean anyone could broadcast a newly discovered block at any
point and have a 50% chance of being the winner. That is a fundamental
change to the dynamics of how Bitcoin works that would require careful
thought and study.
Also, their solution doesn't really address the problem they bring up, it
just changes the size of the threshold required.
Fundamentally, their attack is a sybil attack. It doesn't work if they
can't delay or block a pools competitors because mostly their block will
come in second place and they'll lose the race. Thus the solution should be
a solution to sybil attacks.

@_date: 2013-11-04 16:27:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Auto-generated miner backbone 
So you're back to a complicated sybil attack. I don't follow your thought
process here - I didn't say anything about numerical advantage. The attack
outlined in the paper *requires* you to be able to race the rest of the
network and win some non-trivial fraction of the time. If you can't do that
then all it means is that when you try to release a private block to
compete with the other found block, you're quite likely to lose and you
sacrifice the block rewards by doing so.
There's no stable way to know that. The whole purpose of the block chain to
establish the majority. I think your near-miss headers solution is
circular/unstable for that reason, it's essentially a recursive solution.
But you can't reliably estimate that. You can't even reliably estimate the
speed of the overall network especially not on a short term basis like a
block interval.

@_date: 2013-11-04 20:38:09
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Committing to extra block data/a better 
I like the UUID-as-path idea. That resolves the problem of how to share the
alt-chain merkle tree quite nicely.
The Merkle branch doesn't get stored indefinitely though, whereas the
coinbase hash does. The data stored in the coinbase [output] can always
just be the 256-bit root hash truncated to less.
I doubt the additional bytes make much difference really, so the additional
complexity may not be worth it. But it wouldn't be an issue to do.

@_date: 2013-11-04 21:10:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Committing to extra block data/a better 
Yes, sure. I was talking about the case of transiently relayed data, like
IP addresses.

@_date: 2013-11-05 18:54:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP proposal - patch to raise selfish 
I think it would be helpful if you actually implemented and pulled off this
attack, by becoming the dominant miner capable of reversing spends at will.
Then we'd know how quickly it can be done.

@_date: 2013-11-06 10:23:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [ANN] High-speed Bitcoin Relay Network 
Very cool, thanks Matt.
I was actually thinking this morning, maybe we should require all nodes to
go through the inv/getdata dance. Otherwise it's possible to improve your
chances at racing a block by mining a block, waiting to see a block inv
from another node, then blasting out your block while other nodes are still
waiting on their getdatas.

@_date: 2013-11-07 16:22:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] On the optimal block size and why 
I think trying to help miners figure out the propagation/fees tradeoff at
the moment is a non-starter until we understand it better ourselves. A
server that tracks and records block propagation times, how many fees per
passed up per block, orphan stats per size bucket etc would be tremendously

@_date: 2013-11-07 17:14:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] we can all relax now 
Once the ASIC race calms down because everyone has one, has more or less
optimal power supplies, process improvements aren't easily reachable
anymore etc then I'd expect people to dissipate from the large pools
because eliminating their fees will become the next lowest hanging fruit to
squeeze out extra profit. There's no particular reason we need only a
handful of pools that control a major fraction of the hashpower.
If we end up with a few hundred pools or lots of miners on p2pool, then a
lot of these theoretical attacks become not very relevant (I don't think ID
sacrifices will be so common or large as to justify a pile of custom mining
code+strategies at any point ...)

@_date: 2013-11-08 12:46:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [ANN] High-speed Bitcoin Relay Network 
I took a brief look at the code - it's looking very reasonable. You can
replace any construct like
try {
  Thread.sleep(1000);
} catch (InterruptedException e) {
  throw new RuntimeException(e);
which is quite verbose, just with
Uninterruptibles.sleepUninterruptably(1000, TimeUnit.MILLISECONDS); (and of
course static imports help too)
I think for this concept to take off, you'd need a website and to recruit
someone to help you market it. Pool operators won't reach out to you.
I still find it perhaps more elegant to just boost the connectivity of the
existing network with bitcoind changes, but this can help for now.

@_date: 2013-11-10 12:08:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Extending the Payment Protocol with vCards 
Hey Taylor,
It's great to see people thinking about payment protocol extensions. I'm
not totally convinced vCard support is the best idea relative to social
network integration - I can't recall the last time I saw someone use a
vCard. However, that should not hold you back from experimenting or
prototyping. All an extension requires is some tag numbers and we're not in
danger of running out of numbers any time soon.
The reason I favour social network integration is because those are the
ID's people already have. Distributed social networks (like the PGP web of
trust) have never really taken off, and fixing that is an entirely separate
project to Bitcoin.
Doing so is quite easy. Major social networks all have a concept of a user
ID, moreover, one that can be queried without any kind of API authorization
for basic info. Examples:
So you could simply embed a social network URL into a payment request, and
use that to associate a name/photo with a payment. That would be
unauthenticated (the sender is not proving they are the real owner of the
social network profile). However, authentication may not turn out to be
necessary. If it were to be, then steganographically embedding a key into
the profile picture and signing the payment request with it would be a way
to do so.

@_date: 2013-11-15 21:02:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Testnet under attack? 
I don't use testnet much anymore, partly because it sometimes kind of
breaks like this. It's a public resource and people sometimes abuse it.
You can create your own local network with -regtest and that lets you mint
new blocks instantly. It's a much simpler way to do testing and app

@_date: 2013-11-21 14:48:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Who or what is /Satoshi:0.8.99/Gangnam 
I added some additional logging to my node and ran it for a few days.
There's a pull req open for my extra logging, it is quite trivial. Here's
what it looks like:
2013-11-21 13:41:04 AcceptToMemoryPool:
5.9.24.81:7834/Satoshi:0.8.99/Gangnam Style:2.1/ : accepted
2d1bbcc2bf64dfcb57a2f0180b2607a48a34de4422c446929b26b190083bbfe7 (poolsz
2013-11-21 13:41:05 AcceptToMemoryPool:
198.12.127.2:29057/Satoshi:0.8.99/Gangnam Style:2.1/ : accepted
28bb94978bdaa224faeafa95d03a0c4f5743396d6f592469c5ac2b64184ac716 (poolsz
2013-11-21 13:41:06 ERROR: AcceptToMemoryPool : nonstandard transaction:
2013-11-21 13:41:06
42323d9553e4c592d27765dc3ef9152c186cb7d67b08d783d72974a56085032d from
82.68.68.254:39232 /Satoshi:0.8.1/ was not accepted into the memory pool:
2013-11-21 13:41:06 AcceptToMemoryPool:
198.12.127.2:29057/Satoshi:0.8.99/Gangnam Style:2.1/ : accepted
2fdb19e5e87d518b7b6bb7371d547a5f60c2bb056ba4522190460f0bc41b51fb (poolsz
2013-11-21 13:41:08 AcceptToMemoryPool:
5.9.24.81:7834/Satoshi:0.8.99/Gangnam Style:2.1/ : accepted
52c8ed6a48f89d48b1152b67ac0b718a7aadb5f9a0c70c18b9b2fed058ca3323 (poolsz
2013-11-21 13:41:08 AcceptToMemoryPool:
198.12.127.2:29057/Satoshi:0.8.99/Gangnam Style:2.1/ : accepted
980bbdbd4a6b365fa6f13fb5247eb6cb1e54847e490c3b7c3026d1548fb9efc6 (poolsz
2013-11-21 13:41:08 AcceptToMemoryPool:
64.120.253.194:60896/Satoshi:0.8.99/Gangnam Style:2.0/ : accepted
03f79c611bbdc1afa7afa67eb0bbd4d8bc86a730a7066622e2709ae506e61e0f (poolsz
2013-11-21 13:41:10 AcceptToMemoryPool:
5.9.24.81:7834/Satoshi:0.8.99/Gangnam Style:2.1/ : accepted
af8096ad637af1ca022a5146e07cf1fc6bfbec877935f9e114b279fcfe26c06d (poolsz
2013-11-21 13:41:10 AcceptToMemoryPool:
5.9.24.81:7834/Satoshi:0.8.99/Gangnam Style:2.1/ : accepted
751c2415d058d45ca602fdf1b6490edb6e57fc718e914d628c11b17e25aac834 (poolsz
Despite that I have 87 connections from regular nodes, virtually all
transactions seen by my node are being announced by this modified software,
which appears to run on several different machines.
I am wondering if anyone out there knows/owns these nodes and if they are
relaying transactions without checking their validity. That seems the most
likely reason for how they are always able to win the race to be the first
to announce to my node.

@_date: 2013-11-21 15:47:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Who or what is /Satoshi:0.8.99/Gangnam 
Thanks. By the way, your bitnodes site is excellent. Thanks for doing that.
If you're in the mood for extending it, it'd be great to gather and chart
data on block and tx propagation times.
Do you think the recent explosion in running nodes is real, or due to some
kind of custom experimental thing?

@_date: 2013-11-24 17:38:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Network propagation speeds 
This is great, thanks for doing it. Tip sent your way.
Graphs of how propagation data change over time would also be helpful (as
well as raw data so we can calculate overhead per kilobyte and so on). I
know there are only two days worth of data, but for future, it'd be good.
I think the next part of figuring out why there's such huge disparity is
instrumenting bitcoind to find out where the time goes when relaying a

@_date: 2013-11-27 20:35:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Network propagation speeds 
Hey Christian,
Could you sort the snapshots by date? At the moment they're kind of in a
random order.
Sometimes I wish we had real-time stats too but this is a great start.
On Mon, Nov 25, 2013 at 8:27 PM, Christian Decker <

@_date: 2013-10-03 16:00:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Identity protocol observation 
Interesting observation, thanks.
I'd think any competent implementation of such an identity scheme would not
involve end users directly handling randomized nonsense words, however. I
always imagined a sacrifice as being a file that you make with a GUI tool
and load into a browser extension.

@_date: 2013-10-03 17:22:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Identity protocol observation 
1) Generate sacrifice proof file using an app
2) Load file into browser
3) Surf
Where are the names in that design? I'm not sure where NameCoin comes into
this. The point of a sacrifice is it's an anonymous identity, there's no
point attaching a name to it.
BTW I keep phone numbers in an address book ;)

@_date: 2013-10-04 12:30:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Code review 
Git makes it easy to fork peoples work off and create long series of
commits that achieve some useful goal. That's great for many things.
Unfortunately, code review is not one of those things.
I'd like to make a small request - when submitting large, complex pieces of
work for review, please either submit it as one giant squashed change, or
be an absolute fascist about keeping commits logically clean and separated.
It really sucks to review things in sequence and then discover that some
code you spent some time thinking about or puzzling out got
deleted/rewritten/changed in a later commit. It also can make it harder to
review things when later code uses new APIs or behaviour changes introduced
in earlier commits - you have to either keep it all in your head, do lots
of tab switching, or do a squash yourself (in which case every reviewer
would have to manually do that).
On a related note, github seems to have lost the plot with regards to code
review - they are spending their time adding 3D renderers to their diff
viewer but not making basic improvements other tools had for years.
So, I'd like to suggest the idea of using Review Board:
It's an open source, dedicated code review tool used by lots of big name
companies for their internal work. It has git[hub] integration and a lot of
very neat features, like the ability to attach screenshots to reviews. Also
more basic ones, like side by side diffs. Branches can be and often are
submitted to the system as single reviews.
The company behind it (disclosure - written and run by a long time friend
of mine) offers hosting plans, but we could also host it on a Foundation
server instead.

@_date: 2013-10-04 13:32:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Code review 
When the log messages don't accurately describe the contents of the diff,
it's just misinformation and noise. Everyone starts out by wanting a neat
collection of easy to understand and review commits, but in practice it's
extremely hard to always get it.
I know how to make squashed commits, thanks. I've done LOTS of code review
in my life. I'm making a point here as one of the few people who goes
through large pull requests and reviews them line by line. It's hard,
partly because github sucks, and partly because reviewing lots of small
commits sucks.
There's nothing that makes a single large commit harder to review. It's the
same amount of code or strictly less, given the tendency for later commits
to change earlier ones. You can easily search the entire change whilst
reviewing. There are lots of things that make it easier.
FWIW inside Google the code review process is one-commit-one-review.

@_date: 2013-10-04 14:14:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Code review 
The files changed tab definitely works better for reading. In the past
comments I put there have disappeared, but I think that can also be true of
comments put on the individual commit reviews (which is another issue with
github, but it's unrelated to how the commits are presented). So I have
lost trust in doing reviews that way. It does make things easier to read
One advantage of using github is that they're an independent third
I guess anyone would be able to sign up and comment.

@_date: 2013-10-05 13:36:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Code review 
Thanks, although I wasn't thinking specifically of you. The fee pull is
pretty well laid out. It just reminded me that it seems to be a common
issue I've had over the past year or so, across projects and people.
Yes, I don't know if github supports any kind of SSO. I will investigate.
As for learning another tool, well, when the current tool kind of sucks I
don't see any way around that one :)
Perhaps just have a separate section for people who helped review above the
current section? It seems a bit mean not to credit occasional contributors
who fixed bugs or maintained something important but didn't review
complicated changes to the core.

@_date: 2013-10-10 10:29:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] 0.8.5 with libsecp256k1 
Thanks! I'd love to see this library become usable behind a command line
flag or config setting. At some point we're going to want to switch to it.
I believe the main issue at the moment is the malleability issues? If so,
it would seem possible to use OpenSSL to parse the signature into
components and then libsecp256k1 to verify them.

@_date: 2013-10-20 00:33:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] A critique of bitcoin open source 
I was hoping to see something interesting and useful, but all I saw was
absurd ranting. Example quote:
It is not known where bitcoin contributors are based. Gavin Andersson, a
major contributor, is a well-known South African
anarchist/crypto-libertarian. Most contributors hide their identities.
I don't know who this guy is or why anyone should care what he thinks, but
I doubt any of us have time for someone who can't even be bothered spelling
Gavin's name correctly, thinks he is South African or would describe him as
an anarchist.
Open source development can be intimidating and brutal at times, it's
probably one factor that causes the massive gender skew. But many pages
have been written on that topic, here is probably not the right place to
thrash it out for the umpteenth time.

@_date: 2013-10-24 16:38:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Making fee estimation better 
This is interesting, but I suppose some miners may have business models
that can't be easily summed up as a "fee" - like all-you-can-eat deals with
certain providers, or preference to certain kinds of transactions etc.
For the concern that estimation might force fees down too far if miners
include private transactions, I thought the estimates were calculated only
on broadcast transactions, so transactions that just appear in a block
won't ever influence the estimate?

@_date: 2013-10-24 16:46:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Making fee estimation better 
Well, miners are all supposed to be more or less equivalent - modulo
differences in tx acceptance policies - so I'd hope that having out of bad
fee mechanisms yet still broadcasting the TX isn't that common. If it was
broadcasted, it should get mined in short order, otherwise things are going
I was thinking for transactions that aren't standard so have to be
submitted to miners directly.

@_date: 2013-10-27 15:32:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
Yeah, something like HTTP would work well.
I'm really looking forward to this. Currently bitcoinj gets a small but
steady stream of bug reports of the form "my transaction did not
propagate". It's flaky because the library picks one peer to send the
transaction to, and then watches it propagate across the network. But if
that selected peer refuses the tx for whatever reason, that propagation
never comes, and there's currently no timeout to make it retry with a
different node. The transactions as created usually look fine, so it's not
clear to me why some nodes would accept it others wouldn't given the
absence of double spends, and there's no way to debug and find out :(

@_date: 2013-10-27 15:50:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
These nodes are much more likely to just be broken than malicious, but
without any way to diagnose why they are dropping a transaction it's hard
to find out what's really going on.
Anyway, yes, I need to spend time adding timeouts and all kinds of other
things, although of course if the transactions are being rejected due to a
change in network rules that won't help either - if the nodes you're
connected to are silently eating your transaction, there's no sane UI that
can result from that without more explicit error handling.

@_date: 2013-10-28 14:21:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment protocol for onion URLs. 
A bit late is one way to put it. All these topics and more were discussed
to death a year ago when the payment protocol was first being designed.
Bluntly, I think we're all sick of it. You are welcome to PGP sign your
payment requests if you want to. If not, then please see my FAQ for
   tl;dr - the right way to tackle governments getting bogus certs issued is
certificate transparency. All other suggestions tend to boil down to
"here's some handwaving that doesn't actually solve the problem".
By the way, the evidence from the Snowden case rather reinforces the
strength of the CA system. Did we see stories about bulk usage of fake
certificates? No. What we read is that the increased usage of SSL was a
major game-changer for intelligence agencies. They "solve" SSL by compiling
databases of private keys they obtain in various ways. True to form when
the FBI wanted access to LavaBit, they tried to obtain his private keys
rather than just push a convenient "give me a fake cert" button, and when
it became known that Lavabit had to hand over their key, GoDaddy revoked
their certificate. Industry policies forced their hand and those policies
don't have a get-out clause for the FBI.
It's without a doubt that there are government-issued fake certs floating
about, somewhere, just due to the scale of hacking that's been taking
place. However, demanding perfection in a system that handles security for
over a billion people and tens of millions of operators is unreasonable.
All we can ask for is that it it's being improved, which through
initiatives like cert transparency, it is.
Please, let's call time on these discussions. They long ago ceased to have
any value.

@_date: 2013-10-29 10:52:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
For tx reject, should there be a code for "unknown version"? That is,
tx.nVersion > bestKnownVersion == reject? In that case 0x40 would become
"non-standard transaction type". I think "unknown transaction type" is a
bit vague. Or do we want new tx messages to always be backwards compatible?
0x42 and 0x43 seems a bit similar to me. The sender knows what fee was paid
(presumably). If free transactions and fee-paying transactions end up
having a unified ranking applied, then distinguishing between them in the
reject message won't make much sense.
For block 0x11 again shall there be a separate code for "block is from the
future"? We don't want to lose the nVersion field to people just using it
for nonsense, so does it make sense to reject blocks that claim to be v2 or

@_date: 2013-10-29 13:32:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
Yes, exactly. That's the point. As you well know I think the whole
soft-fork mechanism is wrong and should not be used. If the rules change,
your node is *supposed* to end up on a chain fork and trigger an alert to
you, that's pretty much the whole purpose of Bitcoin's design. Undermining
that security model is problematic.

@_date: 2013-10-30 09:24:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
Perhaps I'm confused about how we're using the term soft fork. My
understanding is that this is where a new upgrade is designed to look valid
to old nodes, and if you don't upgrade you rely on the miner majority to
get you "back on track". For instance, P2SH was done this way - old nodes
that didn't upgrade during that transition believed all spends of P2SH
outputs were valid, even those spending someone elses coins.
In this case, the code you cite won't do anything because your client will
never reject a block during a soft-forking upgrade, even if it does
something that's supposed to be invalid or nonsensical.
If a new block version changes the serialization format or script language
or SIGHASH rules such that old clients reject the block, then they will end
up on a hard fork and the alerting code will trigger, which is correct and
as it should be.

@_date: 2013-10-30 11:26:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
I was referring to the fork alerts that Matt did. They also alert you if
there's a missed upgrade.

@_date: 2013-10-31 13:01:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
============================== START ==============================
That's a good point, however, I would hope that this fairly trivial race
condition can be resolved. There's no requirement that a transaction be
placed into a buffer from which it can be removed before relaying. After
relaying - sure. But the gap of a few seconds between that shouldn't cause
any issues to eliminate.
I believe Gavin's smartfees branch adds mempool persistence to disk, so
restarting nodes won't clear the mempool in future. Or at least that's a
part of the longer term plan once mempool limiting is done.
I think measuring propagation will be a part of bitcoin wallets for the
forseeable future, although if all nodes reject that allows for a more
responsive and more helpful UI than just waiting for some arbitrary timeout
to elapse.

@_date: 2013-09-05 10:26:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] An "app store" and non-network 
Hey Wendell,
Interesting idea you have there!
It might be simpler to not think of it as an app store, but rather see it
as a set of affiliate schemes. To get placed into the apps section you can
say that the business must have an affiliate scheme in place (i.e. open to
more than just you) and then you use the normal mechanisms of affiliate
codes and so on. The apps don't have to be offline. They can (and probably
should) be online, so the businesses can retain control of their features
and brand. If you refer a lot of users to that business, you get the
referral bonuses. Affiliate schemes are a common way for open source
projects to monetize - e.g. Firefox development is largely paid for by
search engine referrals. It's compatible with the ideals of openness
because their income relies directly on their traffic, and there are
several competing search engines the projects can play off against each
other to get the best prices. Also, users expect search engine integration
these days, so they'd be sending search traffic regardless.
The main downside, of course, is it distorts technical judgement. You can
get projects pushing certain businesses heavily not because it's
technically the best thing for users, but because their income depends on
One alternative funding model you could explore is allowing users to bid on
assurance contracts for feature development. This means you think up a
bunch of improvements you could make, then allow users to pledge
Kickstarter-style towards their development. The upside is it allows the
community to direct development, and users feel directly involved and not
exploited. The downside is, no recurring income you can use to support
yourself whilst engaged in other endeavours.
2) Although our BitcoinKit.framework supports both bitcoind and bitcoinj,
Bear in mind that regardless of how much *you* want to support the network,
it's ultimately *your users* resources that will actually get spent. That's
why I'm a bit skeptical of any schemes that rely on random end users
donating lots of cpu time or bandwidth to the network. If they want to do
it, partial UTXO sets and other interesting ideas are worthwhile, but I
guess most users won't. I think Bitcoin will over time be more and more
like Tor where relays are run on dedicated servers by people who have some
modicum of knowledge and community involvement.

@_date: 2013-09-05 10:27:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] GB V04 
Please do not post about this on bitcoin-development again. It's off topic
and you were already asked to stop.

@_date: 2013-09-05 10:33:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Social network integration (brainstorm) 
I guess these days most Facebook/G+/Twitter users are logged in from their
smartphone , so you'd implement it as a mobile app that gets API access via
the standard mobile frameworks. The UI flows for this are highly optimised
and very slick. Once you have API access to read/write the users profile
picture, your app can just wake up from time to time and check if the users
profile picture has changed. If it did, download the highest resolution
available, rewatermark and reupload.
The main sticking point I can see is that the user might end up losing
comments or likes on their primary photo, which would upset some people,
and they might end up with duplicates if the old one was not erased. The
Facebook API docs are notoriously poor - it's unclear to me whether an app
can edit a photo after it was uploaded, or whether it can only create new
ones (deleting photos requires whitelisting by Facebook).
To read the users watermarked address requires no API access or account,
Probably you wouldn't want to watermark an actual Bitcoin address or key.
The capacity of social network photos to carry stegod data is very low due
to the incredibly high compression they go through. More likely you'd
encode a very short URL which contains a payment request and then users
would rotate their key from time to time at the hosting site.

@_date: 2013-09-05 12:14:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] An "app store" and non-network 
Well, it's a bit complicated and needs some software development to do
well. The best way to fund a complex project would be to raise the money
using an assurance contr.... oh wait ;)
It could be automatic in the sense that users don't need to know it's
happening, but look at it this way. Gavin believes the future of computing
is mobile and tablets. I don't know about that, but let's assume for the
sake of argument he turns out to be right. These devices are expected to
have much longer battery life than laptops. Apps that spin up in the
background and use battery+radio can easily be seen as "abusive" by end
users. In fact, if you look in the Bitcoin Wallet section of the forum,
you'll see a giant argument by users of the Android app who are upset
because the app sometimes runs in the background *just to keep up with the
chain*! That's not even donating resources, it's just trying to ensure it
doesn't fall behind, and this enrages some users because it can have a
small but non-zero battery/bandwidth usage impact.
Given the number of complaints generated by just having the app sync
automatically, imagine what would happen if we started relaying blocks!
Generally the ethos and modus operandi of desktops is different to laptops
which is in turn different to mobiles/tablets. Things you can get away with
on more powerful machines that expect to be plugged in all the time are
verboten on more modern devices.
Now that said, I can easily see Bitcoin enthusiasts buying some kind of
cheap embedded device, maybe Raspberry Pi based, and plugging it into a
wall in order to donate to the network. That way it doesn't affect their
primary devices responsiveness or storage or battery life.

@_date: 2013-09-05 14:49:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] An "app store" and non-network 
It needs people to use either a dedicated app or a wallet with the right
features. I've gone back and forth on whether it's better to have wallets
become featureful things or to have lots of separate apps. There are pro's
and con's to each.
Fortunately bitcoinj makes bringing up a new GUI wallet app quite easy
(well ... if you're writing it in java ;). So having a dedicated app just
for managing your pledges is quite straightforward.
At that point it's about contracts programming:

@_date: 2013-09-07 23:44:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Simple contacts exchange (was: Social 
This is the sort of thing the payment protocol is for. The recipient would
vend a PaymentRequest containing identity details. The sender would submit
a Payment containing his/hers. The wallet then understands what to do.

@_date: 2013-09-09 13:43:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Simple contacts exchange (was: Social 
The current version requires a signed cert yes. Whether that's difficult or
not depends on the policies of the cert authorities. Ultimately all they
have to do is verify an email address by sending it a clickable link, which
is why StartSSL do it for free. Probably they aren't optimised for
usability, but there's no technical reason why one couldn't be. It's a
competitive market, after all.
There's also the option of extending the payment protocol to support other
forms of PKI. But from a technical perspective the X.509 PKI is fine.
Someone can always set up their own CA for the Bitcoin community and
convince wallet developers to include their root cert, after all.

@_date: 2013-09-13 18:21:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bluetooth on Android 
Just a heads up,
Over a year ago Andreas and I prototyped bluetooth tx submission on Android
at a hackfest in Berlin, and it will be with support on-by-default for the
sending side soon. That means, anyone can enable the feature in the
settings page and start receiving payments via Bluetooth as long as both
sides use the Bitcoin Wallet app.
The protocol used is a set of proprietary things. Once the payment protocol
is implemented in bitcoinj, I guess we will recast the bluetooth support to
use that and then submit a BIP for it, but right now it wouldn't make sense
to do so as we know the current protocol has a limited lifespan.
Send via bluetooth resolves one of the most common UX fails we see here in
Europe: people travel to conferences or events and then want to spend their
Bitcoins whilst they're abroad, but they can't reasonably do so because
data roaming is so expensive.  By allowing the receiver i.e. merchant to
receive the tx via Bluetooth, this problem is avoided - often the receiver
is local and will be able to broadcast the transaction on your behalf.
Briefly, we use an unauthenticated RFCOMM socket with the adapter MAC
address in a new btcmac parameter in the bitcoin: URI qrcode. No pairing is
required. MITM attacks on the connection are possible, but all that's done
with it is writing raw tx bytes out over the connection so MITM is limited
to DoS.

@_date: 2013-09-17 12:03:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Simple contacts exchange (was: Social 
You can prove ownership of a private key by signing a challenger-generated
nonce with the public part and giving the signature back to the challenger
- same as with any asymmetric crypto system.
As I already noted, the payment protocol is designed to solve that problem.
You could design a BIP that extended the payment protocol to include
information about the person who generated it.

@_date: 2013-09-17 13:00:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Faster databases than LevelDB 
LevelDB is fast - very fast if you give it enough CPU time and disk seeks.
But it's not the last word in performance.
HyperLevelDB is a forked LevelDB with some changes, mostly, finer grained
locking and changes to how compaction works:
However, it comes with a caveat - one of the changes they made is to take
away write throttling if compaction falls behind, the app itself is
expected to do that.
Sophia is a competitor to LevelDB. The website claims that in benchmarks it
completely smokes LevelDB. I have not explored how it does this or tried to
replicate their benchmarks myself:
It's written in C and BSD licensed.
As an example of the kind of speedup they claim to be capable of, they say
LevelDB could do 167,476 random reads per second on their SSD based
machine. Sophia could do 438,084 reads/sec. Random reads are of course the
most interesting for us because that's what UTXO lookups involve.
They also compare against HyperLevelDB, where the differences are much less
pronounced and actually HyperLevelDB appears to be able to do random writes
faster than Sophia.

@_date: 2013-09-17 13:45:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Faster databases than LevelDB 
Nobody has written code to use a better format, migrate old wallets, etc.

@_date: 2013-09-17 14:36:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Simple contacts exchange (was: Social 
The payment protocol doesn't *require* signed certificates, it just gives
the option of using them.
However if you don't have some kind of cryptographic proof of identity,
what stops me putting your name and face into my payment requests and
claiming to be you?

@_date: 2013-09-24 15:52:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
BTW, on the "make qrcodes more scannable" front -- is it too late to change
BIP 72 so the new param is just "r" instead of "request"? Every byte helps
when it comes to qrcodes ...

@_date: 2013-09-25 11:27:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
We could also say that if protocol part ( is missing, it's implied
automatically. So just:
I think that's about as small as possible without re-using the pubkey as a
token in the url.

@_date: 2013-09-25 13:15:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
It won't fit. But I don't see the logic. A URI contains instructions for
making a payment. If that instruction is "pay to this address" or "download
this file and do what you find there", it's no different unless there's
potential for a MITM attack. If the request URL is HTTPS or a secured
Bluetooth connection then there's no such possibility.
On Wed, Sep 25, 2013 at 12:28 PM, Andreas Schildbach

@_date: 2013-09-25 13:45:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
OK, it might fit if you don't use any of the features the protocol provides
:) You can try it here:
certificate or a fingerprint to the QR code.
It's not "utterly broken", that's over-dramatic. It's just the best that
can be done with todays technology. I wrote about the SSL PKI and how it's
being upgraded here:
If you're thinking about governments and so on subverting CA's, then there
is a plan for handling that (outside the Bitcoin world) called certificate
transparency which is being implemented now.
Now when you are getting a QR code from the web, it's already being served
over HTTPS. So if you're up against an attacker who can break a CA in order
to steal your money, then you already lose, the QRcode itself as MITMd.
In the Bluetooth case we might have to keep the address around and use it
to do ECDHE or something like that. The current BT support doesn't need
that because it's just blasting out a tx, the entire protocol is write
only. Once it's reading data as well then it'll need a custom security

@_date: 2013-09-25 16:38:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
Low light shouldn't be an issue for QRcodes generated by phones. They have
backlit screens that should always be bright enough. I can see how it might
be an issue for printed codes.
If your phone has no Bitcoin app installed then being redirected to an
invoice page is pretty useless, you still won't be able to pay the bill no
matter what (where do you get the money from?). If they are just raw HTTP
URLs then it means the effect of scanning a QRcode with a standalone
scanner app is different to scanning it inside the wallet, which is unlike
all other uses of QRcodes I know of. So I'm not really convinced by that UX
yet. Perhaps we can thrash it out in Amsterdam. Right now I'm thinking
QRcodes should always contain bitcoin URIs.

@_date: 2013-09-29 13:33:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] smart contracts -- possible use case? yes 
This kind of thing is better discussed in the dev forum of bitcointalk.org
On Sun, Sep 29, 2013 at 11:46 AM, Melvin Carvalho

@_date: 2014-04-01 21:09:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Finite monetary supply for Bitcoin 
This proposal will destroy Bitcoin. I would expect nothing less coming from
a Google employee.

@_date: 2014-04-02 14:01:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] secure assigned bitcoin address directory 
Hi Daryl,
I think the reason nobody has done that is that BIP70 isn't really that
much work. It's basically just certs inside a protobuf, with a bit of extra
data. I'm not sure yet another way to do the same thing is worth much.

@_date: 2014-04-04 15:08:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for seamless website 
This comes up every few months. I think the problem you are trying to solve
is already solved by SSL client certificates, and if you want to help make
them more widespread the programs you need to upgrade are web browsers and
not Bitcoin wallets. There are certainly bits of infrastructure you could
reuse here and there, like perhaps a TREZOR with a custom firmware
extension for really advanced/keen users, but overall Bitcoin and website
authentication are unrelated problems.

@_date: 2014-04-04 15:43:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for seamless website 
Why do you need it? Because you don't want to implement a login system?
Very, very few websites are the sort of place where they'd want to
authenticate with only a Bitcoin address. If for no other reason than
they'd have no way to email you, and if you lost your wallet, you'd lose
all your associated data.
In future there often won't be a simple paying address. For instance, if my
coins are in a multi-sig relationship with a risk analysis service, there
will be two keys for each input and an arbitrary number of inputs. So does
that mean the risk analysis service gets to open my locker? Why?
What if I do a shared spend/CoinJoin type tx? Now anyone who took part in
the shared tx with me can get into my hotel room too?
These are the kinds of problems that crop up when you mix together two
different things: the act of paying, and the act of identifying yourself.
You're assuming that replacing a password people can remember with a
physical token (their phone) which can be stolen or lost, would be seen as
an upgrade. Given a choice between two physical lockers, one of which lets
me open it with a password and one of which insists on a cryptographic
token, I'm going to go for the former because the chances of me losing my
phone is much higher than me forgetting my password.
All the tools you need already exist in the form of client certificates,
with the advantage that web servers and web browsers already support them.
The biggest pain point with them is backup and cross-device sync, which of
course wallets suffer from too!

@_date: 2014-04-04 15:54:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for seamless website 
Oh, if these seem too abstract, also consider bitbanks. In an ideal world
nobody would outsource running of their Bitcoin wallet, but sadly people
do, so then they don't control the private keys at all.
The goal of writing a BIP seems to be to get lots of different wallet
authors to write lots of code for you - but I *am* a wallet author, and I
don't think that's the right way to get traction with a new scheme. For
instance the TREZOR guys would have to support your new protocol otherwise
if I paid my hotel bill with my TREZOR I couldn't open the door when I got
there! But they probably have better things to be doing right now.
The key difference between just generating a client certificate and using a
Bitcoin address is that the client certificate is something that is used
*specifically* for identification. It leaves no trace in the block chain,
so no weird privacy issues, it doesn't matter how you manage your wallet,
and you don't have to persuade lots of people to support your idea because
it was already done >10 years ago and basically every browser/web server
supports it.
Some reasons client certs aren't more widely used boil down to:
   1. People like passwords. In particular they like forgetting them and
   then having friendly people assist them to get it back. Client certs can
   support this use case, but only if apps are checking the identity in them
   and not the key.
   2. The UI for managing client certs in browsers is pretty horrible.
   There's little incentive to improve it because of (1).
   3. Cross-device sync doesn't work very well. Apple are starting to
   tackle this with their iCloud Keychain Sync service but then of course,
   Apple has all your keys and you may well just sign in to things with your
   Apple account (if it were to be supported). Cross-device sync where the
   server *doesn't* get your keys is supported by Chrome for passwords, but
   not client certs, because (1)
None of the above issues have any obvious fix lurking within Bitcoin.

@_date: 2014-04-04 16:51:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for seamless website 
Well, yes, but we also have browsers too :)
I don't want to suggest the problem is unimportant - I'd love it if the
world could move beyond passwords. But I have many scars from my time in
the Google account swamps. We had a big team, lots of resources and even
just getting people to use their phone as a second factor - *the simplest
second factor possible* - was a huge uphill battle that most users just
didn't care about. People like passwords. If you can find a way to make
something that's better than a password but just as convenient, fantastic!
But I don't think Bitcoin addresses are such a thing.

@_date: 2014-04-04 17:37:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for seamless website 
Hmmm, well TREZOR requires a web plugin. So if nobody installs plugins then
we have a problem :) But regardless, actually like I said, you don't need a
plugin. Browsers do it all already. With the  tag they even create
a private key and upload the public part to be signed for you, it's
seamless for the user. I wanted to give you a link to a demo site, but I
can't find it anymore :(
So there's not even a need for people to upgrade anything! It's all there,
already, for everyone.
If you were to make some upgrades, then you'd want to focus on key
management, which indeed is something the Bitcoin world is trying hard to
solve.  But that's a small subcomponent.  Making a modified version of
Chrome or Firefox that can take their key from a BIP32 hierarchy or
12-words scheme is certainly possible, but then you could still reuse all
the rest of it.
Something I'd really like to see is TREZOR supporting a simple
request/response protocol that a server can trigger, via the USB plugin,
that would allow a server to display some arbitrary text and get a
confirmation. Slush and I talked about it before. There are a LOT of places
that don't care about Bitcoin but do need some kind of safe second factor
auth where users know what they are confirming (e.g. at Google!). If TREZOR
could be used for these things too, that'd increase demand and help push
down prices for Bitcoin users.

@_date: 2014-04-07 13:34:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
At the start of February we had 10,000 bitcoin nodes. Now we have 8,500 and
still falling:
   I know all the reasons why people *might* stop running a node (uses too
much disk space, bandwidth, lost interest etc). But does anyone have any
idea how we might get more insight into what's really going on? It'd be
convenient if the subVer contained the operating system, as then we could
tell if the bleed was mostly from desktops/laptops (Windows/Mac), which
would be expected, or from virtual servers (Linux), which would be more
When you set up a Tor node, you can add your email address to the config
file and the Tor project sends you emails from time to time about things
you should know about. If we did the same, we could have a little exit
survey: if your node disappears for long enough, we could email the
operator and ask why they stopped.

@_date: 2014-04-07 14:34:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
Correct. Still, a high number of nodes has a few other benefits:
1) The more nodes there are, the cheaper it should be to run each one,
given that the bandwidth and CPU for serving the chain will be spread over
more people.
2) It makes Bitcoin *seem* bigger, more robust and more decentralised,
because there are more people uniting to run it. So there's a psychological
Also, we don't have a good way to measure capacity vs demand at the moment.
Whether we have enough capacity is rather a shot in the dark right now.
Which is why I'm interested to learn the reason behind the drop. Is it
insufficient interest, or is running a node too painful?
For this purpose I'd like to exclude people running Bitcoin Core on laptops
or non-dedicated desktops. I don't think full nodes will ever make sense
for consumer wallets again, and I see the bleeding off of those people as
natural and expected (as Satoshi did). But if someone feels it's too hard
to run on a cheap server then that'd concern me.
It would be good to explain the difference, but I suspect your definition
of "well reachable" excludes people running Core at home. From the diurnal
cycle we see in Addy's graphs it's clear some nodes are being shut down
when people go to bed. So if we have 6000 nodes on servers and 2000 at
home, then I'd expect Addy's graphs and yours to slowly come into alignment
as people give up using Core as a consumer wallet.

@_date: 2014-04-07 16:05:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
Sigh. It would not be surprising if MtGox has indeed dealt the community a
critical blow in this regard. TX traffic is down since then too:
Judging from comments and the leaked user db, it seems a lot of well known
people lost money there   (not me fortunately). I wish I could say people
have learned but from the size of the deposit base at Bitstamp they clearly
have not. A lot of Bitcoin users don't seem to be ready to be their own
bank, yet still want to own some on the assumption everyone else either is
or soon will be. So it's really only a matter of time until something goes
wrong with some large bitbank again, either Bitstamp or Coinbase.
Some days I wonder if Bitcoin will be killed off by people who just refuse
to use it properly before it ever gets a chance to shine. The general
public doesn't distinguish between "Bitcoin users" who deposit with a third
party and the real Bitcoin users who don't.

@_date: 2014-04-07 16:23:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
Indeed, fully agreed. The only way to really make progress here is to make
the UX of being your own bank not only as good as trusting a third party,
but better.
I've been encouraged by the rise of risk analysis services, but we need to
integrate them into wallets more widely for them to have much impact.
Otherwise people get to pick between a variety of wallets, none of which
have *all* the features they want. And TREZOR is cool, albeit, something
that's going to be for committed users only.

@_date: 2014-04-07 19:40:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
It uses ~no electricity, it's not like mining.
The primary resources it needs are disk space and bandwidth, after an
intensive initial day or two of building the database.
Actually, I wonder if we should start shipping (auditable) pre-baked
databases calculated up to the last checkpoint so people can download them
and boot up their node right away. Recalculating the entire thing from
scratch every time isn't sustainable in the long run anyway.
On Mon, Apr 7, 2014 at 7:35 PM, Brent Shambaugh

@_date: 2014-04-07 20:23:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
One of the reasons I initiated the (now stalled) PayFile project was in
anticipation of this problem:
At some point if you want to actually download and validate the full block
chain from scratch, you will have to start paying for it I'm sure.
In the meantime:
   1. Getting headers-first implemented and rolled out everywhere would
   reduce the amount of redundant downloading and hopefully reduce transmit
   traffic network-wide.
   2. Implementing chain pruning would allow people to control upload
   bandwidth consumption by reducing the amount of disk storage they allow.

@_date: 2014-04-08 09:50:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
It is starting to happen. If you're OK with using a specific web wallet
there's BitGo and greenaddress.it already, though I think their risk
analysis is just sending you an SMS code. I wrote up an integration plan
for bitcoinj a few days ago:
 but guess what? It's quite complicated. As with all these features.

@_date: 2014-04-08 10:13:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for seamless website 
I'd be careful with swift generalisations. It depends a lot on the value of
your product. I didn't have any hangups about installing a plugin to use my
TREZOR:  compared to the cost and effort involved with the rest of it,
installing a plugin was by far the easiest part.
Another example. Back in 2005 people also used to say that nobody wanted to
download apps anymore. Then I started working on Google Earth, which got
~400 million installs. Obviously, that was cool enough that people were
willing to download and install a giant hulking ugly Qt app :)

@_date: 2014-04-09 20:00:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoind-in-background mode for SPV 
The right way to start with this, if anyone cares, is to add
instrumentation to existing SPV wallet apps to report back to home base how
long they are running for, how much disk space / RAM they have, and
possibly what kind of hardware.
I *strongly* suspect that the vast majority of SPV wallets are not left
running permanently, and run on laptops where battery life is at a premium.
These people will never want to run full nodes.
Sorry. I don't think it will ever make sense to run full nodes on consumer
hardware again. Our time is much better spent on optimising so it's cheaper
for full node operators to run them on cheap virtualised servers.

@_date: 2014-04-10 08:38:49
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoind-in-background mode for SPV 
I tend to agree with slush here - counting the IPs in addr broadcasts often
gives a number like 100,000 vs just 10,000 for actually reachable nodes (or
less). It seems like optimising the NAT tunneling code would help. Starting
by adding more diagnostic stuff to the GUI. STUN support may also help.
The main constraint with home devices is not IMHO their actual power but
rather that a lot of people no longer keep computers switched on all the
time. If you don't do that then spv with bundled Core can't help your
security because the spv wallet would always be syncing from the p2p
network for performance reasons.

@_date: 2014-04-10 09:09:25
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoind-in-background mode for SPV 
It's an optimisation problem. Home environments are much more hostile than
servers are due to things like virus scanners, wildly varying memory
pressure as apps are started and shut down, highly asymmetrical upstream
versus downstream bandwidth,  complicated nat setups, people who only use
laptops (which I think is most people these days) and so on.
So I think the right way to go is to optimise the things that hurt server
node operators like large memory and disk  usage, and this will
automatically make it more pleasant to run on the desktop as well. If at
some point all the low hanging fruit for the server side is gone then
improving things on the desktop would be the next place to go. But we have
to be realistic. Desktop tower machines that are always on are dying and
will not be coming back. Not a single person I know uses them anymore, they
have been wiped out in favour of laptops. This is why, given the tiny size
of the bitcoin core development team, I do not think it makes sense to
spend precious coding hours chasing this goal.

@_date: 2014-04-10 11:17:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoind-in-background mode for SPV 
It's not a new idea, obviously, but there are some practical consequences:
1) To pay a node for serving, you have to have bitcoins. To get bitcoins,
you need to sync with the network via a node. Catch 22.
2) If some nodes choose to charge and others choose to not charge, a smart
wallet will always use the free nodes. In the absence of any global load
balancing algorithms, this would lead to the free nodes getting overloaded
and collapsing whilst the for-pay nodes remain silent.
3) The only payment channel implementations today are bitcoinj's (Java) and
one written by Jeff in Javascript. There are no C++ implementations. And as
Matt and I can attest to, doing a real, solid, fully debugged
implementation that's integrated into a real app is .... a lot of work.
I still think the lowest hanging fruit is basic, boring optimisations
rather than architectural rethinks.

@_date: 2014-04-10 12:40:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoind-in-background mode for SPV 
I think I maybe wasn't clear. To spend coins you need transaction data.
Today, the dominant model is that people get that data by scanning the
block chain. If you can obtain the transaction data without doing that
then, either:
1) Someone is doing chain scanning for free. See my point about "why pay if
you can get it for free".
2) You got your tx data direct from the person you who sent you the funds,
perhaps via the payment protocol. This would resolve the catch 22 by
allowing you to spend bitcoins without actually having talked to the P2P
network first, but we're a loooooong way from this world.
And that's it. I don't think there are any other ways to get the tx data
you need. Either someone gives it to you in the act of spending, or someone
else gives it away for free, undermining the charge-for-the-p2p-network

@_date: 2014-04-10 13:29:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoind-in-background mode for SPV 
Chain pruning is a fairly complicated project, partly because it spans
codebases. For instance if you try and implement it *just* by changing
Bitcoin Core, you will break all the SPV clients based on bitcoinj (i.e.
all of them). Big changes to the P2P network like this require upgrading
both codebases simultaneously.
I think things like this may be why Gavin is now just "chief scientist"
instead of Core maintainer - in future, the changes people need will span
projects and require fairly significant planning.
broadcast how much of the chain they have, and teaching both Core and
bitcoinj how to search for nodes that have enough of the chain for them to
use. Currently bitcoinj still doesn't use addr broadcasts at all, there's
an incomplete patch available but it was never finished or merged. So that
has to be fixed first. And that probably implies improving Bitcoin Core so
the results of getaddr are more usable, ideally as high quality as what the
DNS seeds provide, because if lots of bad addresses are returned this will
slow down initial connect time, which is an important performance metric.

@_date: 2014-04-10 13:37:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Chain pruning 
Chain pruning is probably a separate thread, changing subject.
I doubt anyone would specify blocks to keep in terms of time. More likely
it'd be in terms of megabytes, as that's the actual resource constraint on
nodes. Given a block size average it's easy to go from megabytes to
num_blocks, so I had imagined it'd be a new addr field that specifies how
many blocks from the chain head are stored. Then you'd connect to some
nodes and if they indicate their chain head - num_blocks_stored is higher
than your current chain height, you'd do a getaddr and go looking for nodes
that are storing far enough back.

@_date: 2014-04-10 13:45:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoind-in-background mode for SPV 
Actually, the design is from Satoshi and Matt did most of the
implementation work last year during a Google internship. Though I ended up
doing a lot of work on it too. We actually got pretty far: there was
Android UI for it and a couple of apps we coded up. I wish we could have
pushed it over the finishing line and got real world usage. Hopefully we
can return to it someday soon.
I think the hub/spoke concept was invented by goldsmiths in 16th century
Italy, as they started handing pieces of paper across their benches, or
*bancos* in Italian   :-)

@_date: 2014-04-10 18:28:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Chain pruning 
Suggestions always welcome!
The main problem with this is that the block chain is mostly random bytes
(hashes, keys) so it doesn't compress that well. It compresses a bit, but
not enough to change the fundamental physics.
However, that does not mean the entire chain has to be stored on expensive
rotating platters. I've suggested that in some star trek future where the
chain really is gigantic, it could be stored on tape and spooled off at
high speed. Literally a direct DMA from tape drive to NIC. But we're not
there yet :)

@_date: 2014-04-15 17:05:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bug in 2-of-3 transaction signing in 
Check debug.log to find out the reason it was rejected.

@_date: 2014-04-15 17:30:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bug in 2-of-3 transaction signing in 
If the tx is already in the block chain then it won't be accepted again,
because it would be double spending itself!

@_date: 2014-04-17 17:49:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Timed testing 
You can just reindex/replay the chain. It's been done many times.

@_date: 2014-04-21 18:39:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Economics of information propagation 
Pieter tried it already. If the two nodes views of each others mempools are
not exactly in alignment it ends up being slower than just sending the data
immediately and redundantly.

@_date: 2014-04-23 09:55:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage Finney 
Lately someone launched Finney attacks as a service (BitUndo). As a
reminder for newcomers, Finney attacks are where a miner secretly works on
a block containing a double spend. When they eventually find a block, they
run to the merchant and pay, then broadcast the block. In a simpler variant
of this attack you make purchases as normal with a modified wallet that
always submits a double spend to the service, and then N% of the time where
N is the percentage of overall hash power the dishonest miners have, you
get your money back minus their fee.
N does not need to be very high to render Bitcoin much less useful. Real
time transactions are very important. Although I never expected it when I
first started using Bitcoin, nowadays most of my purchases with it are for
food and drink. If Bitcoin could not support such purchases, I would use it
much less.
Even with their woeful security many merchants see <1-2% credit card
chargeback rates, and chargebacks can be disputed. In fact merchants win
about 40% of chargeback disputes. So if N was only, say, 5%, and there was
a large enough population of users who were systematically trying to
defraud merchants, we'd already be having worse security than magstripe
credit cards. EMV transactions have loss rates in the noise, so for
merchants who take those Bitcoin would be dramatically less secure.
The idea of discouraging blocks that perform Finney attacks by having
honest miners refuse to build on them has been proposed. But it has a
couple of problems:
   1. It's hard to automatically detect Finney attacks. Looking for blocks
   that contain unseen transactions that override the mempool doesn't work -
   the dishonest users could broadcast all their double spends once a Finney
   block was found and then broadcast the block immediately afterwards, thus
   making the block look like any other would in the presence of double spends.
   2. If they could be automatically identified, it possibly could be
   converted into a DoS on the network by broadcasting double spends in such a
   way that the system races, and every miner produces a block that looks like
   a Finney attack to some of the others. The chain would stop advancing.
   3. Miners who want to vote "no" on a block take a big risk, they could
   be on the losing side of the fork and end up wasting their work.
We can resolve these problems with a couple of tweaks:
   1. Dishonest blocks can be identified out of band, by having honest
   miners submit double spends against themselves to the service anonymously
   using a separate tool. When their own double spend appears they know the
   block is bad.
   2. Miners can vote to reallocate the coinbase value of bad blocks before
   they mature. If a majority of blocks leading up to maturity vote for
   reallocation, the value goes into a pot that subsequent blocks are allowed
   to claim for themselves. Thus there is no risk to voting "no" on a block,
   the work done by the Finney attacker is not wasted, and users do not have
   to suffer through huge reorgs.
This may seem a radical suggestion, but I think it's much less radical than
some of the others being thrown around.
The above approach works as long as the majority of hashpower is honest,
defined to mean, working to stop double spending. This is the same security
property as described in the white paper, thus this introduces no new
security assumptions. Note that assuming *all* miners are dishonest and are
willing to double spend automatically resolves the Bitcoin experiment as a
failure, because that would invalidate the entire theory upon which the
system is built. That doesn't mean the assumption is wrong! It may be that
an entirely unregulated market for double spending prevention cannot work
and the participants eventually all end up trashing the commons - but the
hope is that smart incentives can replace the traditional reliance on law
and regulation to avoid this.
The voting mechanism would only apply to coinbases, not arbitrary
transactions, thus it cannot be used to steal arbitrary users bitcoins. A
majority of miners can already reallocate coinbases by forking them out,
but this wastes energy and work presenting a significant discouragement to
vote unless you already know via some out of band mechanism that you have a
solid majority. Placing votes into the coinbase scriptSig as is done with
other things avoids that problem.
The identification of Finney blocks relies on miners to take explicit
action, like downloading and running a tool that submits votes via RPC. It
can be expected that double spending services would try to identify and
block the sentinel transactions, which is why it's better to have the code
that fights this arms race be out of process and developed externally to
Bitcoin Core itself, which should ultimately just enforce the new (forking)
rule change.

@_date: 2014-04-23 13:07:25
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
If you do a chargeback the bank double checks this, investigates it and
people who repeatedly try and do fraudulent chargebacks get their accounts
terminated. It's not like your bank offers you a "reverse this payment"
button in the UI that always works, right?
If you attempt fraud against a bank, they know who you are and will come
after you in one way or another. But it's safe to assume that users of a
double spend service would be anonymous and the kind of merchants they go
after are not hassling their customers with strong ID checks, so there
would be no consequences for them. It's a game they can only win.

@_date: 2014-04-23 13:45:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
OK, sure, let's say most Bitcoin users will be honest (we hope). But
unfortunately in a situation where fraud is possible users wouldn't
necessarily distribute evenly over transactions.
Back when I worked on Gmail, we did a little study where we selected a
random subset of email accounts from Nigeria and waited to see if they
received abuse reports, showed up on dating site blacklists etc. It turned
out about 2/3rds of them did. This obviously doesn't imply that 2/3rds of
all Nigerians are scammers, but unfortunately the few that are are
responsible for a disproportionate number of account creations.
If a merchant is selling something of value repeatedly, then a small number
of scammers can go back and try their luck over and over. I'm not sure how
many trades fall into such an exploitable category, though.
Also, there's the philosophical question of how honest people really are
when there's no consequences to their actions. For instance, if most people
were honest, then piracy would be not a big problem. But game studios that
have cracked DRM quite often report piracy rates of 95%, i.e. for every 5
sales they make, they get 100 people playing on their servers - the vast
majority of their users are not honest.

@_date: 2014-04-23 14:51:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
If everyone votes to reallocate everyone elses blocks all the time, then
you'd end up losing your own coins too, so this doesn't seem like a
workable strategy.
I'm OK with burning actually. The total amount of coins in the system
essentially defines its maximum price resolution. Ideally we'd not lose
resolution, but it's less important than having a system that does actually
work. Moreover, this sort of system is like double spending defence itself
- if it does work, it doesn't need to actually be done very frequently
because people know the safeguards work and don't try. So in practice total
loss of resolution should be limited.
Right. It's indeed an assumption that block rewards matter to miners, even
the ones that have double spend revenues.

@_date: 2014-04-23 15:31:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
Yeah, I was imagining a situation in which people who use Bitcoin regularly
do buy things they actually want, but wouldn't say no to occasionally
getting them for free (think coffees at starbucks etc). So if their double
spend fails, no big deal, they're no worse off than if they didn't try.

@_date: 2014-04-23 17:07:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
As was already pointed out, yes. However this requires them to immediate
establish a majority consensus and be absolutely sure it really is the
majority. You suggest an out of band mechanism for that, but why is this
better than using the actual consensus mechanism you're trying to measure?
Bitcoin imposes far more rules than just execution of the scripting
language, many of which are entirely arbitrary and the result of
(controversial) human judgement, like the inflation schedule. You can't
claim Bitcoin implements only some kind of natural law.

@_date: 2014-04-23 17:09:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
And it still would. Non-collusive miners cast votes based on the outcome of
their own attempts to double spend. If enough agree then they all agree
that the vote is binding.
I'm using it in the same sense Satoshi used it. Honest miners work to
prevent double spends. That's the entire justification for their existence.
Miners that are deliberately trying to double spend are worse than useless.

@_date: 2014-04-23 18:21:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
I think the cost to mines is the same as what's possible today, actually.
Consider a group of miners who wish to do this with no changes to the rule
set. They can coordinate out of band and figure out if they have a majority
of hashpower behind the decision to orphan a block, e.g. by signing a nonce
with their coinbase keys. If they reach quorum, then they begin work on a
parallel chain. Because they have majority they are guaranteed to
eventually win, though depending on luck it may take a while. Because of
this, assuming the external quorum system is public, the moment consensus
is reached the other miners should all abandon the existing branch and
start work on the parallel chain too, lest they waste work mining on a
branch that is surely doomed.
The end result would be that the chain stops making progress, disrupting
end users and generally creating uncertainty as the new chain is forged.
Also, miners who built on top of the orphaned block end up being punished
even if they did nothing wrong. Both these side effects are undesirable and
So the more I think about this scheme, the more it seems like a simple
improvement on the current status quo. Miners can do what they could
already do, but with a more reliable in-band signalling mechanism that
doesn't require things like coinbase keys to be online, and them doing so
does not disrupt existing users or waste energy.

@_date: 2014-04-23 19:57:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
I don't think Twitter is an appropriate medium for discussing the details
of byzantine consensus algorithms.
I'm not going to bother arguing in replies to a blog post. Suffice it to
say, miners are already handsomely compensated via both inflation and fees
for doing their job of preventing double spends. Your suggestion is people
should pay them EVEN MORE for simply not being corrupt. My proposal is
simpler - how about we find the ones that are claiming people's money via
coinbases yet not doing their jobs correctly, and take the money back (or
destroy it). I think I prefer that one. Miners that are maliciously double
spending cannot justify their existence, they offer no useful service and
do not deserve compensation as a result.

@_date: 2014-04-23 20:37:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
If you want to try and argue that the development list is the wrong place
to discuss development, please do so on another thread (or your blog).
Let's keep this thread for discussion of the original proposal - ideally,
discussed with the dryness that a topic as nerdy as distributed consensus
algorithms deserves ;)

@_date: 2014-04-23 21:19:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
That's the definition of a Finney attack, right? A tx is broadcast and
nodes normally take the first one they saw, allowing you to measure
propagation and use double spend alerts to get pretty good confidence,
pretty quick. A Finney attacker doesn't do that and includes a double
spend, so the one in the mempool gets overridden.
I mean, I hope that's the definition of a Finney attack, given that I
coined the term :)
Yes, very disappointing. Though I'd hope that if this sort of thing was
sustained over months and merchants started dropping Bitcoin as a result,
miners would pay more attention.
Right now I suspect miners don't pay attention to anything other than
hardware builds though.
Yes, Bitcoin is imperfect at stopping double spends today. It can certainly
be improved! There are plenty of oft-discussed measures like double spend
alerts and discouraging Finney-attack blocks as was debated extensively in
2011. This thread is just a third such proposal.
More importantly, it's possible to deploy technological approaches to
These sorts of proposals are all just ways of saying block chains kind of
suck and we should go back to using trusted third parties.
That may well be how the Bitcoin experiment ends, but I think we all agree
here that block chains and decentralised consensus are quite spiffy and we
should try hard to make them work as well as possible before just shrugging
and say "find a trusted third party". Otherwise why not just go back to
using MasterCard? Any TTP that enforces anti double spending rules will be
a lot more centralised than miners, given the difficulty of finding them,
their need for a strong brand/reputation, and the difficulty of getting
everyone to agree on them.
Not to mention that this solution makes Bitcoin sound like a joke currency.
It's a super duper low fee totally decentralised financial system .....
unless you want to buy something in, you know, a shop. And walk out. Then
you need to sign up with this company that looks suspiciously like a bank,
and pay their fees, and yeah there's like 3 to pick from. Totally
If a miner is vertically integrated and defrauding merchants themselves,
with no service component, pretty quickly people would talk to each other,
notice this pattern and stop trading with them, making their coins rather
useless. Also if their real identity is ever revealed they could be liable
and there'd be a lot of people wanting to sue them.
So I think the ability to resell double spending to lots of different
people around the world seems important to practicality.

@_date: 2014-04-23 21:59:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
That's the same thing. Whilst you're mining your double spend tx, it's in
your mempool but you don't broadcast it as per normal. Then when you find
the block you broadcast it to override everyone elses mempool. So yours and
theirs were inconsistent.
The only slight way BitUndo differs is, they provide it as a service, and I
don't know if they inform you when they found a block (probably not), so
you have to do the purchase and then hope BitUndo finds the next block.
Otherwise the purchase clears. But they could certainly add a
pre-notification before they broadcast to get back to the exact scheme
originally described, they have everything else in place.
This just brings us back to square one. Who are these parties and what if I
pay them to be corrupt? What if they offer to be corrupt as a service?
Let's say I succeed in finding some parties who are incorruptible no matter
how large of a percentage I offer them. At this point, why bother with
miners at all? Why pay for double spend protection twice, once to a group
of Oscar's who are trustworthy and once to a group of miners who are not?
The point of the broadcast network and mining is so there can be lots of
Oscar's and I don't have to know who they are or sign up with them or put
any effort into evaluating their reputation.
But as you point out, cheating my GHash.io did not result in any obvious
negative consequence to them, despite that preventing double spending is
their sole task. Why would Oscar be different to GHash.io?
Trying to solve the problem of dishonest miners is effectively trying to
solve the "automatically find trusted third parties" problem at scale.

@_date: 2014-04-23 22:37:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
Yes, but that can be fixed with double spend alerts.
No? It's not just your decision that matters, the receiver also has to
trust them. They're like a dispute mediator in this regard. You can pick
whoever you want, but that doesn't matter if the receiver doesn't recognise
them or trust them. You have to find an overlap to make an instant trade.
In practice if people have to think about this, evaluate brands etc then
you'd get a very small number of parties because the value of global
agreement is so high. Then it becomes hard to remove ones that have a lot
of momentum.
The censorship resistance of the block chain doesn't matter if your double
spending partners refuse to help you spend your money (because they're
being coerced). The censorship can just happen at a different place.
..... or, have a majority decide to zero out their coinbase rewards for
blocks that double spent against dice sites. That wouldn't undo the double
spend, but you can't do that with the multisig scheme either. All you can
do is punish the corrupted party post-hoc, either by not using them again,
or by "unpaying" them for the service they did not provide.

@_date: 2014-04-23 22:51:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
The 10 minute average comes from a desire to balance wasted work due to
natural chain splits with latency. With a very fast block interval you end
up with lots of forks and things take longer to converge, also, it can make
attacks easier because an attacker is building on his own blocks so he
doesn't suffer propagation delays and the attendant splits.
It's not clear you can just make a faster block chain. 10 minutes is
somewhat arbitrary, it could be 5 minutes and the system would still work,
but it probably can't be 5 seconds.
Unfortunately for best physical-world usability you really need very fast
payments. A few seconds is competitive with modern credit cards. The new
contactless cards seem to be able to reliably manage <1 sec which is
impressive. Waiting for blocks in a block chain can't really work. Waiting
for propagation can work and has been working so far. Hence, the question
of how that mechanism can be kept working in the face of malicious miners,
before you end up having to fall back to trusted third parties and

@_date: 2014-04-24 09:58:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
Sure, they have different tradeoffs. My assertion is this:  the costs and
disadvantages that come with building what is in effect an entirely
parallel and separate system for stopping double spends, are much much
worse than making simple tweaks to strengthen the mechanism we already have.
Put another way, the cost/benefit ratio of this proposal seems much better
to me than the alternatives.
You also get the costs of both approaches, which are extremely significant.
 Censorship-resistance is irrelevant when one buys a cup of coffee with his
That's like saying banks can't censor you because you can always withdraw
all your money in cash. But in practice:
   1. That's a huge pain in the ass so nobody does it
   2. Many merchants will refuse non-trivial payments in cash and demand
   bank money because it's simpler for them
Analogously, having to wait some large expiry period to extract your money
from the "double spending prevention service" (a.k.a. bitbank) is a pain in
the ass, and many merchants would refuse to take your newly double
spendable money even if theoretically they could, because it keeps their
operations much simpler if they can just assume a sale is final and can't
be reversed.
So I think such a scheme would rapidly return to the a world that looks
much like the one we have now.
The complexity overhead is trivial - we already used coinbase scriptSigs
for voting on P2SH, I'm sure it'll be used for voting on other things in
future too. So that's already in place. Counting up votes and editing the
UTXO set is the sort of patch one guy can create, it's not very big. And
it's conceptually just the same as what miners can do today by re-orging
out blocks, but with much less impact on end users and less implementation
complexity (no giant reorgs that might themselves have to split recursively
whilst they're being built).
On the other hand, building an entirely separate system, with separate
trusted companies that have trusted brand names, adding support to all the
wallets, getting all sellers on board, making everything use an extended
BIP 70 (as that's the only real way to implement it), trying to explain to
users why they're now expected to pay extra fees when they previously
didn't and then discovering that you got a choice of only a handful of
double-spend-preventers everyone could agree on with little potential for
more .... that's hugely complex and messy.
Why? Remember deleting coinbases with nothing more than a simple majority
is already possible in the existing protocol and always has been.

@_date: 2014-04-24 10:09:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure 
Right. So part of this is my fault, I'm afraid, because I do not intend to
implement any kind of subwallet/account support in bitcoinj. My reasons are:
   1. The bitcoinj API already lets you create and use multiple wallets.
   What's more, because of the desire to do key rotation (think rotating a
   previously unencrypted wallet to an encrypted one that is stored on SSD's
   that cannot reliably erase data), a bitcoinj wallet can actually contain
   multiple BIP32 seeds and hierarchies at once, although only the last one
   will be used for vending addresses. So adding subwallet support onto this
   makes it even more complicated.
   2. If there was a much better user experience to be enabled by this, it
   may be worth it, but I believe many people will find subwallets rather
   confusing. They don't match the analogy of bank accounts in several ways.
   For instance, transferring money across them leaks private data and costs
   miners fees, neither of which are true with banks.
   Also it differs in a more important way. People have different bank
   accounts because those accounts implement different policies. Current
   accounts may pay a lower interest rate than savings accounts, but have
   different features, and accounts can be used as security boundaries i.e. no
   card withdrawals from savings. But "subwallets" are not like this. The only
   justification for their existence is to avoid outputs being merged together
   to make payments - a subtle technical detail of the protocol that users are
   ill equipped to understand. If someone asked me "why should I create a
   second account" I would be unable to give them a satisfying answer without
   first teaching them about how the Bitcoin protocol works and the privacy
   implications of that, which is practically a lecture sized topic.
   3. MultiBit did support multiple wallets for a long time (just by
   creating multiple wallet files and using the support in bitcoinj for
   running them in parallel), but they decided to remove this feature in
   MultiBit HD because it caused support headaches. People would stash money
   in one wallet or the other, close the wallet and then forget and think they
   had lost it, etc. It may be that TREZOR type subwallets don't suffer this
   confusion because they can't be moved around or "closed" in the same way a
   file can be, but still, this is a data point against multiple simultaneous
   wallets. At least for products targeting entry level consumers.
Whilst I can well believe there are TREZOR users who are asking for this
feature today, currently the costs feel a bit higher than the benefits.
It would be rather nice to be able to type in a mnemonic code that myTREZOR
was initialised with and duplicate that wallet into a bitcoinj based wallet
app. But if I have to implement subwallets and expose this in the API, and
if all wallet authors that want to be able to share a wallet with myTREZOR
have to expose subwallets in their GUIs too, even though the concept may
prove confusing and hard to explain, then it might be more tempting to just
tell users that want to switch wallet apps to send the money via the block
chain instead.

@_date: 2014-04-24 10:39:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
It absolutely is! It was widely discussed as such at the time, here is a
thread where people ask how to vote and the operator of Eclipse said he was
removing his vote for P2SH:
You might not feel it's a particularly fair or representative vote, but
it's still miners saying "I support enforcement of this new rule" or "I do
not support this" where the majority of cast votes wins. Some miners have
more votes than others, but it's still a vote.
Miners *are* trusted parties, they are just not all trusted simultaneously.
Bitcoin can tolerate a small number of dishonest miners whilst producing a
degraded service. It cannot work if all miners are dishonest or decide to
deviate from their intended operation, like if they all produce empty
blocks. The white paper made this clear from the start, and it's also
common sense.
Allowing the majority of honest miners to keep the dishonest ones in check
is what Bitcoin is all about. I don't understand this view that a very
small change to the existing protocol is somehow terrible or impossible,
but expecting everyone to simply build an entirely new system from scratch
is easy and inevitable. I'd much prefer to just keep the existing system
working as well as it has so far, and I think that is true of most users
No, coinbases are deletable. If some miners fork the chain and build a
longer one, the others will all switch to it and the coinbases blocks they
previously mined will never become spendable (effectively they were
"deleted" before maturity). Only if the other miners also blacklist the
majorities fork and never join it, then the majority for some reason gives
up and rejoins the minority, is what you described correct. But why would
they do that? If they're the majority then all the other nodes will follow
them. They have no incentive to throw away their fork and rejoin the
minority chain ever again.
I think the root of this disagreement is whether the block chain algorithm
left by Satoshi is somehow immutable and itself the end, or whether it's
(as I see it) just a means to an end and therefore an algorithm that can be
tweaked and improved, to get us closer to the goal.
If the end is a useful payments system, as decentralised as possible, that
prevents double spending, then this proposal is a simple enhancement of the
current system that ensures corrupt miners don't get paid by honest users
for services they didn't provide, thus discouraging a particular kind of

@_date: 2014-04-24 11:56:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
understood that you were _not_ proposing that quite specifically. But
Well, my original thought was just to delete the coinbases. But then some
people don't like the idea of destroying money (equivalently, reducing the
system's resolution) so I proposed reallocating it instead. I'm not sure
which is better though. Deletion is closer to what the existing system
allows, for sure.
Would you feel differently if the consequence was UTXO deletion rather than
reallocation? I think the difference makes no impact to the goal of
discouraging double spending.
I think this would not be doable in practice, unless there was a way to
identify that a block was mined with pre-sold equipment. Peter points out
that the pool in question is marking their blocks by reusing addresses -
ditto for the double spending against dice sites - but that's a trivial
thing for them to fix. Then it'd be difficult (impossible?) for miners to
identify KnC blocks even if there was a strong majority consensus to delete
their coinbases.
The reason I think this particular change is doable is that it should be
possible to quite reliably identify blocks that are Finney attacking for
profit. That doesn't generalise to any policy though. Blocks are intended
to be structurally identical to each other if best practices are followed
and even with the dire pool situation a big chunk of mining hash power
today is effectively anonymous.

@_date: 2014-04-24 13:43:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
No! This is a misunderstanding. The mechanism they use to prevent double
spends is to *ignore double spends*. The blocks they created indicate the
ordering of transactions they saw and proof of work is used to arrive at a
shared consensus ordering given the possibility that transactions arrived
at different times.
I'm continually amazed at how many people seem to see the current algorithm
as the goal in and of itself, instead of an imperfect but workable means of
achieving the actual goal.
To distinguish this definition from your own "honest miners are those
This definition of honesty is not my own, the one Bitcoin has always used.
Obviously if Satoshi had wanted transactions to be double spendable by fee
in the mempool he would have made Bitcoin work that way, instead of coming
up with the nSequence based replacement scheme instead.
First-seen *is* a protocol rule, as much as Set-Cookie storing data in a
browser is an HTTP protocol rule. The fact that auditing compliance with it
is harder to do than some others does not make it less of a rule.
I completely disagree.
Again you are hopelessly confused. Miners that are trying to double spend
are *by definition* not making transactions irreversible, they are trying
to make transactions reversible.
Look at it this way. There is no inherent reason BitUndo has to undo only
Finney attacks. If it gets sufficient hash power it could offer undoing of
1-confirm transactions too, right? Sure it'll mostly fail but that's
already a part of its business model. Sometimes it'll get two blocks in a
row and succeed. It's a very minor tweak to what they're doing. Would you
argue these miners are still useful? After all, it's impossible to be
certain after the fact that miners built on top of the "wrong" block
because forks occur naturally.
What I said is, if you believe all miners are willing to double spend for a
fee then this resolves the experiment as a failure. This is also obvious -
if you can pay miners to go back and rewrite the chain at will, Bitcoin
doesn't work.
Consider the incentives. Let's say all miners are "smart" in your
estimation and are willing to double spend transactions for higher fees.
Because all miners follow this ridiculous policy, they should be willing to
fork the chain at any point to claim the higher fee on the new tx. After
all, although they will throw away the work they did on the previous chain,
if the fee on the new tx is high enough to balance this then it can be
profitable for them to do it.
Because a double spender can afford to give nearly all of his new tx away
in fees, this means even txns well buried in the chain can be profitably
double spent: even if the double spender gets back only 10% of the
transferred amount, if it was a big transfer for some expensive object,
they still win! They got object + 10%
Do you see now why your definition of honesty is completely broken?

@_date: 2014-04-24 13:54:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] 0 confirmation txs using replace-by-fee 
The scheme you described does nothing about Finney attacks, which is the
issue presently faced.

@_date: 2014-04-24 14:15:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] 0 confirmation txs using replace-by-fee 
Phrased another way, it simply makes every block a Finney attack that
charges the maximum double spending fee possible. This doesn't solve the
Beyond needing to double balances, what if the shop is selling me a phone
on contract? So the actual cost of the phone is lower than the real price
on the assumption of future revenue. Alice double spends (aka steals) the
phone, paying double the artifically lower cost but still making a good
saving. Bob does not end up with "nothing", he ends up in the red.
But there's a much simpler way to dispose with this idea. Jorge, go down to
your local bars and cafes, and ask them if they'd be willing to accept a
form of payment that allows anyone to steal from them by simply paying
double the purchase price to some other random guy. They *will* look at you
as if you're crazy. Why would they ever do that?

@_date: 2014-04-24 16:09:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
And as I said before, that's a huge leap. A majority of miners deciding
double spending needs tougher enforcement doesn't imply they also think all
miners should identify themselves. Those are unrelated things.
This kind of totally unsupported "obvious next step" argument can be
applied to any proposal in any walk of life. We developed SPV clients? The
obvious next step is that miners have to stop being anonymous. We developed
floating fees? The obvious next step is that miners have to stop being
anonymous. The prior arguments sound absurd exactly because they're not
obvious or even logical - same as this.

@_date: 2014-04-24 16:28:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
You can't disentangle the two. Proof of work just makes a block chain hard
to tamper with. What it contains is arbitrary. Honest miners build a block
chain that's intended to stop double spending. Dishonest miners don't.
They're both engaging in proof of work, to different ends.
No, let's not. Your definition of "smart miner" is one I'd called "stupid
miner" (or possibly "short bitcoin miner"). They are miners who would
reduce the value of their coins, by making their own system less useful.
That's not smart, that's simply short termism taken to an extreme, sort of
like a business owner who puts so much pressure on his employees they all
quit. He might have gained a bit more profit in the short term, but only at
the cost of destroying his business that would have given lower but
sustainable returns over the long term.
Peter always says this too, but it's again an incorrect position. This is
not an argument from authority.
Why are we here? We are here because we were brought together by shared
What are those goals? They were defined at the start of the project by the
creator of the project.
Why do we issue 21 million coins and not 42? Because 21 million is the goal
everyone signed up for.
Why did everyone sign up for 21 million coins? Because that's what Satoshi
If someone asked us to change from 21 to 42 million coins, we'd probably
say no and the justification would be that this is the number we started
with. That's not "argument from authority", it's just recognition that the
parameters of a shared project has to be defined somehow, and for Bitcoin
it was defined at the start.
Now the argument Gregory makes is that changing the block chain algorithm
in this way would be a violation of the social contract. This is a generic
outcome to be legitimately worried about - we don't want to change what
Bitcoin is in ways that would dismay its users. That just leads to a fork.
I argue that this isn't such a change because it makes nothing possible
that was previously impossible, it just makes it less disruptive, and the
*actual* shared goal of Bitcoin is not "preserve the block chain algorithm
exactly as found in v0.1" but rather "stop double spending".
You are arguing elsewhere that Bitcoin should allow double spending for a
fee. That *would* be a clear violation of the social contract!
Right, but I don't accept this definition of honesty. That's not a
definition any man on the street would use:
    "If you pay for something with forged bank notes and walk out
immediately, you are honest. But if you pay for something with forged bank
notes and hang around for longer than 10 minutes, you are dishonest"
That would sound silly to anyone because what's so special about 10
minutes? It's the act of passing counterfeit money and stealing from the
merchant that's the dishonest act, how long it takes is irrelevant.
In Bitcoin, the dishonest act by the user is signing for the same output
twice (ignoring special protocols here), and the dishonest act by the miner
is deviating from normal behaviour for a fee to try and trick the recipient
into believing they have been paid. The exact details are something
computer scientists care about, but the average Bitcoin user would not.
Indeed and that's why we have these threads! These are fundamental issues
that simply must be debated.

@_date: 2014-04-24 17:34:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
Thanks Sergio!
Fascinating! I think that's the first time I heard of an alt coin entirely
based on bitcoinj as its core implementation. Looking forward to your
My understanding is that dogecoin suffers somewhat from having so many
headers. SPV clients have to download them all in sequence so the more
blocks you have, the more data they must download and thus the slower they
sync. Sync times for SPV wallets today are fast enough that unless you
spend six months in the jungle with your phone switched off, you probably
won't notice. With 5 second block times unless there's some other solution
you'd have much worse UX.
BTW, Pieter experimented with relaying blocks as hash lists (actually
merkleblocks) and I believe he found that it could often fail and be slower
if the mempools were not quite synced. At any rate, it was apparently more
complicated than it looked. That may be a side effect of trying to reuse
the Bloom filtering code however.
MinCen looks like a rather interesting idea. I will read the paper.

@_date: 2014-04-24 17:45:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] 0 confirmation txs using replace-by-fee 
Bitcoin's competition is not some theoretical perfect p2p system but
rather, bank notes and credit cards.

@_date: 2014-04-25 12:17:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
interpretation of existing blocks is in any way up for grabs would set a
Hmm, then I think your faith needs to be shaken. Bitcoin  is money, and
money is a purely artificial social construct. The interpretation of what a
bitcoin means, or what a dollar means, has always been and always will be a
human decision taken in order to achieve some socially useful goal. How
could it be any other way? Do you want humanity to be enslaved by its own
This notion that the block chain encodes some kind of natural, immovable
law that's above human judgement is a very strange one to me - I guess it
comes from the fact that encryption *is* based on some kind of natural law.
Without the key you can't decrypt a message no matter how strong the
consensus is. But Bitcoin doesn't use encryption anywhere, just digital
signatures. The only thing approaching natural law, that stops majority
consensus controlling everything, is lack of information. Hence all the
discussion around privacy and anonymity that goes on all the time.

@_date: 2014-04-25 12:19:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] 0 confirmation txs using replace-by-fee 
If they could do that they'd just take the stolen property back and you
would have failed to spend your money twice. So this is by definition, not
a successful double spend. We are worried about the cases when you could
successfully double spend, and the only thing stopping you is Bitcoin.

@_date: 2014-04-25 17:28:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
sure that money is yours - but only because the rules for interpreting
Well, I think we should avoid the term "sacred" - nothing is sacred because
we're not building a religion here, we're engineering a tool.
Consider a world in which 1 satoshi is too valuable to represent some kinds
of transactions, so those transactions stop happening even though we all
agree they're useful. The obvious solution is to change the rules so there
can be 210 million coins and 10x everyones UTXOs at some pre-agreed flag
day. We probably wouldn't phrase it like that, it's easier for people to
imagine what's happening if it's phrased as "adding more places after the
decimal point" or something, but at the protocol level coins are
represented using integers, so it'd have to be implemented as a multiply.
Would this be a violation of the social contract? A violation of all that
is sacred? I don't think so, it'd just be sensible engineering and there'd
be strong consensus for that exactly because 21 million *is* so arbitrary.
If all balances and prices multiply 100-fold overnight, no wealth is
reallocated which would be the *actual* violation of the social
contract: we just get more resolution for setting prices.
So. The thing that protects your money from confiscation is not proof of
work. PoW is just a database synchronisation mechanism. The thing that
protects your money from confiscation is a strong group consensus that
theft is bad. But that's a social rule, not a mathematical rule.

@_date: 2014-04-25 17:49:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP32 "wallet structure" in use? Remove 
I generally agree, but I wonder how popular cloning wallets between devices
will be in future. Right now if someone wants to have a wallet shared
between Hive, blockchain.info and Bitcoin Wallet for Android, we just tell
them they're out of luck and they need to pick one, or split their funds up
But probably a lot of people would like to use different UI's to access the
same wallets. Sharing key trees is a part of that, though full blown wallet
metadata sync would also be needed.
So I guess we're going to end up with some kind of fairly complex
compatibility matrix. But I agree it may be unavoidable.

@_date: 2014-04-26 11:43:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure for P2SH multisig 
I'm not sure I understand why you need any special structure for this at
all. The way I'd do it is just use regular HD wallets for everyone, of the
regular form, and then swap the watching keys. Why do people need to be
given a cosigner index at all, given that they all have unique root keys

@_date: 2014-04-26 19:36:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Error handling in payment protocol 
In future it might be nice to have images and things in the payment
requests, to make UIs look prettier. But with the current version 50kb
should be plenty indeed.

@_date: 2014-04-26 20:07:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Eliminating double-spends with two-party 
What stops the buyer just always waiting to get their money back?

@_date: 2014-04-26 20:18:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proof-of-Stake branch? 
Please be aware that your emails are being spamfoldered by Gmail. This is
because Yahoo has enabled DMARC enforcement for mail sent from Yahoo and
that renders it incompatible with Sourceforge mailing lists.
There are two fixes:
1) Don't use Yahoo.
2) The real fix which is, we should stop using Sourceforge mailing list
Fundamentally all Yahoo is saying with their policy is that rewriting of
mails sent from their service is not allowed. This is a highly reasonable
policy, akin to forbidding SSL MITM attacks, but for email.
There are several ways to be compatible with this policy: unfortunately
sf.net doesn't do any of them.

@_date: 2014-04-26 20:51:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Eliminating double-spends with two-party 
Right, that does make more sense. Yes, it's a good idea. The question is
whether wallet UI's can support it without being overly complex. We'd be
asking users to take extra steps to work around unintuitive limitations of
the protocol. Products that do that too much tend to get left for something
that "just works". But there may be a slick way to present it.

@_date: 2014-04-26 22:17:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP0071 media type registration with IANA 
Bitcoin is not a vendor, so I doubt that would work.
I doubt we should spend any time on this. The chance of a string collision
is extremely low. The current mime types are fine.

@_date: 2014-04-26 22:33:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure for P2SH multisig 
This is the part I struggle to understand. There is no shared branch
because each user/cosigner has their own unique seed and thus unique key
hierarchy, right? What you described above could be an issue if all
co-signers shared the same seed but then the scheme wouldn't work.

@_date: 2014-04-26 23:57:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure for P2SH multisig 
Ah, I see now. Thanks. And actually now I re-read it, Manuel's explanation
was clear, it just didn't sink in for some reason.

@_date: 2014-04-27 16:31:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
Yep, your point is well made.
I don't have much more to say about this proposal specifically, but I think
this whole question of what changes are OK and what would be a violation of
the social contract will get discussed endlessly over the coming years. Put
another way, what do Bitcoin's users expect and want - a system that
evolves or a system that remains exactly as they found it? There will be
good arguments on both sides, and the answer will probably be different on
a case by case basis. But personally I'm skeptical of any argument that
argues against change for its own sake. It has to be an argument rooted in
a careful analysis of costs and benefits.

@_date: 2014-04-28 18:14:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal to change payment protocol 
Who cares what it is? Setting to an empty byte array is fine, IMO. The
payment protocol is already rolling out. It's implemented in several
wallets, BitPay implements it, Coinbase is implementing it, etc.
-100000 for changing such a basic thing at this point. It'd cause chaos for
the early adopters, punishing them instead of rewarding them. It'd
seriously hurt adoption of the payment protocol when it's at its most
vulnerable. We should mark BIP 70 as accepted and be done with it.

@_date: 2014-04-29 16:13:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
I do think we need to move beyond this idea of Bitcoin being some kind of
elegant embodiment of natural mathematical law. It just ain't so.
Every time miners and nodes ignore a block that creates >formula() coins
that's a majority vote on a controversial political matter, as evidenced by
the disagreement with mainstream economics and that it's one of the most
common things for alt coins to change. Indeed Satoshi's chosen inflation
formula is a highly political statement on the value of inflation - he
could have programmed Bitcoin to inflate forever and avoided a whole area
of politics, but he chose not to.
So please, let's agree to accept that Bitcoin is ultimately just a piece of
software that encodes rules helping us run our little community in some
specific ways. It's not physics and we should believe our own hype by
pretending it is.
It's the other way around. If miners decide to fork the chain then that
leaves no proof (beyond the old blocks, which could have been a natural
fork - there's no way to know - and nodes don't want to keep them around
anyway). If they explicitly vote to get the same effect but without
actually forking, it leaves a proof in the form of the votes in the
coinbase that can be seen afterwards.
It only works if the majority of hashpower is controlled by attackers, in
which case Bitcoin is already doomed. So it doesn't matter at that point.

@_date: 2014-04-29 16:15:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] please check my debug.log 
Looks good to me!
You're not in the DNS seeds yet. If you leave your nodes up for a while
then you'll start getting traffic from bitcoinj clients too.

@_date: 2014-04-29 16:26:01
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
Of course not, attackers rarely do :)
But they are miners who are taking part in malicious double spending. That
makes them attackers. If miners don't exist to stop double spending, what
do they exist for?
I mean, this is fundamental. What do you think miners exist for?

@_date: 2014-04-30 15:55:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
I think we're going around in circles here so this will be my last message
on the thread unless someone comes up with something new.
One last time, I request that people read the white paper from 2008 before
making statements like this. If the notion of attacker was irrelevant to
Bitcoin, it would not be mentioned in the abstract, would it?

@_date: 2014-08-05 17:00:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] How to create a pull tester JAR 
I just checked in a change to bitcoinj git master that makes it much easier
to create a pull tester jar. Here are instructions for how to do it.
You will need:
   - A Java Development Kit (JDK), version 6 or up should work. As Java 6
   was released eight years ago, this should not be a challenging requirement.
   If you have a Mac just running "java" from the command line should give you
   a GUI prompt to install it automatically. Otherwise apt-get or fetch the
   latest from the interwebs.
   - Apache Maven. This is a rough equivalent of autotools, except it does
   dependency resolution for you. Grab it from
    then unzip it and make sure the bin
   directory is in your PATH. You may need to set the JAVA_HOME environment
   variable if you installed Java to an odd place.
   - git
Make sure you can run "javac" from the command line, then make sure you can
run "mvn", it should complain it can't find a POM (this is a build config
file) and not, say, that it can't find Java.
Now grab bitcoinj from git master:
git clone ... and build ....
cd bitcoinj
mvn -DskipTests package
It will go off and download the libraries needed, compile, and create a
bundled executable JAR called core/target/pull-tests.jar. This is sort of
analogous to static linking in the Java world. It should be fast - expect a
full build plus downloads to take less than a minute. You can use it either
with the QA scripts in the bitcoin core qa/pull-tester directory or just
run things directly:
./bitcoind -regtest -connect=0.0.0.0 -listen -whitelist=127.0.0.1
java -jar core/target/pull-tests.jar
It should go ahead and print lots of debug spew, then at the end say it's
Let me know if you encounter any problems with this.
Java JARs (which are just zip files renamed) are easily reproduced if you
use the same version of javac and the same bitcoinj version. The ZIP
container has timestamps, but unzipping them and simply diffing the files
between two builds should reveal no differences. I am happy to provide a
pull-tests.jar from my local machine if anyone would like to do this.

@_date: 2014-08-05 17:11:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] How to create a pull tester JAR 
Oh, I forgot to mention something important. Ridiculously, the default
package repository Maven uses was not protected by SSL up until a few days
ago.  They made it available via SSL now, but you have to tell Maven about
the new URL. I guess they'll do a new release where SSL is the default
soon. But for now before you run mvn save the following magic incantation
to the path ~/.m2/settings.xml:
(side note: yes maven's love of XML is widely ridiculed and more modern
build tools have much better config languages, but we didn't upgrade yet)

@_date: 2014-08-05 18:58:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] How to create a pull tester JAR 
No problem.
The pull tester entry point can be found here:
(nb: in the near future I will be re-namespacing the library from
com.google.bitcoin to org.bitcoinj to reflect that it no longer has
anything to do with Google and then this link will break).
The code itself is a rather bad example of copy/paste coding and I can say
that, because Matt knows it and already plans to refactor things ;) So if
anyone is thinking of adding tests to the framework coordinate with him
first to ensure you don't end up conflicting with a big refactor/rewrite.

@_date: 2014-08-05 20:54:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] deterministic transaction expiration 
Yes, indeed. I suspect there's a quick hack that could make this problem a
lot better though.
I think I brought up this idea before, but can't quite remember. Anyway I'm
willing to bet that if we analysed the data some more, we'd discover that
most "legitimate" i.e. non-DoS unconfirmed transactions that sit around for
ages are linked back to the block chain within two hops and not more. That
is people send a transaction that uses up their coin age, and then
immediately those coins are immediately respent again, but then those final
new coins are not spent.
On the other hand DoS attacks look like bouncing your coins around over and
over forever, i.e. more than two or three hops back to the chain.
So I wonder if making priority look back two or three transactions but not
more would help real users a lot, whilst not opening up any significant new
potential for DoS.

@_date: 2014-08-06 15:54:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] deterministic transaction expiration 
We could however introduce a new field in a new tx version. We know we need
to rev the format at some point anyway.

@_date: 2014-08-08 11:42:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Miners MiTM 
Why would miners need updates? If they implement the standard SSL
infrastructure you can change certificates and keys without needing to
update miners.
Besides, when it comes to financial services SSL is essential, I'm kind of
surprised it wasn't already used everywhere. I wouldn't use an online bank
that didn't support SSL, I would see it as a a sign of serious problems.
Heck I wouldn't even use webmail that didn't support SSL these days.

@_date: 2014-08-08 11:45:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] NODE_EXT_SERVICES and advertising related 
Given that we're not running out of service bits and service bits mean you
don't have to try connecting to every node to find out what services it
supports, why not keep using the existing extension mechanism until we
start running out of bits?

@_date: 2014-08-08 11:53:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Miners MiTM 
Surely the TCP connection will be reset once the route reconfiguration is
completed, either by the MITM server or by the client TCP stack when it
discovers the server doesn't know about the connection anymore?
TLS without cert validation defeats the point, you can still be connected
to a MITM at any point by anyone who can simply interrupt or corrupt the
stream, forcing a reconnect.

@_date: 2014-08-08 12:01:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] NODE_EXT_SERVICES and advertising related 
Why not? Does the port matter much?
Yes, I understand what it does, but from a clients perspective what it
means is if someone implements a useful service and exposes it this way you
have to seek out, connect to and interrogate every possible server even if
(say) only a handful actually provide it. The most there's >1 "ext service"
the protocol becomes extremely slow, vs service bits where you can download
addr packets and see which IPs are advertising which services.
I don't see much reason to take a potentially large performance hit when
there's a service advertisement mechanism that already works. What's wrong
with the existing mechanism exactly?

@_date: 2014-08-08 13:38:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] NODE_EXT_SERVICES and advertising related 
I'd like to see a mechanism whereby a Bitcoin node can delegate processing
of unknown messages to an external process, so a P2P node can be composed
out of separated programs, but such a service would be indistinguishable at
the network layer from one provided by Bitcoin Core itself, so a service
bit would be appropriate for those.
For instance, Insight could then offer a command set that extends the p2p
protocol for doing block explorer type queries. There's no need for the
protocol to be Insight specific.  You'd just have NODE_INDEXED_CHAIN
Having the service run on some arbitrary other port isn't particularly
useful, IMO - the biggest win from having some separated protocol would be
the ability to use TLS, but if you're connecting to an IP address rather
than a domain name (like if you discovered via service bits/getextsrv) this
doesn't add much. It boils down to minor syntax differences in how numbers
are laid out in a grid. And the performance issue remains.
Additionally, nothing in this spec requires that a local bitcoind be
running. What stops someone from advertising just NODE_EXTENDED_SERVICES
and nothing else? I don't think a generic service advertisement mechanism
is a bad thing to have, by the way, just pointing out that nothing makes
this more focused than service bits already are.

@_date: 2014-08-08 14:11:25
@_author: Mike Hearn 
@_subject: [Bitcoin-development] NODE_EXT_SERVICES and advertising related 
Right, although getutxos needs access to the UTXO set which bitcoind
already has. An external plugin would have to recalculate it from scratch
which seems redundant.
However there are many other useful services that could be added in such a
way, like -txindex or the nLockTime storage facility we talked about the
other day.
Maybe, that feels like it could be overkill though. Probably just something
./bitcoind -servicecookie= -allowextservices=127.0.0.1/8
and then any program can connect to bitcoind as normal, send "registersrv"
with the cookie and a list of command ids it's interested in, maybe a
service bit to set, and start receiving those messages wrapped in a new
structure that gives some kind of client ID (like IP address). So any
library that can do the basic P2P protocol could then be extended with not
much code to get a multiplexed stream of messages from different clients.
An additional standalone program can then bridge this mechanism to running
a shell command for particular messages, though given the history of shell
based exploits I'd feel safer with something that doesn't do that ....

@_date: 2014-08-08 14:13:45
@_author: Mike Hearn 
@_subject: [Bitcoin-development] NODE_EXT_SERVICES and advertising related 
Sure, that makes more sense I think.
As a motivating use case, Bitcoin Wallet for Android currently has a
hard-coded block explorer (biteasy.com) which it uses to find UTXOs for a
given key. This is used for its "Sweep paper wallet" feature. It must work
this way because P2P nodes don't calculate such indexes.
If there was a way to do block index autodiscovery, that'd help us remove
this hard-coded block explorer and increase decentralisation. But because
it's a GUI app we don't want users to look at a spinner for more than a few
seconds, so a slow discovery process would make it unworkable. With
API-based categories of service bits we could implement such a scheme.

@_date: 2014-08-08 15:55:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] NODE_EXT_SERVICES and advertising related 
Yes, can be done this way too. I was thinking about setups where you have
services distributed across multiple machines. However a separate port does
indeed allow iptables or the like to be used.

@_date: 2014-08-11 14:08:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] CoinShuffle: decentralized CoinJoin 
Putting the efficacy of coinjoin to one side:
On Mon, Aug 11, 2014 at 1:38 PM, Tim Ruffing <
Bear in mind that getutxo does not return the spending transaction - it
can't because the UTXO set doesn't record this information (a spent txo is
However, if you have sufficient peers and one is honest, the divergence can
be detected and the operation stopped/the user alerted. If all peers are
lying i.e. your internet connection is controlled by an attacker, it
doesn't really make much difference because they could swallow the
transaction you're trying to broadcast anyway. Ultimately if your peers
think a TXO is spent and refuse to relay transactions that spend them, you
can't do much about it even in the non-SPV context: you *must* be able to
reach at least one peer who believes in the same world as you do.

@_date: 2014-08-18 19:27:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Outbound connections rotation 
It's also the first/next step towards decentralising the DNS seeds (for SPV
clients), as it'd allow each node to explore the network and return better
quality results in getaddr.
This is sort of what Tor is going through with their guard nodes and how
often to rotate them.
I think the attack Ivan is talking about does not require sybil attacks to
work though, just listening to lots of peers. Raising the bar to require
the attacker to receive lots of connections seems like a win.

@_date: 2014-08-20 16:16:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Reconsidering github 
If github were to be abandoned for anything, it'd make sense to move code
review and bug tracking elsewhere. GitHub does a reasonably good job of
hosting git repositories. It kind of sucks at code review and the issue
tracker is rudimentary at best. These days you can do "log in with my
github account" so if done well, it'd not have to be very painful.
JetBrains make great stuff and they have a code review and repository
exploration tool called Upsource in development, which should come out
soon. I think it's proprietary but that would be no different to github,
and it's designed for self hosting.

@_date: 2014-08-20 16:37:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: Encrypt bitcoin messages 
I would be very happy if we upgraded the P2P protocol with MAC keys and a
simple home grown encryption layer, because:
   1. It's practically guaranteed that 5-eyes intelligence agencies are
   either systematically deanonymising Bitcoin users already (linking
   transactions to real world identities) or close to succeeding. Peter is
   correct. Given the way their infrastructure works, encrypting link level
   traffic would significantly raise the bar to such attacks. Quite possibly
   to the level where it's deemed unprofitable to continue.
   2. Tor is not a complete solution. The most interesting links to monitor
   are those from SPV clients connecting to Core nodes. Whilst Java SPV
   clients have the nice option of an easy bundled Tor client (er, once we fix
   the last bugs) clients that are not based on bitcoinj would have to use the
   full-blown Tor client, which is not only a PITA to bundle as Tor is not at
   all library-fied, but is a giant pile of C which is almost certainly
   exploitable. Even if it runs in a separate address space, for many
   platforms this is insufficient as a compromised Tor client could then go
   ahead and compromise your wallet app too.
Implementing a full Tor client is not a reasonable thing to ask of a wallet
developer, but doing HMAC checks and a simple ECDH exchange + AES would be
quite realistic.

@_date: 2014-08-20 16:41:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: PoW-based throttling of 
You can't solve DoS by requiring all clients to do complicated work, all
that means is that weak clients (like users mobile phones and tablets) are
successfully DoSd whereas the attackers botnet of stolen computers sit
there solving PoWs.
The correct way to solve DoS is by having work prioritisation and queueing
mechanisms, then finding ways to distinguish "good" clients from "bad"
clients. Doing this whilst preserving privacy is hard. Long term the only
way to solve it may be to require clients to present some kind of cookie
during resource exhaustion events that prove they've been around for a
while, thus allowing them to jump the queue.

@_date: 2014-08-23 15:03:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: PoW-based throttling of 
I only know of one site that worked the way you propose: TicketMaster, a
long time ago. They used it as a less harsh form of blocking for IPs that
they strongly suspected were bots, which is what you suggest indeed. But
99% of the hard work of that system was in scoring the connections. The
actual PoW part didn't work that great because bots have much more patience
than humans do.
Other sites also use proofs of work, but they're CAPTCHAs i.e. human PoWs.
And unfortunately those don't work very well these days either :(
Yes, I understand, but then you're back to scoring clients - the hard part
- and the only question is do you slow down that client by sticking them at
the bottom of a work queue or by requiring them to solve a difficult PoW.
The best approach is the first one because that scales naturally .... you
don't have to define some notion of misbehaviour, you just prioritise
amongst clients.
The current notion of "misbehaviour" is only somewhat useful. It's easy to
classify reasonable behaviour as harmful and shoot yourself in the foot. We
managed this at least once back in 2010 when we actually released a version
of Bitcoin that interpreted a normal request to serve the block chain as a
DoS attack! It couldn't serve the chain at all! Additionally many things
that can be interpreted as an attack like sending a message with a bad
signature can also be caused just by mistakes, or version skew during
software upgrades. So it's very tricky to get this right.
That's important because one quite common way big sites suffer DoS attacks
is by accidentally having real users create a DoS "attack" by e.g. pushing
a bad software update, or by having sudden and unexpected press-driven
growth, etc. You really don't want to force users to sit around waiting and
wasting battery. It's better to serve as many requests as you can up to
your absolute limit and try to ensure as many of them as possible are good.
I doubt it matters. Any DoS attack that's powerful enough to use up most of
the networks resources is probably being driven by a botnet of some kind,
and *all* legitimate users will lose in an even fight against a botnet.
Cookies can be somewhat anonymized. For example a cookie that is merely a
signature over a timestamp of some kind (doesn't have to be an secp256k1
signature) can be normalised to the day or week. So you can prove you've
been using Bitcoin for say 3 years but it doesn't pin you down precisely.
This isn't perfect:  attackers can and do "age" accounts before preparing
for abuse. Proof of UTXO is another way to rank users. If you're richer
you're presumably more important for the network to process than poor
people. However you end up back at a CPU imbalance. PoW can possibly play a
role here to even it out: the cost of submitting a UTXO proof should be at
least equal to the cost of verifying the signature, but that is a PoW small
enough that users would not notice.

@_date: 2014-08-23 20:44:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: Encrypt bitcoin messages 
Recall that P2P connections carry Bloom filters too, which are not public

@_date: 2014-12-04 19:04:21
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Serialised P2SH HD chains 
I wrote a little Javascript program
to print some minimal protobufs to base64.
Result for a multisig output:
Result for a regular pay to address output:
That is without any expiry time, which you'd want in practice. For an
HD-iterating payment request you'd also need a few flags and fields, but a
well designed protocol should only add a handful of bytes. The above
strings are, I think, short enough to set as a username in a mining program
so the general UX of Eligius can be maintained.
How to generate them? That's not too hard. Building specialised one-off SPV
wallets is quite easy these days with bitcoinj, there's a template app and
a video tutorial on how to customise it available here:
You can just copy/paste the code into a new directory and start modifying
it. The final result is like Lighthouse - you run a program and get an EXE
installer or MSI for Windows, a DMG for MacOS and a .deb for Linux (though
a tarball would work just as well).
So producing a little GUI that lets you build a base64 encoded payment
protocol request that supports HD iteration for one or more keys, along
with a little BIP70 extension that says "although this output is a multisig
output, please actually create a p2sh output", would make a nice starter
project for someone. It could also then act as a watching wallet and plot a
graph of mining payouts over time, for example.
If anyone wants to take this on let me know. I can help out with the final
code signing steps to make Gatekeeper/Internet Explorer happy so don't
worry about distribution.
On Thu, Dec 4, 2014 at 6:25 PM, William Swanson

@_date: 2014-12-08 17:59:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Deanonymisation of clients in Bitcoin P2P 
Sure. I guess there will be wallets for all kinds of people in future,
sharing a common core that they can customise (this is certainly the vision
and general direction for bitcoinj, and it's working out OK).
To clarify, my comments above were for mainstream granny-focused wallets.
Wallets designed for crypto geeks can and should expose all the knobs to
let people run wild.
One possible direction to go is to use Tor for writing to the network and
use general link encryption and better Bloom filtering for reading it. Thus
new transactions would pop out of Tor exits, but there isn't much they can
do that's malicious there except mutate them or block them entirely. If you
insert the same transaction into the P2P network via say 10 randomly chosen
exits, the worst a malicious mutator can do is race the real transaction
and that's no different to a malicious P2P node. Even in a world where an
attacker has DoS-banned a lot of nodes and now controls your TX submission
path entirely, it's hard to see how it helps them.
The nice thing about the above approach is that it solves the latency
problems. Startup speed is really an issue for reading from the network:
just syncing the block chain is already enough of a speed hit without
adding consensus sync as well. But if you're syncing the block chain via
the clearnet you can connect to Tor in parallel so that by the time the
user has scanned a QR code, verified the details on the screen and then
pressed the Pay button, you have a warm connection and can upload the TX
through that. It reduces the level of startup time optimisation needed,
although Tor consensus download is still too slow even to race a QR code
scan at the moment. I think tuning the consensus caching process and
switching to a fresh one on the fly might be the way to go.
When BIP70 is in use, you wouldn't write the tx to the network yourself but
you could download the PaymentRequest and upload the Payment message via an
SSLd Tor connection to the merchant. Then malicious exits can only DoS you
but not do anything else so there's no need for multiple exit paths

@_date: 2014-12-28 18:25:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cartographer 
Hi there!
Lately we have been bumping up against the limitations of DNS as a protocol
for learning about the p2p network. As a proposal for how to address this,
I have written a new network crawler and seed:
It implements a standard DNS seed with a minimal embedded DNS server (you
can find one running at dnsseed.vinumeris.com) and also has the following
extra features:
   - Can serve seed data using gzipped, timestamped digitally signed
   protocol buffers over HTTP. This fixes authentication, auditability,
   malware false positives and extensibility. The signature uses secp256k1.
   SSL is *not* used, to simplify deployment and to allow ISPs to cache the
   results transparently when a future version sets cache control headers.
   - Can additionally serve data in JSON, XML and HTML (examples for json
    xml
    html
   ) for ease of use with other
   tools, like web browsers.
   - Results can be restricted using query parameters, e.g. for a service
   flags bit mask. Cartographer tests nodes that set service bit 2 to see if
   they really support BIP 64, and this requirement can also be specified as
   an argument to the query.
   - Crawl speed can be specified in terms of successful connects per
   second, rather than the number-of-threads approach used by other crawlers.
   - Can export statistics and controls using JMX, so you can reconfigure
   it at runtime and view charts of things like connects/sec or CPU usage
   using any JMX console, like Mission Control.
   - A client for it is in bitcoinj master branch.
To provide all these features Cartographer relies heavily on libraries and
is written in a concise new language called Kotlin ,
so it fits in about 650 lines of code. Kotlin is easy to learn for anyone
who knows Scala or Java, so it should be straightforward to hack on and
there is no chance of any buffer/heap exploits in the DNS, HTTP or Bitcoin
protocol stacks.
In the new year I will probably write a BIP describing the protocol. For
now you can see the definition here
or just read the textual forms from the links above. It's pretty self
explanatory. I hope that in future other DNS seeds will start supporting
this protocol too, as it has many advantages.
Future versions might include data like how long the peer has been around,
node keys if we add auth/encrypt support to the p2p protocol and so on.

@_date: 2014-12-28 18:04:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin XT 
Hi there,
I hope everyone who celebrates Christmas is having a relaxing and enjoyable
break! :)
I'd like to announce Bitcoin XT , a
patch set on top of Bitcoin Core 0.10rc1 that focuses on enhancements to
the peer to peer protocol. It is reproducibly built with gitian and there
are binaries for Linux, OS X and Windows (code signed). It currently
contains the following two features:
   1. Double spend relaying, by Gavin Andresen and Tom Harding. This is
   useful for merchants that currently connect to thousands of nodes to spot
   double spends, which is wasteful of resources.
   2. BIP 64 support (the getutxo message). This is useful for Lighthouse
   to render a more helpful GUI.
By running XT you provide additional services to users of the P2P network,
test the features more thoroughly and help build the case for inclusion in
Bitcoin Core.
There is a mailing list for discussion of patch inclusion
, and another list for
announcements .
Because XT is a patch set the feature branches will be rebased from time to
time. If you branch from them, be aware of that and plan accordingly.
XT nodes advertise themselves by using the getutxo service bit (i.e. bit
2). You can find them by querying a Cartographer, which I will describe in
another email.
A brief note about the goals of this project. The XT project is intended to
provide a friendly environment where [SPV] app developers and merchants can
experiment with new features and explore new directions for the protocol,
if there is demand for that. Those upgrades could then be considered for
inclusion into Core at a later date. I do not expect there to be thousands
of XT users any time soon, but that's OK. Because the patch set contains
features that don't require everyone to opt in (e.g. changes to the
tx/block formats), even just a few nodes can be useful.
Thanks for reading, and have a great new year's eve!

@_date: 2014-12-29 11:30:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cartographer 
Well, look at the feature list :)
The biggest need from my POV is querying support. It's awkward to try and
retrofit flexible key=value pair queries onto DNS, it just wasn't designed
for that. With HTTP it's easy. This will become more important in future as
the protocol evolves. For example, some nodes will soon stop serving the
block chain because they start pruning. Today this is managed with a hack:
pruning nodes just stop providing *all* services to the p2p network. This
takes them out of the DNS seeds entirely. But they can actually still
provide download of the parts of the chain they still have, and they can
provide transaction filtering and relay support, along with misc other
With the current DNS protocol you get an all or nothing choice - so
probably seeds that only support it will elect to only show nodes that have
the entire block chain, because that's what Bitcoin Core would find most
useful. SPV wallets have slightly different needs.
In theory you could come up with a pile of hacks to specify what the client
needs in the DNS query, but then you have a v2 protocol anyway and might as
well go the whole way.
Additionally, with DNS it's awkward to provide extra data in the responses
beyond IP address and it's VERY awkward to sign the responses. Signing the
responses has a couple of benefits. The biggest is, in future it'd be nice
to have an authenticated and encrypted network, to raise the bar for sybil
and MITM attacks. DNS seeding can't be upgraded to support that with any
reasonable level of effort. And DNS is awkward to configure/set up.
Actually DNS is just awkward, period.
The second benefit of signing is it provides audibility. If you see a seed
give bad answers, you can now prove it to other people.
There is also the previously discussed issue that DNS seeds sometimes get
blocked by aggressive networks because they start serving IPs that are
infected with malware i.e. they look like fast-flux sites.
Using a simple HTTP based protocol fixes all of these problems in one go.
Now, re: privacy.
Firstly, Peter, get help. I'm serious. You are starting to sound like an
auto-generated parody of yourself. When you can't debate something as
boring as HTTP vs DNS without trying to raise an angry mob using bizarre
conspiracy theories, that's not normal.
I don't think the "DNS has caches" issue is worth worrying about for a lot
of reasons:
   1. Full nodes try as hard as they can to open ports and advertise their
   IP addresses to everyone. Even if you change the defaults to disable that,
   you're about to connect to a bunch of random computers with no reputation
   anyway.
   2. Lists of stale IP addresses are hardly useful to regular people and
   network operators can identify Bitcoin users by looking for traffic on port
   8333, so it's unclear what threat model is being addressed here.
   3. The biggest users of the seeds are all SPV wallets. Every single one
   of these already phones home to check for online updates.
   4. DNS proxying only hides part of the IP address. If you're serious
   about this you want to be doing lookups via Tor. Whilst it's possible to
   use the DNS seeds via Tor in a reasonable way with exit diversity (and
   bitcoinj does), doing it requires low level Tor protocol programming
   that is out of reach for most implementors. An HTTP lookup is trivial with
   any HTTP stack that supports SOCKS.
   5. ISPs also deploy transparent HTTP caches. The Cartographer protocol
   uses HTTP with inline signing so responses can be cached, once the right
   headers are being set.
tl;dr it's unclear that DNS caching actually solves any real privacy
problem but regardless, you can get the same distributed caching with HTTP
as with DNS. So in the end it makes little difference.
I believe that Cartographer is a better protocol all round and there are no
costs beyond the one-time upgrades, but even if for some reason you
disagree with the five privacy points above, I think the benefits still
massively outweigh the costs.

@_date: 2014-12-29 21:10:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP: Voluntary deposit bonds 
Could you explain a bit further Sergio? I'm not sure I fully understand the
How does adding inputs to a coinbase differ from just having pay-to-fee
transactions in the block?

@_date: 2014-02-04 13:01:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.11 released, with p2sh, 
I'm pleased to announce the release of bitcoinj 0.11, a library for writing Bitcoin applications that run on the JVM. BitcoinJ is widely used across the Bitcoin community; some users include Bitcoin Wallet for Android, MultiBit, Hive, blockchain.info, the biteasy.com block explorer (written in Lisp!), Circle, Neo/Bee (Cypriot payment network), bitpos.me, Bitcoin Touch, BlueMatt's relay network and DNS crawler, academic advanced contracts research and more.
The release-0.11 git tag is signed by Andreas Schildbach's GPG key. The commit hash is 410d4547a7dd. This paragraph is signed by the same Bitcoin key as with previous releases (check their release announcements to establish continuity). Additionally, this email is signed using DKIM and for the first time, a key that was ID verified by the Swiss government.
Key: 16vSNFP5Acsa6RBbjEA7QYCCRDRGXRFH4m
Signature for last paragraph: H3DvWBqFHPxKW/cdYUdZ6OHjbq6ZtC5PHK4ebpeiE+FqTHyRLJ58BItbC0R2vo77h+DthpQigdEZ0V8ivSM7VIg=
Notable changes and new features
Thanks to Ken Sedgwick, an implementation of BIP39 ("Mnemonic code for generating deterministic keys") has been added. This is compatible with the latest Trezor implementation.
Thanks to Mike Belshe, the wallet can now send to P2SH addresses.
Thanks to Matt Corallo, the network layer was rewritten from scratch. It no longer depends on Netty, and it now supports both blocking and non-blocking sockets. In practice that means Java's built in support for transparent SSL and SOCKS becomes available again, which in turn means connecting via Tor is now possible. The new framework is lightweight, easy to understand and has been running a DNS seed crawler for some months now.
Thanks to Kevin Greene, we've added some support for the BIP70 payment protocol. Wallet authors can now consume payment requests, check their signatures and submit payments with the new easy to use PaymentSession class. The wallet-tool command line UI has support and an article explains how to use it.
Thanks to Miron Cuperman, the wallet can now watch arbitrary addresses and scripts. The wallet could previously watch an address as long as the public key was known. Now it's possible to watch for addresses even when the public key is not known.
Also thanks to Miron, Bloom filtering was also improved. The system now tracks false positive rates and cleans the filter when FP rates get too high. Unfortunately, some privacy bugs in Bloom filtering remain, which could (amongst other things) allow a malicious remote peer to test whether you own a particular key.
Thanks to Alex Taylor (bitpos.me), a new PostgreSQL based pruning block store was added. This block store is fast, and indexes the UTXO set, allowing for fast lookup of the balance of any given address.
A Java 8 based wallet template app is now included. The template is designed for people writing contract based applications. It provides a simple app that can be copy/pasted, which connects to the P2P network, manages a wallet, and provides a GUI that shows progress, balance, address+qrcode for receiving money and has a button that is used to empty the wallet out. It's designed to have an attractive and modern look, with tasteful animations and artwork.
Micropayment channels got many big improvements to the API and implementation. The release in 0.10 can be seen as a beta, in this release the micropayments code has been taken for a test drive for a couple of real apps and many rough edges polished as a result.
The default USER_THREAD executor can now be replaced, allowing a 1-line switch of all callbacks onto a thread of your choice instead of needing to override each callback, each time. This should simplify and clean up the GUI code of wallet apps significantly.
The WalletTool command line app has a more convenient user interface now.
A new DNS seed has been added. The seed is run by Christian Decker, from ETH Zurich.
bitcoinj 0.11 will shortly be available via Maven Central. Please use the dependency verifier plugin and/or check the PGP signatures on the uploads, if you use this!
Smaller improvements
We finished adding nullity annotations to the API. You should now be able to assume that any method not annotated with  won't ever return null values.
The WalletAppKit got a bunch of new features and convenience APIs.
The wallet will now create inputs with dummy signatures if the private key for an output is missing, rather than throwing an exception. You can then edit the input later to substitute in a real signature. This is useful when the signing is being done elsewhere, outside of the library.
In full verification mode, execution of scripts (i.e. checking signatures) can now be switched off. This is useful if you trust the source of the chain and just want to calculate the UTXO set.
The wallet risk analysis code is now pluggable, better documented and checks for finality in a more sensible way.
Various memory usage and flow control optimisations were made to allow much larger wallets to sync on Android.
The transaction broadcast algorithm was changed to be more robust.
Double spend handling in the wallet was improved.
Generated signatures now use canonical S values. This will aid a future hard-forking rule change which bans malleable signatures.
Some fixes were made for enable usage with the Orchid Tor library. Further support for Tor is planned for future releases.
Notable bug fixes
Some hard-forking full verification bugs were fixed.
Thanks to Miron, PeerGroup now performs exponential backoff for peer connections, for instance if we cannot connect to them or if they disconnect us. This resolves an annoying bug in which if the library was configured with a single peer that was down, it would spin in a tight loop consuming battery.
API changes
Some functionality of the Wallet class was moved into separate classes under the wallet package.
The micropayments API and protocol changed. New clients/servers are not compatible with apps running against previous releases.
The Wallet sendCoins/completeTx methods no longer return booleans or null to indicate failure, they now throw InsufficientMoneyException or a subclass if the transaction cannot be completed. The exception object typically contains information on how much money is missing.
Some mis-named methods in the HD key derivation API were renamed.
The WalletEventListener interface has an extra method for watching scripts now.
Peer discovery classes moved under the net.discovery package
Any APIs that relied on Netty are now different.
New documentation
An article on the networking API
Info on testing your apps, and how to use regtest mode to make a private Bitcoin network that allows you to mine blocks instantly.
A reference table showing which API's implement which Bitcoin Improvement Proposals (BIPs).
Please note that as I am no longer employed by Google, after 0.11 signing the Google contributor license agreement will no longer be necessary. I look forward to welcoming contributions from Andreas Schildbach now this requirement has gone away. Also, in future I plan to re-namespace the library from com.google.bitcoin to org.bitcoinj - auto-migration scripts will be provided when this is done.

@_date: 2014-02-04 14:13:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.11 released, with p2sh, 
Hah, good point. If nobody completes the homework, I'll post a fixed
version tomorrow :)

@_date: 2014-02-07 11:48:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.11 released, with p2sh, 
Here?s a new release announcement with full ID?s this time:
The v0.11 tag is signed by Andreas Schildbach?s GPG key (fingerprint E944 AE66 7CF9 60B1 004B C32F CA66 2BE1 8B87 7A60). The commit hash is 410d4547a7dd20745f637313ed54d04d08d28687.
Key: 16vSNFP5Acsa6RBbjEA7QYCCRDRGXRFH4m
Signature: IFXzt4ZdWFEpLrAXRDnQS6ZKJYGmyHDHtyAgeg/2/EaTvg41jSsUQW8rq19evT2UNp+eP0+OWgWM7iDKrTv11DY=
It?s worth noting that this problem crops up in other contexts too. For instance, it?s very common for people to identify PGP keys by a short identifier.
As it happens I do have a PGP key, fingerprint C85A AB0F 7A1C CCA3 2BFC EECC F2E4 861C 9988 816F, and I just signed Andreas? key with it. However, as I?m not myself well connected in the web of trust, that doesn?t add a whole lot. But now that my key is effectively signed out of band by SwissSign so if people wanted to manually trace a trust path across systems, they could. I am skeptical anyone will :-)
Note that thanks to Gary Rowe, there is a Maven dependency checker plugin that verifies the (full) hashes of library dependencies. It could be better integrated but it provides another backstop.

@_date: 2014-02-11 17:24:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Extension for BIP-0070 to support 
Hey guys,
I'm on vacation now so won't be able to take a look until I'm back in a
couple of weeks but the approach sounds reasonable based on your

@_date: 2014-02-19 16:44:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 proposed changes 
Thanks for the feedback guys!
I would also like to understand the problems you've been having with
certificates in node.js. FYI the CA cert is *not* supposed to be included,
this matches what the code in Bitcoin Core and bitcoinj expects. It may be
that Bitcoin Core accepts a redundant CA cert being provided, but if so
that'd fall in the category of openssl being generous. If there are issues
here, it sounds like an issue with node and not the spec. I'm not even sure
why it would matter - certs are just byte arrays so if node can sign a hash
with a private key, the rest should be easy.
With regards to the PKI I'd appreciate it if we don't go around that circle
again. Please remember one of the primary goals of all of this is to show
to the user on their hardware wallet a meaningful name. Almost all
merchants on the Internet already went through the process of associating a
public key with their name, using X.509.
Whilst for now your payment requests will have to be signed as BitPay, this
isn't ideal for the longer term and I'd like to design a protocol extension
to allow merchants to delegate their signature authority to you. In this
way they would be able to sign a secondary key with their own ssl key as
part of the enrolment process, and after that you could sign payment
requests on their behalf. Kind of like a Bitcoin  specific subcert (and
there would be no reason to use X.509 format for that).
Re: feedback url. How is this different to a result code in PaymentAck
which already caused much debate? Surely we want a payment to either work
out boy work and for that decision to be made immediately? Your invoice
page switches to a completed state once you see a tx be broadcast so that's
the "done" state today even if there are caveats. I'd like to see a status
code added to PaymentAck so receivers can reject payments if they are bad
in some way.

@_date: 2014-02-20 14:08:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [RFC] [BIP proposal] Dealing with 
We've done forking changes before much faster than a year and that was with
less experience. If we want, we can get this done within months.

@_date: 2014-02-21 06:07:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [RFC] [BIP proposal] Dealing with 
No, I was thinking of the height in coinbase change. At any rate, p2sh was
supported by the consensus code in bitcoinj for a long time already, since
it was first written.
Support for sending to such addresses in the wallet appeared once an app
that wanted that support also appeared, which seems OK - the market for
wallets is very competitive so there will always be some skew in what
features are worked on in what order. V3 transactions are a consensus
change that wallets will pick up at different times like any other feature.

@_date: 2014-02-21 06:27:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin Core trial balloon: splitting 
Bear in mind a separate process doesn't buy you anything without a sandbox,
and those are expensive (in terms of complexity).

@_date: 2014-02-21 16:11:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin Core trial balloon: splitting 
I'm not sure it does really - typical C/C++ exploits let you run arbitrary
code, at which point you can quite easily ptrace the other process and do
whatever you want with it, or read /proc/pid/mem etc. But process
separation is certainly a prerequisite for sandboxing so I'm not arguing
against such a change, just pointing out that it requires some work to
really get the benefits. Also an SPV Bitcoin Core would obviously be of
tremendous utility all by itself ...

@_date: 2014-02-21 21:04:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 proposed changes 
BIP 73 seems OK except that existing wallets that can scan QR codes will
choke. One reason the new URIs are long is for backwards compatibility.
One thing that makes the URI smaller is not escaping the payment URL -
bitcoinj/Bitcoin Wallet at least does not require it, and it reduces the
size of the QR code by a non-trivial amount.
Removing the https:// and just defaulting to it also saves some bytes.
Finally, BitPay is using rather long invoice IDs. Do you really need an ID
like JkLdFhQVFqmUurXpPXZcRp? That's a really huge ID space and the invoices
expire fast. So you could potentially implement a short mapping on the
server side and make much smaller IDs that way.

@_date: 2014-02-25 18:25:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fee drop 
Given that the fee drop puts fees in "real" (i.e. dollar) terms back to
where they were some months ago, it seems odd to claim this is creating
vulnerabilities that didn't exist in the previous version. The cost of an
attack would be the same as before.

@_date: 2014-02-25 21:59:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Extension for BIP-0070 to support 
Hey there,
So the essence of this protocol is as follows:
enum PaymentFrequencyType {
        WEEKLY = 1;
        MONTHLY = 2;
        QUARTERLY = 3;
        ANNUAL = 4;
message RecurringPaymentDetails {
        // Namespace for the merchant such as org.foo.bar
        required string merchant_id = 1;
        // Id for the recurring subscription
        required bytes subscription_id = 2;
        // Contracts associated with a given subscription
        repeated RecurringPaymentContract contracts = 3;
message RecurringPaymentContract {
        // Unique id for a given contract
        required bytes contract_id = 1;
        // URL to poll to get the next PaymentRequest
        required string polling_url = 2;
        // Timestamp; when this contract starts
        required uint64 starts = 3;
        // Timestamp; when this contract should be considered invalid
        optional uint64 ends = 4;
        // Expected payment frequency
        optional PaymentFrequencyType payment_frequency_type = 5;
        // Max payment amount within that frequency (e.g. no more than
5 BTC per month)
        optional uint64 max_payment_per_period  = 6;
        // Max payment amount (e.g. no more than 3 BTC per payment)
        optional uint64 max_payment_amount = 7;
I have the following comments:
   1. There's no need to serialize RecurringPaymentDetails as bytes here.
   It's done that way outside of PaymentDetails in order to support digital
   signatures over protobufs that may have extensions the wallet app isn't
   aware of, but it's a pain and inside PaymentDetails (and therefore for most
   extensions) it shouldn't be necessary. So you can just use "optional
   RecurringPamentDetails recurring_payments = 8;"
   2. There's only 4 possibilities here for recurrences. That seems rather
   restrictive. Is the cost of being more expressive really so high? Why not
   allow more flexible specification of periods?
   3. If there's no payment_frequency_type field then what happens? A quirk
   of protobufs to be aware of is that making an enum field "required" can
   hurt backwards compatibility. Because it will be expressed using a
   languages underlying enum type, if there's a new enum member added later
   old software that attempts to deserialize this will throw exceptions
   because the new "unknown" member would be unrepresentable in the old model.
   Making the field optional avoids this problem (it will be treated as
   missing instead) but means software needs to be written to know what to do
   when it can't read the enum value / sees enum values from the future.
   4. I assume the amounts are specified in terms of satoshi, and
   timestamps are UNIX time, but better to make that explicit.
   5. Seems there's an implicit value constraint that max_payment_amount <=
   max_payment_per_period. What happens if that constraint is violated? Best
   to document that.
   6. What's the "merchant ID" namespace thing about? What's it for? What
   happens if I set my competitors merchant ID there?
   7. What's the "subscription ID"? Is this stuff not duplicative/redundant
   with the existing merchant_data field?
   8. In what situations would you have >1 contract per payment request?
   I'm not sure I understand why it's repeated. Presumably if there are zero
   contracts included the data should be ignored, or an error thrown and the
   entire payment request rejected? Which should it be?
   9. It's unclear to me given such a contract when the payment should
   actually occur. For instance if it's "monthly" then what day in the month
   would the payment occur?
   10. You'll notice I moved the comments to be above the field
   definitions. I know the current proto isn't done that way, but let's change
   it - long comments are good and putting them above the field definitions
   encourages people to write enough detail without being put off by line
   length constraints
I think the next step would be to talk to BitPay/get Jeff+Stephen involved
because I know they have customers that really want recurring payments, and
those guys will have a clearer idea of customer requirements than we do. I
feel uncomfortable with designing or reviewing in a vacuum without some
actual people who would use it chiming in, as I don't really know much
about the underlying business processes.
I have some other comments about the bitcoinj implementation specifically -
for instance, we don't have a "wallet directory" concept: everything goes
into the wallet file. So we'll need to think about how to structure the
code to allow that. Also, just using a background polling thread is likely
not flexible enough, as on some platforms you can't stay running all the
time (e.g. Android) without upsetting people, but the underlying OS can
wake you up at the right times, so wallet apps should have an ability to
control wakeup tasks. But we can discuss that over on the bitcoinj list
specifically. Let's keep this thread for the general protocol design.
BIP 70 is indeed implemented in Bitcoin Core on the C++ side, so that isn't
a concern. It could be done there too.

@_date: 2014-02-25 22:25:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fee drop 
There are two possibilities.
One is that the value of transactions with the new lower fee is outweighed
by increased orphan costs and miners refuse to include them en-masse.
Wallet authors lose the staring match and go back to setting higher fees
until such a time as block propagation is optimised and the orphan costs go
down. Nodes that are encountering memory pressure can increase their min
relay fee locally until their usage fits inside their resources. It's
annoying to do this by hand but by no means infeasible.
The other is that the total value of transactions even with the lower fee
is not outweighed by orphan costs. The value of a transaction is higher
than its simple monetary value - the fact that Bitcoin is useful, growing
and considered cheap also has a value which is impossible to calculate, but
we know it's there (because Bitcoin does not exist in a vacuum and has
competitors). In this case miners stop including lots of useful
transactions that represent desired economic activity and are put under
pressure by the community to change their policies. If all miners do this
and making small blocks is considered errant behaviour, then we're back to
the same situation we're in today.
The possibility you're worried about - that someone does a DoS attack by
flooding the network with small transactions - is only an issue in the
first situation, and it is by no means the easiest or cheapest way to DoS
Bitcoin. We all want to see more DoS resistance but basically any change to
Bitcoin can be objected to on anti-DoS grounds at the moment, and this will
remain the case until someone steps up to spend significant time on
resource scheduling and code audits.

@_date: 2014-02-26 16:00:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Extension for BIP-0070 to support 
Thanks for the explanation. I agree that makes sense, and you did actually
explain this before, I just didn't connect the dots :)
The accompanying BIP should explain all this, so the rationale for the
design and how you use it is made clear to developers.
I've CCd Jeff and Stephen on this thread, so they can go review it and
weigh in with any comments. They may want to go back to customers who
requested this feature and ask if it'd satisfy their needs.
On Wed, Feb 26, 2014 at 9:23 AM, Stephane Brossier

@_date: 2014-02-28 12:46:49
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 extension to allow for identity 
Now we're starting to see the first companies deploy BIP70, we're
encountering a need for identity delegation. This need was long foreseen by
the way: it's not in BIP70 because, well, we had to draw the line for v1
somewhere, and this is an issue that mostly affects payment processors. But
I figured I'd start a thread anyway because people keep asking me about it
Identity delegation means that a payment request can be signed by someone
who is not holding the certified private key. The most obvious use case for
this is payment processors like BitPay and Coinbase who currently have to
sign payment requests as themselves. Other use cases might involve
untrusted sales agents who want to be able to accept payment as their
employer, but cannot be trusted with a long-term valuable secret, e.g.
because they take their phone into areas with high crime rates.
The lack of this is ok for v1 but not great, because:
1) It requires the name of the *actual* recipient to be put in the memo
field, otherwise you don't have the nice receipt-like properties. The memo
field is just plain text though, it doesn't have any exploitable structure.
2) It gives a confusing UI, the user thinks they're paying e.g. Overstock
but their wallet UI tells them they're paying Coinbase
3) Whilst these payment processors currently verify merchants so the
security risk is low, in future a lighter-weight model or competing sites
that allow open signups would give a weak security situation:  a hacker who
compromised your computer could sign up for some popular payment processor
under a false identity (or no identity), and wait until you use your hacked
computer to make a payment to someone else using the same payment
processor. They could then do an identity swap of the real payment request
for one of their own, and your Trezor would still look the same. Avoiding
this is a major motivation for the entire system!
Also it just looks more professional if the name you see in the wallet UI
is correct.
*Proposed implementation*
We can fix this with a simple extension:
enum KeyType {
  SECP256K1 = 1
message ExtensionCert {
  required bytes signature = 1;
  required bytes public_key = 2;
  required KeyType key_type = 3;
  required uint32 expiry_time = 4;
  optional string memo = 5;
message X509Certificates {
  repeated bytes certificate = 1;
  repeated ExtensionCert extended_certs = 2;
message PaymentRequest {
  // new field
  optional bytes extended_signature = 6;
This allow us to define a so-called *extended certificate*, which is
conceptually the same as an X.509 certificate except simpler and Bitcoin
specific. To create one, you just format a ExtensionCert message with an
ECDSA public key from the payment processor (PP), set signature to an empty
array and then sign it using your SSL private key. Obviously the resulting
(most likely RSA) signature then goes into the signature field of the
ExtensionCert. The memo field could optionally indicate the purpose of this
cert, like "Delegation to BitPay" but I don't think it'd ever appear in the
UI, rather, it should be there for debugging purposes.
The new ExtensionCert can then be provided back to the PP who adds it to
the X509Certificates message. In the PaymentRequest, there are now
*two* signature
fields (this is for backwards compatibility). Because of how the mechanism
is designed they should not interfere with each other - old implementations
that don't understand the new extended_signature field will drop it during
reserialization to set signature to the empty array, and thus signature
should not cover that field. On the other hand, extended_signature would
cover signature. Thus, for full backwards compatibility, you would:
1) Sign the payment request using the PP's SSL cert, i.e. sign as
2) Then sign again using the PP's delegated ECDSA key, i.e. sign as the
The finished protobuf would show up in old clients as signed by
coinbase.comand by new clients as signed by
overstock.com even though Overstock did not provide their SSL key to
If you have *only* an ExtensionCert and not any X.509 cert of your own,
then you cannot of course make backwards compatible signatures in this way,
and in that case you would miss out the signature field and set the
pki_type to a new value:  "x509+sha256+excert". Old wallets would see that
they don't understand this pki_type and treat the request as unverified.
For maximum security the merchant may choose to set very short expiry times
(like, a day) and then have a cron job that uploads a new ExtensionCert at
the end of each expiry period. This means in the case of PP compromise, the
system reseals very fast.
*Alternatives considered*
We could always use a new pki_type and not bother with the two signature
fields. However, this means old wallets will show payment requests as
untrusted during the transition period. Some signing is still better than
none, security-wise.
We could attempt to fix the above by introducing a use of User-Agent field
to the case where a payment request is fetched via HTTP, so the server can
customise the PaymentRequest according to the capabilities of the client.
However, sometimes payment requests are not fetched via HTTP, for example,
they may be attached to an email, sent via an IM network or sent over a
Bluetooth socket. Nonetheless this may be a useful thing to consider for
future cases where the protocol may not be extended in a backwards
compatible manner.
We could create the extension cert as an X.509 cert, rather than a custom
type. However most CA's set path length constraints on their intermediate
certs that forbid this kind of extension (I forgot why, possibly some kind
of anti-DoS mitigation). Also re-using X.509 for the extension cert would
open up the risk of it being accepted by a bogus SSL stack that didn't
check the key usage constraints extension, and that would allow for SSL
delegation as well. It seems safer to just use a different format that
definitely won't be accepted.
Feedback welcome.

@_date: 2014-01-01 15:10:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Dedicated server for bitcoin.org, 
That seems overly complicated, there's no need for the Bitcoin protocol to
be involved. Deterministic builds with threshold signed updates are a
problem the entire crypto community is now interested in solving - any
solution should be generic.
Really all you need is an update engine that allows a CHECKMULTISIG type
approach. When the update engine is not under our control, i.e. on Android,
Shoup style RSA threshold signatures can potentially work (though I must
admit, I have never found time to play with the implementation I have for
that algorithm).

@_date: 2014-01-01 18:33:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Happy new year! 
Bitcoin had an incredible year in 2013, and I very much enjoyed working
with and meeting you all.
I'm very much looking forward to some of the upgrades coming in 2014.
Though a lot happened in the general community, last year was kind of quiet
with respect to the core software. I'm hoping this year we can pick up the
pace a little.

@_date: 2014-01-01 22:15:01
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Dedicated server for bitcoin.org, 
I would be very interested to learn more about this. It seems the steady
state load on the site is not very high:
(Saivann ran Google Analytics on the site for a little while to get traffic
figures). Peak of 10 visitors per second, assume a 10x blowup on resources,
that's only ~100 reqs/sec steady state, that shouldn't strain any kind of
reasonable server. So perhaps the specs of the dedicated server were not
what you might imagine.
Perhaps we should move the site over to Jeremy's hosting? It shouldn't be
very expensive to serve outside of major press cycles. Once that is done,
perhaps we can find/blag some SSL-protected file hosting.

@_date: 2014-01-12 13:51:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Stealth Addresses 
You can always just extend the payment protocol with the new fields as
well, vs making very long addresses. If this technique can be made to work
well, it would have applicability in both fixed textual address context,
and for a fixed/upload-once payment protocol file. That has the advantage
of backwards compatibility as well - the new addresses would not be
clickable or acceptable by old wallets, but with the payment protocol you
can always craft a bitcoin URI that contains a regular current style
address, and a link to a fixed payment protocol file (uploaded to a
pastebin type site), and modern wallets would ignore the address and use
the ECDH based system instead.

@_date: 2014-01-12 19:26:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Stealth Addresses 
Why? Showing an address is meaningless, especially if the user didn't type
it in or see it somewhere else. It's just an opaque random number, all
putting it in the UI can do is make it look scarier :)
Part of the point of the payment protocol is it lets merchants provide
human readable text for transactions instead of addresses.

@_date: 2014-01-13 11:39:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Stealth Addresses 
I was thinking that people could upload a payment protocol file somewhere
once (like to their personal web page, or shared via dropbox or google
drive or some custom new pastebin style service), and then just encode a
regular bitcoin URI into the qrcode on the billboard.
Likewise, I could attach a payment request to an email and send it to you,
and now you can pay me whenever you want forever.
Getting a little static piece of data to someone *once* should be something
we can make easy. Constantly refreshing it, on the other hand ...

@_date: 2014-01-13 12:18:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Stealth Payments - Sample Code / Proof of 
... but can you redeem it?
That's rather interesting code. Is this using a private C# bitcoin
Yes, of course. The transaction list should just say something like
    "Payment received from Jeremy,  0.1 BTC"
Maybe the simple way to punt on this is to just show 'Merchant' in the
I am surprised it's not already the case! Though "merchant" is perhaps a
bit biased as a name, internally it perhaps should just be called
"Recipient". There's no requirement for you to be a merchant to create
payment protocol requests.
The wallet format would need extending.
I'd feel a lot more comfortable if the protocol was reviewed by a
professional cryptographer though. I think think Gregory already brought up
an issue to do with people able to detect such payments by testing if
decrypted values are points on the curve, or something like that.

@_date: 2014-01-13 16:58:01
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Stealth Addresses 
You have to trust the billboard owner too. If you're relying on a third
party to relay a payment instruction, that will always be an issue, hence
the signing.
Signing a payment request for an individual is easy, anyway, depending on
the kind of ID you want. If you want to sign with an email address, just go
here with a browser like Chrome/Safari/IE that uses the system keystore:
   They'll send you an email, you click the link to verify, and a cert will be
generated and installed by your web browser. It's actually easier than
signing up for a website. There are lots of other places that do it for
free too, I just picked the first one from a google search for [free email
Once you've got that in your keystore, a wallet app can quite easily be
told to sign payment requests with your email address.
For a billboard I guess you'd probably be an organisation or company
instead, though an email address can work there too as long as you have a
well known domain name.

@_date: 2014-01-13 20:57:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Stealth Addresses 
Yes indeed ...... which is why we're talking about extending the protocol
(in a future version! the first version isn't even out yet!).

@_date: 2014-01-14 11:45:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment protocol and reliable Payment 
Usually if the merchant has not delivered, then at that point it's not a
problem and he is allowed to change his mind. It's only if they change
their mind *after* you pay that it's a problem, right?

@_date: 2014-01-15 23:51:21
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Tor / SPV 
intro text starts here, protocol upgrade proposal starts further down
Recently on IRC we have discussed what it'd take to use SSL on P2P connections, the goal being encryption and authentication of traffic to help avoid passive wiretapping and sybil attacks.
Gregory pointed out - very reasonably - that OpenSSL is huge and very old-school C, meaning that using it to implement SSL would put a big piece of code exposed to the internet into the same process as people?s wallets. This would be not excellent. Also, even with encryption, with SSL you only get some resistance to traffic analysis. And it'd be a complicated upgrade.
Tor is an option, but it has other disadvantages:
1) Also a giant piece of C that is likely to contain bugs
2) Breaks our anti-sybil heuristics when connecting to hidden services
3) MITM very likely when not connecting to hidden services
4) Is not usable as a library at all. Convention to use Tor is "tell user to start TorBrowser and connect to the SOCKS port".
The latter point means in reality hardly anyone will ever connect via Tor, as you'd have to do extra setup and most people are lazy. Especially it's not going to work on mobile. It?s not worth doing something complicated if hardly anyone would use it.
But recently I discovered this interesting piece of code:
   It is a pure Java implementation of the Tor protocol (client only, no relays), easily usable as a library. Sure enough after about an hour of fiddling around, I now have a bitcoinj that connects via Tor with no other software running.
Suddenly making MultiBit, the Android Bitcoin Wallet app, Hive and other bitcoinj based wallets use Tor by default seems very plausible.
So I started thinking about what it'd take to switch this on for everyone. The biggest problem is that SPV wallets can't verify unconfirmed/pending transactions for themselves, so they rely on counting the number of peers that announced it and assuming that their internet connections aren't being tampered with. Mostly this assumption is a good one - we have never heard anyone report that they were paid with a fake pending tx using a MITM attack.
However, with Tor the chance of being MITMd goes up dramatically. Lots of people have reported exit nodes that are doing SSL stripping. Being sybilled when using exit nodes seems rather likely.
Connecting to hidden services solve the MITM problem but screws you in a different way. Bitcoin Core has some weak heuristics in the code to try and ensure we don?t accidentally connect to nodes all controlled by the same guys ? mostly by trying to keep a good mix of /16s. This is probably not very hard to defeat, but it does at least raise the bar beyond ?buy lots of amazon VMs?. With hidden services we lose that. Also, there aren?t very many nodes running as hidden services - if all bitcoinjs started hitting them simultaneously they?d probably die.
tl;dr the proposal starts here
Let?s fix this so SPV wallets can use Tor by default. Downgrading things is not an option, it must be pure upgrade. We can do it like this:
1) Firstly, we observe that MITM only matters when we?re trying to count pending transaction announcements, but most of the load SPV wallets impose on the network is chain filtering. So it?s OK to download the chain from any arbitrary clearnet IP via Tor because we?re checking Merkle branches.  This ensures we won?t put excessive load on hidden service nodes.
2) Secondly, we bump the protocol version, add a service flag and introduce a new P2P protocol command ?tor??. If a client sends a tor? message to a node that has the new service flag set, it will respond with a new ?tor? message that contains a regular addr packet, with a single address, the IPv6-ified version of its hidden service name.
3) SPV wallets that want to get a good mix of nodes for measuring pending transactions identify nodes on the clearnet via their addr announcements+service flag, in the normal way. They select some of these nodes using the standard clearnet anti-sybil heuristics and connect without using Tor. They proceed to query them for their hidden service key. After they?ve done that, they record the public IP->hidden service mapping and can go ahead and connect back to them at any later time via Tor itself.
This would seem to be pointless - did we not just go ahead and bypass Tor entirely, thus making neither node hidden? Is it not a dead cert that the next connection the node gets via Tor is likely the same computer? Yes, but it only matters the first time. As long as those nodes are somewhat stable the mapping will be recorded on disk and the next time the wallet starts, it?ll skip straight to using Tor.
The goal of all that is that we get to keep our existing IPv4 based anti-sybil heuristics, so we can?t possibly make anything worse, only better. Plus, we?ve now set things up so in future if/when we come up with a better anti-sybil system based on anonymous identities or other fancy crypto, we can take out the ?connect via clearnet? step and go straight to using hidden services with only a very small set of code changes and no new protocol work.
I like this idea for several reasons:
It feels implementable to me in about a couple of weeks wall-time. The tasks are small - the new tor? p2p message is super easy to implement because a node already knows if it?s a hidden service or not. On the bitcoinj side, it?d take a bit of work to implement the extra storage of IPv4->onion mappings and ensure the right kind of connection is used at the right time, but it?s not all that hard.
We could switch Tor on by default for a lot of users.
On the bitcoind side, Tor runs as a separate process and because it initiates connections to bitcoind, it can be easily sandboxed, e.g. ran as a different UNIX user or even run inside a chroot/ptrace jail. Even though Tor is likely to contain exploits, we can easily keep them away from the wallet. So there?s not much additional surface area.
Obviously as it?s pure Java and client only, Orchid is immune to buffer overflows/double frees and other such security problems.
It?s optional for all parties. Wallet clients can try to fall back to non-Tor usage if their access to Tor seems to be blocked somehow.
Tor is the gold standard for resisting traffic analysis - we know thanks to Snowden that it?s good at this task.
To launch I?d probably have a percentage throttle hosted on some SSLd website, so we can control the load placed on the existing hidden service nodes.
Feedback welcome.

@_date: 2014-01-16 00:01:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Stealth Addresses 
Do any people who aren't computer programmers or physicists ever use the
term "static"?
I liked routing address.

@_date: 2014-01-16 00:32:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Tor / SPV 
sipa already implemented some clever hack where the 80-bit Tor keys are
mapped to a subregion of reserved IPv6 space, giving magical IPv6 hidden
service addresses. So addr packets can and do already contain onion
Hmm. So you mean that we pick a set of peers we believe to not be sybils of
each other, but they might give us hidden services run by other people? I
need to think about that. If they're getting the hidden services just from
addr announcements themselves, then you just punt the issue up a layer -
what stops me generating 10000 hidden service keys that all map to my same
malicious node, announcing them, and then waiting for the traffic to
arrive? If clearnet nodes inform of their own hidden service IDs, that
issue is avoided.
My goal here is not necessarily to hide P2P nodes - we still need lots of
clearnet P2P nodes for the forseeable future no matter what. Rather we're
just using hidden services as a way to get authentication and encryption.
Actually the 6-hop hidden service circuits are overkill for this
application, a 3-hop circuit would work just as well for most nodes that
aren't Tor-exclusive.

@_date: 2014-01-16 11:19:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Stealth Addresses 
I think we have a winner in "reusable address". Yes an existing address can
be reused and will superficially appear to work, it just won't work well.
Calling them reusable addresses helps reinforce the idea in peoples mind
that the other kind shouldn't be reused.

@_date: 2014-01-16 11:25:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Tor / SPV 
Yes correct, using hidden services just as a kind of more complicated, out
of process/sandboxable SSL.
If all nodes talked to each other all the time over Tor, probably yes
because Bitcoin is quite sensitive to latency. But what I'm proposing here
is less ambitious. It's just about protecting (parts of)
end-user-to-network communication, which is a much less risky sort of
change. P2P nodes would still talk to each other in the clear.
SSL for everything is still an idea I like, but it's true that increasing
bitcoind attack surface area is not something to take lightly.
Considering that the clearnet sybil protection also relies on scaling
I'm sure we can come up with all kinds of neat anti-sybil techniques, but
IMHO they are separate projects. I'm trying to find an upgrade that's small
enough to be easily switched on by default for lots of users, today, that
is low risk for the network overall. Later on we can add elaborations.
The SPV node could connect to the IP using Tor.  It would preserve the
Right so the key question is, to what extent does Tor open you up to MITM
attacks?  I don't have a good feel for this. I read about exit nodes
routinely doing very naughty things, but I don't know how widespread that
is. Probably you're right that with random selection of exits you're not
excessively likely to get MITMd.
How does Tor itself manage anti-sybil? I know they have the directory
consensus and they measure nodes to ensure they're delivering the resources
they claim to have. Punting anti-sybil up to the Tor people and letting
them worry about it is quite an attractive idea.

@_date: 2014-01-17 10:15:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Stealth Addresses 
I must say, this shed is mighty fine looking. It'd be a great place to
store our bikes. But, what colour should we paint it?
How about we split the difference and go with "privacy address"? As Peter
notes, that's what people actually like and want. The problem with stealth
is it's got strong connotations with American military hardware and perhaps
thieves sneaking around in the night:
   But everyone loves privacy.

@_date: 2014-01-20 19:55:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP0039: Final call 
We have an implementation of the latest spec in bitcoinj, with the wordlist
provided by slush+stick. As far as I can see it's all working fine so LGTM
from us.

@_date: 2014-01-21 10:11:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP0039: Final call 
We should just perform Unicode canonicalization before any text hits the
crypto code.  There are algorithms that automatically resolve such issues.
Although with an English wordlist it would seem to make no difference

@_date: 2014-01-24 12:26:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bait for reusable addresses 
That's not fundamental though, it just reflects that the only
implementation of this is used on a wide range of devices and doesn't yet
have any notion of bandwidth modes or monitoring. It can and will be
resolved at some point.

@_date: 2014-01-25 00:15:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bait for reusable addresses 
I've thought about [ab]using Tor as a STUN replacement before, but the
issue is a lot of people don't have computers that are switched on all the
time anymore except for their smartphones, which are too weak to calculate
the UTXO set. The trend has been for a while towards laptops, phones and
tablets, all of which are relatively weak.
I think there might be a market for a one-click "bring up an amazon VPS,
sync a full node and make it accessible only to me" type service though!

@_date: 2014-01-26 22:24:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70/71 issue, RFD 
Which medium is this an issue for? As you note, for files and HTTP
responses it's not a problem in practice. i'd guess nor for NFC tags nor QR
On Sun, Jan 26, 2014 at 10:11 PM, Andreas Schildbach

@_date: 2014-01-26 23:00:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70/71 issue, RFD 
I think for "binding" the payment protocol to those transports we should
indeed use protobuf varint length prefixes. But it's unnecessary for all
cases. Unless Gavin feels it'd be better to be consistent everywhere and is
willing to change the spec and code - as far as I know though we're trying
to ship 0.9rc1 soonish .....
On Sun, Jan 26, 2014 at 10:32 PM, Andreas Schildbach

@_date: 2014-01-27 00:01:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70/71 issue, RFD 
To be more accurate, the embedded messages already have length prefixes :-)
On Sun, Jan 26, 2014 at 11:14 PM, Andreas Schildbach

@_date: 2014-01-27 14:11:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Thanks Andreas, that's really interesting work. Comments below.
On Mon, Jan 27, 2014 at 12:59 PM, Andreas Schildbach
I would like to see Bluetooth continue to work for scan-to-pay even in the
signed case. So for this reason the current approach with a BTMAC parameter
in the Bitcoin URI seems to work universally across NFC tags and QR codes,
and would allow download of a signed PaymentRequest even in the case where
a QR code is used.
Because a Bitcoin URI already contains a public key (hash), re-using that
to establish an encrypted/authd connection on top of an insecure RFCOMM
socket would seem to be relatively straightforward.
Just a correction here - the reason signed payment requests are "large"
(about 4000 bytes) is exactly because they *can* be verified offline, i.e.
by a Trezor. The signed payment request contains all the data needed to
establish its authenticity, including certificates and the signature
itself. No TCP connection is needed.
For face to face payments, I think signing is still useful. For one, we
want to keep the distinction between "merchant" and "user" as blurry and
indistinct as possible. A strong separation between merchants and consumers
is one of the many bad things about the credit card system. Whilst
initially we'd expect the payment protocol to be used by online webshops,
in future it could be used by little corner shops, children's lemonade
stands and so on. You don't want to exclude entire classes of transactions
from being secure with Trezor type devices, and besides, even without a
Trezor you probably still would like a receipt if you buy something from a
local market trader.
Another use case - we heard a story about a restaurant owner who accepted
Bitcoin. He printed a static bitcoin URI onto a QR code on the menu. A
month or two later he discovered one of his waiters had re-printed the
menus with his own QR code! The people thought they had been paying for the
meal, and in fact it went right into the pocket of the waiter.
As to how it works, well, that's not hard. Comodo give away free email
address certs with a few mouse clicks, it's no harder than signing up for a
website. Then you can just open that cert file on your phone to install it
and it should become usable automatically with a future version of
bitcoinj. Email address doesn't prove a whole lot, of course, but it's
better than nothing. If the restaurant owner had even just a hotmail
address, he could have stuck it up behind the bar or painted it on the
outside of his shop and some customer would have got suspicious when he
didn't see the address (assuming we're successful at deploying it of
Other wallets won't know what to do with it and would yield a strange error
URL length is limited on some versions of internet explorer (probably on
all browsers). Rather than pack a file into a URL, if you don't want to use
the current r= extension it's better for apps to just register to handle
.bitcoinpaymentrequest files / the right MIME type. Downloading it and
opening it would do the right thing automatically.
Remember BIP 73 also! It says that with the apps built-in QR scanner, if
you scan an HTTP[S] URI, you should try downloading it with a magic header.
That way you can get a payment request file out of the server. Without the
magic header (i.e.  a normal generic barcode scanner app) it would open a
web page containing a bitcoin URI clickable link.

@_date: 2014-01-27 16:52:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: PaymentACK semantics 
At the moment there's no way to distinguish between a failed / rejected
submission and a successful one beyond the freeform memo field, right? It'd
be good if we had an error code field as well, perhaps for a future version.

@_date: 2014-01-27 19:34:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
As I said, the test requests generated by Gavin's generator end up being
about 4kb.
Unfortunately most certs are using RSA keys which aren't very compact. You
can get ECC certs, but for whatever reason, the test requests aren't using
There's still an address in the URI for backwards compatibility, right? In
theory if everyone some day uses wallets that support BIP70 it'd be
superfluous and could be removed, but whilst it's there, we could find
alternative uses for it ...
Trust store is just a local database. Why would it involve TCP?
Maybe in Berlin :-) Most of my transactions are sadly with online shops,
A receipt is a proof of purchase. If the payment request isn't signed then
it proves nothing as you could have made it yourself. Of course paper
receipts are forgeable too - we sort of pretend receipt
frauddoes not exist, but it
Nobody would ever be forced to sign to receive money, obviously, but it's
better if people do as it leads to herd immunity. If people expect to see
it then they will be suspicious if an attacker strips the signing data. If
it's randomly hit/miss then the signing data can just be deleted by a MITM
and you'd never think anything was amiss.
And again, how is he going to provide the payment request to the payer
Over Bluetooth, perhaps. That's what we're talking about, right?
It was proposed by the BitPay guys. I think they feel that scanning a QR
code should always make something intelligent happen, even if you don't
(for instance) have a wallet app installed at all. Overloading the URL so
it works for both web browsers and wallet apps is easy, so I can see why
they suggested it. Doesn't seem like a big deal either way.

@_date: 2014-01-27 22:47:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Experiment with linking payment requests 
That's the expected behaviour, right? That's why I said "download and
open". The Bitcoin URI with r= is better because it lets you remove that
second click, but in some contexts the file approach is the right way to go
- like for an email attachment or payment request sent via WhatsApp.

@_date: 2014-01-28 07:34:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Extension for BIP-0070 to support 
I think the right approach for this is to actually implement it and
*then* propose
a BIP. There are so many possible features we could add to the payment
protocol, any other approach would rapidly turn into lots of people
deciding to do the "fun bits" and often leaving others doing the hard work
with difficult or unworkable specs.
For instance, if you try to implement this, you would rapidly discover that
it probably makes more sense to do this as an additional set of fields in
PaymentDetails rather than a new message type entirely. A new top level
message type would in turn require new MIME types, URI extensions and so
on. That doesn't make any sense.
Once you decide to extend PaymentDetails, the next discovery would be that
it probably makes sense to try and solve the problem of address re-use for
recurring payments first, before speccing out time intervals and so on.
That's a separate BIP.
I'm all for adding recurring payments as a feature, that's what the
protocol is there for. But I'd like to see future protocol extension
requests come after at least one working implementation has been made .....
On Tue, Jan 28, 2014 at 3:36 AM, Stephane Brossier

@_date: 2014-01-28 12:42:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: PaymentACK semantics 
Yeah, that's the interpretation I think we should go with for now. There
was a reason why this isn't specified and I forgot what it was - some
inability to come to agreement on when to broadcast vs when to submit via
HTTP, I think.

@_date: 2014-01-28 14:24:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: PaymentACK semantics 
I guess a lot of wallets just won't broadcast at all and try to submit via
the URL. If they don't succeed, then the transaction is just never
committed to the wallet. Doesn't seem like a big deal. Payment submission
is online, interactive. If it fails, you keep the coins. This seems simple
and straightforward.
If someone really wanted to do a real-time coinjoin, they can build the
transaction together and submit it via payment_url, and broadcast as well.
If the merchant has an issue with the payment for some reason (e.g. request
is expired or the tx is non-standard), well, you'll have to sort it out
with them manually.

@_date: 2014-01-28 18:33:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: PaymentACK semantics 
In practice this should only be an issue if a payment is submitted and
fails, which should be rare. Barring internal server errors and screwups on
the merchants side, the only reasons for a rejection at submit time would
be the imperfect fungibility of bitcoins, e.g. you try and pay with a huge
dust tx or one that's invalid/too low fee/etc.
So I think we have a bit of time to figure this out. But yes - once you
broadcast, you probably accept that there might be a more painful path to
resolve issues if something goes wrong, I guess. Right now BitPay has a
support system where you can file a ticket if you pay the bitcoins and they
don't recognise it or the tx never confirms or whatever. It's grotty manual
work but they do it. Not broadcasting unless you "have" to seems like an
optimisation that can reduce pain without much additional complexity.

@_date: 2014-01-30 11:49:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 message delivery reliability 
Hi Chuck,
Both Bitcoin Core and bitcoinj are about to ship with the protocol as-is,
so any changes from this point on have to be backwards compatible.
That's all you need to prove payment, yes.
That's right (+memo). And to provide an additional hook for future
features, like recurring billing, ECDH key agreements etc.
Refund addresses as specced currently are optional. For instance bitcoinj
currently doesn't use them and won't until HD wallets support is done.
Let's get some practical experience with what we've got so far. We can
evolve PaymentRequest/Payment/PaymentACK in the right direction with
backwards compatible upgrades, I am hoping.

@_date: 2014-01-30 11:50:22
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Although it should be noted that these binaries don't yet do URI support so
you can't scan a bitcoin URI with r= in it and see the verified merchant
name, etc. I think Andreas plans to do the UI for that in the next update.
On Thu, Jan 30, 2014 at 11:46 AM, Andreas Schildbach

@_date: 2014-01-30 12:31:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 message delivery reliability 
The arbitrator would presumably have some rules about what is or isn't an
acceptable form of payment.
HTTP has response codes for submission of the Payment message. We could add
signing to PaymentACK and other things in future, if that turns out to be
insufficient in practice.

@_date: 2014-01-30 12:59:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 message delivery reliability 
With the way it works in bitcoinj, the tx is only committed to the wallet
if the server accepts the Payment message and ACKs it. So the tx would not
be retried if there's a failure submitting or some kind of internal server
error, and the UI would show that the payment failed. That seems
straightforward and how I'd expect things to work as a user.

@_date: 2014-01-30 13:38:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 message delivery reliability 
No retries. If there's a timeout the wallet will consider the payment not
made, and if the merchant broadcasts anyway, the wallet will see the
transactions and sync with them correctly. The ACK is not particularly
important in the current design, so that's no big deal.
If we see this situation crop up routinely we can take measures to improve
things. I doubt we will.

@_date: 2014-01-30 16:01:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: PaymentACK semantics 
As per Gavin at the top of the thread, the intent is to give the customer
reassurance that their payment will be processed. The merchant trying to
get the tx confirmed is presumably a part of that as it'd make no sense for
a merchant to give that assurance and decide they don't care about the
But nothing stops the user broadcasting the tx as well, once the receiver
has given that assurance.

@_date: 2014-01-31 19:13:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Extension for BIP-0070 to support 
============================== START ==============================
That looks OK at a very high level. Things you probably want to think about:
   - How to trigger it off the existing payment protocol (no new top level
   messages or mime types or uri extensions please)
   - Data structures to define the payment schedule
   - Do you allow pre-submission of time locked transactions or not?
I think as you prototype these things will become clearer.  You could try
prototyping either in Bitcoin Core (C++) or bitcoinj (java, look at the
PaymentSession class).
On Wed, Jan 29, 2014 at 3:47 AM, Stephane Brossier

@_date: 2014-07-01 10:18:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
So the idea here is that the recipient wallet both uploads to the internet
and exposes the payment request over Bluetooth simultaneously, then let's
the sending wallet pick whatever radio layer works best in its current
I think having multiple r= params is reasonable, but the Bluetooth support
is not specced in any BIP anyway. And if it were to be, people would point
out the lack of link-layer encryption.
So this is a bit tricky, overall. Right now I'd say things are kinda half
baked: not only is bluetooth not standardised nor encrypted (my fault, I
prototyped this code during a hackathon), but Bitcoin Wallet doesn't
properly implement BIP 72 either. To push this work forward I think we need
to sit down and do some more spec and implementation work :/

@_date: 2014-07-01 19:59:45
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Nope, r1/r2 sounds good to me. BTW we should update the spec to reflect
that escaping is largely unnecessary in many cases.

@_date: 2014-07-04 17:20:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] ASIC-proof mining 
Yup, no need to apologise. If nothing else the conversations get archived
where other people can use them to get up to speed faster. A lot of these
discussions get spread across forums, lists and IRC so it can be hard to
know what the current state of the art thinking is.
Recall the second prong of my opening argument - if you could beat ASICs,
you'd end up with botnets. I prefer having the chain be dominated by a
single pool for a while than having one with a major botnet presence, given
their history of doing things like mining empty blocks and giving random
people enormous electricity bills.
I think we can make good head way if we just optimise a lot and finish
things off, to be honest. I'm not sure we need an algorithmic silver
bullet. Remember you can always outsource mining by just not having any
hardware at all, CEX style, so trying to prevent outsourcing using clever
hacks seems ultimately doomed.

@_date: 2014-07-05 10:43:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] ASIC-proof mining 
There's really no concept of a "runner up" because hashing is progress
free. It's unintuitive and often trips people up. There's no concept that
everyone is 95% of the way to finding a solution and then someone pips you
to the post. It's more like playing the lottery over and over again.
Doesn't matter how many times you did it before, the next time your chances
are the same.
A better concept is of rewarding "near miss" solutions which is what we
already do of course, via pools, which pay you for shares which don't quite
meet the difficulty target but almost do. So the question is how can we
implement pools which have this reward structure (which obviously works
well) without miners simultaneously giving up their right to block creation
either due to technical problems or sheer lazyness.

@_date: 2014-07-09 13:57:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin Protocol Specification 
On Tue, Jul 8, 2014 at 10:04 PM, Matt Whitlock There's a high level guide here:
It's not a protocol specification however, more a lay-of-the-land type
description. The protocol is not very complicated however. The wiki page
describes it adequately. It's basically just a framing mechanism with
excessively aggressive checksumming, a version handshake, an inventory
mechanism to cut down on bandwidth usage, the alerts, and that's about it.

@_date: 2014-07-10 16:29:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for geutxos message 
I opened up a pull req for a draft BIP for getutxo.
   I include a rendering below for your reading convenience. If you'd like to
comment on design/security/etc then please first familiarise yourself with
the long discussions that were already had here:
     BIP: 45
  Title: getutxo message
  Author: Mike Hearn   Status: Draft
  Type: Standards Track
  Created: 2014-06-10
Table of Contents
   - Abstract
      - Motivation
      - Specification
      - Backward compatibility
      - Authentication
      - Implementation
This document describes a small P2P protocol extension that performs UTXO
lookups given a set of outpoints.
All full Bitcoin nodes maintain a database called the unspent transaction
output set. This set is how double spending is checked for: to be valid a
transaction must identify unspent outputs in this set using an identifier
called an "outpoint", which is merely the hash of the output's containing
transaction plus an index.
The ability to query this can sometimes be useful for a lightweight/SPV
client which does not have the full UTXO set at hand. For example, it can
be useful in applications implementing assurance contracts to do a quick
check when a new pledge becomes visible to test whether that pledge was
already revoked via a double spend. Although this message is not strictly
necessary because e.g. such an app could be implemented by fully
downloading and storing the block chain, it is useful for obtaining
acceptable performance and resolving various UI cases.
Another example of when this data can be useful is for performing floating
fee calculations in an SPV wallet. This use case requires some other
changes to the Bitcoin protocol however, so we will not dwell on it here.
Two new messages are defined. The "getutxos" message has the following
Field SizeDescriptionData typeComments1check mempoolboolWhether to apply
mempool transactions during the calculation, thus exposing their UTXOs and
removing outputs that they spend.?outpointsvectorThe list of outpoints to
be queried. Each outpoint is serialized in the same way it is in a tx
The response message "utxos" has the following structure:
Field SizeDescriptionData typeComments4chain heightuint32The height of the
chain at the moment the result was calculated.32chain tip hashuint256Block
hash of the top of the chain at the moment the result was calculated.?hit
bitmapbyte[]An array of bytes encoding one bit for each outpoint queried.
Each bit indicates whether the queried outpoint was found in the UTXO set
or not.?result utxosresult[]A list of result objects (defined below), one
for each outpoint that is unspent (i.e. has a bit set in the bitmap).
The result object is defined as:
Field SizeDescriptionData typeComments4tx versionuint32The version number
of the transaction the UTXO was found in.4heightuint256The height of the
block containing the defining transaction, or 0x7FFFFFFF if the tx is in
the mempool.?outputCTxOutThe output itself, serialized in the same way as
in a tx message.
Nodes indicate support by advertising a protocol version above 70003 and by
setting a new NODE_GETUTXO flag in their nServices field, which has a value
of 2 (1
The UTXO set is not currently authenticated by anything. There are
proposals to resolve this by introducing a new consensus rule that commits
to a root hash of the UTXO set in blocks, however this feature is not
presently available in the Bitcoin protocol. Once it is, the utxos message
could be upgraded to include Merkle branches showing inclusion of the UTXOs
in the committed sets.
If the requesting client is looking up outputs for a signed transaction
that they have locally, the client can partly verify the returned output by
running the input scripts with it. Currently this verifies only that the
script is correct. A future version of the Bitcoin protocol is likely to
also allow the value to be checked in this way. It does not show that the
output is really unspent or was ever actually created in the block chain
If the requesting client has a mapping of chain heights to block hashes in
the best chain e.g. obtained via getheaders, then they can obtain a proof
that the output did at one point exist by requesting the block and
searching for the output within it. When combined with Bloom filtering this
can be reasonably efficient.
Note that even when the outputs are being checked against something this
protocol has the same security model as Bloom filtering: a remote node can
lie through omission by claiming the requested UTXO does not exist / was
already spent (they are the same, from the perspective of a full node).
Querying multiple nodes and combining their answers can be a partial
solution to this, although as nothing authenticates the Bitcoin P2P network
a man in the middle could still yield incorrect results.

@_date: 2014-07-10 16:44:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for geutxos message 
I took the number out, it is now just "the getutxo bip" until a number is

@_date: 2014-07-14 13:18:22
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Self-dependency transaction question... 
Conceptually all transactions in the block chain lie on a single timeline.
The fact that we quantise that timeline into blocks is in many ways neither
here nor there - it's still a strict line.
What *can* happen and you must be aware of is duplicated transactions.
Satoshi sort of assumed this could never happen because everything is hash
based, but forgot that duplicating coinbases is possible and at one point
this did happen. It was banned by a rule change afterwards but you still
must be able to process the older parts of the chain that have this. There
is a BIP that covers the new rule.

@_date: 2014-07-14 13:26:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin Protocol Specification 
Nice work, but please don't call it the "Bitcoin protocol spec". Your
document is not a spec. It is an attempt to describe in English the Bitcoin
protocol, but anyone who implemented it based on your description would get
it wrong. For example you didn't mention the SIGHASH_SINGLE bug and many
other important areas like the difficulty transitions are also left
As a loose description of the protocol for newbies it's an invaluable
resource and perhaps we should link to it from the developer guide. As
something that claims to be a specification it is quite possibly dangerous
- the only spec that matters is the C++ original.
On Mon, Jul 14, 2014 at 11:54 AM, Krzysztof Okupski <

@_date: 2014-07-14 13:49:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin Protocol Specification 
Ah, that's great. Still, it would be good to be careful with the word

@_date: 2014-07-14 14:37:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin Protocol Specification 
Well it's a finite code base so yes, it should be possible.
The only problem is .... so far everyone who tried it, didn't succeed :)
Heck even people who tried to reimplement it by reading the code keep
getting subtle details wrong.
So it should definitely be possible one day, assuming Bitcoin doesn't
become radically more complex, but it's a minefield.

@_date: 2014-07-15 12:25:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin address TTL & key expiration? 
Not only useful but essential! Otherwise mobile clients can run out of RAM
and have to cycle around and reuse addresses.
Which is indeed why BIP70 has this feature. It was thought about quite some
time ago. Addresses are an evolutionary dead end, they will never do
everything we need them to do. If there's somewhere that's using addresses,
that's somewhere we will eventually need to upgrade to use BIP70 instead.

@_date: 2014-07-15 14:03:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 38 NFC normalisation issue 
[+cc aaron]
We recently added an implementation of BIP 38 (password protected private
keys) to bitcoinj. It came to my attention that the third test vector may
be broken. It gives a hex version of what the NFC normalised version of the
input string should be, but this does not match the results of the Java
unicode normaliser, and in fact I can't even get Python to print the names
of the characters past the embedded null. I'm curious where this normalised
version came from.
Given that "pile of poo" is not a character I think any sane user would put
into a passphrase, I question the value of this test vector. NFC form is
intended to collapse things like umlaut control characters onto their prior
code point, but here we're feeding the algorithm what is basically garbage
so I'm not totally surprised that different implementations appear to
disagree on the outcome.
Proposed action: we remove this test vector as it does not represent any
real world usage of the spec, or if we desperately need to verify NFC
normalisation I suggest using a different, more realistic test string, like
Z?rich, or something written in Thai.
Test 3:
   - Passphrase ????? (\u03D2\u0301\u0000\U00010400\U0001F4A9; GREEK
   UPSILON WITH HOOK , COMBINING ACUTE ACCENT
   , NULL , DESERET
   CAPITAL LETTER LONG I , PILE OF POO
   )
   - Encrypted key:
   6PRW5o9FLp4gJDDVqJQKJFTpMvdsSGJxMYHtHaQBF3ooa8mwD69bapcDQn
   - Bitcoin Address: 16ktGzmfrurhbhi6JGqsMWf7TyqK9HNAeF
   - Unencrypted private key (WIF):
   5Jajm8eQ22H3pGWLEVCXyvND8dQZhiQhoLJNKjYXk9roUFTMSZ4
   - *Note:* The non-standard UTF-8 characters in this passphrase should be
   NFC normalized to result in a passphrase of0xcf9300f0909080f09f92a9 before
   further processing

@_date: 2014-07-15 16:27:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin address TTL & key expiration? 
You can specify zero as an output value, in which case it's the same as "no
value specified". You can then just reuse the PaymentRequest until it
expires. So I think it provides the same functionality already.
Now sure, you'll get address reuse in this scenario, but that's no worse
than with an extended textual address.

@_date: 2014-07-15 17:18:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin address TTL & key expiration? 
This seems to be the key point of disagreement here. Wladimir and I think
it satisfies your requirement just fine. You disagree. Let's get to the
bottom of that.
A PaymentRequest with a zero valued pay-to-address output and an expiration
time, base58 encoded, would look very much like your extended address form.
I don't suggest anyone actually represents PaymentRequest's using base58
but it helps to see the conceptual analogue. There'd be a bit more stuff in
there like some varint and wiretype codes but we're talking a handful of
bytes. Functionally, it'd be identical.
Places like protocols or APIs that require a piece of text and cannot
handle a piece of binary data could be retrofitted into the new world by
accepting base58 encoded PaymentRequest's. This would be kind of silly
because it's fundamentally binary data, but we already do this so it's at
least consistently silly :)

@_date: 2014-07-15 17:20:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 38 NFC normalisation issue 
UTF-8 guarantees that. Other encodings do not, you can have null bytes in
UTF-16 strings for example. Indeed most languages that use pascal-style
encodings internally allow null characters in strings, it's just not a good
idea to exploit that fact ...

@_date: 2014-07-15 18:26:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin address TTL & key expiration? 
I don't understand this point. It's the *sender* that is parsing the
PaymentRequest and following the instructions. By definition the sender
must be online. A computer that is switched off cannot sign a transaction
at all.
Yes, and an extension to BIP 70 to allow for this (or stealth addresses or
whatever) has been discussed several times.
This thread started by proposing (I think) an expiry time for addresses.
BIP70 satisfies this use case, I think we all agree on that. Now for cases
where someone can't use BIP70 for whatever reason, or it's suboptimal,
absolutely we should design extensions to fix that.

@_date: 2014-07-15 20:20:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 38 NFC normalisation issue 
Yes, we know, Andreas' code is indeed doing normalisation.
However it appears the output bytes end up being different. What I get back
from the spec.
I'm not sure why. It appears this is due to the character from the astral
planes. Java is old and uses 16 bit characters internally - it wouldn't
surprise me if there's some weirdness that means it doesn't/won't support
this kind of thing.
I recommend instead that any implementation that wishes to be compatible
with JVM based wallets (I suspect Android is the same) just refuse any
passphrase that includes characters outside the BMP. At least unless
someone can find a fix. I somehow doubt this will really hurt anyone.

@_date: 2014-07-16 11:12:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 38 NFC normalisation issue 
I'm all for fixing bugs, but I know from bitter experience that outside the
BMP dragons lurk. Browsers don't even expose Unicode APIs at all. You end
up needing to ship an entire pure-js implementation, which can be too large
for some use cases (too much time sunk on that issue in my last job).
I'm hoping BIP 38 doesn't get widely used anyway, to be frank. People
moving private keys around by hand has caused quite a few problems in the
past, sometimes people lost money. It's better to work at the level of a
wallet and ideally ask people to move money using regular transactions. Way
less potential for errors.
Regardless, I'll file a JVM bug and see what the outcome is.

@_date: 2014-07-16 11:29:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 38 NFC normalisation issue 
Yes sorry, you're right, the issue starts with the null code point. Python
seems to have problems starting there too. It might work if we took that
On Wed, Jul 16, 2014 at 11:17 AM, Andreas Schildbach

@_date: 2014-07-16 14:37:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for geutxos message 
Thanks Jeff.
I do feel like a lot of this is covered in the writeup I attached to the
implementation pull request, and I went over it again in the ensuing
discussion, and also in the BIP.
The discussion of how to make it secure is covered in the "Upgrade" section
of the writeup and in the "Authentication" section of the BIP. Please do
let me know if these sections are missing something. The ideas discussed
there are not implemented in this pull request because outside of some
special cases, it is a very large project that involves a chain fork. You
can see the start of a solution here:
The BIP already does discuss this, in the authentication section.
Suggestions for how to make it better are welcome.
I don't think it does proffer that, but if a part of the BIP could be read
as doing so, let me know which part and I'll fix it.

@_date: 2014-07-16 16:39:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for geutxos message 
I'm sorry you think it's unhelpful. It is nonetheless the best that can be
done within the constraints of the current Bitcoin protocol.
It's absent for the same reason it's absent for all the other protocol
BIPs: the ability to use a trusted third party is always present and a
possible answer for any problem in Bitcoin. So I figured it didn't need
How about adding the following sentence:
"If the above constraints are insufficient for your use case, you can
alternatively query a block explorer or other trusted third party to obtain
the same information".
Would that make the BIP clearer?

@_date: 2014-07-16 17:01:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Draft BIP for geutxos message 
It already does, last sentence of the authentication section is:
Querying multiple nodes and combining their answers can be a partial
solution to this, although as nothing authenticates the Bitcoin P2P network
a man in the middle could still yield incorrect results
Yes please.

@_date: 2014-07-17 12:59:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 38 NFC normalisation issue 
Glad we got to the bottom of that. That's quite a nasty compiler/language
bug I must say. Not even a warning. Still, python crashes when trying to
print the name of a null character. It wouldn't surprise me if there are
other weird issues lurking. Would definitely sleep better with a more
restricted character set.

@_date: 2014-07-18 12:41:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Decentralizing ming 
Jeff, I think the message you're replying to got clipped.
Satoshi's only comment AFAIK on the topic of GPU mining was to wish for a
gentlemen's agreement to postpone it as long as possible, to help make sure
the distribution of coins was as even as possible. Indeed this predated
pooled mining.

@_date: 2014-07-18 12:43:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Decentralizing ming 
Oops, sorry, I see the subject line changed. This is what I get for working
down the thread list top to bottom :)
I think the best path forward now is to finish off getblocktemplate support
in the various tools so it's possible to pool for payout purposes without
giving up control of block creation modulo the coinbase. Combined with the
recent sipa performance enhancing goodness, it would hopefully persuade
some non-trivial chunk of hashpower to go back to running their own node
and start the process of turning pools merely into payout trackers rather
than block selectors.

@_date: 2014-07-18 17:39:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Small update to BIP 62 
The rationale doesn't seem to apply to rule  what's so special about
that one?
Although I agree not having to support all of DER is nice, in practice I
think all implementations do and libraries to parse DER are widespread.
Given that the last time we modified tx rules without bumping version
numbers we managed to break the only functioning iPhone client, I've become
a big fan of backwards compatibility: seems the default choice should be to
preserve compatibility over technical niceness until the old versions have
been fully phased out.

@_date: 2014-07-21 00:02:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Trickle and transaction propogation 
No comment on the proposal itself, which sounds reasonable but I didn't
think about it much yet. Instead, just an observation that by now most
users are not using the Core wallet anymore, but rather use either SPV
wallets or more centralised blockchain/coinbase style gateways to the
SPV wallets don't relay thus you know any tx sent from them must be
originated by that wallet. Centralised services accept tx submissions via
SSL and can easily improve their users privacy by sending transactions out
via a node that isn't listening.
So IMHO we should be optimising the network for the common use case rather
than stuff that only helps Core wallet users, and actively slows down
everyone else. If your proposed techniques let us have our cake and eat it,
fantastic, otherwise I still think we should remove tx trickling.

@_date: 2014-07-22 13:13:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Question on creating test cases for 
There is no infrastructure for writing block chain unit tests
unfortunately. Last time I tried to fix this I ended up going down a rabbit
hole - Bitcoin wasn't written to be a testable codebase and as a result
reinitialising it from scratch is rather difficult (there are lots of
global variables that have to be reset to particular states and no real
list of where they are).
Instead what I ended up doing is extending the pull tester. This is a
bitcoinj based app (BitcoindComparisonTool in the codebase) which builds a
regtest chain and submits it to a local regtest node. It tests things like
reorgs and various rules. It speaks to the node only via P2P so how easy it
is to verify your BIP works will depend on that. Also the code needs
cleaning up, there's a lot of copy/paste coding going on in there.
On Mon, Jul 21, 2014 at 7:30 PM, Sergio Lerner

@_date: 2014-07-25 12:26:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Time 
Given that the speed at which the block chain advances is kind of
unpredictable, I'd think it might be better to just record the time to disk
when a PIN attempt is made and if you observe time going backwards, refuse
to allow more attempts until it's advanced past the previous attempt.

@_date: 2014-07-25 12:30:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Time 
Unfortunately not: miners have in the past routinely gamed the timestamp in
order to use it as an extra nonce and squeeze some more gigahashes out of
their hardware/pool.
Also remember that currently the chain could be dominated by a coalition of
just two pools.
The app cannot tell if it was given a truncated chain. You could keep such
an app stuck in the past forever. This is often a problem.
Much though I hate to be a party pooper, you could currently get
Bitcoin-level trusted time by just polling at least two or three
independent servers e.g. google.com, baidu.cn, yandex.ru    (they all serve
time via HTTPS headers).
If we crack the mining decentralisation problem then this argument becomes
a lot stronger, but for now ......
If you have a tamper resistant execution environment (TXT, SGX, Flicker
etc) then yes. However trusted execution environments sometimes have tamper
resistant clocks as well for exactly this reason. So whether this technique
makes sense depends a lot on the details of your configuration, I think.

@_date: 2014-07-25 18:03:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Time 
Sorry, you're right. I'd have hoped a delay that doubles on failure each
time up to some max would be good enough, relying on the p2p network to
unlock a PIN feels weird, but I can't really quantify why or what's wrong
with it so I guess it's just me :-)

@_date: 2014-07-27 21:31:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] "On behalf of" BIP 70 extension proposal 
Hi Mark,
This is very similar to a proposal I made some time ago:
I think the outlines of a design are clear - my proposal and yours don't I
think differ substantially. Someone needs to make it happen though.

@_date: 2014-07-28 12:16:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Abnormally Large Tor node accepting only 
The "exit" flag doesn't mean what you would expect it to mean. The reason
such a node won't get much traffic is that Tor speculatively builds
circuits at startup on the assumption they'll be used for web browsing.
Thus if you don't exit web traffic you won't get much in the way of traffic
at least not until bitcoinj based wallets start shipping Tor mode.
There's a perfectly reasonable explanation for why someone would run such a
node. In fact I run a Tor exit that only allows port 8333 too: it's a way
to contribute exit bandwidth without much risk of getting raided by the
Occam's razor and all ....

@_date: 2014-07-28 14:46:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] "On behalf of" BIP 70 extension proposal 
I'm not sure postponed is the right word. It wasn't in v1, but many useful
things weren't. It's more like, a bunch of people have to do work to
upgrade this and at the moment they're all busy with other things.
I don't think I proposed this exactly? It's the other way around - a
merchant issues an extension cert to allow the PP to act on their behalf.
I'm not sure I understand. Your proposal also has two signatures. Indeed it
must because delegation of authority requires a signature, but old clients
won't understand it.

@_date: 2014-07-28 15:32:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] "On behalf of" BIP 70 extension proposal 
Right, gotcha. Had forgotten about that.
Indeed there is another signature, which is to authenticate the payment
Yes, I see now, you are right. A mandate type system is probably simpler
So what now? To be honest my next priority with BIP70 was to formalise the
extensions process, I've been dragging my feet over that because I'm
working on other things. And then after that to knock some heads together
over at BitPay/Coinbase and get them to put useful text in the memo field
instead of random numbers. Baby steps ....

@_date: 2014-07-30 13:34:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] "On behalf of" BIP 70 extension proposal 
That would definitely be a new BIP.
But firstly it'd make sense to implement it and make sure that the payment
processors intend to use it. Like I said, I wasn't very successful so far
in getting them to make useful memo fields. I'm hoping that once wallets
start actually recording and displaying the memo in their transactions list
that will change.

@_date: 2014-07-31 12:37:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Abusive and broken bitcoin seeders 
The web has managed to survive despite constant fast crawls being the norm
for the past 10 years or so. I wouldn't worry too much about this unless
you can prove that a big chunk of your nodes resources are going to
answering ver queries.

@_date: 2014-06-04 17:51:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] # error "Bitcoin cannot be compiled 
Back in 2010 most code was still being written by Satoshi so perhaps you
should ask him. Regardless, it's very common for professional codebases to
require assertions be enabled. For example the entire Google C++ codebase
uses always-on assertions that have side effects liberally: it's convenient
and safe, when you have the guarantee the code will always run, and the
performance benefits of compiling out assertions are usually non-existent.
So for this reason I think Bitcoin Core currently will fail to build if
assertions are disabled, and that seems OK to me.

@_date: 2014-06-04 18:20:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] # error "Bitcoin cannot be compiled 
I think this class of errors could be removed entirely by just saying it's
OK for assertions to have side effects and requiring them to be enabled, as
is currently done.
The glog library:
provides CHECK macros that print stack traces when they fail. Using them
would also be good.

@_date: 2014-06-04 18:51:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] # error "Bitcoin cannot be compiled 
Currently expensive checks are guarded with command line flags. It'd be
nice if there could be one unified command line flag -expensivechecks that
subsumes -checkmempool and so on.

@_date: 2014-06-05 11:42:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Future Feature Proposal - getgist 
Why do you want to optimise this? getheaders is used by SPV clients not
full nodes. SPV clients like bitcoinj can and do simply ship with gist
files in them, then getheaders from the last "checkpoint"   (I wish I
hadn't reused terminology like that but this is what bitcoinj calls them).
In practice when I look at performance issues with current SPV clients,
getheaders speed is not on my radar.

@_date: 2014-06-07 19:22:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bloom bait 
You can send different bloom filters to different peers too, so I'm not
sure why you're listing subsetting as a unique advantage of prefix filters.
The main advantage of prefix filters seems to be faster lookups if the node
is calculating a sorted index for each block, and the utxo commitment
stuff, both of those would be cool but involve imposing extra costs on
nodes. We lack models that let us understand the tradeoffs involved in
various indexing schemes, I feel.

@_date: 2014-06-10 18:38:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bloom bait 
DoS attack? Nice try.
Performance is subtle, disk iops especially so. I suspect you'd find - if
you implemented it - that for the kinds of loads Bitcoin is processing both
today and tomorrow prefix filtering either doesn't save any disk seeks or
actively makes it worse.
Consider a client that is syncing the last 24 hours of chain. bitcoind
pre-allocates space for blocks in large chunks, so most blocks are laid out
sequentially on disk. Almost all the cost of a disk read is rotational
latency. Once the head is in place data can be read in very fast and modern
kernels will attempt to adaptively read ahead in order to exploit this,
especially if a program seems to be working through a disk file
sequentially. The work of Bloom filtering parts of the chain for this
client boils down to a handful of disk seeks at best and the rest of the
work is all CPU/memory bound as the block is parsed into objects and tested
against the filter. A smarter filtering implementation than ours could do
SAX-style parsing of the block and avoid the overhead of turning it all
into objects.
Now consider a prefix filtering implementation. You need to calculate a
sorted list of all the data elements and tx hashes in the block, that maps
to the location in the block where the tx data can be found. These
per-block indexes take up extra disk space and, realistically, would likely
be implemented using LevelDB as that's a tool which is designed for
creating and using these kinds of tables, so then you're both loading the
block data itself (blocks are sized about right currently to always fit in
the default kernel readahead window) AND also seeking through the indexes,
and building them too. A smart implementation might try and pack the index
next to each block so it's possible to load both at once with a single
seek, but that would probably be more work, as it'd force building of the
index to be synchronous with saving the block to disk thus slowing down
block relay. In contrast a LevelDB based index would do the bulk of the
index-building work on a separate core.
At *some* block size and client load the additional data storage and
increased pressure on the page cache would probably make it worthwhile. But
I find it unlikely to be true at current traffic levels, or double or
triple today's levels. So I'd rather we spend our very limited collective
time on finding ways to increase usage rather than worrying about resources
which are not presently scarce.
(as an aside, some of the above analysis would be invalidated if most nodes
end up running on SSDs, but I doubt most are. It'd be neat to export
storage tech via some kind of stats message - LevelDB is designed for HDDs
not SSDs so at some point a new storage subsystem might make sense if the
network switched over).

@_date: 2014-06-10 18:41:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bloom bait 
BTW, I find it curious that any nodes have code to disconnect peers that
send Bloom filters. It shouldn't be necessary. Bitcoinj is the only large
scale user of filtering and it will disconnect itself if a peer advertises
support for a version lower than 70000. If a node advertises support for
this version or higher then it is supposed to implement BIP37.
It sounds like some node authors decided to advertise support for a
protocol version they didn't bother implementing, which would be a bug.

@_date: 2014-06-11 10:57:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bloom bait 
It's obviously different; a thin client trying to obtain more privacy is
not attempting to deny service to anyone. You can't simply state that a
feature which uses resources for a legitimate reason is a DoS attack,
that's a spurious definition that would reclassify innocuous things like
web browser prefetching as DoS attacks too.
With respect to the work you're proposing, trying to retroactively make
Bloom filtering an optional part of the protocol is just wasting people's
time at this point:
   - There is no evidence there's an actual problem today.
   - There is no evidence there will be a problem any time soon, given the
   meagre levels of traffic growth we have.
   - It involves a complicated rollout strategy that would create work for
   many people.
   - Gavin, Wladimir and myself have all concluded it's not worth the cost.
   - The only justification you have provided is that two node
   implementations hardly anyone uses can't be bothered to implement Bloom
   filtering, but want to advertise support in their ver message anyway. They
   can simply lower the number they advertise in their ver message.
That said, if you want to implement better support for archival nodes then
that'd be great. The way to do it would be either to implement block ranges
in the addr announcements as has been discussed many times before, or
perhaps introduce a new protocol optimised for serving the chain. Nodes
that are CPU limited won't want to take part in the rest of the P2P
protocol anyway, it's not just Bloom filtering that uses CPU time but also
block and tx relay.
But until you have done these things, please stop attempting to reclassify
any feature you can imagine a more efficient version of as an "attack".
It's just silly.

@_date: 2014-06-16 13:35:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Incentivizing the running of full nodes 
Hi Odinn,
I think trying to incentivise nodes with money is tricky: it makes
intuitive sense but right now the market is flooded with supply relative to
demand. Yes, we worry about the falling number of nodes, but that's for
reasons that aren't really economic: the more nodes we have, the bigger and
more grassroots the project seems to the outside world, plus the cheaper it
gets for everyone as the biggest cost (chain upload bandwidth) is spread
over multiple people.
Also there's research showing that when you have people volunteering,
introducing money can ruin the motivation of the volunteers, so the
transition to a pay-for-node-services world could be quite painful and
Right now rather than microdonations to all nodes, IMO the lowest hanging
fruit is to move chain upload onto specialised "archival nodes" which can
potentially charge for their services. I prototyped this here
but never finished it.
On Mon, Jun 16, 2014 at 10:12 AM, Odinn Cyberguerrilla <

@_date: 2014-06-16 14:19:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
Looking good! I think this is much better than the original draft. Agree
with Andreas that supports_instant is simply equal to
(supported_instant_providers.size() > 1) which makes it redundant.
Daniel is right that putting every possible provider in the Payment message
might not scale in a world where there are huge numbers of
instant-confirmation providers, but I'm hoping that we never have to scale
to that size, because if we did that'd rather imply that Bitcoin has become
useless for in-person payments without trusted third parties and avoiding
that is rather the whole point of the project :) So I'm OK with some
theoretical lack of scalability for now.
A more scalable approach would be for the user to send the name and
signature of their "instant provider" every time and the merchant just
chooses whether to ignore it or not, but as Lawrence points out, this is
incompatible with the provider charging extra fees for "instantness". But
should we care? I'm trying to imagine what the purchasing experience is
like with optional paid-for third party anti-double-spend protection.
Ultimately it's the merchant who cares about this, not me, so why would I
ever pay? It makes no sense for me to pay for double spend protection for
the merchant: after all, I'm honest. This is why it doesn't make sense for
me to pay miners fees either, it's the *receiver* who cares about
confirmations, not the sender.
So I wonder if a smarter design is that the user always submits the details
of their instantness provider and we just don't allow for optional
selection of instantness. I'm not sure that works, UX wise, so is having a
less scalable design to support it worthwhile?

@_date: 2014-06-16 14:25:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
Oh yes the other thing we need to decide is how to extend BIP70.
Protocol buffers have an extend keyword. But I'm not sure it's what we
really want. IMHO a simpler solution is to have a single "living" version
of the protobuf (where? in a new git repo?) which has all the fields
defined by all the accepted BIPs in a single place. Otherwise the build
process and so on for wallet implementors would get unnecessarily
complicated for no real reason. Also if you wanted to pick a new number for
fields, you'd end up having to read *all* BIPs to figure out what is
available. Simpler seems better.
If we do that then I suggest just using field number 8 or 9 or whatever
rather than 1000. IMHO fields 1000+ should be for private extensions that
are unlikely to collide with other users.

@_date: 2014-06-16 17:43:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
Sure. I buy this. Although the credit card market is a great example of
what we *don't* want: a stagnant duopoly of trusted third parties who
rampantly abuse their position. So I'd hope we see either (a) nobody really
caring about this BIP because Bitcoin gives good enough double spend
protection or (b) lots of anti-double-spend providers (hundreds seems fine).
No, I will never wait. Neither me nor the merchant wants to me to be
pointlessly hanging around for an hour. The alternative is to pay by credit
card or cash. Outside of experiments there is no such thing as a shop that
only accepts only Bitcoin and will require me to wait for a block because I
didn't use a TTP to guarantee anti-double spends.
So this seems like a fundamental problem to me: having the ability to say,
"here is a proof I won't double spend" is fine, but it doesn't achieve
anything if the merchant would have sold me the goods in return for a
normal Bitcoin tx anyway, which in practice they always will because this
system starts out from zero users and would have to work upwards. I
*especially* will never use this system if I have to pay for it - I'd much
rather just put my money into a wallet that can't generate these proofs and
pay the sticker price.
Maybe what this BIP needs is an extra field that lets the merchant say, I
will give you a discount of X satoshis if you give me a no-double-spends
proof. In other words invert it: the sticker price is what normal Bitcoin
transactions cost, and then your wallet shows you the regular BIP70 price
minus the discount plus the third parties fee as what you finally pay. I
compare it to the sticker price the merchant is asking and if it's lower
I'm happy, and if it's higher my wallet would automatically avoid using the
TTP because I don't want to ever pay more, only less.
The market would then figure out if the fees the TTP charges are worth the
lower losses due to double spending fraud.

@_date: 2014-06-16 17:48:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
Please see  which implements
this exact scheme. It can solve some kinds of double spends (probably), but
others - like ones done by corrupt miners (see bitundo) - can't be solved
this way.
Lawrence's motivation for this BIP is essentially to act as a backup in
case the Bitcoin native double spending protections end up being too weak
to be useful. It reintroduces a notion of centralised trust as a layer on
top of the Bitcoin protocol, but only for cases where the seller/recipient
feels it'd be useful. In this way it gives us slack: if someone is able to
reliably double spend and the merchants losses due to payment fraud go up,
we can fall back to TTPs for a while until someone finds a solution for
Bitcoin, or we just give up on the Bitcoin experiment, but hey - at least
we now have a better intermediary protocol than SWIFT :-)
In practice of course this is something payment processors like Bitpay and
Coinbase will think about. Individual cafes etc who are just using mobile
wallets won't be able to deal with this complexity: if we can't make native
Bitcoin work well enough there, we're most likely to just lose that market
or watch it become entirely centralised around a handful of payment
processing companies.

@_date: 2014-06-16 18:07:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
Yes it's the right place. The original attempt at this concept was in fact
called *green addresses* and the idea was you could identify a spend from a
trusted wallet by checking which keys were being used to sign. But the
problem is, lack of privacy. Everyone can see what wallet provider you use.
Also it'd be inefficient to have in the chain. There's no reason for the
extra signatures to be there: double spend risk is something only the
recipient cares about.

@_date: 2014-06-16 18:45:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
Actually Tom is running a page where he shows double spends detected by his
node or relayed by mine (there are only two nodes in this little detection
network currently), and it does show double spends that occur seconds,
minutes or even days apart.
Regardless, whether that approach helps or not is off topic for this
thread. Let's all hope it does and discuss the details in some other
thread, or on the pull request.
Yes indeed, if you want to do high frequency trading then every millisecond
counts and you probably don't want to rely on watching transactions
propagate across the block chain. For inter-exchange traffic this BIP would
probably be useful. I've been talking about the consumer case.
No, I expect there to be many kinds of trades where dispute mediation is
unnecessary, e.g. when I buy a drink at Starbucks or a burger at McDonalds
the chances of me wanting to charge it back is basically zero. Same for
sending between people who know each other, large corporate transactions
where the threat of a lawsuit is more useful than mediation, etc.
But for transactions where third parties are needed for dispute mediation,
yes, I'd expect there to be a handful of well known trusted names for the
majority of such transactions, and then a long tail of specialists who only
mediate e.g. purchases of rare Aztec artifacts or other things where a
generic company might be easily fooled.

@_date: 2014-06-16 19:01:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
As long as miners stick to Satoshi's first seen rule, which is the default,
it's useful:
(this is the famous "snack machine" thread from 2010)
If they decide to change to something like highest-fee-always-wins, then
they (again) centralise things by forcing all instant transactions to pay
GreenAddress and its competitors money - much though I like your product
Lawrence, let's hope they don't collectively lemming us all off a cliff by
doing that ;)

@_date: 2014-06-16 19:59:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Incentivizing the running of full nodes 
Peers can calculate rewards based on number of inputs or total kb used:
you're paying for kilobytes with either coin age or fees no matter what. So
I think in practice it's not a big deal.

@_date: 2014-06-16 20:09:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
I think many of us feel it'd be better if this kind of thing were not
needed at all, however, the best way to ensure it doesn't end up being used
is to write code, not to try and block alternative approaches. If Bitcoin
is robust the market should sort it out. If it's robust for some
transactions and not others, that makes for a fun project for a future
generation of hackers to sort out.
OK, enough philosophy - let's try and keep this thread just for discussion
of the BIP itself from now on. If you'd like to continue debating the
Future of Bitcoin please change the subject line and break it out into a
new thread.

@_date: 2014-06-16 22:32:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
A provider does not have to be an interactive third party. One reason I
suggested using X.509 is so secure hardware devices like the TREZOR could
also be instant providers. The hardware would be tamperproof and assert
using a secret key embedded in it that the tx came from a genuine,
unflashed TREZOR. The the server can know the device won't double spend.
In this way you have decentralised anti-double spending. Of course, it's an
old solution. MintChip sort of worked a bit like this.

@_date: 2014-06-16 22:46:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
It's no different to the CA problem. People can only mentally handle a few
trust anchors, so for SSL it goes:
   1 User -> 2-3 browser makers -> 100's of CAs -> millions of websites
The trust starts out narrowly funnelled and grows outwards as things get
For this it'd go
   1 merchant -> 4-5 payment processing engines -> dozens of hardware
manufacturers -> hundreds of thousands of devices

@_date: 2014-06-16 22:55:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
Yes that's true. Though it's off topic, check out
  .... it's a project to force CA's
to publish all certs they make publicly.

@_date: 2014-06-18 11:15:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
Please, let's talk about other anti-double spend things on a separate
I linked to Satoshi's post on this earlier, he explains why it works there,
assuming people follow the original protocol rules.
Your analysis holds as long as network abandons the original Bitcoin
design. Obviously, we hope people won't do that. If everyone decides not to
do things how Satoshi laid out then things will break, although whether we
have a failure of "Bitcoin" at that point is debatable.

@_date: 2014-06-18 15:25:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
I'm not sure this is actually important or useful; trusting someone not to
double spend is a pretty binary thing. I'm not sure saying "you need to get
three independent parties to sign off on this" is worth the hassle,
especially because the first signature is obvious (your risk analysis
provider or hardware) but the second and third are ..... who? Special
purpose services you have to sign up for? Seems like a hassle.
But it's up to you.

@_date: 2014-06-18 18:09:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] instant confirmation via payment protocol 
Supporting it in the protocol is easy. Building such a thing: that's hard.
Decentralised automated reputation systems are complex and subtle.
I don't feel strongly about whether the field should be "optional" or
"repeated", 100% of implementations in the forseeable future would just
look at the first item and ignore the rest. But if later someone did crack
this problem it would lead to a simple upgrade path. So perhaps you're
right and the protobuf should allow multiple signatures. It means a new
sub-message to wrap the pki_type, pki_data and signature fields into one,
and then making that repeated.
Up to Lawrence.

@_date: 2014-06-19 19:35:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BlockPow: A Practical Proposal to prevent 
My (fresh!) understanding is that the reason we don't see people using
getblocktemplate to decentralise pools is because libblkmaker and other
implementations don't actually support connecting your own node to the
miners and choosing your own blocks, even though the protocol does.
I've written up a blog post that I hope will go out on the Foundation blog
soon with some low hanging fruity ideas for miner decentralisation.
Sergio, I'd love to give you intelligent feedback but unfortunately reading
it made my brain explode :) Sorry!

@_date: 2014-06-24 11:11:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Plans to separate wallet from core 
bitcoind already supports SPV mode, that's how bitcoinj clients work.
However the current wallet code doesn't use it, it integrates directly with
the full mode main loop and doesn't talk P2P internally. Which is the fine
and obvious way to implement the wallet feature. I'm not totally convinced
it should become an SPV wallet given the complexity of doing that. But if
you did want to separate the wallet code from the full node then that'd be
the way to do it.
The question is; what does this buy us, and is it worth the potentially
huge amount of time it could take? My gut feeling is we have bigger fish to
fry. There's plenty of work to do just on the core consensus code, making
Bitcoin Core into a competitive wallet as well would be an additional
However I may be quite biased, as I am the maintainer of what is primarily
a wallet library :)
People use Electrum as shorthand to mean "something a bit like the P2P
network, but with trusted remote servers which build additional databases
and thus support additional commands".

@_date: 2014-06-24 12:12:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Plans to separate wallet from core 
Yes. I'd love to have a mostly Core compatible JSON-RPC frontend. Most of
my current users are happy using it as a library though. A lot of popular
languages can run directly on the JVM these days. The big ones we miss are
C++ and PHP, I think. But you can use JavaScript, Python 2.7, Lisp, Ruby,
along with other less well known ones.
The other good reason to have JSON-RPC support would be to reuse the Core
regression tests.
Anyway, this is off topic :)

@_date: 2014-06-24 14:16:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Plans to separate wallet from core 
We definitely want to head in the direction of allowing a p2p node to be as
useful as possible within its resource constraints and optional advertising
of new (expensive) indexes is the way to go.
Sometimes I wonder if we should have an RPC or new socket based method
where additional programs could run along side Bitcoin Core and opt to
handle a subset of p2p commands. But then I think, that seems like a lot of
complexity for people who just want to help out the system, which I guess
is the bulk of our network now. Keeping their lives simple should have a
high priority. So a single unified program that just figures it out
automatically rather than expecting users to assemble a bag of parts seems
a goal worth striving for.

@_date: 2014-06-24 15:27:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed BIP 70 extension 
Coinbase have started allowing merchants to set discounts for purchasing
with Bitcoin. Seeing an individual discount is not very motivating as they
tend to be small. Seeing them stack up over time can be more motivating
because it feels like free money. Many businesses exploit this effect with
loyalty points, etc. Bitcoin should do this too - show the user how much
they're saving by using Bitcoin instead of credit cards.
I suggested to Charlie Lee (who pushed this through at Coinbase) and
Stephen Pair the following minor BIP 70 extension:
message PaymentDetails {
    // Size in satoshis of any discount provided by the merchant ONLY
    // because the user chose to pay using Bitcoin or other similar
    // digital currency. Other kinds of discounts, loyalty bonuses and
    // so on should not be recorded here, rather they could be mentioned
    // in the memo field. This field exists so wallets can show the user
    // a running total of how much money they have saved by avoiding
    // credit cards and bank payments; the goal is to encourage people to
    // use Bitcoin. Putting other kinds of discounts here would make the
    // running total calculated meaningless; so don't do it!
    optional uint64 currency_usage_discount_size = 8;
Wallets would then be able to persist this data to disk and compete on cool
visualisations for how much money you saved over time.
We haven't formalised how to extend BIP 70 yet, that's my fault. We should
do that. In the meantime, what do people think of this proposal?

@_date: 2014-06-24 16:24:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed BIP 70 extension 
The user knows the price that is on the website or menu, they know the
price they actually paid ... if the numbers don't add up that would seem to
be pretty easily detectable. But sure it's only for marketing.  I think the
comment makes it clear it's just for fun.

@_date: 2014-06-24 17:06:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed BIP 70 extension 
Your own wallet can look up the exchange rate and compare it to what you're
getting (and in fact, wallets do!).
Besides, assuming the customer is *always* being scammed seems extreme.
There are plenty of merchants that genuinely care about their reputation
and genuinely want people to pay with Bitcoin so they can avoid card fees.
Well, I think the protocol should contain whatever is useful.
I'll probably draft a BIP for this next week or so.

@_date: 2014-06-24 17:59:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed BIP 70 extension 
That might be useful for merchants that already provide a series of
price-differentiated payment methods, yes. Will think about it.
Currently Coinbase let merchants specify the size of their discount (I
guess in percentage terms, I should ask). So the merchants tell the payment
processor. I don't think this is a worry at the moment.

@_date: 2014-06-25 10:25:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed BIP 70 extension 
No, it'd be sensible.
Here's a list I drew up a long time ago of features I imagined adding to
the payment protocol:
The protocol is there to contain features! There is zero benefit to
slavishly following some religious notion of purity or minimalism here. The
shared resource in question is just varint encoded integers. So, we should
be guided by what will help our users and what will help adoption.
Anyway, Gavin asked me to start handling more BIP 70 stuff a few weeks ago.
I want to use something simple to set up the extensions process more
formally. IMO we need a "living document" version of the payment protocol
with all the different extensions out there folded into it, to simplify
programming tasks and ensure field numbers don't collide.

@_date: 2014-06-25 13:23:45
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bill Request Message - (another) Proposed 
I'm not convinced this inversion is really a problem, but as this is quite
a complex proposal (e.g. new barcode types) the best way to move it forward
at this stage is to implement it in some existing wallets.
FWIW NFC is a lot more common than you might think. For the drive-thru case
you could also consider using wifi hotspots with a special name or
Bluetooth LE tags. So I suspect before trying to write a specification it'd
be better to explore different technologies and see what works best in

@_date: 2014-06-25 16:38:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bill Request Message - (another) Proposed 
Alright. I still tend to think it's not a big deal, but there's no reason
both or all mechanisms can't co-exist.
BTW: a QR code next to a cash register can be fixed i.e. printed on paper
when using BIP70. The PoS would upload payment details to the server and
the URL for that particular PoS unit would then serve it when the user
scans the QR code. Alternatively, Andreas' work on Bluetooth may be more
appropriate: the QR code can contain the BT MAC of the device and the
payment request is downloaded that way. That's already implemented! I still
feel that if a seller can scan a users phone, the users phone can certainly
scan some rectangle that's physically near by the sales counter.
The other nice thing about that approach is the QRcode can also be an NFC
tag i.e. have the tag behind it with a little icon in the middle of the QR
code to indicate that touching works as well as scanning.
One project I keep wanting to play with is making these little NFC-QRcode
hybrids and a simple PoS app to go with them. But no time, alas ....

@_date: 2014-03-02 09:44:21
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Hash Comments 
SHA-1 support is there for PHP developers. Apparently it can't do SHA-2.

@_date: 2014-03-02 11:37:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Positive and negative feedback on 
I'm hoping I can convince Saivann to do a bit of graphics work for this at
some point :-)
Something like a green stamp that appears (like a watermark) in the
background, might be good.

@_date: 2014-03-02 11:39:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol Hash Comments 
I'm just repeating the rationale Gavin gave me for adding this to the spec
last year when he was implementing it. Perhaps it only applied to some
versions of PHP or something like that.
Jeremy, good comments. A pull request to fix those would be good.
One issue I seem looming on the horizon is that we'll need a version of the
payment protocol document that's living. Trying to reverse engineer the
current spec by manually reading all the BIPs and layering them in your
head is a non starter.

@_date: 2014-03-02 11:44:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 extension to allow for identity 
I think for now as long as payment processors include the merchant name in
the memo, that's good - as long as hardware devices or second factor
wallets display the memo as well! Trezor has a small screen, I don't know
how feasible displaying the whole memo is there though - hence an interest
in something better. For now we can probably muddle through.
Not really interested in solutions that only help very advanced users.
Besides, my understanding is that most PKI CA's will not sign certs that
include arbitrary data they don't understand for I guess the obvious
security reasons (generally signing things you don't understand is a bad
idea). But I've never actually tried it.
We don't want anyone to have to go back to their CA anyway, especially not
with special requests.

@_date: 2014-03-02 11:57:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 extension to allow for identity 
If they take delivery of an SSL cert from the CA themselves, I don't see
why it'd be an issue. A simple GUI app can be produced that let's you open
the CA cert files and spits out the ExtendedCert file, which you then send
to the PP.
However, for small businesses like local shops, yes we don't expect them to
have a CA cert at the moment. Many of them do have small websites but for
those that don't, I don't think any great solutions exist yet. A virgin
market waiting to be tapped, perhaps ...
What is "the merchant identifier" exactly, and what does it mean? If this
question is left unresolved, then it doesn't mean anything and as such it's
equivalent to putting the merchant name in the memo field, which is fine
and what I expect to happen for now.
If it's resolved, then it makes payment processors into certificate
authorities themselves. I think such a solution would be spiffy, but it can
be done within the same framework we have today by just having wallets add
some Bitcoin specific roots to their trust store before PKI verification.
For example, BitPay could become their own CA that doesn't issue SSL certs
but rather "local business certs" that contain a verified street address.
Indeed X.509 certs include X.520 names, that's one reason they're so damn
complicated, and that's already got ways to express organisation names.
Actually setting such a scheme up requires real work though. If we want a
wallet to display something like:
   "Pay to:  Room 77, Graefestra?e 77, Berlin"
then the question is, how is that verified and what does it mean when a
payment processor issues a cert containing it? Did someone physically visit
them? Did they just check on Google Maps? Does it mean it's a real
incorporated business or could it just be the address of a childs lemonade
My inclination would be to say that the ID requirements should be low and
cheap; for our primary use case of making hardware wallets secure, you
don't need robust ID verification, you just need to ensure a MITM can't
issue themselves duplicated ID's on the fly. Just posting a postcard with a
nonce on it would be sufficient IMO (or making a phone call to a number
obtained from a previously verified business listing).
Alternatively, a bitcoin payment processor CA could make visiting a
business, gathering photo evidence and issuing a cert into a kind of
microwork task with the PP/CA acting as a broker.

@_date: 2014-03-02 12:50:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Thanks Andreas.
For BIP standardisation, I think the VIEW intent seems like an obvious one.
Bluetooth support probably should come later if/when we put encryption/auth
on the RFCOMM link (probably SSL).

@_date: 2014-03-02 17:14:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 extension to allow for identity 
Definitely agree - like I said, I publish this only because I keep getting
asked about it.
That's right. There's little point in having multiple PKI's simultaneously,
that's why it doesn't allow it.
This one is a special case because it doesn't replace but rather
specialises and extends the existing PKI. Old clients that don't understand
it would still show something useful and by upgrading you get better
output. Actually you get closer to the output you're supposed to get.
That's going to be rare though, I think. Generally you wouldn't want to
have multiple PKIs in use simultaneously for the same payment request.
It can be done but only by sacrificing backwards compatibility, which
doesn't seem worth it to me. It's hardly a big deal to have two signature
fields. The rest is all localised to the X509 parts.

@_date: 2014-03-03 22:18:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Procedure for non-tech contributions 
Hey Tom,
Thanks for getting involved! It's great to see someone who would like to
focus on docs.
One project I've been thinking about recently is a "Bitcoin Developer
Network" subsection of our website. Right now bitcoin.org is entirely
consumer focused. And as you noted, the wiki is undergoing some kind of
heart attack - it's not an ideal medium for professional docs anyway.
So it's too hard to learn how to work with Bitcoin as a developer, and we
could really benefit from professionally curated web content. We have a
great web dev in the form of Saivann, who recently got some sponsorship
from the Foundation to spend time on the website, so I'm hoping that if we
find people to produce the content then he can with the visual design and
we could create something really special.
If you're interested in this let me know.

@_date: 2014-03-05 11:18:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 proposed changes 
Because this is such a common sentiment, I wrote a couple of articles on
the matter.
The first is about why BIP 70 uses the SSL PKI and an examination of the
most commonly proposed alternative ideas:
   ... including the web of trust, using bitcoin addresses/the block chain,
allowing multiple certs, trust-on-first-use and (for SSL only)
The second is a summary of some of the most famous crypto-usability
research papers published in the past 10-15 years. They cover SSL and PGP.
If you're interested in designing alternatives, reading these papers would
be a good place to start:
    There's a book from O'Reilly called Security & Usability that contains 34
papers and essays. It's very good:

@_date: 2014-03-05 13:49:22
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New side channel attack that can recover 
A new practical technique has been published that can recover secp256k1
private keys after observing OpenSSL calculate as little as 200 signatures:
This attack is based on the FLUSH+RELOAD technique published last year. It
works by observing L3 CPU cache timings and forcing cache line flushes
using the clflush opcode. As a result, it is applicable to any x86
environment where an attacker may be able to run on the same hardware i.e.
virtualised hosting environments where keys are being reused.
I am not currently aware of any efforts to make OpenSSL's secp256k1
implementation completely side channel free in all aspects. Also,
unfortunately many people have reimplemented ECDSA themselves and even if
OpenSSL gets fixed, the custom implementations probably won't.
So, IMHO this is a sign for hot wallet users to start walking (but not
running) towards the exits of these shared cloud services:  it doesn't feel
safe to sign transactions on these platforms, so hot wallets should be
managed by dedicated hardware. Of course other parts of the service, like
the website, are less sensitive and can still run in the cloud. I doubt the
researchers will release their code to do the side channel attack and it's
rather complex to reimplement, so this gives some time for mitigation.
Unfortunately the huge sums being held in some "bitbank" style hot wallets
mean that attackers are well motivated to pull off even quite complex

@_date: 2014-03-06 09:38:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New side channel attack that can recover 
I'm wondering about whether (don't laugh) moving signing into the kernel
and then using the MTRRs to disable caching entirely for a small scratch
region of memory would also work. You could then disable pre-emption and
prevent anything on the same core from interrupting or timing the signing
However I suspect just making a hardened secp256k1 signer implementation in
userspace would be of similar difficulty, in which case it  would naturally
be preferable.

@_date: 2014-03-06 10:45:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
I just did my first contactless nfc payment with a MasterCard. It worked
very well and was quite delightful - definitely want to be doing more of
these in future. I think people will come to expect this kind of
no-friction payment experience and Bitcoin will need to match it, so here
are some notes on what's involved.
There are two aspects that can be implemented independently of each other:
1) The physical/NFC layer.
2) The risk analysis layer.
A contactless payment needs two things to work: one is a VERY fast, low
latency communication between payment device (phone in our case) and
terminal. I couldn't find actual latency specs yet but it felt like using
an Oyster card, which aims for <400msec.
The other is that obviously the payment device has to decide to sign the
transaction without any user interaction, i.e. the payment is at low risk
of being unintentional. If you nail this it can be used for one-click web
payments too.
Andreas already did some work on embedding full blown payment requests into
an NFC tag, but I think we need to switch this to being a packet based
protocol (via ISO-DEP), otherwise you can't submit the Payment/tx messages
back via NFC as well. This isn't a very complicated task and would make a
fun project for a newbie who has Android and knows some Java. The resulting
ISO-DEP protocol can be turned into a BIP without too much trouble.
The risk analysis is the more complicated part. The real value
Visa/MasterCard provide with NFC payments is not so much the tech (the
clever part is the batteryless nature of the cards rather than the
crypto/comms), but the fact that merchants are all verified and can be
fined or evicted if they abuse the system and try to steal money. Bitcoin
doesn't have anything like that.
I think we have a few options to make it safe:
1) Require some very lightweight user confirmation, like pressing the power
button to reach the lock screen and only allowing small payments. The
combination of physical proximity and pressing the power button is probably
good enough for now to avoid problems. Someone should try it out and see
how it feels.
2) Have some kind of semi-centralised merchant verification/approval
programs, like what the card networks do. The easiest way to start would be
to piggyback on the work BitPay/Coinbase do and just auto-sign if payment
amount is

@_date: 2014-03-06 14:44:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
If the phone isn't willing to immediately authorise then it'd have to fall
back to HTTPS or Bluetooth as normal.
I guess only the amount and destination are relevant for risk analysis.
I think IsoDep based protocols must bypass Beam - when I scan my e-passport
there's no beam animation.
Well, for <400msec there can't be any user interaction. But checking
signatures on the payment request and constructing and signing the inputs
can all be done in parallel - you should be able to max out every core, at
least for a brief moment.
Then that subway kind of sucks ;) Have you been to London and used Oyster?
I think the capital wouldn't work at all without the low latency Oyster
cards. The tube would have stopped scaling some time ago.

@_date: 2014-03-06 17:52:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
Together, the signed PaymentRequest and the transactions in the block chain
should act like a receipt: it's proof you requested payment in a certain
way, and I satisfied that payment. So it's proof of payment and the memo
field can describe what I bought.
He means, contactless credit cards can be used too. No need to enroll for
Oyster specifically. I guess in the long run Oyster and its equivalents in
other cities (octopus etc) will be phased out.

@_date: 2014-03-06 18:00:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments, IsoDep 
I think maybe the way you do it is to have a NDEF tag that triggers the
app, and then that starts an IsoDep protocol once opened. I *think*.

@_date: 2014-03-06 18:03:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
Thanks Alex!
About the video - I'm curious how your device is better than just a regular
tablet. Could you give us the elevator pitch? :)
I guess fees will wander up and down depending on system load rather than
real world value - but maybe you're right. That said, all wallets sync
exchange rates automatically already.
In some Star Trek future, perhaps we would want Bitcoin to be independent
of other value units. But I'm not convinced such a world will ever exist.
Arguably, a stable currency would slowly become worth more over time in
line with economic growth. But then for stable prices you would need
something like a fake currency that was "backed by" (really: represented
by) a basket of goods. Otherwise over time your rent would go up in real
terms, for good real reason.

@_date: 2014-03-06 18:07:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
The identity would be the X.520 name in the signing cert that signed the
payment request. It doesn't have to be a difficult to obtain cert. It could
even be self signed for this use case, but then you lose the security
benefits and a key rotation would delete your reputation, so in practice I
think most people would want the reputation to accrue to the name itself.

@_date: 2014-03-06 19:12:01
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
Well now you're getting into the area that I said "rapidly got very
Define bitcoin user? What stops me paying myself to accrue positive
reputation? Etc.

@_date: 2014-03-06 19:24:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
If it's explicit, I think it's a non starter and nobody will bother with
it, especially not just for instant payments.
If it's just a case of "link your wallet with your Facebook account" and
requires no more effort than that, some people might, but of course the
user experience would be rather random. Hey why did that guy in front of me
get instant payments and I had to confirm even though we bought the same
I'm not a big fan of UX's that appear totally random to the user.

@_date: 2014-03-06 23:59:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bip-0021 and bip-0072 ambiguities & 
Yes please, pull req would be great! I also noticed that escaping doesn't
seem to be necessary, and the resultant de-escaped QRcodes are certainly
much nicer! Thanks!

@_date: 2014-03-07 11:00:21
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
HCE is a bit scary. It's like the card companies tried the secure element
thing, decided the security was too hard and were like "screw it, let's
just use regular apps after all". Not that we're any better :)
At any rate, Bitcoin doesn't have any need to emulate smartcards as we
don't have any pre-existing infrastructure. We can just use a regular
non-smarcard-emulation ISO-DEP protocol. The new UI in Android 4.4 provides
some way to choose the default payment app, but I think it's only intended
to disambiguate between credit card providers. Everything else gets dumped
into CATEGORY_OTHER and I dunno what happens if you have multiple Bitcoin
wallet apps doing the same thing. Worst case, we can add some
disambiguation code on top, inside the apps themselves.

@_date: 2014-03-07 12:01:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
I think you could just put a signed PaymentRequest into an NFC tag and try
reading it from that. It's the same underlying radio tech so the transfer
speeds should be similar, I'd think.
Common X.509 certs are bigger than they need to be for sure, but a lot of
the bulk comes from the use of RSA rather than ECC. An RSA signature alone
can be 256 bytes! There's nothing that states you have to use RSA for
certificates and ECC certs are out there (Google uses one), but I think
they are harder to get hold of. I guess over time SSL will migrate to
mostly ECC (secp256r1) based certs.

@_date: 2014-03-10 17:04:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Instant / contactless payments 
A bit more competitive intelligence - turns out that the experience isn't
quite so good after all. After trying a few more times to use contactless
payments, I found it has a ~75% failure rate based on my usage.
By far the biggest problem is also the most predictable - it's very common
here for merchants to require minimum payment sizes before they'll accept
credit cards, often quite high, like 20 CHF or more. But the PIN-less mode
only works for payments below a certain threshold, I haven't quite figured
out what it is yet, but in the UK it's 20 GBP so maybe it's about 30 CHF.
So there turns out to be an incredibly thin price range in which the simple
touch-to-pay system actually works. Most of the time, either they:
a) Reject cards entirely because the payment is too small
b) Don't have the right hardware, or the hardware just mysteriously fails
to work.
c) Require a PIN because the payment is too large
I'm sure Bitcoin can do better than this.

@_date: 2014-03-10 18:50:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Multisign payment protocol? 
No, this doesn't make any sense. Multisig outputs are a tool you use to
build helpful features, not a feature in and of themselves.
By all means create a nice protocol, implementation and BIP for something
- Creation of multi-user money pools for managing an organisations funds
- Dispute mediated transactions
- Watchdog services that provide a third party risk analysis of transactions
- Micropayment channels (actually me and Matt already did this, sans BIP)
but trying to do just "multisig" won't work well.

@_date: 2014-03-11 16:18:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Multisign payment protocol? 
You can follow HDW progress in bitcoinj on this branch:
  I've been working on it for a couple of months now. Electrum (Thomas V) is
also making good progress, and Trezor already uses HD wallets. I think most
popular end user wallets except blockchain.info and Bitcoin Core will
support HDW soon enough.
At any rate, as Gavin said already, the best way to make a feature you want
happen is just to write it. Devrandom is already working on a watchdog
service, as is another group (TrustedCoin), and that's an obvious use for
multisig/p2sh. They have API's already, it's just a case of standardising
them once we get more experience.

@_date: 2014-03-12 10:48:01
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Multisign payment protocol? 
Good to see so much activity! But please do remember, there's more to "multisig" than just keys - you need the whole user experience to be planned out and specced for fully interoperable implementations.
For the "group account for an organisation" feature, you don't really want to expose end users to the notion of a key. Historically this has just led to confusion (and an ugly visual explosion of padlocks and small metal objects :) It'd be much better for the UI to be designed in terms of people, perhaps with a bit of social network integration to avoid having to set up profiles, and then a "group spend" feature would behind the scenes rendezvous with the others and swap signatures around, etc.  So for interop, you'd need to define all the rendezvous protocols as well.
I don't know how you are implementing this/what framework you're using, but I suggest using placeholders that are the length of an actual expected signature, at least when forming the transaction. This is what bitcoinj will do because otherwise you could end up miscalculating the fee, which is based on the final size. See TransactionSignature.dummy() in the API.

@_date: 2014-03-12 17:02:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Multisign payment protocol? 
What happens if the act of filling out the signature pushes the transaction
into a higher fee level?

@_date: 2014-03-12 17:14:25
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Multisign payment protocol? 
Sure of course. You assume each signature to be placed in the tx is 73
bytes. Not very hard, but if the tx you get back from the API doesn't
contain such a 73-byte sentinel value then it's harder to be sure that this
part was done correctly.

@_date: 2014-03-12 17:41:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Multisign payment protocol? 
Well, we'll have to make sure this is carefully and loudly documented in
the new developer part of the website that's being worked on. Because this
seems like a recipe for people writing flaky apps. In practice it would
seem like you need to implement the fee loop in your own app:
1) Create tx with an estimated fee level
2) Add signatures
3) Submit. If REJECT for too low fees, increment, go to 1 and try again.

@_date: 2014-03-13 14:31:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] moving the default display to mbtc 
The standard has become mBTC and that's what was adopted. It's too late to
try and sway this on a mailing list thread now.

@_date: 2014-03-13 14:53:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] moving the default display to mbtc 
BitPay should use mBTC as well. Unless you can point to any major wallets,
exchanges or price watching sites that use uBTC by default?
I think it is highly optimistic to assume we'll need another 1000x shift
any time soon. By now Bitcoin isn't obscure anymore. Lots of people have
heard about it. Getting from $1 to $1000 was amazing, but it was possible
through huge media coverage. Getting from $1000 to $1,000,000 would take
massive adoption of the kind Bitcoin isn't ready for yet.

@_date: 2014-03-13 16:50:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] moving the default display to mbtc 
That ship sailed months ago. If you wanted a big push for uBTC, then would
have been the time. Though given that it'd have made lots of normal
balances incredibly huge, perhaps it's a good thing that didn't happen.
Also "milli" is a unit people encounter in daily life whereas micro isn't.
Is it milli / micro / nano or milli / nano / micro? I bet a lot of people
would get that wrong.
If you have to export to financial packages that can't handle fractional
pennies, then by all means represent prices in whatever units you like for
that purpose, but in software designed for ordinary people in everyday life
mBTC is a pretty good fit.
Besides, fractional pennies crop up in existing currencies too (the famous
Verizon Math episode showed this), so if a financial package insists on
rounding to 2dp then I guess it may sometimes do the wrong thing in some
business cases already.
Fundamentally, more than two decimal places tends to violate the
Lots of people use currencies that don't have any fractional components at
all ! So perhaps all prices should be denominated in satoshis to ensure
that they're not surprised :)
The (number) line has to be drawn somewhere. Wallets are free to suppress
more than 2dp of precision and actually Andreas' app lets you choose your
preferred precision. So I think in the end it won't matter a whole lot, if
the defaults end up being wrong people can change them until wallet authors
catch up.

@_date: 2014-03-13 18:13:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] moving the default display to mbtc 
This is subjective though. To me the first price looks like the price of a
cup of coffee (or I just mentally double it). The second looks like the
price of an expensive holiday.
If users really find this so terrible, merchants have a simple solution: do
the rounding before presenting the price. Then the price looks like "3.12
mBTC" which is sort of what I'd expect it to look like. But some wallets
already make digits >2dp smaller so visually you can get precision whilst
still looking similar to what you might expect (this is what Bitcoin Wallet
That's the good argument!

@_date: 2014-03-13 18:24:25
@_author: Mike Hearn 
@_subject: [Bitcoin-development] moving the default display to mbtc 
Unfortunately I think some people already started using XBT to mean the
same as BTC (another ship that sailed: somehow Bhutan will have to live
with it). So if some software started to redefine it to mean something
else, that seems like a recipe for accidentally sending far too much or too
little money by mistake.
The whole area of symbols, denominations etc is a confusing mess right now,
it opens up the potential for mistakes and makes Bitcoin look
unprofessional. Part of the reason I don't want us to revisit this at the
moment is we need to grab onto any consistency we can get. People want to
think in terms of a single unit. BTC vs mBTC is already bad enough, it'd be
easy to miss the denomination and do some sums wrong. Introducing a third
unit, especially one that skips the intervening nanoBTC, seems like a way
to make mistakes even more common!

@_date: 2014-03-13 18:51:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] moving the default display to mbtc 
Hmm - be careful with the word "consensus" here. A bunch of people on a
mailing list does not make consensus ;)
If you survey other wallets, you'll find most already switched to mBTC,
that it took some effort to do so (look at the size of the patches for
instance) and that probably, nobody is super-keen to change again so soon.
So uBTC would make you different to most of the other wallets and services
in wide usage.
If Armory wants to do that, that's no problem, maybe it will be a
competitive advantage - just saying, don't quote this thread as indicating
some kind of community consensus.
Wallets and services that are using mBTC (that I know of)
Bitcoin Wallet (Android)
KnC Wallet (defaults to BTC but can be switched to mBTC in settings, uBTC
not an option)
Doing a google search for [bitcoin "mBTC"] and [bitcoin "uBTC"], the former
has a bunch of sites and services with prices in mBTC. The latter only has
faucets, as far as I can tell, which sort of makes sense.

@_date: 2014-03-13 19:29:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] moving the default display to mbtc 
We shouldn't make any assumptions about the future price of bitcoin to make
Hmmm ;) Didn't you just make an assumption about the future price?
The currencies I'm familiar with are CHF, USD, EUR and GBP, which all have
roughly similar values. I guess such currencies make up the bulk of the
Bitcoin userbase at the moment.
Saying "it's already popular and would take work to change" is not really a
fallacy now, is it?
But anyway, this is getting silly. You don't have to convince me. Go visit
all the services I listed above, plus all the ones I didn't find in my five
minutes of searching, and convince them they're wrong like the flies and
switching is the best use of their time :o

@_date: 2014-03-14 16:32:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] moving the default display to mbtc 
The issue here is that most people are producing prices in BTC by just
multiplying through the spot rate with full precision. Obviously if you
converted dollar prices to Euro prices with the same technique, you'd also
end up with lots of numbers after the decimal point, but in the real world
nobody actually does this. They always "prettify" the price.
This practice often annoys people because they feel like they get short
changed. The most notorious example is Apple which likes (liked?) to charge
99 cents per iTunes song in the USA, and 99 pennies per song in the UK,
despite that the British pound is worth a lot more than the dollar. It
should be more like 60 pence.
Nothing stops BitPay rounding the mBTC price to look more natural, but
right now it's not common practice.
On Fri, Mar 14, 2014 at 4:02 PM, Andreas Schildbach

@_date: 2014-03-20 11:36:09
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Encoding entire payment requests into qrcodes is definitely not the way to
go. They can already be large when signed and we're just at the start of
adding features.
Finishing off and standardising the bluetooth support is the way to go
(r=bt:mac). Andreas' app already has some support for this I believe, so
Alex you could prototype with that, but we need to:
1) Add an encryption/auth layer on top, because it runs over RFCOMM
sockets. The authentication would require proof of owning the Bitcoin key
that's in the address part of the URI (which is needed for backwards compat
2) Write a BIP for it and make sure it's interoperable
For the auth layer we could either use SSL and then just ignore the server
certificate and require signing of the session public key with the Bitcoin
key, which should be easy to code up but is rather heavy on the air, or
roll a custom lightweight thing where we just do a basic ECDH, with the
servers key being the same as the address key. But rolling such protocols
is subtle and I guess it'd need to be reviewed by people familiar with such
This feels like a good opportunity to grow the community - perhaps we can
find a volunteer in the forums who enjoys crypto.

@_date: 2014-03-20 13:20:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Very, very limited. The more data you stuff in them, the less reliable and
slower scanning becomes. A URL is about the limit of what's practically
achievable. Even with that, BitPay have been complaining about the
increased character length from adding the https url to download the
payment request (though not escaping reduces character count by a lot and
is valid).
X.509 is extremely bloated, partly due to the number of features it
supports, partly due to its history but mostly due to the widespread use of
RSA which generates giant keys and signatures. Of course you can get ECC
certs as well, but in practice most merchants don't seem to use them yet.
There's no way you can fit a cert chain into a QR code.
However, this is no big deal, because for the serverless PoS device case
Alex cares about you need a backchannel to submit the transaction and
refund address anyway, so Bluetooth is already useful/required. Downloading
the payment request via it as well as uploading the response is not a big
change and - as mentioned - already implemented by Andreas and myself some
time ago.

@_date: 2014-03-20 19:31:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
With Java, in theory, you can use SSLSocketFactory.createSocket(btsocket,
address, 1234, true) to wrap a bluetooth socket in SSL. However I have not
tried it.
For now, just prototype and build your product without the security. We can
find someone to experiment with this, if you don't want to .
Bluetooth needs encryption and MACs as well as signing to be secure,
because there could be radio MITM. Yes, this overlaps somewhat with the PKI
signing in BIP70, but not entirely - you might want to serve unsigned
payment requests, but still have confidentiality and authenticity for a
local face to face transaction. The signing and encryption does different

@_date: 2014-03-21 00:02:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
I'd hope that people can get certs for their actual business name, but
sometimes it does differ yes.
However remember that signing in BIP70 is about more than just security,
though that's the driving factor. It's also needed for things like dispute
mediation, receipts, etc.

@_date: 2014-03-21 12:08:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
If you want to create and run a new CA, by all means. But I bet you don't.
So we're stuck with the current system for now.
But you have to chain up to the root.
The only reason more certs aren't ECC is backwards compatibility. Some old
browsers don't know how to handle them. It wasn't so long ago that Fedora
and Android were deleting ECC code from upstream libraries before shipping
them, either for patent reasons for disk space saving measures.
But it's possible to get ECC certs if you want. For example, Entrust is
starting to sell them:
But their intermediate cert is still RSA. My understanding is that ECC
roots for many CA's have been submitted and are now included, but of course
"give up compatibility with lots of users" vs "save a bit of cpu time and a
handful of bytes" is no real competition so it will be a long time until
most websites are using ECC certs.
Regardless, it's all irrelevant. Who knows when we might want to add
another feature that uses some bytes into PaymentRequests. Stuffing them
into a QR code will never make much sense IMO - it's far more sensible to
just use Bluetooth where the data size constraints are so much easier.

@_date: 2014-03-21 12:09:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Post to list request 
Sounds very relevant to what we were just discussing on the other thread,
about securing Bluetooth connections and BIP70.
On Fri, Mar 21, 2014 at 11:58 AM, Andreas Schildbach

@_date: 2014-03-21 12:33:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Oh, one other reason I found - apparently RIM, at least in the past, has
been telling CA's that they need to pay mad bux for the Certicom ECC
patents. So that's another reason why most certs are still using RSA.

@_date: 2014-03-21 14:07:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Maybe so, but given the relatively minor advantages of ECC certs I can see
why a CA might not want to take any risks. They are sitting ducks for
patent trolls.
I think ECC will still happen, though we end up back into NSA fear
territory thanks to the stupid way secp256r1 was defined. *Hopefully* there's
no back door.

@_date: 2014-03-21 16:24:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
SPDY requires SSL and is even more complex than HTTP.
Really, the current protocol we've got (length prefixed protobufs) is just
fine except for the lack of encryption/authentication. For that you need to
do ECDH to establish a shared AES session key, and MAC each packet. Like I
said, it's not entirely trivial which is why it's worth trying SSL too, but
it's also not a massive effort.
On Fri, Mar 21, 2014 at 4:20 PM, Andreas Schildbach

@_date: 2014-03-22 17:45:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
The usual issue is that they lack internet *for some customers*. The place
may well have private wifi or hardwired connections that work. Even mobile
networks may vary so some customers will have mobile connectivity and
others won't.

@_date: 2014-03-22 18:03:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fake PGP key for Gavin 
In case you didn't see this yet,
If you're using PGP to verify Bitcoin downloads, it's very important that
you check you are using the right key. Someone seems to be creating fake
PGP keys that are used to sign popular pieces of crypto software, probably
to make a MITM attack (e.g. from an intelligence agency) seem more
I think the Mac DMG's of Core are signed for Gatekeeper, but do we codesign
the Windows binaries? If not it'd be a good idea, if only because AV
scanners learn key reputations to reduce false positives. Of course this is
not a panacea, and Linux unfortunately does not support X.509 code signing,
but having extra signing can't really hurt.

@_date: 2014-03-22 18:30:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
I think it's mostly a UI issue. The recipient needs to understand that what
he received is nothing more than an IOU that can be revoked at any time. If
the UI makes it clear and the user trusts the sender, no problem. BIP70
would work as before.

@_date: 2014-03-25 16:20:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Tree-chains preliminary summary 
A few months ago I had a conversation with an executive at a Bitcoin
company, and I suggested their developers should get involved with the
development list. I was told that they are all subscribed but refuse to
post. Puzzled, I asked why, maybe the process isn't clear or we didn't talk
about what they were interested in? No, it's because in that executives
words "They see how Peter Todd shoots people down in flames and want
nothing to do with that".
Peter, you were named explicitly as the source of the problem. Your
immediate knee-jerk reaction to anyone who disagrees with you is making
this forum aggressive and ugly - it puts other people off from
contributing. For what it's worth, if I were the moderator of this list I
would have banned you a long time ago because I value a friendly atmosphere
more than your "insights", which are often deeply suspect (as in this case).
Besides, ground up redesigns of Bitcoin like what you propose are more
appropriate for bitcointalk. So please take it there.

@_date: 2014-03-26 14:07:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Sudden temporary drop in reachable nodes? 
Hey Addy,
I am seeing a big drop in reachable nodes on
 starting from about March 25th 7:20pm
and coming back 9:35pm. Is this a glitch in the monitoring system or did
some real network event happen then?

@_date: 2014-03-26 21:49:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure 
Myself, Thomas V (Electrum) and Marek (Trezor) got together to make sure
our BIP32 wallet structures would be compatible - and I discovered that
only I was planning to use the default structure.
Because I'm hopeful that we can get a lot of interoperability between
wallets with regards to importing 12-words paper wallets, we brainstormed
to find a structure acceptable to everyone and ended up with:
  /m/cointype/reserved'/account'/change/n
The extra levels require some explanation:
   - cointype:  This is zero for Bitcoin. This is here to support two
   things, one is supporting alt coins based off the same root seed. Right now
   nobody seemed very bothered about alt coins but sometimes feature requests
   do come in for this. Arguably there is no need and alt coins could just use
   the same keys as Bitcoin, but it may help avoid confusion if they don't.
   More usefully, cointype can distinguish between keys intended for things
   like multisig outputs, e.g. for watchdog services. This means if your
   wallet does not know about the extra protocol layers involved in this, it
   can still import the "raw" money and it will just ignore/not see the keys
   used in more complex transactions.
   - reserved is for "other stuff". I actually don't recall why we ended up
   with this. It may have been intended to split out multisig outputs etc from
   cointype. Marek, Thomas?
   - account is for keeping essentially wallets-within-a-wallet to avoid
   mixing of coins. If you want that.
   - change is 0 for receiving addresses, 1 for change addresses.
   - n is the actual key index
For bitcoinj we're targeting a deliberately limited feature set for hdw v1
so I would just set the first three values all to zero and that is a
perfectly fine way to be compatible.
The goal here is that the same seed can be written down once, and meet all
the users needs, whilst still allowing some drift between what wallets
Pieter made the I think valid point that you can't really encode how keys
are meant to be used into just an HDW hierarchy and normally you'd need
some metadata as well. However, I feel interop between wallets is more
important than arriving at the most perfect possible arrangement, which
feels a little like bikeshedding, so I'm happy to just go with the flow on
this one.

@_date: 2014-03-26 23:56:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Yeah, for those cases we'd need to think of something else. That gets into
the realm of creating our own infrastructure though ...

@_date: 2014-03-27 10:42:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure 
At this point I'm not sure how much further work people want to do on this:
I got the impression that Trezor will ship soon, and Thomas V seemed
satisfied too. I'm not sure we can get all wallets to be fully
interoperable given the flexibility inherent in BIP32 and people's
differing use cases.
Andreas: good point but I really hope nobody ever deletes a seed after all
this work we put in to make backups so easy! I'm not sure we can really
stop it anyway: not unless we make the seed a full blown data structure
with hints to other apps that they should refuse to load it. And it's a bit
late for that now.

@_date: 2014-03-27 11:08:22
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Payment Protocol for Face-to-face Payments 
Well, you're lucky, you live in Berlin. Most of the payments I make with
Bitcoin are online, to websites. So this will differ between people.
I wonder how critical it is. Let's say you are paying for a meal. In your
head the place you're at is just "the little Indian restaurant on the
corner". In the companies register and therefore certificate it's something
like "Singh Food GmbH". That's probably good enough to prevent shenanigans.
Even if there's a virus on your phone, it can't really replace the cert
with a random stolen one, otherwise your meal could show up like "IronCore
Steel Inc" or something that's obviously bogus. It'd have to be an
incredibly smart virus that knew how to substitute one name for a different
one, from a large library of stolen identities, such that the swap seemed
plausible. That sounds very hard, certainly too hard to bother with for
stealing restaurant fees.
And if a waiter at the restaurant is corrupt and they replace the cert with
one that's for their own 1-man business "BP-Gupta" or something, OK, you
might pay the wrong person by mistake. But eventually the corrupt waiter
will be discovered and then someone will have proof of what they did. It's
FAR more likely they'd just strip the signature entirely and try to
convince you the restaurant doesn't use BIP70 at all.
Still, if we want to fix this, one approach I was thinking about is to have
a super-cheesy CA just for us that issues certs with addresses in them, for
any name you ask for. That is, if you say you want a cert for "Shamrock
Irish Pub, Wollishofen, Zurich, CH" then it either sends a postcard to that
address with a code to check ownership of the address, or it checks
ownership of the place on Google Maps (which does the same postcard trick
but for free!).
That doesn't work for vending machines, but perhaps we just don't care
about those. If a MITM steals your lunch money, boo hoo.

@_date: 2014-03-27 12:39:21
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure 
This is surprising and the first time I've heard about this. Surely your
constraint is CPU or disk seeks? Addresses are small, I find it hard to
believe that clients uploading them is a big drain, and mostly addresses
that are in the lookahead region won't have any hits and so won't result in
any downloads?
This constraint is not so important for bloom-filter clients.
Bloom filters are a neat way to encode addresses and keys but they don't
magically let clients save bandwidth. A smaller filter results in less
upload bandwidth but more download (from the wallets perspective). So I'm
worried if you think this will be an issue for your clients: I haven't
investigated bandwidth usage deeply yet, perhaps I should.
FWIW the current bitcoinj HDW alpha preview pre-gens 100 addresses on both
receive and change branches. But I'm not sure what the right setting is.
We also have to consider latency. The simplest implementation from a
wallets POV is to step through each transaction in the block chain one at a
time, and each time you see an address that is yours, calculate the next
ones in the chain. But that would be fantastically slow, so we must instead
pre-generate a larger lookahead region and request more data in one batch.
Then you have to recover if that batch ends up using all the pre-genned
addresses. It's just painful.
Maybe. I dislike any distinction between users and merchants though. I
don't think it's really safe to assume merchants are more sophisticated
than end users.
I think such synchronization won't be possible as we keep adding features,
because the block chain cannot sync all the relevant data. For instance
Electrum already has a label sync feature. Other wallets need to compete
with that, somehow, so we need to build a way to do cross-device wallet
sync with non-chain data.

@_date: 2014-03-27 13:28:49
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure 
By the way, I just noticed that greenaddress.it is creating seeds that have
24 words instead of 12. Does anyone know what's up with that? They claim to
be using BIP32 wallets so I wanted to see if they were using the default
structure and if so, whether bitcoinj was compatible with it (before I
switch to the one discussed here). But it seems we fall at the first hurdle

@_date: 2014-03-27 13:49:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure 
Ah, BIP32 allows for a range of entropy sizes and it so happens that they
picked 256 bits instead of 128 bits.
I'd have thought that there is a right answer for this. 2^128 should not be
brute forceable, and longer sizes have a cost in terms of making the seeds
harder to write down on paper. So should this be a degree of freedom?

@_date: 2014-03-27 14:19:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure 
Obviously, SHA256 can't magically generate more entropy out of nothing, it
just stretches whatever is put in. If your seed was only 32 bits then
hashing wouldn't save you: every possible private key could easily be
calculated in advance.

@_date: 2014-03-27 14:38:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure 
Yes that sounds more like what I expected.
An address is 160 bits. (1000 * 160) / 8 / 1024 = 19.5 kilobytes of data
which 3G should be able to transfer in <1 second easily. Of course the
encoding may not be optimal. But if it is, I suspect the issue is elsewhere.

@_date: 2014-03-27 15:20:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP32 structure 
For SPV wallets it's more complicated. There must always be a large
lookahead window for latency reasons. We can't query the entire database
because we don't know how far ahead the user is. So we have to assume there
might be a lot of transaction traffic and create a large window, to reduce
the chances that we run out whilst syncing and have to abort/restart the
sync after resetting the Bloom filter.
If you have a full db index then you can calculate some addresses, query,
if they all get hits, calculate some more, requery, etc. It's a bit simpler.

@_date: 2014-03-28 12:07:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
Modern devices like smartphones and tablets do not have swap files. This
design is chosen to ensure responsive, fluid UI that can avoid blocking on
disk regardless of how much multi-tasking is done, but it creates ripples
that impact everything else.
One implication of this is that on these devices, we cannot store all keys
or transactions in memory forever. BIP 70 has an expiry field for
PaymentRequests that we can use to allow us to eventually stop loading
those keys into RAM - at that point payments to those keys would no longer
be recognised. But there's no equivalent for refund addresses.
More generally, though we re-used the output structure to define the
refund, we didn't (for some reason that I forgot) reuse PaymentDetails,
even though the payment details for a refund are indeed PaymentDetails.
Though I am loathe to go back and redesign this part of BIP 70 so soon
after we shipped v1, it seems to me like the refund feature may be hard to
implement on phones if there's no time limit for when you can receive a
refund. Otherwise a wallet has to be looking out for refunds for payments
you may have made years ago. So perhaps we should add a new refund field
that embeds a PaymentDetails structure instead of being just a list of
We could try and solve this problem some other way purely internally, by
doing a kind of wallet-specific swapping process in which things like Bloom
filters are calculated without all keys in them being held in memory at
once (perhaps caching filters for old parts of the key chain on disk), so
you can have "infinite" wallets, but eventually the huge Bloom filters that
would result would hurt efficiency in other ways. So key expiry seems
pretty fundamental to scalability.

@_date: 2014-03-28 12:31:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
You don't need all the fields indeed, but they're mostly optional (except
time). So for the refund you'd fill out:
outputs (same as today)
You're probably aiming for an expires field? How would you refund a
It'd have to be ad-hoc at that point. OK, you don't get the nice UI that
the refund field provides. Oh well. It should be rare to get refunds very
very late after the purchase.
Yes indeed as is the rest of the Payment structure. We talked about signing
it with one of the keys that's signing the Bitcoin transaction as well. But
it seems like a bit overkill. Usually it'll be submitted over HTTPS or a
(secured!) Bluetooth channel though so tampering with it should not be
However this does raise the question of whether a refund should be a full
blown PaymentRequest with optional PKI signing. Normally, I think, a seller
does not know or care about the identity of a buyer for refunds, outside of
their own tracking system.

@_date: 2014-03-28 12:46:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
I don't want to manage a "business relationship" with every shop I buy
something from. That's way too much effort. There can certainly be cases
where a more complicated relationship is created by bootstrapping off
BIP70, perhaps with an extension, but nailing the ordinary buyer-to-seller
relationship seems like a good scope for BIP70 for now.

@_date: 2014-03-28 13:27:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
I think that'd be too abstract. The purpose of the refund field is that so
if/when you receive a payment there, the wallet UI can do something
intelligent, like show you in your transactions list that a certain payment
was refunded using language the user will understand. If it's modelled at
the protocol level without that then it makes producing good UI's harder.

@_date: 2014-03-28 14:00:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
How is this any different? The tag in this case is the address and the
payment is being delivered by the block chain (direct submission for
user->merchant is easier than merchant->user) so we can't stuff extra data
anywhere else. Then the UI knows it was a refund payment and not for
anything else.
I don't see the relevance of VAT here.

@_date: 2014-03-28 15:06:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
Yeah. Though there's actually a proposal for recurring payments from the
KillBill folks. I keep bugging BitPay to review it but it seems they're
lagging behind there, so perhaps we should just move ahead with that
candidate extension.

@_date: 2014-03-28 16:23:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
So I take it BOPShop won't be supporting BIP70 then? :(

@_date: 2014-03-28 17:34:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
So, if e.g. Trezor ships a firmware update that uses BIP70 to present
signed payment identities on the screen, would you support it then?

@_date: 2014-03-28 19:19:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
Yeah I was thinking something like that on the walk home. But 2 years is
a long time. Do we have enough RAM for that? Plus warranties usually
result in the defective goods being replaced rather than a monetary
refund, right?
But adjusting the spec so there's a fixed time limit, and allowing a
future version of the protocol to make it configurable, does indeed feel
like the right way to go.

@_date: 2014-03-29 14:29:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 refund field 
<5335BD17.6050408
So how about we say two months? That way it's easy for merchants to comply
with the EU DSD and we keep RAM usage in check until we come up with a more
sophisticated refund scheme.
There's another issue with BIP 70 and refunds that I noticed. The
PaymentRequest doesn't specify whether refunds are possible. So wallets
have to either never submit refund data, or always submit it even if it
makes no sense. Because setting things up to get refunds has a non-zero
cost for the sender, it'd help if we could optimise it away for merchants
that simply refuse to issue refunds for whatever reason.

@_date: 2014-03-29 14:30:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 and OP_RETURN 
They would just encode the OP_RETURN script into an Output structure. I'm
not sure about the question - you seem to give the answer yourself in the
first paragraph?

@_date: 2014-03-29 14:36:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Presenting a BIP for Shamir's Secret 
Right - the explanation in the BIP about the board of  directors is IMO a
little misleading. The problem is with splitting a private key is that at
some point, *someone* has to get the full private key back and they can
then just remember the private key to undo the system. CHECKMULTISIG avoids
I can imagine that there may be occasional uses for splitting a wallet seed
like this, like for higher security cold wallets, but I suspect an ongoing
shared account like a corporate account is still best off using
CHECKMULTISIG or the n-of-m ECDSA threshold scheme proposed by Ali et al.

@_date: 2014-03-29 16:04:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Presenting a BIP for Shamir's Secret 
Nobody is exactly thrilled by IsStandard, but it's not a deal-killer. If
you have a use for a new type of script it can be added, and people do
As you can see the 0.9 rollout is going OK. If a new script type had been
made standard for 0.9 like OP_RETURN was, I'm guessing it'll only be
another month or so and it'll be quite usable.

@_date: 2014-03-29 16:06:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP 70 and OP_RETURN 
They should do. If they don't they're not spec compliant. I'm not sure what
they actually do though. Currently only Bitcoin Core and Android Bitcoin
Wallet implement BIP 70 so you can just create such a request and then try
it out and see what happens.

@_date: 2014-05-02 17:39:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 implementation guidance 
A bunch of different people either have implemented or are implementing
BIP70 at the moment. Here's a bunch of things I've been telling people in
response to questions. At some point I'll submit a pull req with this stuff
in but for now it's just an email.
*Error handling during signature checking*
I've had queries around the right behaviour here. BIP 70 is underspecified
and we should fix it IMO. If PKI checking fails you should just treat the
request as if it's unsigned. The reason is that there is no incentive for
an attacker to break the signature instead of just removing it entirely, so
an attacker would never trigger any error flows you put in. However,
someone who is signing their request with an unknown CA or using an
upgraded version of the protocol that isn't entirely backwards compatible
*could* trigger signature checking failure.
Therefore, in order to make introducing new (possibly community run) CA's
or new variations on signing possible, please treat any errors as if there
was no signature at all. This is not what browsers do,  but browsers have
an advantage - they were already given an identity and told to expect a
secure protocol when the user typed in the web address with an
 (or clicked a link). Unfortunately a Bitcoin wallet has
no context
like this.
One person asked me whether this makes the whole scheme pointless because a
MITM can just delete the signature. The answer is no - downgrade attacks
are always possible on systems that start out insecure. The solution is to
train users to expect the upgrade and refuse to go ahead if it's not there.
Training users to expect signed payment requests will be a big task similar
to the way the browser industry trained users to look for the padlock when
typing in credit card details, but it must be done.
Because wallets lack context there's no equivalent to HSTS for us either.
So in your GUI's try to train the user - when showing a signed payment
request, tell them to expect the recipient name to appear in future and
that they should not proceed if it doesn't. This gives us a kind of mental
*Extended validation certs*
When a business is accepting payment, showing the name of the business is
usually better than showing just the domain name, for a few reasons:
   1. Unless your domain name *is* your business name like blockchain.info,
   it looks better and gives more info.
   2. Domain names are more phishable than EV names, e.g. is the right name
   bitpay.com or bit-pay.com or bitpay.co.uk?
   3. More important: Someone who hacks your web server or DNS provider can
   silently get themselves a domain name SSL cert issued, probably without you
   noticing. Certificate transparency will eventually fix that but it's years
   away from full deployment. It's much harder for a hacker to get a bogus EV
   cert issued to them because there's a lot more checking involved.
EV certs still have the domain name in the CN field, but they also have the
business name in the OU field.
In theory we are supposed to have extra code to check that a certificate
really was subject to extended validation before showing the contents of
this field. In practice either bitcoinj nor Bitcoin Core actually do, they
just always trust it. It'd be nice to fix that in future.
You should show the organisation data instead of the domain name if you
find it, for EV certs.
Signing is optional in BIP 70 for good reasons. One implementor told me
they were considering rejecting unsigned payment requests. Do not do this!
A MITM can easily rewrite the bitcoin URI to look as if BIP70 isn't in use
at all.
Even though today most (all?) payment requests you'll encounter are signed,
it's important that signing is optional because in future we need
individual people to start generating payment requests too, and many of
them won't have any kind of memorisable digital identity. Plus other people
just won't want to do it. BIP70 is about lots of features, signing is only
*S/MIME certs*
Email address certs look a bit different to SSL certs. You can get one for
free from here
    In these certs the display name can be found in the Subject Alternative
Name field with a type code of 1. Example code:
You won't encounter many of these today except on Gavin's test site, but in
future people may wish to start creating and signing their own payment
requests for individual purposes using these certs (especially as they are
free). So please try to handle them correctly.
*Broadcast vs upload*
Please upload transactions and commit them to your wallet when the server
responds with 200 OK, but expect the merchant to broadcast them. Don't give
the user an option to pick - it's pointless as there's no obvious right
You can find a test site here:
It's testnet only. For testing regular payment requests on the main
network, I use BitPay as they were the first seller-side implementation:
*Memo contents*
Please put something useful here, ideally what is actually being sold but
failing that, the name of the merchant if you're a payment processor. Don't
be like BitPay and put large random numbers in the memo field but nothing
about what's actually purchased.
This is not particularly important today except for cosmetic reasons,
because wallets don't store the payment requests they saw to disk. But in
future they will and then a properly signed memo field + the transactions
used for payment give us a digital receipt. Receipts are useful for things
like filing expense reports, proving a purchase when returning an item to a
merchant, etc.
*Expiry times*
Don't be too aggressive with these. Although today it doesn't matter much,
some users may be trying to pay from multi-party accounts that require
multiple humans to coordinate to make a payment.

@_date: 2014-05-04 15:06:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70 implementation guidance 
Sole traders can just trade under their own name, or their email address,
or their domain name, heck even their telephone number if someone sets up
an SMS verifying CA. I don't worry too much about such things - the point
of the cert is just to disambiguate the payment so people can't get
confused into paying the wrong entity.
Companies that can't get EV certs cause us pain indirectly by making users
less certain about what they're expecting to see when they pay a company,
making confusion attacks a bit easier, but I bet it'll be a minor issue in

@_date: 2014-05-04 17:26:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal for extra nonce in block header 
Although I agree 32 bits for a version is overkill, I really don't like the
idea of you simply ignoring the protocol spec to try and reduce your own
costs. Especially because in future we should make unknown versions a
validation rule, so we can easily trigger hard forks.
If this change was introduced through a proper process and software was
properly upgraded to understand the new header format, that'd be one thing.
Arbitrarily exploiting what is IMHO a missing rule in the rule set to shave
a bit more profit is something else.

@_date: 2014-05-07 21:50:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Announcing the Statoshi fork 
Really nice! We definitely need to put together a team who really cares
about the operations side of the network and this is a fantastic start.
It'd be nice if you didn't assume knowledge of what statsd is out of the
box. Given the name I'd assumed it was a small UNIX daemon but it seems
it's actually a Javascript thingy?
It looks like putting together a monitored bitcoind setup can be quite a
lot of work. I wonder if there are ways to simplify it. For example, would
it make sense for someone to run a community statsd and graphite instance,
so we can get aggregate statistics across many nodes and the node operators
don't have to set everything up themselves? Does that make any sense?

@_date: 2014-05-07 22:12:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Announcing the Statoshi fork 
It looks like the packet format statsd expects is rather simple - it should
be easy to experiment with.
Perhaps a good next step would be to improve your patch so that someone can
get a feed of the stats packets via TCP by e.g. ssh tunnelling to their
host. Once it's easy to get a feed of simple stats packets, people can
easily experiment with different kinds of aggregation and monitoring
software from their desktop.

@_date: 2014-05-07 22:25:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Announcing the Statoshi fork 
I think there a few different possible ways to go here.
One is to try and simplify the setup of all the components so it all gets
installed together. That might be feasible in some quite restricted setups
but the installation instructions for Graphite look kind of terrifying.
Another is to export stats over regular TCP and make them public so
literally anyone can listen to the stats feed for any node. Then people who
dig stats and graphs could work on stats aggregators that give global
network visibility independently, effectively crawling the p2p network for
data. It'd have the advantage of having zero setup for the node operators
and not require much in the way of resources.
For what it's worth, although the environment is a bit different inside
Google the latter approach is used. Monitoring servers locate servers of
interest via a discovery service, connect to them and start streaming stats
data into a database service that can then be queried later to get graphs.
The stats are also run through various rules to obtain alerts about
problematic conditions. For example, if a subset of the network splits it
might be hard to notice that if the node operators aren't paying attention
and Matt's fork alert/emailing code isn't set up. But if there was a site
crawling nodes and aggregating chain heights by version, that could trigger
an alert to people who *are* paying attention.
I know from practical experience that monitoring and analysis tends to
appeal more to certain types of people than others. So I quite like the
"let anyone monitor" approach. However, it may not be appropriate in a P2P
network, I did not think about it much.
Obviously I'm assuming none of the stats expose privacy sensitive data.

@_date: 2014-05-08 12:08:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Announcing the Statoshi fork 
Yeah, it's somewhat similar, except that Tor directory authorities are
authenticated (the public keys are in the source code), whereas DNS seeds
aren't. Also Bitcoin puts way more emphasis on decentralisation than Tor
does. For Tor having a P2P network is just something that's needed in order
to build an anonymity network, but it's not actually the goal. For us,
decentralisation is pretty much the end goal.

@_date: 2014-05-09 14:05:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] ECDH in the payment protocol 
I wrote an article about an ECDH extension for BIP 70:
   The article is meant for people who don't follow bitcoin-development so
I'll summarise it here:
   - The notion of being able to publish a piece of data once and use it to
   receive lots of payments without any coordination is really useful. This is
   the idea behind the stealth address proposal.
   - Stealth addresses don't fit with the payment protocol, because they're
   a new kind of address (obviously).
   - Stealth addresses are not backwards compatible. If you give someone a
   stealth address and their wallet doesn't support it, they can't pay you,
   not even with worse privacy. Sometimes people may optionally want that
   behaviour but stealth addresses have it all the time.
   - The proposed stealth address design makes huge sacrifices to try and
   keep everything within the block chain. It bloats the chain with OP_RETURN
   stuff that isn't a part of the validation. But more seriously, the only way
   to make it efficient enough for lightweight clients is to reduce the
   "stealthyness". The more efficient you make your address the less private
   it becomes. This is somewhat similar to the dilemma we have with Bloom
   filtering, except Bloom filters are transient and can only be used to link
   addresses by someone who observes them on the wire. Stealth addresses
   record the relationship in the block chain forever.
   - The design makes these sacrifices to avoid moving data around outside
   the block chain. But with BIP 70 that's the direction we're heading in
   anyway. So by adding ECDH to the payment protocol and putting our effort
   into making BIP 70 work really well for everyone, we end up killing
   multiple birds with one stone. The same work that resolves the privacy
   problems inherent in the stealth address design also allows us to attach
   messages to payments and other commonly requested features.
There's a straw man in the article that I recreate here:
message Output {
   optional uint64 amount = 1 [default = 0];
   optional bytes script = 2;
   *optional boolean accept_ecdh = 3;  // Requires script to be a
pay-to-pubkey output.*
message Payment {
   optional bytes merchant_data = 1;
   repeated bytes transactions = 2;
   repeated Output refund_to = 3;
   optional string memo = 4;
   *repeated bytes ecdh_nonces = 5;*
The way the nonces are combined to arrive at the address could be the same
as in the current stealth address spec. A wallet that doesn't understand
ECDH but does understand raw BIP 70 would deliver the money to the base
address, which receiving wallets would look for too - so it's backwards
compatible. The nonces stay out of the block chain. The transactions are
delivered directly to the recipient so there's no problems with trying to
make it fit with Bloom/prefix filtering.
To make this work there obviously has to be a backchannel from payer to
payee. BIP 70 is mostly used by web shops today so that back channel is
just HTTPS to the website itself, but shops benefit less from ECDH than
others do. So we need a simple email-like store and forward network where
HTTP POSTs to a server get queued up and delivered later (or possibly
forwarded to another store-and-forward network like the Android push
network). Most of the article discusses how best to build such a thing.
The justification for the original stealth address design can be summed up
as "it's easier to [ab]use the Bitcoin network for delivery of short
messages than use a different system". But there are just so many features
we may want to add into the Payment message in future it seems better to
crack the SaF problem earlier rather than continue trying to jam a square
peg into a round hole. There are lots of very reliable SAF networks around
(email, instant messaging, etc) so it doesn't seem infeasible.
Thoughts welcome!

@_date: 2014-05-09 17:15:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] ECDH in the payment protocol 
Yes, I know you rejected this design, which is why I'm now proposing it
instead. I think you made the wrong design call, but at any rate, it's
something reasonable people can disagree on.
Payment messages are sent directly to the merchant, who takes
responsibility for broadcast. Once you delivered transactions to the
merchant successfully, from your perspective the payment is made. A good
store and forward network doesn't allow messages to go missing - email is
an example of that (ignoring spam filters that explicitly want messages to
go missing). It either gets delivered or it doesn't. So I'm not worried
about atomicity.

@_date: 2014-05-09 17:34:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] ECDH in the payment protocol 
Sounds great! How does a lightweight client identify such transactions
without any markers?
Regardless, there are lots of other useful features that require BIP70 to
work well person to person, like messages, refund addresses, etc. So
extending it with ECDH makes sense in the end anyway no matter what.

@_date: 2014-05-09 18:12:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] ECDH in the payment protocol 
Ah, I see, that's what I was missing. So rather than have an explicit
repeated field for nonces, have an algorithm for extracting randomness from
one of the scriptSigs. I guess that makes sense.

@_date: 2014-05-12 12:28:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Allow cross-site requests of payment 
It sounds OK to me, although we should all sleep on it for a bit. The
reason this header exists is exactly because mobile code fetching random
web resources can result in surprising security holes.
For this to be useful, someone would have to actually want to fully
implement the payment protocol (with its own root cert store, ASN.1
parsing, RSA etc) in browser-sandboxed Javascript rather than just
providing a real app for people to download.
Is that really going to be popular, though? I think it's unclear.

@_date: 2014-05-13 12:29:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] ECDH in the payment protocol 
I think you are right. Awkward.
Wallets could auto-respend transactions to a plain (private) HD derived key
to make them findable again. But that gets us back to using block space
Over time I think wallet backups will get more valuable anyway, as they
will start containing more and more essential data that isn't in the block
chain: receipts, messages, exchange rate records for tax purposes etc. But
being able to get access to your money with just the 12 words (+a date for
SPV wallets) is a pretty desirable safety feature.

@_date: 2014-05-13 12:30:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Regtest Address Version Change Proposal 
Yes, bitcoinj supports and uses regtest mode. It would also have to be
You didn't provide a rationale for this. What's the cost of having them be
the same?

@_date: 2014-05-13 13:28:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Regtest Address Version Change Proposal 
And they can't just do
  NetworkParams.TESTNET = NetworkParams.REGTEST
at the start of a program that is connecting to regtest?
It's not like changing the address code is a huge problem or anything, but
it would disrupt a bunch of people and seems kind of annoying. Surely
there's a simpler way to work around this issue on their side? I mean their
code already has to know what network is *expected*, right, otherwise what
stops you accidentally trying to send coins cross chain?

@_date: 2014-05-16 16:09:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] DNS seeds unstable 
My android wallet is working OK. Yes it isn't great when seeds have
temporary availability problems but things are still working.
There's a couple of pull reqs outstanding to include hard coded seed peers
and getaddr sourced IPs. Once those are finished and merged in there'll be
more backup paths.

@_date: 2014-05-19 14:15:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] About the small number of bitcoin nodes 
The problem is that this is easier said than done. Bitcoin Core won't
notice a remote peer is working but slow and switch to a faster one, and
even if it did, it'd just mean throttling your connection would cause all
remote nodes to give up and hit the other unthrottled peers even more.
The best way to implement this is to do chain pruning, so your node will
still try and shovel bytes as fast as possible, but it's limited by how
many bytes it has to shovel. Remote nodes that are pulling down the block
chain can then switch between nodes depending on what they have available
in order to try and avoid hitting one node too hard. Nodes that were
offline for a while and just catching up would prefer nodes that have less
of the chain.
It'd be great if someone could experiment with this. The first step is
extending the p2p protocol so addr broadcasts and version messages include
how much of the chain (counting blocks from the head?) the peer is willing
to serve, and then updating the downloading code so it tries to be smarter
about peer selection. Unfortunately all this work is sort of backed up
waiting for sipa to finish merging in headers-first downloading.

@_date: 2014-05-19 14:21:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Paper Currency 
Off topic aside, a bunch of us have lately started to think about the
atmosphere on this list and how to improve it. Nobody should have to fear
getting flamed or laughed at for proposing ideas, even if they turn out to
be silly ones. Gavin talked about this in his Bitcoin 2014 keynote and
asked for someone to solve the forum trolling problem.
I don't know if there are any silver bullets per se, but:
1) Please do keep ideas coming. It's easy to mute threads in any good mail
client for people who don't care. If anyone gets too aggressive, the rest
of us will remind them that this is unacceptable.
2) If you're willing to become a list moderator, please get in touch. Gavin
and I are looking for neutral people who are willing to keep up with this
list and help ensure the debate is civilised. Ideally moderation is not
necessary, but that's what we tried so far and we keep getting consistent
feedback from lots of people that it's not working.

@_date: 2014-05-19 14:28:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] About the small number of bitcoin nodes 
Well, I guess "hurting" the network is perhaps a bit dramatic. There are
already lots of ways the download process can go wrong and take days. Using
the torrent is much faster. But my understanding is that this will slow
down the bootstrap process for some people yes. Remote peers won't try and
download in parallel or anything like that.

@_date: 2014-05-19 14:53:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] About the small number of bitcoin nodes 
One thing we could consider as a short term solution (if headers
first+parallel downloading will take a while, which seems plausible) is to
add a service bit that says "I have chain data and am willing to Bloom
filter it for you, but I won't serve full block data", and then just
exclude all of those from the chain download logic. It should not be a deep
change to the code headers first is impacting, and would allow home users
who may have no tolerance for block chain uploads at all to still take part
and offer useful services to the network.
I know Pieter likes the idea of an "archival node" service bit, or
something like that. I'd been thinking that the stored chain height value
would be better, but perhaps we need to divorce "I have CPU and can filter"
from "I have bandwidth and can serve" more vigorously.

@_date: 2014-05-19 17:09:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] patents... 
IMO this list is fine for discussing such topics.
Here are some thoughts. I had to deal with patents at Google (my name is on
a few, not my choice unfortunately). Many aspects of patent law are deeply
unintuitive, so here's the crash course as I was given it.
The first rule of patents is *you do not go looking for patents*. US law is
written in a really stupid way, such that if you knowingly infringe,
damages triple. Because America uses the patent office as a revenue source,
basically everything you can possibly imagine is covered by some ridiculous
patent so if you go looking you will always find applicable patents on
every idea and then you end up potentially much worse off.
Most companies (Google certainly included) have therefore banned their
staff from reading patents, thus ensuring that the whole point of them, the
sharing of knowledge, doesn't actually function! And it's much better I
think if we follow the same policy. So *please do not ever mention that
suchandsuch is patented on this list*! When it comes to patent law,
ignorance is bliss. Patents are written in a heavily obfuscated manner such
that actually trying to learn from them is hard work anyway.
One reason I wrote up the contracts stuff when I did is to get it out there
into the public domain, so people couldn't patent the basics of the Bitcoin
protocol. It'll be much better for everyone if new ideas are just put right
out into the public domain. *Please do not patent Bitcoin related research
you do*, even if you think it's for the best:
1) Defensive patenting doesn't work. The whole idea was mutually assured
destruction, you hit me I'll hit you type of logic, but the prevalence of
shell/troll companies killed off that idea. Plus it turns out that big
companies are quite willing to sue each other into oblivion anyway. Once a
patent exists, it'll be used as a weapon by someone eventually, and
attempting to "fight back" is probably not a workable strategy. Far better
to ensure the material is simply unpatentable by anyone.
2) Patenting with the intention to sue people using Bitcoin in the same
way: well, if you plan to do this, there's not much to talk about .... you
won't make any friends this way.

@_date: 2014-05-19 20:40:25
@_author: Mike Hearn 
@_subject: [Bitcoin-development] patents... 
You can easily find examples that are not relevant to Bitcoin if you want
to discuss the patent system in general.
It is both appropriate and wise. Please keep discussion of Bitcoin-relevant
patents elsewhere.

@_date: 2014-05-19 20:49:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] patents... 
That case raised the bar a bit, but the core problem remains - if you learn
about a patent you definitely violate (and there is very likely to be at
least one and possibly many), via whatever means, then by continuing
business you become a wilful violator. Which makes sense: how could it be
any other way?
It still never makes sense to read patents. You can only lose.

@_date: 2014-05-19 22:06:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Working on social contracts (was: Paper 
Sorry. I will never agree to the concept of a relevant idea so dangerous it
cannot be discussed. That's medieval thinking. If you would like to create
a parallel development forum where people have to swear an oath not to
think bad thoughts, go right ahead and do so.
But I'm glad to see you correctly identified yourself as one of the people
causing problems on this list. Your vicious attacks are one of the reasons
we're now seeing threads that start with "I hope I don't get flamed or
laughed at for this idea but ...." which is totally unacceptable. I would
prefer you just unsubscribe, in the hope we get a second chance from some
of the potential developers we've lost.

@_date: 2014-05-20 10:42:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
Yeah I'm expecting port 8333 to go away in China at some point. Actually I
was expecting that years ago and was kind of surprised that the suppression
was being done via banks. Guess the GFW operators were just slow to catch

@_date: 2014-05-25 11:36:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cut-through propagation of blocks 
Although this is a somewhat appealing notion, would it really improve
feature velocity? I don't think the current p2p protocol is holding
anything back, and having to implement features twice in two protocols
would slow things down quite a bit.
Probably the lowest hanging fruit now is fixing the 100msec sleep and just
generally having tools to measure latency and queuing inside the code.

@_date: 2014-05-26 17:08:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Cut-through propagation of blocks 
Yes, it's certainly better to do that during the development phase. However
if it does turn out to be good and valuable then it'd eventually need to be
integrated or rewritten into Core anyway, lest we accidentally increase the
setup cost of running a node and end up with a two-tier network. And if the
code will eventually want to be merged into Core anyway, it might as well
be implemented into it directly, perhaps behind a switch that can disable
those codepaths if something goes wrong.
So I think the tradeoffs here are rather complicated and subtle.

@_date: 2014-11-04 14:38:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP62 and future script upgrades 
This is another problem that only exists because of the desire to soft
fork. If "script 2.0" is a hard fork upgrade, you no longer need weird
hacks like scripts-which-are-not-scripts.

@_date: 2014-11-07 17:52:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] The difficulty of writing consensus 
No, please don't. That question was rhetorical, not an invitation for you
to try and convince bystanders that anyone who disagrees with you is a
shadowy Agent Of Centralisation or an idiot. You use that tactic way too
much: it's obnoxious and you need to stop it.
Hard forks vs soft forks are *purely* about whether you drag along old
nodes in a quasi-broken state. They do not reduce total work needed by the
community one iota. Non-miners who wish to reject a soft fork can easily
run a node that does so, if they wanted to - the voting mechanism still
boils down to "which side of the fork do I accept in my economic activity".
It's certainly garbage to claim that the reason to want to avoid soft forks
is being an Evil Centralised Foundation:  this is about a set of
engineering tradeoffs only.

@_date: 2014-11-08 17:04:48
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Update on mobile 2-factor wallets 
Here is a summary of current developments in the space of decentralised
2-factor Bitcoin wallets. I figured some people here might find it
There has been very nice progress in the last month or two. Decentralised
2FA wallets run on a desktop/laptop and have a (currently always Android)
smartphone app to go with them. Compromise of the wallet requires
compromise of both devices.
Alon Muroch and Chris Pacia have made huge progress on "Bitcoin
Authenticator", their (HD) wallet app. The desktop side runs on
Win/Mac/Linux and the mobile side runs on Android. Sending money from the
desktop triggers a push notification to the mobile side, which presents the
transaction for confirmation. Additionally the desktop wallet has a variety
of other features like OneName integration. It's currently in alpha, but I
suspect it will be quite popular once released due to its focus on UI and
the simple mobile security model. I've tried it out and it worked fine.
    (mobile)
   (desktop)
Bitcoin Authenticator uses P2SH/CHECKMULTISIG to provide the 2-factor
functionality. However, this has various downsides that are well known:
 less support for the address type and larger transactions that waste block
chain space + result in higher fees.
To solve this problem Christopher Mann and Daniel Loebenberger from Uni
Bonn have ported the efficient DSA 2-of-2 signing protocol by MacKenzie and
Reiter to ECDSA, and implemented their own desktop/Android wallet app pair
showing that it works and has good enough performance. This means that P2SH
thus it's as cheap as using regular addresses.
Their protocol uses an interesting combination of ECDSA, Paillier
homomorphic encryption and some zero knowledge proofs to build a working
solution for the 2-of-2 case only. Their app bootstraps from a QR code that
includes a TLS public key and IP address of the desktop: the mobile app
then connects to it directly, renders the transaction and performs the
protocol when the user confirms. The protocol is online, so both devices
must be physically present.
Their code is liberally licensed and looks easy to integrate with Alon and
Chris' more user focused work, as both projects are built with Android and
the latest bitcoinj. If someone is interested, merging Christopher/Daniel's
code into the bitcoinj multisig framework would be a useful project, and
would make it easier for wallet devs to benefit from this work. I can write
a design doc to follow if needed.
Currently, neither of these projects implement support for BIP70, so the
screen you see when signing the transaction is hardly user friendly or
secure: you just have to trust that the destination address you're paying
to isn't tampered with. Support for sending a full payment request between
devices is the clear next step once these wallets have obtained a
reasonable user base and are stable.

@_date: 2014-11-08 17:37:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Update on mobile 2-factor wallets 
Yes. I think one of the next things we need is a library that produces nice
and attractive PDFs of "wallet certificates" so it's easy to print out a
paper backup.
But the whole field of secure key escrow needs more research. Banking gives
people the very nice property that you can lose literally everything except
your face and still retain access to your money, so people feel very safe
with that. Matching that experience doesn't seem possible at the moment, so
being your own bank will continue to seem much riskier than just using a
real one.

@_date: 2014-11-08 20:36:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Update on mobile 2-factor wallets 
No, it doesn't. Neither device ever sees as master private key.

@_date: 2014-11-18 12:06:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: PoW-based throttling of 
DKIM is hardly a PoW; signing is cheap and gets cheaper all the time. I
used to work in the email business and big bulk mailers all spent far more
CPU time on other aspects of their business, the overhead of DKIM is
PoW didn't work in the anti spam world because it (amongst other problems)
mixes up bulk mail and spam, which are not the same thing. Very common
conceptual error though.
They don't? This is news to me. Humans always care. One of the surest ways
to hurt your online business is to have a slow website because lots of
users will give up rather than tolerate a few seconds of latency. At Google
we actually had formulas that could relate a change in web search latency
to revenue impact.
So humans very much care! I actually doubt that any reasonable mobile
wallet will use the new Tor support bitcoinj by default, for example,
because it imposes quite some startup cost when the downloaded consensus
isn't fresh, and slow startup is painful. It could be optimised but nobody
has done that. For long running desktop wallets where startup time can be
amortised over hours or days, I guess it makes more sense.
I agree that PoW tokens might make sense as a last resort if nodes can't
even put a connection at the bottom of a priority queue and you're right
that it may be a useful tool in a shared toolbox. However if we reach the
point where users are all being PoWd then we're already pretty hosed and
it's probably close to game over :(
I'd say, better have a few Tor-based users realize that they
I think Tor is a separate issue. If an attacker wants to either force all
users off Tor, or force them via a handful of exits, then this attack is
quite detectable already and wallets could already decide to simply give up
on Tor at that point automatically. No PoW needed. Well, ideally, nodes
would disconnect a banned IP with some kind of notice saying why it was
banned, but that's a small improvement.
Still, users should be notified that something is unusual.
If we're talking mainstream success then users by and large do not care
about technical mumbo jumbo like peer to peer networks or Tor ("that's the
thing drug dealers and pedos use???"). They just want the damn thing to
work reliably. So notifying them is unhelpful - it's not actionable. They
would just see a message like
   "The wizzle sprocket is kaput - keep working? YES NO"
and then everyone presses yes.
Stuff like Tor plays well in the crypto community but it's very hard to
actually switch on by default, because it needs to have absolutely no cost
at all, otherwise you'll just annoy the vast majority who don't want to pay
for very abstract and hard to quantify privacy benefits.
So I think it's worth considering the DoS problem and Tor somewhat
separately, even though they're related. The solution to a crafty
privacy-attacking DoS that tries to make exits useless is don't use Tor at
all. The solution to "the entire Bitcoin network is under attack" is much
harder. It's unclear to me we can ever solve it convincingly - banks don't
connect together using private networks in which anonymity is forbidden
because they're stupid. They do it because it solves DoS attacks in one
solid move and they feel it's worth the high cost.

@_date: 2014-11-27 12:06:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Deanonymisation of clients in Bitcoin P2P 
Bitcoin already has a large population of users who have little or no
technical skill, it wouldn't surprise me at all if it was found to be the
clear majority by now. Assuming success and growth in future, very few
users will make any decisions at all about their privacy, they will just
accept the defaults. In such a world no consumer wallet is going to
directly expose Tor to end users - if used at all it'll just be used behind
the scenes. So automated fallback or control over exits would be a concern
for such wallets.
My gut feeling about this stuff has changed over time. I don't think it'd
be a great idea to tie Bitcoin to Tor too deeply, convenient though its
infrastructure is. Most apps don't need a whole lot of onion routing - a
small amount built in to the p2p layer would be sufficient. Tor is huge,
complicated and could be a liability in future.

@_date: 2014-10-03 14:49:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.12 
I?m pleased to announce version 0.12 of bitcoinj, one of the worlds most popular Bitcoin libraries. It is used by at least four Android wallets, three desktop wallets, blockchain.info, Circle, biteasy, CryptoCorp, Lighthouse, BlueMatt?s relay network, bitpos, countless alt coin wallets, for academic research projects and much more.
This release represents 8 months of work. The biggest new feature is HD wallets. Other notable enhancements include a bundled Tor client that can be activated with one line of code, support for multisig wallets, much faster and deterministic ECDSA, many API improvements and big upgrades to the included GUI wallet which can be seen in a new screencasted tutorial.
The commit hash of bitcoinj 0.12 is 83a9a71f3fff3f223d0737ad758b519a39dbbd62. New in this release
Privacy enhancements:
Wallets are now hierarchical and deterministic (HD) by default, using the BIP32 specification. Support for mnemonic codes (BIP 39) is also included. Change and receive addresses are no longer being reused. Old wallets are upgraded in place using the private key of the oldest non-rotating key as the seed bytes, so old backups remain valid.
Thanks to devrandom, we have an integrated Tor mode using the Orchid library. The user does not have to install the Tor client as it?s all pure Java. WalletAppKit users can enable usage of Tor with a single line of code. This support should be considered experimental for now.
Thanks to Kosta Korenkov, we have an experimental multisig wallets implementation. Multisig (also ?married?) wallets are HD wallets that are connected to a third party risk analysis service or device. When married, the wallet tracks multiple BIP32 key trees, keeps them in sync and starts vending P2SH addresses.
As part of this work, transaction signing is now pluggable. TransactionSigner implementations can be added to the wallet and will be serialized into and out of the users saved wallet file. Signers are given a transaction to sign in sequence. This is intended for risk analysis providers to provide a class that talks to their server to get a signature of the right form, so that all bitcoinj based wallets can be easily upgraded to support the new provider.
Reject messages are now deserialized and logged, though not yet exposed in the API.
Upgraded to Guava 16 and Bouncy Castle 1.51. Thanks to Peter Dettman and the rest of the Bouncy Castle team, bitcoinj now uses deterministic ECDSA for signing and we?re now using an accelerated secp256k1 implementation that exploits the special properties of this curve, for dramatically faster calculations.
Payment protocol code improvements: Some X.509 utility code was refactored out of PaymentSession for general usage. StartCom was added to the default trust store which was promoted to override the system trust store on non-Android platforms. A command line tool to dump requests to stdout was added.
Thanks to Andreas Schildbach:
We are now BIP62 (canonical push encodings) compliant.
A new Coin class replaces usage of BigInteger for marking values that are quantities of bitcoin. Formatting has moved into the new MonetaryFormat class.
The wallet now saves the fee paid on transactions we calculated ourselves. This is useful for putting it into a wallet user interface.
Transactions can have user memos and exchange rates attached, that will be saved by the wallet.
Support for decrypting BIP 38 protected private keys has been added.
Checkpoints can now be stored textually as well as in the old binary format.
There is also a new BtcFormat API that provides an alternative to MonetaryFormat that plugs in to the java.text framework.
Added new DNS seed from Addy Yeow.
Wallets can now have string->byte[] mappings attached to them, for lighter weight extensions.
Thanks to Richard Green, there is now a Python version of the ForwardingService program from the getting started tutorial. This shows how to use bitcoinj from Python using the Jython interpreter.
bitcoinj now probes localhost for a Bitcoin node and automatically uses that instead of the P2P network, when present. This means any bitcoinj based app can be easily upgraded from SPV to full security just by running Core at the same time: no setup needed.
Thanks to Michael Bumann, there are now more example apps showing how to use parts of the API.
WalletTemplate/WalletAppKit improvements. WalletTemplate is a demo app that shows how to create a cross-platform GUI wallet with a modern style and 60fps animations. WalletAppKit is a very high level API for creating apps that have a Bitcoin wallet:
Now supports mnemonic code and restore from seed words. A date picker is provided to cut down on the amount of chain that needs to be rescanned.
Support for encrypting wallets. Password is requested when needed. The difficulty of the scrypt function is selected to always take a fixed number of seconds even if hardware gets more powerful.
Some new animation and utility code backported from Lighthouse.
Tor support
Thanks to Martin Zachrison, the micropayment channels implementation has received various improvements.
Thanks to Eric Tierney (Circle), the Postgres store can now take a custom schema.
The Bloom filtering API has been extended so FilteredBlock objects can now be produced from Block objects given a BloomFilter. Previously there was support for client-side Bloom usage but no implementation of the generation part.
Many other bugfixes, cleanups, minor tweaks and small new APIs.
Documentation and tutorials
A JavaScript tutorial has been added, showing how to use bitcoinj from this language. More tutorials in other languages will come in future.
The ?Working with the wallet? document has been significantly extended to cover encryption, watching wallets, HD wallets and multisig/married wallets.
A new document and accompanying screencast shows how to extend the WalletTemplate app to have a transactions list, and then make a native/bundled packages that don?t need the user to install Java. By following this tutorial you will learn how to make a basic cross platform desktop wallet of your own.
All other docs were refreshed to the latest APIs.
API changes
The package name has changed to org.bitcoinj and the core Maven artifact name is now ?bitcoinj-core?. You can auto-port most of your code by running find . -name '*.java' \| xargs sed -i .bak 's/com.google.bitcoin./import org.bitcoinj./g
Wallet.completeTx now throws more precise unchecked exceptions in edge cases, instead of IllegalArgumentException.
The use of BigInteger to represent quantities of Bitcoin has been replaced with the more efficient, type safe and useful class Coin. Coin is mostly source compatible with BigInteger so you can probably just do a search and replace to update your codebase. Utils.bitcoinValueToFriendlyString and friends moved to CoinFormat.
NetworkParameters.getProofOfWorkLimit was renamed to getMaxTarget for consistency with other Bitcoin codebases.
The library no longer uses the misleading term ?nanocoins? to mean satoshis (the old term predated the use of the word satoshi to describe the smallest possible amount of bitcoin).
TransactionConfidence no longer tracks total work done.
Because outputs are now shuffled any code during that assumes the ordering is preserved will break. You can set the shuffleOutputs field of SendRequest to false to disable this behaviour if you need to.
The ECKey and HD API?s have changed quite a bit: several constructors were replaced with clearer static factory methods that make it more obvious how their parameters are interpreted. The new methods don?t change their behaviour depending on the pattern of nulls passed into them.
Some unit testing utilities have been moved to the new testing subpackage and cleaned up/rearranged. It should be easier to write unit tests for your app that need a simulated network now. DeterministicKey now derives from ECKey.
We now use Utils.HEX.encode() and Utils.HEX.decode() to do translation to and from base 16.
Transaction.hashTransactionForSignature was renamed to just hashForSignature.
The subVer string sent by bitcoinj now has a lower cased first component.

@_date: 2014-10-03 22:58:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [BIP draft] CHECKLOCKTIMEVERIFY - Prevent 
Alright. It seems there's no real disagreement about how the opcode
behaves. Perhaps a time limit would be appropriate to stop people creating
outputs locked for 100 years .... is bitcoin even likely to exist in 100
years? The entire history of computing is not even that old, seems hard to
imagine that it'd be good for anything beyond wasting space in the
database. But this is a minor point.
So I guess it's time to start the deployment discussion.
Bitcoin is a consensus system. It works best when everyone is following
exactly the same rules at the same time. A soft fork works against this
principle by allowing nodes to think they're following the majority
ruleset, even if they aren't, effectively downgrading them to something a
bit like SPV security without them realising.
A hard fork has multiple desirable properties. Most importantly, it means a
node can detect it's no longer in the consensus because it'll find its own
chain height has diverged significantly from its peers. Core already has
code that knows how to detect this condition and log errors about it as
well as running the alertnotify script i.e. emailing the admin. Ideally it
would also stop serving work so miners shut down or fail over, but this is
easily added to the CheckForkWarningConditions() function.
In other words, this gives the cleanest failure we can give, such that any
procedures a node operator has put in place to alert them of divergence
will be triggered.  Any code which is waiting for confirmations will wait
forever at this point, thus minimising the risk of loss.
Additionally, forcing old peers to fall behind means SPV clients will pick
the right chain, and not end up downloading transactions or blocks that are
about to be doomed at the next re-org. They can easily choose to ignore
transactions relayed by peers that are too far behind and thus not end up
accepting transactions that are no longer valid according to the majority
(a scenario which can cause monetary loss).
I don't think hard forks should be scary. Mechanisms are in place to warn
people and they can be scheduled with plenty of time in advance. The main
stated justification for a soft fork is backwards compatibility, but in a
system like Bitcoin you really don't want to be running behind the
consensus and it's hard to imagine any node operator deliberately choosing
to stay on the wrong side of the fork. It's not like other software where
people can choose to skip an upgrade and things still work just like before.

@_date: 2014-10-04 14:58:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [BIP draft] CHECKLOCKTIMEVERIFY - Prevent 
Nobody said hard forks shouldn't have an associated block version number
increase - that's a straw man. They should! The difference is only whether
older clients are presented with data they would refuse to accept thus
ensuring they don't accept the new version blocks.
Meanwhile, what I said *is* correct. New version numbers result in only a
log print. Being hard forked off results in both log prints *and* the
-alertnotify being run: it's noisier, and if the user followed the
instructions printed to the console when there is no config file present,
he/she should also get an email or some other kind of more meaningful alert.
Finally, please stop trying to imply that all this is settled and I'm
somehow an idiot for bringing it up. You've done that on the pull request
and now here, it gives me a headache. Instead of making hand-waving
references to "stuff on IRC ages ago", explain why it's better to keep
these nodes in some fantasy world where they think they're fully validating
but are actually not.

@_date: 2014-10-04 15:26:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bitcoinj 0.12 
Hey Kristov,
Stealth addresses and SPV don't mix well, so no. I wrote up a description
of how to do something similar with the payment protocol here:
Because you can send data around outside the block chain on private
channels, with the pp the same issues don't crop up.
At the moment there are no concrete plans what goes into the next release.
I will be focusing on fully launching Lighthouse and crowdfunding for
decentralisation/crypto related projects, so I won't be doing any major
feature work on bitcoinj. Luckily it's become quite an active project now
and there are lots of contributors, so things won't stand still.
If I were to tackle a big project the next one would not be privacy
related. It'd be refactoring the wallet so it doesn't store transactions
directly anymore, just unspent outputs. Bitcoinj has always been largely
driven by the needs of Andreas' mobile app, and right now the top user
reported problem there is people hitting the scalability limits of the
current design (e.g. they are mining directly into their phone's wallet).

@_date: 2014-10-06 13:02:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] The Bitcoin Freeze on Transaction Attack 
I'm skeptical such a situation can ever be stable. People have no incentive
to create a transaction that will remain stuck in the backlog forever,
regardless of the effect it may have on the rest of the system.
If someone invents a business model in which lots of payments are made,
with fees, but that only clear probabilistically, perhaps such a situation
could occur. But otherwise I think we have to assume that people won't make
transactions that will lose the competition game, and instant demand would
only ever be roughly equal to supply.

@_date: 2014-10-07 18:08:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [BIP draft] CHECKLOCKTIMEVERIFY - Prevent 
That's certainly a useful improvement. It won't help the existing userbase
though - assuming CHECKLOCKTIMEVERIFY is to go in to the next major
release. If there's going to be an intermediate release (6 months?) which
lays the groundwork for future rule changes, it helps more.
It would be good if getblocktemplate was updated at the same time to serve
errors if the fork warning is active. I'd hope miners have some way to
automatically handle IBD/getting forked off the chain, but I guess some
(newer) pools might not, and refusing to serve work should be the safest
option that shuts them down.
I don't have any opinion on the hard- versus soft- fork debate. I think
P2SH was a soft fork and the sky did not fall, but miners did lose money
and waste electricity mining blocks on the wrong side of the chain:
Presumably they didn't notice for longer because it looked like a run of
unusually bad orphaning luck. It seems safer to have a clean fork, with
alerts telling people during the lockin period before new rule enforcement
starts (and possibly automated termination if there's no upgrade by the
flag day?). Miners who ignore it would still risk losing money, but
merchants who wait for a block at least would not be at risk.
One open question is how can you actually trigger a hard fork? Coinbase
scriptSigs are not executed, so putting some ignored but failing opcode
sequence there wouldn't work. One possibility would be to have a special
invalid tx in the block that marks the start of new rule enforcement. New
nodes would know to ignore it. But this risks corrupting block explorers.
Alternatively the coinbase outpoint structure could have its hash set to 1
instead of 0.

@_date: 2014-10-08 12:15:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] [BIP draft] CHECKLOCKTIMEVERIFY - Prevent 
I'm not sure why it'd be any different. Soft forks are just as disruptive -
everyone who needs a correct node has to upgrade on time. Given that, I
guess there will be a desire to roll out several changes at once too,
regardless of what happens to older nodes.

@_date: 2014-10-08 12:19:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] The Bitcoin Freeze on Transaction Attack 
This seems to come up a lot. Your definition of rational is a short term
rationality only. I can pass up a short term profit in return for more
stable longer term profits and be completely rational, by a reasonable
definition of the word.
I think it's clear by now that if most or even some miners decide to
prioritise short term profit over the long term health of the system (i.e.
longer term profit), Bitcoin basically doesn't work right. This attack is
only one of several such things that can happen. This certainly can be a
problem when difficulty is skyrocketing because a mining investment is I
guess quite short term anyway, but presumably at some point the mining arms
race will end and miners will become more settled in.

@_date: 2014-10-10 19:26:49
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Something people are forgetting about the 
I'm sure this suggestion will go down like a lead balloon, but Bitcoin Core
is not the first project that's had issues with Linux distros silently
modifying their software as they package it. In this case Luke has changed
things to be closer to what users expect, which is good to see, but I
expect to see the same issue crop up with other Linux distributions in
future. The temptation to "improve" things when you're a middleman is just
too great.
The usual approach to fixing it is trademark the project name and use that
to enforce "clean" packaging. Firefox and Chrome both take this approach.
I'll probably do the same with Lighthouse (need to figure out the
trademarking process first).
The goal here is not to remove choice, rather to ensure people know what
they're getting. It's reasonable to assume if you do "emerge bitcoin" then
you're getting Bitcoin Core as distributed by bitcoin.org, not a highly
opinionated fork of it. Renaming a project and creating a package under the
new name is not only better for end users, but lets the fork grow into
something else and be more usable to people on other distros too.
In this case "Bitcoin" is already a trademark, though I lost track of who
owns it at the moment (the foundation?) but I guess Bitcoin Core is not.

@_date: 2014-10-15 17:46:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP process 
Let's stay away from SF.net or any mailman-controlled lists if at all
possible. They break DKIM signatures which means they're no longer
compatible with Yahoo, all mail from Yahoo users gets spamfoldered
immediately. Google Groups gets this right. Perhaps other list operators do
too. Groups also has moderation features.

@_date: 2014-10-15 20:13:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP process 
I don't care much what exact list software/service is used, but lists.sf.net
hasn't changed in years and is basically dying. Trashing all accounts because ancient mailman does a MITM attack on people's email is no
good, it's not any better than a web proxy that breaks every SSL
connection. For a project that is based on digital signatures, it's really
bad that the mailing list is incompatible with Yahoo's "mail signatures
must be valid" policy.
Plus its moderation features suck, its mail archiving features suck, etc.
It essentially has no redeeming features at all.
mail-archive.com can be easily used with any mailing list, so not sure why
that's brought up. You just add it as a member, as documented here:

@_date: 2014-10-20 12:56:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] About watch-only addresses 
Neither. A watching wallet still has to be synced with the chain in the
same way as any other wallet, i.e. after adding an address, if it was
already used, you must rescan.

@_date: 2014-10-20 14:50:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Two Proposed BIPs - Bluetooth 
Hey Andy,
Thanks for starting this discussion!
One thing this brings up is the never-resolved issue of whether BIPs should
document how we'd *like* things to work, or how things *actually do* work.
BIP32 is an example of the former - it was new technology and the spec was
finalised before any wallets actually implemented it. BIP 44 is an example
of the latter, it basically documents how myTREZOR works and as such there
was minimal or no scope for changes to it. Of course both kinds of document
are valuable.
Currently these specs document how Andreas' app already works. Whilst
preserving compatibility with existing Android apps is surely useful,
having a well designed protocol is also good. The current protocol has
several problems. I don't know which is more important right now and don't
have a strong opinion on that. My gut feeling is that these documents
should possibly be just wiki pages on Andreas' github. Then if the protocol
is brought to a point where it seems pretty good, maybe it can be BIPped at
that point. Alternatively, if developers of other wallet apps feel they'd
like a BIP right now even in the current state, that would be a very
important data point.
Re: the actual specs:
header format is probably not worth the inevitable hassle and transition
period that would result.
first Bluetooth support in Bitcoin Wallet for Android was written by me in
a frantic Berlin hackathon over a weekend. We barely got it working at all
by the end, so doing encryption/auth was out of the question. Then I went
back to more important tasks and what got shipped was a cleaned
up/robustified version of that.
Re: hash. I'm not a fan of this approach. For one, in future there might
not even BE a uri involved, e.g. consider the Square style UX where the
merchant is broadcasting an endpoint via BLE and the phone just
automagically connects, sees a trusted merchant and pays. Super slick, we
definitely want it - but no URI. Then of course there's the usual QR code
size limitations.
Encrypting/authing the connection at the app layer does not have to be
difficult. What we really need/want, is a simple lightweight library that
does an ECDH key agreement using secp256k1, and then does AES+HMAC on
framed messages. Such a protocol would be useful not only for this use
case, but perhaps for encrypting/authing the p2p protocol in future as well.
Once the encrypted connection is set up above the Bluetooth layer, the
payment protocol request can then be signed either with a regular Bitcoin
key that was in the Bitcoin URI as the payment address (when a URI is
available), thus linking the request to the URI without adding any
additional data by doubling up the backwards compatibility support. Or if
there's no URI, then of course, the payment request must be PKI signed and
the signed PaymentDetails structure can contain a copy of the public key
that was used to set up the connection, thus binding the connection to a
PKI identity and ensuring you're not talking to a MITM.
I suspect that this is not anywhere near as hard to implement as one might
think. ECDH is not a complex protocol. You certainly don't need full blown
HTTPS involved.
can't remember why one wasn't included in the final spec. I think we
decided the containing protocol could do this instead (normally HTTP).
Abusing the memo field is definitely the wrong thing to do! Rather the
Bluetooth specific encapsulation protocol should have a notion of failure.
effort, let's not discuss that as part of Bluetooth support.
Besides, no wallet uses even the existing support for merge avoidance in
BIP70. In fact Andreas' wallet is one of the blocking factors here because
it violates the specs by requiring the BIP70 request to have only a single
output that matches the address specified in the URI. All because he
doesn't trust HTTPS :(
I don't think adding even more privacy stuff to BIP70 makes any sense until
we have implementations that actually exploit the existing support. And to
get there, we must fix Andreas' wallet so it doesn't violate the specs
anymore. Sorry Andreas. I know we argue about this all the time, but it's
really a big problem that your app doesn't obey the specs. It makes
everyone reluctant to use new BIP70 features, because they feel a need to
test with every possible wallet app in case one of them has simply decided
to do their own thing and become deliberately incompatible. And then why
bother, there are more important things to do.
unlikely that address-less URIs can be relied upon any time soon - and
besides if the URI needs to bind to an authenticated channel because PKI
signing is not in use, then it makes sense to use that part of the URI to
do so.
access radios of various forms, I doubt it's worth putting much effort in
here. Bluetooth for submitting payments makes sense some of the time,
partly for performance and partly because it's more decentralised than
looping in an intermediary HTTPS server to temporarily host a BIP70 request
file. I don't think we should try and invent an entirely new "block chain
internet" though. At any rate, it's a separate effort.
If you reuse the backwards compatibility address, then the payment_url can
of course be customised based on whatever transport mechanism the request
was fetched over. There is no longer any need to have the payment request
be created (and presumably stored) the moment the QR code is generated.
Besides, that approach has all kinds of messy implementation problems. You
don't know the QR code will *ever* be scanned, but you must have the exact
payment request at the time the QR code is generated. Payment requests
expire, so you have to define some kind of timeout at which point the QR
code itself becomes invalid. Urgh.
Much better to have the PaymentRequest formatted and signed on demand, once
the URI is being resolved. But that means you have to abandon the h=

@_date: 2014-10-20 18:29:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Two Proposed BIPs - Bluetooth 
hard to do with android/java?
Not at all, it should be very easy in Java because of how the SSL API is
designed. I'd worry more about non-Java platforms.
However, SSL is extremely large, old and complicated. We use it on the web
because of a mix of its feature set and legacy concerns. When discussing
encrypted connections in the past, there has been a desire to avoid SSL
because of these issues and do something much simpler and home grown. Of
course, part of the reason SSL is so convoluted is because cryptography
evolves over time, and thus it's not 100% clear to me that a simple
home-rolled crypto link would avoid falling into the same traps as SSL
But, at least for now, it's probably more secure and more robust to not use
Eh, no. Satoshi originally introduced key hashing simply to make shorter
and easier to type destinations. Actually he envisioned most payments being
routed by IP address, where Bitcoin would just connect to the other node
and request a public key directly. There's no problem with the sender
knowing the public key of the address included in the URI.
Alternative PKIs would be a topic for another thread, indeed. But I doubt
you will get anywhere. There are no usable alternatives to the SSL PKI. I
wrote an article on the topic here, you may find it useful:
It summarises why BIP70 uses the PKI.
It's "Respond with 500 Internal Server Error" pretty much.
Originally the idea of BIP70 was that clients would not broadcast
transactions. They would submit them to the merchant for broadcast. If the
merchant didn't like the payment for some reason (e.g. paying with a non
standard transaction or with lots of dust), they could just return an error.
Unfortunately Bitcoin Core does broadcast transactions simultaneously.
Additionally, whilst other wallets  did not, one major payment processor
had a very unreliable BIP70 payment_url endpoint for a while, whilst
broadcasting a tx via the p2p network was fully functioning. So to work
around bugs in this one payment processor some other wallets have started
broadcasting the payment tx simultaneously as well.
This means a receiver cannot meaningfully reject a payment. Some wallets
will send it anyway, via the p2p network.
I suspect it won't work if you leave out the non-standard h= parameter.
WRT the merge avoidance - there's an article here on how it's meant to work:
It's totally OK for you to specify the amounts you want to avoid merges in
your own wallet. The sending wallet could (but none do today) then pay with
multiple transactions.
Your case is really weird because you aren't actually requesting a specific
amout of money. I recall that there's some reason for this, from your
video, but suddenly it escapes me. Because the user scans the payment
request before pumping?
I disagree with all your reasons (e.g. there is nothing wrong with
outsourcing payment processing and it doesn't have to imply the user sees
an incorrect name), and I believe you should trust the PKI a lot more than
you do. If you try and build a better replacement, I think you'll discover
it's a lot harder than you imagine.
Regardless, I am not against an *optional* tighter binding between URI and
payment request, mostly because it's useful for the cases where signing
with a cert isn't possible. But the simple/obvious "embed a hash of it in
the URI" is inefficient, not compatible with the current specs, can make QR
codes harder to scan, and forces you to format your payment request up
front rather than generating it on demand.
Unsigned requests work OK for the phone to phone case, assuming you aren't
actually talking to an imposter.
You can just allow port 8333 and rewrite port 80, as most wifi hotspots do
today already.
But my point about this was that all smartphones get internet access from
time to time. In my own life, I've definitely been in cases where I wanted
to *pay* with bitcoins but didn't have good internet access at that exact
moment, e.g. back of a restaurant. I've also been in the situation more
rarely where I wanted to receive coins from someone in front of me, without
good internet access, but Bluetooth already addresses that.
I don't recall ever being in a situation where I had no internet access,
but somehow knew there was a payment waiting for me on the block chain, and
I needed it right now because it was necessary for me to receive that money
in order to pay a bill. That's what the dedicated blockchain radio would
provide, but it seems like a very rare use case.
I think I said already, but maybe am not explaining well. You use the
address that's already in all backwards compatible URIs. The payment
details can be additionally signed with the key corresponding to that
address. Or, that key can be covered by the PKI signature if there is one.
But dual signing is always possible.

@_date: 2014-10-28 09:55:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Reworking the policy estimation code (fee 
Could you explain a little further why you think the current approach is
statistically incorrect? There's no doubt that the existing estimates the
system produces are garbage, but that's because it assumes players in the
fee market are rational and they are not.
Fwiw bitcoinj 0.12.1 applies the January fee drop and will attach fee of
only 1000 satoshis per kB by default. I also have a program that measures
confirmation time for a given fee level (with fresh coins so there's no
priority) and it aligns with your findings, most txns confirm within a
couple of blocks.
Ultimately there isn't any easy method to stop people throwing money away.
Bitcoinj will probably continue to use hard coded fee values for now to try
and contribute to market sanity in the hope it makes smartfees smarter.

@_date: 2014-09-12 15:49:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP72 amendment proposal 
A few thoughts on this:
(1) Base64 of SHA256 seems overkill. 256 bits of hash is a lot. The risk
here is that a MITM intercepts the payment request, which will be typically
requested just seconds after the QR code is vended. 80 bits of entropy
would still be a lot and take a long time to brute force, whilst keeping QR
codes more compact, which impacts scannability.
(2) This should *not* be necessary in the common HTTPS context. The QR code
itself is going to be fetched from some service, over HTTPS. I see no
reasonable attacker that can MITM the request for the BIP70 message but not
the request to get the QR code. Adding a hash makes QR codes more bloated
and harder to scan, all on the assumption that HTTPS is broken in some odd
way that we haven't actually ever seen in practice.
(3) This can be useful in the Bluetooth context, but then again, we could
also do things a different way by signing with the key in the first part of
the URI, thus avoiding the need for a hash.
I know I've been around the loop on this one with Andreas many times. But
this BIP doesn't fix any actually existing problem in the previous spec. It
exists because Andreas thinks SSL is useless. If SSL is useless we all have
much bigger problems.

@_date: 2014-09-12 17:36:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP72 amendment proposal 
Your example doesn't have an address in it at all, so isn't compatible with
non-BIP70 wallets. Maybe for QRcodes specifically there are no longer any
such wallets out there. For clickable links it can still be an issue.
Can just truncate SHA256, I think.
Their wallet checks the name, though. It sees:
and the wallet verifies that the presented certificate is for CN=bitpay.com
Well, I wrote an article that argues with this PoV:
No disagreement that it's a more complex mechanism. But seeing as we end up
depending on it anyway the moment you load any kind of web page to find out
the URI, adding another mechanism only increases complexity, it doesn't
remove any.
Sure. But signing is harder than just calculating a hash.
Well, again, it saves qrcode bytes. You don't have to include a dedicated
hash. The existing address hash can double up as both a backwards
compatibility measure, and also an auth mechanism.

@_date: 2014-09-12 17:37:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP72 amendment proposal 
Ah, that's a good suggestion if we do go this way.

@_date: 2014-09-12 18:31:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP72 amendment proposal 
Putting aside the question of necessity for a moment, a more efficient
approach to this would be;
   1. Add another marker param like &s to the end of the URL
   2. Add another field to PaymentRequest that contains an ECC signature
   calculated using the public key that hashes to the address in the URI
   3. Upgraded wallets look for the additional param and if it's there,
   expect to find the PaymentDetails signed with the address key. PKI signing
   of course is still useful to provide an actual identity for receipts,
   display on hardware wallets, dispute mediation etc.
This adds only a few characters to a normal backwards-compatible QR code,
and is not hard to implement.

@_date: 2015-04-09 13:29:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Build your own nHashType 
Hi Stephen,
It's an interesting idea. I'm not sure that all the combinations make
sense. Excluding the connected output script or value but still signing the
prev tx hash appears pointless: the script cannot change anyway, and you
still need to know what it is to actually calculate the inputs to it, so
what is the point of this?
I also worry that quite a few of these combinations could be unexpectedly
dangerous. If you don't sign the prevout hash or value and combine it with
a regular pay-to-address output then you've effectively written a blank
cheque that can be used by anyone, to claim any money ever sent to that
address ... no? And then any p2p node or miner could do so, making the
transaction pretty useless.
That isn't inherently a problem as long as people understand which
combinations have what effects or cannot be used for various reasons. But
it would need good documentation and careful thought to explore each
possibility people might use.
I'll leave the soft fork business to one side for now. I think any change
in CHECKSIG or new version of it would likely be ready around the same time
as the hard fork we need for changing the block size limit anyway, and it's
much cleaner to do it that way.
The most important change that we need in sighash calculation, IMO, is
ensuring that you don't have to hash data over and over again without a
good reason. The current sighash definition is unfortunate because it's
possible to make small transactions that involve hashing huge amounts of
data. It's not clear to me that your proposal fixes that: ideally there
would be one exactly one sighash for one transaction no matter how many
checksigs are involved in verifying it.

@_date: 2015-04-09 16:45:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Build your own nHashType 
Right, good point. I wonder if this sort of auto forwarding could even be a
useful feature. I can't think of one right now.
Yes but is that fundamental or is there a way to avoid it? That's what I'm
getting at.
Interesting idea! I don't agree it's messy. If anything it should be
simpler than what we have today - the need to edit a transaction *in the
middle* means that sighash computation involves constantly reserializing a
transaction before it even gets to be hashed.
Consider what happens with very large transactions, like a big assurance
contract that might have thousands of inputs and be multiple megabytes in
size. Obviously such large transactions cannot happen today, but there is
user demand for giant contracts (or at least, users tell me there is,
whether they'd actually do it for real is a bit unclear).

@_date: 2015-04-09 22:23:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] DevCore London 
Next week on April 15th Gavin, Wladimir, Corey and myself will be at
DevCore London:
   If you're in town why not come along?
It's often the case that conferences can be just talking shops, without
much meat for real developers. So in the afternoon I'll be doing two things:
   1. Running a hackathon/workshop type event. The theme is contracts, but
   we can hack on whatever you all feel like.
   2. My "talk" will actually be a live coding event. Writing contracts
   apps has become a lot easier in the past few years, and to prove it to you
   I will write a decentralised cross-platform Tor supporting document
   timestamping app that uses OP_RETURN outputs and has a nice GUI ..... in 30
   minutes, on stage.
   Don't think it can be done? Turn up and see for yourself.
See you there!

@_date: 2015-04-16 13:33:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Where do I start? 
Hey Gabe,
That's diving into the deep end for sure! :)
That depends on your interests.
Many of the highest priority tasks in Bitcoin Core are rather complicated,
unfortunately, even for people with experience. You can consult the issue
tracker to get a feel for it.
Alternatively, there are lots of wallet apps out there and plenty of more
straightforward projects on them. However they may have less of a research

@_date: 2015-04-26 14:58:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fwd: Reusable payment codes 
Could you maybe write a short bit of text comparing this approach to
extending BIP70 and combining it with a simple Subspace style
store-and-forward network?

@_date: 2015-04-27 18:46:33
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Reusable payment codes 
Bear in mind, the spec defines "identity" to mean:
     *Identity is a particular extended public/private key pair. *
So that's not quite what is meant normally by identity. It's not a
government / real name identity or an email address or phone number kind of

@_date: 2015-02-01 14:43:45
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP: protocol for multisignature 
If you decide to implement this in an existing or new bitcoinj based
wallet, then I'm happy to give you pointers on how to do it. Making
one-off, cross platform app specific wallets is pretty easy these days. For
2-of-3 dispute mediation transactions they'd start out being kind of
specialist so asking people to move money from their general spending
wallet into dispute mediation app isn't unthinkable. Eventually general
purpose wallets would integrate protocol, UI ideas and maybe code.
At least, that's how I'd do it.
On Sun, Feb 1, 2015 at 12:02 AM, Martin Habov?tiak <

@_date: 2015-02-01 14:46:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
TREZOR does not support BIP70. I think they planned to work on it after
multi-sig support, which is now done, so I'm hoping that it's next on their
The signing features of BIP70 have (fortunately!) been implemented by
payment processors quite early, before we really have the client side fully
figured out and implemented. Mobile wallets (Android, iOS) do implement it
and they are reasonably secure, for desktops we need TREZOR and we need the
Bitcoin Authenticator 2-factor wallet to support it. I think they do, but
can't remember exactly. Either they do, or it's on their roadmap.
On Sun, Feb 1, 2015 at 2:31 PM, Martin Habov?tiak <

@_date: 2015-02-01 14:48:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
No. It cannot be done in the Bitcoin context. Your wallet MUST be secure.
Otherwise BIP70 is irrelevant - if the attacker can make your wallet sign
some other transaction than what you expect, they can also just steal your
private keys and use them directly. BIP70 is based on the assumption of a
secure signing core that cannot  be compromised, with devices like the
TREZOR and 2-factor pairings of desktops and mobiles being an obvious use

@_date: 2015-02-02 12:33:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Export format for xpub 
We generally don't edit BIPs like that after they've been written except to
add helpful links, examples etc and other things that don't add new
functionality. For this you'd write a new BIP. It doesn't have to be hard.
The process is:
1) Adapt the template BIP and fill it out with your motivation, design,
rationale and ideally some examples.
2) Post it here and ask Gregory for a BIP number. He will select one
through some magic algorithm I am still reverse engineering ;)
3) People will give feedback and try to spot problems in your spec.
I looked at what Andreas is doing a few days ago - basically it's just an
xpub string with a ?a=b&c=d query string added to the end, with a hierarchy
type specifier and something else I forgot, encoded into a QR code. So it
should be a very easy BIP to add.
Whilst you're at it you might want to add an HTTP POST based method,
though. Web apps scanning QR codes is kind of clunky compared to just
picking Coyno from a list in the wallet app and having it all
auto-magically activate.

@_date: 2015-02-02 18:59:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
We're way ahead of you guys ;)
On Mon, Feb 2, 2015 at 6:54 PM, Martin Habov?tiak <
      - does this already, currently
in alpha
BitGo, CryptoCorp and (slight variant) GreenAddress all offer this model.

@_date: 2015-02-02 19:25:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
Bitcoin Authenticator is a desktop app+mobile app pair. It pairs with your
phone over wifi, cloud push, maybe Bluetooth as well. I forget exactly.
It's done in the same way as Lighthouse, so it runs Win/Mac/Linux on
desktop and Android on mobile.
It could be adapted to use BitGo as a third party key holder with SMS
authenticator relatively easily, I think. We did the bulk of all the needed
work last year as part of the bitcoinj multisig work. Then you'd have a
server involved, but not a web app.

@_date: 2015-02-02 19:53:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
Not sure what you mean. The idea is the second factor displays the
transaction and the user confirms it matches what they input to the first
factor. Ideally, using BIP70, but I don't know if BA actually uses that
It's the same model as the TREZOR, except with a desktop app instead of
myTREZOR and a phone instead of a dedicated hardware device.

@_date: 2015-02-03 22:01:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Subject: Re: Proposal to address Bitcoin 
Yes, X.509 is ....... unfortunate. We'll have to wait and see how the
TREZOR team get on with implementing it. TREZOR doesn't have any OS at all
at the moment, so an implementation of PKIX will probably end up being
larger than their existing codebase.
That said, X.509 parsing is so security critical that the existing
codebases for it are by now pretty robust. Touch wood. So just having a
super stripped down OpenSSL implementation is probably good enough.
W.R.T revocation, BIP70 doesn't support this. If your private key leaks
you're currently hosed, identity wise, until the certificate expires. This
is obviously suboptimal. In a world where we all have infinite time and
resources the right fix will be to piggy back on an X.509 extension being
proposed in the browser world called "Must Staple". It's a bit in the
certificate flags that tell the client to expect a stapled OCSP response
and to hard-fail if none is provided. By requesting the CA set this flag
when you get your certificate issued, you sign up for more pain but more
An OCSP stapling extension to BIP70 would probably not be very hard to
implement, but it'd be pointless today because the client has no idea
whether to expect it or not. The absence of a certificate changes the UI by
showing you a random Bitcoin address instead of a human readable name, but
the absence of stapled OCSP would not result in any UI change.
I'm hoping that the hardware wallet world just standardises on the TREZOR
protocol. It's well designed and these devices all have fairly similar

@_date: 2015-02-05 14:57:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
Agreed - it's not clear to me at all that this partial address scheme is
actually secure. The assumption appears to be that the MITM must match the
address prefix generated by the genuine merchant. But if they can do a
wireless MITM they can just substitute their own address prefix/partial
address, no?
To avoid MITM attacks the sender must know who they are sending money to,
and that means they must see a human understandable name that's
cryptographically bound to the right public key. Displaying partial
addresses to the user is not going to solve this unless users manually
compare key prefixes across the screens.... which is even less convenient
than a QR code.
I think it should be explained why to
This is probably an artifact of Apple's restrictions on iOS. Only the
iPhone 6 has NFC hardware and Apple don't expose it via any public API. It
can however support Bluetooth LE.
Apple isn't a big deal in Germany because iPhone only achieved about 17%
market share during the quarter when the iPhone 6 launched. Normally it's
closer to 10-13%. Most other markets are similar.
However in the USA, UK, Australia and Japan iOS is still a big deal and NFC
is going to be seen as a non-universal solution there. At least, until
Apple catches up and provides an NFC API.
It's certainly not a problem to have a working radio based broadcast
system, though the theoretician in me wonders what  happens when lots of
people are trying to pay simultaneously for something that has equal cost
..... e.g. buying movie tickets at a counter. NFC and QR codes prevent any
kind of "oops I paid for someone elses stuff" confusion.
In practice of course Bitcoin payments are not normally popular enough for
this to be a problem outside of Bitcoin community events.

@_date: 2015-02-05 21:28:37
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
BIP70 requests can be sent over bluetooth as well, as can transactions.
Bitcoin Wallet can already send money even when offline by doing this. It's
transparent to the user. I mean original Bluetooth in this context - BLE
has incredibly tight data constraints and isn't really meant for data
Yes Android Beam has a pretty stupid UI. You can actually tap the devices,
take them away and then press, but that's not obvious at all. There have
been new APIs added in recent releases that give more control over this, so
it's possible we can revisit things and make the UI better these days.
The donation to live performer example is good - there's no issue of
accidentally paying for someone else in this context as there's only one
recipient, but many senders.
The issue of confused payments remains in other situations though.
For the coffee shop use case, it'd be nicer (I think) if we aim for a
Square-style UI where the device broadcasts a (link to) a photo of the user
combined with a bluetooth MAC. Then the merchant tablet can show faces of
people in the shop, and can push a payment request to the users device.
That device can then buzz the user, show a confirmation screen, put
something on their smart watch etc or just auto-authorise the payment
because the BIP70 signature is from a trusted merchant. User never even
needs to touch their phone at all.

@_date: 2015-02-05 21:43:03
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
The way Bitcoin Wallet does it, the bitcoin URI includes a MAC address
where you can download the request from. BIP70 does not depend on internet
access or HTTP, plus, you don't have to sign them.
The name field might work but requires the merchant to set it, e.g. by
asking the payer what their name is, then typing it in, then the payer has
to wait for it to show up. By this point it's probably faster to have
scanned a QR code.
Re: security. I'll repeat what I wrote up-thread in case you didn't see it:
it's not clear to me at all that this partial address scheme is actually

@_date: 2015-02-05 21:50:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
I hate to break it to you, but you broadcast a photo of your face every
time you walk outside ;)
Bluetooth MAC addresses are random, they aren't useful identifiers. If
someone can see you, a face is a far more uniquely identifying thing than a
"Payment spam" might be a problem. I can imagine a wallet requiring that
such requests are signed and then spammers can be blacklisted in the usual
fashion so they can't push things to your phone anymore. Anyway, a hurdle
that can be jumped if/when it becomes an issue.

@_date: 2015-02-05 22:36:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
We're talking about BLE, still? The radio tech that runs in the so called
"junk bands" because propagation is so poor?
My watch loses its connection to my phone if I just put it down and walk
around my apartment. I'm all for reasonable paranoia, but Bluetooth isn't
going to be enabling mass surveillance any time soon. It barely goes
through air, let alone walls.
Anyway, whatever. I'm just bouncing around ideas for faster user
interfaces. You could always switch it off or set it to be triggered by the
presence of particular wifi hotspots, if you don't mind an initial bit of
Back on topic - the debate is interesting, but I think to get this to the
stage of being a BIP we'd need at least another wallet to implement it?
Then I guess a BIP would be useful regardless of the design issues. The
prefix matching still feels flaky to me but it's hard to know if you could
really swipe payments out of the air in practice, without actually trying

@_date: 2015-02-06 14:54:49
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Two Proposed BIPs - Bluetooth 
BLE meets a different use case than regular Bluetooth. BLE is designed to
allow always-on broadcast "beacons" which are conceptually similar to NFC
tags, with very low power requirements. The tradeoff for this ultra-low
power consumption and always on nature is the same as with NFC tags: you
get very little space for data, and they are essentially one way. That's
why a common use case for it is to trigger some other mechanism like a
classical Bluetooth socket or HTTPS connection.
I think BLE has a role to play in Bitcoin payments, but probably not for
actually transferring payment data. Rather, a merchant should be able to
drop a BLE beacon in their shop, and then wallet apps can use that to learn
where to download a payment request/upload a payment message. But the
actual data transfer would still take place over Bluetooth, Wifi or the
That leads to the question of what the beacon broadcasts. A bitcoin URI is
the obvious answer: the problem is a URI contains an address. No problem
for the "throw money at a live performer" use case but a problem for the
cafe use case. If we are willing to mandate BIP70 and remove the static
address part from the URI the we get a "uri that points to a url" which is
a bit inefficient but at least lets us distinguish bitcoin beacons from
other kinds. That still leaves the fundamental question raised by the
Airbitz spec - how does your wallet download the right payment request?
Unfortunately that's a tough UI problem. I don't think comparing long hex
strings manually is a good way to go. This seems less user friendly than a
QR code.
Once we solve that problem, how BLE beacons can trigger payments will all
fall into place. The tech part isn't the hard part.

@_date: 2015-02-06 14:57:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Two Proposed BIPs - Bluetooth 
Probably on Android it's being verified in Java instead of C++. Some
Android APIs are backed by OpenSSL but I don't know off hand if the way
we're verifying cert chains on Android is. It's eminently fixable, at any
X.509 cert chains are pretty bloated, but even so, shouldn't take several
seconds to transfer even over Bluetooth.
Bottom line is that there may be ~1s time transferring the data with this
BLE isn't really connection oriented, as far as I know.

@_date: 2015-02-10 12:08:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Standardizing automatic pre-negotiation 
all merchants)
We can certainly imagine many BIP70 extensions, but for things like
auto-filling shipping addresses, is the wallet the best place to do it? My
browser already knows how to fill out this data in credit card forms, it
would make sense to reuse that for Bitcoin.
It sounds like you want a kind of Star-Trek negotiation agent thing, where
your computer knows how to seek out the best deal because all the metadata
is standardised. Such a thing would be an interesting project, but it's
probably not best done in BIP70 given how it's deployed and used today.
Rather, I'd suggest looking at the various HTML5 data standards which would
allow merchants to advertise things like where they ship to in a machine
readable and crawlable form.

@_date: 2015-02-11 14:52:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: Requiring a miner's signature 
If you're interested in working on mining decentralisation, chipping away
at getblocktemplate support would be a better path forward. It's possible
to have decentralised pooled mining - I know it sounds like a contradiction
but it's not.
I wrote about some of the things that can be done in this blog post:

@_date: 2015-02-12 12:58:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
I know you will ignore this as usual, but the entire replace-by-fee folly
is based on your fundamental misunderstanding of miner incentives.
Miners are *not* incentivised to earn the most money in the next block
possible. They are incentivised to maximise their return on investment.
Making Bitcoin much less useful reduces demand for the bitcoins they are
mining, reducing coinbase and fee income in future blocks. Quite possibly,
to the point where those miners are then making a loss.
Your "scorched earth" plan is aptly named, as it's guaranteed to make
unconfirmed payments useless. If enough miners do it they will simply break
Bitcoin to the point where it's no longer an interesting payments system
for lots of people. Then miners who have equipment to pay off will be
*really* screwed, not to mention payment processors and all the investors
in them.
I'm sure you can confuse a few miners into thinking your ideas are a
super-duper way to maximise their income, and in the process might
facilitate a pile of payment fraud. But they aren't. This one is about as
sensible as your "let's never increase the block size"  and "let's kill SPV
clients" crusades - badly thought out and bad for Bitcoin.

@_date: 2015-02-12 13:49:01
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
It makes unconfirmed transactions useless in the classical Bitcoin model.
Obviously if you introduce a trusted third party you can fix things, but
then you're back to having the disadvantages of centralised trust.
If unconfirmed payments become flaky enough that people stop using them,
then a portion of the Bitcoin community will find workarounds like trusted
third parties, trusted hardware, whatever and will just struggle one. Other
people will look at the new tradeoffs/complexity, and decide that Bitcoin
is no longer better for them than banks.

@_date: 2015-02-12 14:18:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
Yes, like any P2P network Bitcoin cannot work if a sufficiently large
number of miners decide to attack it. This is an ancient argument. It came
up the moment Bitcoin was first invented.
But this argument could have been made at any time in Bitcoin's entire
history. Lots of miners have dropped out due to hardware obsolescence, yet
massive double spending hasn't happened. Perhaps the system is not as
simple as you boil it down to be.
Anyway, what would happen in that event is within a few days some people
would stop selling Bitcoin for hamburgers, others would find workarounds,
and the fees collected from the double spends would be worth very little.
Nobody wins.
So would you take a responsibility for pushing the approach which isn't
"The approach" is how Bitcoin has always worked.
People have been using game theory to predict the imminent demise of
Bitcoin since I first found it. Just one example:   "Bitcoin will collapse
when the 50->25 BTC drop happens" was promoted as a dead cert thing by game
theorists. Every miner becomes unprofitable and stops at once!
So far game theory based predictions tend to be proven wrong by reality, so
this sort of argument doesn't impress me much.
Anyway, going around this loop again is pointless. I brought up the counter
argument so people who see this thread don't mistakenly think Peter's
position is some kind of de-facto consensus about how Bitcoin should work.
Not because I love rehashing the same arguments every six months ad nauseum.

@_date: 2015-02-12 14:44:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
There have been lots of e-cash schemes proposed in the academic literature
that work like this, or variants of it. Schemes where participants are
anonymous until they double spend are popular.
Let's re-write your proposal but substituting the word notary for miner:
To profit, the *miner* would have to be sure the payout from agreeing on
collusion (or to perform the doublespend themselves) would pay out better
than acting honestly for a given amount of time info the future. This means
transactions for small sums are secure.
That's the exact argument we're having. The assertion is that a "rational"
notary would kill his own business to increase his profits in the next few
hours. So you're just arguing that a notary is different to a miner,
without spelling out exactly why.
Does the notary have to make a big up front investment? If so, why is that
different to mining investment?
Is the notary non-anonymous and afraid of being charged with payment fraud?
If so, note that big miners do lots of non-anonymous things too, like
renting warehouses and importing specialised equipment.
Is it because of the big up front collateral they're meant to have lying
around? If so, how do you ensure a fluid market for notaries?

@_date: 2015-02-12 14:52:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
Which is basically all of them other than exchanges. Any merchant that uses
BitPay or Coinbase, for instance, or any physical shop.
If you want to play word games and redefine "Bitcoin" to be something other
than what people are actually using, go right ahead. You will win the
argument under your own definitions which nobody else is using.
In your scenario I won't be able to get hamburgers for free because people
will stop selling them for ordinary bitcoin transactions. Most will say,
you know what, just pay me with Visa instead. And a few might knuckle down
and set up some network of PKI-like trusted third parties that interacts
with the block chain in some way.
Though eventually, if that were to happen, cunning merchants will notice
that having received a transaction counter-signed by a TTP they don't
actually have to broadcast it or pay miner fees at all. They can just keep
it around in their wallet and pass it along to the next guy when they
purchase something with those coins. Eventually whoever ends up not being
able to find a matching TTP gets to be the sucker who pays all the miner
fees at once, because he is the only one who actually needs their services.

@_date: 2015-02-12 15:16:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
Fraudulent in what sense?
If you mean the legal term, then you'd use the legal "beyond reasonable
doubt" test. You mined a double spend that ~everyone thinks came 5 minutes
later once? OK, that could be a fluke. Reasonable doubt. You do it 500
times in a row? Probably not a fluke.
If you mean under a technical definition then I think Tom Harding has been
researching this topic, though I've only kept half an eye on it. I guess
it's some statistical approximation of the above, i.e. sufficient to ensure
good incentives with only small false positive losses. Sort of like how the
block chain algorithm already works w.r.t orphans.

@_date: 2015-02-12 15:53:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
I'm afraid I still don't understand why you think notaries would build long
term businesses but miners wouldn't, in this model.
I think you are saying because notaries have identity, brand awareness and
because they have big up front bonds, that means they will be trustworthy.
Well, sure. It's the same model governments use and is why being a money
transmitter in the USA is so difficult: you need to put up large sums of
money as collateral and have your fingerprints taken 48 times. *Then* you
can start advertising to get customers!
The reason mining is such a nice model is it doesn't have these sorts of
Which is it? Are notaries small operations or large operations?
I think exploring new consensus models with semi-trusted notaries is
interesting, but it's not Bitcoin.
Please don't try and apply this logic in the real world :( Rephrased:
"*That's a nice house. I noticed it's made of wood. I'm going to start
fires until it burns down, because there is no guarantee your house won't
burn down in future and it's important you understand that wooden houses
aren't safe. Really I'm just doing you a favour*."
Don't get me wrong. I'm all for what *you're* doing - please do continue to
research and explore alternative trust configurations! This is helpful and
useful work. Perhaps we will find something that solves the burger problem
in a way that satisfies everyone.
I'm really not a fan of Peter's approach, which is "hey let's try and cause
as many problems as possible to try and prove a point, without having
created any solutions". Replace-by-fee-scorched-earth doesn't work and
isn't a solution. Miners can easily cut payment fraudsters in on the stolen
money, and as they'd need to distribute custom double-spending wallets to
make the scheme work it'd be very easy to do.
Why? You think ability to make payments in a few seconds is some irrelevant
Let's put it this way. If BitPay's business model evaporates tomorrow,
along with all the merchants they support, do you think that'd have any
effect on Bitcoin's value? If not, why not?

@_date: 2015-02-12 16:15:00
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
To clarify once more, I'm all for people researching and building ways to
make Bitcoin better and safer. And debating that here is cool too.
The "replace by fee" patches don't do this; as you said yourself the whole
scorched earth thing makes no sense. It's not a solution to anything and
it's important people realise that.
Perhaps it will help if I spell out why this whole approach won't work (but
can easily damage bitcoin a lot along the way).
Normal Bitcoin nodes pick which transaction to put into a block by simply
selecting whichever they saw arrive first, as determined by the arrival
order of network packets. This rule is simple and has multiple advantages
for people using Bitcoin to buy and sell things.
Replace-by-fee changes this so nodes select whichever chain of unconfirmed
transactions pays the highest miner fees. Up until the point that a
transaction appears in a block, anyone can broadcast a double spend (or a
spend of an unconfirmed transaction) which pays higher fees than before,
causing that tx chain to become the candidate for chain inclusion.
Peter argues that this is stable and makes unconfirmed transactions safe
because a fraudster can buy something, walk out of the shop, and broadcast
a double spend with a higher fee. But then the merchant can re-spend the
original payment back to themselves with an *even* higher fee than that.
Then the fraudster can re-spend their double spend with an *even* higher
fee than that, and so on back and forth, until *all* the money has been
spent to miner fees. Thus the merchant loses their goods but the fraudster
has still "paid" in some sense because they don't get the money either.
This argument makes no sense for two reasons.
The first is that this setup means miners can steal arbitrary payments if
they work together with the sender of the money. The model assumes this
collaboration won't happen, but it will. Because no existing wallet has a
"double spend this" button, to make the scheme work the dishonest miners
must create and distribute such a wallet that implements the whole
scorched-earth protocol. At that point it's easy for miners to reward the
payment fraudster with some of the stolen money the merchant lost, meaning
it now makes sense for the fraudster to always do this. The situation isn't
stable at all.
The second is that it incentivises competitors to engage in payment fraud
against each other. A big rich coffee shop chain that is facing competition
from a small, scrappy newcomer can simply walk into the new shop and buy
things, then trigger the "scorched earth". Even with no miner
collaboration, this means the big company is down the cost of the product
*but* so is the little company who lost everything. Whoever can outspend
the other wins.
We don't really need game theory to tell us that this plan is a bad idea.
Just imagine trying to explain it to an actual shop keeper. They would
think you were crazy. Bitcoin is already a hard enough concept to
understand without throwing into the mix "anyone can burn the money they
gave you after walking out of the shop".

@_date: 2015-02-12 16:42:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
Well, they're the same thing. Replace-by-fee *is* miner collusion in
knowingly mining a double spend, just triggered in a certain way.
Remember that you aren't paying the bad pool, the bad pool is paying you.
Whichever pool benefits from the scorched earth protocol can simply pick an
address out of the transaction it perceived as starting the protocol, and
pay that.
I think this is the core point which many of these debates revolve around.
No payment system provides *guarantees*, though some are stronger than
others. All they do is manage risk.

@_date: 2015-02-13 12:34:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] replace-by-fee v0.10.0rc4 
Hmm. I think this is a disagreement over the term massive. I was meaning we
don't see double spending like we see carding fraud in the traditional
online payments world. We can talk about Finney attacks by linking to
specific discussions of specific events, because they are very rare, which
is why merchants generally ignore the possibility. I didn't mean the
numeric value of lost coins added up so far.

@_date: 2015-02-19 18:30:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] On Rewriting Bitcoin (was Re: 
Java/JNA bindings can be used from Python, Ruby, Javascript, PHP as well as
dialects of Haskell, Lisp, Smalltalk and a bunch of more obscure languages
like Scala, Kotlin, Ceylon, etc.
It makes more sense to talk about bindings to particular runtimes these
days, rather than particular languages.

@_date: 2015-02-20 17:54:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bloom filtering, privacy 
Hey Adam,
To clarify, we *could* improve privacy and still preserve usefully high
performance, it's just a lot of complicated programming work. You need to
find out from the OS how much bandwidth you have to play with, for example,
and do all the very complex tracking to surf the wave and keep yourself in
roughly the right place.
The basic summary of which I think is that its not even intended to
The original intent of Bloom filtering was to allow both. We want our cake
and we want to eat it.
The protocol can still do that, with sufficiently smart clients. The
problem is that being sufficiently smart in this regard has never come to
the top of the TODO list - users are always complaining about other things,
so those things are what gets priority.
It's not IMO a protocol issue per se. It's a code complexity and manpower
And then what? So you know the block matches. But with reasonable FP rates
every block will match at least a few transactions (this is already the
case - the FP rate is low but high enough that we get back FPs on nearly
every block). So you end up downloading every block? That won't work.
Eventually, wallets need to stop doing linear scans of the entire block
chain to find tx data. That worked fine when blocks were 10kb, it's still
working OK even though we scaled through two orders of magnitude, but we
can imagine that if we reach 10mb blocks then this whole approach will just
be too slow.
The main reason wallets are scanning the chain today (beyond lack of
protocol support for querying the UTXO set by script), is that they want to
show users time-ordered lists of transactions. Financial apps should show
you payment histories, everyone knows this, and without knowing roughly
when a tx happened and which inputs/outputs were mine, providing a useful
rendering is hard. Even with this data the UI is pretty useless, but at
least it's not actually missing.
By combining Subspace and BIP70 we can finally replace the payments list UI
with actual proper metadata that isn't extracted from the block chain, and
at that point non-scanning architectures become a lot more deployable.

@_date: 2015-02-20 18:36:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin ATM 
Hi Fikret,
This is the wrong mailing list for such questions. Most Bitcoin ATM's are
commercial products anyway and don't accept contributors. If you find one
that is different, it's better to contact them directly.

@_date: 2015-02-20 18:43:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bloom filtering, privacy 
Ah, I see, I didn't catch that this scheme relies on UTXO commitments
(presumably with Mark's PATRICIA tree system?).
If you're doing a binary search over block contents then does that imply
multiple protocol round trips per synced block? I'm still having trouble
visualising how this works. Perhaps you could write down an example run for
How does it interact with the need to download chains rather than
individual transactions, and do so without round-tripping to the remote
node for each block? Bloom filtering currently pulls down blocks in batches
without much client/server interaction and that is useful for performance.
Like I said, I'd rather just junk the whole notion of chain scanning and
get to a point where clients are only syncing headers. If nodes were
calculating a script->(outpoint, merkle branch) map in LevelDB and allowing
range queries over it, then you could quickly pull down relevant UTXOs
along with the paths that indicated they did at one point exist. Nodes can
still withhold evidence that those outputs were spent, but the same is true
today and in practice this doesn't seem to be an issue.
The primary advantage of that approach is it does not require a change to
the consensus rules. But there are lots of unanswered questions about how
it interacts with HD lookahead and so on.

@_date: 2015-02-20 18:53:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bloom filtering, privacy 
I read the following comment to mean it requires the UTXO commitments.
Otherwise I'm not sure how you prove absence of withholding with just
current block structures+an extra filter included in the block:
but with the bloom commitment (and UTXO trie organised commitment) he

@_date: 2015-02-20 19:10:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bloom filtering, privacy 
This is the part where I get lost. How does this improve privacy? If I have
to specify which addresses are mine in this block, to get the tx data, the
node learns which addresses are mine at this point, no?
Also, are you saying each block needs a record of the entire UTXO set at
the time the block was made? I'm not sure how to parse this sentence.
Could you please walk me through precisely what happens and what data is
sent, once I learn that a block has interesting data in it?

@_date: 2015-02-20 20:03:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bloom filtering, privacy 
OK, I see now, thanks Gregory. You're right, the use of UTXO set in that
context was confusing me.
If I go back to when we first did Bloom filtering and imagine the same
proposal being made, I guess I would have been wondering about the
following issues. Perhaps they have solutions:
1. Miners have to upgrade to generate the per-block filters. Any block that
doesn't have such a filter has to be downloaded in full, still. So it would
have taken quite a while for the bandwidth savings to materialise.
2. If checking the filter isn't a consensus rule, any miner who builds a
wrong filter breaks the entire SPV userbase. With per-node filtering, a
malicious or wrong node breaks an individual sync, but if the wallet user
notices they don't seem to be properly synchronised they can just press
"Rescan chain" and most likely get fixed. In practice broken nodes have
never been reported, but it's worth considering.
3. Downloading full blocks is still a lot of data. If you have a wallet
that receives tips a couple of times per day, and you open your wallet once
per week, then with 1mb blocks you would be downloading ~14mb of data each
time. Pretty pokey even on a desktop. Much sadness if you're on mobile.
4. Header size is constant, but per-block filters wouldn't be. So even the
null sync would download more data as the network got busier. Of course
Bloom filtering has the same scaling problem, but only between hard disk ->
RAM -> CPU rather than across the network.
5. Is it really more private? Imagine we see a hit in block 100, so we
download the full block and find our transaction. But now we must also
learn when that transaction is spent, so we can keep the wallet-local UTXO
set up to date. So we scan forward and see another hit in block 105, so now
we download block 105. The remote node can now select all transactions in
block 105 that spend transactions in block 100 and narrow down which txs
are ours. If we are watching a wallet that does multi-sends then it feels
like this problem gets much worse.
I'd really like to find a solution that has O(1) scaling on sync. If we see
nodes just as sources of UTXO data then shovelling the client (tx, existing
merkle path) pairs keyed off script prefixes would (with one additional
index) be O(1) and provide the same security guarantees as Bloom filtering
today. It creates lots of other problems to solve, but at least it would
scale into the forseeable future.

@_date: 2015-02-21 14:28:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bloom filtering, privacy 
Let's put the UTXO commitments/anti-fraud proofs to one side for a moment.
I would like to see them happen one day, but they aren't critical to these
protocols and are just proving to be a distraction.
About privacy the node can make different random connections to
Apologies for the wall of text, but I don't think this will work nor solve
any real problem. And I must justify such a strong statement clearly.
*First: technical issues*
When you download the per-block Bloom filter and test, what you get back is
a set of script elements (addresses, keys, OP_RETURN tags etc). But then in
the next step you are saying that you connect to random peers and request
individual transactions. We don't know that at this point. All we know are
a set of addresses that possibly matched. So I think what you mean is
"wallets connect to random peers and request transactions in block N that
match a given set of addresses".
This is what Bloom filtering already does, of course. Doing the test
against the per-block filter first doesn't seem to buy us much because with
thousands of transactions per block, even a very tiny FP rate will still
trigger a match on every single one.
The second problem I see is that we can't do this in parallel because of
the following edge case: wallet contains key K and someone sends it money
using an OP_CHECKSIG output. The input which spends this output does not
contain any predictable data, thus we do not know what to look for in the
following blocks to detect a spend of it until we have seen the first
transaction and know its hash.
In practice this means we must either scan through the chain in sequence
and update our matching criteria if we see such an output (this is what the
Bloom filtering protocol already does server-side), or we must constrain
the user such that output scripts always force repetition of predictable
data - this is what mostly happens today due to pay-to-address outputs, but
not always, and correctness is more important than completeness.
If we can't do it in parallel then we must suffer a node round-trip for
every single block we traverse, because we can't request long runs of
blocks with a single command. That latency will kill performance dead. It's
a non starter.
But let's imagine we don't care about OP_CHECKSIG outputs and are willing
to ignore them. There are cases where they are the best and most efficient
technical solution, but let's put that to one side.
The primary difference after making the above changes are that no one node
gets a filter containing *all* our keys and addresses. I don't think a per
block pre-test filter would gain us much efficiency so from a privacy
perspective this is what it boils down to - sharding of the scan.
But we can already do this with the current Bloom filtering protocol.
BitcoinJ doesn't do so because having multiple parallel scans uses up
network IOPs which are a resource of unknown quantity, and because stepping
through the chain in parallel with multiple peers complicates the chain
sync implementation quite a bit.
*Second: this doesn't solve any real problem*
Who cares about collecting Bloom filters off the wire?
Commercial fraudsters? Doubtful. There are much easier ways to steal money.
Spies? Yes! Without a doubt NSA/GCHQ are building or have built databases
of IP addresses to Bitcoin addresses and are correlating it via XKEYSCORE
with other identifiable information.
However, just requesting data from different nodes doesn't help with that,
because they are doing DPI and can still see all the connections, so can
still combine all the filters or received transactions.
Ah, you say, but we're requesting everything via Tor.
Yes, about that. We've implemented that already. Some wallets even use it
by default, like Alon & Chris' Bitcoin Authenticator wallet. It's just one
line of code to activate.
Unfortunately there are severe practical problems to using Tor:
   1. If you don't have a warm consensus then booting it up is very slow.
   We're already slower than our competitors like blockchain.info and
   VISA/MasterCard, we can't make this any worse.
   This one is possibly not that big a deal and can be solved with more
   technical tricks.
   2. Bitcoin Core's DoS strategy means anyone can block all of Tor quite
   trivially. So we'd need some complicated fallback mechanism to disable Tor
   remotely, in case someone did this.
   3. Bitcoin wire traffic isn't encrypted or authenticated so it makes it
   much easier for trolls to tamper with lots of wire traffic at once, whereas
   without Tor it's much harder.
Let's ignore the fact that the Tor project insists on poking the law
enforcement bear with rusty nails, and has been receiving tipoffs about
plans to seize directory authorities. How much Bitcoin wallets should rely
on Tor sticking around is a debate for some other time.
There's a much simpler way to fix all of this - add opportunistic
encryption to the wire protocol.

@_date: 2015-02-21 15:45:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bloom filtering, privacy 
Well, what I mean is, bitcoinj already gets criticised for having very low
FP rates, but even with those rates we're applying them to hundreds of
thousands of transactions per sync. So it's still enough FPs to trigger at
least one per block, often several, yet people tell us this isn't enough to
give meaningful privacy.
Yup, see here:
Subspace looks like it's developing into what we need.
No, Tor is effective against in that threat model. What I meant is that
without Tor, someone doing wire intercepts isn't going to be fazed by using
multiple peers together, and with Tor it's not clear that syncing from
multiple peers in parallel gives much an additional win.
Also, getting Tor practical enough to activate by default is tricky. Though
the same people who are doing Subspace are trying it out to see what
secondly that other types of attackers are disinterested (how do we know
Some of my opinions are based on experience of HTTPS deployments, where
many of the same issues apply.
Yes, but what's the best way to fix that?
The calculation goes like this:  we have ~80 hours of hacking time to spend
on privacy this quarter. Do we:
a) Do wire encryption
b) Make Bloom filter clients smarter
c) Optimise Tor
d) Do a new PIR protocol from scratch and possibly run out of time having
failed to launch
Of these (d) is the least appealing to me, especially because I don't feel
like submitting SPV related stuff to Bitcoin Core any more. If I were to
work on the protocol it'd be in the context of Bitcoin XT, which rules out
consensus changes or other things that rely on miners. Wire encryption
would probably raise the bar for our spooky friends quite a lot, with
minimal effort. The ROI looks good, compared to more complex PIR.

@_date: 2015-02-21 17:47:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] bloom filtering, privacy 
No, I think it's less efficient (for the client).
Quick sums:  blocks with 1500 transactions in them are common today. But
Bitcoin is growing. Let's imagine a system 10x larger than today. Doesn't
seem implausible to reach that in the next 5-10 years, so 15,000
transactions. Each transaction has multiple elements we might want to match
(addresses, keys, etc).
Let's say the average tx contains 5 unique keys/elements. That's the base
case of {1 input, 2 outputs} without address reuse, plus fudged up a bit
for multi-sends then down a bit again for address reuse.
15,000*5=75,000 unique elements per block. With an FP rate of 0.1% we get:
131.63KB per block extra overhead.
144 blocks in a day, so that's 18mb of data per day's worth of sync to pull
down over the network. If you don't start your wallet for a week that's 126
megabytes of data just to get started.
Affordable, yes (in the west). Fast enough to be competitive? Doubtful. I
don't believe that even in five years mobiles will be pulling down and
processing that much data within a few seconds, not even in developed
But like I said, I don't see why it matters. Anyone who is watching the
wire close to you learns which transactions are yours, still, so it doesn't
stop intelligence agencies. Anyone who is running a node learns which
transactions in the requested block were yours and thus can follow the tx
chain to learn which other transactions might be yours too, no different to
today. If you connect to a single node and say "give me the transactions
sending money to key A in block N", it doesn't matter if you then don't
request block N+6 from the same peer - they know you will request it
eventually anyway, just by virtue of the fact that one of the transactions
they gave you was spent in that block.

@_date: 2015-02-23 11:58:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
You're right that just sending the session key is simpler. I originally
suggested doing ECDHE to set up an encrypted channel for the following
   1. URIs are put in QR codes more often than NFC tags. QR codes have
   limited space. The more stuff you pack into them, the slower and flakier
   the scanning process becomes.
   For normal wallets, doing ECDH over secp256k1 to derive a session key
   means we can reuse the address that was put in the URI already for
   pre-BIP70 wallets, thus we don't have to expand the URI at all except
   perhaps to flag that crypted Bluetooth connections are supported. Win!
   2. If the wallet is a watching wallet, this won't work and in that case
   you would need to put a separate key into the URI. However, this key is
   ephemeral and does not need to be very strong. So we can generate a regular
   secp256k1 key and then put say 5-8 prefix bytes into the URI as a new
   parameter. The public key can then be provided in full in the clear over
   the Bluetooth connection and the session key derived. If we put the session
   key into the URI in full, then we could not use this trick. Win!
   3. It's quite common in low tech scenarios like little coffee shops to
   just print a QR code and put it in the menu, or sticky tape it to the back
   wall of the shop.
   In these cases, it's possible that the device is actually hanging around
   in the shop somewhere but having the QR code somewhere larger and more
   accessible than the shop devices screen is highly convenient. However it
   means the data is entirely static.
   Putting/reusing an identity key from the URI means the session keys are
   always unique and known only to both devices, even though the bootstrap
   data is public.
   4. Doing ECDHE to derive the keys means we can derive a MAC key as well
   as an AES key. Otherwise you have the issue of exchanging both, which again
   uses up valuable bootstrap space.
So for a small increase in session setup complexity we potentially avoid
troubling problems down the line where people the same functionality from
NFC and QR code based bootstrap, but we can't provide it.
These discussions keep coming up. I think the next step is for someone to
upgrade Andreas' wallet to support encrypted connections and the TBIPs, to
see what happens.
Re: the h= parameter. I only objected to requiring this when the payment
request is also signed. It adds complexity, uses space, and the rationale
was "the PKI can't be trusted" even though it's been used to protect credit
card payments for 20 years without any issues. In the case of unsigned
payment requests, sure ... but with a proper implementation of an encrypted
Bluetooth channel it'd be unnecessary as the channel establishment process
would guarantee authenticity anyway.
But don't let me hold you guys back! I'd rather see something that works
than an endless debate about the perfect arrangement of hashes and URI
parameters :)

@_date: 2015-02-23 12:03:36
@_author: Mike Hearn 
@_subject: [Bitcoin-development] alternate proposal opt-in miner takes 
Beyond the fact that this risk can be priced in when enough data is
available, I'd be interested to talk to this merchant and dig into what
happened a bit.
For example:
   1. Was the dependent tx non-standard?
   2. Was it double spent?
   3. Could a wallet have co-operated with the P2P network to detect and
   flag whatever the issue was?
My own experience has been that when this happens, it's usually not the
result of outright maliciousness (especially not at a Bitcoin t-shirt
seller at a Bitcoin conference!) but rather something messed up somewhere
and the software in use just didn't detect it well enough.

@_date: 2015-02-23 13:18:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
Which situations do you mean? I think it can be used in every situation.
It's the opposite way around - a fixed session key in the URI cannot be
used in every situation.

@_date: 2015-02-23 21:31:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
We need a BIP70 conformance suite really. There are so many deviations from
the spec out there already and it's brand new :(

@_date: 2015-02-24 00:11:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
Sorry, I skipped a step. I shouldn't make assumptions about what's obvious.
The server would provide the public key and the client would convert it to
address form then match against the URI it has scanned. If it didn't match,
stop at that point.

@_date: 2015-02-24 11:41:01
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
You mean if the URI you're serving is like this?
   bitcoin:3aBcD........?bt=....
Yes it would. I guess then, the server would indicate both the script, and
the key within that script that it wanted to use. A bit more complex but
would still work to save URI space.

@_date: 2015-02-25 13:30:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Request for comments on hybrid PoW/PoS 
Hi Chris,
Just FYI you may not have received much feedback on this because Gmail put
it into the spam folder for some reason. So I'm guessing a lot of people
didn't see it.
My main feedback is - I do not really see how this is different from actual
mining. Mining also incentives the running of full nodes, miners are
rewarded via coinbases, etc. I'm missing a crisp description of why your
scheme is better than this, in particular, taking into account the
difficulty of distinguishing full node sybils of each other.

@_date: 2015-02-25 21:44:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Providing Payment Request within URI 
Andreas' wallet supports this, but don't do it. Payment requests can get
larger in future even without signing. Exploding the capacity of a QR code
is very easy.
Instead, take a look at the Bluetooth/NFC discussion happening in a
different thread.

@_date: 2015-01-09 14:20:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bi-directional micropayment channels with 
It's worth noting that the original protocol as designed by Satoshi did not
have this limitation. It has evolved this way because of ad-hoc DoS fixes
over time (btw I'm not saying they were the wrong thing to do, as non "ad
hoc" solutions are significantly more work). But it seems like eventually a
different approach to handling DoS attacks based on resource prioritisation
and scheduling will become needed / implemented, and at that point the
original design could be safely brought back to life.

@_date: 2015-01-09 14:42:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bi-directional micropayment channels with 
The original design is documented at the bottom of here:
In this design, time locked transactions can be broadcast across the
network and replaced by broadcasting a new transaction that uses higher
sequence numbers. That's what the sequence number field is for. It was
intended to allow arbitrary high frequency trading between a set of
parties, though the "channel" notion is a simple way to think about the two
party case.
The issue is that you can broadcast transactions with a lock time far in
the future to fill up memory, and keep broadcasting replacements to use up
CPU time and bandwidth.
Additionally, there is a school of thought that says Bitcoin must work even
if lots of miners are malicious and willing to break arbitrary things in
order to try and get more money. I don't think Bitcoin can really be a
mainstream success under such a threat model, for a whole bunch of reasons
(e.g. the economy relies pretty heavily on unconfirmed transactions), but
under such a threat model there's nothing that forces miners to actually
include the latest version in the block chain. They could pick any version.
In the 2-of-2 channel model it takes both parties to sign, so clients can
enforce that all versions have the same fee attached.
I disagree with Gregory that people refuse to use protocols that are
affected by malleability. There aren't any user-friendly apps that use
refunds currently, so we have no idea whether people would refuse to use
them or not. It's an open question. The answer would probably depend on the
real prevalence of attacks, which is currently unknowable and likely
application specific.

@_date: 2015-01-09 15:00:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] A look back and a look forward 
I think the observation about Target vs Bitcoin exchanges is a sharp one,
but I'm not sure how your proposal helps. You say it's an optional identity
layer, but obviously any thief is going to opt out of being identified.
For things like the Bitstamp hack, it's not clear how identity can help,
because they were already doing KYC for all their customers. To take that
further at the protocol level would require* all* transactions to have
attached identity info, and that isn't going to happen - it wouldn't be
Bitcoin, at that point.
I think that long term, it's probably possible to defend private keys
adequately, even for large sums of money (maybe not bitstamp-large but
we'll see). You can have very minimalist secure hardware that would have
some additional policies on top, like refusing to sign transactions without
an identity proof of who controls the target address. Very tight hot
wallets that risk analyse the instructions they're receiving have been
proposed years ago.
No such hardware presently exists, but that's mostly because
implementations always lag behind a long way behind ideas rather than any
fundamental technical bottleneck. Perhaps the Bitstamp event will finally
spur development of such things forward.

@_date: 2015-01-11 19:56:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Bi-directional micropayment channels with 
Firstly, apologies to Nathan for not actually providing feedback on his
protocol. I've put pondering it onto my mental todo list. The notion of a
payment tree is interesting but complicated - I would need to think about
it and maybe draw myself some diagrams before having useful feedback here.
If you wanted to implement it, you could fork the existing code in bitcoinj
and extend it with the new functionality.
I raised the original Satoshi design mainly to inform and so the approaches
can be compared. It may well be that this proposed protocol is superior in
every way, in which case the nSequence approach would be of no further use,
assuming Nathan's protocol generalises to n-party HFT.
Replying now to Gregory:
I think we agree, and are just phrasing things differently (or slowly
groping towards consensus at the speed of email threads :-).
It's likely that over time Bitcoin will end up being multi-layered, with
the block chain being the base layer that syncs everyone up, and higher
layers doing things that miners either can't do or can't be trusted to do.
Like the proposal from GreenAddress to be a well known signer who is
trusted to not double spend.
if cost(fraud) < benefit, at the moment unconfirmed transactions appear to
be an example of that, and putting resource control considerations to one
side, it's possible that tx replacement would be the same. Or not. The
calculation for miners isn't easy, because if they play by the rules then
they may have a long term and reliable income stream, but if they break the
rules then that payment traffic will migrate to other solutions and they
end up with nothing. Whether it's worth it depends on how long term they're
If we imagine a hypothetical future where lots of economic activity is
being done over Satoshi-style replaceable contracts, and suddenly a new big
short-termist miner comes along who decides that just breaking the rules
will give him more profit before the business dries up, what would happen?
If fraud costs get too extreme the old fallback of a purely centralised
solution is always there - for software compatibility purposes this would
look like a trusted node who doesn't broadcast the transactions at all and
just keeps them centrally, then mines or broadcasts the final version
themselves. Client apps would just be configured to connect directly to
that node.
Making that more competitive means having more such nodes/miners, until
eventually you have a network of miners that are regulated by identity and
bannable and don't share the tx's outside their network. That probably gets
you 95% of the benefit of the old model with maybe 150% (wild ass guess) of
the costs. "Identity" in this case can mean lots of fancy crypto things
beyond old-fashioned govt name+address style.
I don't think that'd be just an expensive and inefficient PayPal, as you'd
still have the key difference that simplifies so much - the trusted third
party doesn't hold any funds on deposit and can't directly
steal/lend/gamble with any funds. To earn money by being corrupt requires
complicated schemes where they strike secret deals to favour one party or
another, and that corruption can then be easily detected and published, so
it seems like the risk is much lower.
Bitcoin is already a pretty complex ecosystem with different kinds of trust
and decentralisation models in use. I see the next 5-10 years as a giant
cost optimisation experiment  .... where are the best settings of the
various decentralisation/speed/fees/complexity/identity knobs for different
kinds of people?

@_date: 2015-01-19 20:37:22
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: why Google Protocol Buffers for 
The engineers at Google were well aware that ASN.1 existed. I can assure
you of that, because I was one of them.
The protobuf FAQ has a very polite take on the matter:
   This email thread gives more enlightenment:
   Anyone who has actually had to work with both ASN.1 and protocol buffers
will be able to explain why ASN.1 should not be chosen for any modern
formats. A lot of it boils down to simplicty and quality of
implementations, especially open source implementations.
With respect to the specific concerns Richard raises:
Performance doesn't feel that relevant when you think that:
Performance wasn't a concern.
HTTP transmits files as binary on the wire. So it's binary-clean and,
moreover, HTTP/2 aka SPDY is fully binary and doesn't use text anywhere
except the gzip dictionary.
Luckily, this is also true of protocol buffers. Language support is pretty
good these days.
BIP 70 doesn't contain any code, as far as I know. The protobuf schema
might look like code, but it's not - it's just a description of what fields
a message can contain and their types. This is very relevant for a
JSON in particular is pretty awful and I don't like it much. It suffers
complexities with things as basic as encoding numbers and strings. It's
very much unsuited to applications where correctness matters and where
you're dealing with binary structures.

@_date: 2015-01-19 21:40:13
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: why Google Protocol Buffers for 
It's not guaranteed no, which is why we store signed sub-messages as byte
arrays instead of typed submessages. In practice though, most
implementations do seem to serialise things the same way. I recall Python
used to be an odd one out, unsure if it still is.
OK, I guess we can boil this down more simply. BIP 70 uses protocol buffers
because I designed it and implemented the original prototype (with lots of
input from Gavin and an earlier proposal by sipa). I used protocol buffers
because, beyond all their nice properties, I used to work at Google and so
was very familiar with them.

@_date: 2015-01-22 14:20:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Deanonymisation of clients in Bitcoin P2P 
I think there was some misunderstanding. I was saying they *could and
should* share common cores, so we are in agreement without realising it :)
I also didn't mean to imply there was anything special about bitcoinj, just
that it's an example of a wallet engine that's already in use.
Because it's intended to be submitted via HTTPS. But what would you sign
the message with? Some arbitrary key bound to the transaction?

@_date: 2015-01-28 16:42:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: why Google Protocol Buffers for 
That's what cross-platform abstraction libraries are for. Both Java and Qt
provide a key store library that can load from either the OS root store or
a custom one. If your chosen app platform doesn't, OK, then you'll have to
make or find one yourself. Perhaps contribute it upstream or make it a
library. But that's not a limitation of BIP70.
Just as a reminder, there is no obligation to use the OS root store. You
can (and quite possibly should) take a snapshot of the Mozilla/Apple/MSFT
etc stores and load it in your app. We do this in bitcoinj by default to
avoid cases where BIP70 requests work on some platforms and not others,
although the developer can easily override this and use the OS root store
Of all possible solutions, using a third party service to convert things to
JSON is one of the least obvious and highest effort. I don't know anyone
else who arrived at such a conclusion and respectfully disagree that this
is a problem with the design choices in BIP70. It sounds like a bizarre
hack around lack of features in whatever runtime you're using.

@_date: 2015-01-28 17:55:43
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: why Google Protocol Buffers for 
Platforms that support HTTPS but not certificate handling are rare - I know
HTML5 is such a platform but such apps are inherently dependent on the
server anyway and the server can just do the parsing and validation work
itself. If WinRT is such a platform, OK, too bad.
The embedding of the certificates is not arbitrary or pointless, by the
way. It's there for a very good reason - it makes the signed payment
request verifiable by third parties. Effectively you can store the signed
message and present it later to someone else, it's undeniable. Combined
with the transactions and merkle branches linking them to the block chain,
what you have is a form of digital receipt ... a proof of purchase that can
be automatically verified as legitimate. This has all kinds of use cases.
Because of how HTTPS works, you can't easily prove to a third party that a
server gave you a piece of data. Doing so requires staggeringly complex
hacks (see tls notary) and when we designed BIP70, those hacks didn't even
exist. So we'd lose the benefit of having a digitally signed request.
Additionally, doing things this way means BIP70 requests can be signed by
things which are not HTTPS servers. For example you can sign with an email
address cert, an EV certificate i.e. a company, a certificate issued by
some user forum, whatever else we end up wanting. Not every payment
recipient can be identified by a domain name + dynamic session.
That's a bit melodramatic. BitcoinJ is able to use the Android, JRE,
Windows and Mac certificate stores all using the same code or very minor
variants on it (e.g. on Mac you have to specify you want the system store
but it's a one-liner).
Yes, that's not *every* platform. Some will require custom binding glue and
it depends what abstractions and languages you are using.
There is code to do iOS using the Apple APIs here:
WinRT is a minority platform in the extreme, and all the other platforms
you mentioned have the necessary APIs. Java abstracts you from them. So I
think you are encountering this problem because you desire to target WinRT
and other platforms with a single codebase. That's an unusual constraint.
AFAIK the only other people who encountered this are BitPay, because they
want to do everything in Javascript which doesn't really provide any major
Yes, there are pros and cons to bundling a custom root store.
It can do OCSP checks, yes, although I believe no wallets currently do so.
A better solution would be to implement an OCSP stapling extension to BIP70

@_date: 2015-01-28 18:02:15
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: why Google Protocol Buffers for 
If your wallet is unmaintained, you have other problems beyond (extremely
rare) root CA revocations.
As far as I know the only time a CA in wide usage has been revoked entirely
is DigiNotar.
One advantage of doing it this way is if, for example, a widely used piece
of community infrastructure (e.g. bitcointalk, reddit, whatever) decides to
become a CA, the Bitcoin community can decide to have different inclusion
rules vs the OS/browser root CA programs. For example we'd probably relax
the constraint to use an HSM and just ensure that the rendering of the
asserted identity isn't confusible with other kinds of more strongly
protected identities. For example no forum usernames like "foo.com" but
rendering it in the UI as "Reddit forum user foo.com" would be OK.
Also you don't get problems due to old operating systems not including new
Finally, Linux doesn't have any kind of standardised cert/keystore API.
There are a few places where popular distros put certs but AFAIK they
aren't standardised and there's no standard code to load them. So that's
another reason why there's a built in store.
But yes, this is a debatable topic on which reasonable people can disagree.
The API makes it easy to use the platform OS store for wallet devs that
want to do that, and I think using the platform store on Android is the
default. It's only on the desktop where we fall back to a different store.

@_date: 2015-01-28 18:14:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: why Google Protocol Buffers for 
I think we'll just have to agree to disagree on this one. I've implemented
BIP70 a couple of times now and didn't find it to be difficult. I know you
had odd problems with the C# protobuf implementation you were using but
library bugs can happen for any kind of programming.
I forgot to mention the other reason it's done this way. One of the driving
goals of BIP70 was to support the TREZOR and similar devices. For hardware
wallets, it's critical to keep the amount of code they need to run as small
as possible. Any bugs in the code there can cause security holes and lead
to the device being hacked.
Doing it the way you suggest would mean the secure code would have to
contain complex and bug-prone text parsing logic as well as a full blown
HTTP and SSL stack, that requires not only X.509 handling but also lots of
other stuff on top. It'd increase cost, complexity and decrease security
quite a bit.
Whilst I appreciate if your platform provides a scripting-like API and
nothing low level it might seem easier to use JSON+HTTPS, that isn't the
case for one of the primary design targets.
On Wed, Jan 28, 2015 at 6:04 PM, Nicolas Dorier

@_date: 2015-01-28 18:45:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP70: why Google Protocol Buffers for 
To back Jeff up on this point, today we see this story:
The maker of BlackPhone ? a mobile marketed as offering unusually high
levels of security ? has patched *a critical vulnerability that allows
hackers to run malicious code on the handsets*. Attackers need little more
than a phone number to send a message that can compromise the devices via
the Silent Text application.
"The SCIMP protocol encodes messages as JSON objects, which are then
transmitted to the remote party over XMPP," Dowd explained to *The Register*.
"*The flaw I discovered occurs during the deserialization of these JSON
objects*. It is *a type confusion vulnerability*, which when exploited
allows an attacker to overwrite a pointer in memory, either partially or in
full. This pointer is later manipulated by the program and also the system
allocator, allowing you to do things such as pass arbitrary pointers to
The C++/Java/Python protocol buffer implementations are used by Google for
all internal inter-server communication. Any similar exploit in them would
result in total bypass of their entire internal security and auditing
system by allowing you to run code as any user. The Google security team is
very good, the protobuf code is carefully reviewed and the format is
relatively constrained. The chances of there being any security problems in
the parsing code generated by the protobuf compilers is drastically
smaller. As BIP70 requests are parsed by security sensitive code, this
The vision for BIP70 has always been to be a foundation for many features.
We haven't really done much with it so far because there have always been
higher priorities. But I hope that if Bitcoin continues to be successful
and grows, one day payment requests will have many different features in
them and those will likely include many complex data structures.

@_date: 2015-01-31 18:04:52
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Is there a way to estimate the maximum 
I know China is a very big place but even so - 47,500 transactions per
second would be almost quintiple what Visa handles across the entire world.
With only 300 million users and primarily online usage (?) this claim feels
a little suspect to me.
Given the wording "up to 2.85 million" I wonder if that is some freak spike
caused by people's behaviour being synchronised externally (e.g. a fixed
start time for the sale that people are waiting for). It's hard to imagine
that they sustained anything close to that for the entire day.
So this is really a discussion about peak performance.
If you average every transaction around 250 bytes, then you'd need ~15
There's a discussion of such things here that might be useful:
It discusses various optimisations, like not actually sending tx data twice.
I wouldn't worry about it too much. It took decades for Visa to even
approach 10,000 txns/sec. PayPal, I believe, still "only" handles a few
hundred. And those services had the benefits of minimal competition,
working in people's local currencies, integrated dispute mediation and not
representing any real threat to the political status quo. Bitcoin isn't
going to be needing to handle Alipay's level of traffic any time soon.
Frankly, scaling is a nice problem to have, it means you're popular. It'd
be a mistake to just blindly assume Bitcoin will take over the world.
Growing market share is difficult. Worry more about how to get 300 million
crazy users than the precise broadcast protocol that'd be needed to handle
them ;)

@_date: 2015-01-31 18:19:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP: protocol for multisignature 
Hi Martin,
You're on the right lines. Your writeup is pretty similar to the high level
overview given here though:
To make 2-of-3 dispute mediation works requires implementing a wallet that
supports it, and the tools mediators need to manage incoming tickets, etc.
The BIP70 extension is probably the smallest part of the project.
On Sat, Jan 31, 2015 at 2:30 AM, Martin Habov?tiak <

@_date: 2015-01-31 19:07:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New BIP: protocol for multisignature 
IMO it's better to pair a protocol spec with an implementation. For one, it
can show up issues in the design you didn't think of. For another,
implementation is a lot more work than speccing out a few protocol buffers
and high level procedures, so people who are going to write an
implementation probably won't follow your design unless they have a great
degree of confidence in it and some compelling reason to use it (e.g.
interop with other users).

@_date: 2015-06-01 12:13:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
Whilst it would be nice if miners in China can carry on forever regardless
of their internet situation, nobody has any inherent "right" to mine if
they can't do the job - if miners in China can't get the trivial amounts of
bandwidth required through their firewall and end up being outcompeted then
OK, too bad, we'll have to carry on without them.
But I'm not sure why it should be a big deal. They can always run a node on
a server in Taiwan and connect the hardware to it via a VPN or so.

@_date: 2015-06-01 15:21:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
Then please enlighten me. You're unable to download block templates from a
trusted node outside of the country because the bandwidth requirements are
too high? Or due to some other problem?
With respect to "now it's your turn". Let's imagine the hard fork goes
ahead. Let us assume that almost all exchanges, payment processors and
other businesses go with larger blocks, but Chinese miners do not.
Then you will mine coins that will not be recognised on trading platforms
and cannot be sold. Your losses will be much larger than from orphans.
This can happen *even* if Chinese miners who can't/won't scale up are >50%
hashrate. SPV clients would need a forced checkpoint, which would be messy
and undesirable, but it's technically feasible. The smaller side of the
chain would cease to exist from the perspective of people actually trading
If your internet connectivity situation is really so poor that you cannot
handle one or two megabits out of the country then you're hanging on by
your fingernails anyway: your connection to the main internet could become
completely unusable at any time. If that's really the case, it seems to me
that Chinese Bitcoin is unsustainable and what you really need is a
China-specific alt coin that can run entirely within the Chinese internet.

@_date: 2015-06-01 17:33:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
I'm OK with a smaller size + a formula that ramps it up over time. We are
far from having enough demand to fill 10MB blocks, let alone 20MB today.
To put it in perspective, to be feeling squeezed inside 10MB within two
years, we would need to double usage five times. I wish I knew a way to
make that happen. So the chances of us going to 20MB blocks full of real
transactions any time soon is close to zero short of some amazing killer
app that takes the world by storm (in which case: yay, nice problem to
have). As long as capacity significantly outpaces organic growth, we should
avoid problems.
The reason to pick 20MB then is merely one of expedience: we have to pick a
number, 20 is tested and seems to work, and we don't want to get caught by
surprise if demand does outstrip expectations.
Still, I question the underlying logic. We have no idea what connectivity
into China will look like a few years from now: it's seems to be a function
of politics rather than hardware trends. It might go down rather than up.
So 10 vs 20 feels a bit arbitrary. We can't let the Chinese government
dictate how Bitcoin is used, that would never be accepted by the rest of
the world. But if we optimistically assume things don't get worse, and 10
== more acceptance, then alright - it should make no difference in practice.

@_date: 2015-06-01 17:55:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
I agree that it is a waste of time. Many agree. The Bitcoin ecosystem
doesn't really need lobbying - my experience from talking to businesses and
wallet developers months ago is they virtually all see raising capacity as
a no brainer ... and some of them see this "debate" as despair-inducing
What's happened here is that a small number of people have come to believe
they have veto power over changes to Bitcoin, and they have also become
*wildly* out of step with what the wider community wants. That cannot last.
So, short of some sudden change of heart that lets us kick the can down the
road a bit longer, a fork is inevitable.
Just be glad it's Gavin driving this and not me ... or a faceless coalition
of startups.
No. Usage is what gives Bitcoin value.
It's kind of maddening that I have to point this out. Decentralisation is a
means to an end. I first used Bitcoin in April 2009 and it was perfectly
decentralised back then: every wallet was a full node and every computer
was capable of mining.
So if you believe what you just wrote, I guess Bitcoin's value has gone
down every day since.
On the other hand, if you believe the markets, Bitcoin's value has gone up.
Apparently the question of what gives Bitcoin its value is a bit more
complicated than that.
I have seen this notion a few times. I would like to dispose of it right
I am one of the wallet developers you would be trying to "incentivise" by
letting Bitcoin break, and I say: get real. Developers are not some
bottomless fountain of work that will spit out whatever you like for free
if you twist their arms badly enough.
The problems that incentivised the creation of Bitcoin existed for decades
before Bitcoin was actually invented. Incentives are not enough. Someone
has to actually do the work, too. All proposals on the table would:
   - Involve enormous amounts of effort from many different people
   - Be technically risky (read: we don't know if they would even work)
   - Not be Bitcoin
The last point is important: people who got interested in Bitcoin and
decided to devote their time to it might not feel the same way about some
network of payment hubs or whatever today's fashion is. Faced with their
work being broken by armchair developers on some mailing list, they might
just say screw it and walk away completely.
After all, as the arguments for these systems are not particularly logical,
they might slave over hot keyboards for a year to support the Lightning
Network or whatever and then discover that it's no longer the fashionable
thing ... and that suddenly an even more convoluted design is being

@_date: 2015-06-01 18:12:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] soft-fork block size increase (extension 
Hi Adam,
I have more experience than Gavin of building consumer wallets, so I'll
make an attempt to answer your questions.
I am a wallet developer and I am telling you that it is.
I don't see how this is the case. If an exchange supports extension blocks
and I withdraw from that to a wallet that doesn't, the money will never
arrive from my perspective. Yet the exchange will claim they sent it and
they will wash their hands of the matter. Disaster.
I am not a UX guy
But I am. I've designed both consumer and engineering UI's at Google, and
also more recently for Lighthouse.
Attempting to explain to a user why they sent money that didn't show up on
the other end is a non starter. It's bad enough when things take a long
time to confirm or bugs cause propagation failures. Doing it
deliberately is not going to work. Payments *must* be reliable and wallets
*must* be compatible with each other.
This is one reason why a Lightning style approach also isn't going to work
any time soon. For example, it would require people to abandon Bitcoin
addresses. I pushed for that before, around the P2SH time, and Gavin
correctly intuited that the community wasn't ready for it yet. I'm not sure
much has changed.
I disagree with all of those points. I find Lightning/Stroem etc to be more
dangerous, less flexible, and worse for decentralisation. I explain why
You mentioned decentralisation metrics. Gregory's post is ignoring one of
the most important decentralisation metrics, which is number of wallets
made by independent developers. That has got dramatically better over time.
It would get worse if wallets became more complex very suddenly.
companies entirely, which will give you a radically more distorted view of
the consensus. As companies providing services to our community have
serious economic weight, it stands to reason that their opinions would
matter a great deal. Yet on this mailing list I see zero effort to even
recognise their concerns, let alone care about them.
Anyway, let me repeat again to make it clear - as someone who has spent
five years writing SPV wallets, I am not on board with extension blocks or
any other Rube Goldberg contraption that exists purely to work around
theoretical objections by Blockstream employees+Peter Todd, which is what
this feels like to me.

@_date: 2015-06-01 20:01:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] soft-fork block size increase (extension 
Well, yes. Isn't that rather key to the issue?  Whereas by simply
increasing the block size, SPV wallets don't care (same security and
protocol as before) and fully validating wallets can be updated with a very
small code change.
Let's say an old client makes a payment that only gets confirmed in an
extension block. The wallet will think the payment is unconfirmed and show
that to the user forever, no?
Can you walk through the UX for each case?
It would be Satoshi, that argued that.
I think there must be a communication issue here somewhere. I'm not sure
how this meme has taken hold amongst you guys, as I am the guy who wrote
the scalability page back in 2011:
It says:
*The core Bitcoin network can scale to much higher transaction rates than
are seen today, assuming that nodes in the network are primarily running on
high end servers rather than desktops. *
By "much higher rates" I meant VISA scale and by "high end server" I meant
high end by today's standards not tomorrows. There's a big difference
between a datacenter and a single server! By definition a single server is
not a datacenter, although it would be conventional to place it in
one. But even
with the most wildly optimistic growth imaginable, I couldn't foresee a
time when you needed more than a single machine to keep up with the
transaction stream.
And we're not going to get to VISA scale any time soon: I don't think I've
ever argued we will. If it does happen it would presumably be decades away.
Again, short of some currently unimagined killer app.
So I don't believe I've ever argued this, and honestly I kinda feel people
are putting words in my mouth.

@_date: 2015-06-01 20:30:20
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
I don't see this as an issue of sensitivity or not. Miners are businesses
that sell a service to Bitcoin users - the service of ordering transactions
chronologically. They aren't charities.
If some miners can't provide the service Bitcoin users need any more, then
OK, they should not/cannot mine. Lots of miners have come and gone since
Bitcoin started as different technology generations came and went. That's
just business.

@_date: 2015-06-02 13:03:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
magnitude more decentralized.
Yet Bitcoin has got worse by all these metrics: there was a time before
mining pools when there were ~thousands of people mining with their local
CPUs and GPUs. Now the number of full nodes that matter for block selection
number in the dozens, and all the other miners just follow their blocks
If you really believe that decentralisation is, itself, the end, then why
not go use an "ASIC resistant" alt coin with no SPV or web wallets which
resembles Bitcoin at the end of 2009? That'd be a whole lot more
decentralised than what you have now.
The *percentage* of the community that mines is totally irrelevant, it's
So usage does matter, then? You'd rather have a coin that has power
concentrated in a far smaller elite, proportionally, but has overall more
usage? If there are say, 5000 full nodes today, and in ten years there are
6000, and they all run in vast datacenters and are owned by large
companies, you'll feel like Bitcoin is more decentralised than ever?
(n.b. I do not think this situation will ever happen, it's just an example).
That's not the vibe I'm getting from most people on this list. What I'm
seeing is complaints about how in the good old days back when Core was the
only wallet and ASICs hadn't been made,  there were lots of nodes and lots
of people mining solo and since then it's all been downhill and woe is us
... and let's throw on the brakes in case it gets worse.
Not for the first time, these discussions remind me very strongly of the
old desktop Linux/free software debates.

@_date: 2015-06-02 13:26:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] 
Obviously if the majority of the mining hash rate is doing double spending
attacks on exchanges then the Bitcoin experiment is resolved as a failure
and it will become abandoned. This has been known since day one: it's in
the white paper. The basic assumption behind Bitcoin is that only a
minority of actors are dishonest - if the majority are then Satoshi's
scheme does not work.
So you are not stating anything new here.

@_date: 2015-06-02 16:20:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] DevCore London 
Hi there,
I got some requests to re-record the tutorial talk I gave at DevCore 2015,
"How to build a timestamping smart contracts app in 30 minutes". It's now
available here:
    It covers:
   - How to customise the wallet-template app for this use case
   - How to construct a complex multi-stage SPV proof of block chain
   inclusion
   - How to save and then verify proof files
   - How to bind transaction confidence state to the user interface
   - How to create a Mac DMG bundle with a custom icon
I hope someone finds it enjoyable!

@_date: 2015-06-10 22:26:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: SPV Fee Discovery mechanism 
I described an alternative way for SPV wallets to learn about fees some
time ago. It requires a new transaction version that embeds output values
into the signed data. Then an upgrade to the P2P protocol to send UTXO data
along with transactions when they are relayed.
The idea is that the wallet sets a Bloom filter with an FP rate that
ensures it will see some random subset of all transactions being broadcast
on the network, and with the extra data, it can calculate the fee paid.
Once a transaction broadcast is observed the wallet includes that tx hash
in its next Bloom filter, thus it can see which block the tx confirmed in.
By measuring the amount of time that passed between a broadcast and it
appearing in a block, it can calculate its own tables of fee paid:time
This has the advantage that you don't have to trust miners to publish data
accurately. However it requires some protocol upgrades and of course, a lot
of new code in SPV wallets.
The way Bitcoin Wallet for Android handles fees currently is to just update
a hard coded value every so often.

@_date: 2015-06-11 12:19:09
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: SPV Fee Discovery mechanism 
Yeah, my proposal is not intended to function correctly with full blocks,
as Bitcoin cannot work at all in such a state. It assumes that fees only
change slowly and that transactions are being cleared normally.

@_date: 2015-06-11 19:52:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: SPV Fee Discovery mechanism 
No, Aaron is correct. It's unpredictable from the perspective of the user
sending the transaction, and as they are the ones picking the fees, that is
what matters.

@_date: 2015-06-12 20:24:50
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Mining centralization pressure from 
That's very slow indeed. For comparison, plain old 3G connections routinely
cruise around 7-8 Mbit/sec.
So this simulation is assuming a speed dramatically worse than a mobile
phone can get!

@_date: 2015-06-15 00:23:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] comments on BIP 100 
Um, you mean except all the people who have built more scalable wallets
over the past few years, which is the only reason anyone can even use
Bitcoin from their phone? Or maybe you mean initiatives like Lightning ....
except StrawPay already developed something similar to the Lightning
network (complete with a working GUI wallet) and were ignored by
Blockstream as you prefer to write your own from scratch?
Sure, people in the industry take development initiatives. That doesn't
mean their work will be recognised on this mailing list.
"The laggards" being *everyone* who has already invested in building
Bitcoin software so far. Not a great way to frame things. Many of those
"laggards" have written orders of magnitude more code than you or Gregory
or Jeff, for instance.
I still think you guys don't recognise what you are actually asking for
here - scrapping virtually the entire existing investment in software,
wallets and tools.
Bitcoin does not have n-squared scaling. I really don't get where this idea
comes from. Computational complexity for the entire network is O(nm) where
n=transactions and m=fully validating nodes. There is no fixed
relationships between those two variables.
"Exposing the companies to back-pressure" sounds quite nice and gentle. Let
me rephrase it to be equivalent but perhaps more direct: you mean "breaking
the current software ecosystem to force people into a new, fictional system
that bears little resemblance to the Bitcoin we use today, whether they
want that or not".
As nothing that has been proposed so far (Lightning, merge mined chains,
extension blocks etc) has much chance of actual deployment any time soon,
that leaves raising the block size limit as the only possible path left.
Which is why there will soon be a fork that does it.

@_date: 2015-06-15 00:26:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] User vote in blocksize through fees 
Reposting as Jeff's mail got eaten by the anti-phishing filters, due to
SourceForge's obsolete mailman setup.

@_date: 2015-06-15 11:06:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] comments on BIP 100 
There's a brief discussion here:
But yes, they are developing it before publishing more details that may be
subject to change post-implementation experience anyway.
Great!  I am waiting for Gavin to finish writing the patches. Once he has a
patch and there's been some time for review, I guess it will go in,
assuming no other issues.

@_date: 2015-06-15 11:27:24
@_author: Mike Hearn 
@_subject: [Bitcoin-development] comments on BIP 100 
OK, good to hear that. I'm not happy about the use of web technologies in
wallets/services either, but the causes of that trend are nothing to do
with block chain sizes. It's more because there's a generation of
developers who see no alternatives.
With projects like Lighthouse, I'm trying to show people that they can
blend the good bits of the web with the good bits of more traditional
client side development, at a cost they can afford.
Unfortunately, as you know, one of the reasons that developers turn to
outsourced services is that those services actually like developers and
give them the features they need. Whereas any attempt to add protocol
features for app/wallet developers to Bitcoin Core becomes controversial
due to some perceived or real lack of perfection.
I persevered for several months to add a very small "API" I needed for my
app to Bitcoin Core, and it was in the end a waste of time. There are no
actionable items left for the getutxo patch, regardless, I had to fork
Bitcoin to get it out there. It would have been *much* easier to just say,
fuck it, I'll use blockchain.info and in fact some in this community told
me to do exactly that. But, the approach I chose has been working fine for
months now.
Compare this experience to companies like chain.com, blockcypher etc - when
developers say jump, they say "how high?"
So It's unreasonable for the Bitcoin Core developer group to constantly
call developers building apps idiots or "non technical" (as I see so often
in this block size debate), and then complain that people don't write apps
in their preferred way! Just accept that decentralised app dev is already
hard, and the way Core is run makes it much harder still.
As I said I dont think we can expect Bitcoin to scale with no further
A big part of the debate around this change is showing that this statement
is wrong. "Scaling" is not some kind of binary yes/no thing. It's a
continuous effort. You write a system that scales a certain amount, and
then if you find you need more capacity, you scale it again. Maybe that
 involves rewriting the existing code or maybe it just means improving what
you've got.
Or maybe (painful truth coming up) your product is not that compelling, or
times change and your users leave, and you discover you never actually need
to scale to the giddy heights originally envisioned.
A big part of the reason modern web dev is so messed up is that lots of
developers starting thinking every app they built needed to be "web scale"
from day one. SQL databases? Pah. Doesn't scale. Think big. We gotta no
NoSQL sharded key/value store from the start! Otherwise we're just showing
lack of confidence in our own product.
Then when they used up all their budget solving consistency bugs a
relational database would have avoided, they notice their competitors
sailing past them on a not-fully-scalable but certainly-scalable-enough
architecture that let them focus on features and making users happy.
OK. O() notation normally refers to computational complexity, but ... I
still don't get it - the vast majority of users don't run relaying nodes
that take part in gossiping. They run web or SPV wallets. And the nodes
that do take part don't connect to every other node.
Alright - let's agree that we disagree on a few areas, like the relative
desirability of alternative non-blockchain designs - but we do seem to
agree that there is a case for an increase in the block size limit. That
seems like progress.
As you agree with that, what sort of schedule and time are you thinking of?
(well, by "you" I really mean blockstream because it's taking forever to
try and negotiate with every single person individually).

@_date: 2015-06-15 11:56:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] questions about bitcoin-XT code fork & 
Hi Adam,
Provisional answers below!
- Are you releasing a BIP for that proposal for review?
The work splits like this:
   - Gavin is writing the code and I think a BIP as well
   - I will review both and mostly delegate to Gavin's good taste around
   the details, unless there is some very strong disagreement. But that seems
   unlikely.
   - I have been handling gitian and the patch rebases, the code signing
   and so on, so far. I've also been doing some work to setup the basic
   infrastructure of the project (website etc).
- If the reviewers all say NACK will you take on board their suggestions?
Feedback will be read. There are no NACKS in Bitcoin XT. Patch requests
aren't scored in any way. The final decision rests with the maintainer as
in ~all open source projects.
Yes, I have been working on an article that explains how we got to this
point from my perspective. It is quite long, but only because I want it to
be readable for people who weren't following the debate.
Anyway, I think I've laid out the gist of it over and over again, but to
If Bitcoin runs out of capacity *it will break and many of our users will
leave*. That is not an acceptable outcome for myself or the many other
wallet, service and merchant developers who have worked for years to build
an ecosystem around this protocol.
The approach is the same for other forks. Voting via block versions and
then when there's been >X% for Y time units the 1mb limit is
Good question!  I have various thoughts on this, but let's wait and see
what happens first. Perhaps the new chain won't get the majority on it.
In the event that the >1mb chain does eventually win, I would expect Core
to apply the patch and rejoin the consensus rather than lose all its users.
That would take XT back to being a fairly small patchset to improve the
network protocol.
- Do you have contingency plans for what to do if the non-consensus
Where did you get the $3B figure from? The fork either doesn't happen, or
it happens after quite a long period of people knowing it's going to happen
- for example because their full node is printing "You need to upgrade"
messages due to seeing the larger block version, or because they read the
news, or because they heard about it via some other mechanisms.
Let me flip the question around. Do you have a contingency plan if Bitcoin
runs out of capacity and significant user disruption occurs that results in
exodus, followed by fall in BTC price? The only one I've seen is "we can
perform an emergency hard fork in a few weeks"!
Gavin and I have been polling many key players in the ecosystem. The
consensus you seek does exist. All wallet developers (except Lawrence), all
the major exchanges, all the major payment processors and many of the major
mining pools want to see the limit lifted (I haven't been talking to pools,
Gavin has).
This notion that the change has no consensus is based on you polling the
people directly around you and people who like to spend all day on this
mailing list. It's not an accurate reflection of the wider Bitcoin
community and that is one of the leading reasons there is going to be a
fork. A small number of people have been flatly ignoring LOTS of highly
technical and passionate developers who have written vast amounts of code,
built up the Bitcoin user base, designed hardware and software, and yes
built companies.
How do you think that makes Bitcoin Core look to the rest of the Bitcoin
world? How much confidence does that give people?
Of the overall process, I think you can agree we should not be making
This debate will never end until a fork makes it irrelevant. There is no
process for ending it, despite me begging Wladimir to make one.
And there is no haste. We have been debating the block size limit for
*years*. We have known it must be lifted for *years*. I kicked off this
current round of debates after realising that Wladimir's release timeline
wouldn't allow a block size limit to be released before the end of the
year. The reason we're talking about it now and not next year is exactly to
ensure there is plenty of time.
I really wish you were right, and I definitely feel you are one of the more
reasonable ones Adam. But the overwhelming impression I get from a few
others here is that no, they don't want to scale Bitcoin. They already
decided it's a technological dead end. They want to kick end users out in
order to "incentivise" (force) the creation of some other alternative,
claiming that it's still Bitcoin whilst ignoring basic details ... like the
fact that no existing wallets or services would work.
Scaling Bitcoin can only be achieved by letting it grow, and letting people
tackle each bottleneck as it arises at the right times. Not by convincing
ourselves that success is failure.

@_date: 2015-06-15 12:13:32
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposal: Move Bitcoin Dev List to a 
Bear in mind the problem that stops Jeff's messages getting through is that
mailman 1.0 doesn't know how to handle DKIM properly. Switching to a
different mailman provider won't fix that.
Does mailman 3.0 even fix this? I found it difficult to tell from their
website. There's a big page on the mailman wiki that suggests they "fixed"
it by simply deleting the signatures entirely, which won't work. DMARC
policies state that mail *must* be signed and unsigned/incorrectly signed
message should be discarded.
The user documentation for mailman 3 doesn't seem to exist? The links on
the website are docs for 2.1, perhaps they released mailman 3 without
refreshing the docs.
Google Groups may be "controversial" but if I recall correctly the main
issue was the question of whether you needed a Google account or not. I'm
pretty sure you can just send an email to
groupname+subscribe at googlegroups.com even if you don't have a Google
account. But of course this is a bizarre standard to hold mailing list
software to: mailman asks users to create an account for each listserv in
order to manage a subscription too!

@_date: 2015-06-15 12:36:35
@_author: Mike Hearn 
@_subject: [Bitcoin-development] comments on BIP 100 
I understand the arguments against it. And I think you are agreeing with me
- Adam is bemoaning the way developers outsource stuff to third party
services, and suggesting it is relevant to the block size debate. And we
are saying, no, it's happening because it's easier than doing things in a
decentralised way.
Right. There's a deeper issue here. The sort of 'trustless' querying of the
UTXO set that was demanded from me is impossible even with commitments,
because the answer can change the moment you receive it. All it takes is a
new block or new transaction to be broadcast a split second after you
download and use the data, and suddenly what you did is incorrect no matter
how many proofs you verified!
The only way to know this has happened is to be a full node and download
all transactions yourself ... and even then, you are trusting your peers to
actually relay you all transactions and not a subset. So in the end you can
never achieve perfection, only get closer to it.
But that situation is *fine* for many use cases, like showing someone a
snapshot of their crowdfund in a user interface. We just accept that what
we see on the screen may lag behind reality. It happens all the time with
all kinds of non-Bitcoin apps. We accept that there may be cases where the
answer we get is wrong. The software can nevertheless still be useful.
So Lighthouse compromises. It queries multiple peers and cross-references
their answers. If their answers don't match it shows an error on the screen
and won't show the user any status for their crowdfund at all. This error
has never occurred. Maybe one day it will. So the app gets more
decentralisation, more robustness, and accepts that the user interface
might one day show a wrong answer if the P2P network starts lying (or your
internet connection is hacked, but the right fix for that is P2P
Unfortunately this sort of balance-of-risks approach is considered a
non-starter in Bitcoin Core. So why would developers even try? The message
sent was clear:  even if you have an approach you think will work, don't
Much easier to just outsource to a trusted service indeed.

@_date: 2015-06-15 12:50:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] comments on BIP 100 
Well sure, that's easy for you to say, but you have a salary :) Other
developers may find the incremental benefits of decentralisation low vs
adding additional features, for instance, and who is to say they are wrong?
It does add something though! It means, amongst other things, I can switch
of all my servers, walk away for good, discard this Mike Hearn pseudonym I
invented for Bitcoin and the app will still work :) Surely that is an
important part of being decentralised?
It also means that as the underlying protocol evolves over time, getutxos
can evolve along side it. P2P protocol gets encrypted/authenticated? Great,
one more additional bit of security. If one day miners commit to UTXO sets,
great, one more additional bit of security. When we start including input
values in the signature hash, great ... one more step up in security.
Anyway, I didn't really want to reopen this debate. I just point out that
third party services are quite happy to provide whatever developers need to
build great apps, even if doing so fails to meet some kind of perfect
cryptographic ideal. And that's why they're winning devs.
Now back to your regularly scheduled block size debates ...

@_date: 2015-06-15 19:18:25
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Scaling Bitcoin with Subchains 
Pedantically: you could validate a random subset of all scripts, to give
yourself probabilistic verification rather than full vs SPV. If enough
people do it with a large enough subset the probability of a problem being
detected goes up a lot. You still pay the cost of the database updates.
But your main point is of course completely right, that side chains are not
a way to scale up.

@_date: 2015-06-15 22:55:07
@_author: Mike Hearn 
@_subject: [Bitcoin-development] questions about bitcoin-XT code fork & 
Hi Adam,
I replied publicly because your questions were sent to the mailing list.
I'd have been happy to reply in private if so asked.
I started to write up a much longer reply, but I'm tired - we've long since
been going in circles. I feel like I've written down answers to almost all
your questions before, including some in the email above.
Still, there are a few new ones. Let me work through them now.
Yes, I am on the bitcoin-security list. I have always been on it. I have
taken part in many threads there and started one or two myself. I guess
you're not though, otherwise you'd know that. You can ask, I'm sure Gavin
will add you if you like.
Re: BIP. Gavin is working on a BIP to go along with his patch. I hope that
will satisfy. I do not expect the resulting discussion to differ much from
the discussion so far, though.
Re: summit. No, I would not attend. I have been to several Bitcoin
conferences over the years where the block size issue was discussed. No
progress was ever made at these events.
Re: if some flaw or bug was found in the patch. Yes, of course if there was
some specific problem with the code then we would fix it. There will be
time to review Gavin's patches for these reasons.
Re: anyone who agrees with noted non-programmers Mike&Gavin must be
non-technical, stupid, uninformed, etc .... OK, go ahead and show them the
error of their ways. Anyone can write blogs.

@_date: 2015-06-16 13:20:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] questions about bitcoin-XT code fork & 
Hi Bryan,
Specifically, when Adam mentioned your conversations with non-technical
Yes, my comment was prickly and grumpy. No surprises, I did not sleep well
last night.
I am upset about this constant insistence from Adam, Gregory and others
that the "technical community" or "technical majority" agree with them and
anyone who doesn't is "non technical" or "not a contributor" or not an
expert or not had things properly explained to them.
This is not true and needs to stop. Gavin and I have both been working on
Bitcoin in substantial ways for longer than Gregory and Adam have been in
the community at all. We are extremely technical, as are many of the people
who want us to release XT+larger blocks. We cannot make progress in any
kind of negotiation if one side constantly blows off the other and refuses
to take anything they say seriously, which has been a feature of this
"debate" from the start.
In contrast Gavin and I have written vast amounts of analysis on the
concerns raised by larger blocks. So many hours were spent, we could
probably fill a small book by now. We have carefully read and addressed
*dozens* of points raised by the 1mb camp. We have also done our best to
open this debate to the whole community.
So it would be nice if the people who are so keen on 1mb blocks show the
same respect to us.

@_date: 2015-06-16 13:29:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] questions about bitcoin-XT code fork & 
How do we plan to deal with security & incident response - exactly the same
way as before. Remember that XT is basically Core plus a few patches.
Gavin and myself are both on the bitcoin-security mailing list and have
been for years. Both of us have experience of responding to very serious
and tight-deadline security incidents, for example, the accidental bdb hard
fork and (in my case) when we discovered that Android phones had so little
entropy in them that different devices were actually generating the same
That one required co-ordinated crash rollouts of multiple wallets across
the Bitcoin ecosystem because there was a parallel investigation into key
collisions taking place in an open forum and they were not far from
discovering the truth about how badly the Android RNG was broken   (I knew
because at the time I had access to the Google internal Android bug
tracker). I organised the whole thing.
So I think we'll manage. But I don't expect things to exist in a state of
disjointness for very long. XT will rebase on top of Core and follow it's
releases for as long as there seems to be interest in bigger blocks and as
long as I have the time/energy/interest. If the >1mb chain wins then Core
will have to adopt the new ruleset or simply stop being relevant, as it
will have no users. That wouldn't make much sense.
Now, there have been concerns raised that a hard fork is unbelievably
risky, the sky will fall, the value of Bitcoin will drop to zero, etc. I
don't believe it's anywhere near that risky. The patch Gavin is working on
requires both a miner majority *and* also has a date trigger in it. Much
like previous forks, in fact. So nobody should be taken by surprise if/when
bigger blocks appear, because it will have been known for a long time
beforehand that there was sufficiently strong consensus, there will have
been messages printed to the node logs, announcements in various places and
so on.
Does that help clear things up?

@_date: 2015-06-18 12:00:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Concerns Regarding Threats by a Developer 
Dude, calm down. I don't have commit access to Bitcoin Core and Gavin
already said long ago he wouldn't just commit something, even though he has
the ability to do so.
So why did I say it? Because it's consistent with what I've always said:
 you cannot run a codebase like Wikipedia. Maintainers have to take part in
debates, and then make a decision, and anyone else who was delegated commit
access for robustness or convenience must then respect that decision. It's
the only way to keep a project making progress at a reasonable pace.
This is not a radical position. That's how nearly all coding projects work.
I have been involved with open source for 15 years and the 'single
maintainer who makes decisions' model is normal, even if in some large
codebases  subsystems have delegated submaintainers.
This is also how all my own projects are run. Bitcoinj has multiple people
with commit access. Regardless, if there were to be some design dispute or
whatever, I wouldn't tolerate the others with commit access starting some
kind of Wiki-style edit war in the code if they disagreed. Nor would I ever
expect to get my own way in other people's projects by threatening to
revert the maintainers changes.
Core is in the weird position where there's no decision making ability at
all, because anyone who shows up and shouts enough can generate
'controversy', then Wladimir sees there is disagreement and won't touch the
issue in question. So it just runs and runs and *anyone* with commit access
can then block any change.
I realise some people think this anti-process leads to better decision
making. I disagree. It leads to no decision making, which is not the same
thing at all.

@_date: 2015-06-18 15:31:54
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Concerns Regarding Threats by a Developer 
OK, let's agree to unpack the two things.
The first issue is how are decisions made in Bitcoin Core? I struggle to
explain this to others because I don't understand it myself. Is it a vote
of people with commit access? Is it a 100% agreement of "core developers"
and if so, who are these people? Is it "whoever reverts the change last"?
Could I write down in a document a precise description of how decisions are
made? No, and that's been a fairly frustrating problem for a long time.
But let's leave it to one side for a moment.
Let's focus on the other issue:   what happens if the Bitcoin Core decision
making process goes wrong?
For the sake of argument let's pretend we're discussing a different change,
let's imagine there is a proposal to change the block format to include a
Widget, where a Widget is some potentially desirable thing. And this change
means a hard fork. Let's put the block size to one side for a second to
avoid getting distracted.
Imagine that 90% of people in Bitcoin want their Widgets, but one of your
committers refuses to accept it.  I am not saying the block size debate has
such proportions but pretend Widgets do.
What is the process for resolving this problem?
Gavin and I say - there is a process, and that process is a hard fork of
the block chain.
What you're saying is - there is no process because a contentious hard fork
must never happen. Such a change is simply impossible.
Now which is a better description of this situation? Is the "it must never
happen end of story" really the cuddly warm democracy that you seem to
suggest? Or is it more like a dictatorship where the opinions of one or two
people can override all the others?
The typical answer I'm seeing to this is that Bitcoin Core's own decision
making process is so fantastic that it never goes wrong, even though
"consensus" is not defined and "technical majority" is not defined and we
have serious long time contributors on this mailing list (such as wallet
developers) disagreeing with this consensus yet our feedback is being
You guys *must* accept that your preferred process for resolving disputes
is, itself, in dispute. That leaves the block chain itself as the only
remaining method for bringing this saga to a close.
So this is why we keep disagreeing:
   - If Bitcoin Core has reached a formal decision made by the maintainer
   via whatever mechanism he likes to not accept the block size increase, then
   alright, technical disputes will happen. But ....
   - You should agree that the next step is a fork of both the software and
   the block chain. And you should welcome such a thing because it is the ONLY
   check on your own power. It's the one thing that allows the community to
   reject the decision making process you are using in case it goes wrong.
I keep reading that Bitcoin cannot survive a hard fork. Well, we've
survived an accidental fork that happened without anyone being prepared,
and even with a planned soft fork "never upgrade" isn't really an option
for either miners or businesses, so ultimately node operators must know
about upgrades and make them. Both myself and Gavin think this process can
work out OK.
Do you at least understand where we're coming from here, even if you
disagree? And if you disagree, is it because you think a hard fork to
resolve a dispute can't work technically, or is it some other reason?

@_date: 2015-06-18 15:36:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Concerns Regarding Threats by a Developer 
This was a reference to a post by Gregory on Reddit where he said if Gavin
were to do a pull request for the block size change and then merge it, he
would revert it. And I fully believe he would do so!

@_date: 2015-06-18 15:49:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Concerns Regarding Threats by a Developer 
Hi Pieter,
I believe Gavin plans to write a blog post about the hard fork process, but
I'd like to debate this with you now, if only to give him material to work
with :)
Your points look to me like the hard/soft fork debate in different clothes.
For example, we all agree that the rules of Bitcoin *can* be changed, and
have been before (e.g. P2SH), with software upgrades.
When such a fork happens, any user who does not upgrade their node isn't
fully verifying the block chain anymore. Their software might *think* it
is, but it's running NOPs that don't mean NOP to other nodes. So there is a
divergence in the consensus, it's merely been done in such a way that the
node won't stop and print "hard fork detected" to the logs. It'll happily
accept a block that violates the new rules, then wait to be corrected by
So with any fork, hard or soft, there is risk to those who don't upgrade.
They may accept a block, or even two blocks, that they believe are valid
according to their old rule set, but which other miners would reject. The
effect on double spending is much the same.
Now let's talk philosophy.
* Philosophy: Bitcoin is not a democracy.
This appears to be a key point of dispute. Bitcoin is a democracy, though
the analogy is not perfect. You can certainly believe whatever you like
about the true state of the ledger, but rubber hits the road the moment you
go and trade with other people.
If 90% of the people you trade with believe a coin exists, and you don't,
you're gonna discover you keep getting paid with that coin and its
descendents. You may hate it, you may feel your rights are being violated,
you may refuse to trade with those people but it will keep happening.
Money is about trade, and trade inherently involves the decisions of other
people. No man is an island.
With Bitcoin we have a great way to quickly find out what other people
believe about the ledger. If the vast majority of people are on ledger A
and you're on ledger B, then you've got a strong incentive to come into
line with the majority in order to keep trading.
Nobody, not even after a hard fork, is *forced* to change their code
against their will. It may be something that *other people require* as part
of trading with them though. Whether one considers this "forced" or not I
guess can be argued either way. Are you "forced" to buy oranges from the
single orange seller in town if the other goes bankrupt, or could you just
avoid oranges? Where does economic freedom begin and end?
I think it's surely the opposite - *not* being able to push for
controversial changes sets an incredibly dangerous precedent. Namely,
whoever gets to decide that a change is controversial gets to veto anything
they like!
Indeed, me too! But it's worse than that: what if someone sockpuppets a
discussion to make it look like a change does or does not have consensus?
One reason I keep banging on about *process* and how Wladimir needs to be
The Decider is that the current attempt at "process" is so vague, not only
is it unexplainable, but it's wide open to manipulation.
Good thing we have a way to resolve this problem:  the block chain. Now it
doesn't matter if someone points a gun at you or me. We can object to
whatever we like and that wouldn't bring Bitcoin to a halt, thus removing
the incentive to try and pressure individuals.
But if we don't have that ability to vote through choice of software and
rulesets, then us poor developers really are in charge and that's not a
place any of us should want to go. There must be a mechanism for people to
disagree with the consensus, even in major, controversial ways, and that
mechanism must have real force to it.

@_date: 2015-06-18 16:16:51
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Concerns Regarding Threats by a Developer 
As the outcome of a block size BIP would be a code change to Bitcoin Core,
I cannot make improvements, only ask for them. Which is what I'm doing.
I agree that BIP 1 is not clear enough. Gavin is writing a BIP to accompany
his patch, because BIPs are best when they describe working code, and BIP 1
*is* at least clear about that. Otherwise it can turn out during
implementation that something was different to what was anticipated. I'm
sure you agree with this.
So a BIP is coming. However, BIP 1 also says this:
Vetting an idea publicly before going as far as writing a BIP is meant to
BIP authors are responsible for collecting community feedback on a BIP
OK. Gavin has been vetting the idea publicly and collecting community
feedback. Note that the entire Bitcoin community is not on this list, so he
published a series of blog posts to get wider feedback, and then was
criticised for not doing it all here instead.
But anyway - so far, so good.  The procedure is being followed.
What happens once a BIP is written? The process says:
For a BIP to be accepted it must meet certain minimum criteria. It must be
This is where the problem starts.
The BIP process you refer to *does not state how acceptance will happen*.
It merely sets out a few minimum requirements like making some sort of
sense, having code. It's also full of extremely vague descriptions like
"must represent a net improvement". Improvement according to who? That's
left unexplained.
And then it says what happens once a BIP is accepted.
The middle bit is missing. When there is disagreement over a consensus BIP,
how are decisions made?

@_date: 2015-06-18 18:05:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Concerns Regarding Threats by a Developer 
Alright. Here is a first cut of my proposal. It can be inserted into an
amended BIP 1 after "What belongs in a successful BIP?". Let me know what
you think.
The following section applies to BIPs that affect the block chain consensus
rules or the peer to peer protocol and thus require changes to Bitcoin
Once a draft BIP has been submitted to bitcoin-development for
consideration, the Bitcoin Core maintainer will deliver a preliminary
yes/no verdict within three weeks. This verdict may be informed by the
debate that has taken part in the previous three weeks. If more time is
required, the maintainer is required to request an extension from the BIP
author, who may then elect to force an immediate decision (risking a no),
or choosing to allow more time.
The verdict will meet the following criteria:
   - It will address the latest version of the BIP at the time the verdict
   is rendered.
   - In case of a rejection, it will spell out and describe the technical
   rationale for this decision. Opinions held by other people are not
   considered technical rationales: if the maintainer agrees with a technical
   point made during discussion, he must own that opinion for himself.
   Therefore no BIP will be rejected on grounds of controversy, disagreement,
   lack of consensus or otherwise.
   - In case of rejection, the maintainer will provide a clear, specific
   list of actionable steps the BIP author can take next. For example, a list
   of what changes would address the technical objections raised. In case the
   maintainer believes no change could ever make the BIP acceptable, the list
   must consist of instructions for how to create a patch set and, in the case
   of changes to the consensus rules, how to initiate a hard fork.
A BIP, even once rejected, may live on in the BIPS repository, though its
entry in the index may be sorted below others. The BIP author may update
the BIP with a summary of any resulting discussion. As such a summary may
be inherently contentious in case of a dispute, the authors wording of that
summary is final and may not be subject to meta-debate.

@_date: 2015-06-19 11:37:34
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Concerns Regarding Threats by a Developer 
It's impossible, Mark. *By definition* if Bitcoin does not have sufficient
capacity for everyone's transactions, some users who were using it will be
kicked out to make way for the others. Whether that happens in some kind of
stable organised way or (as with the current code) a fairly chaotic way
doesn't change the fundamental truth: *some users will find their bitcoin
savings have become uneconomic to spend*.
Here's a recent user complaint that provides a preview of coming
Hello, I'm just trying to send my small Sarutobi-tips stash (12,159 bits)
These sorts of complaints will get more frequent and more extreme in the
coming months. I realise that nobody at Blockstream is  in the position of
running an end user facing service, but many of us are .... and we will be
the ones that face the full anger of ordinary users as Bitcoin hits the

@_date: 2015-06-19 11:56:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Mailman incompatibility with DKIM ... 
I still see footers being added to this list by SourceForge?
I've asked Jeff to not use his  account for now.
The only real fix is to use a mailing list operator that is designed to
operate correctly with DKIM/DMARC, either by not modifying messages in
transit, or by re-sending (and ideally re-signing) under their own identity.
Though I'm sure this won't be an issue for the Linux Foundation, the latter
approach is dangerous because it means the list operator takes full
responsibility for any spamming that occurs from that domain. If the mail
server is ever hacked or spammers start posting to the lists themselves,
all that spam will be seen as originating from the listserv itself and the
reputation will be degraded. It can end with everyone's mail going to the
spam folder.

@_date: 2015-06-19 12:19:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Concerns Regarding Threats by a Developer 
Are you sure? That sort of statement is hard to answer because it doesn't
say what you think long term is, or how much you expect Bitcoin to grow.
Satoshi thought it was a perfectly fine long term solution because he
thought hardware would get cheaper as fast or faster than Bitcoin would
grow. You may disagree with him, but as we're talking about the future are
you 100% certain he was wrong? I did calculations a long time ago that
suggested even with today's hardware (+some software optimisations) it
would be feasible to keep up with Visa.
Hardware improvements can be unintuitive. There's a spreadsheet here that
lets you play with various parameters.
(note: the spreadsheet says avg txn size is 250 bytes, but if you check the
formula for the middle column, it does actually use 500 bytes as the
multiplier hard coded).
That's not clear either, I'm afraid.
Remember that there's an upper limit on how high Bitcoin fees can go. When
fees become higher than what the banking system charges, many users won't
use Bitcoin for moving money around anymore. Fees cannot really go much
higher than that even if you assume the currency is still attractive for
other reasons, because people would just sell their coins for fiat, move
the fiat, and buy back the coins the other side.
The way mining will be funded in future is an open question. There are
differing proposals. Still, even with a higher hard block size limit,
miners can always refuse to mine transactions that don't include a
particular fee. So if you're worried about this, miners aren't being forced
into any particular policy.

@_date: 2015-06-19 12:24:01
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Mailman incompatibility with DKIM ... 
Lists can do what are effectively MITM attacks on people's messages in any
way they like, if they resign for the messages themselves. That seems fair
to me!  :)
DKIM is used by most mail on the internet. DMARC rules that publish in DNS
statements like "All mail from bitpay.com is signed correctly so trash any
that isn't" are used on some of the worlds most heavily phished domains
like google.com, PayPal, eBay, and indeed BitPay.
These rules are understood and enforced by all major webmail providers
including Gmail. It's actually only rusty geek infrastructure that has
problems with this, I've never heard of DKIM/DMARC users having issues
outside of dealing with mailman. The vast majority of email users who never
post to technical mailing lists benefit from it significantly.
Really everyone should use them. Adding cryptographic integrity to email is
hardly a crazy idea :)
It's not SourceForge, it's your spam filter. His mail gets through to me
but it's all in the spam folder.

@_date: 2015-06-19 12:49:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Mailman incompatibility with DKIM ... 
Mailman must take responsibility for the mail itself. It doesn't have to
actually sign with DKIM to do so: for backwards compatibility, spam filters
fall back to other heuristics to try and figure out the 'owner' of the mail
if it doesn't use DKIM. Those heuristics can go wrong of course. Ideally
all mail would be DKIM signed. There's no reason not to do it, really.
Yes mailing lists that edit people's emails resign. For example, from a
recent message to the bitcoinj list
DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        *d=googlegroups.com *; s=20120806;
        h=to:from:subject:date:lines:message-id:references:mime-version
         :content-type:user-agent:in-reply-to:x-original-sender
         :x-original-authentication-results:reply-to:precedence:mailing-list
         :list-id:list-post:list-help:list-archive:sender:list-subscribe
         :list-unsubscribe;
Good email clients can extract the same information from the headers
anyway. I filter all my mail based on them, and the headers also contain
unsubscribe instructions. Gmail is capable of using them programmatically.

@_date: 2015-06-19 15:43:14
@_author: Mike Hearn 
@_subject: [Bitcoin-development] improving development model (Re: Concerns 
Developers
Hi Adam,
I am still confused about whether you actually support an increase in the
block size limit to happen right now. As you agree that this "layer 2" you
speak of doesn't exist yet, and won't within the next 10-12 months (do you
agree that actually?), can you please state clearly that you will support
Gavin's patch once posted? As Gavin's work takes some ideas from BIP100 but
does/soon will have some code associated with it.
But if we do no R&D on layer2, and insist that clients can never
I think there's been some confusion here.
I, at least, have never argued that other systems can *never* happen. Never
is a long time, and I myself maintain a payment channels implementation.
These things have their place.
The argument is solely around the need to raise the block size *now* and
not allow the existing layer 1 to gum up and fall over.
If Stroem or Lightning or other block chains or Coinbase or secure hardware
tokens or whatever take off and people start moving bitcoins around that
way - fine. If they're choosing it of their own free will I have no issue
with that, nor does anyone else, I suspect.
However you don't seem fully confident that people actually will choose
whatever is being cooked up as "layer 2", if left to their own devices.
Indeed it's impossible for anyone to know that, as no "layer 2" actually
exists. Any such implementation could have all sorts of flaws that lead to
it not gaining traction.
As you know from the discussion with myself and Gavin a few days ago on
IRC, neither of us believe any such constructive process exists. There is
another thread to discuss the lack of such a process.
Oh please. Conspiracy theories, now, Adam? My position has been consistent
for years. I don't care whether the figure is 20 or something else (looks
like it'll be lucky 8 instead), but I have always been clear that the limit
must rise.
But for the avoidance of doubt: the answer is no.
Gavin is paid by MIT. The MIT deal gives Gavin complete independence.
I am currently self employed and most of income comes from a client that is
actually interested in Lighthouse. Luckily they have given me some leeway
to do general Bitcoin development as well, which this business falls under.
I would *much* rather be working on Lighthouse than this, and so would they.
But seeing as you've gone there - let me flip this around. Blockstream has
a very serious conflict of interest in this situation. I am by no means the
first to observe this. You are building two major products:
   1. Sidechains, a very complex approach to avoid changing the Bitcoin
   consensus rules to add new features.
   2. Lightning, a so-called "layer two" system for transaction routing
No surprise, the position of Blockstream employees is that hard forks must
never happen and that everyone's ordinary transactions should go via some
new network that doesn't yet exist.
The problem is that rather than letting the market decide between ordinary
Bitcoin and Lightning, you are attempting to strangle the regular Bitcoin
protocol because you don't trust people to spontaneously realise that they
should be using your companies products.
I know that many of you guys had these views before joining Blockstream. I
am not saying you are being paid to have views you didn't previously have.
I realise that birds of a feather flock together.
Regardless, that conflict of interest DOES exist, whether you like it or
not, because if you succeed in running Bitcoin out of capacity your own
company stands to benefit from selling consulting and services around your
preferred solutions.
With respect to user rights: all the polling done so far suggests users who
are paying attention strongly support increasing the block size. For
Q: "Should the bitcoin block size be raised in the next two years"
A: 92% yes
Additionally, many Bitcoin users have explicitly delegated handling the
technical details to someone else, like a payment processor or their wallet
developers. Those people are nearly all sure that the block size limit
should rise too.
So please don't engage in idle speculation about "users vs companies". They
aren't some kind of opposing forces. Companies live for their users, and
many of those companies were formed by long time Bitcoin users.
And finally, the Bitcoin social contract is not defined by whatever random
state the code was in at the time Gavin decided to focus on research. Both
Gavin and I have been working on Bitcoin longer than you, Gregory or Peter
Todd. The social contract was and still is defined by the project's
founding vision - written down in words.
Heck, if Satoshi had spent another hour or two on his original size limiter
patch this entire dispute would never have happened. He'd have put in some
kind of automatic timeout or limit riser because the plan was to remove it
all along, and then it'd be you guys arguing for putting a limit in place,
Gavin would object, it'd be controversial and nothing would happen. But
Satoshi never anticipated this bizarre attempt to turn the project into
something else and so figured he'd just remove it himself later. Too bad.

@_date: 2015-03-02 16:37:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Electrum 2.0 has been tagged 
Congrats Thomas! Glad to see Electrum 2 finally launch.
Does this mean a "12 words" wallet created by Electrum won't work if
imported into some other wallet that supports BIP39? Vice versa? This seems
unfortunate. I guess if seeds are being represented with 12 words
consistently, people will expect them to work everywhere.

@_date: 2015-03-04 07:28:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] New paper: Research Perspectives and 
Nice, Andrew.
Just one minor point. SPV clients do not need to maintain an ever growing
list of PoW solutions. BitcoinJ uses a ring buffer with 5000 headers and
thus has O(1) disk usage. Re-orgs past the event horizon cannot be
processed but are assumed to be sufficiently rare that manual intervention
would be acceptable.

@_date: 2015-03-11 10:14:19
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Electrum 2.0 has been tagged 
Sigh. The wallet words system is turning into kind of a mess.
I thought the word list is in fact not a fixed part of the spec, because
the entropy is a hash of the words. But perhaps I'm misunderstanding
The main problem regular SPV wallets have with BIP39 is that there is no
birth time included in the data. Therefore we must ask users to write down
a timestamp as well, so we know where to start rescanning the chain. It
sounds like the Electrum version doesn't fix this, so now we have at least
FIVE incompatible results from a 12 word list:
   - Electrum v2 with a version number but no date
   - myTREZOR with no version and no date and BIP44 key derivation. Some
   seeds I believe are now being generated with 24 words instead of 12.
   - MultiBit HD with no version and a date in a custom form that creates
   non-date-like codes you are expected to write down. I think BIP32 and BIP44
   are both supported (sorta).
   - GreenAddress with no version, no date and BIP32
   - Other bitcoinj based wallets, with no version and a date written down
   in normal human form, BIP32 only.
I really hope we can recover from this somehow because otherwise all
wallets will have to provide the user with a complicated matrix of
possibilities and software combinations, and in practice many won't bother
so these word combinations will actually end up being wallet specific for
no particularly good reason, just very minor details like the presence or
absence of single fields.
It feels like we somehow fell flat on our faces just before the finishing
line. This is deeply unfortunate. Compatibility and UX consistency is
Currently, I don't have any bright ideas for how to get everyone back onto
the same page with a fully compatible system that is acceptable to all. If
anyone else has suggestions, I'm all ears.

@_date: 2015-03-11 16:22:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Electrum 2.0 has been tagged 
Users will want to have wallets shared between devices, it's as simple as
that, especially for mobile/desktop wallets. Trying to stop them from doing
that by making things gratuitously incompatible isn't the right approach:
 they'll just find workarounds or wallet apps will learn how to import
seeds from other apps. Better to just explain the risks and help people
mitigate them.

@_date: 2015-03-11 16:54:59
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Electrum 2.0 has been tagged 
Sure. But in practice people will want to have a pool of spending money
that they can spend when they are out and about, and also with one click
from their web browser on their primary computer, and maybe also on their
games console, etc etc.
I don't think we can realistically tell people to *always* use clever
multi-device wallets - there will always be a desire to have a convenient
hot wallet that's synchronised between different devices.

@_date: 2015-03-12 09:47:56
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Electrum 2.0 has been tagged 
I agree, but we need things to be easy in the short term as well as the
long term :)
The long term solution is clearly to have the 12 word seed be an encryption
key for a wallet backup with all associated metadata. We're heading in that
direction one step at a time. Unfortunately it will take time for wallets
to start working this way, and all the pieces to fall into place. Restoring
from the block chain will be a semi regular operation for users until then.
WRT version number I have no real strong feelings about this. But
representing short pieces of binary data as words is so convenient, it
seems likely that it could be similar to addresses: people find other uses
for this mechanism beyond just storing a raw private key. Bitcoin addresses
have versions and that's proven to be useful several times, even though in
theory an address is "just" a hash of a pubkey.

@_date: 2015-03-13 09:40:27
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP32 Index Randomisation 
Hey Matias,
We are working on bitcore-wallet-server (BWS), a HD multisig wallet
Could you describe what exactly BWS does? It sounds like the server doesn't
have to actually derive the keys itself for any particular purpose beyond
knowing the addresses are a part of the wallet. Could the server work if it
didn't even know that, and was just a bucket of arbitrary addresses with
the clients themselves deriving the addresses?

@_date: 2015-03-13 11:04:57
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP32 Index Randomisation 
It sounds like the main issue is this is a web wallet server of some kind.
If the clients were SPV then they'd be checking their own balances and
downloading their own tx history, which would mean the coordination tasks
could be done by storing encrypted blobs on the server rather than the
server itself having insight into what's going on (see: Subspace).
So whilst you might be able to use some scheme to avoid the server knowing
the xpubkey, if the server still knows all addresses and all transactions
because the clients are web wallets ..... is there any point? It seems like
maybe going from server knows everything to server knows 95% of everything:
maybe not worth the engineering cost.

@_date: 2015-03-13 14:31:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proof of Payment 
Hi Kalle,
I think you're thinking along the right lines, but I am skeptical that this
protocol adds much. A saved payment request is meant to be unique per
transaction e.g. because the destination address is unique for that payment
(for privacy reasons). Where would you store the signed payment request?
Probably in the wallet. You could just extract the metadata that's useful
for UI rendering into a separate structure and then encrypt the original
full payment request under the wallet key. At least this is how I imagine
it would work.
So then, if someone can steal a payment request they can probably steal the
wallet signing keys too, and thus signing a challenge with the wallet keys
doesn't add much. It means the wallet doesn't have to store the
PaymentRequest encrypted. But AFAICT that's about all it does.
Do you agree with this analysis?

@_date: 2015-03-13 14:34:31
@_author: Mike Hearn 
@_subject: [Bitcoin-development] BIP32 Index Randomisation 
Sure, sorry, by web wallet I meant a blockchain.info/CoPay type setup where
the client has the private keys and signs txns, but otherwise relies on the
server for learning about the wallet contents. I tend to call wallets where
the server has the private key BitBanks but I don't know if anyone else
uses this terminology. It might just be a personal quirk of my own ;)
Fair enough. Yes, push notifications to mobiles in a decentralised way is
rather a hard problem.
I think what Gregory suggested is then the best approach for you to do what
you want. Whether it's worth the additional complexity is something I don't
have any feedback on, only you can judge that.

@_date: 2015-03-13 14:48:17
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Criminal complaints against "network 
That would be rather new and tricky legal territory.
But even putting the legal issues to one side, there are definitional
For instance if the Chainalysis nodes started following the protocol specs
better and became just regular nodes that happen to keep logs, would that
still be a violation? If so, what about blockchain.info? It'd be shooting
ourselves in the foot to try and forbid block explorers given how useful
they are.
If someone non-maliciously runs some nodes with debug logging turned on,
and makes full system backups every night, and keeps those backups for
years, are they in violation of whatever pseudo-law is involved?
I think it's a bit early to think about these things right now. Michael
Gr?nager and Jan M?ller have been Bitcoin hackers for a long time. I'd be
interested to know their thoughts on all of this.

@_date: 2015-03-13 15:03:23
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proof of Payment 
Is it? I'm assuming TLS is being used here. And the hotel server also has a
copy of the PaymentRequest, as the hotel actually issued it and that's how
they're deciding the receipt is valid. So I don't know how it could be
stolen unless the attacker can break TLS.

@_date: 2015-03-13 15:08:08
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Criminal complaints against "network 
That definition would include all SPV clients?
I get what you are trying to do. It just seems extremely tricky.

@_date: 2015-03-13 15:24:05
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Criminal complaints against "network 
Well they don't set NODE_NETWORK, so they don't claim to be providing
network services. But then I guess the Chainalysis nodes could easily just
clear that bit flag too.
It's not quite pay-as-you-go, but I just posted a scheme for funding of
network resources using crowdfunding contracts here:
That comment doesn't have any kind of provision for access control, but
group signatures could be extended in both directions: the server proves it
was a part of the group that was funded by the contract, and the client
proves it was in group that funded the contract, but it's done in a
(relatively) anonymous way. Then any client can use any node it funded, or
at least, buy priority access.
But it's rather complicated. I'd hope that nodes can be like email
accounts: yes they have a cost but in practice people everyone gets one for
free because of random commercial cross-subsidisation, self hosting and
other things.

@_date: 2015-03-28 14:58:53
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Double spending and replace by fee 
I've written a couple of blog posts on replace by fee and double spending
mitigations. They sum up the last few years (!) worth of discussions on
this list and elsewhere, from my own perspective.
I make no claim to be comprehensive or unbiased but I keep being asked
about these topics so figured I'd just write up my thoughts once so I can
send links instead of answers :) And then so can anyone who happens to
(1) Replace by fee scorched earth, a counter argument:
This article lays out the case against RBF-SE and argues it is harmful to
(2) Double spending and how to make it harder:
This article summarises a couple of double spending incidents against
merchants and then discusses the following techniques:
   1. Risk analysis of transactions
   2. Payment channels
   3. Countersigning by a trusted third party
   4. Remote attestation
   5. ID verification
   6. Waiting for confirmations
   7. Punishment of double spending blocks
I hope the material is useful / interesting.

@_date: 2015-05-07 11:25:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
Hey Matt,
OK, let's get started ....
However, there hasnt been any discussion on this
Probably because this list is not a good place for making progress or
reaching decisions. Those are triggered by pull requests (sometimes).
If you're wondering "why now", that's probably my fault. A few days ago
Wladimir posted a release timeline. I observed to Wladimir and Gavin in
private that this timeline meant a change to the block size was unlikely to
get into 0.11, leaving only 0.12, which would give everyone only a few
months to upgrade in order to fork the chain by the end of the winter
growth season. That seemed tight.
Wladimir did not reply to this email, unfortunately. Perhaps he would like
the issue to go away. It won't - if Bitcoin continues on its current growth
trends it *will* run out of capacity, almost certainly by some time next
What we need to see right now is leadership and a plan, that fits in the
available time window.
I'm afraid I have come to disagree. I no longer believe this community can
reach consensus on anything protocol related. Some of these arguments have
dragged on for years. Consensus isn't even well defined - consensus of who?
Anyone who shows up? And what happens when, inevitably, no consensus is
reached? Stasis forever?
I disagree. When the money supply eventually dwindles I doubt it will be
fee pressure that funds mining, but as that's a long time in the future,
it's very hard to predict what might happen.
Many do because free transactions are broken - the relay limiter means
whether a free transaction actually makes it across the network or not is
basically pot luck and there's no way for a wallet to know, short of either
trying it or actually receiving every single transaction and repeating the
calculations. If free transactions weren't broken for all non-full nodes
they'd probably be used a lot more.
I have two huge problems with this line of thinking.
Firstly, no, the "Bitcoin ecosystem" is not well funded. Blockstream might
be, but significant numbers of users are running programs developed by tiny
startups, or volunteers who don't have millions in venture capital to play
Arm-twisting "the ecosystem" into developing complicated Rube Goldberg
machines in double quick time, just to keep the Bitcoin show on the road,
is in fact the opposite of decentralisation - it will effectively exclude
anyone who isn't able to raise large amounts of corporate funding from
writing code that uses the Bitcoin network. Decentralisation benefits from
simplicity, and bigger blocks are (in Gavin's words) "the simplest thing
that will work".
My second problem is the claim that everyone is playing pretend about
Bitcoin, except you guys. I would put it another way - I would say those
people are building products and getting users, by making reasonable
engineering tradeoffs and using systems that work. Yes, one day those
systems might have to change. That's the nature of scaling. It's the nature
of progress. But not today. Probably not tomorrow either.
What I would like to see from Blockstream is a counter-proposal. So far you
have made lots of vague comments that we all agree with - yes,
decentralisation is good, yes some block size limit must exist, if only
because computers are finite machines.
What I don't see from you yet is a *specific and credible plan* that fits
within the next 12 months and which allows Bitcoin to keep growing. Not
some vague handwave like "let's all use the Lightning network" (which does
not exist), or "let's do more research" (Gavin has done plenty of
research), or "but what about the risks" (Bitcoin is full of risks). A
plan, with dates attached, and a strong chance of actually being deployed
in time.

@_date: 2015-05-07 13:29:44
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
I was referring to winter next year. 0.12 isn't scheduled until the end of
the year, according to Wladimir. I explained where this figure comes from
in this article:
It's a fairly simple estimate based on previous growth patterns.
Because I love wild guesses and mine is that full 1 MB blocks will not
OK, it could be. But do you think this debate will play out significantly
differently if you are right, I am wrong, and we have this discussion next
summer instead? Because in several years of watching these debates, I
haven't seen much change in them.
Are you sure about that?
What if Gavin popped up right now and said he disagreed with every current
proposal, he disagreed with side chains too, and there would be no
consensus on any of them until the block size limit was raised.
Would you say, oh, OK, guess that's it then. There's no consensus so might
as well scrap all those proposals, as they'll never happen anyway. Bye bye
side chains whitepaper.
No. What I meant is that someone (theoretically Wladimir) needs to make a
clear decision. If that decision is "Bitcoin Core will wait and watch the
fireworks when blocks get full", that would be showing leadership .....
albeit I believe in the wrong direction. It would, however, let people know
what's what and let them start to make longer term plans.
This dillydallying around is an issue - people just make vague points that
can't really be disagreed with (more nodes would be nice, smaller pools
would also be nice etc), and nothing gets done.
I never said Bitcoin is broken in the long term. Far from it - I laid out
my ideas for what will happen when the block subsidy dwindles years ago.
But yes, it's hard for me to care overly much about what happens 30 years
from now, for the same reason you probably care more about what happens
tomorrow than what happens after you are dead. The further into the future
you try and plan, the less likely your plans are to survive unscathed.
I think I see one of the causes of disagreement now.
I will write more on the topic of what will happen if we hit the block size
limit soon, maybe this evening. I have some other tasks to do first.
Regardless, I don't believe we will get any useful data out of such an
event. I've seen distributed systems run out of capacity before. What will
happen instead is technological failure followed by rapid user abandonment
that pushes traffic back below the pressure threshold .... and those users
will most likely not come back any time soon.
I disagree that'd be the outcome, but good, this is progress. Now we need
to hear something like that from Wladimir, or whoever has the final say
around here.
With respect to the fee market: I think it's fairer to say Gavin wants a
market to exist, and he also wants supply to be plentiful. 20mb limit
doesn't actually mean every block will be 20mb the day after, no more than
they're all 1mb today. Miners may discover that if they go beyond 5mb they
have too many orphans and then propagation speed will have to be optimised
to break through the next bottleneck. Scaling is always about finding the
next bottleneck and removing it, ideally, before you hit it.

@_date: 2015-05-07 16:05:41
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
size", I guess the community should say "then we will just ignore your
Oh good! We can just kick anyone out of the consensus process if we think
they make no sense.
I guess that means me and Gavin can remove everyone else from the developer
consensus, because we think trying to stop Bitcoin growing makes no sense.
Do you see the problem with this whole notion? It cannot possibly work.
Whenever you try and make the idea of developer consensus work, what you
end up with is "I believe in consensus as long as it goes my way". Which is
Because he is formally the maintainer.
Maybe you dislike that idea. It's so .... centralised. So let's say Gavin
commits his patch, because his authority is equal to all other committers.
Someone else rolls it back. Gavin sets up a cron job to keep committing the
patch. Game over.
You cannot have committers fighting over what goes in and what doesn't.
That's madness. There must be a single decision maker for any given
No. I'll write an article like the others, it's better than email for more
complicated discourse.
As others have said, if the answer is "forever, adoption is always the most
This appears to be another one of those fundamental areas of disagreement.
I believe there is no chance of Bitcoin ending up like Visa, even if it is
wildly successful. I did the calculations years ago that show that won't
    Decentralisation is a spectrum and Bitcoin will move around on that
spectrum over time. But claiming we have to pick between 1mb blocks and
"Bitcoin = VISA" is silly.
Peter:   your hypocrisy really is bottomless, isn't it? You constantly
claim to be a Righteous Defender of Privacy, but don't even hesitate before
publishing hacked private emails when it suits you.
Satoshi's hacker had no illusions about your horrible personality, which is
why he forwarded that email to you specifically. He knew you'd use it. You
should reflect on that fact. It says nothing good about you at all.

@_date: 2015-05-07 17:12:38
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
Much of the belief in Bitcoin is that it has a bright future. Certainly the
huge price spikes we've seen were not triggered by equally large spikes in
usage - it's speculation on that future.
I quite agree that if people stop believing in Bitcoin, that will be bad. A
fast way to bring that about will be to deliberately cripple the technology
in order to force people onto something quite different (which probably
won't be payment channel networks).
I doubt it. The disagreement seems more philosophical than technical. If
Bitcoin fell off a cliff then that'd just be taken as more evidence that
block chains don't work and we should all use some network of payment hubs,
or whatever the fashion of the day is. Or anyone who doesn't want to pay
high fees is unimportant. See all the other justifications Gavin is working
his way through on his blog.
That's why I conclude the opposite - if there is no fork, then people's
confidence in Bitcoin will be seriously damaged. If it's impossible to do
something as trivial as removing a temporary hack Satoshi put in place,
then what about bigger challenges? If the community is really willing to
drive itself off a cliff due to political deadlock, then why bother
building things that use Bitcoin at all?

@_date: 2015-05-07 17:29:10
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
Hmm - again I'd argue the opposite.
Up until now Bitcoin has been unconstrained by the hard block size limit.
If we raise it, Bitcoin will continue to be unconstrained by it. That's the
default "continue as we are" position.
If it's not raised, then ....... well, then we're in new territory
entirely. Businesses built on the assumption that Bitcoin could become
popular will suddenly have their basic assumptions invalidated. Users will
leave. The technical code change would be zero, but the economic change
would be significant.

@_date: 2015-05-07 18:11:11
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
If it's an argument against something you said, it's not a straw man, right
Consensus has to be defined as agreement between a group of people. Who are
those people? If you don't know, it's impossible to decide when there is
consensus or not.
Right now there is this nice warm fuzzy notion that decisions in Bitcoin
Core are made by consensus. "Controversial" changes are avoided. I am
trying to show you that this is just marketing. Nobody can define what
these terms even mean. It would be more accurate to say decisions are
vetoed by whoever shows up and complains enough, regardless of technical
merit. After all, my own getutxo change was merged after a lot of technical
debate (and trolling) ..... then unmerged a day later because "it's a
So if Gavin showed up and complained a lot about side chains or whatever,
what you're saying is, oh that's different. We'd ignore him. But when
someone else complains about a change they don't like, that's OK.
Heck, I could easily come up with a dozen reasons to object to almost any
change, if I felt like it. Would I then be considered not a part of the
consensus because that'd be convenient?
20mb is an arbitrary number, just like 1mb. It's good enough to keep the
Bitcoin ecosystem operating as it presently does: gentle growth in usage
with the technology that exists and is implemented. Gavin has discussed in
his blog why he chose 20mb, I think. It's the result of some estimates
based on average network/hardware capabilities.
Perhaps one day 20mb will not be enough. Perhaps then the limit will be
raised again, if there is sufficient demand.
You are correct that "no limit at all" is a possible answer. More
precisely, in that case miners would choose. Gavin's original proposal was
20mb+X where X is decided by some incrementing formula over time, chosen to
approximate expected improvements in hardware and software. That was cool
too. The 20mb figure and the formula were an attempt to address the
concerns of people who are worried about the block size increase:  a
meet-in-the-middle compromise.
Unfortunately it's hard to know what other kinds of meet-in-the-middle
compromise could be made here. I'm sure Gavin would consider them if he
knew. But the concerns provided are too vague to address. There are no
numbers in them, for example:
   - We need more research -> how much more?
   - I'm not against changing the size, just not now -> then when?
   - I'm not wedded to 1mb, but not sure 20mb is right -> then what?
   - Full node count is going down -> then what size do you think would fix
   that? 100kb?
   - It will make mining more centralised -> how do you measure that and
   how much centralisation would you accept?
and so on.

@_date: 2015-05-07 18:13:47
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
It's a problem with the mailing list software, not your setup. BitPay could
disable the phishing protections but that seems like a poor solution. The
only real fix is to send from a non  email address. Gmail or
Hotmail will work, I think. Yahoo won't: they enforce the same strict
policies than bitpay does.

@_date: 2015-05-07 19:43:30
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
Matt, you know better than that. Gavin neither lacks clue nor is he
He has been working on the assumption that other developers are reasonable,
and some kind of compromise solution can be found that everyone can live
with. Hence trying to find a middle ground, hence considering and writing
articles in response to every single objection raised. Hence asking for
suggestions on what to change about the plan, to make it more acceptable.
What more do you want, exactly?
And I'll ask again. Do you have a *specific, credible alternative*? Because
so far I'm not seeing one.

@_date: 2015-05-07 20:06:09
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
I have explained why I believe there is some urgency, whereby "some
urgency" I mean, assuming it takes months to implement, merge, test,
release and for people to upgrade.
But if it makes you happy, imagine that this discussion happens all over
again next year and I ask the same question.

@_date: 2015-05-07 21:34:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
So your concern is just about the ordering and process of things, and not
about the change itself?
I have witnessed many arguments in IRC about block sizes over the years.
There was another one just a few weeks ago. Pieter left the channel for his
own sanity. IRC is not a good medium for arriving at decisions on things -
many people can't afford to sit on IRC all day and conversations can be
hard to follow. Additionally, they tend to go circular.
That said, I don't know if you can draw a line between the "ins" and "outs"
like that. The general public is watching, commenting and deciding no
matter what. Might as well deal with that and debate in a format more
accessible to all.
There have been many such discussions over time. On bitcointalk. On reddit.
On IRC. At developer conferences. Gavin already knew what many of the
objections would be, which is why he started answering them.
But alright. Let's say he should have started a thread. Thanks for starting
it for him.
Now, can we get this specific list of things we should do before we're
Do you have a specific research suggestion? Gavin has run simulations
across the internet with modified full nodes that use 20mb blocks, using
real data from the block chain. They seem to suggest it works OK.
What software do you have in mind?

@_date: 2015-05-07 21:37:28
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
Thank you for your patience, Jorge.
I have written up an explanation of what I think will happen if we run out
of capacity:
   Now I'm going to go eat some dinner :)

@_date: 2015-05-08 11:43:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase 
By the way, just to clear this up - the real limit at the moment is more
like 3 tps, not 7.
The 7 transactions/second figure comes from calculations I did years ago,
in 2011. I did them a few months before the "sendmany" command was
released, so back then almost all transactions were small. After sendmany
and as people developed custom wallets, etc, the average transaction size
went up.

@_date: 2015-05-08 12:03:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Block Size Increase Requirements 
With a 20mb cap, miners still have the option of the soft limit.
I would actually be quite surprised if there were no point along the road
from 1mb to 20mb where miners felt a need to throttle their block sizes
artificially, for the exact reason you point out: propagation delays.
But we don't *need* to have fancy protocol upgrades implemented right now.
All we need is to demolish one bottleneck (the hard cap) so we can then
move on and demolish the next one (whatever that is, probably faster
propagation). Scaling is a series of walls we punch through as we encounter
them. One down, onto the next. We don't have to tackle them all
FWIW I don't think the GFW just triggers packet loss, these days. It's
blocked port 8333 entirely.
 * I'd very much like to see someone working on better scaling
So this request is already satisfied, isn't it? As you point out, expecting
more at this stage in development is unreasonable, there's nothing for
anyone to experiment with or commit to.
They have code here, by the way:
   You can find their fork of MultiBit HD, their implementation library, etc.
They've contributed patches and improvements to the payment channels code
we wrote.
What are your thoughts on using assurance contracts to fund network
I don't *know* if hashing assurance contracts (HACs) will work. But I don't
know they won't work either. And right now I'm pretty sure that plain old
fee pressure won't work. Demand doesn't outstrip supply forever - people
find substitutes.

@_date: 2015-05-08 12:15:16
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
There are certainly arguments to be made for and against all of these
The fixed 20mb cap isn't actually my proposal at all, it is from Gavin. I
am supporting it because anything is better than nothing. Gavin originally
proposed the block size be a function of time. That got dropped, I suppose
to make the process of getting consensus easier. It is "the simplest thing
that can possibly work".
I would like to see the process of chain forking becoming less traumatic. I
remember Gavin, Jeff and I once considered (on stage at a conference??)
that maybe there should be a scheduled fork every year, so people know when
to expect them.
If everything goes well, I see no reason why 20mb would be the limit

@_date: 2015-05-25 20:07:09
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Virtual Notary. 
Very nice Emin! This could be very useful as a building block for oracle
based services. If only there were opcodes for working with X.509 ;)
I'd suggest at least documenting in the FAQ how to extract the data from
the certificate:
openssl pkcs12 -in virtual-notary-cert-stocks-16070.p12 -nodes -passin
pass:"" | openssl x509 -text|less
That's good enough to get started, but I note two issues:
   1. X.509 is kind of annoying to work with: example code in popular
   languages/frameworks to extract the statement would be useful.
   2. The stock price plugin, at least, embeds the data as text inside the
   X.509 certificate. That's also not terribly developer friendly and risks
   parsing errors undermining security schemes built on it.
   The way I'd solve this is to embed either a protocol buffer or DER
   encoded structure inside the extension, so developers can extract the
   notarised data directly, without needing to do any additional parsing.

@_date: 2015-05-25 20:15:39
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Scaling Bitcoin with Subchains 
Hi Andrew,
Your belief that Bitcoin has to be constrained by the belief that hardware
will never improve is extremist, but regardless, your concerns are easy to
assuage: there is no requirement that the block chain be stored on hard
disks. As you note yourself the block chain is used for building/auditing
the ledger. Random access to it is not required, if all you care about is
running a full node.
Luckily this makes it a great fit for tape backup. Technology that can
store 185 terabytes *per cartridge* has already been developed:
As you could certainly share costs of a block chain archive with other
people, the cost would not be a major concern even today. And it's
virtually guaranteed that humanity will not hit a storage technology wall
in 2015.
If your computer is compromised then all bets are off. Validating the chain
on a compromised host is meaningless.

@_date: 2015-05-25 20:31:12
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Long-term mining incentives 
Hi Thomas,
My problem is that this seems to lacks a vision.
Are you aware of my proposal for network assurance contracts?
There is a discussion here:
 at lists.sourceforge.net/msg07552.html
But I agree with Gavin that attempting to plan for 20 years from now is
ambitious at best. Bitcoin might not even exist 20 years from now, or might
be an abandoned backwater a la USENET.

@_date: 2015-05-25 20:36:04
@_author: Mike Hearn 
@_subject: [Bitcoin-development] No Bitcoin For You 
Hardly. Nobody is currently exhausting the CPU capacity of even a normal
computer currently and even if we did a 20x increase in load overnight,
that still wouldn't even warm up most machines good enough to be always on.
The reasons full nodes are unpopular to run seem to be:
1. Uncontrollable bandwidth usage from sending people the chain
2. People don't run them all the time, then don't want to wait for them to
catch up
The first can be fixed with better code (you can already easily opt out of
uploading the chain, it's just not as fine-grained as desirable), and the
second is fundamental to what full nodes do and how people work. For
merchants, who are the most important demographic we want to be using full
nodes, they can just keep it running all the time. No biggie.
This meme about datacenter-sized nodes has to die. The Bitcoin wiki is down
right now, but I showed years ago that you could keep up with VISA on a
single well specced server with today's technology. Only people living in a
dreamworld think that Bitcoin might actually have to match that level of
transaction demand with today's hardware. As noted previously, "too many
users" is simply not a problem Bitcoin has .... and may never have!

@_date: 2015-05-25 20:41:06
@_author: Mike Hearn 
@_subject: [Bitcoin-development] A suggestion for reducing the size of the 
Andreas' wallet hasn't done that for years. Are you repeating this from
some very old memory or do you actually see this issue in reality?
The only time you're forced to wait for confirmations is when you have an
unconfirmed inbound transaction, and thus the sender is unknown.

@_date: 2015-05-25 20:44:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] A suggestion for reducing the size of the 
Wallets are incentivised to do a better job with defragmentation already,
as if you have lots of tiny UTXOs then your fees end up being huge when
trying to make a payment.
The reason they largely don't is just one of manpower. Nobody is working on
As a wallet developer myself, one way I'd like to see this issue be fixed
by making free transactions more reliable. Then wallets can submit free
transactions to the network to consolidate UTXOs together, e.g. at night
when the user is sleeping. They would then fit into whatever space is
available in the block during periods of low demand, like on Sunday.
If we don't do this then wallets won't automatically defragment, as we'd be
unable to explain to the user why their money is slowly leaking out of
their wallet without them doing anything. Trying to explain the existing
transaction fees is hard enough already ("I thought bitcoin doesn't have
banks" etc).
There is another way:  as the fee is based on a rounded 1kb calculation, if
you go into the next fee band adding some more outputs and making a bigger
change output becomes "free" for another output or two. But wallets don't
exploit this today.

@_date: 2015-05-25 23:12:58
@_author: Mike Hearn 
@_subject: [Bitcoin-development] A suggestion for reducing the size of the 
Ah, I see, non default configuration. Because the Bitcoin network can and
does change in backwards incompatible ways, the app wants to see that the
transaction it made actually propagated across the network. If you set a
trusted node it won't see that.
Probably the logic should be tweaked so if you set a trusted node you're
just assumed to know what you're doing and we assume the transactions we
make ourselves always work.

@_date: 2015-05-26 12:48:46
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Zero-Conf for Full Node Discovery 
Very interesting Matt.
For what it's worth, in future bitcoinj is very likely to bootstrap from
Cartographer nodes (signed HTTP) rather than DNS, and we're also steadily
working towards Tor by default. So this approach will probably stop working
at some point. As breaking PorcFest would kind of suck, we might want a
ZeroConf/Rendezvous solution in place so local LANs can capture Bitcoin
traffic away from Tor (with some notification to the user, presumably).
On Tue, May 26, 2015 at 7:47 AM, Matt Whitlock

@_date: 2015-05-27 12:11:26
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Consensus-enforced transaction 
Yes indeed they were. Satoshis mechanism was more general than micropayment
channels and could do HFT between any set of parties.
Safe is relative - this is the same logic the original replace-by-fee
argument uses. There's no enforcement that miners use any particular
ordering of transactions.
As I believe out of all proposed protocols Satoshi's is still the most
powerful, I would suggest that any change to the semantics on nSequence be
gated by a high bit or something, so the original meaning remains available
if/when resource scheduling and update flood damping are implemented. That
way people can try it out and if miners are breaking things too frequently
by ignoring the chronological ordering people can abandon protocols that
rely on it, and if they aren't they can proceed and benefit from the
greater flexibility.

@_date: 2015-05-27 19:39:29
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Consensus-enforced transaction 
Right, but the original protocol allowed for e.g. millions of revisions of
the transaction, hence for high frequency trading (that's actually how
Satoshi originally explained it to me - as a way to do HFT - back then the
channel concept didn't exist).
As you point out, with a careful construction of channels you should only
need to bump the sequence number when the channel reverses direction. If
your app only needs to do that rarely, it's a fine approach.And your
proposal does sounds better than sequence numbers being useless like at the
moment. I'm just wondering if we can get back to the original somehow or at
least leave a path open to it, as it seems to be a superset of all other
proposals, features-wise.

@_date: 2015-05-27 23:59:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Long-term mining incentives 
I wrote an article that explains the hashing assurance contract concept:
(it doesn't contain an in depth protocol description)

@_date: 2015-05-28 12:30:55
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Long-term mining incentives 
The same is true today - via inflation I pay for blocks regardless of
whether they contain or double spend my transactions or not. So I don't see
why it'd be different in future.
The article states quite clearly that assurance contracts are proposed only
if people setting transaction fees themselves doesn't work. There's some
reasonably good arguments that it probably won't work, but I don't assign
very high weight to game theoretic arguments these days so it wouldn't
surprise me if Satoshi's original plan worked out OK too.
Of course, by the time this matters I plan to be sipping a pina colada on
my private retirement beach :) It's a problem the next generation can
tackle, as far as I am concerned.
Patience :)
Right now it's a lot easier to get development money from VC funds and rich
benefactors than raising it directly from the community, so unsurprisingly
that's what most people do.
Despite that, the Hourglass design document project now has sufficient
pre-pledges that it should be possible to crowdfund it successfully once I
get around to actually doing the work. And BitSquare was able to raise
nearly half of their target despite an incredibly aggressive deadline and
the fact that they hadn't shipped a usable prototype. I think as people get
better at crafting their contracts and people get more experience with
funding work this way, we'll see it get more common.
But yes. Paying for things via assurance contracts is a long term and very
experimental plan, for sure.
Lighthouse wasn't written to do hashing assurance contracts, so no, it
doesn't have such a feature. Perhaps in version 2.

@_date: 2015-05-28 19:05:18
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
Isn't that a step backwards, then? I see no reason for fee pressure to
exist at the moment. All it's doing is turning away users for no purpose:
mining isn't supported by fees, and the tiny fees we use right now seem to
be good enough to stop penny flooding.
Why not set the max size to be 20x the average size? Why 2x, given you just
pointed out that'd result in blocks shrinking rather than growing.

@_date: 2015-05-28 19:34:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
To whom? The only justification for the max size is DoS attacks, right?
Back when Bitcoin had an average block size of 10kb, the max block size was
100x the average. Things worked fine, nobody was scared.
The max block size is really a limit set by hardware capability, which is
something that's difficult to measure in software. I think I preferred your
original formula that guesstimated based on previous trends to one that
just tries to follow some average.
As noted, many miners just accept the defaults. With your proposed change
their target would effectively *drop* from 1mb to 800kb today, which seems
crazy. That's the exact opposite of what is needed right now.
I am very skeptical about this idea.
Miners can already attempt to apply fee pressure by just not mining
transactions that they feel don't pay enough. Some sort of auto-cartel that
attempts to restrict supply based on everyone looking at everyone else
feels overly complex and prone to strange situations: it looks a lot like
some kind of Mexican standoff to me.
Additionally, the justification for the block size limit was DoS by someone
mining "troll blocks". It was never meant to be about fee pressure.
Resource management inside Bitcoin Core is certainly something to be
handled by developers.

@_date: 2015-05-29 13:26:40
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
Yes, possibly.
It is, but only by a trivial amount - hitting the limit is still very
likely. I don't want to see this issue come up over and over again. Ideally
never. We shouldn't be artificially throttling organic growth of the
network, especially not by accident.
IMO it's not even clear there needs to be a size limit at all. Currently
the 32mb message cap imposes one anyway, but if miners can always just
discourage blocks over some particular size if they want to.
But I can get behind a 20mb limit (or 20mb+N) as it represents a reasonable
compromise: the limit still exists, it's far below VISA capacity etc, but
it should also free up enough space that everyone can get back to what we
*should* be focusing on, which is user growth!

@_date: 2015-05-29 13:57:42
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
Well, but RAM is not infinite :-) Effectively what these caps are doing is
setting the minimum hardware requirements for running a Bitcoin node.
That's OK by me - I don't think we are actually going to exhaust the
hardware abilities of any reasonable computer any time soon, but still,
having the software recognise the finite nature of a computing machine
doesn't seem unwise.
Not "any" size because, again, the remote node must buffer things up and
have the transaction data actually in memory in order to digest it. But a
much larger size, yes.
However, that's a bigger change.

@_date: 2015-05-29 16:21:02
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
Asking them.
In fact, we already have. I have been talking to well known people and CEOs
in the Bitcoin community for some time now. *All* of them support bigger
blocks, this includes:
   - Every wallet developer I have asked (other than Bitcoin Core)
   - So far, every payment processor and every exchange company
I know Gavin has also been talking to people about this.
There's a feeling on this list that there's no consensus, or that Gavin and
myself are on the wrong side of it. I'd put it differently - there's very
strong consensus out in the wider community and this list is something of
an aberration.

@_date: 2015-05-29 16:22:22
@_author: Mike Hearn 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
Yeah, though FYI Luke informed me last week that I somehow managed to take
out the change to the user-agent string in Bitcoin XT, presumably I made a
mistake during a rebase of the rebranding change. So the actual number of
XT nodes is a bit higher than counting user-agent strings would suggest.
I sort of neglected XT lately. If we go ahead with this then I'll fix
things like this.
