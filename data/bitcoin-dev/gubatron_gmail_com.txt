
@_date: 2014-04-08 12:13:18
@_author: Angel Leon 
@_subject: [Bitcoin-development] have there been complains about network 
I was wondering if the level of traffic a Bitcoin node gets is or will be
so high that you have heard/will hear complains like the following:
   1. a home router that crashes or slows down when its NAT pin-hole table
   overflows, triggered by many TCP connections.
   2. a home router that crashes or slows down by UDP traffic
   3. a home DSL or cable modem having its send buffer filled up by
   outgoing data, and the buffer fits seconds worth of bytes. This adds
   seconds of delay on interactive traffic. For a web site that needs 10 round
   trips to load this may mean 10s of seconds of delay to load compared to
   without bittorrent. Skype or other delay sensitive applications would be
   affected even more.
These are issues the bittorrent community faced and eventually solved
brilliantly with uTP, which uses a congestion window algorithm that allows
you to use as much of the TCP bandwidth as possible and automatically
throttling down if there's any cross traffic, while also taking into
consideration things like the optimum MTUs (Path MTU discovery), Clock
Drift phenomena and other features.
I was wondering if we have or expect to have these issues in the future,
perhaps uTP could help greatly the performance of the entire network at
some point.
Detailed information about uTP here

@_date: 2014-04-08 12:36:07
@_author: Angel Leon 
@_subject: [Bitcoin-development] have there been complains about network 
only that in the real world most routers suck and people don't even know
how to configure them (reminds me of the convo about people not installing
this is why the wheel had to be reinvented for the bittorrent world, and it

@_date: 2014-04-08 13:33:18
@_author: Angel Leon 
@_subject: [Bitcoin-development] have there been complains about network 
Those clarifications are what I needed to hear. For some reason I started
thinking about this last night and wanted to bring it up just in case it
would help, but def. not necessary. Will get back to more low hanging fruit
in the UI/UX as I get to know the project more.
Gregory: "But there doesn't have to be and shouldn't just be one
network transport
for Bitcoin."
is there a formal abstraction for a Transport layer? I suppose if there
isn't it'll be there when needed.

@_date: 2014-08-19 12:58:41
@_author: Angel Leon 
@_subject: [Bitcoin-development] Proposal: Encrypt bitcoin messages 
"I suggest that Bitcoin Core should generate a public/private key pair and
share the public one with peers."
I've not read the p2p protocol of Bitcoin core, but I suppose the initial
handshake between 2 peers would be the ideal place to exchange a public
would it make sense to generate a new random pair of keys per each peer you
connect to?
then each subsequent message to every peer gets encrypted differently,
keeping each conversation isolated from each other encryption-speaking.
These keys would have nothing to do with your wallet, they're just to
encrypt any further communication between peers post-handshake. Would that
be of any use to "This could provide privacy and integrity but not
On Tue, Aug 19, 2014 at 12:38 PM, Gregory Maxwell

@_date: 2014-08-22 15:31:43
@_author: Angel Leon 
@_subject: [Bitcoin-development] Reconsidering github 
+1000. Don't fix it if it ain't broken. Don't kill community support. I for
instance wouldn't have contributed or forked if the project hadn't been on
"Bitcoin has currently 4132 forks on Github. This means that you can get
contributions by pull requests from 4132 developers. That is a HUGE amount,
and you shouldn't ditch that due to not using all features of git :)
To get a grasp of how much that is: When you search projects with more than
4100 forks, there are only 32 of them!
You are one of the top open source projects, and you should be grateful for
that and keep Github up so the other people can send you pull requests with
their improvements :) Volunteer contributions need to be honored and made as
easy as possible, for people are investing their personal time.
Greetings and thanks for your work,
        xor, one developer of

@_date: 2014-08-23 07:59:04
@_author: Angel Leon 
@_subject: [Bitcoin-development] Reconsidering github 
I think this is the only project where people are concerened wether commit
messages are signed or not.
Commit messages should be merged only upon their correctness, not their
I could care less if I receive a buggy patch that's signed.

@_date: 2014-07-03 12:21:50
@_author: Angel Leon 
@_subject: [Bitcoin-development] Building from git on OSX 
a million thanks for this FYI
On Thu, Jul 3, 2014 at 11:56 AM, Gavin Andresen

@_date: 2014-06-02 15:41:12
@_author: Angel Leon 
@_subject: [Bitcoin-development] [QT] Feature proposal: Displaying current 
With this I'll continue then to work on this with the addition of:
- Showing the current unit on the header column title "Amount ($unitHere)"
- Will make sure the user cannot change the current unit of display by
mistake by adding a confirmation dialog.
Thanks all for the feedback!

@_date: 2014-03-19 13:27:08
@_author: Angel Leon 
@_subject: [Bitcoin-development] [QT] how to disable block verification for 
the command line options mention a -checklevel  parameter.
I've been passing 0 assuming there'd be little to no verification, but it's
happened a few times that when I open the official binary (while not doing
development) there's some sort of database corruption and Bitcoin-Qt needs
to reindex blocks on disk, a process that can take probably a whole day.
how do you guys develop the UI and avoid these issues?

@_date: 2014-03-19 14:36:31
@_author: Angel Leon 
@_subject: [Bitcoin-development] [QT] how to disable block verification 
"If you have database problems are you perhaps switching between 0.8.x and
0.9.x with the same directory?"
I think that may have been the issue.
Maybe now that I have a 0.9.0 official binary, when I switch to the source
builds I won't have the issue.
However, I think I'll do what you do and have separate bitcoin data
directories, that's probably the best.
not trying to test anything specifically, just codign, building, launching
over and over, would like to make the startup of the Qt client faster.

@_date: 2014-05-30 12:39:40
@_author: Angel Leon 
@_subject: [Bitcoin-development] [QT] Feature proposal: Displaying current 
============================== START ==============================
There's been quite a lot of debate over the default unit of display to use,
you can read the conversation here, which was closed.
Whatever the side of the debate you're on, wether it should be BTC or mBTC,
or other, regular users will probably take too long to find a way to change
the current unit of display, and if the unit of display were ever changed
to something other than BTC, the current transaction tables"Amount" column
don't mention anywhere what Unit of Display is being used.
So last night I started playing with the idea of having a status bar
component that would:
1. Show you what is the current unit of display at all times.
2. Let you change the unit of display easily.
Here's how it looks (see attachment), just wanted to get feedback, if this
is something you also consider valuable in terms of user experience, or
maybe you don't want to allow any more controls on the status bar (because
then people will want to add more and more)
Just want to get some feedback before I continue working on this to polish
it and submit a pull request.
Angel (

@_date: 2015-08-11 05:14:07
@_author: Angel Leon 
@_subject: [bitcoin-dev] Fees and the block-finding process 
- policy neutrality.
- It can't be censored.
- it can't be shut down
- and the rules cannot change from underneath you.
except it can be shutdown the minute it actually gets used by its inability
to scale.
what's the point of having all this if nobody can use it?
what's the point of going through all that energy and CO2 for a mere 24,000
transactions an hour?
It's clear that it's just a matter of time before it collapses.
Here's a simple proposal (concept) that doesn't pretend to set a fixed
block size limit as you can't ever know the demands the future will bring
We don't need to go as far as countries with hyper inflation trying to use
the technology to make it collapse, anybody here who has distributed
commercial/free end user software knows that any small company out there
installs more copies in a couple weeks than all the bitcoin users we have
at the moment, all we need is a single company/project with a decent amount
of users who are now enabled to transact directly on the blockchain to
screw it all up (perhaps OpenBazaar this winter could make this whole thing
come down, hopefully they'll take this debate and the current limitations
before their release, and boy are they coding nonstop on it now that they
got funded), the last of your fears should be a malicious government trying
to shut you down, for that to happen you must make an impact first, for now
this is a silly game in the grand scheme of things.
And you did sound pretty bad, all of his points were very valid and they
share the concern of many people, many investors, entrepreneurs putting
shitload of money, time and their lives on a much larger vision than that
of a network that does a mere 3,500 tx/hour, but some people seem to be
able to live in impossible or useless ideals.
It's simply irresponsible to not want to give the network a chance to grow
a bit more. Miners centralizing is inevitable given the POW based
consensus, hobbists-mining is only there for countries with very cheap
If things remain this way, this whole thing will be a massive failure and
it will probably take another decade before we can open our mouths about
cryptocurrencies, decentralization and what not, and this stubornness will
be the one policy that censored everyone, that shutdown everyone, that made
the immutable rules not matter.
Perhaps it will be Stellar what ends up delivering at this stubborn pace.
On Tue, Aug 11, 2015 at 4:38 AM, Thomas Zander via bitcoin-dev <

@_date: 2015-08-11 17:30:42
@_author: Angel Leon 
@_subject: [bitcoin-dev] Fees and the block-finding process 
tell that to people in poor countries, or even in first world countries.
The competitive thing here is a deal breaker for a lot of people who have
no clue/don't care for decentralization, they just want to send money from
A to B, like email.
On Tue, Aug 11, 2015 at 5:23 PM, Adam Back via bitcoin-dev <

@_date: 2015-08-11 18:06:52
@_author: Angel Leon 
@_subject: [bitcoin-dev] Fees and the block-finding process 
off-chain systems, right?
You betcha! Just talk to a regular people and try to sell them on the
different scenarios.
They will start using something cheaper/faster the minute it comes along
from the banking industry, just to give you a real world example, this week
I've been dreading the idea of having to go to the bank to make a couple of
cash deposits. If I could open my bank's web page right now and do a very
simple interbank transaction (without having to convince the to let me link
their accounts to mine, with the process that takes like 2 days when they
deposit 2 different cent amounts...) just here within the retarded US
banking system... which has clearly realized the threat from
cryptocurrencies as evidenced on many banker conferences this year.
They will come up with ways to allow us to do person to person transfers,
but this will surely be limited to transactions within the country,
international remittances still have a great chance of being disrupted by
Bitcoin, if and only if, it will be cheap, otherwise the western unions and
xooms of the world will still rule.
Please get out of our your academic cocoon for a bit, talk to real people,
try to convince them to use Bitcoin, and think how hard it will be to make
the sell if on top you tell them... "it costs more... but it's
decentralized!" LOL

@_date: 2015-08-14 09:32:33
@_author: Angel Leon 
@_subject: [bitcoin-dev] Adjusted difficulty depending on relative 
Like this?
On Fri, Aug 14, 2015 at 5:59 AM, Jakob R?nnb?ck <

@_date: 2015-08-15 18:27:01
@_author: Angel Leon 
@_subject: [bitcoin-dev] Bitcoin XT 0.11A 
"I don?t think the concern here is so much that some people want to
increase block size. It?s the *way* in which this change is being pushed
that is deeply problematic."
As a developer on the side lines, bitcoin holder, bitcoin entrepreneur, and
someone who thinks block size limits should be dynamic, I applaud Mike and
Co. for this initiative, some of us that have different ideas on how to
deal with the blocksize issue will certainly not be afraid of wasting time
sending patches to the Bitcoin XT project where it seems they're a bit more
open minded about this issue. I bet sending the same patch to Bitcoin-Core
would be rejected on the spot. Bitcoin XT, I hope, will give room to allow
for scalability, it seems the other camp is bent on using Bitcoin their own
way and their own way only and that's far more problematic because that
will allienate the entire user base eventually.
On Sat, Aug 15, 2015 at 6:16 PM, Eric Lombrozo via bitcoin-dev <

@_date: 2015-08-17 08:38:06
@_author: Angel Leon 
@_subject: [bitcoin-dev] Dynamically Controlled Bitcoin Block Size Max Cap 
I've been sharing a similar solution for the past 2 weeks. I think 2016
blocks is too much of a wait, I think we should look at the mean block size
during the last 60-120 minutes instead and avert any crisis caused by
transactional spikes that could well be caused by organic use of the
network (Madonna sells her next tour tickets on Bitcoin, OpenBazaar network
starts working as imagined, XYZ startup really kicks ass and succeeds in a
couple of major cities with major PR push)
Pseudo code in Python
My idea stems from a simple scalability metric that affects real users and
the desire to use Bitcoin:
Waiting times to get your transactions confirmed on the blockchain.
Anything past 45mins-1 hour should be unnacceptable.
Initially I wanted to measure the mean time for the transactions in blocks
to go from being sent by the user
(initial broadcast into mempools) until the transaction was effectively
confirmed on the blockchain, say for 2 blocks (acceptable 15~20mins)
When blocks get full, people start waiting unnaceptable times for their
transactions to come through
if they don't adjust their fees. The idea is to avoid that situation at all
costs and keep the network
churning to the extent of its capabilities, without pretending a certain
size will be right at some
point in time, nobody can predict the future, nobody can predict real
organic usage peaks
on an open financial network, not all sustained spikes will come from
they will come from real world use as more and more people think of great
uses for Bitcoin.
I presented this idea to measure the mean wait time for transactions and I
was told
there's no way to reliably meassure such a number, there's no consensus
when transactions are still
in the mempool and wait times could be manipulated. Such an idea would have
to include new timestamp fields
on the transactions, or include the median wait time on the blockheader
(too complex, additional storage costs)
This is an iteration on the next thing I believe we can all agree is 100%
accurately measured, blocksize.
Full blocks are the cause why many transactions would have to be waiting in
the mempool, so we should be able
to also use the mean size of the blocks to determine if there's a
legitimate need to increase or reduce the
maximum blocksize.
The idea is simple, If blocks are starting to get full past a certain
threshold then we double the blocksize
limit starting the next block, if blocks remain within a healthy bound,
transaction wait times should be as
expected for everyone on the network, if blocks are not getting that full
and the mean goes below a certain
threshold then we half the maximum block size allowed until we reach the
level we need.
Similar to what we do with hashing difficulty, it's something you can't
predict, therefore no fixed limits,
or predicted limits should be established.

@_date: 2015-08-17 12:52:03
@_author: Angel Leon 
@_subject: [bitcoin-dev] BIP [104]: Replace Transaction Fees with Data, 
to supplement mining revenue and so those who do not have access to cheap
or free power to mine;"
wouldn't a bigger block size actually allow for more transactions per
block, therefore more fees to be collected, and the cost spread out among
many more users (thus still keeping tx fees low). If anything, wouldn't
bigger blocksizes are needed to suplement the losses of coinbase rewards
being halfed.
On Mon, Aug 17, 2015 at 12:39 PM, Ahmed Zsales via bitcoin-dev <

@_date: 2015-08-17 13:16:10
@_author: Angel Leon 
@_subject: [bitcoin-dev] BIP [104]: Replace Transaction Fees with Data, 
so you want us to, (i) at the moment of payment decide wether to pay a tx
fee, or to include some data about what the transaction is about...
(ii) and (iii) are out of the question as you'd be forcing people to not
have privacy, which is one of the main reasons people use bitcoin, just
paying like cash.
then the rest goes down hill.
1. You want to add more data to a transaction, which would fill blocks even
2. The data will be on the blockchain, why in hell would anybody pay the
miners for it when you can just mine it yourself, or pay XYZ online service
to give you the tools you mention, and why would XYZ company pay miners for
the revenues of such service?
because... you want to change the Bitcoin license from MIT to something
I'm sorry. this is dead on arrival, very unrealistic. Perhaps this will
work for some other coin where people accept all these orwellianism from
the start.
If you think there's much debate about blocksize you've no idea how things
would get at the mention of moving away from MIT into some sort of
commercial license, that would indeed destroy Bitcoin from being adopted as
it would enter into many many conflicts that would render it unusable by
lots of organizations.

@_date: 2015-08-18 22:59:01
@_author: Angel Leon 
@_subject: [bitcoin-dev] Bitcoin XT Fork 
"How then to end this XT madness?"
Instead of bashing on someone that has actually put a solution forward,
make your own fork and see if your ideas on how to solve the issue are any
As of now, 1Mb blocks are pure madness, and people are voting over an 8mb
block increase every day that passes, even with a "useless project" like
you call it.
Go out there and see how bitcoin is actually used.
On Tue, Aug 18, 2015 at 10:54 PM, odinn via bitcoin-dev <

@_date: 2015-02-19 17:53:27
@_author: Angel Leon 
@_subject: [Bitcoin-development] On Rewriting Bitcoin (was Re: 
I strongly suggest you take a look at swig for doing this. It's very
straightforward generating bindings in an automated fashion with it.
You could probably  have it done in one or two days with Swig.
Once you do the Java bindings with it, it'll be a few adjustments and
you'll have bindings for other languages as well.

@_date: 2015-01-28 12:17:54
@_author: Angel Leon 
@_subject: [Bitcoin-development] BIP70: why Google Protocol Buffers for 
why not allow both serializations and keep serialization format a
parameter, keep everyone happy.

@_date: 2015-01-31 01:48:40
@_author: Angel Leon 
@_subject: [Bitcoin-development] Is there a way to estimate the maximum number 
On the Chinese "Single's Day" (sort of like the american Black Friday)
according to MIT's Tech Review
"Alipay handled up to 2.85 million transactions per minute, and 54 percent
of its transactions are made via mobile device."
For a few weeks I've been reading the conversations about block sizes and
the experiments being done on the subject with larger blocks.
On the day with the most transactions, the Bitcoin block chain averages
about 73 transactions per minute. I kept wondering what blocksize we'd need
for handling 100,000 transactions per minute, and estimated that roughly
we'd need a blocksize of about 1300x times larger than what we have now, so
bigger than 1Gb block... but seeing the numbers Alipay gets to handle just
in China make me wonder how scalable is Bitcoin if it were to truly compete
with worldwide financial services.
If you were to include double the number Alipay can handle, you'd be
shooting about 6 million transactions per minute, or roughly 60 million
transactions per block.
If you average every transaction around 250 bytes, then you'd need ~15
Gigabytes per block to be broadcast and hashed by all the full nodes every
10 minutes, eating good 2Tb of storage daily... do miners have enough
bandwidth and CPU power to handle this?
are my scalability concerns absurd?

@_date: 2015-01-31 20:08:57
@_author: Angel Leon 
@_subject: [Bitcoin-development] Is there a way to estimate the maximum 
My concerns come from 2 projects that could easily raise the current
transaction volume 10x daily in the short term,  perhaps even 100x a year
from now after the media blows it out.
Think legal bittorrent file sales: ebooks, indie music (albums and
singles), films, art, stock photography.
Think p2p amazon (OpenBazaar) and how that could grow exponentially in
terms of transactional volume when ecommerce penetrates geos currently
Thanks for your explanations. it seems as of now we must rely on the likes
of centralized solutions like Bitpay, Coinbase to manage the transactional
volume we expect, or just wait for the technology to be ready finally
handle it in a real p2p fashion, no intermediaries.

@_date: 2015-07-17 17:13:25
@_author: Angel Leon 
@_subject: [bitcoin-dev] BIP 102 - kick the can down the road to 2MB 
When blocks are found under or over the 10 minute threshold, hashing
difficulty is raised or reduced dinamically to keep a balance. This
intelligent measure has avoided us having discussions and kept a balance.
The same way you can't assume how much hashpower there will be to find the
next blocks, why can't we have a
function that adapts to the transactional volume on the blockchain, one
which allows us to grow/shrink an acceptable maximum block size. We're not
putting caps on processing, why should we put a date based cap on
transactional volume per block? You can't predict the future, but you can
look at what's happened recently to correct these limits.
Such function/filter should be able to recognize real sustained growth in
transactional volume and let us adjust the maximum accepted blocksize to
allow for the organic growth that will come due to real activity from
things like distributed market-places, decentralized bitcoin based services
(and all the things the community dreams about and might be building
already), truly decentralized technological breakthroughs that geniunely
need to use the blockchain. It should be able to adapt fast enough so that we don't have episodes where
people need to wait 4 hours to days for transactions to get on the
blockchain and be confirmed. I believe proposals that include "every
100,000 blocks" are out of touch with reality, the blocksize needs to adapt
the same way blockdifficulty already adapts to growth or lack of hashing
I'm not a statistician/mathematician, but I'm sure if we propose the
parameters that need to be considered for a realistic blocksize that
reflects the needs of the Bitcoin network users, there's plenty of
crypto/statistician/mathematician brain power to propose such filtering
function here.
Things that could be considered:
- median number of transactions per block (between 6 to 12 hours, you
should be able to adjust to a real shopping sprint for instance, or huge
pop band/artist decides to sell concert tickets on Bitcoin)
- median fees offered per transaction (can we detect spammers)
- median blocksizes
- median size per transaction
- number of new addresses signing off transactions, number of addresses
we've already seen in the blockchain before (are these spammers creating
lots of new addresses to move around the same outputs, is there an
efficient way to detect the likelyhood of a transaction being spam? Bayes?
No clue, no mathematician)
- median velocity between which an address receives an input and sends it
to another one?
- more things I've no knowledge of since I'm not familiar with the details,
but could immediatly come to mind to the experts.
Mining Centralization is already happening due to its competitive nature,
we don't complain or try to force hashing limits, we shouldn't do the same
for storage. There will be no shortage of blockchain mirrors, and those
interested in running full nodes, will surely find a way to do so.
On Fri, Jul 17, 2015 at 4:29 PM, Luke Dashjr via bitcoin-dev <

@_date: 2015-05-13 07:25:47
@_author: Angel Leon 
@_subject: [Bitcoin-development] Block Size Increase 
blockchain for each pizza. And  why should this expense be good for trivial
things of everyday life?
Then what's the point?
Isn't this supposed to be an Open transactional network, it doesn't matter
if you don't want that, what matters is what people want to do with it, and
there's nothing you can do to stop someone from opening a wallet and buying
a pizza with it, except the core of the problem you ask yourself about,
which is, the minute this goes mainstream and people get their wallets out
the whole thing will collapse, regardless of what you want the blockchain
Why talk about the billions of unbanked and all the romantic vision if you
can't let them use their money however they want in a decentralized
fashion. Otherwise let's just go back to centralized banking because the
minute you want to put things off chain, you need an organization that will
need to respond to government regulation and that's the end for the
billions of unbanked to be part of the network.

@_date: 2015-11-13 11:52:08
@_author: Angel Leon 
@_subject: [bitcoin-dev] How to evaluate block size increase suggestions. 
I believe in the end it's the usability of bitcoin that matters.
For instance, a goal could be that no user on the network should wait more
than an hour to get 3 confirmations on the blockchain so that they can
actually have useful Bitcoins.
We can debate all we want about lots of technical aspects, but if you can't
send money what's the point?
My humble proposal tried to take that into consideration, but I like way
way more what you propose with NG.
On Fri, Nov 13, 2015 at 11:37 AM, Emin G?n Sirer <

@_date: 2015-09-15 08:48:35
@_author: Angel Leon 
@_subject: [bitcoin-dev] Instant exchange rates URI scheme 
might want to specify there that the rate being sent is out of USD.
On Tue, Sep 15, 2015 at 7:10 AM, John Bailon via bitcoin-dev <

@_date: 2015-09-23 20:31:27
@_author: Angel Leon 
@_subject: [bitcoin-dev] Torrent-style new-block propagation on Merkle 
has anybody ever submitted a patch using libtorrent's library for this
would it make sense to create a torrent per confirmed valid block once it's
been truly added to the blockchain?
if we used libtorrent, I imagine the following to announce the new block on
libtorrent's DHT
(PSEUDO CODE)
block at a certain height.
information about that block.
string peer_announcement_key = sha1_hasher("blockchain::bitcoin::block::" +
session.dht_announce(peer_announcement_key, rpc_port, 0);
height would:
sessoin.dht_get_peers(sha1_hasher("blockchain::bitcoin::block::" +
the DHT
for the .torrent
then you'd start the block download by building a magnet link out of the
infohash received for the block.
The download would be done directly to memory and then such byte array
would be serialized as a block
as it is done now, and you'd then announce yourself both on the
sha1(peer_announcement_key) and
on the infohash of the block you just downloaded, after you start seeding
perhaps the block's torrent chunk sizes could be made optimal so that
chunks sent would perfectly match
tranactions, this way you could start building the blocks on the other end
as they're being downloaded from the swarm.
On Wed, Sep 23, 2015 at 7:12 PM, Jonathan Toomim (Toomim Bros) via

@_date: 2016-12-15 22:25:04
@_author: Angel Leon 
@_subject: [bitcoin-dev] Planned Obsolescence 
Perhaps if there were a message that would nag your stdout or log output
letting you know there's a new version available, or N more versions
available and that you might be missing out on X security patches, Y
protocol improvements, depending on how far back you are, you'd be tempted
to upgrade, works for me in Ubuntu every time I log to my servers and I see
how far behind I am in terms of available updates.
Other thing done in open source projects to encourage updates, is to
automatically distribute (download) the patches and let the node operator
know an update has been downloaded for them, and let them know they're just
one step away from applying such update.
We do this for our bittorrent client. We don't ever want to do automatic
upgrades of our network, however, we want to make it painless to update.
For Bitcoin this could be done for the official binary distribution, would
not be an option for those that build from source.
On Thu, Dec 15, 2016 at 11:49 AM Jorge Tim?n via bitcoin-dev <

@_date: 2017-04-19 13:47:40
@_author: Angel Leon 
@_subject: [bitcoin-dev] Small Nodes: A Better Alternative to Pruned Nodes 
allow someone to essentially automate the deployment of nodes. i.e. if a
node can pay for itself 100% (even at a lesser value, it just becomes
cheaper overall), you could write an application that uses an AWS API or a
digital ocean API to automatically deploy 100's of nodes. Which sounds
great but not if that person is malicious and wants to prevent the
community adopting proposals.
what other projects have done to avoid such attacks (while incentivizing
economically running full nodes) is to only distribute part of the block
rewards back such nodes if that node has committed/frozen a predetermined
amount of coins that can't be spent. This also leaves less liquidity for
market speculation and a incentives for long term commitments.
On Wed, Apr 19, 2017 at 5:14 AM udevNull via bitcoin-dev <

@_date: 2020-01-15 18:21:52
@_author: Angel Leon 
@_subject: [bitcoin-dev] Coins: A trustless sidechain protocol 
services, only their customers need to know those internal ledgers, and
sign off on the updates of those ledgers.
That's right, all you need to broadcast is a small proof, a non-interactive
blockchain suffix proof
On Sun, Jan 12, 2020 at 7:33 PM ZmnSCPxj via bitcoin-dev <
