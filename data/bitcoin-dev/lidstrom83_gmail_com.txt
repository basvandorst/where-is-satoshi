
@_date: 2012-06-25 16:21:14
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] Enforcing inflation rules for SPV clients 
Here's the conversation I had with Mike that Gregory requested a link to:
Bad or hacked client devs is indeed a huge, worrying problem. The official client is addressing this with a system called gitian, where multiple developers all compile the same source to the same binary and then sign the results. Multi-signatures raise the bar for releasing hacked clients a lot. We're starting to investigate this with bitcoinj too, but it's a lot of work.
Generally, the more people you have to involve in a conspiracy, the less likely it is to succeed. If a few miners started to dominate the system they have strong financial incentives to cheat, alternatively, they may be subjected to government pressure. Having to get the client developers involved too makes it much harder, especially as users have to actually I started a thread on the development mailing list with your suggestion, by the way.
    Hey Mike,
    I put our conversation in the email for easy reference.
    In the unlikely event of a miner conspiracy to print money, is it
    really so much of a further stretch to think the developers of a
    widely used client could also be involved?  (Well, maybe, since
    miners are unaccountable and developers are not.  OTOH if most users
    are apathetic...)  Also, isn't the advantage for lightweight clients
    of SPV over the server-client model that you don't have to trust any
    operator?  Maybe I'm being too much of a purist here...
    Regarding errors being cheap to send and expensive to verify,
    compartmentalizing them the way I suggested before would make them
    individually cheaper to verify.  Just throwing around ideas:
    requiring the error message be received by a quorum of peers before
    checking, and dropping misbehaving or unreliable peers could help.
    Also, not verifying error messages unless the peers relaying them
    are willing to send all the data necessary to do so would help.     Hashcash could also be used to balance the costs to send and to
    verify a given type of error message.  I like your idea to only
    check errors in blocks that are split points, and the length of the
    split could also be a consideration.

@_date: 2013-06-10 03:34:33
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] Proposal: Vote on the blocksize limit 
Reserving my judgement until I've though about it more (design by committee
scares me, and this voting sounds expensive), I think the SPV-verifiable
moving median can be done by binning the space of block size limits, and
for each node in the UTXO tree, a value for each bin is stored which is the
sum of the corresponding bins of each of the children.  The childless nodes
- which correspond to the individual UTXOs - increment the appropriate bin
of their parents according to the rules you mentioned.  The bin values in
the root node of the UTXO tree would then be added to those, weighted
appropriately, of the previous N blocks.
The hash of a node would be that of the bin values, concatenated with the
child nodes' hashes.  In this way, any step of the calculation of the
median would produce a localized error in the UTXO tree that's easily
The number of bins would have to be kept relatively small in order to keep
this from adding too much data to the UTXO tree branches though.

@_date: 2013-03-07 14:31:10
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] Large-blocks and censorship 
My views on censorship resistance in the face of scaling:
1) I expect if I'm not careful about preserving my privacy with the way I
use Bitcoin, then I will always run the risk of being censored by miners.
This means connecting to the network anonymously, not reusing addresses,
and perhaps even mixing my coins.  The onus is on me here to avoid
censorship, but I'm optimistic that this privacy preservation can be made
pretty automatic.
2) I expect anonymity systems to scale to accommodate Bitcoin full nodes,
not Bitcoin to stay small to avoid putting pressure on anonymity systems to
3) If 2 is too tall an order, then mining in a pool is always an option.
There should always be some countries in the world free enough to allow
mining pools to operate, and miners in countries that ban Bitcoin can
simply connect to these anonymously.  If not, then Bitcoin is toast anyway,
is it not?  If these miners are really interested in avoiding censoring
transactions, then they will do their due diligence and choose a pool that
doesn't do this.  But even if they don't, censorship can be personally
avoided by following 1.

@_date: 2013-11-07 11:28:52
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] we can all relax now 
Hey Peter, something seems wrong with your above analysis: I think a miner
would withhold his block not because it leads to a greater probability of
winning the next one, but because it increases his expected revenue.
Suppose a cabal with fraction q of the total hashing power is n blocks
ahead on a secret branch of that has mined r_tot coins, and let r_next be
its next block's reward.  If the cabal chooses not to broadcast its secret
chain until at least the next block, its expected revenue after the next
block is found is
(1 - (1-q)^(n+1))*(r_tot + r_next)
If it does broadcast, its expected revenue after the next block is found is
r_tot + q * r_next
If the cabal seeks only to maximize immediate revenue, then after a bit of
algebra we find that it will withhold its chain if
q > 1 - ( 1 + r_tot / r_next )^(-1/n)
So if the cabal has just mined his first block off of the public chain,
i.e. n = 1, and if the block reward is relatively stable, i.e. r_next =
r_tot, then it needs q > 50% to profitably withhold, not the 29.2% you
withholds again, then he must grow q to compensate for the increase in
r_tot, and any decrease in n.  So generally publication becomes
increasingly in the cabal's interest, and secret chains will tend not to
grow too large (intuition tells me that simulations using the above formula
should bear this out).
This seem correct to you?

@_date: 2013-10-03 03:35:30
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] Identity protocol observation 
The location of a tx in the blockchain can be encoded in n=log2(h)+log2(t)
bits, where h is the block height, and t is the number of transactions in
the block.  Currently h~250,000 and t~500, so n~27.  A CVC phoneme encodes
~10.7 bits *, so a transaction today can be located in the blockchain with
3 of these, e.g. reb-mizvig.  This is reasonably short, readable and
The identity protocol Jeff Garzik is working on will link a public key
fingerprint to a miner sacrifice transaction.  This tx could in turn be
uniquely described with a short name as above.  Associating this name with
the public key becomes secure once the tx is sufficiently buried in the
blockchain.  In the identity protocol, lightweight clients check the
validity of a sacrifice tx by checking that its merkle path is valid.  But
this path encodes, via the ordering of the hashes at each level, the
location of the transaction in the block, so the lightweight client can
verify the sacrifice tx's short name using only the information he already
Some more random names:
Sources of inspiration:
* This is somewhat restricted: I disallowed q for obvious reasons and k
because it conflicts with c, and c looks much softer and less like
Klingon.  H is allowed for the first consonant, but not the second, and x
is allowed for the last one, but not the first one.  Y is a vowel, but not
a consonant.  Maybe these weren't quite the right choices.  Paint away!

@_date: 2013-10-03 07:35:32
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] Identity protocol observation 
A couple more thoughts on this:
1) Both c and k can be kept if c is pronounced 'ch', giving ~10.9 bits per
2) An extra phoneme (4 encode 43 bits total) gives room to put extra
information into the name, e.g. the first 5 bits could be input as the key
to a PRP that permutes the last 38 back to a standard encoding of a tx
location.  This would give the user 32 random names per sacrifice to choose
from, and 38 bits to encode its location in the blockchain, which is enough
for pretty large blocks.
Sample 4 phoneme names:
They're not that bad IMHO, especially if you get to pick a decent one from
a bunch.

@_date: 2013-10-03 09:16:51
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] Identity protocol observation 
Fair enough, though people still manage okay with phone numbers.  And a
decentralized naming system seems to come at great cost - with namecoin you
need the whole blockchain to resolve names without trust.  Strip out a bell
and whistle - meaningfulness and transferability of names - and you get a
simple, rudimentary (spam killing!) system that scales on any device.  I'll
only argue that it seems to be Good Enough *for the types of people who
might care about decentralized names*.  Probably a very small set :)

@_date: 2013-10-03 10:16:27
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] Identity protocol observation 
Names clearly solve a different problem than that, but we still use them,
so they must be solving _some_ problem :p  In this case they're a unique
identifier humans can remember after a bit of use and easily communicate to
each other with little room for error.  Securely mapping them to public
keys would make key verification simpler.  Simpler than checking a much
larger key fingerprint, at least.  Like I said, it's probably a niche
product ;)
I used to remember dozens of phone numbers before my phone did it for me,
but maybe I was just weird.

@_date: 2014-04-20 22:44:24
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] Economics of information propagation 
If it's only during the few seconds that it takes to to verify the block,
then would this really be that big of a deal?  E.g. even if all miners did
this, a 10 second delay would only yield an average of a couple blind/empty
blocks per day.

@_date: 2014-04-20 23:46:29
@_author: Daniel Lidstrom 
@_subject: [Bitcoin-development] Economics of information propagation 
If this policy of mining empty blocks upon new block headers before
downloading and verifying the blocks became the standard, then wouldn't the
marginal orphan probability per transaction vanish?  It seems like this
could be a way to seriously reduce transaction fees.
