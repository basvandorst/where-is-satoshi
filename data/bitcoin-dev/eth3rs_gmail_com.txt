
@_date: 2014-06-03 07:51:45
@_author: Ethan Heilman 
@_subject: [Bitcoin-development] Lets discuss what to do if SHA256d is 
An attack on the mining difficulty algorithm does not imply violation of
the typical security properties of a cryptographic hash function*.
Assume someone discovers a method which makes it far easier to discover new
blocks, this method: may or may not be implementable by the current SHA256
ASIC hardware.
1. If it is usable by the mining hardware, then there will be brief period
of overproduction and then difficulty will adjust. If the attack is so bad
that difficulty can't scale and we run out of a leading zero's, then the
SHA256 collision resistance is broken and we have bigger problems. Under
this scenario, everyone would see the need to immediately switch to new
hardware as people could create cycles and irreconcilable forks in the
block chain
2. If the attack is not usable by the mining hardware, then the miners will
need to switch to new ASICs anyways and the hash function can be changed
without resistance.
But lets ignore all that and say, for some unspecified reason, the bitcoin
community wants to switch hash functions and has some lead time to do so.
One could require that miners find two blocks, one computed using SHA256
and one computed using the new hash function. We could then slowly shift
the difficulty from SHA256 to the new hash function. This would allow
miners a semi-predicable roadmap to switch their infrastructure away from
* It would be a distinguisher which would be bad, but collision resistance
could be merely weakened.

@_date: 2015-02-15 11:15:15
@_author: Ethan Heilman 
@_subject: [Bitcoin-development] P2P tests: peers.dat's requested 
Hi All,
I am currently running some tests on the peering system in Bitcoind for a
research paper. We hope to develop improvements which we can share with the
community. A wide diversity of real peers.dat files would be very helpful.
If you are willing, please email me your peers.dat.

@_date: 2015-06-01 23:32:58
@_author: Ethan Heilman 
@_subject: [Bitcoin-development] Meta suggestions for this block size 
I second this, I don't have time to read the large number of emails
generated every day from the block size debate. A summary of the various
positions and arguments would be extremely helpful.

@_date: 2015-03-23 11:33:18
@_author: Ethan Heilman 
@_subject: [Bitcoin-development] =?utf-8?q?Research_on_partitioning_Bitcoind?= 
Hi All,
There has been much discussion lately on the dev list about
misbehaving peers and attacks on the P2P network. We'd like to share
our research on partitioning Bitcoind nodes from the rest of the
Eclipse Attacks on Bitcoin?s Peer-to-Peer Network
Abstract: We present eclipse attacks on bitcoin's peer-to-peer
network. Our attack allows an adversary controlling a sufficient
number of IP addresses to monopolize all connections to and from a
victim bitcoin node. The attacker can then exploit the victim for
attacks on bitcoin's mining and consensus system, including
N-confirmation double spending, selfish mining, and adversarial forks
in the blockchain. We take a detailed look at bitcoin?s peer-to-peer
network, and quantify the resources involved in our attack via
probabilistic analysis, Monte Carlo simulations, measurements and
experiments with live bitcoin nodes. Finally, we present
countermeasures, inspired by botnet architectures, that are designed
to raise the bar for eclipse attacks while preserving the openness and
decentralization of bitcoin?s current network architecture.
Full paper available here:

@_date: 2016-12-15 17:44:55
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] Planned Obsolescence 
I assume this has been well discussed in at some point in the Bitcoin
community, so I apologize if I'm repeating old ideas.
Problem exploitable nodes:
It is plausible that people running these versions of bitcoind may not
be applying patches. Thus, these nodes may be vulnerable to known
exploits. I would hope none of these nodes are gateway nodes for
miners, web wallets or exchanges. How difficult would it be to crawl
the network to find vulnerable nodes and exploit them? What percentage
of the network is running vulnerable versions of bitcoind?
Problem eclipsable nodes:
Currently a bitcoind node disconnects from any node with a version
below MIN_PEER_PROTO_VERSION. Such nodes become be ripe for an eclipse
attack because they are partitioned from the newer nodes, especially
when they are "freshly obsolete". I have not examined how protocol
versioning works in detail so I could be missing something.
One option could be that after a grace period:
1. to still connect to obsolete nodes and even to transmit blockheaders,
2. but to stop sending the full-blocks and transactions to these
nodes, thereby alerting the operator that something is wrong and
causing them to upgrade.
It may make sense to create this as a rule, if your longest chain
consists of only blockheaders and no one will tell you the
transactions for over 1000 blocks you are obsolete, spit out an error
message and shutdown.
This would not address the issue of alt-coins which are forked from
old vulnerable versions of bitcoind, but that is probably out of
On Thu, Dec 15, 2016 at 1:48 PM, Jorge Tim?n via bitcoin-dev

@_date: 2016-02-22 13:06:56
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] New paper: On Bitcoin Security in the Presence of 
"*Abstract: *Digital currencies like Bitcoin rely on cryptographic
primitives to operate. However, past experience shows that cryptographic
primitives do not last forever: increased computational power and advanced
cryptanalysis cause primitives to break frequently, and motivate the
development of new ones. It is therefore crucial for maintaining trust in a
crypto currency to anticipate such breakage.
We present the first systematic analysis of the effect of broken primitives
on Bitcoin. We identify the core cryptographic building blocks and analyze
the various ways in which they can break, and the subsequent effect on the
main Bitcoin security guarantees. Our analysis reveals a wide range of
possible effects depending on the primitive and type of breakage, ranging
from minor privacy violations to a complete breakdown of the currency.
Our results lead to several observations on, and suggestions for, the
Bitcoin migration plans in case of broken cryptographic primitives."

@_date: 2016-01-07 15:40:03
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
Based on current GH/s count of 775,464,121 Bitcoin tests 2^80 every 19 days.
log2(775464121*(1000*1000*1000*60*60*24*19)) = ~80.07
I don't fully understand the security model of segwit, so my analysis
will assume that any collision is bad.
You don't store all 2^80 previous hashes, instead you just hash a seed
value 2^80 times, then look for a cycle.
seed = {0,1}^160
x = hash(seed)
for i in 2^80:
....x = hash(x)
x_final = x
y = hash(x_final)
for j in 2^80:
....if y == x_final:
........print "cycle len: "+j
....y = hash(y)
If at any point x collides with a prior value of x it will form a
cycle. Thus y will also cycle and collide with x_final. j gives you
the cycle length, which allows you find the collision:
hash^(2^80-j)(seed) == hash^(j)(hash^(2^80-j)(seed)).
Worst case:
First loop costs 2**80, second loop costs 2**80=j, finding the
colliding value is 2**80. Total cost 2**80+2**80+2**80 = 2**81.5 and
requires storing less than a kilobyte.
This is a toy example, does not exploit parallelism, time memory trade
offs, can be easily made better, etc...
On Thu, Jan 7, 2016 at 2:02 PM, Gavin Andresen via bitcoin-dev

@_date: 2016-01-07 17:56:38
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
I'm not sure exactly the properties you want here and determining
these properties is not an easy task, but the case is far worse than
just two random values. For instance: (a). with a small modification
my algorithm can also find collisions containing targeted substrings,
(b). length extension attacks are possible with RIPEMD160.
(a). targeted cycles:
target1 = "str to prepend"
target2 = "str to end with"
seed = {0,1}^160
x = hash(seed)
for i in 2^80:
....x = hash(target1||x||target2)
x_final = x
y = hash(tartget1||x_final||target2)
for j in 2^80:
....if y == x_final:
........print "cycle len: "+j
....y = hash(target1||y||target2)
If a collision is found, the two colliding inputs must both start with
"str to prepend" and end with the phrase "str to end with". As before
this only requires 2^81.5 computations and no real memory. For an
additional 2**80 an adversary has an good change of finding two
different targeted substrings which collide. Consider the case where
the attacker mixes the targeted strings with the hash output:
hash("my name is=0x329482039483204324423"+x[1]+", my favorite number
is="+x) where x[1] is the first bit of x.
(b). length extension attacks
Even if all the adversary can do is create two random values that
collide, you can append substrings to the input and get collisions.
Once you find two random values hash(x) = hash(y), you could use a
length extension attack on RIPEMD-160 to find hash(x||z) = hash(y||z).
Now the bitcoin wiki says:
"The padding scheme is identical to MD4 using Merkle?Damg?rd
strengthening to prevent length extension attacks."[1]
Which is confusing to me because:
1. MD4 is vulnerable to length extension attacks
2. Merkle?Damg?rd strengthening does not protect against length
extension: "Indeed, we already pointed out that none of the 64
variants above can withstand the 'extension' attack on the MAC
application, even with the Merkle-Damgard strengthening" [2]
3. RIPEMD-160 is vulnerable to length extension attacks, is Bitcoin
using a non-standard version of RIPEMD-160.
RIPEMD160(SHA256()) does not protect against length extension attacks
on SHA256, but should protect RIPEMD-160 against length extension
attacks as RIPEMD-160 uses 512-bit message blocks. That being said we
should be very careful here. Research has been done that shows that
cascading the same hash function twice is weaker than using HMAC[3]. I
can't find results on cascading RIPEMD160(SHA256()).
RIPEMD160(SHA256()) seems better than RIPEMD160() though, but security
should not rest on the notion that an attacker requires 2**80 memory,
many targeted collision attacks can work without much memory.
[1]: [2]: "Merkle-Damgard Revisited: How to Construct a Hash Function"
[3]: On Thu, Jan 7, 2016 at 4:06 PM, Gavin Andresen via bitcoin-dev

@_date: 2016-01-18 22:58:22
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] What is OpenSSL still used for? 
I believe libsecp256k1 just performs Elliptic Curve operations
required by Bitcoin. OpenSSL is used for all other crypto.
For instance the PRNG appears to be OpenSSL:
On Mon, Jan 18, 2016 at 8:39 PM, Andrew C via bitcoin-dev

@_date: 2016-06-28 21:56:55
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] BIP 151 use of HMAC_SHA512 
SHA256(key|cipher-type|mesg) is an extremely insecure MAC because of
the length extension property of SHA256.
If I have a tag y = SHA256(key|cipher-type|mesg), I can without
knowing key or msg compute a value y' such that
y' = SHA256(key|cipher-type|mesg|any values I want).
Thus, an attacker can trivially forge a tag protected by
For more details see:
On Tue, Jun 28, 2016 at 9:00 PM, Rusty Russell via bitcoin-dev

@_date: 2016-06-29 10:38:43
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] BIP 151 use of HMAC_SHA512 
Just to clarify in BIP-0151 when it says:
the cipher-type here refers to the ECDH negotiation parameters?

@_date: 2017-08-11 16:36:59
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] ScalingBitcoin 2017: Stanford - Call For Proposals 
Dear All,
The Call for Proposals (CFP) for 'Scaling Bitcoin 2017: Stanford' is now
Please see  for details
*Important Dates*
Sept 25th - Deadline for submissions to the CFP
Oct 16th - Applicant acceptance notification
Hope to see you in California (Nov 4-5 2017)
Full CFP can be found at

@_date: 2017-02-25 11:10:02
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] SHA1 collisions make Git vulnerable to attakcs by 
160bits isn't enough.
I would argue that 160-bits isn't enough for collision resistance. Assuming
RIPEMD-160(SHA-256(msg)) has no flaws (i.e. is a random oracle), collisions
can be generated in 2^80 queries (actually detecting these collisions
requires some time-memory additional trade-offs). The Bitcoin network at
the current hash rate performs roughly SHA-256 ~2^78 queries a day or 2^80
queries every four days. Without any break in RIPEMD-160(SHA-256(msg)) the
US could build an ASIC datacenter and produce RIPEMD-160 collisions for a
fraction of its yearly cryptologic budget.
The impact of collisions in RIPEMD-160(SHA-256(msg)) according to "On
Bitcoin Security in the Presence of Broken Crypto Primitives"(
adversary?s control, and again the adversary does not have access to the
private keys. In both scenarios, there is a question of nonrepudiation
external to the protocol itself: by presenting a second pre-image of a key
used to sign a transaction, a user/adversary can claim that his coins were
How would such an event effect the price of Bitcoin when headlines are
"Bitcoin's Cryptography Broken"? How much money could someone make by
playing the market in this way?
For both reasons of credibility and good engineering (safety
margins) Bitcoin should strive to always use cryptography which is beyond
On Sat, Feb 25, 2017 at 9:50 AM, Leandro Coutinho via bitcoin-dev <

@_date: 2017-02-25 13:36:49
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] SHA1 collisions make Git vulnerable to attakcs by 
collision that is also a valid sha-256 hash - and that's much much much
more difficult.
I agree that merely finding a collision in RIPEMD-160 will be hard to use
in Bitcoin.
However finding a collision in RIPEMD-160(SHA-256(msg)) via bruteforce
(2^80 queries) is not particular more difficult than finding a collision in
RIPEMD-160 via brute force. Furthermore if you find a collision in
RIPEMD-160(SHA-256(msg)) you also get a valid SHA-256 hash for which you
know the preimage.
On Sat, Feb 25, 2017 at 1:19 PM, Alice Wonder via bitcoin-dev <

@_date: 2017-02-25 17:34:38
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] SHA1 collisions make Git vulnerable to attakcs by 
I strongly encourage Bitcoin to move from 80-bit collision resistance
(RIPEMD-160) to 128-bit collision resistance (SHA-256).
On Sat, Feb 25, 2017 at 5:14 PM, Pieter Wuille via bitcoin-dev <

@_date: 2017-05-22 10:41:40
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] A proposal to reintroduce the disabled script 
I want OP_CAT so that I can securely and compactly verify many hashes and
hash preimages. This would shrink offchain Tumblebit transactions
For instance if I want a transaction TxA which checks that a transaction
TxB releases preimages x1,x2,...,x10 such that
y1=H(x1), y2=H(x2),...,y10=H(x10). Currently I just put y1,...y10 and check
that the preimahes hash correctly. With OP_CAT I would only have to store
one hash in TxA, yhash
ytotal = H(OP_CAT(H(OP_CAT(y1, y2)),y3)...y10)
TxA could then just hash all the preimages supplied by TxB and confirm they
hash to TxA. This would reduce the size of TxA from approx 10*32B to
32+10*16B. I have a version which improves this further but it is more
Most of the math OP codes aren't particularly helpful due to their 32bit
nature and their strange overflow behavior.

@_date: 2017-05-22 12:43:11
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] A proposal to reintroduce the disabled script 
My OP_CAT usecase only needs to glue together hash outputs, so two 32
Bytes inputs generating a 64 Byte output. However increasing this
would enable additional space savings. I would push for an OP_CAT
which can generate an output of no greater than 512 Bytes. Is there
are maximum byte vectors size for script?
The ideal instruction for this usecase be an instruction that pops N
vectors of the stack, concatenates them together and hashes them.
OP_CATHASH256(N) --> OP_HASH256(v1||v2||..||vN)
where || denotes concatenation. You could do this in a streaming
fashion so that memory usage would never exceed 32 Bytes regardless of
the size of the input vectors.
However I recognize that OP_CAT is more generally useful and it
already in scripts but just disabled.

@_date: 2019-04-18 16:12:20
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] Improving SPV security with PoW fraud proofs 
I'm probably repeating a point which has been said before.
If this minority miner has > 10% of network hashrate, then the rule of
thumb above would, on average, give it the ability to disrupt the
SPV-using network.
Proposed rule:
Whenever a chainsplit occurs SPV clients should download and validate
the "longest chain" up to more than one block greater than the height
of the losing chain.
Lets say a block split causes chain A and chain B: Chain A is N blocks
long, chain B is M blocks long, and N < M. Then the SPV client should
download all the block data of N+1 blocks from Chain B to verify
availability of chain B. Once the SPV client has verified that chain B
is available they can use fraud proofs determine if chain B is valid.
An attacker could use this to force SPV clients to download 1 block
per block the attacker mines. This is strictly weaker security than
provided by a full-node because chain B will only be validated if the
client knows chain A exists. If the SPV client's view of the
blockchain is eclipsed then the client will never learn that chain A
exists and thus never validate chain B's availability nor will the
client be able to learn fraud proofs about chain B. A full node in
this circumstance would notice that the chain B is invalid and reject
it because a full node would not depend on fraud proofs. That being
said this rule would provide strictly more security than current SPV
On Thu, Apr 18, 2019 at 3:08 PM ZmnSCPxj via bitcoin-dev

@_date: 2019-04-18 21:13:07
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] Improving SPV security with PoW fraud proofs 
Hi ZmnSCPxj,
Let's see if I understand what you are saying. In your scenario chain
A consists of honest miners (10% of the hash rate) and chain B  (90%
of the hash rate) consists of dishonest miners who are inflating the
coin supply.
Chain A: S, S+1
Chain B: S, S+1 (invalid), S+2, S+3, S+4, S+5, S+6, S+7, S+8, S+9
Chain B S+1 has a invalid coinbase
What I am suggesting is that when the minority miners generate an
alternate block at S+1 (chain A) the SPV node would download blocks
S+1 and S+2 from chain B (the dishonest chain). Since S+1 has the
invalid coinbase the SPV node would learn that chain B is invalid and
abandon it.
Bitcoin is in big trouble if a malicious party controls 90% of the
mining power. The malicious miners can spend +11% of their mining
power ensuring that the honest chain never reaches consensus by
continuously forking it. The malicious miners can then extend their
favored chain using the other 79% of the mining power. This would
produce a scenario in which users are forced to choose between a
stable chain that violates a consensus rule and an unstable honest
chain that is completely unusable and which never pays out mining
rewards. I agree that SPV nodes and many wallets would make this even
worse especially in their current condition where they just trust the
hash rate/wallet provider and there are no fraud proofs.

@_date: 2019-04-18 23:21:53
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] Improving SPV security with PoW fraud proofs 
Good morning to you as well ZmnSCPxj,
My above email contains an error. The SPV client needs to only
download S+1, not S+1 and S+2.
I agree with you that a weakness of this approach is a miner can make
SPV clients do substantially more work. However:
1. Mining a block which will never be accepted is an expensive way to
make SPV clients download, validate and discard ~2-4 megabytes of
data. There are far less expensive ways of wasting the resources of
SPV clients. Its unclear why someone would want to do this instead of
just packeting full nodes or SPV servers like we saw with the recent
DDoS attacks against electrum servers.
2. SPV clients may not even learn about these splits because it
requires that someone relay the split to them. Honest full nodes
should not relay such splits. To their bitcoin's worth the attacker
must also connect to lots of SPV clients.
3. Having SPV clients slow down or become full nodes when a malicious
miner with significant mining power is attempting to disrupt the
network is probably a best case outcome. I would prefer this failure
mode to the current SPV behavior which is to just go with the
"longest" chain.

@_date: 2019-08-02 08:19:03
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] Add a moving checkpoint to the Bitcoin protocol 
Attack 1:
I partition (i.e. eclipse) a bunch of nodes from the network this partition
contains no mining power . I then mine 145 blocks for this partition. I
don't even need 51% of the mining power because I'm not competing with any
other miners. Under this rule this partition will hardfork from the network
permanently. Under current rules this partition will be able to rejoin the
network as the least weight chain will be orphaned.
Attack 2:
I pre-mine 145 blocks. A node goes offline for 24 hours, when it rejoins I
feed it 145 blocks which fork off from the consensus chain. I have 24+24
hours to mine these 145 blocks so I should be able to do this with 25% of
the current hash rate at the time the node went offline. Under your rule
each of these offline-->online nodes I attack this way will hardfork
themselves from the rest of the network.
I believe a moving-checkpoint rule as describe above would make Bitcoin
more vulnerable to 51% attacks.
A safer rule would be if a node detects a fork with both sides of the split
having  length > 144 blocks, it halts and requests user intervention to
determine which chain to follow.  I don't think 144 blocks is a great
number to use here as 24 hours is very short. I suspect you could improve
the security of the rule by making the number of blocks a fork most reach
to halt the network proportional to the difference in time between the
timestamp in the block prior to the fork and the current time. I am **NOT**
proposing Bitcoin adopt such a rule.
NXT has a fundamentally different security model as it uses Proof-of-stake
rather than Proof-of-Work.
On Wed, Jul 31, 2019 at 2:37 PM Kenshiro [] via bitcoin-dev <

@_date: 2019-12-28 12:38:11
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] Non-equal value CoinJoins. Opinions. 
I'm only going to talk about cashfusion and not the knapsack paper.
The language they use to describe the cashfusion protocol is very
broad and could describe many things. Because it is hard so vague I
don't want to dismiss the cashfusion approach out of hand. For
instance they say: "inputs of arbitary amounts in the neighborhood of
~0.1 BCH" what exactly does this mean?
Attack 1:
If we assume arbitrary means any precision then a trivial attack is
possible. Consider the case where one of the inputs has more precision
than any other input. This allows an attacker to trivially break the
privacy of that input:
Lets look at a toy example that takes 12 inputs and creates 3 outputs
Clearly output output 0.4648111 contains input 0.1144111.
Attack 2:
Let's say you attempt to address this problem this by limiting the
precision of inputs to two decimal places i.e. 0.1X where 0<=X<=9.
Consider the case of 10 users where each user is always joining sets
of 10 inputs to create 1 output. Thus in total you would have 100
inputs and 10 outputs in the coinjoin. If one of those outputs is 2
then you know its inputs must all be 0.2. Using this method you can
start eliminate input output pairs far faster brute force. How much
faster is hard to say without adding additional assumptions for
instance are these inputs amounts drawn from a uniform distribution?
I want to be clear. I'm not saying cashfusion is broken or that this
more inputs than outputs technique is a dead end. However the
description given is vague and could be interpreted to describe a
broken protocol. Is this actively being used?
On Fri, Dec 27, 2019 at 8:29 PM nopara73 via bitcoin-dev

@_date: 2019-10-01 10:27:21
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] [Lightning-dev] Continuing the discussion about 
I want to second this. The most expensive part of wallet design is
engineering time. Writing code that uses a new sighash or a custom
script with a OP_CODE is a very large barrier to use. How many wallets
support multisig or RBF? How much BTC has been stolen over the entire
history of Bitcoin because of sighash SIGHASH_NONE or SIGHASH_SINGLE
vs ECDSA nonce reuse?

@_date: 2019-10-03 11:05:52
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] OP_CAT was Re: Continuing the discussion about 
To avoid derailing the NO_INPUT conversation, I have changed the
subject to OP_CAT.
Responding to:
* `SIGHASH` flags attached to signatures are a misdesign, sadly
retained from the original BitCoin 0.1.0 Alpha for Windows design, on
par with:
* `OP_CAT` and `OP_MULT` and `OP_ADD` and friends
OP_CAT is an extremely valuable op code. I understand why it was
removed as the situation at the time with scripts was dire. However
most of the protocols I've wanted to build on Bitcoin run into the
limitation that stack values can not be concatenated. For instance
TumbleBit would have far smaller transaction sizes if OP_CAT was
supported in Bitcoin. If it happens to me as a researcher it is
probably holding other people back as well. If I could wave a magic
wand and turn on one of the disabled op codes it would be OP_CAT.  Of
course with the change that size of each concatenated value must be 64
Bytes or less.
On Tue, Oct 1, 2019 at 10:04 PM ZmnSCPxj via bitcoin-dev

@_date: 2019-10-03 20:48:17
@_author: Ethan Heilman 
@_subject: [bitcoin-dev] [Lightning-dev] OP_CAT was Re: Continuing the 
I hope you are having an great afternoon ZmnSCPxj,
You make an excellent point!
I had thought about doing the following to tag nodes
`node = SHA256(type||SHA256(data))`
so a subnode would be
`subnode1 = SHA256(1||SHA256(subnode2||subnode3))`
and a leaf node would be
`leafnode = SHA256(0||SHA256(leafdata))`
Yet, I like your idea better. Increasing the size of the two inputs to
OP_CAT to be 260 Bytes each where 520 Bytes is the maximum allowable
size of object on the stack seems sensible and also doesn't special
case the logic of OP_CAT.
It would also increase performance. SHA256(tag||subnode2||subnode3)
requires 2 compression function calls whereas
SHA256(1||SHA256(subnode2||subnode3)) requires 2+1=3 compression
function calls (due to padding).
I agree that tagged SHA256 as an op code that would certainty be
useful, but OP_CAT provides far more utility and is a simpler change.
