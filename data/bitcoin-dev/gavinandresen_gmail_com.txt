
@_date: 2011-08-05 10:07:46
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Double spend detection to speed up 
Couple of semi-random thoughts:
RE: detecting double spends:  I agree that extending the protocol to make
double-spend detection better is probably a bad idea.
That said, I could see extending the information reported by the
listtransactions/gettransaction API calls to report detected double spends (
== transaction uses the same inputs as another transaction in the block
chain or memory pool). IIRC, now the code just drops double spends, so if
this was done the implementation would have to be careful about being
vulnerable to a "fill memory with bogus transactions" attack.
RE: badly-behaved nodes:  I'd really like somebody to start experimenting
with algorithms for detecting well-behaved and ill-behaved nodes-- maybe
starting with a dns-seed implementation.  I suspect people are starting to
experiment with various types of Sybil attacks, which might explain why
network connectivity has been so bad.
(sent from the Sydney airport, before a very LOOONG flight back to

@_date: 2011-08-05 11:16:36
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Blitcoin? (Black Hat 2011) 
Dan gave a brief explanation of "blitcoin" on the forums:
  "As reported, I've got a BitCoin deanonymization mechanism.  It's not
Connect to every node in the cloud, discoverable via sweeping/IRC/get_peers
messages.  The first IP to consistently relay transactions for a given
identity, is the given identity.
Of course the entire BitCoin cloud doesn't allow inbound connections
(although you can do rather evil stuff with UPNP to force that open too).
But this isn't a problem -- there's only about 3000 to 8000 IPs that are
BitCoin nodes that accept inbound connections.  Since everyone else depends
on them, you just need to create your own mass cluster of IPs that are a
decent chunk of the P2P network.  Nodes on average have seven outbound
connections, so it should take only a few hundred unique to be one of the
first-hop peers even for the outbound-only set."
... so it is a de-anonymize-via IP address not de-anonymize-via Bitcoin
address.  And might go partway to explaining why we're having trouble with
network connectivity...

@_date: 2011-08-10 12:29:50
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Roadmap/schedules 
I've been wading through the pull requests and bug lists to figure out
a roadmap for the next few months.
Here are the things on my priority list:
1. Where are we at with network health? What metrics should we be
using? Is there work to be done?
And meta-issue:  can somebody volunteer to be the Bitcoin Network
Health Inspector to keep track of this?
2. We've got a chronic problem with new code causing CRITICAL_SECTION
deadlocks (see issue  for the latest). Detecting potential
deadlocks early should be done; longer term I think re-architecting to
be single-threaded/asio is probably the right thing to do.
3. Wallet security.  I'd like to get Matt's wallet encryption shipped
soon, along with all or part of groffer's Multisign patch ( --
since that will enable the creation of trojan-resistant secure wallet
4. Bug fixing.  44 bugs in the issue list, some of which I think are
already fixed. Anybody else want to volunteer to be BugKeeper?  (job
would be: prioritize/assign bugs, make sure they get closed when
they're fixed).
5. Testing. I don't have time to personally test every PULL request,
but if a pull involves more than trivial code changes I'm not going to
pull it unless it has been thoroughly tested.  We had a very good rule
at a company I used to work for-- programmers were NOT allowed to be
the only ones to test their own code. Help finding money and/or people
for a dedicated "core bitcoin quality assurance team" is welcome.
More unit tests and automated testing is also certainly welcome.
If this was open source blogging software I'd be much less uptight
about testing and code review and bugs. But it's not, it is software
for handling money.
Stuff I'd like to see in the release-after-next:
fClient mode (download headers only, for faster initial startup; I've
started the work, talk to me if you want to take over)
Sipa's wallet and key export/import
Move from wxWidgets to qt for the GUI
Un-hardcode fee handling (anybody already working on this?)
And research-y features I'd like to see happen soon:
"Impolite peer" detection/reaction to prevent various DOS/Sybil attacks
Better detection/reaction to double spend attempts or block-chain splits
Code for mining pool participants that helps keep mining pool operators honest
Everything else I consider lower priority. But if it is important to
you, is important to other people (and non-controversial), you
thoroughly test it, and there's zero chance it introduces a security
vulnerability... then I'll have no objections to pulling it.
Did I miss anything important? I'll create a Roadmap page on the
bitcoin wiki if there is general consensus about priorities.

@_date: 2011-08-10 12:49:21
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Change to multiple executables? 
RE: splitting off the "send commands to a running bitcoin" :
I'm mildly against it. It would be less confusing for newbies, at the
cost of forcing everybody who has already written backup scripts or
other interact-with-running-bitcoin tools to tweak their code. The
coding will be easy, but do you really want to spend the time to
answer all the "I installed Bitcoin X.Y and now my backup script
doesn't work" questions and modify the wiki pages and ...
I'd rather that time be spent working on any remaining build issues so
we can switch to bitcoin-qt.  I don't care if it is autotools or qmake
or QT creator, I just care that it works on Windows and Linux under
gitian and has clear instructions so I can build it on my Mac.

@_date: 2011-08-10 14:41:51
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Change to multiple executables? 
Well, to be honest I don't think more developers adding new features
are needed right now-- I think the project's critical needs are more
people testing and helping to fix bugs and scalability issues.
In this particular case, I said I was mildly against it-- if you want
me to switch to supporting it, then reassure me you're willing to do
ALL the work to make it happen.  Send me a list of wiki pages you'll
edit to document the change and tell me that you'll be around to help
people rewrite their backup scripts.
I don't see how dividing efforts between a 'bug fix' and 'development'
branch will help fix the project's critical needs. If we did, I think
there would be less pressure to help with the boring bug-fixing and
testing of the bug-fix branch, which I think would be bad.

@_date: 2011-08-17 10:53:43
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] DEBUG_LOCKORDER : early detection of 
Commit 865ed8a adds a new compile-time  : DEBUG_LOCKORDER
Compile with -DDEBUG_LOCKORDER and every time a lock is acquired by a
CCriticalSection a check is made to record the order of locks and
complain if they are being acquired in an inconsistent order.  Here's
what you get in debug.log when potential deadlocks are detected:
POTENTIAL DEADLOCK DETECTED
Previous lock order was:
 pwallet->cs_mapWallet  db.cpp:686
 pwallet->cs_KeyStore  db.cpp:687
 cs_KeyStore  keystore.cpp:74
 cs_vMasterKey  keystore.cpp:75
 cs_KeyStore  keystore.cpp:31
Current lock order is:
 pwallet->cs_mapWallet  db.cpp:686
 pwallet->cs_KeyStore  db.cpp:687
 cs_KeyStore  keystore.cpp:74
 cs_vMasterKey  keystore.cpp:75
POTENTIAL DEADLOCK DETECTED
Previous lock order was:
 pnode->cs_vRecv  net.cpp:1525
 cs_main  main.cpp:2372
 cs_vSend  net.h:681
Current lock order is:
 pnode->cs_vSend  net.cpp:1531
 cs_main  main.cpp:2411
I'll be working on figuring out how to eliminate these, and will be
working on some RPC stress-tests that try to exercise all the code
paths to early-detect other potential problems.

@_date: 2011-08-18 10:00:01
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] From the forums: one-confirmation attack 
vector76 on the Forums posted this interesting variation on a 'Finney attack' :
  "Let's say I observe the timing of when nodes are broadcasting
transactions and how they are propagating through the network.  By
watching for which nodes are earliest to broadcast transactions from
my target, I manage to establish a direct connection to my target.
I use a similar method of watching block broadcasts to establish
connections to most of the mining pools.
Now I create a transaction making a valid, large deposit into my
target.  I do not broadcast this transaction but I add it to a block
that I am attempting to mine.  I mine solo, just like normal, except
that I have an extra non-broadcasted tx that I am including.
Eventually, I succeed in creating a valid block.  I do not broadcast
it immediately, but instead I wait until someone else mines a block,
and when that happens, I immediately broadcast my block to my target.
If my target sees my block before the other block, they will accept
it, and my transaction will have one confirmation.  The block chain
has forked, and my target (and possibly other nodes, if my target
relays quickly enough) will believe that my block is the correct one,
while other nodes will believe that the other fork is the correct one.
I immediately request a withdrawal, and my target generates a
transaction sending the large amount of coins to an address I control.
 I also double-spend some of the inputs, sending the coins to myself.
The part of the network that did not receive my block first (which
hopefully is most of the miners) will accept this as valid and work to
include it in the next block.
If my block eventually "wins" because enough miners saw my block first
and added onto it first, then I have just made a deposit and
withdrawal, and I lose nothing.
If my block eventually "loses", then the deposit is invalidated.  If
the deposit tx was not one of the inputs to the withdrawal
transaction, then the withdrawal is still valid."
The lessons are "don't accept 1-confirmation transactions" and  "try
to be well-connected."
But maybe the deeper lesson is "don't trust information you get from
only one peer." Or maybe "watch for peers that are trying to fool

@_date: 2011-08-18 12:16:31
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] From the forums: one-confirmation attack 
Or maybe report them as 'suspicious.'  Changing the meaning of
'confirmations' is likely to break code (e.g. code like block =
current_blockchain[blockcount-tx.confirmations] ... would give the
wrong block).
A floating-point 0.0-1.0 'confidence' measure might be a good idea to
go along with the integer confirmations. I can think of all sorts of
ways of gauging the reliability of transactions or blocks (did it come
from a trusted peer-- assuming we eventually have trusted peers.  Does
it have a lot of confirmations?  Are there no active block chain
forks?  Have we been getting new blocks at the rate we expect?  etc
etc etc)
We could start with an as simple-as-possible "confidence == 0 if
confirmations < 2, otherwise confidence = function(
and improve it from there.

@_date: 2011-08-18 13:36:05
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] From the forums: one-confirmation attack 
Gregory said: "...if this causes people to wait less than the 6 blocks
that the software currently waits for before leaving unconfirmed
status then that would be sad."
People are already considering transactions 'confirmed enough' at less
than six blocks. I'm guilty, too-- 3 is/was the magic number for
And people are already experimenting with ways of safely accepting
0-confirmation transactions, like InstaWallet's "green" payments (sent
from a trusted-not-to-double-spend address).
Since there is definitely market demand for "as fast as possible"
confirmation, I'm thinking adding a placeholder to the RPC interface
might be a good idea.  Although after thinking about it some more,
maybe a signed integer "trust" rating for blocks/transactions would be
a better way of doing it...
RE: miners connecting themselves together in a semi-trusted "bitcoin
backbone"  :  agreed.
Matt submitted a patch to connect and stay-connected to a set of
nodes, but I complained about the implementation.  Seems to me the
networking code needs an overhaul, to implement a priority queue of
potential peers (trusted peers would be sorted to near the top of the
queue, peers you think are badly-behaved would be sorted to the
bottom, with lots of randomness so not everybody on the network is
trying to connect to the same set of peers). With peer rotation to
mitigate manipulate-time and other Sybil attacks.

@_date: 2011-08-24 11:12:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] New standard transaction types: time to 
It seems to me the fastest path to very secure, very-hard-to-lose
bitcoin wallets is multi-signature transactions.
To organize this discussion: first, does everybody agree?
ByteCoin pointed to a research paper that gives a scheme for splitting
a private key between two people, neither of which every knows the
full key, but, together, both can DSA-sign transactions.  That's very
cool, but it involves high-end cutting-edge crypto like zero-knowledge
proofs that I know very little about (are implementations available?
are they patented?  have they been thoroughly vetted/tested?  etc).
So I'm assuming that is NOT the fastest way to solving the problem.
If anybody has some open-source, patent-free, thoroughly-tested code
that already does DSA-key-splitting, speak up please.
I've been trying to get consensus on low-level 'standard' transactions
for transactions that must be signed by 2 or 3 keys; current draft
proposal is here:
 and discussion on the forums here:
 ... and there is a pull request that is relevant here:
 I still think it is a good idea to enable a set of new 'standard'
multisignature transactions, so they get relayed and included into
blocks.  I don't want to let "the perfect become the enemy of the
good" -- does anybody disagree?
The arguments against are that if the proposed standard transactions
are accepted, then the next step is to define a new kind of bitcoin
address that lets coins be deposited into a multisignature-protected
And those new as-yet-undefined bitcoin addresses will have to be 2 or
3 times as big as current bitcoin addresses, and will be incompatible
with old clients.
So, if we are going to have new releases that are incompatible with
old clients why not do things right in the first place, implement or
enable opcodes so the new bitcoin addresses can be small, and schedule
a block chain split for N months from now.
My biggest worry is we'll say "Sure, it'll only take a couple days to
agree on how to do it right" and six months from now there is still no
consensus on exactly which digest function should be used, or whether
or not there should be a new opcode for arbitrary boolean expressions
involving keypairs.  And people's wallets continue to get lost or

@_date: 2011-08-24 13:57:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] New standard transaction types: time to 
This discussion is convincing me that scheduling a blockchain split is
definitely the wrong idea at this time.  We can revisit in N months,
when we've got a roadmap and nice unit tests and a bunch of
well-tested patches for fixing all of the things that aught to be
fixed when we DO decide a blockchain split is necessary.
There seems to be rough consensus that new, imperfect standard
transactions are a good-enough short term solution.

@_date: 2011-08-25 13:18:24
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] New standard transaction types: time to 
I should have been more clear in my initial email and in the
proposal-- I am not proposing anything more than just agreeing on the
very lowest-level infrastructure, so there is a solid foundation upon
which we can build a couple of key very-high-priority features.
I wanted to talk about it now so there is rough consensus on what to
put on the road map, and to get as many smart brains looking at the
proposal and making it as good as possible.  Current proposal is at:
  I have two issues with it:
1) groffer reports that there's a bug in CHECKMULTISIG (pops too many
arguments off the stack), so perhaps we should avoid using it at all.
Fixing the bug would change its behavior, and is not an option because
that would cause a blockchain split. We absolutely need unit tests and
better documentation for how CHECKMULTISIG behaves (perhaps it is
working as intended, and Satoshi just messed up the description of
what it does in the comment).
2) How often will the 1-of-3 and 3-of-3 cases be used? I included them
just for completeness, but perhaps they should be dropped for now so
there is less code to write and test.  I just don't imagine there are
many cases where you have exactly three parties and 1-of-3 or 3-of-3
are required to spend.

@_date: 2011-08-26 15:44:59
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] New standard transaction types: time to 
That seems like the right way forward.
I just wrote a unit test and stepped through the CHECKMULTISIG code to
see exactly what the bug is, and the offending line is:
   797	                    int isig = ++i;
   798	                    i += nSigsCount;
It should be just   int isig = i;
The result is CHECKMULTISIG expects one extra item on the stack, so
the workaround would be a standard transaction type of the form:
scriptSig: OP_0 sig1...m
scriptPubKey: m pubkey1...n  n OP_CHECKMULTISIG

@_date: 2011-08-29 16:10:01
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Project status 
Quick brain dump on a bunch of stuff:
I'd like to get a 0.4 release out, but am still working on a fix for
the deadlock bugs that the new wallet encryption and/or the CWallet
refactoring caused. My short-term plan is to reduce the number of
locks and make sure they're always acquired in a consistent order.
Longer term, I think reworking the design to be based on
boost::asio and use fewer threads is probably the right thing to do.
Other things on the 0.4 TODO list:  block chain checkpoint (got a PULL
for that, thanks).  Updated list of hard-coded seed nodes (nanotube
did that last time). Pieter's dump/import privkey patch.
After my talk at the conference, Alex Waters approached me about being
the core bitcoin Q/A lead; he'll be working on creating test plans,
keeping on top of the issues list, testing new features, and
suggesting improvements to the code/test/release process.  And
whatever else he thinks needs to be done to improve core bitcoin.
I'll be rewriting the m-of-n signature "standard transaction" proposal
to mitigate a potential denial-of-service attack that I realized it
would open up (details later, I don't want to give bad guys ideas).

@_date: 2011-12-13 08:06:15
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: [BIP 15] Aliases 
I agree with Mike Hearn and Christian Decker-- paying to
'somebody at foo.com' should become, behind the scenes, a HTTPS query to
 If you just want to (say) donate to
eff.org, then paying to ' aught to work nicely.
And if namecoin ever takes off you'll pay to 'somebody at foo.bit'.
It seems to me that if it was DNS-based, the address should be
something like 'somebody.bitcoin.foo.com'. But I think it is unlikely
people will setup and run a custom DNS server just to support bitcoin

@_date: 2011-12-13 11:48:31
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: [BIP 15] Aliases 
RE: IIBAN numbers:
Nifty!  Thanks for the pointers, I think we should avoid reinventing
wheels whenever possible.
When composing my last response in this thread I wrote, and then erased:
"There doesn't have to be one solution: I'd like to see some
experimentation, with clients supporting different schemes for bitcoin
address aliases, and maybe supporting plugins to extend the schemes
supported (a plugin would take a string, do some
behind-the-scenes-magic, and return a bitcoin address or public key)."
Defining Bitcoin as an IIBAN "institution", with 36^6 "accounts",
seems like a forward-thinking idea, although I'm not clear on exactly
how those 2.2billion "accounts" would get allocated and mapped into
bitcoin addresses.
I imagine some central organization that maps IIBAN account numbers to
domain names... and then clients (or plugins in the clients) query
that trusted central organization and then the account holder's domain
to get a (possibly unique) public key or bitcoin address.
As long as IIBANs are not the ONLY way of aliasing bitcoin addresses
to more-human-friendly strings I think that would be a fine way to do

@_date: 2011-12-16 14:06:52
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: [BIP 15] Aliases 
First: everybody please try to focus on the issues/ideas, and try to
avoid this becoming a flame war.
Second: I think Walter Stanish made several good points that may have
been missed in all the long posts and discussion, the main one being:
The banking industry has been dealing with many of these issues for
years; I think we should not dismiss their experience.
I think there is also a huge public relations benefit to using a
standard like IIBAN instead of inventing our own. Having a Bitcoin
Payment Routing Address (or whatever it ends up being called) that
looks like the number issues by big financial institutions will give
people the warm fuzzies.
I don't really care what happens behind the scenes, as long as it is
as secure as an HTTPS connection (RE: CA pwnage:  there's no such
thing as perfect security, and until a more secure solution comes
along HTTPS is the best we've got).
And I'll reiterate that there doesn't have to be just one solution.
My only concern is that IIBAN is Yet Another Fledgling Standard, and
those little details that remain to be worked out could take years to
actually work out.

@_date: 2011-12-17 14:06:56
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Protocol extensions 
There was a discussion about using DHT's for transactions a while back
on the forums:
If you can figure out a scheme that is secure from malicious Sybil
attacks then you're smarter than I am.
And additional protocol messages for lightweight clients is a good
idea, as long as they don't make it a lot easier to pull off a
denial-of-service attacks on a "full" node.
Although I do also wonder if we'll ever run into a problem with full
nodes refusing to answer requests from lightweight nodes (there might
be a tragedy-of-the-commons problem lurking there).
Gavin Andresen

@_date: 2011-12-20 15:49:16
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Changes for version 0.6 are being pulled into 
FYI for anybody who doesn't hang out in IRC:
I've been busy pulling patches into git HEAD for a Bitcoin version
0.6, with the goal of having a Release Candidate 1 out in a couple of
So if you've done all your Christmas shopping and have time to help
test, code review, etc. now would be the time.

@_date: 2011-12-25 11:05:42
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] IMPORTANT: if you are running latest git HEAD 
Reposted from the forums:
makomk reported a remote vulnerability that I pulled into the master
bitcoin/bitcoin tree on December 20. If you are running git-HEAD code
on the production network you should pull the latest code to get the
bug fixed.
This affects only anybody who has pulled and compiled their own
bitcoind/bitcoin-qt from the source tree in the last 5 days.
Gory details:
I made a mistake.  I refactored the ConnectInputs() function into two
pieces (FetchInputs() and ConnectInputs()), and should have duplicated
a check in ConnectInputs for an out-of-range
previous-transaction-output in the FetchInputs() method.  The result
was a new method I wrote to help prevent a possible OP_EVAL-related
denial-of-service attack (AreInputsStandard()) could crash with an
out-of-bounds memory access if given an invalid transaction.
The bug-fix puts a check in FetchInputs and an assertion in
AreInputsStandard. This does not affect the back-ported "mining only"
code I wrote that some miners and pools have started using.
The good news is this was found and reported before binaries with the
vulnerability were released; the bad news is this was not found before
the code was pulled and could have made it into the next release if
makomk had not been testing some unrelated code.
Before releasing 0.6, I would like to have an "intelligent,
bitcoin-specific fuzzing tool" that automatically finds this type of
bug that we can run before every release. If anybody already has one,
please speak up!

@_date: 2011-12-29 11:23:56
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Alternative to OP_EVAL 
First, thanks very much to Russell for looking more closely at both
BIP 12 and the patch than anybody else-- he's found two bugs and two
things the BIP isn't clear enough on (so far).
And I've got to say, I'm very sympathetic to the "OP_EVAL starts down
the code-as-data path, and There Be Dragons" argument.
I don't think the proposed alternative would be, in practice, any
better.  I see two main disadvantages over OP_EVAL:
  about 20-bytes larger
  it means going back to where we were two months ago, writing more
code, reviewing it, finding bugs in it, backporting it so miners
running old software can support it, etc.
... and some other minor disadvantages:
  'standard' scripts will need to be slightly different in the
scriptSig and the scriptPubKey
   (e.g.  CHECKSIG  becomes   CHECKSIGVERIFY
with OP_CODEHASH)
  OP_EVALs are not executed, and so the code associated with them does
not have to be part of the transaction, if they are in the
non-executed branch of an OP_IF. That could be good for privacy, and
could be good for reducing block-chain size.
In discussions in IRC yesterday, we talked a little about possible
changes to the OP_EVAL BIP to make it less subject to abuse. In
particular, the big can of worms is allowing arithmetic or bit
operations on the serialized script that will be EVAL'ed:
    OP_ADD OP_EVAL  <-- Look! Dragons!
If  is more than 4 bytes, that is actually illegal
right now (all of the arithmetic operations are limited to operating
on numbers that are 4 bytes of less, and I believe we could prove that
no series of operations will ever produce a value more than 5 bytes
big given the current limitations).
Which leads me to suggest that BIP 12 be amended to state that:
  OP_EVAL shall cause script validation to fail if the top item on the
stack is less than 8 bytes long.
I'm tempted to propose a rule:
  OP_EVAL shall fail if the top item on the stack is the result of any
... but I don't think the extra code it would take to implement that
(keep track of which items on the stack were the results of
OP_ADD/etc) is worth it.
On the "you can't tell how many CHECKSIG operations will be performed
before executing the script" issue:
That is already true, because the parameters to CHECKMULTISIG that
determine how many signatures it checks might be computed.
Finally, I would echo theymos' observation that I think we'll
eventually do something very much like OP_EVAL in the future-- maybe
to support (in a backwards-compatible way) a
quantum-computing-resistant signature algorithm or SHA3. When that is
done, I think it might make sense to do a bottom-up redesign of Script
based on what we've learned.

@_date: 2011-12-29 13:00:23
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Alternative to OP_EVAL 
RE: preventing OP_EVAL from executing the result of calculations:
Good point, the rule should be "OP_EVAL shall fail if asked to execute
8 or fewer bytes."
RE: this minor disadvantage:
It is the "Either This or That can redeem" case that motivated me to
allow 2-deep EVAL recursion.
Start with the most straightforward code for doing "this or that" (in
scriptSig:     IF  EQUALS hash of This or hash of That:
    EVAL
  ELSE
    fail validation
  ENDIF
That can be done with CODESEPARATOR/CODEHASH.
But if you want to then bundle that up so the scriptPubKey is a
standard 'pay to script', you get:
scriptSig:   scriptPubKey:  ... standard DUP HASH160 <> EQUALVERIFY EVAL
To be backwards compatible with old clients the scriptSig would have to be:
   CODESEPARATOR this_or_that_code
 CODEHASH
 CODESEPARATOR
 IF  does not equal hash2:
   fail verification
 ENDIF
That could only be done if the definition of CODEHASH was modified to
hash only the stuff between CODESEPARATORS instead of hashing from
CODESEPARATOR to the end of the scriptSig.
RE: static analysis:
The vast majority of miners are "discouraging" (not relaying or
putting into blocks) anything besides 'standard' transaction types.
Until somebody smarter than me (like Russell) has done a deep analysis
of Script and all of its opcodes, I don't think that should change.
The standard transaction types are easy to reason about, and the
standard types extended with OP_EVAL are also easy to reason about--
you can template-match them to find out how many ECDSA operations a
CHECKMULTISIG will do, etc.
Again, in practice, I don't think EVAL as proposed is a danger.
RE: delaying EVAL rollout:  I could live with rolling out just BIP 11
(up-to-3-signature-CHECKMULTISIG as 'standard' transactions) and
delaying EVAL rollout on the main network, but I worry that will just
encourage people to delay thoroughly reviewing/testing for a couple of
months, and we'll be right back here at the beginning of March.

@_date: 2011-07-01 08:31:29
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.3.24 
dnsseed on, block send, segfault bugfix:  Agreed.
upnp: I think should be enabled on Windows/Mac, but remain
off-by-default on Linux.
I think adding another block-chain checkpoint is a good idea, too.

@_date: 2011-07-01 11:06:56
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.3.24 
OK.  I mis-remembered the poll:
   On by default	                       8 (20%)
Off by default	                       22 (55%)
On by default in the GUI, off by default in bitcoind	 10 (25%)

@_date: 2011-07-01 22:05:01
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.3.24 
I think we should move forwards, not sideways-- git tip + whatever we
need to fix bugs in current tip is my preference.
RE: upnp:  I say pull Matt's patch (bitcoin=upnp, bitcoind=!upnp).

@_date: 2011-07-04 14:23:53
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Encrypted Wallet Backward Compatibility 
RE: "You have some unencrypted keys, should I encrypt them for you?"
That re-opens an "attacker packs the keypool with keypairs that they
know about" (if I can read/write wallet.dat, then I can delete
encrypted keypool keys and insert a bunch of unencrypted keypool keys
that I know how to spend, and rely on the user to click "OK" because
users are trained to just click "OK").
RE: breaking backup scripts:  if they use the backupwallet  RPC
command, then they will Just Work.
0.4 and later could, on wallet encryption, create a wallet_e.dat
(encrypted wallet).  Then truncate wallet.dat and set its
file-permissions to 000, so if old versions of bitcoin OR any dumb
wallet backup scripts try to read it they fail.
RE: future-proofing: wallet.dat contains nFileVersion (version of
bitcoin that last wrote the wallet).  Adding a nMinVersion that
specifies "you must be at least THIS version to read this file" seems
like a good idea so if you have version 0.4 or later future wallet
upgrades give you a reasonable message if you try to downgrade after
an incompatible change.

@_date: 2011-07-04 22:26:17
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Encrypted Wallet Backward Compatibility 
I don't think 0.3.24 "needs" either of those pulls.  Fixing
downgrade-to-0.3.24 is low on the priority list, because
downgrade-to-something-before-0.3.24 is just about as likely, and that
has to do something mostly reasonable.
I just pulled  "Do not use
comma as thousands separator", and pulled a block-chain lock-in at
block 13444.  Those were the only issues I think really need to be in

@_date: 2011-07-12 13:31:07
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] overall bitcoin client code quality 
It is SO tempting to start over from scratch, isn't it?
We'll just tell everybody to stop using bitcoin so much for six months
or so while we implement a much better client.  It will be exactly
like the bitcoin we have now, except with a much nicer internal
architecture and much cleaner code-base, and we're pretty sure we can
get it done in six months if everything goes exactly as planned.
I think incremental improvement of the "devil we know" is the right
thing to do right now, although I'm going to spend more time thinking
about how to make sure different bitcoin implementations work well
together (I've started working on network-protocol-level testing).
Regarding Michael's specific suggestions:  the
lots-of-threads-and-mutexes architecture of the client bothers me
because it is too easy to change code and create a deadlock that is
very hard to debug and fix. Switching to asynchronous IO might be the
right thing to do.  Then again, it might be easier to modify the
CRITICAL_SECTION code to detect and report deadlocks (anybody have
experience doing that?).

@_date: 2011-07-17 13:02:51
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [RFC] listtransactions reformatting 
Fixing listtransactions (and listreceivedby/etc) so coin generation
transactions to particular addresses/accounts are credited to that
address/account is a good idea.
I don't think changing listtransactions output would be on the
priority list for any web services operators (in fact, I think most
would scream bloody murder if the output changed in a way that forced
them to change their code). The accounts-related things that I think
ARE on their high-priority list are:
1) Fixing getbalance and listtransactions performance problems when
you have hundreds of thousands of transactions and thousands of
2) push-notification of coins received to accounts, so they don't have
to poll for changes.

@_date: 2011-07-27 11:31:14
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Seeking advice: Encouraging bug-fixing over 
Anybody have advice on how to encourage more bug-fixing and testing of
existing functionality instead of yet-more-features?
When I get back home from here in Australia I plan on trying to
lead-by-example by starting to tackle the huge backlog of reported bugs, but
I'd like to know if anybody has seen other open source projects successfully
get people to fix bugs instead of constantly adding features. Would policies
like "that spiffy new feature you want won't be considered until you've
helped close some open bugs" be effective (or would it just encourage people
to create shill accounts to open trivial-to-fix issues)?
If this was your run-of-the-mill open source project I would be much
more lackadaisical about letting in new features... but when people lose
money because bugs slip through (and several people HAVE recently lost money
because of bugs slipping through) we obviously have a pretty big problem
just making sure that the features we have now work properly.
(Thanks VERY much to those of you have HAVE been helping test and have been
submitting bug fixes; I don't mean to imply that everybody has been
feature-happy, just that it seems like a lot of potential bitcoin
contributors start out by submitting a nifty new feature that sure would be
nice to have if we weren't so busy trying to make sure the features we
already have work properly all the time).

@_date: 2011-07-28 08:45:37
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Seeking advice: Encouraging bug-fixing 
RE: bounties:
"A couple of bitcoins to fix a bug" sounds to me like nothing but trouble
for whoever is in charge of awarding the bounties, but maybe I'm just
anti-bounty because spending 2 or 3 hours and getting $30 worth of bitcoins
for fixing a bug wouldn't motivate me.
Anybody know how cash bounties have worked for other projects?  Have any
others paid bounties on run-of-the-mill bugs, and did that cause any
problems?  I'm worried that if contributors start getting bounties that will
change the dynamic from cooperative to competitive.  For example, if
somebody has figured out how to solve 90% of some tricky bug I don't want
them to hesitate to ask for help on the last 10% because they're worried "if
I describe the progress I've made so far somebody might swoop in and steal
my bounty...."
RE: road-map and bug-fix-only-releases:  Great ideas.
RE: paid full-time project lead:  I arranged to get paid to work on bitcoin
full-time before I left for Australia; more details when I get back

@_date: 2011-07-29 08:41:12
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Forking personal "vanity" versions... 
Matt:  First I agree with you.  Second: your should have sent your message
directly to Alan instead of to the entire bitcoin-development list.
All: The idea is for this mailing list to be CONSTRUCTIVE discussion of
bitcoin development.  Please ask yourself "will my message help move the
bitcoin project forward or will it just make somebody angry" before posting.
 And assume that at least someone on the list just broke up with their
girlfriend and is in a crappy mood.

@_date: 2011-06-13 14:41:35
@_author: Gavin 
@_subject: [Bitcoin-development] Bootstrapping via BitTorrent trackers 
Adding that code to bitcoin in a contrib/dns folder seems like a good idea.  I'd be happy to run a dns seed.

@_date: 2011-06-16 12:32:57
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Development priorities 
Right!  I'm back from the CIA, and trying to ignore all the reporters
who want to talk with me.
I want to do a quick brain dump on what I think the short-term
development priorities are.  Here's my list:
1) Scaling-up issues, like disconnections when downloading the block chain.
2) Wallet security.
3) Unit testing framework.  There was a PULL that had the start of
boost unit tests; I think that is a critical need, along with a good
suite of test cases.
Those are the big issues for me.  Anything that slows those down I'm
going to ignore (example: love the idea of escrow transactions, but I
do NOT want to add nifty new features when we're having trouble
keeping the features we're using now working properly).
Does everybody agree those are the critical priorities? (try not to
let this thread wander into a discussion of HOW to do stuff, just WHAT
the priorities aught to be)

@_date: 2011-06-17 12:27:22
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Roadmap for autotools / Qt gui merge 
I'm in favor of dropping the wxWidgets GUI and replacing it with a Qt
GUI. I think supporting more than one GUI for the reference client is
a bad idea.
Qt is LGPL, so license for that is not an issue.
John, you willing to release your code under the bitcoin MIT license?
Everybody else:  anybody object to replacing "the devil we know"
(wxWidgets) with Qt?

@_date: 2011-06-19 18:33:14
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin fun day! 
Some of us take private disclosures of vulnerabilities very seriously.
In any case, the ClearCoin CSRF vulnerability is fixed.  Thank you for
bringing it to my attention.

@_date: 2011-06-22 10:08:05
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [PULL] Add scriptPubKey enforced 
I think it is time to start experimenting with MULTISIG transactions on testnet.
Mike:  Did Satoshi ever tell you what he was thinking for the best way
to implement MULTISIG transactions?
I'm wondering if hard-coding new standard script templates in
script.cpp Solver():
 vTemplates.push_back(CScript() << OP_1 << OP_PUBKEY << OP_PUBKEY <<
OP_2 << OP_CHECKMULTISIGVERIFY);
 vTemplates.push_back(CScript() << OP_2 << OP_PUBKEY << OP_PUBKEY <<
OP_2 << OP_CHECKMULTISIGVERIFY);
 vTemplates.push_back(CScript() << OP_1 << OP_PUBKEY << OP_PUBKEY <<
OP_PUBKEY << OP_3 << OP_CHECKMULTISIGVERIFY);
 vTemplates.push_back(CScript() << OP_2 << OP_PUBKEY << OP_PUBKEY <<
OP_PUBKEY << OP_3 << OP_CHECKMULTISIGVERIFY);
 vTemplates.push_back(CScript() << OP_3 << OP_PUBKEY << OP_PUBKEY <<
OP_PUBKEY << OP_3 << OP_CHECKMULTISIGVERIFY);
... would be the right approach to support 1/2 of 2 and 1/2/3 of 3
signatures.  It'd be nice if there were generic
OP_N << OP_PUBKEY_N << OP_N  ... template matching opcodes, but there aren't.
I'm also wondering if it makes sense to just support 2-of-2 (for
validate-on-multiple-devices) and 2-of-3 (for escrow) for now.
I think all of these could use a new type of bitcoin payment address;
it might make sense for THAT to be generic, maybe containing:
 version byte
 m
 n
 hash of xor of all n public keys
 checksum
I'm most interested in the 2-of-2 case; I think merchants and
exchanges need bitcoin deposit/payment addresses that they can make
secure by requiring a 2-step signature process for spending those

@_date: 2011-06-22 11:32:49
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [PULL] Add scriptPubKey enforced 
You're right, it doesn't make sense.  The use case I would like to work is:
I setup an escrow that requires m of n signatures to release funds,
securely getting public keys from the other n-1 parties.
Now we all need to fund the escrow. Or maybe other people can fund the
escrow (it just takes m of n of us to decide when/how/where to spend
the funds).
It would be spiffy to publish a new type of bitcoin address that is an
"m of n address", that anybody could pay into, but would require m of
n signatures to spend.  Publishing a really really long address with
all n public keys would work.
It would be great if the "higher level protocol" for pay-to-escrow was
just get a bitcoin address via https (or other secure mechanism), like
we do now for pay-to-single-party.  Where the person you're paying has
their own mechanisms for generating or fetching/authenticating the
public keys, and knows which bitcoin addresses they've published.
All of which makes me wonder if the straightforward "n PUBKEYS m
CHECKMULTISIG" transaction type is the right thing to do.
Following the pattern of our standard DUP HASH160 etc. transaction
type, maybe 2 of 2 and 2 of three should be:
2DUP ADD HASH160 ...hash(pubkey1+2)... EQUALVERIFY 2 2 ROLL CHECKMULTISIGVERIFY
3DUP ADD  ADD HASH160 ...hash(pubkey1+2+3)... EQUALVERIFY 2 3 ROLL
Spending those transactions would mean putting the m signatures and
the n public keys in the TxIn, but sending funds you'd only need the
hash of the sum of the public keys.

@_date: 2011-06-27 22:08:57
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Test away 
I got Steve-from-the-Forum's boost unit test skeleton code compiling
and running, so there's now a src/test directory and you can 'make -f
makefile.unix test_bitcoin'
More tests are very welcome. I'd welcome higher-level tests (not just
code unit tests), too.
And speaking of testing:  if you know a good QA test manager type
person interested in bitcoin, I think we can wrangle up funding for
somebody to put together a team to help test bitcoin (and hopefully
pull requests). I think lack of testing resources for core bitocin is
a big weakness right now.

@_date: 2011-11-04 14:08:00
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Please help sanity test: Linux/Windows 
I tagged v0.5.0rc2 this morning (then Luke hit me upside the head and
I tagged it again because I messed up).
Gitian-built binaries are uploaded to:
  I sanity-tested the windows setup.exe in an XP virtual machine, it
installs and runs nicely. I'm about to run out; if somebody can sanity
test the windows .zip and the 32/64 bit Linux .tar.gz I'd much
appreciate it.
shasums for the uploads are:
  df994f18b6b715f6e0451b98b55ddd1946f2f353  bitcoin-0.5.0-win32-setup.exe
  bfbad8acae987467976d535e48653ac7e28c6c76  bitcoin-0.5.0rc2-linux.tar.gz
  fb2cfd2d8ad45269025a4604c679364a934796b4  bitcoin-0.5.0rc2-win32.zip
Mac builds will be delayed a bit; there are issues creating a standalone .app.
shasums of my v0.5.0rc2 gitian.zips:
  f1fa954d179c65d1043438b78fcde8237874b9e1  bitcoin-0.5.0rc2-linux-gitian.zip
  cec50f4b5d7222e475466143eb9e37aae026a582  bitcoin-0.5.0rc2-win32-gitian.zip

@_date: 2011-11-04 17:29:09
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Please help sanity test: Linux/Windows 
If you wonder where the bitcoin-0.5.0rc2-linux.tar.gz went...
I removed it because it is not sane (we need to teach the Qt build to
statically link dependencies).
Once the Mac and Linux deployment issues are fixed, expect a release
candidate 3...

@_date: 2011-11-09 14:13:54
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] multisig, 
As Alan said, that won't work-- it will not be relayed across the
network because it isn't a valid transaction until it has enough
Formats and protocols for gathering signatures are in the TODO
category-- Alan's BIP 10 is the next piece of the puzzle, maybe a
standardized http/https RESTful API, or HTTP/JSON, or protocol buffers
and raw sockets, or... something... solution (or solutions) built on
top of that makes sense.
I don't think partially-signed transactions belong on the main Bitcoin
P2P network, mostly because I don't see any way of preventing somebody
from endlessly spamming bogus, will-never-be-completed partial
transactions just to be annoying.

@_date: 2011-11-09 15:02:23
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] multisig, 
... of course I write that and then start thinking about ways you
COULD use the P2P network to distribute signatures, maybe by
broadcasting (and paying fees for) complete transactions that contain
extra signatures for the transaction that you want to sign.
Here's a half-baked idea that might be brilliant or stupid:
+ Start with an escrow transaction, with 3 public keys.  I own one of the keys.
+ I broadcast a 'fee-only' transaction that pays 0 bitcoins to the key
I own. But I add extra data to the scriptSig; something like:
scriptSig:     scriptPubKey: ...standard DUP HASH160  ...etc
nValue: 0
The other parties to the escrow transaction could monitor the
block-chain for transactions to my , and get the signature
and proposed "spend the funds in escrow" transaction from the
"But won't that gunk up the block chain with more data?"
Yup.  But the parties to the transaction will have to pay for the
extra data they're including.
And everything in the scriptSigs can, theoretically, be forgotten (or
never sent) to most nodes on the network once the transaction is spent
and is buried deep enough in the block chain.  (a nValue=0 transaction
can be considered 'immediately spent').
"Can you really put arbitrary stuff in the scriptSig?"
Yup.  The IsStandard() check today allows up to 200 bytes, which
wouldn't be enough for an extra signature and .
The standard   is about 150 bytes; part of the
multi-signature proposal will be increasing that to 500 bytes to
accomodate 3-signatures transactions.  A simple 1-input-1-output
 would be around 50 bytes or so.
"Wouldn't it be cheaper/better to NOT use the block chain to
distribute signatures?"
Yup. The only advantage I see is it might be more anonymous to use the
blockchain instead of directly connecting to, and finding out the IP
address of, the parties involved in the transaction.

@_date: 2011-11-09 16:18:04
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] multisig, 
One more thought on putting arbitrary stuff in the scriptSig:
Miners could decide to revolt and remove the extra scriptSig
information before including the transaction in their blocks. They'd
still get the full transaction fee, and the transaction would still
validate so the block would be accepted by everybody else.
Come to think of it, if a node relaying transactions wanted to save
bandwidth costs or be annoying, it could also strip off the extra
information before forwarding it, so this isn't a reliable
communication mechanism. It is probably a much better idea to use
another protocol to gather signatures.

@_date: 2011-11-17 09:28:27
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] There will be a release candidate 6... 
I got email from a tester who gave this feedback:
I agree that is likely to happen and, when it does, will be disastrous.
So I'll be reworking the wallet encrypt/rewrite code today and
creating a release candidate 6.
My previous attempt (encrypt, invalidating keypool, then unlock and write
a new keypool) resulted in unencrypted private keys in the new wallet.
I think this will work, I'll implement and test today.
Invalidate all the old keypool keys in the old wallet.Write new
keypool keys to the old wallet.Encrypt all the keys in the old
wallet.Rewrite the old wallet to create a new wallet.Shutdown/restart.
IF ANYBODY IS WILLING TO HELP:
There is still a mysterious problem with bdb throwing an exception
when dbenv.close(0) is called during shutdown. If you can compile
a -g version of bdb and then step through DbEnv::close in a debugger
and tell me why it is throwing an exception that would be
extremely helpful.

@_date: 2011-11-19 11:20:48
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Need help testing/debugging: Linux64 
There is one issue holding up a 0.5.0/0.4.1 final release:  I've seen
a couple of bug reports of crashes on startup when re-encrypting
previously encrypted wallets on Linux64 systems.
I've tried to reproduce on Ubuntu 10.10 server and "it worked for me"

@_date: 2011-11-21 20:06:27
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] State of Bitcoin Development: November Brain 
It has been a busy month; here's what I'm thinking about:
? It's great to get 0.5 out; congratulations to Wladimir for doing a
great job with the new GUI.
? The wallet encryption bug was embarrassing and stressful, and chewed
up a lot of my time over the past couple of weeks. Bugs happen, but
I've been spending time thinking about what I can do differently to
make it less likely major bugs slip into releases.
Finding the money to hire some professional QA people to help create
test plans and then execute them (the test plans, not the QA people)
is one possible answer. If you have experience finding funding for
open source projects (or know somebody who does) I'd like to talk with
you--  I would much rather spend my time writing code and thinking
about technical issues instead of trying to figure out if advertising
or sponsorship or a Donate menu entry in the client is a reasonable
way to get more testing resources for the project.
Last month I mentioned I was thinking about Organization; there is a
non-profit organization forming to handle Bitcoin PR and marketing,
which takes care of one big area of work.
? The BIP (Bitcoin Improvement Proposal) process seems to be working
well, with good proposals and good discussions (both here and on the
  Things I think are high priority but am not planning on working on:
? Implement BIP 14 (separate the protocol and client versions)
? Rework/rethink wallet handling:  I think we could do a much better
job with both encryption and backups.
? Work on higher-level multi-signature/multi-device transaction
approval; I really want a version of bitcoin-qt that requires me to
poke an "OK" button on my iPhone before it can send coins.
? Code clean-up; I'd like to see more small code refactors that moves
non-performance-critical code from .h files to .cpp files, makes
classes  more self-contained, etc. "Rename the world" or "change every
single file"  pull requests are hard to deal with because there is
never a good time  to pull them, but a steady stream of "makes the
code a little bit easier  to work with" would be a Good Thing.
Especially if you submit unit  tests for whatever you touch...
Thinks I think are high priority and AM planning on working on; if any
of them inspire you, feel free to steal them from me, I still have too
many things on my TODO list:
? Create a pull request for OP_EVAL/multisignature transactions
? Back-port OP_EVAL/multisig to 0.3/0.4 and release patches to  make
it easy for the big mining pools to support it, so the network  is
ready for multisig/multi-device transactions.
? Work on the 'headers-only' branch, so users have a better first-time
??I want to start doing some internal re-architecting, and I think
porting my old monitor transactions/blocks patch to use Boost.Signals
might be a good place to start.  The internal pieces are pretty
obvious (GUI, database, network, wallet, transaction validation, and
block-chain handling) and I think starting to rearchitect to use
Boost.Signals for internal communications would be a big step towards
more re-usable code.
? Get back to the cross-platform testing infrastructure tool, and lots
of good and  bad blockchains that can be used for cross-platform
I'm probably forgetting several things, but I think that's enough for
now. If you're going to the conference in Prague, have fun!  Please
figure out all the hard questions while you're there, and report
Previous Brain Dump:

@_date: 2011-11-23 10:09:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Addressing rapid changes in mining power 
On Wed, Nov 23, 2011 at 9:38 AM, Christian Decker
Seems to me that's the real problem with any "hardest block found in X
minutes" scheme.
If I get lucky and find a really extremely hard block then I have an
incentive to keep it secret and build a couple more blocks on top of
it, then announce them all at the same time.
If the rest of the network rejects my longer chain because I didn't
announce the extremely hard block in a timely fashion... then how
could the network ever recover from a real network split?  A network
split/rejoin will look exactly the same.
Bitcoin as-is doesn't have the "I got lucky and found an extremely
hard block" problem because the difficulty TARGET is used to compute
chain difficulty, not the actual hashes found.
PS: I proposed a different method for dealing with large hash power
drops for the testnet on the Forums yesterday, and am testing it

@_date: 2011-10-05 14:42:59
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Mac libboost_thread or thread-mt? 
I updated src/makefile.osx and doc/build-osx.txt  today, assuming that
the MacPorts versions of dependencies will be used and the -mt boost
libraries will be used.
I also modified makefile.unix and makefile.osx to auto-build
dependencies using gcc's  -MMD  option.

@_date: 2011-10-08 17:13:28
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Help wanted: translations 
Reposting here from the forums:
Good news: I'm just about to get a Bitcoin-Qt version 0.5 Release
Candidate 1 out, with a much-improved GUI.
Bad news: all the translations for the old wxWidgets Bitcoin are
obsolete, and the process for making translations is different.
Is anybody willing to write new translations?  Here's what you'll need to know:
Three translations already exist: de nl and ru.
Translations are stored in ".ts" files in the src/qt/locale folder
The 'QT Linguist' tool can be used to create translations
... or maybe an online tool like Transifex could/should be used to
crowd-source the work
And is anybody willing to take the job of coordinating translation
efforts, figuring out if Transifex is a good tool to use, and writing
some documentation to make it easy for people to create and submit new

@_date: 2011-10-10 12:32:41
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Please help test 0.5 release candidate 1 
Reposting from the forums:
  I just tagged the git tree "v0.5.0rc1". If you are able, please
compile and help test.
See the INSTALL file at the top of the source tree for instructions on
compiling. Binary releases for at least unix and mac should be
available in the next day or two (there is a show-stopper bug on
Windows, and we could use help from people familiar with
cross-compiling using mingw to update the Windows build process).
Major bugs you should be aware of:
Wallet does not relock on Win32
Major changes from version 0.4:
Switched from wxWidgets for the GUI to Qt, using Wladimir J. van der
Laan's bitcoin-qt. Why? We didn't have any wxWidgets programmers
contributing fixes or improvements.
New JSON-RPC commands:
getmemorypool : alternative to 'getwork' that provides everything
needed to construct a block with a custom generation transaction.
listsinceblock : Get all transactions in blocks since block [blockid]
signmessage/verifymessage : sign/verify a message with a wallet
public/private keypair
Deprecated JSON-RPC features:
'midstate' data item from getwork requests
Deprecated JSON-RPC commands that have been REMOVED:
Run: git shortlog --no-merges v0.4.0..
... to get a complete list of changes, and thanks to everybody who is

@_date: 2011-10-13 09:32:48
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] State of Bitcoin Development: October Brain 
In the spirit of open communication, I thought I'd try doing a monthly
"what's up" with bitcoin development. Here's what's on my radar:
? Wladimir agreed to help pull patches, especially Qt-GUI-related
patches, and is now part of the core dev team (Wladimir did the bulk
of the work on the new Qt-based GUI).
? Matt and Wladimir will be working on 0.5 release candidate 1
binaries and an updated release process to either ship the Qt
libraries or statically link against Qt; the goal is to have them
ready this weekend.
? Network stability and wallet security are still my top concerns;
start-up experience for new users (the long wait to download the block
chain) is next on my list.
? Amir's Bitcoin Improvement Process proposal hasn't been getting the
attention it deserves; I'm just as guilty as anybody, I suppose we're
all very busy. Helping improve it and writing some BIPs is high on my
priority list.
? I've setup a public-write-only
bitcoin-security at lists.sourceforge.net mailing list to be used as an
official way to report and then discuss potential security or
denial-of-service vulnerabilities in the bitcoin protocol, and invited
the following people to participate:  Amir Taaki, Mike Hearn, Stefan
Thomas, Nils Schneider, Pieter Wuille, Jeff Garzi and myself.
Stuff I've been working on or plan to be working on soon; let me know
if you are able to take on any of these, there are too many things on
my TODO list:
? Implementing/experimenting: multi-signature transactions and using
OP_EVAL and a new type of bitcoin address to create 'always secure' or
'always backed up' wallets.
? Write BIPs proposing:  OP_EVAL.  'standard' multi-signature
transactions. Maybe an informational BIP proposing how to roll out
upgrades in general.
? Denial-of-service detection/prevention (see the DoSorphans pull
request). It would be really nice if somebody with experience
simulating network behavior would take this over...
? Cross-platform testing infrastructure. I've made good progress on a
Twisted-based tool, but still have a lot to do.
? Tighten up block-time rules to fix the potential "timejacking" attack.
? Work on 'discouraging' blocks/transactions to punish
bad-for-the-common-good-but-good-for-me behaviors from miners or
? Get back to work on headers-only-for-initial-download, so initial
startup experience is better for people.
Ongoing longer-term:
??Rethink/rework transaction fees; give both miners and clients more
flexibility to create a market instead of magic hard-coded constants.
? Organization; many things would be much easier if there was a
non-profit organization like the Tor Project to pay core developers,
testers, a PR person, pay for the Jenkins nightly build server, etc
etc etc.

@_date: 2011-10-18 15:17:43
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP process 
Amir started the "get more formal about changes to bitcoin" ball
rolling by creating BIP 0001, starting from the Python "PEP" /
BitTorrent "BEP" processes:
  The idea is to use BIPs for changes that may or will affect every
bitcoin implementation (not to use them for proposed changes to one
particular implementation).
I'd like to propose some minor changes to the process:
? I propose that BIPs be wiki pages, with a social convention that the
Author gets final word if any editing wars break out.
? If he's willing, I propose that Amir take the role of BIP editor.
? I think bitcoin is still too small to have a specialized
"bitcoin-ideas" mailing list; I propose that new potential BIPs be
discussed either here or on the bitcoin-dev mailing list.
What do y'all think?

@_date: 2011-10-24 10:55:14
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Determine input addresses of a transaction 
Sure. There are lots of non-standard scriptPubKey scripts that will
validate if given   as input:  a simple OP_NOP would work
(do nothing, then check the top value on the stack and validate if it
is not zero-- and  is not zero).
If you assume the client has all previous transactions, then you could
get the transaction input's prevout (from the memory pool or disk) and
then ExtractAddress() from it. That is probably a bad idea for
listtransactions, since fetching all the previous inputs from disk
just so you can check to see if they're 'green' violates the "a
feature shouldn't cost anything if it is not being used" design
You know, just thinking out loud...
Green addresses could be implemented as a second signature in the
scriptSig.  You'd have to hack your bitcoin client, but you could
generate a transaction that had     ... as the
input instead of  .
The  will be ignored by old clients.  The transactions is
still considered 'standard'.  But you could teach bitcoin to look for
 signatures in wallet transactions...

@_date: 2011-10-25 09:21:30
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Detecting OP_EVAL scriptPubKeys that are 
You could do it that way...  but that would be inefficient.
You give the hash to whoever is paying you, and store the hash -->
script  mapping when you do that (assuming you're not using a
deterministic wallet; if you are, you probably just increment a
counter in the wallet).
The only use case I can think of where you'd want to check for every
possible hash is if you lose your wallet, you have a wallet backup
that has your private keys in it, but DOES NOT have the hash -->
script mapping(s).
For use cases involving other people, that's probably not a problem--
you could ask them to tell you what public keys are involved, and then
add them back in to the wallet (the RPC interface I settled on for
m-of-n txns is an "addmultisigaddress" that takes the "m" and an array
of "n" public keys, creates the script, adds the hash-->script mapping
to the wallet, and returns the hash).
For use cases where all the keys belong to you... either a good,
automatic, in-the-cloud-backup or the equivalent of "-rescan" is
needed to recover in case the mappings are lost.

@_date: 2011-10-26 11:00:48
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Detecting OP_EVAL scriptPubKeys that are 
Why? If somebody is sending me bitcoins, then they'll have to get
either an address or one or more public keys from me. OP_EVAL just
lets me give them a short address that represents an arbitrary number
of keys combined in an arbitrary way.
I agree with Gregory: it shouldn't matter if that address is
HASH(public key) or HASH(op_eval_script), the issues are the same (if
you lose or cannot re-create the key/script then you're in trouble).
Maybe I'm missing something; are you worried that blockexplorer won't
know that coins sent to HASH(op_eval_script) are actually a
complicated transaction until the coins are spent again?  I'd consider
that a feature, not a bug, because only the people involved in the
transaction need to know the details until after the transaction is
Feel free to contact me about your 'tiered implementation for thin
clients' -- I don't think OP_EVAL will make that significantly harder.
I also agree with Alan: using OP_EVAL is not mandatory, I'm proposing
that CHECKMULTISIG becomes a standard transaction type.

@_date: 2011-10-27 12:13:04
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Multisignature scriptSigs 
D'oh!  I forgot about that check (and should have remembered, I had to
increase it for my 'standard' multisig transactions branch).
Assuming BIPS 11 and 12 are adopted, there will be room in the
scriptSig for more than one signature. Once that happens, implementing
green addresses as an extra signature on the first scriptSig in a
transaction seems like a better way to do it than generating two
separate transactions.
Speaking of more-than-on-signature transactions:
I'm proposing a maximum 3 signatures for an IsStandard() transaction,
which would be a 600-byte scriptSig.
It is tempting to just bump the maximum up to 8 or 10, but I think we
should stay conservative about IsStandard() transaction size until
after two things happen:
1) bitcoin-qt gets smarter about downloading just block headers, and
maybe downloading transactions without scriptSigs (for transactions it
doesn't need/care to validate... need to think about that a little
more, but ByteCoin suggested that if you're not mining then the only
transaction signatures you need to check are not-yet-confirmed
transactions to you).
2) Transaction priority / maximum block size / free-transaction area /
transaction fees is reworked.  Miners should be making the policy
decisions on minimum fee per kilobyte or ECDSA signature check, and
how many free transactions (if any) they'll include in the blocks they
create.  And bitcoin clients should be smarter about looking at what
transactions are and are not getting into the chain so they can
suggest appropriate fees to users.

@_date: 2011-10-28 14:33:44
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.5 release updated 
Quick update on why there is no final 0.5 release out yet:
Short answer: because I'm really paranoid about bitcoin binary builds,
and the switch to Qt means a change in the way the builds are done.
Long answer:
Linux builds should be all set; the 'gitian' trusted build process works nicely.
Windows builds are being difficult; we need a gcc expert to help debug
the 'gitian' cross-compile (see
 ).
Unless somebody steps forward and says "I'll support compiling
bitcoin-qt/bitcoind with Visual Studio) I'm going to remove
src/makefile.vc and make sure the readmes say that only the mingw
toolchain is supported.
Mac builds were slightly broken for the 0.4 release (they don't run on
OSX 10.5-- you need 10.6 or greater). I'm "recompiling the world" to
hopefully fix that, and hope to have mac binaries available soon (let
me know if you can help test, especially if you have a 32-bit Intel
mac running 10.5).
On my wish list for builds (anybody want to volunteer?):
I think it'd be spiffy to have a .pro file to compile bitcoind;
maintaining N different makefiles is annoying and error-prone.

@_date: 2011-10-29 13:01:00
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Detecting OP_EVAL scriptPubKeys that are 
RE: buying me and Gregory a shared beer:
But that transaction won't show up in my bitcoin wallet as bitcoins I can spend.
And even if my wallet DID show me "transactions that involve your keys
but that you can't spend," all I would know is there are N bitcoins
that I can only spend if I can somehow figure out that Gregory has
public key XYZ.
How would I know that unless you told me?
I think the right long-term solution is moving away from bitcoin
addresses as 'pay-to entity' and create an infrastructure where we're
paying people or organizations. But in the short term, I think there
are lots of benefits to creating a new type of bitcoin address built
on top of OP_EVAL that will be very easy for all of our existing
infrastructure to support.

@_date: 2011-10-31 08:30:50
@_author: Gavin 
@_subject: [Bitcoin-development] Snowstorm 
============================== START ==============================
We've got no power, so it might be a day or two before I can help verify gitian builds or pull patches.
Sent from my iPhone

@_date: 2011-09-02 16:12:43
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Version 0.4 release candidate 1 
Bitcoin version 0.4 release candidate 1 is ready for initial testing;
please grab the source from github and try to break it.
The big, visible change is wallet private key encryption, which is NOT
turned on by default.
The big, invisible change is a reworking of internal critical section
mutexes to fix some chronic problems with bitcoind becoming
unresponsive due to deadlocks.
git shortlog --no-merges v0.3.24..
 ... will give you all the changes.
Thanks to everybody who contributed patches, and sorry if your
favorite patch is not included.

@_date: 2011-09-03 20:13:14
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.4rc1 known bugs 
Quick status update on 0.4; I probably won't have time to tackle these
properly before Tuesday:
+ sipa found what looks like a deadlock between the addr-handling and
IRC-join-handling code.
+ UukGoblin reports a deadlock problem on a bitcoind handling getwork requests.
If you want to get more familiar with the bitcoin code and you have a
lot of patience, tracking down deadlocks a great way to do it.
+ ArtForz found a performance bug with transactions that have
thousands of inputs and outputs on the solidcoin test network.
 (not as big an issue for bitcoin due to fees being based on
transaction size, but still worrying)

@_date: 2011-09-05 16:41:24
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Pull request: faster initial blockchain 
I'd appreciate review/feedback on this:
This change skips ECDSA signature verification for transactions during
the initial block-chain download, which makes downloading the block
chain much faster.
"Initial block chain download" is all blocks up to 120 blocks before
the last blockchain lock-in point.
Reasoning for why this is safe:
If an attacker tries to feed a client bad transactions during the
initial block-chain download (transactions with invalid signatures),
then they change the merkle tree, and at the first blockchain lock-in
the bad chain will be rejected.
Transactions are still checked for orphan blocks that come in during
initial block-chain-download (ConnectInputs will be called with
fBlock=FALSE) and for mined blocks (ConnectInputs called with

@_date: 2011-09-05 16:43:17
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Pull request: Optimize database writes for 
And I'd appreciate review/feedback on this:
  Patch from ArtForz, who discovered the problem.
The problem was chaining large transactions (transactions with lots of
ins and outs) would make the berkeley db transaction log get very big,
as the dependencies (TxIns) of a transaction might be re-written
multiple times.
With this fix, each each transaction referred to by TxIns is written once.

@_date: 2011-09-06 11:21:52
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Many-output transactions in the main chain 
Somebody has been inserting transactions with lots of outputs into the
main bitcoin block chain:
  Their next step will be creating transactions with thousands of inputs
from those transactions. The result will be lots of excessive disk
space usage.
The fix is this patch:
  Suggestions on the best way to let merchants, miners, and pools know
about the potential problem?
I hate to take time away from the 0.4 release to re-spin 0.3.24 with
the patch, but we may have to.

@_date: 2011-09-06 13:59:29
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.4rc1 known bugs 
Nice work, Detective Wuille!
Patch for the deadlock issue:
I took a different approach to fix from the one Pieter suggested,
performing the database operation after the cs_mapaddresses deadlock
is released.  Please review to check my logic, it did survive my
start/stop/restart... stress test.
And I did review every place in the code that starts a database
transaction, to look for similar issues, and they are all OK.
RE: improving DEBUG_LOCKORDER:  requires some thought.  Deadlocks are
still possible with TRY_CRITICAL_SECTION, if some codepaths TRY and
some don't.
On Tue, Sep 6, 2011 at 7:55 AM, Pieter Wuille

@_date: 2011-09-07 11:07:25
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.4rc1 known bugs 
Turned this into a pull request:
  I reviewed the code but have not tested.
Rough sketch of a test plan:
Run clean testnet-in-a-box bitcoind, with -keypool=1
Encrypt the wallet
Run bitcoind getnewaddress until it tell you keypool is exhausted
Generate a couple of blocks via internal miner -- verify: coinbase
transactions have unique txids even though they pay-to default key
Generate a couple of blocks via getwork RPC call -- verify: coinbase
transactions have unique txids

@_date: 2011-09-09 10:02:05
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.4 Release Candidate 2 
I just tagged the git tree:  v0.4.00rc2
Fixes from release candidate 1:
+ Optimize database writes for transactions with lots of inputs
+ Fix a deadlock that could occur when adding addresses from 'addr'
messages and irc
+ Fix a potential problem with duplicate, un-spendable coinbase
transactions if you were generating bitcoins, with a locked wallet,
and ran out of keypool keys.

@_date: 2011-09-11 13:12:27
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin-qt ready for merging 
I haven't heard any objections to pulling it as soon as 0.4 is
officially released, a pull request is ready, and a couple of people
have a chance to read over the differences and ACKnowledge that
nothing sinister snuck in somewhere.

@_date: 2011-09-13 10:43:27
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Project status 
0.4 RELEASE
Bitcoin version 0.4 release candidate 2 looks stable; I've been
running a slightly-modified version of it on the Faucet website with
no issues for a couple of days now, and am not aware of any
show-stopper issues.
I built and uploaded OSX binaries to github:
  Windows and Linux binaries will appear as soon as our "gitian-capable"
builders get a minute to create them (Jeff and Matt have been busy
with real life or their day jobs).
I'd like to switch from distributing binaries on SourceForge to
distributing them on GitHub, since GitHub supports https downloads.
NEXT RELEASE
If you have patches waiting to be pulled, now would be a good time to
rebase them; I expect minimal-to-no changes between release candidate
2 and the final 0.4 release.
And, if you haven't already, write up a little test plan and/or add
some unit tests.
The big planned feature for next release is switching from wxWidgets
to qt for the GUI client.
ON THE RADAR
I'm going to start separate discussions about a few need-deep-thinking issues:
1) There is a bug/design flaw in bitcoin's difficulty adjustment
algorithm. More generally, there have been nagging issues surrounding
how bitcoin handles time that I think need to be addressed.
2) I'm going to submit pull requests for an implementation of the
"don't talk to misbehaving peers" idea. That should proactively
prevent a whole swath of potential denial-of-service attacks, but if I
got it wrong it could be very bad for the network.
3) I'd really like to come to consensus on one or more
'multi-signature' standard transactions to enable much better wallet
backup and security.
Lets talk about those three issues in separate threads.

@_date: 2011-09-13 11:06:37
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Difficulty adjustment / time issues 
And a recent related exploit launched against the low-difficulty
alternative chains:
  Seems to me there are two fundamental problems:
1) Bitcoin should be overlapping the ranges of block timestamps that
it uses to calculate difficulty adjustments.
2) Bitcoin's "what time is it" code is kind of a hack.
Fixing (1) would mean a potential block-chain split; before
considering doing that I'd like to consider second-best solutions.
Fixing (2) is easier; incorporating a ntp library and/or simply
removing the bitcoin mining code from the client but requiring pools
and miners to have accurate-to-within-a-minute system clocks (or their
blocks will be "discouraged") seems reasonable to me. If you want to
produce blocks that the rest of the network will accept, run ntp on
your system.
I THINK that fixing (2) will make (1) a non-issue-- if miners can't
mess around with block times very much then it will be very difficult
for them to manipulate the difficulty for their benefit.

@_date: 2011-09-14 10:45:36
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Difficulty adjustment / time issues 
The block timestamp rules currently give HOURS of wiggle-room for
timestamps. We can't change those rules without risking a chain split.
Here's a thumbnail sketch of what I'm thinking:
When new tip-of-chain blocks are received, IF their timestamp is
unreasonable with respect to system time and the previous block's
timestamp, then add them to a 'discouraged' list.  (but follow the
current rules for outright rejecting blocks based on timestamps too
far in the future or past)
Modify the getwork code to build on the second-from-tip block if the
first-on-tip block is on the discouraged list.
Assuming a majority of pools/miners adopt the "discourage blocks with
stale timestamps" rule, that should squash any incentive for cartels
to try to start playing with difficulty-- you would have to have 50+%
power to start, or you risk producing mostly orphan blocks.
I'll trade more security for "make at least one pool operator have to
do some work" any day.

@_date: 2011-09-14 16:28:01
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Difficulty adjustment / time issues 
Excellent idea, that gets the incentives right.
RE: fixing the root cause with a forking change:
What do other people think?  I think it is too high risk for too
little benefit and shouldn't be done until we have a really compelling
reason to introduce a forking change.
The first really compelling reason I can think of is removing the
MAX_BLOCK_SIZE limit (but does something clever to prevent the
rogue-miner-sends-you-a-valid-10Terabyte-block attack).

@_date: 2011-09-14 21:57:00
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
I'm looking for review of this pull request:
  The big idea: if a peer is sending you obviously wrong information,
punish it by maybe dropping your connection to it, and ban it's IP
address so it cannot immediately re-connect.
The probability of dropping the connection, and the length of the ban,
depend on how how potentially wasteful/damaging the peer is behaving.
So sending an extra 'version' message is a minor transgression that is
usually tolerated, sending a more-than MAX_BLOCK_SIZE block is a major
transgression that gets the peer disconnected immediately.
Detailed how-it-works, using "I got a version message I wasn't
expecting" as the specific example:
Getting an unexpected version message from a peer increases that
peer's 'misbehaving' score by 10, and (assuming that is the peer's
first bad behavior) gives it a 10% chance of being disconnected.  If
it is disconnected, then that peer's IP address is banned from
connecting for a couple of hours.  If it is not disconnected, then
nothing happens unless the peer misbehaves again; if it does, then its
chances of being disconnected go up, and the length of time it will be
banned increases.
Misbehavior/ban information is stored only in memory, and information
about misbehaving peers is never broadcast. Also, peers that are
disconnected/banned are just dropped, there is no warning or reason
I think this will eliminate a lot of potential denial-of-service
attacks, and could be a good framework for responding to other
potential attacks. "We" should still look through the code and limit
the potential size of any data structures that an attacker might
target (transaction pool, orphan block pool); the DoSprevention
changes are meant to make it harder for an attacker to stay connected
long enough to pull off an attack.
The danger is that I got something wrong; what if an attacker can
leverage the DoSprevention code to split or shatter the network?
Here's my thinking on that, please help check my work:
+ I'm relying on TCP to prevent IP address spoofing (otherwise an
attacker could force you to disconnect from your peers by pretending
to be them and sending you a bad block).
+ Peers are only penalized for sending messages that won't, and
shouldn't, get relayed. So an attacker shouldn't be able to poison the
network with a bad message that is propogated and then causes
everybody to disconnect from everybody else.
+ I specifically do not punish peers for relaying what look like
double-spend transactions. If I did, then an attacker could try to
segment the network into two pieces by broadcasting a series of
double-spends from two halves of the network, and waiting until the
nodes "in the middle" disconnected/banned across the 'seam'.
So: please let me know if or how I'm being an idiot.

@_date: 2011-09-15 08:25:23
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
Thanks Mike, that's exactly the kind of detailed review I was looking
for.  I think you're right an all points.
I'll simplify:  I'll add a -banscore option (default 100), and if a
node accumulates more than -banscore misbehavior points it'll get
dropped and banned for -bantime (default 60*60*24) seconds.
I'll make bad signatures a banning offense, and I'll remove the
number-of-sigops and non-standard-transaction penalties.
I used a mutable field with const setter to avoid modifying a bunch of
methods to take non-const blocks/transactions instead of const; I
think it is appropriate because a block/transaction's DoS score is
really meta-data and not part of it's state.
I'll make GetTime() unit-test friendly as you suggest.

@_date: 2011-09-15 10:06:37
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
Darn good question. If the protection fails, would it be better for it
to 'fail hard', leaving people complaining "bitcoin won't stay
Or fail soft, so you at least have a couple of connections.
I think fail hard is better-- we'll immediately know about the
problem, and can fix it.  Fail soft makes me nervous because  I think
that would make it more likely a bug splits the network (and,
therefore, the blockchain).
If I think you're trying to DoS me, why would I be nice to you?  I
think response messages would just give an attacker another potential
attack vector, and it is clear from the debug.log what triggers a ban.
Good question. Anybody see a reason not to?  How much tolerance (if
any) should there be for sending garbage data (I assume the
lower-level network stack almost never garbles data, is that a good

@_date: 2011-09-15 12:19:45
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
I hate to get specific about potential attacks on a public mailing
list, but I think the debate over what to do with non-standard
transactions means we need to.
I agree with Gregory; if there are NO rules about what transactions
peers can send at you, then an attacker can trivially get around other
the DoS rules.
I also agree we need to think hard about what will happen when new
'standard' transaction types are deployed.
There are two significant DoS attacks I can imagine using transactions
that will never be included in blocks.  The "will never be included in
blocks" bit is important, because if an attacker can make you do
significant work at no cost to themselves then they win. And if the
transactions will never be included in blocks the attacker can include
lots of transaction fees that will never be spent.
1) Exhaust memory by filling up the transaction memory pool. I think
another patch needs to be written to deal with that (keep the size of
the transaction pool reasonable by evicting low-priority
2) Waste CPU time validating transactions   They can make you use an
arbitrary amount of CPU time just by flooding you with a stream of
valid-but-won't-ever-get-into-a-block transactions.
The code already refuses to relay non-standard transactions, and
doesn't check their signatures or add them to the memory pool, so I
think no DoS check is needed for them (and would be harmful when we do
start supporting new standard transactions).
It also drops transactions with "too few fees" before checking
signatures or doing other CPU-intensive work, so no I think no DoS
check is needed there, either (and again, would be harmful when
transaction fee rules change).
I'm ignoring bandwidth DoS attacks-- we already have the
-maxreceivebuffer option to deal with those.
PS: I'll add Gregory's comment:
"There should be nothing I can give a node that it will
forward on that will make that node's peers drop it. (and this needs
to remain true while forwarding rules evolve)"
... as a comment in the code so hopefully we don't forget it.

@_date: 2011-09-15 15:07:57
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
I took it off the list because snarky comments are not appropriate for
bitcoin-dev, and I was being snarky.
Please try to keep your comments on-topic; if you want to talk about
fixing -maxreceivebuffer (a change I would wholeheartedly embrace, the
code I slapped together was reacting to phantomcircuit's "here's a
python script that will kill any bitcoin node on the network" 0-day
exploit), then please start a new topic.

@_date: 2011-09-19 08:49:08
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.4.x stable branch 
My initial reaction is no. Testing and bug-fixing is the bottleneck
for making core bitcoin better, and maintaining two release lines
won't make that better.
I also think that until we get to a "1.0" that we can all agree is
ready for everybody AND their grandma to use, using the word "stable"
would be dishonest.
Would we link to your binaries if you want to create 0.4.* releases,
build binaries, then QA test and release them?
I dunno-- what do other people think?
Eventually, when there are a bunch of bitcoin implementations to
choose from, I think bitcoin.org should look like bittorrent.org -- it
should become a forum for developers to exchange ideas about the
direction of bitcoin.

@_date: 2011-09-19 12:57:58
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin Enhancement Proposals (BEPS) 
New 'standard' transaction forms would be perfect candidates for BEPS.
I think we aught to have a formal proposal to separate the protocol
version from the client version, too.
Does anybody besides me think maybe we should name them something
other than "BEP" ?
I'm worried we'll regret it in two years when a google for "BEP003"
takes you to the BitTorrent EPs instead of the BitCoin EPs.
Maybe "BIP" == Bitcoin Improvement Proposal
or "PEB" == Proposal to Enhance Bitcoin
or "BER" == Bitcoin Enhancement Request
I think I like "BIP"  (PEB sounds like a diet soda, and I don't know
if BER should be pronounced "bear" or "beer").
I generally don't care about names, but it seems like a little
planning now might save some confusion later. And I don't want the
BitTorrent folks to get pissed off at us for 'stealing' their acronym,

@_date: 2011-09-23 14:09:58
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin 0.4.0 released 
Thanks to everybody who contributed:
Bitcoin version 0.4.0 is now available for download at:
  The main feature in this release is wallet private key encryption;
you can set a passphrase that must be entered before sending coins.
See below for more information; if you decide to encrypt your wallet,
WRITE DOWN YOUR PASSPHRASE AND PUT IT IN A SECURE LOCATION. If you
forget or lose your wallet passphrase, you lose your bitcoins.
Previous versions of bitcoin are unable to read encrypted wallets,
and will crash on startup if the wallet is encrypted.
Also note: bitcoin version 0.4 uses a newer version of Berkeley DB
(bdb version 4.8) than previous versions (bdb 4.7). If you upgrade
to version 0.4 and then revert back to an earlier version of bitcoin
the it may be unable to start because bdb 4.7 cannot read bdb 4.8
"log" files.
Notable bug fixes from version 0.3.24:
Bitcoin supports native wallet encryption so that people who steal your
wallet file don't automatically get access to all of your Bitcoins.
In order to enable this feature, choose "Encrypt Wallet" from the
Options menu.  You will be prompted to enter a passphrase, which
will be used as the key to encrypt your wallet and will be needed
every time you wish to send Bitcoins.  If you lose this passphrase,
you will lose access to spend all of the bitcoins in your wallet,
no one, not even the Bitcoin developers can recover your Bitcoins.
This means you are responsible for your own security, store your
passphrase in a secure location and do not forget it.
Remember that the encryption built into bitcoin only encrypts the
actual keys which are required to send your bitcoins, not the full
wallet.  This means that someone who steals your wallet file will
be able to see all the addresses which belong to you, as well as the
relevant transactions, you are only protected from someone spending
your coins.
It is recommended that you backup your wallet file before you
encrypt your wallet.  To do this, close the Bitcoin client and
copy the wallet.dat file from ~/.bitcoin/ on Linux, /Users/(user
name)/Application Support/Bitcoin/ on Mac OSX, and %APPDATA%/Bitcoin/
on Windows (that is /Users/(user name)/AppData/Roaming/Bitcoin on
Windows Vista and 7 and /Documents and Settings/(user name)/Application
Data/Bitcoin on Windows XP).  Once you have copied that file to a
safe location, reopen the Bitcoin client and Encrypt your wallet.
If everything goes fine, delete the backup and enjoy your encrypted
wallet.  Note that once you encrypt your wallet, you will never be
able to go back to a version of the Bitcoin client older than 0.4.
Keep in mind that you are always responsible for your own security.
All it takes is a slightly more advanced wallet-stealing trojan which
installs a keylogger to steal your wallet passphrase as you enter it
in addition to your wallet file and you have lost all your Bitcoins.
Wallet encryption cannot keep you safe if you do not practice
good security, such as running up-to-date antivirus software, only
entering your wallet passphrase in the Bitcoin client and using the
same passphrase only as your wallet passphrase.
See the doc/README file in the bitcoin source for technical details
of wallet encryption.
Full changelog ("git shortlog --no-merges v0.3.24..")
Abraham Jewowich (1):
      Fix bug with accessing vchData[0] when vchData is empty.     Fix
typo in CBase58Data::CompareTo
Alex B (2):
      Romanian translation added
      Spanish translation update
Alex Waters (1):
      Updated readme file
Daniel Folkinshteyn (1):
      Update the list of seednodes.
Dawid Spiechowicz (1):
      added polish wallet encryption messages
Dean Lee (1):
      Update to the Chinese Simp translation
Dev Random (4):
      Linux gitian config with separate wxWidgets build
      Mingw gitian with separate wxWidgets and boost
      Mingw gitian build with deterministic bitcoin.exe by use of faketime
      Add Gitian Build descriptors for Boost and wxWidgets.
Doug Huff (1):
      Make mlock() and munlock() portable to systems that require the
address to be on a page boundary.
Dylan Noblesmith (1):
      mlock() all private keys in memory
Eric Hosmer (1):
      Added crypter to makefile.vc.
Fabian H jr. (1):
      Updated checkpoints, maybe Tx fee should be reduced to 0.0001
from 0.0005 and maximum minimum tx should be 0.0010.
Gavin Andresen (24):
      Do-nothing MapPort() ifndef USE_UPNP.  fixes       Don't std::advance past beginning of transactions array.  Fixes       Remove unused ScanMessageStart function
      Compile with DEBUG_LOCKORDER to detect inconsistent lock
orderings that can cause deadlocks
      CHECKMULTISIG unit tests.
      Highlight mis-matching locks
      Fix rpc-hanging deadlocks
      Fixed potential deadlocks in GUI code.     Also changed
semantics of CWalletTx::GetTxTime(); now always returns the time the
transaction was received by this node, not the average block time.
And added information about -DDEBUG_LOCKORDER to coding.txt.
      Fix typo ("you own security")
      SetCrypted() obtains keystore lock, to be safe.
      Logic running with -keypool=0 was wrong (empty keys were being
returned). Fixes       Fix RPC call name in error message.
      obtain cs_wallet mutex to protect vchDefaultKey
      Fixed regression I introduced: wallets with lots of transactions
were unusable in GUI.
      Fix bad merge: getaccountaddress was broken for new accounts
      Give hard-coded seed nodes a random last-seen time, to randomize
order they're tried.
      Do not try to download blockchain from 0.3.23 nodes
      If compiled -DDEBUG_LOCKORDER and run with -debug, print out
every mutex lock/unlock (helpful for debugging
something-is-holding-a-mutex-too-long problems)
      Stay connected to seed nodes; disconnecting causes problems if
you are trying to make the initial blockchain download.
      Versions 0.3.20 THROUGH 0.3.23 have trouble with blockchain
downloads; avoid them
      Bumped version numbers to 0.4.0rc1
      Optimize database writes for transactions with lots of TxIns.
 Patch from ArtForz, who discovered the problem.
      Fix AddAddress cs_mapaddresses/db transaction deadlock
      Fix QA email address
Giel van Schijndel (15):
      fix warning on 64bit systems: cast to pointer from integer of
different size [-Wint-to-pointer-cast]
      fix warnings: expression result unused [-Wunused-value]
      fix warnings: using the result of an assignment as a condition
without parentheses [-Wparentheses]
      fix warning: comparison of unsigned expression < 0 is always
false [-Wtautological-compare]
      fix warning: X enumeration values not handled in switch [-Wswitch-enum]
      fix warning: unused variable 'X' [-Wunused-variable]
      fix warning: unused function 'SigIllHandlerSSE2' [-Wunused-function]
      fix warning: variable ?nMinDepth? set but not used
      fix warning: control reaches end of non-void function [-Wreturn-type]
      Make some global variables less-global (static)
      Cleanup makefiles such that diffs to them are smaller
      Move func 'REF' from util.h to serialize.h
      Start moving protocol-specific code to protocol.[ch]pp
      Move CAddress to protocol.[ch]pp
      Move CInv to protocol.[ch]pp
Han Lin Yap (2):
      Comment "deprecated"
      Add a note to only include .po file
Jay Weisskopf (4):
      Add logos/branding currently found on bitcoin.org into NSIS installer.
      Set default compression for NSIS installer to LZMA.
      Remove NSIS branding from bottom divider.
      Increase resolution of Windows icon.
Jeff Garzik (8):
      Update CWallet::LoadWallet for proper return type.
      Bump version to 0.3.25
      doc/README: word wrap into something readable
      CAddrDB::LoadAddresses: properly initialize CAddress
      src/makefile.unix: remove -DFOURWAYSSE2
      Add reference python miner, in contrib/pyminer/
      README.md: word wrap text file
      Revert "Define MSG_NOSIGNAL to 0 on platforms where it is unavailable."
Jeroenz0r (1):
      Translation from "Open Bitcoin" to "Verstuur Bitcoins"
JoelKatz (1):
      Fix UNIX-specific thread handle leak.
Johannes Henninger (1):
      Identify as "Bitcoin + version number" when mapping UPnP port
Luke Dashjr (7):
      Update nTime after nExtraNonce to avoid potential race
(extraNonce being reset due to just-occurred time change after nTime
is set)
      Reset extraNonce only every 15 seconds, just in case some miner
is updating time himself and stuff
      Reset extraNonce only when prevBlock changes, so miners can
continue updating the time on their work until it's stale
      Support for boost filesystem version 3
      ignore stuff
      Save coinbase, not just extraNonce
      Bugfix: Use timestamp in coinbase rather than "bits", needed to
ensure coinbase txn is unique even if address is the same
Matt Corallo (35):
      Add minversion to wallet.
      Add wallet privkey encryption.
      Set the number of SHA512 rounds based on the speed of the computer.
      Push unlocked_until in getinfo.
      Dynamically remove/insert the Options for encryption in the menus.
      Add the walletlock RPC method to lock the wallet manually.
      Add Wallet Encryption section to README
      Use DB Transactions when encrypting wallet.     This speeds up
the encryption process significantly.
      Make an invalid addrIncoming so that old clients crash.
      Update makefile.linux-mingw to work with crypter and UPnP fix.
      Fix makefile.linux-mingw
      Fix crashes when a wallet is locked and GetReservedKey() is called
      Generate Warning when using default key.
      Fix Build in GetReservedKey() in wallet.cpp
      Fix bad return values in LoadWallet.
      Actually use mapAlreadyAskedFor.
      Fix EncryptKeys crash introduced by a9ba4710, identified by TD.
      Check for duplicate txins in CheckTransaction.
      Make it clear that setting proxy requires restart to fully apply.
      Don't listen if on TOR (resolves       Add missing include to serialize.h
      Add file for transaction tests.
      Cleanup test suite output to be more useful.
      Unify copyright notices.
      Missed a 'password' should be 'passphrase'.
      Fix incorrect RPC error messages
      Add specific wallet encryption details to doc/README
      Upgrade dependancies and tweak build process.
      Update binary mos to latest translations.
      Fix build process to actually work.
      Add binary mo for new translation.
      Update gitian build descriptors to produce proper builds.
      Update bitcoin icon to make nsis setup exe deterministic.
      Update binary mo to match latest po translation.
      Restructure gitian files and add download config files.
Michael Bemmerl (4):
      Basically some grammatical fixes of the German translation.
      Added German wallet encryption messages translation.
      Changed Russian translation according to comment in issue 395
      Updated German translation
Michal Zima (1):
      Updated czech translation
Nils Schneider (2):
      log low-level network messages only when fDebug is set
      missed printf in AbortMessage(); merged printfs in EndMessage
Patrick Varilly (1):
      Single DB transaction for all addresses in a message
Pieter Wuille (11):
      Prepare codebase for Encrypted Keys.
      Do not use obsolete CPrivKey for passing keys around
      Bugfix: add autogenerated addresses to address book
      get rid of mapPubKeys
      Use CBitcoinAddress instead of string/uint160
      split off CBase58Data from CBitcoinAddress
      Fix for small change outputs
      Bugfix: don't overuse limited ExtractAddress
      avoid strAddress + validity checks
      SocketHandler thread can be detached
      Updated dutch translation
St?phane Gimenez (1):
      Single DB transaction for addresses from DNS seeds
Vegard Nossum (6):
      Add missing includes to key.h
      Add missing include to script.h
      Add missing includes to net.h
      Fix testing setup
      Add prototype for EvalScript() to script.h
      Add a file for script tests
Venkatesh Srinivas (4):
      Test for SO_NOSIGPIPE rather than assuming all BSDs support it.
      Qualify make_tuple with boost:: namespace.
      Use 'unsigned char' rather than 'char' for pchMessageStart.
      Define MSG_NOSIGNAL to 0 on platforms where it is unavailable.
Wladimir J. van der Laan (2):
      remove magic number: change threshold for nLockTime to constant
      make SetHash160 return a value (as specified in the function signature)
cjdelisle (1):
      wxWidgets needs to be at least version 2.9.1 because wallet
crypto uses ToStdString() which is not in 2.9.0
ovdeathiam (1):
      Edited locale/pl/LC_MESSAGES/bitcoin.po via GitHub

@_date: 2011-09-23 17:36:56
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin 0.4.0 released 
What Daniel said.  Although I did upload the signatures to github, too:
  The github downloads have been unreliable, so I didn't announce that
you can download from there.

@_date: 2011-09-24 11:19:40
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Pulling for the 0.5 release 
Bright and early Monday morning I plan on pulling changes for the
Bitcoin 0.5 release into tip-of-git. Expect some tip-of-git chaos and
instability, I'm sure there will be issues to work through to move
from wxwidgets to qt for the GUI.
I'd like to have a release candidate ready in a week or two, giving
time for a week or two of testing, and have the 0.5 release available
a month from now, assuming no major show-stopper bugs or network
stability or denial-of-service or security vulnerabilities turn up
between now and then.

@_date: 2011-09-26 16:47:06
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Newly introduced DoS 
So in the future lets suppose we schedule a change to the acceptable
block rules that allows more SigOps in a block, or allows generation
transaction to be spent before 100 confirmations. At that same time,
the DoS rules will be changed.
You cannot "legitimately" relay those blocks without a scheduled
block-chain-split.  If a block-chain-split IS scheduled and the rules
change, then denying service to nodes running old, obsolete versions
of bitcoin is the right thing to do-- it is better to "fail hard" and
find it difficult or impossible to connect to the network rather than
continue with an obsolete client and a non-majority block chain.
(and the third DoS in AcceptBlock(): prev block not found  is a
"should be impossible" case, because AcceptBlock is only called when
extending the best-block chain).

@_date: 2011-09-26 17:38:41
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Newly introduced DoS 
I sit corrected. The context is:
    // Checking ECDSA signatures is a CPU bottleneck, so to avoid
    // attacks disallow transactions with more than one SigOp per 34
    // 34 bytes because a TxOut is:
    //   20-byte address + 8 byte bitcoin amount + 5 bytes of ops + 1
byte script length
    if (GetSigOpCount() > nSize / 34 || nSize < 100)
out-of-bounds SigOpCount"));
I'm having trouble imagining some future world where valid,
new-versions-agree-to-relay-transactions have more than one SigOp per
34 bytes; can you give an example?
That would imply you're on a blockchain fork of more than 99 blocks
with respect to the person spending the transaction, in which case I'd
argue you have much bigger problems and it is a good idea for the DoS
code to kick in and kick either you or them off the network...

@_date: 2011-09-26 20:07:07
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Newly introduced DoS 
You're absolutely right.
And you're right about the 99 confirmations, too-- I was thinking
blocks again, not transactions.
Good to get all of the wrong-ness out of my system on a Monday so I
know I'll be perfect the rest of the week.  :-)

@_date: 2011-09-27 13:12:09
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] More denial-of-service prevention code to 
Pull request:
  Denial-of-service prevention: orphan blocks
The attack this prevents: Generate valid "orphan" blocks and send them
to a bitcoin node. Orphan blocks are blocks that are not in the main
blockchain, and before this patch the bitcoin client would store an
arbitrary number of them in memory, in case they later became part of
the main chain.
Two checks are added:
1) Orphan blocks before the last blockchain lock-in are rejected, and
if the node sends enough of those obviously-not-part-of-the-main-chain
blocks it will be disconnected and banned.
2) Orphan blocks must have a plausible proof-of-work. It is impossible
for a difficulty 1.0 block to follow a difficulty 1-million block (it
would take at least 19 months for difficulty to drop from 1-million to
1). Orphan blocks with too-low proof-of-work are ignored, and if a
node sends ten of them it is disconnected/banned.
Requiring plausible proof-of-work for orphan blocks will make this
attack too expensive to attempt (you would have to generate valid
blocks at current difficulty).

@_date: 2011-09-27 16:39:32
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Newly introduced DoS 
As I said, that is a "can't never happen but we'll wear a
belt-and-suspenders just in case" case.
AcceptBlock() is called from two places in the code:
ProcessBlock, if the block is not an orphan:
    // If don't already have its previous block, shunt it off to
holding area until we get it
    if (!mapBlockIndex.count(pblock->hashPrevBlock))
    {
....  orphan processing stuff...
      return true;
    }
    // Store to disk
    if (!pblock->AcceptBlock())
        return error("ProcessBlock() : AcceptBlock FAILED");
The mapBlockIndex.find(hashPrevBlock) in AcceptBlock can't fail.
The second place is recursively, in AcceptBlock(), processing orphans
that link to the block being accepted, and mapBlockIndex.find() would
find the used-to-be-an-orphan-block-that-is-now-being-accepted.
So: it is a case that should be impossible to trigger. However, in
case there is some subtle bug or edge case I'm not considering it seem
to me keeping the check is appropriate, and, because it will be a
subtle bug or edge case, it seems to me keeping the DoS penalty is
also appropriate, because attackers look for subtle bugs and edge
cases that can be exploited.

@_date: 2011-09-29 12:07:41
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Multisignature transations 
Design discussion:  Pull request:  Initial support for multisignature transactions
This adds initial support for three new types of transactions:
(a and b)
(a or b)
(a and b) or c
... where a/b/c are keys. These new transaction types will enable
better wallet security and backup in future versions of bitcoin.
I've taken a conservative approach with this initial pull; the new
transaction types will be relayed and included in blocks, but are
ignored by the wallet code, so will not affect the balance and will
never be considered available to spend. I'm going to start a
discussion on bitcoin-dev to do a bit of a brain-dump on what NOT to
do with multi-signature transactions (there are several potential
attacks that we'll need to be careful to avoid).
I'll be creating a multisig_testing branch in the gavinandresen github
fork that WILL add multisig transactions to the balance, will have a
new RPC call to create multisig transactions, and will be able to
spend the multisig transactions; that will be for testing this PULL
only for now.
Here's the discussion of potential attacks that occurred to me while I
was working on this:
+ Attacker has an account and a funding address/key ("a") at a
shared-wallet service.  Attacker also has their own address/key ("b").
+ They send 100 bitcoins that can be spent by (a or b).  Note that the
shared-wallet service can't stop the attacker from doing that.
IF the shared-wallet service credits their account (because "a" can
spend the coins), then Bad Things might happen:
+ The shared-wallet service probably assumes that it controls all the
keys in its wallet, and the only time coins in its wallet will be
spent will be when it issues a send* RPC command. But the attacker can
spend using "b" anytime they like.
+ If the shared-wallet service allows importing of keys then the
attacker might be able to get double-credit by importing "b"
(depending on what the 'import private key' code does).
The pull I've submitted doesn't have any of those issues because
multisignature transactions are not credited / added to the wallet.
Going forward, I think the right thing to do is only add
multisignature transactions to the wallet's balance (and make them
available to spend) if the public half of ALL of the keys involved are
known to the wallet.  The private half of the key may not be in the
wallet (maybe it is on another device or maybe it is a deterministic
backup master key protected by a passphrase), but the public key must
be known and in the wallet.
I'd really like to get this into the 0.5 release because it will
enable much better wallet security and backup in some future release
or alternative client (but these transaction types need to be relayed
and mined BEFORE then to make that possible).

@_date: 2011-09-30 13:21:33
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Multisignature transations 
Not with this PULL-- I think wallet security and backup is a critical
feature, so that is what this is for.
groffer pointed out that might cause problems when transaction volume
ramps up, because each CHECKMULTISIG counts as 20 sigops, and there is
a limit to the number of sigops you can put into a block. And since it
isn't needed for wallet security and backup I dropped it.
Accepting this does not preclude adding more 'standard' transaction
types in the future.

@_date: 2011-09-30 13:57:38
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Multisignature transations 
============================== START ==============================
RE: 2 of 3 being far more useful:
So create a clean pull request, unit tests, and test plan for an
"IsStandard" 2-of-3 transaction, either using CHECKMULTISIG or
groffers proposal:
OVER 2SWAP CHECKSIG SWAP HASH160 {pk1hash} EQUAL BOOLAND ADD
OVER 2SWAP CHECKSIG SWAP HASH160 {pk2hash} EQUAL BOOLAND ADD
OVER 2SWAP CHECKSIG SWAP HASH160 {pk3hash} EQUAL BOOLAND ADD
2 GREATERTHANOREQUAL
The low-level support is relatively easy, reporting these transactions
in listtransactions and figuring out if or how to report them in your
wallet balance is tricky.
I generated and then spent three multisig transactions on testnet:
 Code I used to send them is:
 (that code is NOT intended for mainline bitcoin, I just needed a way
of testing the new transactions).

@_date: 2012-04-02 11:36:54
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Release plan: 0.6.1 
Summarizing a discussion from  this morning:
The merge window for pull requests for a 0.6.1 release is now open.
This will be a bug-fix and code-cleanup only release, with the goal to
have Release Candidate 1 binaries available for testing in three
weeks: April 23'rd.  We want this to be a quick release cycle so we
can start pulling new features for a 0.7 release in a month or so.
The major issues I would like to get resolved:
 # 1024 Correct passphrase crashed the client
 # 1012 bitcoin-qt slow to shut down after recent commits
There are currently 189 open issues in our bug tracker; lets try to
get that down to under 100.
I know this will frustrate some of you who think development is
happening at a snail's pace; feel free to pull and test new features
(IPv6 support and coin control) that are important to you. Adequate
testing is still our biggest issue, if you want your favorite feature
to get into bitcoin core faster please spend some time helping test
other people's favorite features.

@_date: 2012-04-03 14:46:17
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Signature Blocks and URI Sign Requests 
RE: signature blocks and BIP 10:
We should avoid reinventing the wheel, if we can. I think we should
extend existing standards whenever possible.
So: could we encode signature blocks or BIP-10 transactions using
S/MIME ?  Or is there a more appropriate "sign a message" standard we
could/should use?
You're glossing over little details like what character encoding is
used for the message, but I'd rather leverage all the work already
done by the IETF to nail down all those little details rather then
re-discover them and come up with our own solutions.

@_date: 2012-04-12 11:41:05
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Adding request/reply id in messages 
That seems like a perfectly reasonable protocol improvement to me.
Anybody else have an opinion?

@_date: 2012-08-02 12:00:47
@_author: Gavin 
@_subject: [Bitcoin-development] Version 0.7 release planning 
I have no objections to a rc1 happening before I'm back.
Gavin Andresen

@_date: 2012-08-28 16:00:47
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Please help test: 0.7.0 release candidate 1 
============================== START ==============================
Bitcoin version 0.7.0 release candidate 1 binaries are now available
for download at:
  Please use the issue tracker at
 to report bugs.
Notable changes:
Qt GUI
* Add UI RPC console / debug window
* Re-Enable URI handling on Windows, add safety checks and tray-notifications
* Add 2 labels to the overviewpage that display Wallet and Transaction
status (obsolete or current)
* Extend the optionsdialog (e.g. language selection) and re-work it to
a tabbed UI
* Merge sign/verify message into a single window with tabbed UI
* Improve error reporting at startup
* Fine-grained UI updates for a much smoother UI during block downloads
* Reorganize tray icon menu into more logical order
* Persistently poll for balance change when number of blocks changed
* Much better translations
* Added 'immature balance' display on the overview page
* (Windows only): enable ASLR and DEP for bitcoin-qt.exe
* (Windows only): add meta-data to bitcoin-qt.exe (e.g. description)
Bitcoin Improvement Proposals implemented
* IPv6 support
* Tor hidden service support
* Attempts to fix "stuck blockchain download" problems
* Replace BDB database "addr.dat" with internally-managed "peers.dat"
  file containing peer address data.
* Lower default send buffer from 10MB to 1MB
* proxy: SOCKS5 by default
* Support connecting by hostnames passed to proxy (-proxydns)
* Add -seednode connections, and use this for -dnsseed + -proxydns
* Added -externalip and -discover
* Add -onlynet to connect only to a given network (IPv4, IPv6, or Tor)
* Separate listening sockets, -bind=
Internal codebase
* Additional unit tests
* Compile warning fixes
* Reopen debug.log upon SIGHUP
* Bash programmable completion for bitcoind(1)
* On supported OS's, each thread is given a useful name
Thanks to everybody who contributed to this release:
Chris Moore
Christian von Roques
David Joel Schwartz
Douglas Huff
Gavin Andresen
Giel van Schijndel
Gregory Maxwell
Jeff Garzik
Luke Dashjr
Matt Corallo
Michael Ford
Michael Hendricks
Peter Todd
Philip Kaufmann
Pieter Wuille
R E Broadley
Ricardo M. Correia
Rune K. Svendsen
Scott Ellis
Stephane Glondu
Wladimir J. van der Laan

@_date: 2012-12-01 14:25:17
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Spec updated: Changes are:
Version numbers:  a couple of people asked privately about adding
version numbers to the messages. In general, Protocol Buffers don't
need version numbers if later versions add only optional fields.
And best-practice is to know what version of something you're
expecting BEFORE you start parsing that something.
So, if a bitcoin client is getting Invoice messages via email or from
a web server, the version will be specified as part of the MIME type;
for example:
   Content-Type: application/x-bitcoin-invoice; version=1
The version= syntax is part of the MIME standard.
Following that best-practice of knowing what you're parsing before you
parse it, I added an invoice_version field to the SignedInvoice
message. It is now:
message SignedInvoice {
    required bytes pki_data = 1;
    required string pki_type = 2 [default = "x509"];
    required bytes serialized_invoice = 3;
    required uint32 invoice_version = 4 [default = 1];
    required bytes signature = 5;
Handling of receiptURI errors:
Following discussion here, I changed the spec to say:
"Clients may handle errors communicating with the receiptURI server
however they like, but should assume that if they cannot communicate
at all with the server then the Payment should either be retried later
or immediately rejected."
and under Receipt added:
"The Bitcoin client must be prepared to handle the case of an evil
merchant that returns accepted=false but broadcasts the transactions
I also added a TODO "Test Vectors" section with base64-encoded
examples of everything.

@_date: 2012-12-03 15:59:16
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Because the results from standard JSON parsers are undefined if I give
you an "envelope" JSON that has repeated keys.
For example:
  "pki_data" : "...hex-or-base64-encoded certificate chain...",
  "signature" : "....hex-or-base64-encoded-signature-bytes",
  "message" : "....string-encoded-utf8-JSON",
  "message" : "....another string-encoded-utf8-JSON",
  "signature" : "....more hex-or-base64-encoded-signature-bytes",
  "pki_data" : "...another certificate chain...",
The JSON spec doesn't say what you'll get when you decode that mess.
Maybe the first instance of each field, maybe the last, maybe one
picked at random...
The JOSE (Javascript Signing and Encryption) spec says "Thou Shalt Use
A JSON Parser That Treats Multi-defined-keys As An Error."
I expect that most developers will be lazy and will just use whatever
JSON parser is convenient, no matter how much the spec/documentation
warns them not to. And that makes me nervous, because I can imagine
attackers taking advantage of mismatches between (say) the JSON
parsing software used by some back-end server process and a front-end
JavaScript web wallet UI.

@_date: 2012-12-05 14:34:49
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
I've had some push-back on the names of the proposed messages-- e.g.
"Invoice" in the accounting world means "I've already given you a
product or service, here is what you owe, payment terms, what forms of
payment are accepted, etc."
I think there might also be confusion about why we're defining our own
Invoice when there are at least three or four other existing standard
for electronic invoices.
So unless there is strong objection I'm going to change the names of
the messages:
Invoice -->  PaymentRequest
Payment : ok as-is
Receipt --> PaymentACK  (payment acknowledgement)
BIP 0001 says:  "If in doubt, split your BIP into several well-focussed ones."
I think it makes sense to keep the URI extension separate from the
binary message format.

@_date: 2012-12-06 11:56:49
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Spec updated yet again:
  Renamed to PaymentRequest/PaymentACK.
Added a 'network' field ("main" or "test") to PaymentRequest so testnet and
main network (and alterna-chain) payment requests don't get confused.
Updated description of PaymentRequest.outputs:
outputs: one or more outputs where Bitcoins are to be sent. If the sum of
outputs.amount is zero, the customer will be asked how much to pay, and the
bitcoin client may choose any or all of the Outputs (if there are more than
one) for payment. If the sum of outputs.amount is non-zero, then the
customer will be asked to pay the sum, and the payment shall be split among
the Outputs with non-zero amounts (if there are more than one; Outputs with
zero amounts shall be ignored).
RE: escrow/multisig:
Setting up a multi-person escrow will, I think, need it's own set of
messages. I think we should leave that for a future spec.
Thumbnail sketch:  escrow service or participant sends around an
EscrowProposal, gets EscrowProposalACK's with public keys to use, then
sends all participants an EscrowEstablished message with the final multisig
script or address.  Escrow gets funded by any/all of the participants, and
then gets spent using the SignedPaymentRequest/Payment/PaymentACK
protocol-- participants will pass around a SignedPaymentRequest and a
partially-signed Payment message for all to approve.
When I say "pass around" I'm not thinking of users copying and pasting,
that would be a terrible user experience; all of that communication needs
to happen automatically behind the scenes. Lets tackle that after we've got
the simpler customer-pays-merchant flow working nicely
(funded-escrow-pays-merchant is a subset of that, anyway).

@_date: 2012-12-06 14:13:06
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
OK. I want to keep the signature field required, though, so how about:
signature: digital signature over a protocol buffer serialized variation of
the SignedPaymentRequest message where signature is a zero-byte array and
fields are serialized in numerical order (all current protocol buffer
implementations serialize fields in numerical order), using the public key
in pki_data.

@_date: 2012-12-07 11:19:12
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Yes, my next step is prototyping.
Note that this is not a BIP yet:  I want to have a working implementation
before making this an Official BIP.
   receipt_url: Secure (usually https) location where...
Though it's not strictly necessary, it'd be nice to have defined
yeah... I had similar thoughts on what to do if some Outputs specify an
amount and others don't. I'm still waffling on whether or not I like
allowing repeated Outputs; a single Output would make the spec a fair bit
simpler, and if a merchant wants to split up a payment for some reason they
could just generate another transaction.
I want to move on to actually implementing this before creating complicated
rules. Maybe the best way to tip a waitress is to get two separate
PaymentRequests, one for the restaurant and one that goes directly to the
waitress (depends on whether or not the restaurant needs or wants to know
how much their employees are getting tipped, I suppose).  Maybe it would be
best to have a separate "gratuity" Output in the PaymentRequest. That's the
kind of detail I think doesn't need to be worked out right now, I'd rather
restaurants tell us what they need/want.
This is the case of getting an UNSIGNED payment request; I've changed the
wording a little to make that more clear.
If a bitcoin client accepts unsigned payment requests (a couple of people
have asked if that would be possible so I think that is desired), then it
doesn't have the payer's identity-- all it has is the Outputs that will be
Not a BIP yet....
serialized_paymentrequest -> serialized_payment_request?
I still like the idea of only including the root CAs who have jumped
through the hoops needed to get the "allowed to issue EV certs" blessing.
 I'm not suggesting that all bitcoin merchants must get EV certs, but I am
suggesting that they must get a certificate from one of the most reputable
certificate authorities, and the ability to issue EV certificates is, I
think, a good proxy for that.
But, again:  Not a BIP yet.  Lets get something implemented and then hammer
out details (implementing always turns up edge cases you forgot when

@_date: 2012-12-17 12:57:53
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
On Mon, Dec 17, 2012 at 6:23 AM, Melvin Carvalho
The decision has already been made.

@_date: 2012-02-06 10:44:09
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Version 0.6 release candidate 1 plan 
There are several major changes in git HEAD that are ready for wider
testing. The best way of getting lots of testing is to release
binaries, so I'm going to be pulling together a release candidate in
the next day or two.
The goal will be to get at least a full month of release candidate
review/testing before releasing a 0.6 final, with zero High Priority
bugs ( Here's the proposed TODO list for a rc1:
800 : bug fix, multiple output display fix in GUI
799 : Have bitcoind recomend a secure RPC password
769 : Make transactions with extra data in scriptSig non-standard
795 : Fix minimize to tray
Pull a modified version of:
755 : Don't vote for /P2SH/ unless -p2sh specified
I'd like to pull 787 (CAddrMan: stochastic address manager) but it
didn't pass my sanity tests.
I'm going to start a separate discussion thread with some thoughts on
rolling out higher-level multisignature support.

@_date: 2012-02-06 11:07:00
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Multisignature transaction support in the GUI 
I've been testing how the Bitcoin-Qt GUI deals with multisignature transactions.
The good news is it seems to display them just fine; even my
insanely-messy test wallets look reasonable.
It does not support sending multisig/BIP16 transactions, which is
definitely a feature for the main network (we don't want users sending
them until they will get relayed, get mined, AND will be fully
verified by a large super-majority of miners).
But... to encourage more testing it might make sense to enable sending
multisig transactions in the GUI if (fTestNet).
So I see two possible paths:
1) Leave the GUI as-is; require multisig testing to use the RPC interface.
 Note: the RPC call that make multisig sends possible
(addmultisigaddress) is disabled for the main network for the 0.6
 Don't start rolling out GUI support until the next (0.7?) release cycle.
2) Start implementing multisig support in the GUI during the 0.6
release process, enabled only for test network. This could be as
simple as allowing the 35-character BIP16 multisig addresses in the
'send' dialog, to as complicated as adding/extending dialogs that let
you create multisig addresses to add to your address book.
Advantage of (1) is it should mean 0.6 gets to final release faster.
Advantage of (2) is it should mean more testing of multisig, and fewer
bug reports of "I added a multisig address via RPC but I can't send to
it using the GUI"
My opinion: I think it is worth allowing send-to-multisig-address via
the GUI (should be a very simple change to the address validation
logic).  But creating multisig addresses via the GUI should wait until
the next release.

@_date: 2012-02-07 11:14:14
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Version 0.6 release candidate 1 plan 
Sure, here's one:
Green address provider give a REST-ful API, that provides the
following functionality:
+ Give transaction ID and credentials, request that the transaction be
declared "green"
  (sender's wallet site/software would do this)
+ Give transaction ID, return boolean "has this transaction been
deeclared green?"
As I said, I think any design that relies on clients recognizing two
variations of a transaction is a very bad idea.

@_date: 2012-02-08 11:27:03
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.6 Release Candidate 1 
I'd like version 0.6 to get lots of review, "soak time" and testing, so
please download and run release candidate 1 from:
You can review the code changes using github's compare feature:
 Please report bugs using the github issue tracker.
Release notes:
NEW FEATURES SINCE BITCOIN VERSION 0.5
The -nolisten, -noupnp and -nodnsseed command-line
options were renamed to -listen, -upnp and -dnsseed,
with a default value of 1. The old names are still
supported for compatibility (so specifying -nolisten
is automatically interpreted as -listen=0; every
boolean argument can now be specified as either
-foo or -nofoo).
The -noirc command-line options was renamed to
-irc, with a default value of 0. Run -irc=1 to
get the old behavior.
PRELIMINARY SUPPORT FOR MULTISIGNATURE TRANSACTIONS
This release has preliminary support for multisignature
transactions-- transactions that require authorization
from more than one person or device before they
will be accepted by the bitcoin network.
Prior to this release, multisignature transactions
were considered 'non-standard' and were ignored;
with this release multisignature transactions are
considered standard and will start to be relayed
and accepted into blocks.
It is expected that future releases of Bitcoin-Qt
will support the creation of multisignature transactions,
once enough of the network has upgraded so relaying
and validating them is robust.
For this release, creation and testing of multisignature
transactions is limited to the bitcoin test network using
the "addmultisigaddress" JSON-RPC api call.
Short multisignature address support is included in this
release, as specified in BIP 16. Run with -bip16=0 to
turn off support for BIP 16.

@_date: 2012-02-13 21:49:03
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] IRC meeting Tuesday, Feb 14, 21:00 UTC 
Tomorrow, Feb 14'th at 21:00 UTC on  on Freenode IRC I'd
like to chat about:
Status of BIP 16 support (progress towards 50% hashing power).
Protocol change coming up Feb. 20 (checksums in version messages).
Duplicate coinbase issue (and requiring block height in the coinbase
as a solution).
Then when we're done talking tech we can all send each other bitcoins
with addresses that are cute Valentine's day messages...

@_date: 2012-02-15 14:20:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 14 Feb IRC meeting summary 
Full conversation starts here:
  Summary of what was discussed/decided; please correct anything I get wrong:
1. BIP 16 support is at about 34% of hashing power, so we'll continue
to ask big pools and miners to upgrade and will re-evaluate support on
March 1'st, with a potential switchover date if there is enough
support of March 15'th.
2. On February 20'th the protocol changes to include checksums on the
initial version messages. version includes an 'addrFrom' field with
your IP address, and there are (unconfirmed) reports of NAT routers
changing the contents of packets to modify the inside-the-NAT IP
address to the outside-the-NAT address. If you've got a router that
does that, then the version message checksum will be wrong and you'll
be unable to connect.
Two things are being done to address this:
+ A patch that puts the outside-the-NAT IP address in addrFrom. That's
a good idea in any case, exposing interior IP addresses was a mistake.
There will be either a 0.5.3 or 0.5.2.1 release available for anybody
+ An alert will be sent next Friday on the main network directing
people to a to-be-created bitcoin.org/feb20 web page explaining the
3. The third issue was how to deal with potential chain-splitting
attacks involving duplicate coinbase transactions. The general
consensus is that in the long-term requiring that the first four bytes
of every coinbase be the block height is the best solution, but
looking for and 'discouraging' just blocks that have duplicate
coinbases is a reasonable short-term solution.
There's still some research and thinking to be done on this issue (see
the IRC discussion for details), but I expect that the final version
of bitcoin-qt/bitcoind version 0.6 will be putting the block height
into coinbases that it creates.

@_date: 2012-02-20 12:17:07
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP-13 
class][3-byte checksum]
How will the code distinguish between the old scheme:
and the new?
1 in 256 old addresses will have a first-byte-of-checksum that matches the
new address class; I guess the code would do something like:
a) If the 4-byte checksum matches, then assume it is a singlesig address (1
in 2^32 multisig addresses will incorrectly match)
b) If the one-byte-address-class and 3-byte checksum match, then it is a
valid p2sh
c) Otherwise, invalid address
The 1 in 2^32 multisig addresses also being valid singlesig addresses makes
me think this scheme won't work-- an attacker willing to generate 8 billion
or so ECDSA keys could generate a single/multisig collision.  I'm not sure
how that could be leveraged to their advantage, but I bet they'd find a way.
RE: should it be a BIP:  The BIP process is described in BIP
and you're following it perfectly so far:
1) Post a rough draft of the idea here to see if there's any chance it'll
be adopted
2) Assuming a positive response and no major flaws: write up a draft BIP
3) Post the draft BIP here, where it can be picked apart.
4) Assuming no major flaws, ask the BIP editor (Amir) for a BIP number
I'd also encourage you to actually implement your idea between steps 3 and
4. But in this particular case, I think an attacker being able to create
singlesig/p2sh address collisions counts as a major flaw.

@_date: 2012-02-22 11:40:19
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP-13 
PUBKEY_ADDRESS_TEST is/was supposed to change (the logic for it being 111
was "eleven is Gavin's favorite number"), but I have higher priority things
to do than make all the necessary code changes to upgrade testnet wallets
(unfortunately the address:account mappings in the wallet store the address
base58-encoded) and the testnet faucet and get theymos to change the
blockexplorer.com/testnet site to change the version number and publicize
the change so anybody else who has created testnet infrastructure changes.
If you'd like to spearhead that effort, be my guest, but it is not as
trivial as just changing the definition.
Luke can explain why SCRIPT_ADDRESS_TEST is 196, my memory is fuzzy about
that (it always decodes to the same digit in base58 maye?)

@_date: 2012-02-22 11:44:06
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Where to have discussions... 
I've been trying to move discussions to this mailing list, by starting
conversations here and posting links to the mailing list archives in the
discussion forums just so people know there is a conversation going on.
IRC conversations are great for rapid back-and-forth brainstorming, so I
expect a lot of work to continue getting done via IRC, but once there's
general consensus there I expect issues to migrate here.

@_date: 2012-02-23 15:26:40
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BitcoinQt eating 100% CPU 
Bitcoin-Qt is now running nicely using around 0.9% CPU. So it seems like
I can definitely reproduce the issue on my mac.
If I recall correctly, the Mac Bitcoin-Qt does not register itself as a
bitcoin: URL handler, so the easiest fix for the 0.6 release would be to
just never launch the ipcThread  Q_WS_MAC

@_date: 2012-02-27 11:10:17
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP 16 status update 
Mining support for BIP 16 is still under 50%, and won't possibly be over
50% by March 1.  Which means we need a new evaluation/switchover date:
Re-evaluate support: March 15'th
Target switchover: April 1
If you're already supporting BIP16, restart bitcoind with the argument:
  -paytoscripthashtime=1333238400
... to delay switchover until April 1.
Hopefully this will be the last delay; Tycho has told me that deepbit will
support BIP16 as soon as he's able to merge and test the changes, which
will put support at well over 55%.

@_date: 2012-02-28 13:10:41
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Duplicate transactions vulnerability 
Most of you might already know this, but I'm strongly in favor of doing
this as soon as possible.

@_date: 2012-02-28 13:56:26
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Anything to chat about today at 21:00 UTC ? 
I'll be in the  IRC channel in two hours, for the
semi-regular Tuesday IRC meeting. Things that might be worth some
+ The duplicate coinbase attack/fix, and strategy for rolling out sipa's
+ 0.6 release schedule
+ Is there anything we can do to attract a great Windows developer?  (we've
got issues piling up...)
+ Multisignature next-steps: who is working on what?
Am I forgetting anything?

@_date: 2012-02-29 17:46:55
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Duplicate transactions vulnerability 
That can't happen until the coinbase matures, which takes 100 blocks.
And it won't mature because a majority of hashing power is rejecting
it, right?

@_date: 2012-01-02 10:59:00
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Alternative to OP_EVAL 
Here are my latest thoughts on a safer OP_EVAL alternative, inspired
by all the ideas and agitated IRC and email
discussions of the last week or so:
Goal:  Let users publish a short "funding address" that is the hash of
an arbitrary redemption Script revealed when they spend the funds,
implemented in a backwards-compatible-in-the-blockchain way.
A new 'standard' transaction type, "pay to Script hash":
scriptPubKey:  HASH160   EQUAL
Redeemed with the same scriptSig as the OP_EVAL proposal:
Old clients/miners will ignore  and just validate that the
hash of  matches.
New clients/miners will recognize the new type of transaction and will
do the following additional validation:
1. Fail validation if there were any operations other than "push data"
in the original scriptSig.
2. Deserialize the top (last) item on the scriptSig stack (fail
validation if it fails to deserialize properly).
3. Run an additional validation on the deserialized script, using the
remaining items on the scriptSig stack and the deserialized script as
the scriptPubKey.
As Amir said in IRC chat today, "the idea is a hack.... but I like it."
I like it, too-- it is cleaner than OP_EVAL, more straightforward to
implement, and pretty much exactly matches the feature I care about
(moving code from the scriptPubKey to the scriptSig). There are no
special cases like "CODESEPARATORS not allowed in ".

@_date: 2012-01-07 17:48:47
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Pull 748 pay to script hash 
I count the 1 major merge then 8 commits to fix bugs or tweak
things...  I just tried reverting them and stopped when I got scared
I'll accidentally revert a fix we do want to keep.
Instead, I updated my gavinandresen/master github branch to the state
of the tree just before the OP_EVAL merge, so for code review purposes
you can look at:
There are unrelated 0.6 pulls in those changes, too, but it should be
pretty obvious what is what.

@_date: 2012-01-07 20:12:35
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Pull 748 pay to script hash 
The purpose is to comply with the "a block shall not contain more than
MAX_BLOCK_SIGOPS (20,000)" rule, under both the old way of counting
(look at the scriptPubKeys and count CHECKMULTISIGs as 20 sigops no
matter what) and the new way (look at both scriptPubKeys and
pay-to-script-hash scripts in the scriptSig, but count CHECKMULTISIGS
preceded by OP_1/2/3/... as 1/2/3 operations).
RE: too late:
Excellent point. I'll refactor ConnectInputs further, and do something like:
AreInputsStandard() <-- reject from memory pool if nonstanard
ComputeFees() <-- reject if too little fees per byte / sigop
Pieter's compressed-public-keys patch (which was just pulled)
interacts with pay-to-script-hash to make ECDSA denial-of-service
attempts less expensive; I think we need to think hard again about
transaction fees before releasing 0.6, and maybe tweak the fee policy
so denial-of-service attacks using compressed public keys and 1-of-3
CHECKMULTISIG transactions is expensive enough to deter would-be

@_date: 2012-01-16 16:22:54
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP Submission 
Your approach won't work-- OP_ADD is limited to 4-byte operands.  Changing
that would require a "hard" blockchain split / entire-network-upgrade.
I wish to submit the following draft BIP for discussion and possible

@_date: 2012-01-19 11:29:29
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Extending IsStandard() to transaction 
I've been working on a patch to make transaction inputs (scriptSigs) with
extra data non-standard, as part of a general attitude of "try to
anticipate possible problems before they turn into real problems."
Today, any node on the network that is relaying unconfirmed transactions
can add bytes to the transaction's scriptSig's before passing it on, and
that modified version of the transaction will get relayed and might
possibly get mined.
For example, take a standard scriptSig that is:   OP_PUSHDATA OP_PUSHDATA ... and change it to:   OP_PUSHDATA  OP_PUSHDATA OP_PUSHDATA ... and the modified transaction will pass all of the IsStandard(),
IsValid(), and OP_CHECKSIG checks.
That is... unexpected, especially since it changes the transaction id.  You
might transmit a transaction with ID 123 but find out it has been mined as
transaction ID 456.  Satoshi's code doesn't care (it just looks like an
attempted double-spend of the coins), but I wouldn't be surprised if it
caused problems for other implementations or other transaction-handling
My patch will make transactions with extra stuff in the scriptSig
non-standard, so they won't get relayed or mined by new nodes. Alternative
implementations will still have to deal with all types of double-spends, of
course, and there are other ways of producing two transactions that are
identical except for their scriptSigs  (you can generate an arbitrary
number of valid signatures for a transaction if you have the private keys,
for example) so this isn't a panacea for poorly-implemented bitcoin
transaction handling software. But it does remove some "wiggle room," which
is generally a good idea for improving security.
I'm still thinking about how much further to go with this:
+ I think requiring that the  and  be DER-encoded
for the transaction to be IsStandard() is a good idea.  DER encoding
defines a canonical way of representing data; Satoshi's code relies on
OpenSSL to decode signatures and public keys, and OpenSSL accepts any, more
general, BER encoding.
+ I'm tempted to require that the "filler item" to workaround the
OP_CHECKMULTISIG pops-one-too-many-items-off-the-stack bug be exactly OP_0.
Discussion welcome; I should be making a pull request for my patch this
Gavin Andresen

@_date: 2012-01-26 10:32:33
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fuzzer? 
It is a transaction fuzzer; adding block fuzzing is on the TODO.
Basic usage is:
1. Use the send* RPC commands to get one or more transaction IDs
2. Run a script that repeatedly calls relayfuzzed with a nonce/txid
... and see how the connected peer(s) react to all the fuzzy 'inv/tx'
protocol messages.
I built it to stress-test BIP 16, there are lots of useful features that
could be added.  Patches welcome!

@_date: 2012-01-29 09:30:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fw: Quote on BIP 16 
That's an alternative design for multisig addresses that would put a byte
giving the type of transaction and the 20-byte hashes of each of the public
keys involved. They would not have been redeemed using CHECKMULTISIG, but
would use DUP HASH160 CHECKSIG and the arithmetic or logical opcodes to
create the "m of n" condition.
Nobody really liked that solution because it means a new 'type' of bitcoin
address every time we want a new transaction type and long addresses.
Its only advantage is it didn't use CHECKMULTISIG, so there were no
problems with maximum-sigops-per-block.

@_date: 2012-01-30 12:55:50
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP 16/17 deadlines 
I've started a discussion on BIP 16/17 support moving forward
(including trying to improve the testing process) here:
(please reply there so the discussion stays mostly in one place)
Gavin Andresen

@_date: 2012-01-30 21:05:49
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] CAddrMan: Stochastic IP address manager 
Given the randomness in Pieter's design, that seems extremely unlikely
calculation to figure out what percentage of nodes on the network an
attacker would have to control to have a (say) 1% chance of a
successful Sybil attack?
I like this change; I'd like to pull it for the 0.6 release.
I've also been wondering if it is time to remove the IRC bootstrapping
mechanism; it would remove a fair bit of code and we'd stop getting
reports that various ISPs tag bitcoin as malware.  When testing the
list of built-in bootstrapping IP addresses I always connect fairly
quickly, and the DNS seeding hosts seems to be working nicely, too.

@_date: 2012-01-31 08:12:19
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP 21 (modification BIP 20) 
RE: BIP 21 versus BIP 20:  I like BIP 21; simpler is better.
RE: signing and dating URIs:  good ideas.  I think we should agree
that there is consensus around BIP 21 and then after there is some
experience with signing/dating URIs you should write follow-up BIPs .

@_date: 2012-07-06 16:02:16
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP 34: Block v2, Height in Coinbase 
Yes, that is essentially what BIP 30 did.
We want to do this also, partly for "belt and suspenders" security but
mostly for two reasons:
1. To test using block/transaction version numbers to smoothly roll
out changes. The next change we need to make might be prompted by some
crisis; better to learn any lessons now, when we have the luxury of
time to fix problems that might crop up.
2. We think we'll all appreciate the change in a year or three, when
the whole network has upgraded and we can start writing code that
assumes all new blocks past a certain checkpoint contain their height;
that should make it easier to do things like figure out whether or not
an orphan chain can possibly be part of the main chain.

@_date: 2012-07-22 20:41:15
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Reconsidering block version number use 
I'd thought about bumping the coinbase transaction version, but the
problem is if we want a smooth rollout then, during the rollout, every
time a new block comes in the percentage of the last 1,000 blocks that
support the new version has to be computed.
If that means looking in the coinbase transaction, then either the
last 1,000 coinbases have to be stored in memory or they have to be
fetched from disk. Which isn't a huge deal, unless we start
aggressively pruning spent transactions, and that coinbase 900 blocks
back got spent and pruned.
Hmm...  I think it'd be ok to give 3 of the 4 block version bytes as a
simple extranonce, so version=0x00000001 is what we have now, version
2 blocks are any with 0x02 in the low byte, 0x03 is version 3, etc.  I
don't think we'll go through 253 block versions before we're all dead.
That'd be 7 bytes of nonce in the block header, which is
  72,057,594,037,927,936  ~ 72 petahashes = 72,000 terahashes
So: the changes for version 2 blocks would be "has height in the
coinbase, and has a 1-byte version number with a 3-byte extranonce."
No, the rules are "enforce the rules when the chain has a
super-majority."  Since block 190192 is in a part of the chain with
zero other version==2 blocks, the height-in-the-coinbase rule will not
be enforced.

@_date: 2012-07-29 20:52:28
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] script tests - invalid script in 
Yes, more tests are definitely welcome.
check*sig tests are tricky, because they have to refer to previous
unspent transactions and private keys (so require a particular block
chain to test against). Brilliant ideas on a simple data-driven format
block verification tests would be great; a collection of good/bad
block chains, starting from a common chain (maybe the testnet3
tesnet-in-a-box chain) would be very useful for regression testing.

@_date: 2012-06-11 13:47:59
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP22/getmemorypool 
I think the sourceforge mailing list system had the hiccups this
weekend; sorry for Pieter's messages appearing in your inbox multiple
times, it is not his fault.
I deleted the extra copies from the mailing list archives.
As for the contents of his message, since this mailing list was not
working discussion wandered into the pull request:
  Assuming this mailing list is now fixed, I'd like to pull that
discussion back here.  The executive summary:  Pieter and I feel like
BIP 22 is overly complicated, and would like it to be simpler. I'd
especially like to hear what people think will be the "will be used by
lots of pool customers" features and what are the "will be used by
less than 5% of pool customers" features.

@_date: 2012-06-14 09:22:08
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Raw Transaction RPC calls for bitcoind 
I submitted a pull request yesterday that implements low-level "raw"
transaction, and am looking for feedback on the API and help with
trying to test/break it.
Design doc:  Pull request: Test plan: Playing around with this API on the command line I'm pretty happy with
the level of abstraction and the way it interacts with existing RPC
commands; for example, "createrawtx" is just like "sendmany" in the
way outputs are specified.
The signrawtx method is the key new method; it takes a raw
transaction, signs as many inputs as it can, and returns the same raw
transaction with signatures. Typical usage would be:
Funds are sitting in a multisignature transaction output, and it is
time to gather signatures and spend them.
Assumption: you know the multisignature transaction's [txid,
outputNumber, amount].
Create a raw transaction to spend, using createrawtx.
Use signrawtx to add your signatures (after unlocking the wallet, if necessary).
Give the transaction to the other person(s) to sign.
You or they submit the transaction to the network using sendrawtx.
I don't imagine anybody but very-early-adopters or ultra-geeks will do
this by calling these RPC methods at a command-line. They are really
intended for people writing services on top of bitcoind. The service
should be careful to include an appropriate transaction fee, or the
sendrawtx method is likely to fail.
I've been asked a couple of times: why doesn't signrawtx handle the
BIP 0010 ( transaction format?
I considered parsing/writing BIP 10 format for raw transactions, but
decided that reading/writing BIP 10 format should happen at a higher
level and not in the low-level RPC calls. So 'raw transactions' are
simply hex-encoded into JSON strings, and encoding/decoding them is
just a couple of lines of already-written-and-debugged code.
Here is the help output and example use for all the new RPC calls:
listunspent [minconf=1] [maxconf=999999]
Returns array of unspent transaction outputs
with between minconf and maxconf (inclusive) confirmations.
Returns an array of 4-element arrays, each of which is:
[transaction id, output, amount, confirmations]
E.g:  listunspent 1 2
    [
        "2881b33a8c0bbdb45b0a65b36aa6611a05201e316ea3ad718762d48ef9588fb3",
        0,
        40.00000000,
        2
    ],
    [
        "894a0fc535c7b49f434ceb633d8555ea24c8f9775144efb42da85b853280bcd7",
        0,
        50.00000000,
        1
    ]
getrawtx Returns hexadecimal-encoded, serialized transaction data
for . Returns an error if  is unknown.
E.g.: getrawtx fce46ea2448820f7bb8091b5f5e3fd75b7b267e60b9a22af88a9eeabfb084233
createrawtx [["txid",n],...] {address:amount,...}
Create a transaction spending given inputs
(array of (hex transaction id, output number) pairs),
sending to given address(es).
Returns the same information as gettransaction, plus an
extra "rawtx" key with the hex-encoded transaction.
Note that the transaction's inputs are not signed, and
it is not stored in the wallet or transmitted to the network.
E.g.: createrawtx '[
]' '{"mqYmZSQQuAWNQcdwBrDwmtTXg2TLNz748L":50}'
    "version" : 1,
    "locktime" : 0,
    "size" : 85,
    "vin" : [
        {
            "prevout" : {
                "hash" :
                "n" : 0
            },
            "scriptSig" : "",
            "sequence" : 4294967295
        }
    ],
    "vout" : [
        {
            "value" : 50.00000000,
            "scriptPubKey" : "OP_DUP OP_HASH160
6e0920fc26383dc7e6101bc417cf87169d0cedbd OP_EQUALVERIFY OP_CHECKSIG"
        }
    ],
    "rawtx" : "0100000001334208fbabeea988af229a0be667b2b775fde3f5b59180bbf7208844a26ee4fc0000000000ffffffff0100f2052a010000001976a9146e0920fc26383dc7e6101bc417cf87169d0cedbd88ac00000000"
signrawtx  [,...]
Sign inputs for raw transaction (serialized, hex-encoded).
Second argument is an array of raw previous transactions that
this transaction depends on but are not yet in the blockchain.
Returns json object with keys:
  rawtx : raw transaction with signature(s) (hex-encoded string)
  complete : 1 if transaction has a complete set of signature (0 if not)
E.g.: signrawtx
    "rawtx" : "0100000001334208fbabeea988af229a0be667b2b775fde3f5b59180bbf7208844a26ee4fc000000009100473044022007f3ba1b8bdc156f2340ef1222eb287c3f5481a8078a8dad43aa09fd289ba19002201cc72e97406d546dc918159978dc78aee8215a6418375956665ee44e6eacc1150147522102894ca6e7a6483d0f8fa6110c77c431035e8d462e3a932255d9dda65e8fada55c2103c556ef01e89a07ee9ba61581658fa007bf442232daed8b465c47c278550d3dab52aeffffffff0100f2052a010000001976a9146e0920fc26383dc7e6101bc417cf87169d0cedbd88ac00000000",
    "complete" : false
sendrawtx Submits raw transaction (serialized, hex-encoded) to local node and network.
E.g.: sendrawtx
error: {"code":-22,"message":"TX rejected"}
(Rejected because it doesn't have all required signatures, if it was
accepted it would return the transaction id)

@_date: 2012-06-14 16:00:57
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Raw Transaction RPC calls for bitcoind 
I like that idea.
A third argument that is an array of private keys (in the same format
as the dumpprivkey RPC call) should be easy to support, assuming the
semantics are:
+ If third argument given, do not require that the wallet be unlocked,
and only sign using the private key(s) given (ignore the bitcoind
wallet entirely).
+ Private keys would stay in bitcoind memory only for the duration of
the RPC call.

@_date: 2012-06-15 16:56:25
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Near-term scalability 
I think there is general consensus this is a good idea.
I don't think the problem is with SatoshiDice, but is with the current
fixed/inflexible fee rules:
I've been thinking about fees a lot the last couple of days, and I'm
close to making a formal proposal. Here are my thoughts so far:
It seems to me there are two typical use cases:
Case 1:  I want my transaction to be confirmed quickly, and am willing
to pay a fee to make that happen.
Case 2: I want my transaction to be confirmed eventually. I'd rather
not pay, unless I have to.
I don't think the current code handles those two cases as well as it
could; here's a proposal to fix that:
o Let miners decide on how many free transactions they'll support, by
letting them specify how much of each block to set aside for 'free'
transactions (bytes) and what the threshold for 'free' is
(bitcoins/kilobyte). I think a new RPC call to get/set the parameters
dynamically is the right way to go.
o Change the block creation code to calculate a
bitcoin-fee-per-kilobyte for each transaction, where the fee and size
are both calculated based on the transaction and it's dependent
descendants (so we get the receiver-can-opt-to-pay-the-fee behavior we
want). Order transactions so highest-paying get into the non-free
space first.
o Fill up the "free" space (if any) with the highest-priority
transactions, where priority is a function of transaction size, age of
inputs, number of bitcoins... and ratio of inputs to outputs (to
encourage combining inputs so more pruning is possible).
The fee-paying space in a block lets Use Case  users compete to make
their fees high enough to get into the block.
The free space should let non-spamming Use Case  users (who don't
send a lot of transactions, and so have well-aged, high-priority
inputs) send transactions for free, at least as long as there are
miners willing to accept free transactions.
The question is: how do clients suggest fees to users if miners might
have very different fee policies?
I think full, transaction-verifying clients can watch how long
transactions stay in the memory pool to figure it out. I'm gathering
statistics right now to test a couple of simple heuristic algorithms
for reasonable fee/priority policies.
But that won't work for newly started clients that haven't seen a lot
of transactions enter/exit the memory pool, or SPV clients that can't
lookup transaction inputs (so can't calculate what fees are being paid

@_date: 2012-06-16 17:41:52
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] After compressed pubkeys: hybrid pubkeys 
RE: 0x06/0x07 'hybrid' public keys:
I say treat any transactions that use them as 'non-standard' -- don't
relay/mine them by default, but accept blocks that happen to contain
I agree that a rule change isn't worth it right now, but making them
non-standard now is easy and should make a rule change in the future

@_date: 2012-06-19 11:05:21
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] LevelDB benchmarking 
What problem does it solve?
If the problem it will solve is "it will only take 4 hours to download
the entire blockchain next year instead of taking 16 hours" then no, I
don't think we should do it, both 4 and 16 hours to get fully up and
running is too long.
If the problem it will solve is the "too easy to get a DB_RUNRECOVERY
error" because bdb is fragile when it comes to its environment... then
LevelDB looks very interesting.
If the problem is bdb is creaky and old and has obscure semantics and
a hard-to-work-with API, then yes, lets switch (I'm easily seduced by
a pretty API and blazing fast performance).
As long as it compiles and runs on mac/windows/linux that doesn't
really worry me. I just tried it, and it compiled quickly with no
complaints on my mac.
Lack of infrastructure because it is new does worry me; for example,
could I rework bitcointools to read the LevelDB blockchain?  (are
there python bindings for LevelDB?)
Satoshi rolled his own network serialization because he didn't trust
existing serialization solutions to be 100% secure against remote
exploits. Then it made sense to use the same solution for disk
serialization; I don't see a compelling reason to switch to some other
serialization scheme.
Modifying the database schema during migration to better support
applications like InstaWallet (tens of thousands of separate wallets)
or something like Pieter's ultra-pruning makes sense.

@_date: 2012-03-03 12:55:02
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: Proposal for a new opcode 
That's very exciting!  I'm eager to read the paper for all of the
details, and working out what else would need to be done besides a new
opcode to enable strong anonymity (at the very least, I assume we'll
need one or more new 'standard' transaction types that clients

@_date: 2012-03-13 14:46:50
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.6rc3 binaries available 
Version 0.6 release candidate 3 binaries are available at:
  The big reason to run rc3 is to get the BIP30 security fix that takes
effect on March 15.
It also includes a fix to the problem of running rc1, upgrading, and
being stuck on the wrong block-chain fork

@_date: 2012-03-16 13:44:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] April 1 BIP16 switchover time is definite 
Support for BIP16 has been approximately 70% of hashing power for the
last two days, and is 54% over the last week, so we're going to
announce that the BIP16 switchover time of April 1 is final and
strongly encourage any pools/miners that haven't yet upgraded their
software to do so in the next two weeks or risk hashing on a minority
I'll be checking to make sure support doesn't slip before April 1.
I've learned a lot, and have started writing up a document that
suggests how we can make the next upgrade process less painful for
everybody; when I've got a reasonable draft I'll start a discussion
about it here.

@_date: 2012-03-16 20:14:26
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Urgent: Windows Bitcoin-Qt update 
Hash: SHA1
A potential security vulnerability has been discovered in the Windows
version of Bitcoin-Qt. If you are running Bitcoin-Qt versions 0.5
through 0.6 on Windows you should shut it down and upgrade to either
version 0.5.3.1 or 0.6rc4 NOW.
The command-line bitcoin daemon (bitcoind), Mac and Linux versions of
Bitcoin-Qt, and versions prior to 0.5 are not affected.
Due to the nature of the vulnerability, we believe it would be very
difficult for an attacker to do anything more than crash the
Bitcoin-Qt process. However, because there is a possibility of such a
crash causing remote code execution we consider this a critical issue.
Binaries are available at SourceForge:
If you have questions, feel free to drop by the  channel
on FreeNode IRC.

@_date: 2012-03-19 12:07:13
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Full disclosure on the Bitcoin-Qt on Windows 
Reposting from my tech blog:
  A major bug in Bitcoin-Qt on Windows went unnoticed for over four
months. The bug was in the bitcoin-qt.pro file, in these two lines of
  windows:LIBS += -lws2_32 -lshlwapi
  windows:DEFINES += WIN32
See the bug?
I don't-- I can't see it, because the problem was Bitcoin-Qt on
Windows should have been linked with the "mingw" multithreading
library and compiled with the -D_MT to turn on support for
multithread-safe C++ exception handling in the "mingw" library (you
can see the 3-line fix here).
There might be developers reading this who have had experience writing
multithreaded mingw-based C++ applications who will say "Duh! You guys
are idiots, everybody knows that!"
If that's you and you're interested in Bitcoin:  we need people like
you to help out! Review the code, review the build process, let us
know when we're being idiots. There seem to be a lot fewer Windows
developers willing to help out with Bitcoin than Linux or Mac
developers, which is unfortunate since a majority of our downloads are
Windows users.
Non-mingw-C++-multithreaded developers are reading this and thinking
"the bug was THERE?  Not in some  WINDOWS C++ code or some
slightly-out-of-date library that you were linking against?"
The other reason this bug went unnoticed for so long is because it
almost never matters. Bitcoin-Qt doesn't throw a lot of exceptions
normally, and most of the time the single-threaded-application
exception support in mingw works just fine. I'm still not sure exactly
what triggers the bug-- probably something like two threads throwing
exceptions at the same time, or one thread being interrupted while in
a try{} block and then resuming later and crashing because the
exception handling code is in a different state.
Matt Corallo deserves a lot of credit for being persistent and finding
the bug when investigating hard-to-reproduce reports of Bitcoin-Qt
crashing sometimes when run with the -server flag and handling
JSON-RPC requests. He was never able to get the code to crash when
running outside of the debugger, which is typical of bugs related to
multithreading. But he did see crashes not involving RPC requests, and
that is why we consider this a critical issue and are telling
everybody affected to upgrade immediately.
It it exploitable? Could an attacker craft bitcoin protocol messages
that triggered the bug and compromised Windows computers? Has it
already been exploited?
We don't know. We think it would be extremely difficult to craft a
usable exploit, partly because it is hard to even trigger the bug
reliably but also because Bitcoin-Qt has some security-in-depth to try
to prevent this type of bug from becoming exploitable.
If we're very careful and extremely lucky, this will be the last time
we have to tell users to shutdown and upgrade immediately because of
some potential vulnerability. But there is no such thing as perfect
security, and I expect that there will be another subtle bug either in
Bitcoin or in one of the many libraries we link against that becomes a
potential security issue.
That doesn't mean we give up and go back to paying each other with
cowrie shells; it means we assume that devices get compromised and
design around that assumption. I think that is a lesson that the
entire software industry needs to learn better.

@_date: 2012-03-22 13:06:20
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Please trim excessive quoting 
Messages over 40Kbytes big require moderator approval on this list; if
you want your messages to appear promptly, please trim excessive
quoting before hitting send.

@_date: 2012-03-26 19:40:18
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Version 0.6 release candidate 5 binaries 
Hash: SHA1
Barring any last-minute showstopper issues, the plan is for release
candidate 5 to become the official 0.6.0 release on Wednesday.
So please help look for last-minute showstopper issues:
The major changes from release candidate 4:
+ Much faster writing of blkindex.dat during initial blockchain
download (by modifying the default bdb environment cache settings)
+ A new policy for wallet.dat upgrades: use the old format unless the
user either uses a feature that requires an upgrade (encrypts the
wallet) or explicitly requests that the wallet be upgraded using the
new -upgradewallet option. New wallets will use new features (for 0.6,
the only new wallet feature is compressed public keys).
+ bugfix introduced in rc4 for an assertion failure that could occur
during blockchain reorganizations
+ New code for managing the addr.dat file that prevents an attacker
from filling it with bogus entries.

@_date: 2012-05-29 10:54:03
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Testnet reset for the 0.7 release 
Testnet "Mark III" will be part of the 0.7 release, and is now in the
master github branch.
"Mark III" because this is the third genesis block for the testnet. The
main reason for the reset is to get a more 'sane' test network; with the
BIP16 and BIP30 and testnet difficulty blockchain rule changes the old
testnet is a mess, with old clients serving up different, incompatible
chains. The good news is the mess uncovered a couple of
large-block-chain-reorganization bugs, but having a stable testnet to test
new implementations or services is more important.
Rules for tesnet3:
  + Minimum difficulty 1.0 (same as main net-- old testnet min difficulty
was 0.125)
  + max-difficulty-protection rule that allows blocks to be mined at min
difficulty if the block's timestamp is 20 minutes or more after the last
block AND the block isn't on a difficulty-adjustment boundary.
To make it easy to run either old code (using the old tesnet) and new code,
the wallet and blockchain are stored in $DATADIR/testnet3 instead of
And to make it easy to find other testnet3-running nodes, the IRC channel
used for bootstrapping is  (instead of The new testnet comes with a new blockchain that is full of interesting
test cases. In particular, there are test cases for:
 + BIP16; early blocks were generated with a timestamp before the BIP16
switchover date, and there are transactions that test the BIP16 switchover
 + Most of the enabled Script opcodes. I created thousands of transactions
that try to exercise edge cases in the Script interpreter. Missing are
comprehensive tests for the signature opcodes and SIGHASH_ modes.
 + Block acceptance rules, including the rule on maximum block size, block
times, etc (thanks to gmaxwell)
If you're re-implementing Bitcoin then accepting the Mark III testnet
blockchain is a good first test for compatibility. You'll still need to do
a lot of work to make sure you reject the same set of invalid transactions
or blocks as the original Bitcoin code.

@_date: 2012-11-06 13:47:34
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] IRC meeting agenda, 18:00 UTC Thursday 
Thursdays at 18:00 UTC (6PM Europe/1PM east US/10AM west US) seem to
be a good time for the core dev team to meet on the freenode IRC channel to chat.
I'd like to talk about:
o Can we put together a TODO list to get to a 0.8 release candidate ?
o Is it time to feature-freeze 0.8 and work on just testing the new
features and fixing existing bugs (the issues list keeps getting
longer and longer ... )?
o BIP process: are we happy with how it is working? What can we do to
improve it?
What else should we talk about?

@_date: 2012-11-26 17:37:31
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
This is the next big "lets all agree to do things the same way" thing
I think we should tackle. I'm particularly looking for feedback from
other bitcoin client developers, even if it is just a quick "looks
reasonable, if everybody else is going to do it then I will
(eventually) too..."
Thanks to Pieter Wuille and Mike Hearn for lots of feedback and
suggestions and brainstorming.
This document is online at If you respond to this message, please be considerate of people who
subscribe to the digest version of this mailing list and trim your
Invoices, Payments and Receipts for Bitcoin Transactions
This document proposes protocol buffer-based formats for signed,
authenticated "invoices" and "receipts" -- requests for payment, and
Separate documents propose an extension to the Bitcoin URI syntax and
new MIME types to support them.
The idea of a "payment protocol" to improve on Bitcoin addresses has
been around for over a year. Users have been asking for some features
in this proposal (like the ability to provide a refund address so
overpayments or refunds can be returned to customers without the need
to ask them for their address) for two or three years, and have
started to work around shortcomings in the Bitcoin payment process
with creative (but inefficient) uses of transactions.
The key features of this proposal are:
+ Requests for payment (Invoices) are tied to authenticated identities
using the only widely-deployed identity authentication system we have
right now (X.509 certificates signed by root certificate authorities)
+ Invoices include a user-friendly description of what the payment is for
+ Payments include where refunds should be sent
+ At the end of the payment process, the customer holds a
cryptographically signed Receipt that can be used as proof-of-payment
if there is any dispute with the merchant.
    message Receipt {
        required Payment payment = 1;
        required bool accepted = 2;
        optional string memo = 3;
    }
accepted : true if the Payment is accepted and will be broadcast on
the Bitcoin p2p network.
memo : UTF-8 encoded note that should be displayed to the customer
indicating that the transaction is complete.
    message SignedReceipt {
        required Receipt receipt = 1;
        required bytes signature = 3;
    }
A SignedReceipt is a Receipt signed using the private key
corresponding to the public key in the first certificate in the
Receipt->Payment->Invoice.x509chain and the HMAC SHA-256 algorithm.
Upon receiving a SignedReceipt, a Bitcoin client should validate the
signature and, if valid, display the Receipt.memo and store the
SignedReceipt as proof-of-payment.
If a SignedReceipt is not received for any reason (timeout, error) and
Payment.transactions has not been broadcast by the merchant on the
Bitcoin p2p network, then the Bitcoin client should assume that the
payment failed, inform the customer that the payment failed, and
return coins involved in the transaction to the customer's wallet.
The Invoice.x509chain (X.509 Certificate Chain) field contains the
X.509 public key certificate or certificate chain [RFC5280]
corresponding to the key used to digitally sign the Invoice and
Receipt. The certificate or certificate chain is represented as an
array of DER [ITU.X690.1994] PKIX certificate value. The certificate
containing the public key of the entity that digitally signed the
Invoice MUST be the first certificate. This MAY be followed by
additional certificates, with each subsequent certificate being the
one used to certify the previous one. The recipient MUST verify the
certificate chain according to [RFC5280] and reject the payment
request if any validation failure occurs.
*What should we say about root certificates and certificate management
in general? Any requirements, or leave it up to each Bitcoin client to
determine which root CA's are trustworthy, as happens with web
browsers? Gavin suggests trusting only (say) ten of the Extended
Validation authorities:
*X.509 is widely criticised for doing too much. However, it is the
Public Key Infrastructure (PKI) system we're stuck with. Do web
browsers / certificate authorities support the full X.509 spec, or
only a subset? Should Bitcoin clients only support some well-defined
subset of X.509 ? More research needed here... *
Use Cases
Merchant Payment Service
This use case starts with a multi-signature Bitcoin address or wallet,
with keys held by two different people (Alice and Bob). Payments from
that address/wallet must be authorized by both Alice and Bob, and both
are running multi-signature-capable Bitcoin clients.
Alice begins the payment process by getting a SignedInvoice from a
merchant that needs to be paid. She authorizes payment and her Bitcoin
client creates a Payment message with a partially-signed transaction,
which is then sent to Bob any way that is convenient (email
attachment, smoke signals...).
Bob's Bitcoin client validates the SignedInvoice and asks Bob to
authorize the transaction. He says OK, his Bitcoin client completes
the transaction by providing his signature, submits the payment to the
merchant, and then sends a message to Alice with the SignedReceipt he
received from the merchant, completing the payment process.
Design Notes
Why X.509 Certificates?
The Online Certificate Checking Protocol (OCSP) is supposed to be a
quick and easy way for applications to check for revoked certificates.
In practice, it doesn't work very well. Certificate Authorities have
no financial incentive to support a robust infrastructure that can
handle millions of OCSP validation requests quickly.
Ideally, Bitcoin clients would use OCSP to check certificate statuses
every time they received or re-used an Invoice. But if that results in
long pauses or lots of false-positive rejections (because an OCSP
endpoint is offline or overwhelmed, perhaps) then merchants and
customers might revert to just using "never fails" Bitcoin addresses.
Public-Key Infrastructure (X.509) working group :
RFC 2560, X.509 Internet Public Key Infrastructure Online Certificate
Status Protocol - OCSP : Protocol Buffers : See Also
Javascript Object Signing and Encryption working group :
sipa's payment protocol proposal: ThomasV's "Signed Aliases" proposal :

@_date: 2012-11-26 20:09:25
@_author: Gavin 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Supporting DNSSEC/DANE in the future when they are widely deployed is a great idea.
Note that the x509chain field is 'repeated', and any repeated field may have zero entries. So I would suggest supporting other PKI systems in the future by adding optional new fields (for maximum compatibility or security merchants might want to include both a x509chain AND Gavin Andresen

@_date: 2012-11-27 09:05:13
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
RE: SignedReceipt:  I agree it is superfluous.  I'll remove it from the spec.
RE: "it is controversial use of the host key to use it for digital
signing of documents"  :  The idea of embedding a x509 certificate
chain comes from the IETF's JSON Object Signing and Encryption working
group "JWS" specification, so I can't be TOO controversial.
RE: the ifex-project and other electronic invoicing standards:  Thanks
for the pointers, Walter! I'm all for adopting the best ideas that
have come before, as long as we end up with something useful and small
enough to convince ourselves it is as secure as we can make it. I
looked at the ifex spec, and quickly got lost. It would help me if you
could write up what our motivating use cases would look like if
implemented on top of ifex.
RE: jgarzik's suggestion to allow txids in the Payment: that worries
me, because it is trivial to create several different variations of
the same transaction (same inputs to same outputs) with different
txids (re-signing inputs uses a different signature nonce, which
changes the signature/txid, for example).
RE: using self-signed certificates:  as Mike said, I assume Bitcoin
clients will have some way of managing root certificates, so experts
could add trusted self-signed certs.

@_date: 2012-11-27 09:26:07
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
One more thought:
RE: "Receipt" verus "Acceptance" :
I believe "Receipt" is the right term-- it means "I got your payment",
NOT "your payment has cleared."  E.g. if I hand a merchant a paper
check they'll hand me a receipt, but the check could still bounce.
That's the analogy here-- a merchant might give you a receipt, but if
the transaction is rejected by the network for whatever reason (Finney
attack maybe) you cannot expect to go to court with your
invoice/receipt and claim you made a valid payment.

@_date: 2012-11-27 16:39:55
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Spec updated: Notable changes are:
+ Removed SignedReceipt
+ Replaced Invoice.x509chain with a "pki_type" and "pki_data" to make
using other identity systems cleaner.
+ Added a "Why not an existing electronic invoice standard?" section
to the design notes

@_date: 2012-11-28 09:09:45
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
RE: Changing SignedInvoice's invoice field to 'bytes serialized_invoice':
Good Idea, I agree it will avoid potential issues. I think it then
makes sense to pull the pki_type and pki_data into SignedInvoice, too,
and specify that the signature is on the SHA256-HMAC of pki_type,
pki_data, and serialized_invoice (being careful to combine them in a
way that is secure).
RE: Changing Payment to include just merchant_data and not the entire Invoice:
Agreed, good idea.
RE: Mr. Stanish's suggestion to punt all of this and wait for a Grand
Unified Solution:
No, we have problems that need a solution right now. And, having
written one (I was the lead author of the ISO/IEC 14772-1
international standard) I'm very pessimistic about your chances for
anything like IFEX to actually be adopted.

@_date: 2012-11-29 11:11:51
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
RE: Roy Badami's comments on edge cases around submitting a Payment
message to a merchant and then not receiving a timely response:
I agree, it is messy.
I'm hesitant to try to specify One True Way of handling it in the
spec; I've got a feeling that this might be a place where different
implementations might try different things, with the best
implementation winning.
For example, if some future nifty-keen Bitcoin client is re-using an
old Invoice to send a monthly subscription payment and they can't
contact the paymentURI, then the right thing is probably for it to
retry once a day for three or four days and if they all fail then give
up and tell the user that the service is no longer in business (or
changed their paymentURI without leaving behind a redirect).
If it has a single-use Invoice created a minute or two ago, the right
logic might be:
  + If the paymentURI is completely non-responsive, just error and
tell the user "payment failed"
  + If connected to the paymentURI and payment sent, but disconnected
before receiving a response, then try to send-to-self the coins to
cancel payment.
Again, I'm not at all sure that is the best way to handle it;
implementors have the right incentives to give their users the best
user experience, so I feel comfortable leaving the spec fuzzy for now.

@_date: 2012-11-29 12:30:33
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol Proposal: 
Mike Hearn has experimented with in-person payments using
bluetooth/NFC on a phone, where the merchant has full Internet
connectivity but the phone might only be able to connect to the
merchant via a Bluetooth/NFC paymentURI.
I think I agree with you, though: if the device DOES have
bitcoin-p2p-network-connectivity, then expecting the client to
broadcast the transaction might be cleaner.
However, if a connection to the paymentURI is made and the transaction
data has been sent, clients have to deal with the case where the
merchant also broadcasts the transaction, no matter what the spec says
and even if the merchant sends an "accepted : false" response.

@_date: 2012-10-02 13:43:51
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment protocol thoughts 
I agree we need a payment protocol, but instead of thinking of all of the
things we might possibly want I would like to solve a few boring problems
that we have right now.
Absolutely critical:
+ Bitcoin addresses by themselves are insecure against man-in-the-middle
attacks. We need a payment protocol so if you get a donation link for
"Bitcoin Foundation" in an email message and click on it you can be
reasonably certain that your coins will actually go to the Foundation and
not some hacker at your ISP that modified the email message.
+ After sending payment I should have a receipt that proves I followed the
payee's instructions, so if the payee says they never received the funds I
can prove that it wasn't my fault.
+ Protocol for gathering signatures from multiple devices
(extension/variation of the basic payment protocol, I think).
Not absolutely necessary, but I think v1 should have it anyway:
+ Where-to-send-refund information included with payments, so
overpayments/refunds can be handled efficiently and displayed intelligently
in the customer's wallet.
Everything else I think can wait.

@_date: 2012-10-03 13:30:44
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: Re: Bitcoin Testing Project 
I had hope the Testing Project would be self-organizing, with somebody
taking on the QA lead role and figuring out the hard questions like:
+ How to do fundraising?
+ If/when bitcoins are available, how to decide who gets rewarded for what?
+ If somebody wants to help, how do they start?
Steve jumped in and started creating a gazillion tests cases, which is
great, but creating test cases isn't the hard part. Creating a
"community" of testing that gets things done is the hard part that I,
frankly, don't have time to do.
I hoped that the BetterMeans platform would help, but it sounds like
it was more of a hindrance than a help.  Ok:  live and learn.  Failed
experiment, lets move on...
So, RE: moving on:  I'd like to tag a 0.7.1rc1 release in the next few
days (I'll start another thread about that). How about a very
short-term goal of getting these QA deliverables:
1. A process for QA testers to sanity-test release builds, and
sign-off as "Tested/problems found" or "Tested/OK"
2. Some place online I can look to see if all of our supported
platforms have been tested before promoting a release candidate to
"final release"
PS: Thanks to Peter for responding to the "what's the relationship
between the Foundation and the Testing Project" (executive summary: no
relationship right now).

@_date: 2012-10-03 13:49:22
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.7.1 release 
There is consensus that we need to do a 0.7.1 release to fix the
"click on a bitcoin: URI and nothing happens" bug on Windows.
I would really like to fix the "I upgraded from a binary running an
incompatible version of BDB and now I get a DB_RUNRECOVERY error on
startup" problem, too, and I've got a pull request that fixes half of
that problem (plus a bunch of other "my wallet is broken" cases):
"Handle corrupt wallets gracefully" :
This pull request:
"Add -reindex, to perform in-place reindexing of blockchain data
files" : ... could be the basis for fixing the other half of the problem (if
blkindex.dat is bad, delete it and re-create it from the blk000?.dat
Are there any other very-high-priority pull requests that should go
into a 0.7.1 release?
I'd like to pull:
"P2P: Do not request blocks from peers with fewer blocks than us" :
"In listaddressgroupings push down the IsMine check to run on each
input." : ... and these which could be considered fixes to the new raw transactions API:
"Add redeemScript to raw transactions API"  :
"Add new RPC "lockunspent", to prevent spending of selected outputs" :
Gavin Andresen

@_date: 2012-10-11 11:46:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.7.1 release candidate 1 ready for testing 
Any progress on a release candidate QA sanity testing plan?
Bitcoin version 0.7.1 release candidate 1 is now available from:
  This is a bug-fix minor release.
New features
* Added a boolean argument to the RPC 'stop' command, if true sets
  -detachdb to create standalone database .dat files before shutting down.
* -salvagewallet command-line option, which moves any existing wallet.dat
  to wallet.{timestamp}.dat and then attempts to salvage public/private
  keys and master encryption keys (if the wallet is encrypted) into
  a new wallet.dat. This should only be used if your wallet becomes
  corrupted, and is not intended to replace regular wallet backups.
* Import $DataDir/bootstrap.dat automatically, if it exists.
Dependency changes
* Qt 4.8.2 for Windows builds
* openssl 1.0.1c
Bug fixes
* When running -testnet, use RPC port 18332 by default.
* Better detection and handling of corrupt wallet.dat and blkindex.dat files.
  Previous versions would crash with a DB_RUNRECOVERY exception, this
  version detects most problems and tells you how to recover if it
  cannot recover itself.
* Fixed an uninitialized variable bug that could cause transactions to
  be reported out of order.
* Fixed a bug that could cause occasional crashes on exit.
* Warn the user that they need to create fresh wallet backups after they
  encrypt their wallet.

@_date: 2012-10-21 13:05:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Public key and signature malleability 
Any objections from other transaction-validating implementations?
I strongly support more precisely defining the transaction validity
rules by changing the reference implementation.

@_date: 2012-10-24 14:54:15
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
RE: sharing parts of the merkle branches when returning a 'merkleblock' :
I think I agree that complicating the BIP for what should be a very
rare case (more than a handful of transactions in a block match the
transactions in your wallet) is the right decision.
I want to make sure I'm understanding this bit correctly:
"In addition, because a merkleblock message contains only a list of
transaction hashes, any transactions that the requesting node hasn't
either received or announced with an inv will be automatically sent as
well. This avoids a slow roundtrip that would otherwise be required
(receive hashes, didn't see some of these transactions yet, ask for
Requiring serving/relaying nodes to keep track of which transactions
they have or have not sent to their peers makes me nervous. I think
requiring an extra 'inv' round-trip would be simpler to implement and
less likely to lead to some kind of DoS attack.

@_date: 2012-10-24 16:29:07
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Draft BIP for Bloom filtering 
Oops, right. That memory usage is bounded right now by bounds on the
memory pool size, though, right? (I'm being lazy and not digging into
that code)
What is the worst-case for an attacker interested in trying to get you
to saturate your upstream bandwidth or use lots of memory?  Set a
bloom filter that matches everything, and then start requesting old
blocks in the chain? It would be nice if the worst-case was no worse
than the worst-case we've got now (... requesting full, old

@_date: 2012-09-17 20:03:46
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin-Qt/bitcoind version 0.7 released 
Bitcoin version 0.7.0 is now available for download at:
  We recommend that everybody running prior versions of bitcoind/Bitcoin-Qt
upgrade to this release.
Please report bugs using the issue tracker at github:
  Project source code is hosted at github; you can get
source-only tarballs/zipballs directly from there:
    # .tar.gz
    # .zip
Ubuntu Linux users can use the "Personal Package Archive" (PPA)
maintained by Matt Corallo to automatically keep
bitcoin up-to-date.  Just type
  sudo apt-add-repository ppa:bitcoin/bitcoin
in your terminal, then install the bitcoin-qt package:
  sudo apt-get install bitcoin-qt
How to Upgrade
* Replaced the 'getmemorypool' RPC command with 'getblocktemplate/submitblock'
  and 'getrawmempool' commands.
* Remove deprecated RPC 'getblocknumber'
Bitcoin Improvement Proposals implemented
* IPv6 support
* Tor hidden service support (see doc/Tor.txt)
* Attempts to fix "stuck blockchain download" problems
* Replace BDB database "addr.dat" with internally-managed "peers.dat"
  file containing peer address data.
* Lower default send buffer from 10MB to 1MB
* proxy: SOCKS5 by default
* Support connecting by hostnames passed to proxy
* Add -seednode connections, and use this instead of DNS seeds when proxied
* Added -externalip and -discover
* Add -onlynet to connect only to a given network (IPv4, IPv6, or Tor)
* Separate listening sockets, -bind=
Qt GUI
* Add UI RPC console / debug window
* Re-Enable URI handling on Windows, add safety checks and tray-notifications
* Harmonize the use of ellipsis ("...") to be used in menus, but not on buttons
* Add 2 labels to the overviewpage that display Wallet and Transaction
status (obsolete or current)
* Extend the optionsdialog (e.g. language selection) and re-work it to
a tabbed UI
* Merge sign/verify message into a single window with tabbed UI
* Ensure a changed bitcoin unit immediately updates all GUI elements
that use units
* Update QR Code dialog
* Improve error reporting at startup
* Fine-grained UI updates for a much smoother UI during block downloads
* Remove autocorrection of 0/i in addresses in UI
* Reorganize tray icon menu into more logical order
* Persistently poll for balance change when number of blocks changed
* Much better translations
* Override progress bar design on platforms with segmented progress
bars to assist with readability
* Added 'immature balance' display on the overview page
* (Windows only): enable ASLR and DEP for bitcoin-qt.exe
* (Windows only): add meta-data to bitcoin-qt.exe (e.g. description)
Internal codebase
Thanks to everybody who contributed to this release:
Chris Moore
Christian von Roques
David Joel Schwartz
Douglas Huff
Gavin Andresen
Giel van Schijndel
Gregory Maxwell
Jeff Garzik
Luke Dashjr
Matt Corallo
Michael Ford
Michael Hendricks
Peter Todd
Philip Kaufmann
Pieter Wuille
R E Broadley
Ricardo M. Correia
Rune K. Svendsen
Scott Ellis
Stephane Glondu
Wladimir J. van der Laan
Thanks to Sergio Lerner for reporting denial-of-service
vulnerabilities fixed in this release.

@_date: 2012-09-26 14:09:55
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin Testing Project 
There are test cases that can be automated. That's Jenkins, and those will
be run automagically.
Then there are tests that cannot be automated; things like "Does the GUI
look OK on all of the platforms that we support (Windows XP/2000/Vista/7/8,
Ubuntu/Debian blah with window managers foo and bar, OSX 10.5/6/7/8)."
Thanks to Matt, we're doing great with automated functional test cases (can
always do better, of course).
We're failing on simple, boring stuff like making sure we actually run on
all of the platforms that we say we run on BEFORE final release. That is
where I think a QA team can add a lot of value.
Steve: I'm worried you're over-designing The Process. A release acceptance
test plan could be nothing more than a step-by-step checklist on a wiki
page, Google Doc, or Drobox shared folder...

@_date: 2013-04-03 12:05:39
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] bitcoin pull requests 
I would rather we spend time working to make users' bitcoins safe EVEN IF
their bitcoin software is compromised.
Eliminate the "if you get a bad bitcoin-qt.exe somehow you're in big
trouble" risk entirely, instead of worrying about unlikely scenarios like a
timing attack in between ACKs/pulls. Eliminate one piece of software as the
possible single point of failure...

@_date: 2013-04-18 09:37:46
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Anti DoS for tx replacement 
I don't want to spend any time thinking about memory pool transaction
replacement until after we pay some technical debt:
+ Memory-limited memory pool, with relay policy matching block-creation
+ Child-pays-for-parent fees
+ Auto-computed fees, based on transactions moving from the memory pool
into blocks

@_date: 2013-04-24 10:51:57
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP21 bitcoin URIs and HTML5 
amending the BIP? Do we need to create a new one and mark the old one as
replaced, or can we just fix it in place given the relatively exotic nature
of most of the issues?
Those all sound like bugs in the BIP; I think they should just be fixed, I
don't think we need a new BIP.
I vote for a new meta-data item in the BIP header:
  Corrected:

@_date: 2013-04-24 11:22:44
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Time for a 0.8.2 release 
Consensus in  chat is that it is time to do a 0.8.2 release. A
few important bugs have been fixed, and the goal will be to get a 0.8.2
final release before the May 15'th hard fork deadline.
Pieter has already started going through the issues list; help with
testing, debugging, and fixing high-priority issues is very welcome. I'll
also be going through the issues list and marking any issues I think need
to be fixed with the '0.8.2' milestone.
If translation work needs to be done, now is a great time to do it.
We still don't have a basic QA checklist for testing of release candidates;
I'll commit to spending a little of the remaining "Bitcoin Testing Project"
bitcoins to whoever contributes to creating one.

@_date: 2013-04-25 21:07:07
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Cold Signing Payment Requests 
As usual, our bottleneck is code review / testing, so it would be nice if
you spent some time reviewing code and helping test v0.9 so we can actually
ship a v1 sometime in the next several months before you start working on a

@_date: 2013-04-30 09:14:53
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Cold Signing Payment Requests 
RE: Timo's proposal for protecting the refund address:
Seems to me there are two risks:
1) The risk that the merchant's web server will be compromised and the
attacker will redirect refunds
2) The risk that the merchant will miss payments because they miss a POST
to the payment_url (maybe the customer's machine crashes during the HTTPS
If payments are a lot more common than refunds, then (2) will outweigh (1).
I also think an attacker who compromises the front-end web server would
probably just have it start generating plain-old pay-to-bitcoin-address
payment requests, and hope that lots of customers pay them directly before
the attack is discovered.

@_date: 2013-08-08 07:10:05
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
RE: making the bitcoin address in the bitcoin: URI optional:
Ok, I'm convinced, sometimes merchants won't want or need backwards
compatibility and sometimes it won't make sense for them to put an
arbitrary bitcoin: address there.
RE: should the customer's machine not broadcast the transaction:
I'd like to hear from other wallet implementors. Do you have a notion
of 'locked inputs' ?  The tricky bit in constructing a transaction but
not broadcasting it right away is the inputs must be locked, so
they're not accidentally double-spent.
I'd also like to hear from merchants: any issue with your payment
processing server having "broadcast transaction" functionality?
My biggest worry is that the payment protocol will not get wide
support if it is too hard to implement.

@_date: 2013-08-08 10:48:07
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
I've updated the BIP 72 spec at  so
the bitcoin address is optional:
"If the "request" parameter is provided and backwards compatibility is
not required, then the bitcoin address portion of the URI may be
omitted (the URI will be of the form: bitcoin:?request=... )."
The spec already said what should happen if both request and
address/amount/etc were given:
"it should ignore the bitcoin address/amount/label/message in the URI
and instead fetch a PaymentRequest message and then follow the payment
I think this gives us a smooth, clear upgrade path.

@_date: 2013-08-10 07:51:00
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Optional "wallet-linkable" address format 
As Mike said: the payment protocol doesn't use bitcoin addresses under
the covers.
It is also designed to be easily extensible, so if you want the server
to send the wallet software a public key and multiplier, then add
"publickey" and "multiplier" optional fields to the PaymentDetails (or
maybe Output) message.

@_date: 2013-08-15 10:29:40
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Version 0.9 goals 
It feels to me like we're close to a 0.9 "feature freeze" / start of
release cycle; I'd like to talk a little bit about what we'd like to see in
the final 0.9 release.
My list:
Bug:  I'd really like to see the leveldb corruption issue (mostly on OSX,
it seems) fixed. This is hard because it can't be reliably reproduced, and,
at least on my machine, takes weeks to occur. Help needed to reproduce/fix,
see  for what we know about
the problem.
Payment Protocol support is ready to be pulled (
 . Unless there are major
objections, I will pull it tomorrow (it has already gone through two rounds
of bounty-driven QA testing, so I'm convinced it is ready).
I'd love for 0.9 to contain sipa's "headers first" initial block download
optimization; I think it is a big enough improvement to justify making the
0.9 test/release cycle longer.
Coin control (
The autotools work (
Gitian-build with the latest openssl and Qt5. Perhaps update the version of
Debian VMs that we gitian-build with.
I plan on spending about half my time on code review and helping get pull
requests tested, and the other half of my time working on code that
probably won't make it into the 0.9 release.

@_date: 2013-08-16 11:00:38
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Gavin's post-0.9 TODO list... 
Mike asked what non-0.9 code I'm working on; the three things on the top of
my list are:
1) Smarter fee handling on the client side, instead of hard-coded fees. I
was busy today generating scatter-plots and histograms of transaction fees
versus priorities to get some insight into what miner policies look like
right now.
2) "First double-spend" relaying and alerting, to better support low-value
in-person transactions.  Related:
*Have *a *Snack*, Pay with
3) Work on 2-3 whitepapers on why we need to increase or remove the 1MB
block size limit, how we can do it safely, and go through all of the
arguments that have been made against it and explain why they're wrong.

@_date: 2013-08-19 08:22:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] NODE_BLOOM BIP 
Mike pointed out exactly the reason I oppose a NODE_BLOOM service bit: I
also think it is a bad idea to start making various bits and pieces of the
protocol optional.
It is bad for privacy (easier to fingerprint nodes) and bad for
decentralization (fewer nodes support your required feature set). And every
bit you add can give you an exponential number of combinations your QA team
should test.
I'd say the same thing about NODE_TRANSACTION ("I don't know about blocks,
have and NODE_BLOCK bits.

@_date: 2013-08-19 10:59:18
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bloom io attack effectiveness 
Peter said:
"In any case given that SPV peers don't contribute back to the network
they should obviously be heavily deprioritized and served only with
whatever resources a node has spare."
This seems very much like a "cut off your nose to spite your face" solution.
SPV peers are INCREDIBLY IMPORTANT to the growth of Bitcoin; much more
important than nodes that have the bandwidth and disk I/O capability of
being a full node.  Bitcoin will be just fine if there are never more than
10,000 big, beefy, full nodes forming the backbone of the network, but will
be NOTHING if we don't support tens of millions of lightweight SPV devices.
Ok, that's an exaggeration, Bitcoin would be just fine in an Electrum model
where tens of millions of lightweight devices rely 100% on a full node to
operate. But I would prefer the more decentralized, less-trust-required SPV

@_date: 2013-08-20 09:19:38
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
No. There are XML-based (shudder) standards for electronic invoicing that
include all sorts of bells and whistles; the PaymentDetails message could
easily encapsulate one of them in an 'invoice' field extension. Or we could
reinvent the wheel and come up with our own, but I'd rather use an existing
standard (or maybe a subset of an existing standard).
I didn't want to wade into that swamp for the 1.0 version of the payment
"Two Burgers, one Club Mate" seems pretty user-friendly.
Second, is there a way to communicate acceptance levels of TX
No, because the Payment->PaymentACK communication round-trip is done in
one, non-persistent http request-response round-trip.
I don't think we want to allow merchants to push messages to the wallet
(wouldn't take long for merchants to use the opportunity to push annoying
advertising at me, I think), and I don't think we want wallets to poll the
merchant. Although maybe a payment protocol version 2.0 feature could be a
PaymentACK extension that says "ask me how the transaction is going at THIS
URL in THIS many minutes."

@_date: 2013-08-21 07:28:06
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] There will be a 0.8.4 release 
There have been a few not-quite-serious-enough-to-justify-a-release
security fixes that, along with a couple of serious bugs, we think together
DO justify a new 0.8.* release.
So I just created a 0.8.4 branch, based on the 0.8.3 branch, and will be
cherry-picking from the master branch.
Planned changes from the 0.8.3 release:
42656ea  Make RPC password resistant to timing attacks
159bc48  Simplify storage of orphan transactions, fix CVE-2013-4627
37c6389  Performance optimization for bloom filters (help mitigate
potential DoS attack discussed last week)
Bug fixes:
9bf2a4ab  Fix multi-block reorg transaction resurrection
bf81a3ef  Fix Gnome bitcoin: URI handler
f0784ac4  Fix non-standard disconnected transactions causing mempool orphans
2461aba1  Mempool consistency check
pull 2916  Import OSX fsync change from LevelDB subtree  (will hopefully
fix the random-OSX leveldb corruption issues)
There are lots of little fixes that could be included, but those will wait
for the 0.9 release.

@_date: 2013-08-22 08:19:39
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.8.4 release candidate 2 : please help test 
0.8.4 release candidate 2 is available at:
  This is a maintenance release to fix a critical bug and fix three minor
security issues; it contains very few changes from the 0.8.3 release.
The two changes that need testing:
1) OSX FD_FULLSYNC leveldb corruption fix. If you have had trouble with
database corruption on OSX, please try this release and let us know if it
seems to help. Also let us know if you experience any performance problems
with this release.
2) Bloom filter optimization. If you have code that uses the bloom-filtered
block (merkleblock) protocol, please try it against this release and let us
know if you run into any issues.
PS: a critical last-minute bug was found in release candidate 1; it was
never released.

@_date: 2013-08-28 11:40:28
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP 72 updated: require Accept HTTP header 
============================== START ==============================
I just added a requirement to the BIP 72 (bitcoin: URI payment protocol)
Wallets must include an Accept HTTP header in HTTP requests:
Accept: application/bitcoin-paymentrequest
... and submitted a pull request so the reference implementation follows
the spec.
Thanks to Stephen/Jeff at BitPay for the suggestion. I'll make a similar
change to BIP 70 and require wallets set Accept:
application/bitcoin-paymentrequestack when sending the Payment and
expecting a PaymentACK message in return.

@_date: 2013-12-03 11:40:35
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Lets bang out a merchant-pays-fee extension.
How about:
    optional uint64 allowfee    tag number=1000
Allow up to allowfee satoshis to be deducted from the amount paid to be
used to pay Bitcoin network transaction fees. A wallet implementation must
not reduce the amount paid for fees more than allowfee, and transaction
fees must be equal to or greater than the amount reduced.
Rationale: we don't want wallet software giving users discounts-- sending
transactions that are amount-allowfee without paying any fee.  We also want
to allow users to pay MORE in fees, if they need to (fragmented wallet,
maybe, or big CoinJoin transaction) or decide to.
PS: I think there was also consensus that the BIP72  request=...   should
be shortened to just r=... (save 6 chars in QR codes).  Unless somebody
objects, I'll change the BIP and the reference implementation code to make
it so...

@_date: 2013-12-03 21:07:30
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
Ok, revised spec:
message PaymentDeatils {
    ...
    optional uint64 minfee    tag number=8
Pay at least minfee satoshis in transaction fees. Wallet software should
add minfee to the amount the user authorizes and pays, and include at least
minfee in the transaction created to pay miner's transaction fees. Wallet
software may request that the user pays more, if it must create a complex
transaction or judges that minfee is not sufficient for the transaction to
be accepted by the network..
Making it fee-per-kilobyte is a bad idea, in my opinion; users don't care
how many kilobytes their transactions are, and they will just be confused
if they're paying for a 10mBTC burger and are asked to pay 10.00011 or
9.9994 because the merchant has no idea how many kilobytes the paying
transaction will be.

@_date: 2013-12-03 21:41:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
If users want to pay with a huge transaction then it seems to me the user
should cover that cost. Allowing users to pay merchants with 100K
transactions full of dust and expecting them to eat the cost seems like a
great way to enable bleed-the-merchant-dry attacks.
RE: hiding or showing fees:  I pointed out to Peter that there doesn't have
to be One True Answer.  Let wallets experiment with either hiding or
exposing fees, and may the best user experience win.

@_date: 2013-12-03 21:54:41
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Floating fees and SPV clients 
No, they can't, at least not in bitcoin-qt:  when the user pokes the SEND
button, the transaction is broadcast on the network, and then the merchant
is also told with the Payment/PaymentACK round-trip.
Allowing merchants to cancel (e.g. having a PaymentNACK) makes
implementation harder, and brings up nasty issues if we want to allow
CoinJoin or CoinJoin-like transactions as payments to merchants.
 Bitcoin-Qt ALREADY allows you to pay several PaymentRequests with one
transaction; handling the case where one merchant gives you a PaymentACK
and another gives you (or wants to give you) a PaymentNACK is a nightmare.
Gavin Andresen

@_date: 2013-12-06 09:16:47
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Move authorative source for BIPs to git 
RE: replace BIPs on the wiki with links to github documents: agreed.
Wladimir or Gregory: can one of you update BIP 0001 to describe the Proper
Process for creating/editing a BIP? It doesn't mention the github repo at
all right now.

@_date: 2013-12-06 16:52:02
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.8.6 release candidate 1 
0.8.6 release candidate 1 is available from:
  Please help sanity-test, especially if you are running OSX or Windows.

@_date: 2013-12-09 08:44:26
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Dedicated server for bitcoin.org, 
That is a really bad idea.  If there is not a CLEAR answer to "who admins
it", there will be a bunch of "I thought YOU were applying security
patches... no, I thought YOU were..." the first time it gets hacked.
So, the question is:  who wants to take responsibility for keeping
bitcoin.org safe and secure?
I am not going to do that, I've got too many other things to worry about.
It is exactly the type of thing the Foundation was setup to do, but if
y'all want to create some other organization to do it, then please make it

@_date: 2013-12-09 16:14:37
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.8.6 release candidate 1 
I see:
  db/autocompact_test.cc
... which I assume is a leveldb unit test file that should be in
Not a showstopper bug.
Given we've had hundreds of downloads and no reports of insanity, I think
we should tag v0.8.6 today (same commit as v0.8.6rc1) and ship it.

@_date: 2013-12-10 08:06:23
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Monetary Authority for Bitcoin 
That is like saying "We need a way to travel around the world quickly.
There will be an anti-gravity technology; how this works is not something
I'm personally focused on."
Or, in other words, you are ignoring exactly the sticky, difficult problem
that would have to be solved for your proposal to have any chance of

@_date: 2013-12-13 10:20:50
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Merge avoidance and P2P connection 
Why would there be an iteration count? The payer would handle that,
wouldn't they?
If the use case is:  I give the Foundation a "here's where to pay my
salary" PaymentRequest, maybe with several Outputs each having a different
xpubkey, then it seems to me the Foundation's wallet software should take
care of iterating.
(either saving state, so it knows it used xpubkey+10 last month and should
use xpubkey+11 this month, or maybe it knows I'm paid monthly and just uses

@_date: 2013-02-08 18:49:09
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.8.0rc1 status 
Linux builds of 0.8.0rc1 are in good shape; easily gitian-reproduceable.
Windows builds are varying with every compile, and I think I finally
figured out why: we are not passing the -frandom-seed flag down into
the leveldb build (I used objdump to dump two different binaries, and
they differed only in the names of some leveldb objects). That should
be an easy makefile fix.
The OSX build is in pretty good shape, but needs
 to compile.
So: I think the path forward is to announce 0.8.0rc1 with the binaries
we've got, to get more testing.
Then before final release (or rc2, if that is needed) pull  and
create and pull a patch to fix the windows non-determinism problem.
I'm done for today, but should have time to sign the windows setup.exe
and send out a rc1 announcement tomorrow.

@_date: 2013-02-09 10:50:34
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Version 0.8.0rc1 ready for testing 
Bitcoin version 0.8.0 release candidate 1 is now available from:
  This is a major release designed to improve performance and handle the
increasing volume of transactions on the network.
Please report bugs using the issue tracker at github:
  Release-candidate 1 notes:
The OSX binary reports its version as "0.8.0rc1-1-gba1d080-beta" due to
issue  . This will be fixed
before the final 0.8.0 release.
The Windows binaries could not be reproducibly built, due to issue
 . This will also be fixed
before the final 0.8.0 release.
How to Upgrade
This release no longer maintains a full index of historical transaction ids
by default, so looking up an arbitrary transaction using the getrawtransaction
RPC call will not work. If you need that functionality, you must run once
with -txindex=1 -reindex=1 to rebuild block-chain indices (see below for more
Mac and Windows binaries are signed with certificates owned by the Bitcoin
Foundation, to be compatible with the new security features in OSX 10.8 and
Windows 8.
LevelDB, a fast, open-source, non-relational database from Google, is
now used to store transaction and block indices.  LevelDB works much better
on machines with slow I/O and is faster in general. Berkeley DB is now only
used for the wallet.dat file (public and private wallet keys and transactions
relevant to you).
Pieter Wuille implemented many optimizations to the way transactions are
verified, so a running, synchronized node uses much less memory and does
much less I/O. He also implemented parallel signature checking, so if you
have a multi-CPU machine all CPUs will be used to verify transactions.
New Features
"Bloom filter" support in the network protocol for sending only
relevant transactions to
lightweight clients.
contrib/verifysfbinaries is a shell-script to verify that the binary downloads
at sourceforge have not been tampered with. If you are able, you can help make
everybody's downloads more secure by running this occasionally to check PGP
signatures against download file checksums.
contrib/spendfrom is a python-language command-line utility that demonstrates
how to use the "raw transactions" JSON-RPC api to send coins received
from particular
addresses (also known as "coin control").
New/changed settings (command-line or bitcoin.conf file)
lockunspent / listlockunspent allow locking transaction outputs for a
period of time so
they will not be spent by other processes that might be accessing the
same wallet.
addnode / getaddednodeinfo methods, to connect to specific peers
without restarting.
importprivkey now takes an optional boolean parameter (default true)
to control whether
or not to rescan the blockchain for transactions after importing a new
private key.
Important Bug Fixes
Qt 4.8.3 (compiling against older versions of Qt 4 should continue to work)
Thanks to everybody who contributed to this release:
Alexander Kjeldaas
Andrey Alekseenko
Arnav Singh
Christian von Roques
Eric Lombrozo
Forrest Voight
Gavin Andresen
Gregory Maxwell
Jeff Garzik
Luke Dashjr
Matt Corallo
Mike Cassano
Mike Hearn
Peter Todd
Philip Kaufmann
Pieter Wuille
Richard Schwab
Robert Backhaus
Rune K. Svendsen
Sanjay Ghemawat
Sergio Demian Lerner
Wladimir J. van der Laan

@_date: 2013-02-12 12:42:37
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] RFC: empty scriptPubKeys and OP_RETURN 
First: I really like the fidelity bond concept, and want to see it happen.
RE: OP_RETURN : I've got a knee-jerk opposition to the OP_RETURN opcode,
because it was the cause of the nastiest bug ever Bitcoin history. So I'd
be more comfortable using either OP_FALSE or OP_INVALIDOPCODE for the
"provably unspendable" transaction.
RE: anyone-can-spend transactions:  Thinking aloud... I wonder if we might
inadvertently cause "spend storms" on the network; if suddenly there are 11
BTC sitting in an anybody-can-spend txout, I could imagine EVERYBODY on the
network trying to race each other to spend it (maybe assuming that there
are a few miners on old versions of the software who are too dumb to claim
it for themselves).

@_date: 2013-02-13 16:02:16
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Incorporating block validation rule 
I disagree with Gregory on this.  I believe that Bitcoin CAN meet its
security and decentralization promises without any hard limit on block
I had a fruitful discussion about this with an economist friend this
weekend, and I'll eventually getting around to writing up why I believe
raising the block size limit will not be a problem.

@_date: 2013-02-19 14:27:50
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin-Qt / bitcoind version 0.8.0 released 
Bitcoin-Qt version 0.8.0 are now available from:
  This is a major release designed to improve performance and handle the
increasing volume of transactions on the network.
Please report bugs using the issue tracker at github:
  How to Upgrade
This release no longer maintains a full index of historical transaction ids
by default, so looking up an arbitrary transaction using the
RPC call will not work. If you need that functionality, you must run once
with -txindex=1 -reindex=1 to rebuild block-chain indices (see below for
Mac and Windows binaries are signed with certificates owned by the Bitcoin
Foundation, to be compatible with the new security features in OSX 10.8 and
Windows 8.
LevelDB, a fast, open-source, non-relational database from Google, is
now used to store transaction and block indices.  LevelDB works much better
on machines with slow I/O and is faster in general. Berkeley DB is now only
used for the wallet.dat file (public and private wallet keys and
relevant to you).
Pieter Wuille implemented many optimizations to the way transactions are
verified, so a running, synchronized node uses less working memory and does
much less I/O. He also implemented parallel signature checking, so if you
have a multi-CPU machine all CPUs will be used to verify transactions.
New Features
"Bloom filter" support in the network protocol for sending only relevant
transactions to
lightweight clients.
contrib/verifysfbinaries is a shell-script to verify that the binary
at sourceforge have not been tampered with. If you are able, you can help
everybody's downloads more secure by running this occasionally to check PGP
signatures against download file checksums.
contrib/spendfrom is a python-language command-line utility that
how to use the "raw transactions" JSON-RPC api to send coins received from
addresses (also known as "coin control").
New/changed settings (command-line or bitcoin.conf file)
lockunspent / listlockunspent allow locking transaction outputs for a
period of time so
they will not be spent by other processes that might be accessing the same
addnode / getaddednodeinfo methods, to connect to specific peers without
importprivkey now takes an optional boolean parameter (default true) to
control whether
or not to rescan the blockchain for transactions after importing a new
private key.
Important Bug Fixes
Qt 4.8.3 (compiling against older versions of Qt 4 should continue to work)
Thanks to everybody who contributed to this release:
Alexander Kjeldaas
Andrey Alekseenko
Arnav Singh
Christian von Roques
Eric Lombrozo
Forrest Voight
Gavin Andresen
Gregory Maxwell
Jeff Garzik
Luke Dashjr
Matt Corallo
Mike Cassano
Mike Hearn
Peter Todd
Philip Kaufmann
Pieter Wuille
Richard Schwab
Robert Backhaus
Rune K. Svendsen
Sergio Demian Lerner
Wladimir J. van der Laan

@_date: 2013-01-14 13:31:59
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposal: make the private key for 
The testnet3 genesis block is identical to the main network genesis
block, except it has a different timestamp and nonce.
So its coinbase pays to the same public key as the main network. I
don't have that private key.
Good idea for testnet4, whenever that happens, though.

@_date: 2013-07-31 16:28:25
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
I've turned the preliminary payment protocol spec into three BIPs:
 : Network protocol / messages
 : MIME types for the messages
 : bitcoin: URI extension
I expect the wallet-side implementation to be pulled into Bitcoin-Qt Real
  There is also a reference implementation of server-side code for generating
payment requests in php and C++ :

@_date: 2013-07-31 21:19:05
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
Thanks, Mike!
   "PaymentRequest messages larger than 50,000 bytes should be rejected by
Yes, fixed.
I don't like putting "this is what we think will happen in the future"
types of statements in specifications, so I'm inclined to leave that out.
"Resistance from man-in-the-middle attacks that replace a merchant's
bitcoin address with an attacker's address before a transaction is
authorized with a hardware wallet."
Perhaps note in the BIP that the merchant should not assume the
"Note that malicious clients may modify the merchant_data, so should be
authenticated in some way (for example, signed with a merchant-only key)."
"payment | Copy of the Payment message that triggered this PaymentACK.
Clients may ignore this if they implement another way of associating
Payments with PaymentACKs."
Modified that section to say:
"...followed by additional certificates, with each subsequent certificate
being the one used to certify the previous one, up to a trusted root
authority. The recipient must verify the certificate chain according to
[RFC5280] and reject the PaymentRequest if any validation failure occurs.
Trusted root certificates may be obtained from the operating system; if
validation is done on a device without an operating system, the Mozilla
root store

@_date: 2013-07-31 21:33:07
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
I think we'll want a bitcoin address in there for a long time for
backwards compatibility.
If web browser support for arbitrary MIME types is strong enough (I
haven't tested), then a payment request can be initiated with just an
anchor tag:
Doing it that way saves a http round-trip.
Gavin Andresen

@_date: 2013-08-01 09:38:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
P2SH addresses already support all exotic transactions.
Do you mean assemble the PaymentRequest message?  Because the payment
transaction will always be created by the customer's wallet software.
IF PaymentRequests take over the world and we get 100% wallet software
support, then I'd be happy to write another BIP that says that a
bitcoin: URI can be just bitcoin:?request=http...

@_date: 2013-06-28 10:24:16
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposal: MultiBit as default desktop 
I vote "yes" to have MultiBit replace Bitcoin-Qt as the recommended
desktop wallet app. I think most users will be happier with it.
If I'm wrong, it is easy to change back.

@_date: 2013-03-02 16:09:38
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Secure download 
My gpg key is on the bitcoin.org homepage: .... which you can access securely (and see the history of) at:
  If you're really super-duper paranoid, you could also fetch it from
the MIT pgp keyserver or look for it in the bitcointalk forums
Import it into pgp/gpg, then you can verify that the download
checksums you have are correct with:
gpg --verify SHA256SUMS.asc
All that assuming you're running Linux.  If you're Windows or OSX, the
latest downloads are code-signed and checked for integrity
automatically by Windows/OSX.

@_date: 2013-03-11 11:36:08
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Blocking uneconomical UTXO creation 
demurrage of any kind will never, ever happen, just give up on that idea.
The negative publicity of "the bitcoin developers are destroying YOUR
coins!" would be devastating.

@_date: 2013-03-13 13:01:43
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Blocksize and off-chain transactions 
I really don't understand this either/or mentality.
OF COURSE we're going to raise the block size limit. Limiting the main
blockchain to single-digit transactions-per-second is not an option,
the vision FOREVER has been to scale it up.
And OF COURSE there will be off-chain transactions-- at the very
least, we need them for "instantly confirmed" transactions.
But lets table that whole discussion until 0.8.1 is out the door.

@_date: 2013-03-14 00:01:46
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Ok to use 0.8.x? 
Bitcoin version 0.8.0 is safe to use for everything EXCEPT creating blocks.
So: safe for everybody except solo miners / pool operators.

@_date: 2013-03-16 21:13:51
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.8.1 plan 
Here's the plan for the 0.8.1 release:
A new CheckBlock() rule, in effect until 15 May, that ensure only
blocks compatible with old releases are accepted into the main chain
(only blocks that touch 4,500 or fewer distinct txids are allowed).
A limit of 500k to blocks created, also in effect until 15 May.
Alerts will be sent to pre-0.8 releases over the next two months,
telling people to either upgrade or create a DB_CONFIG file so they
can handle large blocks.
Code is : I chose May 15 arbitrarily; two months seems like a reasonable 'quick'
amount of time to give people to upgrade/workaround.
The fix was written to be trivial to port to previous versions, and to
be as simple as possible.
Some of the exact details may still change before the 0.8.1 release
(e.g. it might not be exactly 4,500 distinct txids).
0.8.1 binaries late tomorrow or Monday.  An expires-after-24-hours
Alert sent on Tuesday to everybody running pre-0.8, pointing to
Another 24-hour Alert sent on April 15, reminding everybody again they
will need to upgrade or workaround.
A final Alert that never expires sent on May 8th.
After May 15, miners will be free to create blocks up to 1MB, and
anybody running old versions who ignored the alerts may be left

@_date: 2013-03-16 22:31:38
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.8.1 plan 
Not crazy, just inconvenient, and possibly confusing.
I'm going to be pretty stubborn about the dates. I'm just not
interested in lots of discussion about what the perfect times/dates
will be, there are much more important things that need to get done
Like hard-forking to increase the 1MB blocksize limit.  This will be
good practice for that.

@_date: 2013-05-07 08:28:15
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] minor bitcoin-qt gripes moving BTC off 
"sweep private key" is the missing functionality.
I agree, it would be nice to have.

@_date: 2013-05-10 11:39:08
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.8.2rc1 ready for testing 
Bitcoin-Qt version 0.8.2 release candidate 1 is now available from:
  This is a maintenance release that fixes many bugs and includes
a few small new features.
Please report bugs using the issue tracker at github:
  How to Upgrade
The default fee for low-priority transactions is lowered from 0.0005 BTC
(for each 1,000 bytes in the transaction; an average transaction is
about 500 bytes) to 0.0001 BTC.
Payments (transaction outputs) of 0.543 times the minimum relay fee
(0.00005430 BTC) are now considered 'non-standard', because storing them
costs the network more than they are worth and spending them will usually
cost their owner more in transaction fees than they are worth.
Non-standard transactions are not relayed across the network, are not included
in blocks by most miners, and will not show up in your wallet until they are
included in a block.
The default fee policy can be overridden using the -mintxfee and -minrelaytxfee
command-line options, but note that we intend to replace the hard-coded fees
with code that automatically calculates and suggests appropriate fees in the
0.9 release and note that if you set a fee policy significantly different from
the rest of the network your transactions may never confirm.
Bitcoin-Qt changes
* -walletnotify will call a command on receiving transactions that
affect the wallet.
* -alertnotify will call a command on receiving an alert from the network.
* -par now takes a negative number, to leave a certain amount of cores free.
JSON-RPC API changes
* Significant changes to the networking code, reducing latency and
memory consumption.
* Avoid initial block download stalling.
* Remove IRC seeding support.
* Performance tweaks.
* Added testnet DNS seeds.
Wallet compatibility/rescuing
Andrew Poelstra
Calvin Owens
Chuck LeDuc D?az
Colin Dean
David Griffith
David Serrano
Eric Lombrozo
Gavin Andresen
Gregory Maxwell
Jeff Garzik
Jonas Schnelli
Larry Gilbert
Luke Dashjr
Matt Corallo
Michael Ford
Mike Hearn
Patrick Brown
Peter Todd
Philip Kaufmann
Pieter Wuille
Richard Schwab
Roman Mindalev
Scott Howard
Tariq Bashir
Wladimir J. van der Laan

@_date: 2013-05-15 18:24:47
@_author: Gavin 
@_subject: [Bitcoin-development] blind symmetric commitment for stronger 
Busy with pre-conference stuff, not following details of this conversation...
... but it sounds a lot like the "guy fawkes" protocol Zooko was thinking about a year or so ago.

@_date: 2013-05-20 21:39:02
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Double Spend Notification 
I'm very much in favor of double-spend propagation across the network.
Most of the arguments about replace-based-on-fee /
child-pays-burn-coins / etc are orthogonal.
Letting a merchant know ASAP that their customer is trying to cheat
them is, in my opinion, strictly better than what we have now.

@_date: 2013-05-29 17:18:58
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin-Qt / bitcoind version 0.8.2 (final) 
Bitcoin-Qt version 0.8.2 is now available from:
  This is a maintenance release that fixes many bugs and includes
a few small new features.
Please report bugs using the issue tracker at github:
  How to Upgrade
The default fee for low-priority transactions is lowered from 0.0005 BTC
(for each 1,000 bytes in the transaction; an average transaction is
about 500 bytes) to 0.0001 BTC.
Payments (transaction outputs) of 0.543 times the minimum relay fee
(0.00005430 BTC) are now considered 'non-standard', because storing them
costs the network more than they are worth and spending them will usually
cost their owner more in transaction fees than they are worth.
Non-standard transactions are not relayed across the network, are not included
in blocks by most miners, and will not show up in your wallet until they are
included in a block.
The default fee policy can be overridden using the -mintxfee and -minrelaytxfee
command-line options, but note that we intend to replace the hard-coded fees
with code that automatically calculates and suggests appropriate fees in the
0.9 release and note that if you set a fee policy significantly different from
the rest of the network your transactions may never confirm.
Bitcoin-Qt changes
* -walletnotify will call a command on receiving transactions that
affect the wallet.
* -alertnotify will call a command on receiving an alert from the network.
* -par now takes a negative number, to leave a certain amount of cores free.
JSON-RPC API changes
* Significant changes to the networking code, reducing latency and
memory consumption.
* Avoid initial block download stalling.
* Remove IRC seeding support.
* Performance tweaks.
* Added testnet DNS seeds.
Wallet compatibility/rescuing
Andrew Poelstra
Calvin Owens
Chuck LeDuc D?az
Colin Dean
David Griffith
David Serrano
Eric Lombrozo
Gavin Andresen
Gregory Maxwell
Jeff Garzik
Jonas Schnelli
Larry Gilbert
Luke Dashjr
Matt Corallo
Michael Ford
Mike Hearn
Patrick Brown
Peter Todd
Philip Kaufmann
Pieter Wuille
Richard Schwab
Roman Mindalev
Scott Howard
Tariq Bashir
Warren Togami
Wladimir J. van der Laan

@_date: 2013-11-06 10:00:04
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Possible Solution To SM Attack 
I would like to be convinced that there is, actually, a real-world problem
before thinking about potential solutions.
I'd like to see more analysis of the proposed selfish-mining algorithm at a
particular share-of-network and gamma=0 (assume second-broadcast blocks
always lose, to make the math easier). I can't reproduce the finding in the
paper if I take into account the "opportunity cost" of working on more
blocks in the private chain that might be orphaned instead of always simply
extending the public chain, but it is very possible my little brain is
missing something obvious.

@_date: 2013-11-07 14:56:56
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] we can all relax now 
If I find out one of the large pools decides to run this 'experiment' on
the main network, I will make it my mission to tell people to switch to a
more responsible pool.
And if you think you can get away with driving up EVERYBODY's orphan rate
without anybody noticing, you should think again.
That I agree with.

@_date: 2013-11-14 09:52:41
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Even simpler minimum fee calculation 
Couple of thoughts:
RE: the marvelous coincidence that the average fee these days is very close
to the modeled minimum orphan cost:
Engineers tend to underestimate the power of markets, even inefficient
markets, to arrive at the 'correct' price. It would not surprise me at all
if the messy, chaotic inefficient market with tens of thousands of
individual decisions ("which mining pool should I join" and "how high
should my dice site set fees" and "how large should the minimum payout be"
and "should I make my blocks bigger or smaller") might arrive at the
'correct' price, even if NOBODY involved has any clue how or why it
Or it might just be a coincidence.
RE: orphan rate:
The network-wide orphan rate has been very steady apart from the March
blockchain fork. Kudos to Ben Reeves for keeping track of the data and
giving us a nice chart:
  RE: new block latency:
We should be able to reduce the size of new block announcements by about a
factor of ten with very little additional effort (transmit/relay as
"merkleblock" with full bloom filters-- the factor of 10 is because a
transaction id hash is 32 bytes, average transaction size is a few hundred
Mining revenue is a fixed-size pie, so if EVERYBODY agreed to accept
(somewhat) higher orphan rates for more transaction volume then, in the
long run, there is no difference.  Well, except that more transaction
volume means more utility for Bitcoin as a whole, so everybody should
benefit from a higher bitcoin price.
That's a classic free-rider problem, though-- a miner could defect to try
to get a lower orphan rate.
This is one of the reasons why I think relaying all blocks in a race is
probably the right thing to do; if a miner is mildly punished (by losing
the occasional block race) for creating blocks that don't include "enough"
already-relayed transactions, that is a strong incentive to go along with
whatever consensus has been established.
The same argument applies for a miner producing too-large blocks, or blocks
with lots of transactions that were never relayed across the network.

@_date: 2013-10-04 16:22:34
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] bitcoind stops responding 
getinfo does a bunch of stuff; with 0.9 you will be able to use
getbestblockhash instead.
If you just want to see if bitcoind is responding to RPC requests, then
'help getinfo' would do the trick without acquiring any locks.
RE: running into the maximum-of-4-keepalive-requests : simple workaround is
to run with -rpcthreads=11 (or however many keepalive connections you need
to support).  I agree that the rpc code should be smarter; making the last
rpc thread ignore keepalive and always disconnecting should be a fairly
simple patch, and "patches welcome."

@_date: 2013-10-05 12:31:57
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Code review 
I'll try harder to be a fascist (it doesn't come naturally to me). HUGE
thanks for taking the time to review the fee changes in detail.
RE: using Review Board:
I'm all for using better tools, if they will actually get used. If a
potential reviewer has to sign up to create a Review Board account or learn
Yet Another Tool, then I think it would be counter-productive:  we'd just
make the pool of reviewers even smaller than it already is.
Are there good examples of other open source software projects successfully
incentivizing review that we can copy?
For example, I'm wondering if maybe for the 0.9 release and onwards the
"Thank you" section should thank only people who have significantly helped
test or review other people's code.

@_date: 2013-10-11 16:04:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] FYI: pull-tester status 
Since the autotools merge, the pull-tester has been misbehaving-- marking
valid pulls as invalid, etc.
So I've turned off some pull-tester features until somebody has time to
figure out how to fix them. Right now, pull-tester does the following:
+ Cross-compile windows binaries
+ Compile linux binaries
+ Run unit tests (binaries compiled on linux)
The following features are turned off:
- Running unit tests under wine with cross-compiled windows binaries
- Running the block-chain-compatibility tester
- Computing code coverage
Medium-term, there are several changes that need to be made to the
pull-tester environment; I'd like the following to get done:
+ Upgrade the pull-tester machine from Ubuntu 10.04 to 12.04. Or, probably
better, create a new 12.04 virtual machine and move the pull-tester over to
+ Upgrade compilers/dependencies based on what we think we'll use for the
0.9 release.
+ Figure out how to unify the pull-tester and gitian build processes.
 Maybe the pull-tester should run gitian builds to create binaries (that
are then tested against the blockchain tester)? Maybe the pull-tester
scripts should be gitian scripts, which the pull-tester machine runs inside
an LXC container?

@_date: 2013-10-25 06:39:34
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Making fee estimation better 
Yes, and I asked Luke what percentage of that 10% is OOB fee payments, and
the answer is "a small percentage."
So: there are multiple layers of reasons why OOB fee payments will not
screw up the fee estimation code:
+ If the transactions are not broadcast, then they have no effect on the
+ If the transactions are broadcast but not relayed because their priority
and fee are way below current estimates then they will have very close to
zero effect on the estimates.
+ If the OOB transaction is zero-fee, zero-priority (e.g comes from a
high-tx-volume service and relies on recently spent outputs) it will have
zero effect on the estimates.
+ If they make up less than about 40% of broadcast transactions they will
have very close to zero effect on the fee estimate (because of the
distribution of fees and behavior of taking a median)
The only case where the estimation code is even slightly likely to get
confused is estimating the priority needed to get into a block IF there are
a significant number of zero-fee, low-but-not-zero-priority OOB
transactions being broadcast.
And since priority naturally increases over time, even if that case DOES
occur the failure is very mild-- it means your free transactions might have
to build up more priority than the code estimates before successfully
entering a block.  If that gets to be an actual problem, then implementing
Pieter's idea of keeping track of memory pool transactions that are NOT
getting mined would fix it. But I don't want to waste time on a theoretical
problem when it is very possible miners will decide to stop accepting free
transactions alltogether.
And all of the above is completely orthogonal to child-pays-for-parent
and/or replace-with-higher-fee.
PS: I would appreciate it if you stop saying things like "Regarding the
transaction fee estimate code, it's not very well thought out."

@_date: 2013-10-26 10:25:06
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Making fee estimation better 
The blog post is the best place for high-level overview.
The (closed for now, but it will come back) pull request is the best place
for low-level details and nit-picking discussion:
  The pull request adds an 'estimatefees' JSON-RPC api call:
estimatefees [prioritymedian=0.1] [feemedian=0.5]
Estimates the priority or fee a transaction needs
to be relayed across the network and included in
the block chain.
prioritymedian and feemedian are values from 0.0
to 1.0, where 0.0 will return the smallest
recently-included-in-a-block priority (or fee) seen,
1.0 the largest, and 0.5 the median priority (or fee)
for transactions that were broadcast on the network and
included in a block.
The default value for prioritymedian (0.1) is
chosen to return a priority for free transactions that
will eventually be confirmed, but might take several hours.
The default value for feemedian (0.5) returns how much
fee you should include to have your transactions confirmed
in an average amount of time.
Values returned are:
 freepriority : priority needed to out-compete a prioritymedian
  fraction of free transactions to be relayed and included in blocks.
 feeperbyte : fee, in satoshis/byte, needed to out-compete a
  feemedian fraction of fee-paying transactions.
Values of -1.0 are returned if not enough transactions
have been seen to make a good estimate.
That API doesn't give "30 minute versus 24 hour" confirmation time or
confidence intervals. I've always regretted not taking a statistics class;
if you want to help write code that estimates confidence intervals send me
an email. The API certainly isn't set in stone.
  - Is it globally consistent?
Ummm.... roughly, yes, it will be. Nodes that have just joined the network
and haven't seen enough transactions enter and leave the memory pool will
have a different estimate than long-running nodes, but in my testing the
estimate narrows down very quickly (with three or four blocks enough
fee-paying transactions have been seen to make a reasonable estimate; it
takes longer to see enough free transactions to get a good estimate of the
priority needed to get into the free space of a block).
RE: lots of other comments:
I feel like there is a lot of "in the weeds" discussion here about
theoretical, what-if-this-and-that-happens-in-the-future scenarios.
I would just like to point out (again) that this is not intended to be The
One True Solution For Transaction Fees And Transaction Prioritization. If
you've got a better mechanism for estimating fees, fantastic! If it turns
out estimates are often-enough wrong to be a problem and you've got a
solution for that, fantastic!
RE: are we already seeing pressure on transaction fees:
I believe we are, yes. As part of the prep work for the smart fee work I
spent some time plotting priority (for zero-fee transactions) and
transaction fee (for zero-priority transactions) versus confirmation time,
and it looks to me like people/services are starting to include more than
the hard-coded fees in the reference implementation-- I assume because they
want their transactions to be confirmed more quickly.
There is definitely already competition among zero-fee transactions for the
"free" block space. One of the reasons I'm comfortable with the fee changes
I'm proposing is if the estimation code gets it very wrong we'll see that
first as free transactions taking "too long" to confirm, but they'll
confirm eventually because priority increases over time.

@_date: 2013-10-26 10:34:51
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
Mike Hearn has been lobbying for an "error" message in the Bitcoin p2p
protocol for years (at least since the "ban peers if they send us garbage"
denial-of-service mitigation code was pull-requested). This came up again
with my proposed "smartfee" changes, which would drop low-priority or
low-fee transactions.
In short, giving peers feedback about why their blocks or transactions are
dropped or why they are being banned should help interoperability between
different implementations, and will give SPV (simplified payment
verification) clients feedback when their transactions are rejected due to
insufficient priority or fees.
See the gist for details, I'm looking for feedback and planning on
implementing this before circling back to finish the 'smart fee' work:

@_date: 2013-10-26 12:00:03
@_author: Gavin 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
No. Enums or fixed length strings just make it harder to extend, for no benefit (bandwidth of 'reject' messages doesn't matter, they will be rare and are not relayed).

@_date: 2013-10-26 13:55:35
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment protocol for onion URLs. 
This would give us an fully supported option which is completely CA
I think a tiny number of people would use it, so from a purely engineering
priority perspective my initial reaction is "not worth it."
However, as a demonstration of the flexibility of the payment protocol and
because it is a really nifty idea that will give lots of people warm
fuzzies I think you should do it and we should pull it.

@_date: 2013-10-28 08:46:34
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Advisory: PHP library Bitcoin SCI weak 
Thanks for the warning; to be clear, "the Bitcoin SCI library" is this
  Gavin Andresen

@_date: 2013-10-28 08:52:25
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
RE: use HTTP-like status codes:
Okey dokey, I'll add a one-byte machine-readable HTTP-like status code.
Unless y'all want a 32-bit status code.  Or maybe a varint. Or a
three-character numeric string. I really and truly don't care, but I am
writing this code right now so whatever you want, decide quickly.
If anybody has strong feelings about what the reject categories should be,
then please take the time to write a specific list, I can't read your

@_date: 2013-10-29 15:37:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
Thanks for the feedback, everybody, gist updated:
  Categories are:
0x01-0x0fProtocol syntax errors0x10-0x1fProtocol semantic errors0x40-0x4fServer
policy rule
RE: why not a varint:  because we're never ever going to run out of reject
codes.  Eight are defined right now, if we ever defined eight more I'd be
RE: why not use HTTP codes directly: because we'd be fitting round pegs
into square holes.

@_date: 2013-10-30 12:01:16
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Feedback requested: "reject" p2p message 
But if you are getting soft-forked recent versions of the reference
implementation WILL alert you; see this code in main.cpp:
        if (nUpgraded > 100/2)
            strMiscWarning = _("Warning: This version is obsolete, upgrade
That is, if more than half of the last 100 blocks are up-version, warn.
 block.version is part of the block header, so SPV clients can (and
probably should) do the same.
There are also warnings if you are forked, and, most recently, warnings if
there is a high-work alternative fork.

@_date: 2013-09-13 11:11:43
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin-Qt / bitcoind version 0.8.5 released 
Bitcoin-Qt version 0.8.5 is now available from:
  This is a maintenance release to fix a critical bug;
we urge all users to upgrade.
Please report bugs using the issue tracker at github:
  0.8.5 Release notes
Bugs fixed
Transactions with version numbers larger than 0x7fffffff were
incorrectly being relayed and included in blocks.
Blocks containing transactions with version numbers larger
than 0x7fffffff caused the code that checks for LevelDB database
inconsistencies at startup to erroneously report database
corruption and suggest that you reindex your database.
This release also contains a non-critical fix to the code that
enforces BIP 34 (block height in the coinbase transaction).
Thanks to Gregory Maxwell and Pieter Wuille for quickly
identifying and fixing the transaction version number bug.

@_date: 2013-09-25 09:35:07
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
Not too late, assuming there are no objections. Smaller QR codes is a very
good reason to change it.

@_date: 2013-09-29 18:32:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] smart contracts -- possible use case? yes 
Yes, that's off-topic for this mailing list. Lets stick to technical issues
that we can solve by writing code.

@_date: 2014-04-04 09:32:40
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Draft BIP for seamless website 
Using a bitcoin address repeatedly is something we're trying to move away
And using a bitcoin address as a persistent identity key feels like the
wrong direction to me.
Better to use something like client certificates, the FIDO alliance's
(new!) specs:
  ... or Steve Gibson's proposed SQRL system:
  If one of those systems gets critical mass and actually starts being
successful, then I think it would make sense to specify a standard way of
using a HD wallet's deterministic seed to derive a key used for the FIDO or
SQRL systems.

@_date: 2014-04-08 17:11:50
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.9.1 released 
Bitcoin Core version 0.9.1 is now available from:
  This is a security update. It is recommended to upgrade to this release
as soon as possible.
It is especially important to upgrade if you currently have version
0.9.0 installed and are using the graphical interface OR you are using
bitcoind from any pre-0.9.1 version, and have enabled SSL for RPC and
have configured allowip to allow rpc connections from potentially
hostile hosts.
Please report bugs using the issue tracker at github:
  How to Upgrade
If you are running an older version, shut it down. Wait until it has
shut down (which might take a few minutes for older versions), then run the
installer (on Windows) or just copy over /Applications/Bitcoin-Qt (on Mac)
bitcoind/bitcoin-qt (on Linux).
If you are upgrading from version 0.7.2 or earlier, the first time you run
0.9.1 your blockchain files will be re-indexed, which will take anywhere
30 minutes to several hours, depending on the speed of your machine.
0.9.1 Release notes
No code changes were made between 0.9.0 and 0.9.1. Only the dependencies
were changed.
- Upgrade OpenSSL to 1.0.1g. This release fixes the following
vulnerabilities which can
  affect the Bitcoin Core software:
  - CVE-2014-0160 ("heartbleed")
    A missing bounds check in the handling of the TLS heartbeat extension
    be used to reveal up to 64k of memory to a connected client or server.
  - CVE-2014-0076
    The Montgomery ladder implementation in OpenSSL does not ensure that
    certain swap operations have a constant-time behavior, which makes it
    easier for local users to obtain ECDSA nonces via a FLUSH+RELOAD cache
    side-channel attack.
- Add statically built executables to Linux build
Credits go to the OpenSSL team for fixing the vulnerabilities quickly.

@_date: 2014-04-17 09:00:54
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Timed testing 
How is this different from just running in -regtest mode and asking the
nodes to generate a block after 1 or 2 seconds?

@_date: 2014-04-17 13:07:48
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Timed testing 
Unless I misunderstood what your private mode does, you can get the same
effect with -regtest by just controlling nodes connectivity. For example:
Start 2 nodes, connected to each other. Mine a -regtest chain they both
agree on.
Restart them so they're not connected.  Have one mine normally,
have the other  mine... however you like to simulate some attack (deep
chain re-org, double-spend,
To simulate launching the attack, connect them together again, let the two
chains compete and see
what happens.

@_date: 2014-04-23 13:47:47
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
I strongly disagree.  It makes perfect sense to discuss changes here,
first, where there are lots of people who understand how the system works
at a very detailed level.
And why do you think your blog is more public than this open, publicly
archived mailing list???

@_date: 2014-04-26 09:23:03
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Error handling in payment protocol 
Why does error handling have to be standardized?
I generally think that wallet software should be free to do whatever gives
the user the best experience, so I'm in favor of restricting BIPs to things
that must be standardized so that different implementations inter-operate.
Referencing whatever RFCs defines how to fetch URLs would be the best way
to do this. Submit a pull request.
PaymentRequests are limited to 50,000 bytes. I can't think of a reason why
Payment messages would need to be any bigger than that. Submit a pull
request to the existing BIP.
Implementation detail that doesn't belong in the spec, in my humble opinion.
I think this should be left to implementations to work out.
.... not a good idea. The user should get feedback right away. Poking a
"pay now" button and then waiting more than a second or three to get "your
payment has been received and is being processed" is terrible UI.

@_date: 2014-04-28 08:39:36
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposal to change payment protocol signing 
There is a discussion about clarifying how BIP70 signs payment requests
  The issue is what to do with the signature field before signing. The code
Mike and I initially wrote does this:
    request.set_signature(string(""));
(sets signature to the empty string)
I think that is a mistake; it should be:
   request.clear_signature();
(clears signature field, so it is not serialized at all).
So: if you are implementing, or have implemented, the payment protocol,
please chime in. I'd like to change the spec and the reference
implementation NOW, while BIP70 is still a 'Draft'.
Because this type of "hey, I'm implementing your standard and it doesn't
work the way I think it should" mistake is exactly why BIPs take a while
before being declared 'Final.'

@_date: 2014-04-29 12:12:49
@_author: Gavin 
@_subject: [Bitcoin-development] Proposal to change payment protocol 
Consensus is the spec should be clarified to match current behavior, so it won't change.
Gavin Andresen

@_date: 2014-12-04 11:46:28
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Serialised P2SH HD chains 
Seems like the wrong approach to me, because in practice you really need
a reasonable expiration date or some way of determining that whatever you
are paying
is still around (I still get random transactions to the Bitcoin Faucet's
old addresses).
See the discussion from January about extending the payment protocol for
recurring transactions:
 at lists.sourceforge.net/msg03823.html
"Give them a single token" == "give them a recurring PaymentRequest" in my
mind. Or maybe "Give them a URL where they can fetch PaymentRequests
whenever they need to make a payment" or maybe "Give them an array of
PaymentRequests for the next X days/months/years of payments."

@_date: 2014-02-10 13:53:16
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] MtGox blames bitcoin 
RE: taking discussion elsewhere:
Yes, please, the purpose of this mailing list is technical discussions to
encourage interoperability of Bitcoin implementations, improve ease-of-use
and security, etc.

@_date: 2014-02-18 15:15:45
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP70 proposed changes 
Fantastic feedback, thanks Ryan and Andreas!
Please don't let me being busy get in the way of progress, so submit pull
requests to the BIP (the UTC timezone issue seems obvious and
non-controversial) or write up draft specs for extensions.
RE: wallets checking the status of payment:  excellent idea. A URL that can
be polled to check payment processing status sounds like the right thing to
That feels very similar to the proposal for recurring payments; I think
they would be separate mechanisms, but maybe their specs could share some
of the same concepts / field names....

@_date: 2014-02-20 09:29:40
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [RFC] [BIP proposal] Dealing with 
I think we should get Pieter's proposal done and implemented quickly. I
agree with Mike, it doesn't have to take a long time for the core network
to fully support this.
Getting wallets to start generating transaction.version=3 might take years,
but that is OK.

@_date: 2014-02-20 09:58:30
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [RFC] [BIP proposal] Dealing with 
Great, I'm hearing rough consensus to proceed with Pieter's plan.
RE: far from confident on malleability routes:  I'm reasonably confident
that we can squash malleability for IsStandard, SIGHASH_ALL transactions. A
proper proof of DSA signature un-malleability (or an lower bound for how
much work it would be to create a valid doppleganger signature) would be
great, but I don't think it is necessary to proceed.

@_date: 2014-02-20 10:40:34
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Transaction malleability in the core code: 
A quick update on the state of transaction malleability work in
Bitcoind/Bitcoin-Qt (aka Bitcoin Core). This is not about longer-term
malleability issues, just the very short-term work being done (or already
done) to the reference implementation.
First, the problems:
We've had a longstanding TODO to improve the way the core code deals with
double-spends. From the core code's point of view, malleable transactions
are just one particular form of double-spend.
Improving double-spend handling never made it to the top of the TODO list,
because the cases where it happened involved doing unsupported things (like
copying your wallet.dat to another machine and then spending on both
And because there is a heavy-handed workaround if a wallet becomes confused
because of a double-spend:  restore all of the keys, rescan for
transactions confirmed in the blockchain, and any outputs tied up in
double-spends get released. Coins (really, unspent transaction outputs)
were never permanently lost, but they could be tied up and unspendable when
associated with a 0-confirmation transaction that would never confirm.
So, work in progress or done:
These implements a kinder, gentler sledgehammer (-zapwallettxes) to fix a
confused wallet. If you have a wallet with 0-confirmation transactions that
are tying up bitcoins these should fix it.
These three merged pull requests implement a new command-line option:
-nospendzeroconfchange .  The best way to get a wallet confused is to spend
zero-confirmation change outputs that you created yourself; if the
transaction creating the change gets mutated, then the subsequent
transaction is invalid and will never confirm.
The core code spends unconfirmed change only as a last resort. If you are a
service using bitcoind that generates a lot of transactions then best
practice would be to run with -nospendzeroconfchange, and use "sendmany" to
batch payments only after previous payments have confirmed.
This tightens up the IsStandard() rule, so the easiest-to-implement method
of mutating transactions is blocked. Many big mining pools are already
running this patch.
These three get at the root of the problem; they rework the core wallet
code to implement "handle double spends better."  See the pull requests for
How can you help:
Testing and code review is, as always, the bottleneck for getting out a
release with these changes.
We have a chronic problem with people running Bitcoin services on top of
the core code waiting until there is an "official" release, and then
assuming that somebody else has done the hard work of reviewing and testing
the changes.
YOU SHOULD NOT BE MAKING THAT ASSUMPTION!  Your particular RPC call usage
might trigger some edge-case bug that was missed, or perhaps the size of
your wallet triggers a performance problem introduced by a fix.
Or, in other words: do not treat the core development team as if we were a
commercial company that sold you a software library. That is not how open
source works; if you are making a profit using the software, you are
expected to help develop, debug, test, and review it.

@_date: 2014-02-24 11:45:16
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] On OP_RETURN in upcoming 0.9 release 
40 bytes is small enough to never require an OP_PUSHDATA1, too, which will
make writing the OP_RETURN-as-standard BIP simpler.

@_date: 2014-01-12 16:18:33
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Stealth Addresses 
No, please. Make it easy for non-geeks, extend the payment protocol, or
we'll spend the next two years writing code that tries to ignore linebreaks
and spaces and changing  elements in HTML forms to  ....

@_date: 2014-01-26 21:05:31
@_author: Gavin 
@_subject: [Bitcoin-development] BIP70/71 issue, RFD 
Message encoding and length (or terminator or checksum or error correction or...) should be part of the transport protocol, in my humble opinion.
Gavin Andresen

@_date: 2014-01-27 09:54:09
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP70: PaymentACK semantics 
Does it mean the Payment is valid?
The purpose of PaymentACK is to give the customer reassurance that their
payment request has been received and will be processed (or not).
If it is syntactically incorrect or invalid in a way that the payment
processor can detect right away then a PaymentACK with a message saying
that there is a problem should be the response.
Waiting until confirmed is definitely not the right thing to do, but
waiting a few seconds to detect a 0-confirmation double-spend attempt
before sending back an ACK is fine.  The BIP is intentionally vague on how
long it might take to get an ACK, but, again, the intent is to give the
customer reassurance that their payment was received and is being
processed, whatever "processed" means (order sent to shipping for
fulfillment, or awaiting 11 confirmations, or "your burger is paid for you
can leave the restaurant and we won't chase after you").
Gavin Andresen

@_date: 2014-01-28 07:53:14
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP70: PaymentACK semantics 
If the wallet software is doing automatic CoinJoin (for example), then
typically one or several of the other participants will broadcast the
transaction as soon as it is complete.
If the spec said that wallets must not broadcast until they receive a
PaymentACK (if a payment_url is specified), then you'd have to violate the
spec to do CoinJoin.
And even if you don't care about CoinJoin, not broadcasting the transaction
as soon as the inputs are signed adds implementation complexity (should you
retry if payment_url is unavailable? how many times? if you eventually
unlock the probably-not-quite-spent-yet inputs, should you double-spend
them to yourself just in case the merchant eventually gets around to
broadcasting the transaction, or should you just unlock them and squirrel
away the failed Payment so if the merchant does eventually broadcast you
have a record of why the coins were spent).

@_date: 2014-01-30 10:06:23
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP70: PaymentACK semantics 
The intent is to give the customer a great experience. We could talk for
months about whether having the wallet broadcast the transaction as soon as
possible or having it wait for the merchant to respond with a PaymentACK is
better. But I think we should let wallets experiment with different ways of
doing it, and see what works best in practice.

@_date: 2014-07-03 11:56:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Building from git on OSX 
Just FYI for anybody else building on OSX:
libtool is a new dependency, so if you update to git HEAD and have trouble
brew install libtool
  (or port install libtool -- see doc/build-osx.md for all the dependencies)
./configure  .... etc, whatever configure options you use. I develop with:
./configure --disable-hardening --disable-silent-rules CXXFLAGS='-g3 -O0

@_date: 2014-07-17 18:46:52
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Squashing redundant tx data in blocks on 
A couple of half-baked thoughts:
I'd encourage you to code up a prototype first (or at the same time), in
whatever programming language / networking library you're most familiar
Maybe not even using the existing p2p protocol; there could be a
mining-only very-fast-block-propagation network separate from the existing
p2p network.
Combining your optimizations with "broadcast as many near-miss blocks as
bandwidth will allow" on a mining backbone network should allow insanely
fast propagation of most newly solved blocks.

@_date: 2014-07-18 10:53:01
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Squashing redundant tx data in blocks on 
Two more half-baked thoughts:
We should be able to assume that the majority of transaction data (except
for coinbase) has already been propagated. As Jeff said, incentivizing
nodes to propagate transactions is a very good thing (the signature cache
already gives a small incentive to miners to propagate and not 'hoard'
So the only information that theoretically needs to be propagated is which
transactions a miner is including in their block, and in what order they
are included.
But if there was some agreed-upon canonical ordering, then it should
theoretically be possible to take shortcuts in the "what order".
You'd start with setof(transactions I think everybody knows about)
Select some subset, based on miner's policy
Sort that subset with the canonical ordering algorithm
Very efficiently broadcast, taking all sorts of shortcuts assuming most of
your peers already know the set you started with and expect the same
canonical ordering (see gmaxwell's thoughts on block encoding).
Second half-baked thought:
I wonder if broadcasting your transaction selection policy ("11KB of free
transactions, sorted by priority, then 111K of fee-paying transactions,
sorted by fee") might make it possible to save even more bandwidth by
letting your peers create a very good approximation of your block with just
that information....

@_date: 2014-06-24 16:12:09
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed BIP 70 extension 
Protocol buffers are designed to be extensible, and there are hundreds of
field numbers available.
It would be silly to add a "generic stuff" field inside a container format
that ALREADY has all the mechanisms necessary for forwards and backwards

@_date: 2014-03-02 08:54:12
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.9.0 release candidate two 
Please download and help test 0.9.0rc2; binaries are available from:
   If no serious bugs are found in this release candidate, it will be the
final 0.9.0 release.
Release notes (please help proofread/improve these, too):

@_date: 2014-03-10 13:49:04
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Multisign payment protocol? 
In my experience, best process for standardizing something is:
1) Somebody has a great idea
2) They implement it
3) Everybody agrees, "Great idea!" and they copy it.
4) Idea gets refined by the people copying it.
5) It gets standardized.
Mutisig wallets are at step 2 right now. BIP is step 5, in my humble

@_date: 2014-03-10 21:15:28
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Multisign payment protocol? 
Multisig is orthogonal to the payment protocol (but payment protocol is
needed first).
There need to be protocols for:
a) Establishing multisig wallets of various sorts. See:
    ... etc.  for a UI mock-up.
  There needs to be some protocol so all participants in a multisig wallet
contribute keys (actually, we should just assume everybody uses BIP32 HD
public keys so we get privacy from the start).
Multi-person shared wallets, escrows, and "wallet protection service"
wallets (which might be protected with two-factor authentication) are
different use cases and probably use slightly different protocols (and will
probably need different BIPs eventually).
b) Gathering signatures for a multisig spend. Here is where the payment
protocol is useful; the PaymentRequest message should be passed around so
all participants know what is being paid for, and maybe a partially-signed
Payment message is where the signatures are gathered (or maybe the
signatures are sent separately and one of the participants creates and
submits the Payment and gets the PaymentACK... "to be designed").
  See:
        ... for UI mock-up for the multi-person-spend case.
And maybe a protocol for "I don't want to be part of this multisig any more
Gavin Andresen

@_date: 2014-03-11 09:51:36
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Multisign payment protocol? 
Multisig wallets are a different reality from our current one, so when we
move to that new reality we should do it correctly from the beginning.

@_date: 2014-03-11 10:23:32
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Multisign payment protocol? 
If the remote party is one of the parties involved in a multisig, and
speaks the "Lets set up a multisig wallet together / Lets spend from a
multisig" protocols, then it should be perfectly reasonable to assume that
they're HD-capable.
Remote parties paying into a multisig, or receiving funds from a multisig,
don't have to support it (that's what P2SH gives us).

@_date: 2014-03-13 08:25:32
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] 0.9.0rc3 tagged 
Binaries for 0.9.0rc3 are available at:
    Please help sanity test.
We will also need more 'gitian builders' for the final 0.9.0 release
(Wladimir and I are the only builders so far for the rc3 binaries), so if
you are running Linux or OSX and are willing to help please start up those
virtual machines and start building dependencies.

@_date: 2014-03-19 09:26:15
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Bitcoin Core version 0.9.0 released 
Bitcoin Core version 0.9.0 is now available from:
  This is a release candidate for a new major version. A major version brings
both new features and bug fixes.
Please report bugs using the issue tracker at github:
  How to Upgrade
New in 0.9.0 is the Windows 64-bit version of the client. There have been
frequent reports of users running out of virtual memory on 32-bit systems
during the initial sync. Because of this it is recommended to install the
64-bit version if your system supports it.
NOTE: Release candidate 2 Windows binaries are not code-signed; use PGP
and the SHA256SUMS.asc file to make sure your binaries are correct.
In the final 0.9.0 release, Windows setup.exe binaries will be code-signed.
OSX 10.5 / 32-bit no longer supported
The 'chainstate' for this release is not always compatible with previous
releases, so if you run 0.9 and then decide to switch back to a
0.8.x release you might get a blockchain validation error when starting the
old release (due to 'pruned outputs' being omitted from the index of
unspent transaction outputs).
Running the old release with the -reindex option will rebuild the chainstate
data structures and correct the problem.
Also, the first time you run a 0.8.x release on a 0.9 wallet it will rescan
the blockchain for missing spent coins, which will take a long time (tens
of minutes on a typical machine).
Rebranding to Bitcoin Core
For 0.9.0 we switched to an autotools-based build system instead of
Using the standard "./autogen.sh; ./configure; make" to build Bitcoin-Qt and
bitcoind makes it easier for experienced open source developers to
to the project.
Be sure to check doc/build-*.md for your platform before building from
Another change in the 0.9 release is moving away from the bitcoind
functioning both as a server and as a RPC client. The RPC client
("tell the running bitcoin daemon to do THIS") was split into a separate
executable, 'bitcoin-cli'. The RPC client code will eventually be removed
bitcoind, but will be kept for backwards compatibility for a release or two.
`walletpassphrase` RPC
This release drops the default fee required to relay transactions across the
network and for miners to consider the transaction in their blocks to
0.01mBTC per kilobyte.
Note that getting a transaction relayed across the network does NOT
that the transaction will be accepted by a miner; by default, miners fill
their blocks with 50 kilobytes of high-priority transactions, and then with
700 kilobytes of the highest-fee-per-kilobyte transactions.
The minimum relay/mining fee-per-kilobyte may be changed with the
minrelaytxfee option. Note that previous releases incorrectly used
the mintxfee setting to determine which low-priority transactions should
be considered for inclusion in blocks.
The wallet code still uses a default fee for low-priority transactions of
0.1mBTC per kilobyte. During periods of heavy transaction volume, even this
fee may not be enough to get transactions confirmed quickly; the mintxfee
option may be used to override the default.
0.9.0 Release notes
- New notion of 'conflicted' transactions, reported as confirmations: -1
- 'listreceivedbyaddress' now provides tx ids
- Add raw transaction hex to 'gettransaction' output
- Updated help and tests for 'getreceivedby(account|address)'
- In 'getblock', accept 2nd 'verbose' parameter, similar to
  but defaulting to 1 for backward compatibility
- Add 'verifychain', to verify chain database at runtime
- Add 'dumpwallet' and 'importwallet' RPCs
- 'keypoolrefill' gains optional size parameter
- Add 'getbestblockhash', to return tip of best chain
- Add 'chainwork' (the total work done by all blocks since the genesis
  to 'getblock' output
- Make RPC password resistant to timing attacks
- Clarify help messages and add examples
- Add 'getrawchangeaddress' call for raw transaction change destinations
- Reject insanely high fees by default in 'sendrawtransaction'
- Add RPC call 'decodescript' to decode a hex-encoded transaction script
- Make 'validateaddress' provide redeemScript
- Add 'getnetworkhashps' to get the calculated network hashrate
- New RPC 'ping' command to request ping, new 'pingtime' and 'pingwait'
  in 'getpeerinfo' output
- Adding new 'addrlocal' field to 'getpeerinfo' output
- Add verbose boolean to 'getrawmempool'
- Add rpc command 'getunconfirmedbalance' to obtain total unconfirmed
- Explicitly ensure that wallet is unlocked in `importprivkey`
- Add check for valid keys in `importprivkey`
Command-line options:
- New option: -nospendzeroconfchange to never spend unconfirmed change
- New option: -zapwallettxes to rebuild the wallet's transaction information
- Rename option '-tor' to '-onion' to better reflect what it does
- Add '-disablewallet' mode to let bitcoind run entirely without wallet
  built with wallet)
- Update default '-rpcsslciphers' to include TLSv1.2
- make '-logtimestamps' default on and rework help-message
- RPC client option: '-rpcwait', to wait for server start
- Remove '-logtodebugger'
- Allow `-noserver` with bitcoind
Block-chain handling and storage:
- Update leveldb to 1.15
- Check for correct genesis (prevent cases where a datadir from the wrong
  network is accidentally loaded)
- Allow txindex to be removed and add a reindex dialog
- Log aborted block database rebuilds
- Store orphan blocks in serialized form, to save memory
- Limit the number of orphan blocks in memory to 750
- Fix non-standard disconnected transactions causing mempool orphans
- Add a new checkpoint at block 279,000
- Bug fixes and new regression tests to correctly compute
  the balance of wallets containing double-spent (or mutated) transactions
- Store key creation time. Calculate whole-wallet birthday.
- Optimize rescan to skip blocks prior to birthday
- Let user select wallet file with -wallet=foo.dat
- Consider generated coins mature at 101 instead of 120 blocks
- Improve wallet load time
- Don't count txins for priority to encourage sweeping
- Don't create empty transactions when reading a corrupted wallet
- Fix rescan to start from beginning after importprivkey
- Only create signatures with low S values
- Increase default -blockmaxsize/prioritysize to 750K/50K
- 'getblocktemplate' does not require a key to create a block template
- Mining code fee policy now matches relay fee policy
Protocol and network:
- Drop the fee required to relay a transaction to 0.01mBTC per kilobyte
- Send tx relay flag with version
- New 'reject' P2P message (BIP 0061, see
   for draft)
- Dump addresses every 15 minutes instead of 10 seconds
- Relay OP_RETURN data TxOut as standard transaction type
- Remove CENT-output free transaction rule when relaying
- Lower maximum size for free transaction creation
- Send multiple inv messages if mempool.size > MAX_INV_SZ
- Split MIN_PROTO_VERSION into INIT_PROTO_VERSION and MIN_PEER_PROTO_VERSION
- Do not treat fFromMe transaction differently when broadcasting
- Process received messages one at a time without sleeping between messages
- Improve logging of failed connections
- Bump protocol version to 70002
- Add some additional logging to give extra network insight
- Added new DNS seed from bitcoinstats.com
- Log reason for non-standard transaction rejection
- Prune provably-unspendable outputs, and adapt consistency check for it.
- Detect any sufficiently long fork and add a warning
- Call the -alertnotify script when we see a long or invalid fork
- Fix multi-block reorg transaction resurrection
- Reject non-canonically-encoded serialization sizes
- Reject dust amounts during validation
- Accept nLockTime transactions that finalize in the next block
Build system:
- Switch to autotools-based build system
- Build without wallet by passing `--disable-wallet` to configure, this
  removes the BerkeleyDB dependency
- Upgrade gitian dependencies (libpng, libz, libupnpc, boost, openssl) to
  recent versions
- Windows 64-bit build support
- Solaris compatibility fixes
- Check integrity of gitian input source tarballs
- Enable full GCC Stack-smashing protection for all OSes
- Switch to Qt 5.2.0 for Windows build
- Add payment request (BIP 0070) support
- Improve options dialog
- Show transaction fee in new send confirmation dialog
- Add total balance in overview page
- Allow user to choose data directory on first start, when data directory is
  missing, or when the -choosedatadir option is passed
- Save and restore window positions
- Add vout index to transaction id in transactions details dialog
- Add network traffic graph in debug window
- Add open URI dialog
- Add Coin Control Features
- Improve receive coins workflow: make the 'Receive' tab into a form to
  payments, and move historical address list functionality to File menu.
- Rebrand to `Bitcoin Core`
- Move initialization/shutdown to a thread. This prevents "Not responding"
  messages during startup. Also show a window during shutdown.
- Don't regenerate autostart link on every client startup
- Show and store message of normal bitcoin:URI
- Fix richtext detection hang issue on very old Qt versions
- OS X: Make use of the 10.8+ user notification center to display
  notifications
- OS X: Added NSHighResolutionCapable flag to Info.plist for better font
  rendering on Retina displays.
- OS X: Fix bitcoin-qt startup crash when clicking dock icon
- Linux: Fix Gnome bitcoin: URI handler
- Add Linux script (contrib/qos/tc.sh) to limit outgoing bandwidth
- Add '-regtest' mode, similar to testnet but private with instant block
  generation with 'setgenerate' RPC.
- Add 'linearize.py' script to contrib, for creating bootstrap.dat
- Add separate bitcoin-cli client
Thanks to everyone who contributed to this release:
- Andrey
- Ashley Holman
- b6393ce9-d324-4fe1-996b-acf82dbc3d53
- bitsofproof
- Brandon Dahler
- Calvin Tam
- Christian Decker
- Christian von Roques
- Christopher Latham
- Chuck
- coblee
- constantined
- Cory Fields
- Cozz Lovan
- daniel
- Daniel Larimer
- David Hill
- Dmitry Smirnov
- Drak
- Eric Lombrozo
- fanquake
- fcicq
- Florin
- frewil
- Gavin Andresen
- Gregory Maxwell
- gubatron
- Guillermo C?spedes Tab?rez
- Haakon Nilsen
- HaltingState
- Han Lin Yap
- harry
- Ian Kelling
- Jeff Garzik
- Johnathan Corgan
- Jonas Schnelli
- Josh Lehan
- Josh Triplett
- Julian Langschaedel
- Kangmo
- Lake Denman
- Luke Dashjr
- Mark Friedenbach
- Matt Corallo
- Michael Bauer
- Michael Ford
- Michagogo
- Midnight Magic
- Mike Hearn
- Nils Schneider
- Noel Tiernan
- Olivier Langlois
- patrick s
- Patrick Strateman
- paveljanik
- Peter Todd
- phantomcircuit
- phelixbtc
- Philip Kaufmann
- Pieter Wuille
- Rav3nPL
- R E Broadley
- regergregregerrge
- Robert Backhaus
- Roman Mindalev
- Rune K. Svendsen
- Ryan Niebur
- Scott Ellis
- Scott Willeke
- Sergey Kazenyuk
- Shawn Wilkinson
- Sined
- sje
- Subo1978
- super3
- Tamas Blummer
- theuni
- Thomas Holenstein
- Timon Rapp
- Timothy Stranex
- Tom Geller
- Torstein Huseb?
- Vaclav Vobornik
- vhf / victor felder
- Vinnie Falco
- Warren Togami
- Wil Bown
- Wladimir J. van der Laan

@_date: 2014-03-22 13:33:02
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fake PGP key for Gavin 
Yes, the -setup.exe installers are Authenticode (or whatever Microsoft is
calling that these days) code-signed.

@_date: 2014-03-25 09:50:02
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] New side channel attack that can recover 
Y'all are getting deep into tinfoil-wearing-hat-conspiracy-theory territory.
If you are worried about the NSA compromising your hardware or software,
then use multisig transactions and
sign on diverse hardware/software stacks. Generate the multiple private
keys on different hardware/software
stacks, too.
Or, in other words, eliminate the single point of failure and you will
mitigate whole families of possible attacks,
from "NSA compromised the hardware random number generator in my CPU" to
"NSA is listening to EMF
radiation coming from my dedicated server in my data center" to the much
more likely "data center employee
is tricked into letting somebody have access to my dedicated server."

@_date: 2014-03-28 10:01:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP 70 refund field 
It doesn't.
"walk before you run" and all that; lets see what problems we run into with
the minimal payment protocol we have now (like refund outputs you have to
remember forever) before we create an insurmountable set of problems by
trying to solve everything we can think of all at once.

@_date: 2014-05-19 15:41:15
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Working on social contracts (was: Paper 
Now I'm really confused.
Why would Mike or I have the authority to write a "social contract" to
promise anything about future-Bitcoin?
I thought the only "social contract" was the decentralized one we have
already-- if you don't like something about the code, then don't download
and run it. Or fork it if you're able.
As the person who started this mailing list, I DO feel like I have the
authority to enforce a social contract of "no trolling or flaming or
name-calling" here. I'd very much like to delegate that authority, though;
ideally to some software algorithm that automatically censors topics or
people who don't contribute to a productive discussion.
PS: speaking of productive discussion...
... please change the Subject line when the topic wanders.

@_date: 2014-05-19 16:06:33
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Working on social contracts (was: Paper 
Okey dokey:
I hereby promise and solemnly swear on pain of atomic wedgie that I will
never ever work on or endorse any changes to the Bitcoin system that would
enable any person or group to confiscate, blacklist, or devalue any other
person or group's bitcoin.
RE: writing an RFC: go for it. I have much higher tasks on my TODO list.

@_date: 2014-11-04 09:01:37
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP62 and future script upgrades 
I agree; soft-forking is a useful way of rolling out upgrades, we shouldn't
prohibit it.

@_date: 2014-10-01 11:01:28
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [BIP draft] CHECKLOCKTIMEVERIFY - Prevent 
Very nice, semantics are clear and use cases are compelling.
Can we defer discussion of how to roll this out for a little bit, and see
if there is consensus that:
a) benefits of having this outweigh risks
b) we're all happy with exact semantics
Then we can have a knock-down drag-out argument about whether it should
roll out as a soft fork, wait for a hard fork, be combined with some other
things that it would be nice to add or change, etc.....

@_date: 2014-10-01 16:58:34
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [BIP draft] CHECKLOCKTIMEVERIFY - Prevent 
If the first transaction is P2SH, then the miner won't know there is an
advantage to holding it until it is too late (the scriptPubKey is an opaque
hash until the second transaction is final and relayed/broadcast).

@_date: 2014-10-01 17:34:33
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [BIP draft] CHECKLOCKTIMEVERIFY - Prevent 
No, the burner would supply the funding transaction plus the redeeming
script as the proof-of-burn to whoever needed the proof.
Only after at least one confirmation, if there was some risk that revealing
the redeeming script would make miners refuse to mine that first
transaction because they want to get it plus the CHECKTIMELOCKVERIFY "burn"

@_date: 2014-10-07 11:50:45
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [BIP draft] CHECKLOCKTIMEVERIFY - Prevent 
That is easy to change; I'll submit a pull request. It is a good idea to
get an -alertnotify sooner rather than later for EITHER a hard fork or a
soft-fork. Better to be told you have to upgrade while the block.version is
on its way to being a super-majority than after you are either hard-forked
off the main chain (or soft-forked).
I don't have any opinion on the hard- versus soft- fork debate. I think
either can work.

@_date: 2014-10-15 11:37:57
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] BIP process 
RE: process:
I like author == primary control, and an "assume they will do the right
thing, revert if they don't"
RE: separate mailing list for BIP discussion:
Great idea. Jeff Garzik was looking for a better mailing list solution than
SourceForge, but assuming
there isn't a clearly better solution I think "we" should create a strictly
moderated bitcoin-bips at lists.sourceforge list.

@_date: 2014-10-25 15:16:26
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] death by halving 
We had a halving, and it was a non-event.
Is there some reason to believe next time will be different?

@_date: 2014-10-28 09:59:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Reworking the policy estimation code (fee 
I think Alex's approach is better; I don't think we can know how much
better until we have a functioning fee market.
We don't have a functioning fee market now, because fees are hard-coded. So
we get "pay the hard-coded fee and you'll get confirmed in one or two or
three blocks, depending on which miners mine the next three blocks and what
time of day it is."
git HEAD code says you need a fee of 10,0000 satoshis/kb to be pretty sure
you'll get confirmed in the next block. That looks about right with Alex's
real-world data (if we take "90% chance" as 'pretty sure you'll get
Fee rate 100000 Avg blocks to confirm 1.09 NumBlocks:% confirmed 1: 0.901
2: 1.0   3: 1.0
My only concern with Alex's code is that it takes much longer to get
'primed' -- Alex, if I started with no data about fees, how long would it
take to be able to get enough data for a reasonable estimate of "what is
the least I can pay and still be 90% sure I get confirmed in 20 blocks" ?
Hours? Days? Weeks?

@_date: 2014-10-28 10:58:36
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Reworking the policy estimation code (fee 
RE: 80% versus 90% :  I think a default of 80% will get us a lot of "the
fee estimation logic is broken, I want my transactions to confirm quick and
a lot of them aren't confirming for 2 or 3 blocks."
RE: RPC argument:  I'm reluctant to give too many 'knobs' for the RPC
interface. I think the default percentage makes sense as a
command-line/bitcoin.conf option; I can imagine services that want to save
on fees running with -estimatefeethreshold=0.5  (or
-estimatefeethreshold=0.95 if as-fast-as-possible confirmations are
needed). Setting both the number of confirmations and the estimation
threshold on a transaction-by-transaction basis seems like overkill to me.

@_date: 2015-08-03 11:22:14
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Eli Dourado on "governance" 
I haven't seen this excellent recent blog post by Eli Dourado referenced
  I agree with his conclusions: we need better communication/organization
mechanisms among 'stakeholders' and between the various factions
(developers, miners, merchants, exchanges, end-users).
And the preliminary results of using a prediction market to try to wrestle
with the tough tradeoffs looks roughly correct to me, too:
   (my only big disagreement with those predictions is the 'Number of nodes'

@_date: 2015-08-03 18:21:30
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Eli Dourado on "governance" 
No, I think one of the fundamental problems with the Foundation is it tries
to represent everybody's interests. The interests of exchanges are not
necessarily the same as end-users or miners, for example.
But it would make sense for exchanges (for example) to get together and
come to consensus on whatever issues are important to them, like the recent
consensus and then statement from "the Chinese miners" regarding the block
size issue.

@_date: 2015-08-04 09:12:36
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Block size following technological growth 
And that is a problem... why?
As far as I can tell, nobody besides miners running old and/or buggy
software lost money due to outsourced mining validation (please correct me
if I'm wrong-- I'm looking forward to Greg's post-mortem). The operators of
bitcoin.org seem to have freaked out and pushed the panic button (with dire
warnings of not trusting transactions until 20 confirmations), but theymos
was well known for using an old, patched version of Core for
blockexplorer.com so maybe that's not surprising.
As Bitcoin grows, pieces of the ecosystem will specialize. Satoshi's
original code did everything: hashing, block assembly, wallet, consensus,
network. That is changing, and that is OK.
I understand there are parts of the ecosystem you'd rather not see
specialized, like transaction selection / block assembly or validation. I
see it as a natural maturation. The only danger I see is if some unnatural
barriers to competition spring up.
outsourcing of full validation keeps growing.
Both side effects of increasing specialization, in my opinion. Many
companies quite reasonably would rather hire somebody who specializes in
running nodes, keeping keys secure, etc rather than develop that expertise
Again, not a problem UNLESS some unnatural barriers to competition spring
I understand you want to build an extremely decentralized system, where
everybody participating trusts nothing except the genesis block hash.
I think it is more interesting to build a system that works for hundreds of
millions of people, with no central point of control and the opportunity
for ANYBODY to participate at any level. Permission-less innovation is what
I find interesting.
And I think the current "demonstrably terrible" Bitcoin system is still
INCREDIBLY interesting.

@_date: 2015-08-04 17:30:28
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] "A Transaction Fee Market Exists Without a Block 
On Tue, Aug 4, 2015 at 2:41 PM, Dave Hudson via bitcoin-dev <
Unless the block maker has an infinitely fast connection to it's hashpower
OR it's hashpower is not parallelized at all, that's not strictly true --
it WILL orphan its own blocks because two hashing units will find solutions
in the time it takes to communicate that solution to the block maker and to
the rest of the hashing units.
That's getting into "how many miners can dance on the head of a pin"
territory, though. I don't think we know whether the communication
advantages of putting lots of hashing power physically close together will
outweigh the extra cooling costs of doing that (or maybe some other
tradeoff I haven't thought of). That would be a fine topic for another

@_date: 2015-08-05 19:51:03
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Superluminal communication and the consensus 
No, it depends on all of the variables that go into the mining
profitability equation.
Does miner B have access to cheaper electricity than miner A?
Access to more advanced mining hardware, sooner?
Ability to use excess heat generated from mining productively?
Access to inexpensive labor to oversee their operations?
Access to inexpensive capital to finance investment in hardware?
The number of fee-paying transactions a miner can profitably include in
their blocks will certainly eventually be part of that equation (it is
insignificant today), and that's fantastic-- we WANT miners to include lots
of transactions in their blocks.

@_date: 2015-08-06 09:40:39
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Block size following technological growth 
It REALLY doesn't help the debate when you say patently false statements
like that.
My first blog post on this issue is here:
  ... and I NEVER say "Bitcoin will fail".  I say:
"If the number of transactions waiting gets large enough, the end result
will be an over-saturated network, busy doing nothing productive. I don?t
think that is likely? it is more likely people just stop using Bitcoin
because transaction confirmation becomes increasingly unreliable."
Mike sketched out the worst-case here:
  ... and concludes:
"I believe there are no situations in which Bitcoin can enter an overload
situation and come out with its reputation and user base intact. Both would
suffer heavily and as Bitcoin is the founder of the cryptocurrency concept,
the idea itself would inevitably suffer some kind of negative
So please stop with the over-the-top claims about what "the other side"
believe, there are enough of those (on both sides of the debate) on reddit.
I'd really like to focus on how to move forward, and how best to resolve
difficult questions like this in the future.

@_date: 2015-08-06 10:21:54
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Block size following technological growth 
No, competition for block space is good.
What is bad is artificially limiting or centrally controlling the supply of
that space.

@_date: 2015-08-06 11:24:58
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Fwd:  Block size following technological growth 
Yes, that's fine. If the network cannot handle the transaction volume that
people want to pay for, then the marginal transactions are priced out. That
is true today (otherwise ChangeTip would be operating on-blockchain), and
will be true forever.
"better is better" -- I applaud efforts to fundamentally improve the
scalability of the system, but I am an old, cranky, pragmatic engineer who
has seen that successful companies tackle problems that arise and are
willing to deploy not-so-perfect solutions if they help whatever short-term
problem they're facing.
I think consensus is against you on that point.

@_date: 2015-08-06 12:03:57
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Block size following technological growth 
Fees are already above zero. See
3) Does this mean that you would be in favor of completely removing
I don't believe that the maximum block size has much at all to do with
mining centralization, so I don't accept the premise of the question.

@_date: 2015-08-06 15:42:10
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Block size following technological growth 
Two answers:
1. If you are willing to wait an infinite amount of time, I think the
minimum fee will always be zero or very close to zero, so I think it's a
silly question.
2. The "market minimum fee" should be determined by the market. It should
not be up to us to decide "when is a good time."
Sure, if keeping up with transaction volume requires a cluster of computers
or more than "pretty good" broadband bandwidth I think that's too far.
That's where original 20MB limit comes from, otherwise I'd have proposed a
much higher limit.
Although I've been very clear with my criterion, no, I don't think all
blocksize increase proposals should have to justify "why this size" or "why
this rate of increase." Part of my frustration with this whole debate is
we're talking about a sanity-check upper-limit; as long as it doesn't open
up some terrible new DoS possibility I don't think it really matters much
what the exact number is.
It prevents trivial denial-of-service attacks (e.g. I promise to send you a
1 Terabyte block, then fill up your memory or disk...).
 I said that the block limit has LITTLE effect
on MINING centralization.  Not "no effect on any type of centralization."
If the limit was removed entirely, it is certainly possible we'd end up
with very few organizations (and perhaps zero individuals) running full

@_date: 2015-08-07 10:57:23
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Fees and the block-finding process 
Popping this into it's own thread:
Jorge asked:
I answered:
Which Jorge misinterpreted to mean that I think there will always be at
least one miner willing to mine a transaction for free.
That's not what I'm thinking. It is just an observation based on the fact
that blocks are found at random intervals.
Every once in a while the network will get lucky and we'll find six blocks
in ten minutes. If you are deciding what transaction fee to put on your
transaction, and you're willing to wait until that
six-blocks-in-ten-minutes once-a-week event, submit your transaction with a
low fee.
All the higher-fee transactions waiting to be confirmed will get confirmed
in the first five blocks and, if miners don't have any floor on the fee
they'll accept (they will, but lets pretend they won't) then your
very-low-fee transaction will get confirmed.
In the limit, that logic becomes "wait an infinite amount of time, pay zero
So... I have no idea what the 'market minimum fee' will be, because I have
no idea how long people will be willing to wait, how many times they'll be
willing to retransmit a low-fee transaction that gets evicted from
memory-limited memory pools, or how much memory miners will be willing to
dedicate to storing transactions that won't confirm for a long time because
they're waiting for a flurry of blocks to be found.

@_date: 2015-08-07 11:55:09
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Fees and the block-finding process 
I think there are multiple reasons to raise the maximum block size, and
yes, fear of Bad Things Happening as we run up against the 1MB limit is one
of the reasons.
I take the opinion of smart engineers who actually do resource planning and
have seen what happens when networks run out of capacity very seriously.
And if so, if that is a reason for increase now, won't it be a reason for
Sure, it might be a reason for an increase later. Here's my message to
in-the-future Bitcoin engineers:  you should consider raising the maximum
block size if needed and you think the benefits of doing so (like increased
adoption or lower transaction fees or increased reliability) outweigh the
costs (like higher operating costs for full-nodes or the disruption caused
by ANY consensus rule change).

@_date: 2015-08-07 13:50:00
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Fwd: Block size following technological growth 
On Fri, Aug 7, 2015 at 12:30 PM, Pieter Wuille via bitcoin-dev <
Are you saying that unless the majority of people in the ecosystem decide
to trust nothing but the genesis block hash (decide to run a full node)
there is a problem?
If so, then we do have a fundamental difference of opinion, but I've
misunderstood how you think about trust/centralization/convenience
tradeoffs in the past.
I believe people in the Bitcoin ecosystem will choose different tradeoffs,
and I believe that is OK-- people should be free to make those tradeoffs.
And given that the majority of people in the ecosystem were deciding that
using a centralized service or an SPV-level-security wallet was better even
two or three years ago when blocks were tiny (I'd have to go back and dig
up number-of-full-nodes and number-of-active-wallets at the big web-wallet
providers, but I bet there were an order of magnitude more people using
centralized services than running full nodes even back then), I firmly
believe that block size has very little to do with the decision to run a
full node or not.

@_date: 2015-08-09 18:44:08
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] What Lightning Is 
While we're on the subject of payment hubs / lightning network...
I'd love to see somebody write up a higher-level description of what the
user experience is like, what communication happens underneath, and what
new pieces of infrastructure need to get built to make it all work.
A use-case to start with:
A customer starts with eleven on-chain bitcoin. They want to pay for a nice
cup of tea. Walk me through what happens before/during/after the
transaction, assuming I have a  lightning-enabled wallet on my iPhone and
the tea shop has a lightning-enabled cash register.
Assume neither the customer nor the tea shop are technically sophisticated

@_date: 2015-08-10 10:12:05
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Fees and the block-finding process 
It is frustrating to answer questions that we answered months ago,
especially when I linked to these in response to your recent "increase
advocates say that not increasing the max block size will KILL BITCOIN"
false claim:
    Executive summary: when networks get over-saturated, they become
unreliable.  Unreliable is bad.
Unreliable and expensive is extra bad, and that's where we're headed
without an increase to the max block size.
RE: the recent thread about "better deal with that type of thing now rather
than later" :  exactly the same argument can be made about changes needed
to support a larger block size-- "better to do that now than to do that
later."  I don't think either of those arguments are very convincing.

@_date: 2015-08-27 09:28:29
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIPS proposal for implementing AML-KYC in bitcoin 
Have you talked with anybody at the Bitcoin Foundation about this proposal?
As Chief Scientist of the Foundation, I am strongly opposed to any proposal
that puts the Foundation in a position of centralized authority, so this is
unacceptable: "The Bitcoin Foundation will act as fair play party and
enforcement body to control the misuse of vast financial powers which
bitcoin has."
The idea that a central organization can be trusted to keep secrets secure
is just fundamentally wrong. In the very recent past we have seen
government organizations fail in that task (the NSA, the OPM) and we see
commercial organizations that SHOULD be highly motivated to do a good job
also fail (e.g. the Ashley Madison leak).
Even if it were technically possible, I would be opposed because
decentralization is a bedrock principle of Bitcoin.

@_date: 2015-08-27 09:48:47
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIPS proposal for implementing AML-KYC in bitcoin 
This is a development list; organizations like  work
on high-level policy issues.
Last I heard, competent law enforcement organizations said they were
perfectly capable of tracking down criminals using Bitcoin using
traditional investigative techniques (like infiltrating criminal
organizations or setting up honeypots). Given how many "dark markets" have
either disappeared or been taken down, it seems they are correct.

@_date: 2015-08-28 18:24:01
@_author: Gavin 
@_subject: [bitcoin-dev] Consensus based block size retargeting algorithm 
With this proposal, how much would it cost a miner to include an 'extra' 500-byte transaction if the average block size is 900K and it costs the miner 20BTC in electricity/capital/etc to mine a block?
If my understanding of the proposal is correct, it is:
500/900000 * 20 = 0.11111 BTC
... Or $2.50 at today's exchange rate.
That seems excessive.
Gavin Andresen

@_date: 2015-12-03 14:14:55
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] [BIP Draft] Datastream compression of Blocks and 
On Wed, Dec 2, 2015 at 1:57 PM, Emin G?n Sirer <
I love this idea. Lets build a standardized data set to test against using
real data from the network (has anybody done this yet?).
Something like:
Starting network topology:
list of:  nodeid, nodeid, network latency between the two peers
Changes to network topology:
list of:  nodeid, add/remove nodeid, time of change
Transaction broadcasts:
list of :  transaction, node id that first broadcast, time first broadcast
Block broadcasts:
list of :  block, node id that first broadcast, time first broadcast
Proposed transaction/block optimizations could then be measured against
this standard data set.

@_date: 2015-12-04 12:34:27
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Blockchain verification flag (BIP draft) 
Overall, good idea.
Is there a write-up somewhere describing in detail the 'accidental selfish
mining' problem that this mitigates? I think a link in the BIP to a fuller
description of the problem and how validation-skipping makes it go away
would be helpful.
RE: which bit to use:  the draft versionbits BIP and BIP101 use bit 30; to
avoid confusion, I think it would be better to use bit 0.
I agree with Jannes Faber, behavior with respect to SPV clients should be
to only tell them about fully validated headers. And I also agree that
immediately relaying full-proof-of-work blocks before validation (with an
indication that they haven't been fully validated) is a good idea, but that
discussion didn't reach consensus when I brought it up two years ago (

@_date: 2015-12-08 10:12:10
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Capacity increases for the Bitcoin system. 
Thanks for laying out a road-map, Greg.
I'll need to think about it some more, but just a couple of initial
Why segwitness as a soft fork? Stuffing the segwitness merkle tree in the
coinbase is messy and will just complicate consensus-critical code (as
opposed to making the right side of the merkle tree in block.version=5
blocks the segwitness data).
It will also make any segwitness fraud proofs significantly larger (merkle
path versus  merkle path to coinbase transactions, plus ENTIRE coinbase
transaction, which might be quite large, plus merkle path up to root).
We also need to fix the O(n^2) sighash problem as an additional BIP for ANY
blocksize increase. That also argues for a hard fork-- it is much easier to
fix it correctly and simplify the consensus code than to continue to apply
band-aid fixes on top of something fundamentally broken.
Segwitness will require a hard or soft-fork rollout, then a significant
fraction of the transaction-producing wallets to upgrade and start
supporting segwitness-style transactions.  I think it will be much quicker
than the P2SH rollout, because the biggest transaction producers have a
strong motivation to lower their fees, and it won't require a new type of
bitcoin address to fund wallets.  But it still feels like it'll be six
months to a year at the earliest before any relief from the current
problems we're seeing from blocks filling up.
Segwitness will make the current bottleneck (block propagation) a little
worse in the short term, because of the extra fraud-proof data.  Benefits
well worth the costs.
I think a barrier to quickly getting consensus might be a fundamental
difference of opinion on this:
   "Even without them I believe we?ll be in an acceptable position with
respect to capacity in the near term"
The heaviest users of the Bitcoin network (businesses who generate tens of
thousands of transactions per day on behalf of their customers) would
strongly disgree; the current state of affairs is NOT acceptable to them.

@_date: 2015-12-08 20:09:16
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Capacity increases for the Bitcoin system. 
Here's the attack:
Create a 1-megabyte transaction, with all of it's inputs spending
segwitness-spending SIGHASH_ALL inputs.
Because the segwitness inputs are smaller in the block, you can fit more of
them into 1 megabyte. Each will hash very close to one megabyte of data.
That will be O(n^2) worse than the worst case of a 1-megabyte transaction
with signatures in the scriptSigs.
Did I misunderstand something or miss something about the 1-mb transaction
data and 3-mb segwitness data proposal that would make this attack not
RE: fraud proof data being deterministic:  yes, I see, the data can be
computed instead of broadcast with the block.
RE: emerging consensus of Core:
I think it is a huge mistake not to "design for success" (see
 ).
I think it is a huge mistake to pile on technical debt in
consensus-critical code. I think we should be working harder to make things
simpler, not more complex, whenever possible.
And I think there are pretty big self-inflicted current problems because
worries about theoretical future problems have prevented us from coming to
consensus on simple solutions.

@_date: 2015-12-09 11:40:34
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Capacity increases for the Bitcoin system. 
So just design ahead for those future uses. Make the merkle tree:
             root_in_block_header
                     /      \
  tx_data_root      other_root
                               /       \
        segwitness_root     reserved_for_future_use_root
... where reserved_for_future_use is zero until some future block version
(or perhaps better, is just chosen arbitrarily by the miner and sent along
with the block data until some future block version).
That would minimize future disruption of any code that produced or consumed
merkle proofs of the transaction data or segwitness data, especially if the
reserved_for_future_use_root is allowed to be any arbitrary 256-bit value
and not a constant that would get hard-coded into segwitness-proof-checking

@_date: 2015-12-11 11:43:40
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Capacity increases for the Bitcoin system. 
Any code that just checks merkle paths up into the block header would have
to change if the structure of the merkle tree changed to be three-headed at
the top.
If it remains a binary tree, then it doesn't need to change at all-- the
code that produces the merkle paths will just send a path that is one step
Plus, it's just weird to have a merkle tree that isn't a binary tree.....

@_date: 2015-02-03 13:19:50
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [softfork proposal] Strict DER signatures 
I think we should just do it, and include it with the other DERSIG changes
for 0.10.
On Tue, Feb 3, 2015 at 1:15 PM, Pieter Wuille

@_date: 2015-01-21 15:37:06
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [softfork proposal] Strict DER signatures 
DERSIG BIP looks great to me, just a few nit-picky changes suggested:
You mention the "DER standard" : should link to
 (or
whatever is best reference for DER).
"this would simplify avoiding OpenSSL in consensus implementations"  -->
"this would make it easier for non-OpenSSL implementations"
"causing opcode failure"  : I know what you mean by "opcode failure", but
it might be good to be more explicit.
"since v0.8.0, and nearly no transactions" -->  "and very few
"reducing this avenue for malleability is useful on itself as well"  :
awkward English. How about just "This proposal has the added benefit of
reducing transaction malleability (see BIP62)."

@_date: 2015-01-31 17:50:15
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] New BIP: protocol for multisignature 
I agree- standards should be descriptive ("here is how this thing I did
works") and NOT proscriptive ("here's what I think will work, lets all try
to do it this way.").

@_date: 2015-07-20 15:10:26
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] For discussion: limit transaction size to mitigate 
Draft BIP to prevent a potential CPU exhaustion attack if a significantly
larger maximum blocksize is adopted:
  Title: Limit maximum transaction size
  Author: Gavin Andresen   Status: Draft
  Type: Standards Track
  Created: 2015-07-17
Mitigate a potential CPU exhaustion denial-of-service attack by limiting
the maximum size of a transaction included in a block.
Sergio Demian Lerner reported that a maliciously constructed block could
take several minutes to validate, due to the way signature hashes are
computed for OP_CHECKSIG/OP_CHECKMULTISIG ([[
Each signature validation can require hashing most of the transaction's
bytes, resulting in O(s*b) scaling (where n is the number of signature
operations and m is the number of bytes in the transaction, excluding
signatures). If there are no limits on n or m the result is O(n^2) scaling.
This potential attack was mitigated by changing the default relay and
mining policies so transactions larger than 100,000 bytes were not
relayed across the network or included in blocks. However, a miner
not following the default policy could choose to include a
transaction that filled the entire one-megaybte block and took
a long time to validate.
After deployment, the maximum serialized size of a transaction allowed
in a block shall be 100,000 bytes.
This change should be compatible with existing transaction-creation
because transactions larger than 100,000 bytes have been considered
(they are not relayed or mined by default) for years.
Software that assembles transactions into blocks and that validates blocks
must be
updated to reject oversize transactions.
This change will be deployed with BIP 100 or BIP 101.
Alternatives to this BIP:
1. A new consensus rule that limits the number of signature operations in a
single transaction instead of limiting size. This might be more compatible
future opcodes that require larger-than-100,000-byte transactions, although
any such future opcodes would likely require changes to the Script
rules anyway (e.g. the 520-byte limit on data items).
2. Fix the SIG opcodes so they don't re-hash variations of the
transaction's data.
This is the "most correct" solution, but would require updating every
piece of transaction-creating and transaction-validating software to change
they compute the signature hash.
[[ Sergio Demian
Lerner's original report

@_date: 2015-07-20 16:30:08
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] For discussion: limit transaction size to 
Mmmm.... you'd have to:
a) Have lost or thrown away the keys to the unspent transaction outputs
b) Have created a locktime'd transaction with a lock time after the
BIP100/101 switchover times
that is more than 100,000 bytes big
c) Have some special relationship with a miner that you trust to still be
around when the transaction
unlocks that would mine the bigger-than-standard transaction for you.
I don't think adding extra complexity to consensus-critical code to support
such an incredibly unlikely
scenario is the right decision here. I think it is more likely that the
extra complexity would trigger a bug
that causes a loss of bitcoin greater than the amount of bitcoin tied up in
locktime'ed transactions
(because I think there are approximately zero BTC tied up in >100K
locktime'ed transactions).
RE: limit size of transaction+parents:  Feature creep, belongs in another
BIP in my opinion. This one
is focused on fixing CVE-2013-2292

@_date: 2015-07-21 14:09:19
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] For discussion: limit transaction size to 
Yes.  The tradeoff is implementation complexity: it is trivial to check
transaction size,
not as trivial to count signature operations, because
doesn't require any context.
But I would REALLY hate myself if in ten years a future version of me was
struggling to
get consensus to move away from some stupid 100,000 byte transaction size
I imposed to mitigate a potential DoS attack.
So I agree, a limit on sigops is the right way to go. And if that is being
might as well accurately count exactly how many sigops a transaction
requires to be validated...

@_date: 2015-07-22 17:06:02
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIP: Short Term Use Addresses for Scalability 
That's the killer: introducing Yet Another Type of Bitcoin Address takes a
very long time and requires a lot of people to change their code. At least,
that was the lesson learned when we introduced P2SH addresses.
I think it's just not worth it for a very modest space savings (10 bytes,
when scriptSig+scriptPubKey is about 120 bytes), especially with the
extreme decrease in security (going from 2^160 to 2^80 to brute-force).

@_date: 2015-07-23 11:04:39
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Bitcoin Node Speed Test 
Ahh, data... a breath of fresh air...
Can you re-analyze for 8MB blocks?  There is no current proposal for 20MB
Also, most hashing power is now using Matt Corallo's fast block propagation
network; slow 'block' propagation to merchants/end-users doesn't really
matter (as long as it doesn't get anywhere near the 10-minute block time).
On Thu, Jul 23, 2015 at 10:19 AM, slurms--- via bitcoin-dev <

@_date: 2015-07-23 11:41:18
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] For discussion: limit transaction size to 
To get a feeling for the implementation complexity / correctness tradeoff,
I implemented changes to Core to count exactly how many signature operations
are performed and how many bytes are hashed to compute sighashes:
I haven't benchmarked how much keeping track of the counts affects
performance (but I expect
it to be minimal compared to ECDSA signature validation, accessing inputs
from the UTXO, etc).
I like the idea of a consensus rule that directly addresses the attack--
e.g. "validating
a transaction must not require more than X megabytes hashed to compute
signature hashes."
(or: "validating a block must not require more than X megabytes hashed..."
which is
more symmetric with the current "maximum number of sigops allowed per
Thinking about this and looking at block 364,292, I think I see a simple
optimization that would
speed up validation for transactions with lots of inputs:  use
for all of the inputs instead of SIGHASH_ALL.
(which would make the transaction malleable-- if that's a concern, then
make one of the inputs
SIGHASH_ALL and the rest SIGHASH_ANYONECANPAY-- I think this is a change
should be made to Core and other wallets should make).
I'd like to hear from maintainers of other full implementations: how hard
would it be for you
to keep track of the number of bytes hashed to validate a transaction or
block, and use
it as a consensus rule?

@_date: 2015-07-23 12:28:44
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Bitcoin Core and hard forks 
On Thu, Jul 23, 2015 at 12:17 PM, Tom Harding via bitcoin-dev <
Yes! Lets plan for success!
I'd really like to move from "IMPOSSIBLE because...  (electrum hasn't been
(by the way: you should run on SSDs, LevelDB isn't designed for spinning
what if the network is attacked?  (attacked HOW???), current p2p network is
the simplest, stupidest possible block propagation algorithm...)"
... to "lets work together and work through the problems and scale it up."
I'm frankly tired of all the negativity here; so tired of it I've decided
to mostly ignore
all the debate for a while, not respond to misinformation I see being spread
(like "miners have some incentive to create slow-to-propagate blocks"),
work with people like Tom and Mike who have a 'lets get it done' attitude,
focus on what it will take to scale up.

@_date: 2015-07-23 15:35:10
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Bitcoin Core and hard forks 
There are so many things wrong with this paragraph I just can't let it
"Mainstream usage will be enabled primarily by..."  Maybe. Maybe not, we
don't know what use case(s) will primarily take cryptocurrency mainstream.
I believe it is a big mistake to pick one and bet "THIS is going to be the
"we can address it either by... or..."  False dichotomy. There are lots of
things we can do to decrease costs, and a lot of things have ALREADY been
done (e.g. running a pruned full node).  I HATE the "it must be this or
that" "us or them" attitude, it fosters unproductive bickering and
(and yes, I'm human, I'm sure you can find instances in the recent past
where I did it, too... mea culpa)

@_date: 2015-07-24 16:59:40
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] For discussion: limit transaction size to 
After thinking about it, implementing it, and doing some benchmarking, I'm
convinced replacing the existing, messy, ad-hoc sigop-counting consensus
rules is the right thing to do.
The last two commits in this branch are an implementation:
   Summary of old rules / new rules:
Old rules: 20,000 inaccurately-counted-sigops for a 1MB block
New: 80,000 accurately-counted sigops for an 8MB block
A scan of the last 100,000 blocks for high-sigop blocks gets
a maximum of 7,350 sigops in block 364,773 (in a single, huge,
~1MB transaction).
For reference, Pieter Wuille's libsecp256k1 validation code
validates about 10,000 signatures per second on a single
2.7GHZ CPU core.
Old rules: no limit for number of bytes hashed to generate
signature hashes
New rule: 1.3gigabytes hashed per 8MB block to generate
signature hashes
Block 364,422 contains a single ~1MB transaction that requires
1.2GB of data hashed to generate signature hashes.
TODO: benchmark Core's sighash-creation code ('openssl speed sha256'
reports something like 1GB per second on my machine).
Note that in normal operation most validation work is done as transactions
are received from the network, and can be cached so it doesn't have to be
repeated when a new block is found. The limits described in this BIP are
intended, as the existing sigop limits are intended, to be an extra "belt
and suspenders" measure to mitigate any possible attack that involves
creating and broadcasting a very expensive-to-verify block.
Draft BIP:
  BIP: ??
  Title: Consensus rules to limit CPU time required to validate blocks
  Author: Gavin Andresen   Status: Draft
  Type: Standards Track
  Created: 2015-07-24
Mitigate potential CPU exhaustion denial-of-service attacks by limiting
the maximum number of ECDSA signature verfications done per block,
and limiting the number of bytes hashed to compute signature hashes.
Sergio Demian Lerner reported that a maliciously constructed block could
take several minutes to validate, due to the way signature hashes are
computed for OP_CHECKSIG/OP_CHECKMULTISIG ([[
Each signature validation can require hashing most of the transaction's
bytes, resulting in O(s*b) scaling (where s is the number of signature
operations and b is the number of bytes in the transaction, excluding
signatures). If there are no limits on s or b the result is O(n^2) scaling
(where n is a multiple of the number of bytes in the block).
This potential attack was mitigated by changing the default relay and
mining policies so transactions larger than 100,000 bytes were not
relayed across the network or included in blocks. However, a miner
not following the default policy could choose to include a
transaction that filled the entire one-megaybte block and took
a long time to validate.
After deployment, the existing consensus rule for maximum number of
signature operations per block (20,000, counted in two different,
idiosyncratic, ad-hoc ways) shall be replaced by the following two rules:
1. The maximum number of ECDSA verify operations required to validate
all of the transactions in a block must be less than or equal to
the maximum block size in bytes divided by 100 (rounded down).
2. The maximum number of bytes hashed to compute ECDSA signatures for
all transactions in a block must be less than or equal to the
maximum block size in bytes times 160.
This change is compatible with existing transaction-creation software,
because transactions larger than 100,000 bytes have been considered
(they are not relayed or mined by default) for years, and a block full of
"standard" transactions will be well-under the limits.
Software that assembles transactions into blocks and software that validates
blocks must be updated to enforce the new consensus rules.
This change will be deployed with BIP 100 or BIP 101.
Linking these consensus rules to the maximum block size allows more
and/or transactions with more inputs or outputs to be included if the
block size increases.
The constants are chosen to be maximally compatible with the existing
consensus rule,
and to virtually eliminate the possibility that bitcoins could be lost if
somebody had locked some funds in a pre-signed, expensive-to-validate,
But they are chosen to put a reasonable upper bound on the CPU time
required to validate
a maximum-sized block.
===Alternatives to this BIP:===
1. A simple limit on transaction size (e.g. any transaction in a block must
be 100,000
bytes or smaller).
2. Fix the CHECKSIG/CHECKMULTISIG opcodes so they don't re-hash variations
the transaction's data. This is the "most correct" solution, but would
updating every piece of transaction-creating and transaction-validating
to change how they compute the signature hash, and to avoid potential
attacks would
still require some limit on how many such operations were permitted.
[[ Sergio Demian
Lerner's original report

@_date: 2015-07-30 08:29:49
@_author: Gavin 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure isn't 
I would like (and have been asking) those people to take the time to quantify those costs and write up those risks in a careful way.
I believe the costs and risks of 8MB blocks are minimal, and that the benefits of supporting more transaction FAR outweigh those costs and risks, but it is hard to have a rational conversation about that when even simple questions like 'what is s reasonable cost to run a full node' are met with silence.

@_date: 2015-07-30 10:05:34
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure isn't 
On Thu, Jul 30, 2015 at 8:50 AM, Pieter Wuille Yes, lets do that-- that is EXACTLY what BIP101 intends to do.
With the added belt&suspenders reality check of miners, who won't produce
blocks too big for whatever technology they're using.
So what do you think the scalability road map should look like? Should we
wait to hard fork until Blockstream Elements is ready for deploying on the
main network, and then have One Grand Hardfork that introduces all the
scalability work you guys have been working on (like Segregated Witness and
Or is the plan to avoid controversy by people voluntarily moving their
bitcoin to a sidechain where all this scaling-up innovation happens?
No plan for how to scale up is the worst of all possible worlds, and the
lack of a direction or plan(s) is my main objection to the current status
And any plan that requires inventing brand-new technology is going to be
riskier than scaling up what we already have and understand, which is why I
think it is worthwhile to scale up what we have IN ADDITION TO working on
great projects like Segregated Witness and Lightning.

@_date: 2015-07-30 11:55:50
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Why Satoshi's temporary anti-spam measure 
On Thu, Jul 30, 2015 at 11:24 AM, Bryan Bishop via bitcoin-dev <
This is a meme that keeps coming up that I think just isn't true.
What other decentralized systems can we look at as role models?
How decentralized are they?
And why did they succeed when "more efficient" centralized systems did not?
The Internet is the most successful decentralized system to date; what
lessons should we learn?
How decentralized is the technology of the Internet (put aside governance
and the issues of who-assigns-blocks-of-IPs-and-registers-domain-names)?
How many root DNS servers?  How many BGP routers along the backbone would
need to be compromised to disrupt traffic? Why don't we see more
disruptions, or why are people willing to tolerate the disruptions that DO
And how did the Internet out-compete more efficient centralized systems
from the big telecom companies?  (I remember some of the arguments that
unreliable, inefficient packet-switching would never replace dedicated
circuits that couldn't get congested and didn't have inefficient timeouts
and retransmissions)
What other successful or unsuccessful decentralized systems should we be
looking at?
I'm old-- I graduated from college in 1988, so I've worked in tech through
the entire rise of the Internet. The lessons I believe we should take away
is that a system doesn't have to be perfect to be successful, and we
shouldn't underestimate people's ability to innovate around what might seem
to be insurmountable problems, IF people are given the ability to innovate.
Yes, people will innovate within a 1MB (or 1MB-scaling-to-2MB by 2021) max
block size, and yes, smaller blocks have utility. But I think we'll get a
lot more innovation and utility without such small, artificial limits.

@_date: 2015-07-30 12:20:30
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Block size following technological growth 
First, THANK YOU for making a concrete proposal!
Specific comments:
So we'd get to 2MB blocks in the year 2021. I think that is much too
conservative, and the most likely effect of being that conservative is that
the main blockchain becomes a settlement network, affordable only for
large-value transactions.
I don't think your proposal strikes the right balance between
centralization of payments (a future where only people running payment
hubs, big merchants, exchanges, and wallet providers settle on the
blockchain) and centralization of mining.
I'll comment on using median time generally in Jorge's thread, but why does
monotonically increasing matter for max block size? I can't think of a
reason why a max block size of X bytes in block N followed by a max size of
X-something bytes in block N+1 would cause any problems.

@_date: 2015-07-30 14:16:22
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Consensus fork activation thresholds: Block.nTime 
I still think using the version and timestamp fields in the block header
are simplest and best.
  Available to SPV nodes with no change to the network protocol
  Available after headers downloaded, before full block data is available
  Once well past a fork, allows all block validation except validation
against the UTXO to happen in parallel, out-of-order, independent of any
other block.
  Not monotonically increasing
I think discussion about transactions in the memory pool are just a
distraction: no matter what criteria is used (timestamp, height, median
time), a blockchain re-organization could mean the validity of transactions
you've accepted into the memory pool (if you're accepting transactions that
switch from valid to invalid at the consensus change -- Core tries hard not
to do that via IsStandard policy) must be re-evaluated.
I don't strongly care if median time or block timestamp is used, I think
either will work. I don't like height, there are too many cases where the
time is known but the block height isn't (see, for example, the
max-outputs-in-a-transaction sanity check computation at line 190 of
bitcoin-tx.cpp -- bitcoin-tx.cpp has no idea what the current block height

@_date: 2015-06-01 09:15:18
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
You said that no, on contrary those who make big blocks have a disadvantage.
Did you just lie to Chun?
Chun said that if somebody produced a big block it would take them at least
6 seconds to process it.
He also said he has nodes outside the great firewall ("We also use Aliyun
and Linode cloud services for block
So I assumed that he was talking about the "what if somebody produces a
block that takes a long time to process" attack -- which doesn't work (the
attacker just increases their own orphan rate).
If the whole network is creating blocks that takes everybody (except the
person creating the blocks) six seconds to broadcast+validate, then the
increase in orphan rate is spread out over the whole network. The
network-wide orphan rate goes up, everybody suffers a little (fewer blocks
created over time) until the next difficulty adjustment, then the
difficulty drops, then everybody is back in the same boat.
If it takes six seconds to validate because of limited bandwidth, then he
should connect via Matt's fast relay network, which optimize new block
announcements so they take a couple orders of magnitude less bandwidth.
If it takes six seconds because he's trying to validate on a raspberry
pi.... then he should buy a better validating machine, and/or help test the
current pending pull requests to make validation faster (e.g.
 or
 ).
If Chun had six seconds of latency, and he can't pay for a lower-latency
connection (or it is insanely expensive), then there's nothing he can do,
he'll have to live with a higher orphan rate no matter the block size.

@_date: 2015-06-01 09:37:11
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
RE: going to the public:
I started pushing privately for SOMETHING, ANYTHING to be done, or at the
very least for there to be some coherent plan besides "wait and see" back
in February.
As for it being unhealthy for me to write the code that I think should be
written and asking people to run it:
Ok. What would you suggest I do? I believe scaling up is the number one
priority right now. I think core devs SHOULD be taking time to solve it,
because I think the uncertainty of how it will be solved (or if it will be
solved) is bad for Bitcoin.
I think working on things like fixing transaction malleability is great...
but the reason to work on that is to enable smart contracts and all sorts
of other interesting new uses of the blockchain. But if we're stuck with
1MB blocks then there won't be room for all of those interesting new uses
on the blockchain.
Others disagree, and have the advantage of status-quo : if nothing is done,
they get what they want.
Based on some comments I've seen, I think there is also concern that "my
own personal network/computer connection might not be able to handle more
transaction volume." That is NOT a good reason to limit scalability, but I
think it is clouding the judgement of many of the core contributors who
started contributing as a spare-time hobby from their homes (where maybe
they have crappy DSL connections).
RE: decentralization:
I think this is a red-herring. I'll quote something I said on reddit
"I don't believe a 20MB max size will increase centralization to any
significant degree.
and And I think we will have a lot LESS centralization of payments via services
like Coinbase (or hubs in some future StrawPay/Lightning network) if the
bitcoin network can directly handle more payment volume.
The centralization trade-offs seems very clear to me, and I think the "big
blocks mean more centralized" arguments are either just wrong or are
exaggerated or ignore the tradeoff with payment centralization (I think
that is a lot more important for privacy and censorship resistance)."
RE: incentives for off-chain solutions:
I'll quote myself again from
 :
"The ?layer 2? services that are being built on top of the blockchain are
absolutely necessary to get nearly instant real-time payments,
micropayments and high volume machine-to-machine payments, to pick just
three examples. The ten-minute settlement time of blocks on the network is
not fast enough for those problems, and it will be the ten minute block
interval that drives development of those off-chain innovations more than
the total number of transactions supported."
On Mon, Jun 1, 2015 at 8:45 AM, J?r?me Legoupil That is the problem: this will be a "frog in boiling water" problem. I
believe there will be no sudden crisis-- instead, transactions will just
get increasingly unreliable and expensive, driving more and more people
away from Bitcoin towards... I don't know what. Some less expensive, more
reliable, probably more-centralized solution.
The Gavin 20MB proposal is compromising Bitcoin's long-term security in an
If by long-term security you mean "will transaction fees be high enough to
pay for enough hashing power to secure the network if there are bigger
blocks" I've written about that:
If you mean something else, then please be specific.

@_date: 2015-06-01 09:59:31
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
Thanks, that's useful!
What do other people think?  Would starting at a max of 8 or 4 get
consensus?  Scaling up a little less than Nielsen's Law of Internet
Bandwidth predicts for the next 20 years?  (I think predictability is
REALLY important).
I chose 20 because all of my testing shows it to be safe, and all of my
back-of-the-envelope calculations indicate the costs are reasonable.
If consensus is "8 because more than order-of-magnitude increases are
scary" -- ok.

@_date: 2015-06-04 18:47:57
@_author: Gavin 
@_subject: [Bitcoin-development] Tough questions for Peter Todd, 
Viacoin}
Completely off-topic for this mailing list, which is about coding/technology not people.
Stop or I will excercise my moderator superpowers and remove you from this list.
Gavin Andresen

@_date: 2015-06-09 09:36:04
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] New attack identified and potential 
limit
How about this for mitigating this potential attack:
1. Limit the memory pool to some reasonable number of blocks-worth of
transactions (e.g. 11)
2. If evicting transactions from the memory pool, prefer to evict
transactions that are part of long chains of unconfirmed transactions.
3. Allow blocks to grow in size in times of high transaction demand.
The combination of (1) and (2) means an attacker needs to prepare lots of
confirmed inputs to pull off the attack. By itself that means they MUST pay
transaction fees.
(3) further mitigates the attack because it allows miners to just absorb
fees that the attacker is throwing at miners.

@_date: 2015-06-09 14:25:18
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] New attack identified and potential 
limit
It doesn't have to be enforced. As long as a reasonable percentage of hash
rate is following that policy an attacker that tries to flood the network
will fail to prevent normal transaction traffic from going through and will
just end up transferring some wealth to the miners.
Although the existing default mining policy (which it seems about 70% of
hashpower follows) of setting aside some space for high-priority
transactions regardless of fee might also be enough to cause this attack to
fail in practice.

@_date: 2015-06-12 13:21:46
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Mining centralization pressure from 
Nice work, Pieter. You're right that my simulation assumed bandwidth for
'block' messages isn't the bottleneck.
But doesn't Matt's fast relay network (and the work I believe we're both
planning on doing in the near future to further optimize block propagation)
make both of our simulations irrelevant in the long-run?
Or, even simpler, why couldn't the little miners just run their
block-assembling-and-announcing code on the other high-bandwidth-side of
the bandwidth bottleneck?

@_date: 2015-06-18 14:23:33
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Concerns Regarding Threats by a Developer 
2) Changes to the consensus rules: As others have said, this isn't anyone's
I don't think I agree with "pretty much everybody", because status-quo bias
is a very powerful thing. Any change that disrupts the way they've been
doing things will generate significant resistance -- there will be 10 or
20% of any population that will take a position of "too busy to think about
this, everything seems to be working great, I don't like change, NO to any
For example, I think some of the resistance for bigger blocks is coming
from contributors who are worried they, personally, won't be able to keep
up with a bigger blockchain. They might not be able to run full nodes from
their home network connections (or might not be able to run a full node AND
stream Game of Thrones), on their old raspberry pi machines.
The criteria for me is "clear super-majority of the people and businesses
who are using Bitcoin the most," and I think that criteria is met.
Yes, that's the way it has mostly been working. But even before stepping
down as Lead I was starting to wonder if there are ANY successful open
source projects that didn't have either a Benevolent Dictator or some clear
voting process to resolve disputes that cannot be settled with "rough

@_date: 2015-06-19 09:33:03
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] F2Pool has enabled full replace-by-fee 
I just sent the following email to F2Pool:
I was disappointed to see Peter Todd claiming that you have (or will?) run
his replace-by-fee patch.
I strongly encourage you to wait until most wallet software supports
replace-by-fee before doing that, because until that happens replace-by-fee
just makes it easier to steal from bitcoin-accepting merchants.
I will tell you the same thing about 8MB blocks: until most merchants
support bigger blocks I will strongly encourage you keep creating
less-than-1MB blocks. If we want Bitcoin to succeed more quickly, we should
all be thinking about what is good for the whole system: users, merchants,
exchanges and miners.
As always, if you have questions or concerns feel free to email me.

@_date: 2015-06-22 14:18:19
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
I promised to write a BIP after I'd implemented
increase-the-maximum-block-size code, so here it is. It also lives at:
I don't expect any proposal to please everybody; there are unavoidable
tradeoffs to increasing the maximum block size. I prioritize implementation
simplicity -- it is hard to write consensus-critical code, so simpler is
  BIP: ??
  Title: Increase Maximum Block Size
  Author: Gavin Andresen   Status: Draft
  Type: Standards Track
  Created: 2015-06-22
This BIP proposes replacing the fixed one megabyte maximum block size with
a maximum size that grows over time at a predictable rate.
Transaction volume on the Bitcoin network has been growing, and will soon
reach the one-megabyte-every-ten-minutes limit imposed by the one megabyte
maximum block size. Increasing the maximum size reduces the impact of that
limit on Bitcoin adoption and growth.
After deployment on the network (see the Deployment section for details),
the maximum allowed size of a block on the main network shall be calculated
based on the timestamp in the block header.
The maximum size shall be 8,000,000 bytes at a timestamp of 2016-01-11
00:00:00 UTC (timestamp 1452470400), and shall double every 63,072,000
seconds (two years, ignoring leap years), until 2036-01-06 00:00:00 UTC
(timestamp 2083190400). The maximum size of blocks in between doublings
will increase linearly based on the block's timestamp. The maximum size of
blocks after 2036-01-06 00:00:00 UTC shall be 8,192,000,000 bytes.
Expressed in pseudo-code, using integer math:
    function max_block_size(block_timestamp):
        time_start = 1452470400
        time_double = 60*60*24*365*2
        size_start = 8000000
        if block_timestamp >= time_start+time_double*10
            return size_start * 2^10
        // Piecewise-linear-between-doublings growth:
        time_delta = block_timestamp - t_start
        doublings = time_delta / time_double
        remainder = time_delta % time_double
        interpolate = (size_start * 2^doublings * remainder) / time_double
        max_size = size_start * 2^doublings + interpolate
        return max_size
Deployment shall be controlled by hash-power supermajority vote (similar to
the technique used in BIP34), but the earliest possible activation time is
2016-01-11 00:00:00 UTC.
Activation is achieved when 750 of 1,000 consecutive blocks in the best
chain have a version number with bits 3 and 14 set (0x20000004 in hex). The
activation time will be the timestamp of the 750'th block plus a two week
(1,209,600 second) grace period to give any remaining miners or services
time to upgrade to support larger blocks. If a supermajority is achieved
more than two weeks before 2016-01-11 00:00:00 UTC, the activation time
will be 2016-01-11 00:00:00 UTC.
Block version numbers are used only for activation; once activation is
achieved, the maximum block size shall be as described in the specification
section, regardless of the version number of the block.
The initial size of 8,000,000 bytes was chosen after testing the current
reference implementation code with larger block sizes and receiving
feedback from miners stuck behind bandwidth-constrained networks (in
particular, Chinese miners behind the Great Firewall of China).
The doubling interval was chosen based on long-term growth trends for CPU
power, storage, and Internet bandwidth. The 20-year limit was chosen
because exponential growth cannot continue forever.
Calculations are based on timestamps and not blockchain height because a
timestamp is part of every block's header. This allows implementations to
know a block's maximum size after they have downloaded it's header, but
before downloading any transactions.
The deployment plan is taken from Jeff Garzik's proposed BIP100 block size
increase, and is designed to give miners, merchants, and
full-node-running-end-users sufficient time to upgrade to software that
supports bigger blocks. A 75% supermajority was chosen so that one large
mining pool does not have effective veto power over a blocksize increase.
The version number scheme is designed to be compatible with Pieter's
Wuille's proposed "Version bits" BIP.
TODO: summarize objections/arguments from
TODO: describe other proposals and their advantages/disadvantages over this
This is a hard-forking change to the Bitcoin protocol; anybody running code
that fully validates blocks must upgrade before the activation time or they
will risk rejecting a chain containing larger-than-one-megabyte blocks.
Simplified Payment Verification software is not affected, unless it makes
assumptions about the maximum depth of a transaction's merkle branch based
on the minimum size of a transaction and the maximum block size.

@_date: 2015-06-22 14:46:03
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
9,000 of last 12,000 blocks is OK with me (I don't think scanning through
the last 12,000 block headers every new block will cause performance
problems, but I'd want to benchmark it to be absolutely sure).
Do old nodes detect an upgrade by version numbers?  If that was headers
Bitcoin Core will alert when automatically when 51% of blocks have a
version it doesn't understand.
It will also alert automatically if it detects a chain with more work that
it doesn't consider valid for some reason. And 0.11 contains code that
alerts if you're on a chain that is being mined really slowly.
Have you considered a "fail" condition?  For example, if 750 of the last
I like the fail-if-not-activated-by idea. Not so crazy about the vote idea
(what if miners set bits 3 AND 4 ?).

@_date: 2015-06-22 15:54:26
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
As Tier says, the current network message limit is 2MB (reduced from 32MB
in the... uhh, 0.10? release).
I think keeping the consensus rules distinct from limitations of the p2p
network makes sense-- we are already seeing different protocols for
announcing transactions and blocks (Matt's relay network is, essentially, a
separate protocol). I could write a separate BIP describing the change to
the p2p network protocol, but that feels like busy-work to me.
RE: setting the DoS size check farther than 2 hours into the future: the
block, itself, will be rejected if it has a timestamp more than 2 hours in
the future. That is already a consensus rule.
RE: what happens if block timestamps are not in chronological order:
The activation counting happens in block-height-order, so timestamps on all
but the "activating" block are all that matters.
Code that looks for the activation condition must properly handle re-orgs
around the activation block, of course.
RE: testnet parameters:  big blocks can be tested in -regtest mode with
arbitrary timestamps in the past or future. Testing maximum-8MB-blocks
mined "in the past" on testnet will just result in a testnet that is even
more useless for ordinary testing of products or services being developed

@_date: 2015-06-22 16:46:51
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
Thanks, I'll fix.
Excellent point. That could only happen if activation happened on 11 Jan
2016; instead of complicating the code and spec with another condition, I
think it would be better to specify that the activation date is the later
of the miner supermajority and 11 Jan, with the first big block two weeks

@_date: 2015-06-22 16:51:23
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
.... I take that back, I'm wrong and Tier is correct: if activation
happened right at midnight 11 Jan 2016 and the next block's timestamp was
before midnight, that next block would just be limited to 1MB in size.

@_date: 2015-06-22 17:21:40
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
That complicates the implementation quite a bit.
I mostly implemented a variant that replaced the MAX_BLOCK_SIZE constant
with a function that took both a timestamp and a block height, and there
are several places in the current reference implementation where digging
out the block height (or, worse, calculating the median timestamp for the
block) would involve changing quite a few functions in the call-chain or
acquiring the cs_main lock to consult the current best chain.

@_date: 2015-06-23 16:12:17
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
Consensus is that this process is too painful to go through once a year.  I
If you disagree and would like to see a Blocksize Council meet once a year
to issue a decree on what the maximum block size shall be for the next
year, then propose a process for who gets to sit on the Council and how
their decrees are enforced.....
Simulations show that:
Latency/bandwidth matter for miners.  Low latency, high bandwidth is
better. However, miners with bad connectivity can simply create smaller
... until transaction fees become significant.  But by the time that
happens, protocol optimizations of block propagation will make the block
size an insignificant term in the "how profitable is it to mine in THIS
particular place on the Internet / part of the world" equation.
 at lists.sourceforge.net/msg08224.html
So: for the immediate future, there is no problem. And in the long term,
there is no problem.

@_date: 2015-06-23 17:24:23
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
... but the effect is only significant if they have an absurdly
low-bandwidth connection and do NOTHING to work around it (like rent a
server on the other side of the bandwidth bottleneck and write some code to
make sure you're creating blocks that will propagate quickly on both sides
of the bottleneck).
Why do you think connectivity is a centralizing effect? It is just one
factor in the profitability-of-mining equation. A location with bad
connectivity (the US, maybe) but 10% cheaper electricity might be just as
good as one with great connectivity but more expensive electricity.
Having lots of variables in the profitability equation is a decentralizing
force, it means there is very likely to be several different places in the
world / on the net where mining is equally profitable.
Long term the p2p protocol will evolve to incorporate those optimizations,
so will require no co-operation.
Are you familiar with the terms "Gish Gallop" and "Moving the Goalposts" ?
I have written quite a lot about the kind of resources needed to run a full
node, and have asked you, specifically, several times "how much do you
think is too much" and received no answer.

@_date: 2015-06-24 09:44:13
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
This BIP has been assigned number 101 by the BIP editor. I plan on filling
in the TODOs and will submit it as a pull request to the BIP repository

@_date: 2015-06-26 13:39:58
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Draft BIP : fixed-schedule block size increase 
I think the default block size is an orthogonal issue to the max block size.
HOWEVER: I think changing the default 'target' block size from the current,
fixed 750K to the average of the size of the last N blocks would have some
nice properties. It is policy-neutral (we should get out of the business of
deciding the right block size and let the miners who care drive block size
up or down) and if there are a significant proportion of lazy miners going
with defaults it gives the system a healthy "fee pressure."

@_date: 2015-06-26 13:55:28
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] The need for larger blocks 
I completely agree with Pieter: usage will grow to fill whatever maximum
block size the miners decide to allow (or whatever maximum block size is
imposed by minimum transaction fees or a hard cap on block size).
I am not scared by increased usage, though: more usage and adoption means
more investment, more smart engineers, and more people with incentives to
solve whatever scaling problems crop up. All of that makes Bitcoin stronger.
And I don't feel like this process has been hurried: I've been working on
this (thinking, testing, simulating, talking, writing code, talking to key
people and companies) almost exclusively since late last year. In my humble
opinion, BIP 101 is a good compromise between "no limit, let the miners
decide" and "lower the max size so a raspberry pi running on a 56K modem
can be a full node."

@_date: 2015-06-28 13:29:10
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] A Proposed Compromise to the Block Size Limit 
Very few of my own personal Bitcoin transactions fit that use-case.
In fact, very few of my own personal dollar transactions fit that use-case
(I suppose if I was addicted to Starbucks I'd have one of their payment
cards that I topped up every once in a while, which would map nicely onto a
payment channel). I suppose I could setup a payment channel with the
grocery store I shop at once a week, but that would be inconvenient (I'd
have to pre-fund it) and bad for my privacy.
I can see how payment channels would work between big financial
institutions as a settlement layer, but isn't that exactly the
centralization concern that is making a lot of people worried about
increasing the max block size?
And if there are only a dozen or two popular hubs, that's much worse
centralization-wise compared to a few thousand fully-validating Bitcoin
Don't get me wrong, I think the Lightning Network is a fantastic idea and a
great experiment and will likely be used for all sorts of great payment
innovations (micropayments for bandwidth maybe, or maybe paying workers by
the hour instead of at the end of the month). But I don't think it is a
scaling solution for the types of payments the Bitcoin network is handling

@_date: 2015-06-28 17:05:10
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] A Proposed Compromise to the Block Size Limit 
If I don't see how switching from using the thousands of fully-validating
bitcoin nodes with (tens? hundreds?) of Lightning Network hubs is better in
terms of decentralization (or security, in terms of Sybil/DoS attacks),
then I doubt other people do, either. You need to do a better job of
explaining it.
But even if you could convince me that it WAS better from a
security/decentralization point of view:
a) Lightning Network is nothing but a whitepaper right now. We are a long
way from a practical implementation supported by even one wallet.
b) The Lightning Network paper itself says bigger blocks will be needed
even if (especially if!) Lightning is wildly successful.

@_date: 2015-05-07 10:52:54
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Block Size Increase 
For reference: the blog post that (re)-started this debate, and which links
to individual issues, is here:
  In it, I asked people to email me objections I might have missed. I would
still appreciate it if people do that; it is impossible to keep up with
this mailing list, /r/bitcoin posts and comments, and  and
also have time to respond thoughtfully to the objections raised.
I would very much like to find some concrete course of action that we can
come to consensus on. Some compromise so we can tell entrepreneurs "THIS is
how much transaction volume the main Bitcoin blockchain will be able to
support over the next eleven years."
I've been pretty clear on what I think is a reasonable compromise (a
one-time increase scheduled for early next year), and I have tried to
explain why I think it it is the right set of tradeoffs.
There ARE tradeoffs here, and the hard question is what process do we use
to decide those tradeoffs?  How do we come to consensus? Is it worth my
time to spend hours responding thoughtfully to every new objection raised
here, or will the same thing happen that happened last year and the year
before-- everybody eventually gets tired of arguing
angels-dancing-on-the-head-of-a-pin, and we're left with the status quo?
I AM considering contributing some version of the bigger blocksize-limit
hard-fork patch to the Bitcoin-Xt fork (probably  "target a hobbyist with a
fast Internet connection, and assume Nelson's law to increase over time),
and then encouraging merchants and exchanges and web wallets and
individuals who think it strikes a reasonable balance to run it.
And then, assuming it became a super-majority of nodes on the network,
encourage miners to roll out a soft-fork to start producing bigger blocks
and eventually trigger the hard fork.
Because ultimately consensus comes down to what software people choose to

@_date: 2015-05-07 12:59:13
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Block Size Increase 
Fee dynamics seems to come up over and over again in these discussions,
with lots of talk and theorizing.
I hope some data on what is happening with fees right now might help, so I
wrote another blog post (with graphs, which can't be done in a mailing list
   We don?t need 100% full one megabyte blocks to start to learn about what is
likely to happen as transaction volume rises and/or the one megabyte block
size limit is raised.

@_date: 2015-05-07 13:40:59
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd:  Block Size Increase 
On Thu, May 7, 2015 at 1:26 PM, Matt Corallo I think the strongest thing I've ever said is:
"There is consensus that the max block size much change sooner or later.
There is not yet consensus on exactly how or when. I will be pushing to
change it this year."
This is what "I will be pushing to change it this year" looks like.

@_date: 2015-05-08 08:48:47
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
I like the bitcoin days destroyed idea.
I like lots of the ideas that have been presented here, on the bitcointalk
forums, etc etc etc.
It is easy to make a proposal, it is hard to wade through all of the
proposals. I'm going to balance that equation by completely ignoring any
proposal that isn't accompanied by code that implements the proposal (with
appropriate tests).
However, I'm not the bottleneck-- you need to get the attention of the
other committers and convince THEM:
a) something should be done "now-ish"
b) your idea is good
We are stuck on (a) right now, I think.
On Fri, May 8, 2015 at 8:32 AM, Joel Joonatan Kaartinen <

@_date: 2015-05-09 07:58:20
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
RE: fixing sigop counting, and building in UTXO cost: great idea! One of
the problems with this debate is it is easy for great ideas get lost in all
the noise.
RE: a hard upper limit, with a dynamic limit under it:
I like that idea. Can we drill down on the hard upper limit?
There are lots of people who want a very high upper limit, right now (all
the big Bitcoin companies, and anybody who thinks as-rapid-as-possible
growth now is the best path to long-term success). This is the "it is OK if
you have to run full nodes in a data center" camp.
There are also lots of people who want an upper limit low enough that they
can continue to run Bitcoin on the hardware and Internet connection that
they have (or are concerned about centralization, so want to make sure
OTHER people can continue to run....).
Is there an upper limit "we" can choose to make both sets of people mostly
happy? I've proposed "must be inexpensive enough that a 'hobbyist' can
afford to run a full node" ...
Is the limit chosen once, now, via hard-fork, or should we expect multiple
hard-forks to change it "when necessary" ?
The economics change every time the block reward halves, which make me
think that might be a good time to adjust the hard upper limit. If we have
a hard upper limit and a lower dynamic limit, perhaps adjusting the hard
upper limit (up or down) to account for the block reward halving, based on
the dynamic limit....
RE: the lower dynamic limit algorithm:  I REALLY like that idea.

@_date: 2015-05-10 17:21:06
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
Let me make sure I understand this proposal:
I'm going to try to figure out how much transaction fee a transaction would
have to pay to bribe a miner to include it. Greg, please let me know if
I've misinterpreted the proposed algorithm. And everybody, please let me
know if I'm making a bone-headed mistake in how I'm computing anything:
Lets say miners are expressing a desire for 600,000 byte blocks in their
computed_max = 600,000 - 600,000/52 = 588,462 bytes.
  --> this is about 23 average-size (500-byte) transactions less than
effective_max = 1,176,923
Lets say I want to maintain status quo at 600,000 bytes; how much penalty
do I have?
((600,000-588,462)/588,462)^2 + 1 = 1.00038
How much will that cost me?
The network is hashing at 310PetaHash/sec right now.
Takes 600 seconds to find a block, so 186,000PH per block
186,000 * 0.00038 = 70 extra PH
If it takes 186,000 PH to find a block, and a block is worth 25.13 BTC
(reward plus fees), that 70 PH costs:
(25.13 BTC/block / 186,000 PH/block) * 70 PH = 0.00945 BTC
or at $240 / BTC:  $2.27
... so average transaction fee will have to be about ten cents ($2.27
spread across 23 average-sized transactions) for miners to decide to stay
at 600K blocks. If they fill up 588,462 bytes and don't have some
ten-cent-fee transactions left, they should express a desire to create a
588,462-byte-block and mine with no penalty.
Is that too much?  Not enough?  Average transaction fees today are about 3
cents per transaction.
I created a spreadsheet playing with the parameters:
"We" could tweak the constants or function to get a transaction fee we
think is reasonable... but we really shouldn't be deciding whether
transaction fees are too high, too low, or just right, and after thinking
about this for a while I think any algorithm that ties difficulty to block
size is just a complicated way of dictating minimum fees.
As for some other dynamic algorithm: OK with me. How do we get consensus on
what the best algorithm is? I'm ok with any "don't grow too quickly, give
some reasonable-percentage-minority of miners the ability to block further
Also relevant here:
"The curious task of economics is to demonstrate to men how little they
really know about what they imagine they can design." - Friedrich August
von Hayek

@_date: 2015-05-11 13:29:02
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Long-term mining incentives 
I think long-term the chain will not be secured purely by proof-of-work. I
think when the Bitcoin network was tiny running solely on people's home
computers proof-of-work was the right way to secure the chain, and the only
fair way to both secure the chain and distribute the coins.
See   for some
half-baked thoughts along those lines. I don't think proof-of-work is the
last word in distributed consensus (I also don't think any alternatives are
anywhere near ready to deploy, but they might be in ten years).
I also think it is premature to worry about what will happen in twenty or
thirty years when the block subsidy is insignificant. A lot will happen in
the next twenty years. I could spin a vision of what will secure the chain
in twenty years, but I'd put a low probability on that vision actually
turning out to be correct.
That is why I keep saying Bitcoin is an experiment. But I also believe that
the incentives are correct, and there are a lot of very motivated, smart,
hard-working people who will make it work. When you're talking about trying
to predict what will happen decades from now, I think that is the best you
can (honestly) do.

@_date: 2015-05-12 12:10:53
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Long-term mining incentives 
Added back the list, I didn't mean to reply privately:
Fair enough, I'll try to find time in the next month or three to write up
four plausible future scenarios for how mining incentives might work:
1) Fee-supported with very large blocks containing lots of tiny-fee
2) Proof-of-idle supported (I wish Tadge Dryja would publish his
proof-of-idle idea....)
3) Fees purely as transaction-spam-prevention measure, chain security via
alternative consensus algorithm (in this scenario there is very little
4) Fee supported with small blocks containing high-fee transactions moving
coins to/from sidechains.
Would that be helpful, or do you have some reason for thinking that we
should pick just one and focus all of our efforts on making that one
scenario happen?
I always think it is better, when possible, not to "bet on one horse."
On Tue, May 12, 2015 at 10:39 AM, Thomas Voegtlin

@_date: 2015-05-13 09:24:04
@_author: Gavin 
@_subject: [Bitcoin-development] Long-term mining incentives 
Checkpoints will be replaced by compiled-in 'at THIS timestamp the main chain had THIS much proof of work.'
That is enough information to prevent attacks and still allow optimizations like skipping signature checking for ancient transactions.
I don't think anybody is proposing replacing checkpoints with nothing.
Gavin Andresen

@_date: 2015-05-13 09:41:44
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [BIP] Normalized Transaction IDs 
I think this needs more details before it gets a BIP number; for example,
which opcodes does this affect, and how, exactly, does it affect them? Is
the merkle root in the block header computed using normalized transaction
ids or normalized ids?
I think there might actually be two or three or four BIPs here:
 + Overall "what is trying to be accomplished"
 + Changes to the OP_*SIG* opcodes
 + Changes to the bloom-filtering SPV support
 + ...eventually, hard fork rollout plan
I also think that it is a good idea to have actually implemented a proposal
before getting a BIP number. At least, I find that actually writing the
code often turns up issues I hadn't considered when thinking about the
problem at a high level. And I STRONGLY believe BIPs should be descriptive
("here is how this thing works") not proscriptive ("here's how I think we
should all do it").
Finally: I like the idea of moving to a normalized txid. But it might make
sense to bundle that change with a bigger change to OP_CHECKSIG; see Greg
Maxwell's excellent talk about his current thoughts on that topic:

@_date: 2015-05-13 11:41:16
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Long-term mining incentives 
Yes... or an alternative might be found that weakens the Bitcoin security
model by a small enough amount that it either doesn't matter or the
weakening is vastly overwhelmed by some other benefit.
I'm influenced by the way the Internet works; packets addressed to
74.125.226.67 reliably get to Google through a very decentralized system
that I'll freely admit I don't understand. Yes, a determined attacker can
re-route packets, but layers of security on top means re-routing packets
isn't enough to pull off profitable attacks.
I think Bitcoin's proof-of-work might evolve in a similar way. Yes, you
might be able to 51% attack the POW, but layers of security on top of POW
will mean that won't be enough to pull off profitable attacks.

@_date: 2015-05-28 11:53:41
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
A lot of people like this idea, or something like it. It is nice and
simple, which is really important for consensus-critical code.
With this rule in place, I believe there would be more "fee pressure"
(miners would be creating smaller blocks) today. I created a couple of
histograms of block sizes to infer what policy miners are ACTUALLY
following today with respect to block size:
Last 1,000 blocks:
  Notice a big spike at 750K -- the default size for Bitcoin Core.
This graph might be misleading, because transaction volume or fees might
not be high enough over the last few days to fill blocks to whatever limit
miners are willing to mine.
So I graphed a time when (according to statoshi.info) there WERE a lot of
transactions waiting to be confirmed:
   That might also be misleading, because it is possible there were a lot of
transactions waiting to be confirmed because miners who choose to create
small blocks got lucky and found more blocks than normal.  In fact, it
looks like that is what happened: more smaller-than-normal blocks were
found, and the memory pool backed up.
So: what if we had a dynamic maximum size limit based on recent history?
The average block size is about 400K, so a 1.5x rule would make the max
block size 600K; miners would definitely be squeezing out transactions /
putting pressure to increase transaction fees. Even a 2x rule (implying
800K max blocks) would, today, be squeezing out transactions / putting
pressure to increase fees.
Using a median size instead of an average means the size can increase or
decrease more quickly. For example, imagine the rule is "median of last
2016 blocks" and 49% of miners are producing 0-size blocks and 51% are
producing max-size blocks. The median is max-size, so the 51% have total
control over making blocks bigger.  Swap the roles, and the median is
Because of that, I think using an average is better-- it means the max size
will change (up or down) more slowly.
I also think 2016 blocks is too long, because transaction volumes change
quicker than that. An average over 144 blocks (last 24 hours) would be
better able to handle increased transaction volume around major holidays,
and would also be able to react more quickly if an economically irrational
attacker attempted to flood the network with fee-paying transactions.
So my straw-man proposal would be:  max size 2x average size over last 144
blocks, calculated at every block.
There are a couple of other changes I'd pair with that consensus change:
+ Make the default mining policy for Bitcoin Core neutral-- have its target
block size be the average size, so miners that don't care will "go along
with the people who do care."
+ Use something like Greg's formula for size instead of bytes-on-the-wire,
to discourage bloating the UTXO set.
When I've proposed (privately, to the other core committers) some dynamic
algorithm the objection has been "but that gives miners complete control
over the max block size."
I think that worry is unjustified right now-- certainly, until we have
size-independent new block propagation there is an incentive for miners to
keep their blocks small, and we see miners creating small blocks even when
there are fee-paying transactions waiting to be confirmed.
I don't even think it will be a problem if/when we do have size-independent
new block propagation, because I think the combination of the random timing
of block-finding plus a dynamic limit as described above will create a
healthy system.
If I'm wrong, then it seems to me the miners will have a very strong
incentive to, collectively, impose whatever rules are necessary (maybe a
soft-fork to put a hard cap on block size) to make the system healthy again.

@_date: 2015-05-28 13:19:44
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
Twenty is scary.
And two is a very neutral number: if 50% of hashpower want the max size to
grow as fast as possible and 50% are dead-set opposed to any increase in
max size, then half produce blocks 2 times as big, half produce empty
blocks, and the max size doesn't change. If it was 20, then a small
minority of miners could force a max size increase.  (if it is less than 2,
then a minority of minors can force the block size down)
As for whether there "should" be fee pressure now or not: I have no
opinion, besides "we should make block propagation faster so there is no
technical reason for miners to produce tiny blocks." I don't think us
developers should be deciding things like whether or not fees are too high,
too low, .....

@_date: 2015-05-28 14:21:48
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB 
I've tried to cover all that I've heard about in my blog posts about why I
think the risks of 20MB blocks are outweighed by the benefits, am I missing
  (blog posts are linked from
 )
There is the "a sudden jump to a 20MB max might have unforseen
consequences" risk that I don't address, but a dynamic increase would fix

@_date: 2015-05-28 14:23:59
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
By the time a hard fork can happen, I expect average block size will be
above 500K.
Would you support a rule that was "larger of 1MB or 2x average size" ? That
is strictly better than the situation we're in today.

@_date: 2015-05-28 14:31:43
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
Can we hold off on bike-shedding the particular choice of parameters until
people have a chance to weigh in on whether or not there is SOME set of
dynamic parameters they would support right now?

@_date: 2015-05-29 08:39:30
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
What do other people think?
If we can't come to an agreement soon, then I'll ask for help
reviewing/submitting patches to Mike's Bitcoin-Xt project that implement a
big increase now that grows over time so we may never have to go through
all this rancor and debate again.
I'll then ask for help lobbying the merchant services and exchanges and
hosted wallet companies and other bitcoind-using-infrastructure companies
(and anybody who agrees with me that we need bigger blocks sooner rather
than later) to run Bitcoin-Xt instead of Bitcoin Core, and state that they
are running it. We'll be able to see uptake on the network by monitoring
client versions.
Perhaps by the time that happens there will be consensus bigger blocks are
needed sooner rather than later; if so, great! The early deployment will
just serve as early testing, and all of the software already deployed will
ready for bigger blocks.
But if there is still no consensus among developers but the "bigger blocks
now" movement is successful, I'll ask for help getting big miners to do the
same, and use the soft-fork block version voting mechanism to (hopefully)
get a majority and then a super-majority willing to produce bigger blocks.
The purpose of that process is to prove to any doubters that they'd better
start supporting bigger blocks or they'll be left behind, and to give them
a chance to upgrade before that happens.
Because if we can't come to consensus here, the ultimate authority for
determining consensus is what code the majority of merchants and exchanges
and miners are running.

@_date: 2015-05-29 10:20:01
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
Public statements saying "we're running software that is ready for bigger
And looking at the version (aka user-agent) strings of publicly reachable
nodes on the network.
(e.g. see the count at   )

@_date: 2015-05-29 18:36:51
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Block Size Increase Requirements 
Matt brought this up on Twitter, I have no idea why I didn't respond weeks
ago (busy writing blog posts, probably):
On Thu, May 7, 2015 at 6:02 PM, Matt Corallo If block propagation isn't fixed, then mines have a strong incentive to
create smaller blocks.
So the max block size is irrelevant, it won't get hit.
See for analysis of "but that means bigger miners can get an advantage"
Executive summary: if little miners are stupid and produce huge blocks,
then yes, big miners have an advantage.
But they're not, so they won't.
Until the block reward goes away, and assuming transaction fees become an
important source of revenue for miners.
I think it is too early to worry about that; see:
   Ok. What does this have to do with the max block size?
Are you arguing that work won't happen if the max block size increases?
  * I'd like to see some better conclusions to the discussion around
Again, see  for
what I think about that.

@_date: 2015-05-29 20:16:01
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] soft-fork block size increase (extension 
RE: soft-forking an "extension block":
So... go for it, code it up. Implement it in the Bitcoin Core wallet.
Then ask the various wallet developer how long it would take them to update
their software to support something like this, and do some UI mockups of
what the experience would look like for users.
If there are two engineering solutions to a problem, one really simple, and
one complex, why would you pick the complex one?
Especially if the complex solution has all of the problems of the simple
one (20MB extension blocks are just as "dangerous" as 20MB main blocks,
yes? If not, why not?)

@_date: 2015-05-30 09:57:32
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Block Size Increase Requirements 
Thanks for giving your opinion!
I ran some simulations, and I could not find a network topology where a big
miner producing big blocks could cause a loss of profit to another miner
(big or small) producing smaller blocks:
(the 0.3% advantage I DID find was for the situation where EVERYBODY was
producing big blocks).
Why 2 MB ?   You said that server bandwidth is much more expensive in
China; what would be the difference in your bandwidth costs between 2MB
blocks and 20MB blocks?

@_date: 2015-05-30 16:37:15
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Block Size Increase Requirements 
On Sat, May 30, 2015 at 3:32 PM, Matt Corallo "good behavior" models? I intentionally modeled what should be a worst-case.
If you have a specific network topology you want to model, please email me
details and I'll see what worst case is. Or, even better, take my
simulation code and run it yourself (it's C++, easy to compile, easy to
modify if you think it is too simple).
I get frustrated with all of the armchair "but what if..."
how-many-miners-can-dance-on-the-head-of-a-pin arguments.
No, they're not. They are only at a disadvantage when THEY mine bigger
I guess I wasn't clear in the "do bigger miners have an advantage" blog
I spent last week doing simulation and study. Please, do your own
simulation and study if you don't trust my results. There are big
full-scale-bitcoin-network-simulations spinning up that should have results
in a month or two, also, but there will ALWAYS be "but we didn't think
about what if THIS happens" scenarios that can require more simulation and
Last night's transaction volume test shows that most miners do just go
along with defaults:
  Mining is a competitive business, the marginal miner will ALWAYS be going
out of business.
That is completely independent of the block size, block subsidy, or
transaction fees.
The question is "will there be enough fee+subsidy revenue to make it
unprofitable for an attacker to buy or rent enough hashpower to
It is obvious to me that bigger blocks make it more likely the answer to
that question is "yes."
Mike Hearn wrote about that just a couple days ago:
  (See "How much is too much" section)
I have said repeatedly that if it was left completely up to me I would go
back to Satoshi's original "there is no consensus-level blocksize limit".
20MB is a compromise.
 > Ok, I wrote about that here:
... and now you're pissing me off. I have NEVER EVER said that they need
bigger blocks to continue operating. Please stop being overly dramatic.
They believe that bigger blocks are better for Bitcoin.
Brian Armstrong at Coinbase, in particular, said that smaller blocks drive
centralization towards services like Coinbase ("look ma! No blockchain
transaction!" <-- if you pay a Coinbase merchant from your Coinbase
wallet), but he supports bigger blocks because more transactions on our
existing decentralized network is better.

@_date: 2015-05-31 08:40:35
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
That orphan rate increase will go to whoever is producing the 20MB blocks,
NOT you.
Or, we can mine the next block only on
Are you sure that is the best strategy? If a big block is slow to
propagate, I suspect it will be better to punish the miner that created it
by refusing to build on it until it has been fully validated.
I'll try to find time to run a couple of simulations.
I can benchmark it. It should be pretty fast, and sipa has a couple of
patches pending to make the UTXO cache much faster.
It can be fast because the vast majority of the work of validating all
those transactions can happen as they are received into the memory pool.
You should be able to handle 20MB blocks no problem; if I round up to 100MB
per block that works out to 1.3Mbps.
We also use Aliyun and Linode cloud services for block
That speed will handle 20MB blocks no problem.
If each 20MB block is 100MB of data up/down the wire (I'm vastly
over-estimating, after optimization it should be 40MB) then you'll be
0.1 GB / block-data-on-wire * 144 blocks/day * 30.5 days/month * 0.13 $ /
GB = $57
Less than $2 per day in bandwidth, surely you can afford that.
That's OK, you'll 1.3Mbps or less.
Are you worried about paying too much, or do 20MB blocks "feel like too
much" ?

@_date: 2015-05-31 08:51:04
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Block Size Increase Requirements 
What compromise? I haven't seen a specific proposal that could be turned
into a pull request.
NO I AM NOT.
I simulated a variety of connectivities; see the .cfg files at
  The results I give in the "are bigger blocks better" blog post are for
WORST CASE connectivity (one dominant big miner, multiple little miners,
big miner connects to only 30% of little miners, but all the little miners
connected directly to each other).
Again, I did not simulate all miners directly connected to each other.
I will note that miners are VERY HIGHLY connected today. It is in their
best interest to be highly connected to each other.
Really? How is that easily subject to change? If it is easily subject to
change, do bigger blocks have any effect? Why are 1MB blocks not subject to
I talk about "what if your government bans Bitcoin entirely" here:
   ... and the issues are essentially the same, independent of block size.

@_date: 2015-05-31 08:52:45
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
That orphan rate increase will go to whoever is producing the 20MB blocks,
NOT you.
Or, we can mine the next block only on
Are you sure that is the best strategy? If a big block is slow to
propagate, I suspect it will be better to punish the miner that created it
by refusing to build on it until it has been fully validated.
I'll try to find time to run a couple of simulations.
I can benchmark it. It should be pretty fast, and sipa has a couple of
patches pending to make the UTXO cache much faster.
It can be fast because the vast majority of the work of validating all
those transactions can happen as they are received into the memory pool.
You should be able to handle 20MB blocks no problem; if I round up to 100MB
per block that works out to 1.3Mbps.
We also use Aliyun and Linode cloud services for block
That speed will handle 20MB blocks no problem.
If each 20MB block is 100MB of data up/down the wire (I'm vastly
over-estimating, after optimization it should be 40MB) then you'll be
0.1 GB / block-data-on-wire * 144 blocks/day * 30.5 days/month * 0.13 $ /
GB = $57
Less than $2 per day in bandwidth.
That's OK, you'll 1.3Mbps or less.
Are you worried about paying too much, or do 20MB blocks "feel like too
much" ?

@_date: 2015-05-31 10:47:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
Thanks for chiming in with facts, Yifu!
Do you have any real-world data on latency/bandwidth/cost through the gfw ?
Chung Wang's post was very helpful to get away from hypotheticals to "what
would it actually cost."

@_date: 2015-05-31 10:49:02
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Block Size Increase Requirements 
I wrote about long-term hypotheticals and why I think it is a big mistake
to waste time worrying about them here:

@_date: 2015-05-31 10:54:10
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Fwd: Block Size Increase Requirements 
Yes, if you are on a slow network then you are at a (slight) disadvantage.
There are lots of equations that go into the "is mining profitable"
equation: cost of power, Internet cost and connectivity, cost of capital,
access to technology other miners don't have, inexpensive labor or rent,
inexpensive cooling, ability to use waste heat...
That's good. An equation with lots of variables has lots of different
maximum solutions, and that means better decentralization -- there is less
likely to be one perfect place or way to mine.

@_date: 2015-05-31 11:08:12
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] Block Size Increase Requirements 
Sorry, but that's ridiculous.
If Miner B is leaving 18BTC per block on the table because they have bad
connectivity, then they need to pay for better connectivity.
If you are arguing "I should be able to mine on a 56K modem connection from
the middle of the Sahara" then we're going to have to agree to disagree.
So: what is your specific proposal for minimum requirements for
connectivity to run a full node? The 20MB number comes from estimating
costs to run a full node, and as my back-and-forth to Chang Wung shows, the
costs are not excessive.

@_date: 2015-05-31 15:49:05
@_author: Gavin Andresen 
@_subject: [Bitcoin-development] [Bulk] Re: Fwd: Block Size Increase 
No, randomly connected gossip networks (which is what the Bitcoin p2p
network is) don't work that way, bandwidth is (roughly) O(N) where N is the
number of bytes relayed to everybody.
(it is actually a small multiple of N, because of the overhead of 'inv'
messages, and if we ever get really serious about scaling up we'll need to
fix the protocol to reduce that overhead, but that won't be a problem for

@_date: 2015-11-02 15:33:47
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Compatibility requirements for hard or soft forks 
I like those guidelines, although I'm sure there may be lots of arguing
over what fits under "protects the integrity of the network" or what
constitutes "reasonable notice" (publish a BIP at least 30 days before
rolling out a change? 60 days? a year?)

@_date: 2015-11-05 09:23:44
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] A validation-cost metric for aggregate limits and 
I have several thoughts:
Weighing CPU validation cost should be reasonably straightforward-- just
pick some arbitrary, commonly-available, recent hardware and then benchmark
the two things that take the bulk of validation time (hashing to create the
signature hash, then ECDSA validation), and weigh the terms in the
validation cost equation appropriately (e.g. hashing X GB of data takes the
same amount of CPU time as one libsecp256k1 validation, so count cpu cost
of an OP_CHECKSIG as 1 + X/actual_bytes_hashed).
But how should bandwidth cost be counted? There isn't an obvious "Y GB of
bandwidth-per-month equals 1 ECDSA validation. We need to find common units
for the terms in the validation cost equation for it to make sense,
otherwise we're adding apples and oranges.
I think the only units that will work is "percentage of maximum validation
ability for some reference hardware running with a network connection
capable of some reference bandwidth."
For example, imagine the reference was the typical home computer being sold
today running with some multiple or fraction of the average global
broadband connection speed of 5Mbps. CPU cost to validate a block can then
be expressed as a percentage of maximum capacity, as can bandwidth--
hooray, two metrics with the same units, so they can be added up.  If the
result is less than 100%, then the block is valid-- it can be received and
validated in a reasonable amount of time.
Rolling in UTXO growth is harder, for two reasons:
1) UTXO changes per block can be negative or positive, as opposed to
bandwidth/CPU costs.
2) It is not clear how to choose or benchmark "reference UTXO growth"
(1) could be finessed to just treat UTXO shrinkage as zero.
(2) could just be decided by picking a reasonable growth number. Since we
want the UTXO set to fit into main memory, something a bit below the
long-ish term price/performance trend of main memory would be a good target.
So, starting with that growth rate and an initial UTXO size in bytes,
divide by the number of blocks in a year to get a maximum UTXO growth in
bytes per block.
When validating a block, take the actual UTXO growth, express it as a
percentage of the maximum allowed (make it zero if it is negative), and
combine with the CPU and bandwidth percentages.
If the total is less than 100%, block is valid. Otherwise, invalid.
Now.... all of that worked through, I'm not 100% sure it solves the "do
miners or wallet have to solve a bin-packing problem to determine which
transactions to put into their blocks or what fees to attach."
I think it mostly works out-- instead of fee-per-kilobyte, it would be
fee-per-validation-cost (which is in the weird units "fraction of 100%
validation cost").
But the UTXO term might be a problem-- transactions that create more UTXOs
than they spend might end up being costly. I'm traveling right now, perhaps
somebody could pick some arbitrary reference points and try to get a rough
idea of what different transactions might pay in fees (e.g. if a
one-input-two-output had a cost of X, two-output-one-input would have a
cost of X/something).
I'm not convinced that a single validation cost metric is the best
approach-- it might be better to break the cost into three (UTXO growth,
CPU, and bandwidth) and just let miners set reasonable transaction
selection policies that keep each of the three under whatever caps are
imposed on each. If a miner comes up with a clever algorithm that lets them
pack in more transactions and get more fees, good for them!
But I do like the simplicity of a single validation cost metric.

@_date: 2015-11-08 14:54:04
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] summarising security assumptions (re cost metrics) 
Agreed. That is why BIP101 / BitcoinXT includes code to limit the relay and
validation cost of blocks.
Agreed, with a quibble: mining economics means they will ALWAYS have a low
profit margin.
Okey dokey-- perhaps we should have another discussion about SPV mining, as
far as I know it harmed nobody besides the miners who mindlessly created
invalid, empty blocks (well, and besides being very annoying for developers
who had to figure out what was happening and get the offending miners to do
the right thing).
In any case, it seems to me all of this (except perhaps selfish mining) is
independent of the maximum block size, and solutions for all of the above
(including selfish mining) should be pursued regardless of what is done
with the max block size (e.g. I sent Ittay and Gun email a few minutes ago
with some might-be-wong-ideas for how weak block announcements might be
used to detect selfish mining).
I'm very disappointed you don't mention the tradeoff at "the other end of
the bathtub" -- Key-holder versus Validator decentralization balance. Did
you see the excellent Poon/Dryja "bathtub" presentation at Montreal?
Agreed, which is why BIP101/XT consider pathological behavior.
Disagree on wording: we should not ignore attacks that have not seen
exploitation. But in the never-ending-list of things to be worried about
and to write code for, attacks that have not been seen should be lower
priority than attacks that have been seen, either in Bitcoin or elsewhere.
E.g. Bitcoin has never seen a buffer-overflow attack, but we absolutely
positively need to put a very high priority on the network attack surface

@_date: 2015-11-09 11:27:22
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] summarising security assumptions (re cost metrics) 
Both.  If few transactions are possible, then that limits the number of
key-holders who can participate in the system.
Imagine the max block size was really small, and stretch your imagination
and just assume there would be enough demand that those small number of
transactions pay enough transaction fees to secure the network. Each
transaction must, therefore, pay a high fee. That limits the number of
keyholders to institutions with very-large-value transactions-- it is the
"Bitcoin as a clearing network for big financial players" model.
Using the Lightning Network doesn't help, since every Lightning Network
transaction IS a set of Bitcoin transactions, ready to be dropped onto the
main chain. If those Lightning Network transactions don't have enough fees,
then the whole security of the Lightning Protocol falls apart (since it
relies on being able to get timelocked transactions confirmed on the main
chain in case your trading partner cheats).
There is video of the Poon/Dryja talk:

@_date: 2015-11-24 15:32:37
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] OP_CHECKWILDCARDSIGVERIFY or "Wildcard Inputs" or 
So every input has:
 32-byte hash (transaction being spent)
 4-byte output (output being spent)
 4-byte sequence number
... plus the scriptSig. Which is as small as about 73 bytes if you're
spending a raw OP_CHECKSIG (which you can't do as a bitcoin address, but
could via the BIP70 payment protocol), and which is at least two serialized
Best case for any scheme to coalesce scriptSigs would to somehow make
all-but-the-first scriptSig zero-length, so the inputs would be 42 bytes
instead of 40+73 bytes -- the coalesce transaction would be about one-third
the size, so instead of paying (say) $1 in transaction fees you'd pay 37
That's in the gray are of the "worth doing" threshold-- if it was a 10x
improvement (pay 10 cents instead of $1) it'd be in my personal "definitely
worth the trouble of doing" category.
RE: the scheme:  an OP_RINGSIGVERIFY is probably the right way to do this:
  The funding transactions would be:   OP_RINGSIGVERIFY
... which might could be redeemed with  for one input and
then... uhh... maybe just  for the other
inputs that are part of the same ring signature group (OP_0 if the first
input has the signature that is good for all the other public keys, which
would be the common case).

@_date: 2015-10-28 10:06:22
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Compatibility requirements for hard or soft forks 
I'm hoping this fits under the moderation rule of "short-term changes to
the Bitcoin protcol" (I'm not exactly clear on what is meant by
"short-term"; it would be lovely if the moderators would start a thread on
bitcoin-discuss to clarify that):
Should it be a requirement that ANY one-megabyte transaction that is valid
under the existing rules also be valid under new rules?
Pro:  There could be expensive-to-validate transactions created and given a
lockTime in the future stored somewhere safe. Their owners may have no
other way of spending the funds (they might have thrown away the private
keys), and changing validation rules to be more strict so that those
transactions are invalid would be an unacceptable confiscation of funds.
Con: It is extremely unlikely there are any such large, timelocked
transactions, because the Core code has had a clear policy for years that
100,000-byte transactions are "standard" and are relayed and
mined, and
larger transactions are not. The requirement should be relaxed so that only
valid 100,000-byte transaction under old consensus rules must be valid
under new consensus rules (larger transactions may or may not be valid).
I had to wrestle with that question when I implemented BIP101/Bitcoin XT
when deciding on a limit for signature hashing (and decided the right
answer was to support any "non-attack"1MB transaction; see
 for more details).

@_date: 2015-09-08 13:04:16
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Dynamic limit to the block size - BIP draft 
I'm not clear on what problem(s) you're trying to solve.
If you want blocks to be at least 60% full, then just specify a simple rule
like "maximum block size is 1.0/0.6 = 1.666 times the average block size
over the last N blocks (applied at every block or every 2016 blocks or
whatever, details don't really matter)".
If you want an upper limit on growth, then just implement a simple rule
like "Absolute maximum block size is 1 megabyte in 2016, 3.45 megabytes in
2017, and increases by a maximum of 3.45 times every year."
If you want me to take your proposal seriously, you need to justify why 60%
full is a good answer (and why we need a centralized decision on how full
blocks "should" be), and why 3.45 times-per-year is a good answer for
maximum growth (and, again, why we need a centralized decision on that).

@_date: 2015-09-23 11:43:11
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Weak block thoughts... 
I've been thinking about 'weak blocks' and SPV mining, and it seems to me
weak blocks will make things better, not worse, if we improve the mining
code a little bit.
First:  the idea of 'weak blocks' (hat tip to Rusty for the term) is for
miners to pre-announce blocks that they're working on, before they've
solved the proof-of-work puzzle. To prevent DoS attacks, assume that some
amount of proof-of-work is done (hence the term 'weak block') to rate-limit
how many 'weak block' messages are relayed across the network.
Today, miners are incentivized to start mining an empty block as soon as
they see a block with valid proof-of-work, because they want to spend as
little time as possible mining a not-best chain.
Imagine miners always pre-announce the blocks they're working on to their
peers, and peers validate those 'weak blocks' as quickly as they are able.
Because weak blocks are pre-validated, when a full-difficulty block based
on a previously announced weak block is found, block propagation should be
insanely fast-- basically, as fast as a single packet can be relayed across
the network the whole network could be mining on the new block.
I don't see any barrier to making accepting the full-difficulty block and
CreateNewBlock() insanely fast, and if those operations take just a
microsecond or three, miners will have an incentive to create blocks with
fee-paying transactions that weren't in the last block, rather than mining
empty blocks.
A miner could try to avoid validation work by just taking a weak block
announced by somebody else, replacing the coinbase and re-computing the
merkle root, and then mining. They will be at a slight disadvantage to
fully validating miners, though, because they WOULD have to mine empty
blocks between the time a full block is found and a fully-validating miner
announced their next weak block.
Weak block announcements are great for the network; they give transaction
creators a pretty good idea of whether or not their transactions are likely
to be confirmed in the next block. And if we're smart about implementing
them, they shouldn't increase bandwidth or CPU usage significantly, because
all the weak blocks at a given point in time are likely to contain the same

@_date: 2015-09-23 13:40:58
@_author: Gavin 
@_subject: [bitcoin-dev] Weak block thoughts... 
I didn't mention the block size limit; weak blocks are a good idea no matter the limit.
As for miners paying for the work: lots of companies contributed to the Foundation, and will contribute to the DCI. When there are big, stable, profitable companies I think we'll see them task their developers to contribute code.
I think optimizing new block propagation is interesting and important, so I plan on working on it.

@_date: 2015-09-23 15:01:55
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] [BIP Proposal] Version bits with timeout and 
I say keep it simple.
If the 75% threshold is hit, then support suddenly drops off below 50%,
"meh" -- there will be a big ruckus, everybody will freak out, and miners
will refuse to build big blocks because they'll worry that they'll get
Adding more complexity for a case that ain't gonna happen (and isn't a
disaster if it does) is a mistake, in my humble opinion.
On Wed, Sep 23, 2015 at 2:33 PM, Tom Harding via bitcoin-dev <

@_date: 2015-09-23 17:37:25
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Weak block thoughts... 
I'm assuming the optimized protocol would be forward-error-coded (e.g.
using IBLTs)  and NOT require the full solution (or follow-on weak blocks)
to be exactly the same.
Yup, although I don't get the 'merge mined' bit; the weak blocks are
ephemeral, probably purged out of memory as soon as a few full blocks are
I don't see any incentive problems, either. Worst case is more miners
decide to skip validation and just mine a variation of the
highest-fee-paying weak block they've seen, but that's not a disaster--
invalid blocks will still get rejected by all the non-miners running full
If we did see that behavior, I bet it would be a good strategy for a big
hashrate miner to dedicate some of their hashrate to announcing invalid
weak blocks; if you can get your lazy competitors to mine it, then you

@_date: 2015-09-28 09:01:02
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Let's deploy BIP65 CHECKLOCKTIMEVERIFY! 
I think three things need to happen:
1) Stop pretending that "everyone must agree to make consensus rule
changes." "Rough consensus" is what we've always gone with, and is good
2) Mr. Todd (or somebody) needs to write up a risk/benefit security
tradeoff analysis doo-hickey document and publish it. I'm reasonably
confident that the risks to SPV nodes can be mitigated (e.g. by deploying
mempool-only first, before the soft fork rolls out), but as somebody who
has only been moderately paying attention, BETTER COMMUNICATION is needed.
What should SPV wallet authors be doing right now, if anything? Once the
soft fork starts to roll out or activates, what do miners need to be aware
of? SPV wallet authors?
3) I agree CLTV is ready to roll out, that there is rough consensus a soft
fork is a reasonable way to do it, and that it should happen ASAP.
On Mon, Sep 28, 2015 at 6:48 AM, Mike Hearn via bitcoin-dev <

@_date: 2015-09-28 09:43:42
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Let's deploy BIP65 CHECKLOCKTIMEVERIFY! 
Hmmm?  When I asked YOU for that kind of security analysis document, you
said you'd see if any of your clients would be willing to let you publish
one you'd done in the past. Then I never heard back from you.
So, no, I don't have one for BIP 101, but unless you were lying and just
trying to add Yet Another Hoop for BIP 101 to jump through, you should
already have something to start from.
RE: mempool only: yes, pull-req 5000 satisfies (and that's what I was
thinking of). There should be a nice, readable blog post explaining to
other full node implementors and wallet implementors why that was done for
Core and what they should do to follow 'best practices to be soft-fork

@_date: 2015-09-29 10:04:39
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Is it possible for there to be two chains after a 
I keep seeing statements like this:
On Tue, Sep 29, 2015 at 9:30 AM, Jonathan Toomim (Toomim Bros) via
... but I can't see how that would work.
Lets say there is a hard fork, and 5% of miners stubbornly refuse to go
along with the 95% majority (for this thought experiment, it doesn't matter
if the old rules or new rules 'win').
Lets further imagine that some exchange decides to support that 5% and lets
people trade coins from that fork (one of the small altcoin exchanges would
definitely do this if they think they can make a profit).
Now, lets say I've got a lot of pre-fork bitcoin; they're valid on both
sides of the fork. I support the 95% chain (because I'm not insane), but
I'm happy to take people's money if they're stupid enough to give it to me.
So, I do the following:
1) Create a send-to-self transaction on the 95% fork that is ONLY valid on
the 95% fork (maybe I CoinJoin with a post-fork coinbase transaction, or
just move my coins into then out of an exchange's very active hot wallet so
I get coins with a long transaction history on the 95% side of the fork).
2) Transfer  those same coins to the 5% exchange and sell them for whatever
price I can get (I don't care how low, it is free money to me-- I will
still own the coins on the 95% fork).
I have to do step (1) to prevent the exchange from taking the
transfer-to-exchange transaction and replaying it on the 95% chain.
I don't see any way of preventing EVERYBODY who has coins on the 95% side
of the fork from doing that. The result would be a huge free-fall in price
as I, and everybody else, rushes to get some free money from anybody
willing to pay us to remain idealogically pure.
Does anybody think something else would happen, and do you think that
ANYBODY would stick to the 5% fork in the face of enormously long
transaction confirmation times (~3 hours), a huge transaction backlog as
lots of the 95%'ers try to sell their coins before the price drops, and a
massive price drop for coins on the 5% fork.

@_date: 2015-09-29 13:35:20
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Is it possible for there to be two chains after a 
Ok, I have a hidden assumption: I assume most miners are also not
completely insane.
I have met a fair number of them, and while they are often a little bit
crazy (all entrepreneurs are a little bit crazy), I am confident that the
vast majority of them are economically rational, and most of them are also
meta-rational: they want Bitcoin to succeed. We've seen them demonstrate
that meta-rationality when we've had accidental consensus forks.
If you start with the premise that more than half of Bitcoin miners would
do something crazy that would either destroy Bitcoin or would be completely
unacceptable to you, personally... then maybe you should look for some
other system that you might trust more, because Bitcoin's basic security
assumption is that a supermajority of miners are 'honest.'

@_date: 2015-09-29 14:01:59
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Is it possible for there to be two chains after a 
We really shouldn't have to go over "Bitcoin 101" on this mailing list, and
this discussion should move to the not-yet-created more general discussion
list.  I started this thread as a sanity check on myself, because I keep
seeing smart people saying that two chains could persist for more than a
few days after a hard fork, and I still don't see how that would possibly
So: "fraud" would be 51% miners sending you bitcoin in exchange for
something of value, you wait for confirmations and send them that something
of value, and then the 51% reverses the transaction.
Running a full node doesn't help.
On Tue, Sep 29, 2015 at 1:55 PM, Allen Piscitello <

@_date: 2016-02-02 10:58:21
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIP Process: Status, comments, 
I like the more concrete definitions of the various statuses.
I don't like the definition of "consensus".  I think the definition
described gives too much centralized control to whoever controls the
mailing list and the wiki.

@_date: 2016-02-04 12:36:06
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Hardfork bit BIP 
This BIP is unnecessary, in my opinion.
I'm going to take issue with items (2) and (3) that are the motivation for
this BIP:
" 2. Full nodes and SPV nodes following original consensus rules may not be
aware of the deployment of a hardfork. They may stick to an
economic-minority fork and unknowingly accept devalued legacy tokens."
If a hardfork is deployed by increasing the version number in blocks (as is
done for soft forks), then there is no risk-- Full and SPV nodes should
notice that they are seeing up-version blocks and warn the user that they
are using obsolete software.
It doesn't matter if the software is obsolete because of hard or soft fork,
the difference in risks between those two cases will not be understood by
the typical full node or SPV node user.
" 3. In the case which the original consensus rules are also valid under
the new consensus rules, users following the new chain may unexpectedly
reorg back to the original chain if it grows faster than the new one.
People may find their confirmed transactions becoming unconfirmed and lose
If a hard or soft fork uses a 'grace period' (as described in BIP 9 or BIP
101) then there is essentially no risk that a reorg will happen past the
triggering block. A block-chain re-org of two thousand or more blocks on
the main Bitcoin chain is unthinkable-- the economic chaos would be
massive, and the reaction to such a drastic (and extremely unlikely) event
would certainly be a hastily imposed checkpoint to get everybody back onto
the chain that everybody was using for economic transactions.
Since I don't agree with the motivations for this BIP, I don't think the
proposed mechanism (a negative-version-number-block) is necessary. And
since it would simply add more consensus-level code, I believe the
keep-it-simple principle applies.

@_date: 2016-02-04 17:15:41
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Hardfork bit BIP 
It is always possible I'm being dense, but I still don't understand how
this proposal makes a chain-forking situation better for anybody.
If there are SPV clients that don't pay attention to versions in block
headers, then setting the block version negative doesn't directly help
them, they will ignore it in any case.
If the worry is full nodes that are not upgraded, then a block with a
negative version number will, indeed, fork them off the the chain, in
exactly the same way a block with new hard-forking consensus rules would.
And with the same consequences (if there is any hashpower not paying
attention, then a worthless minority chain might continue on with the old
If the worry is not-upgraded SPV clients connecting to the old,
not-upgraded full nodes, I don't see how this proposed BIP helps.
I think a much better idea than this proposed BIP would be a BIP that
recommends that SPV clients to pay attention to block version numbers in
the headers that they download, and warn if there is a soft OR hard fork
that they don't know about.
It is also a very good idea for SPV clients to pay attention to timestamps
in the block headers that the receive, and to warn if blocks were generated
either much slower or faster than statistically likely. Doing that (as
Bitcoin Core already does) will mitigate Sybil attacks in general.

@_date: 2016-02-05 15:51:08
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIP proposal: Increase block size limit to 2 megabytes 
This has been reviewed by merchants, miners and exchanges for a couple of
weeks, and has been implemented and tested as part of the Bitcoin Classic
and Bitcoin XT implementations.
Constructive feedback welcome; argument about whether or not it is a good
idea to roll out a hard fork now will be unproductive, so I vote we don't
go there.
Draft BIP:
    Increase block size limit to 2,000,000 bytes.
  After 75% hashpower support then 28-day grace period.
  With accurate sigop counting, but existing sigop limit (20,000)
  And a new, high limit on signature hashing
Blog post walking through the code:
  Blog post on a couple of the constants chosen:

@_date: 2016-02-06 10:37:30
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIP proposal: Increase block size limit to 2 
Responding to "28 days is not long enough" :
I keep seeing this claim made with no evidence to back it up.  As I said, I
surveyed several of the biggest infrastructure providers and the btcd lead
developer and they all agree "28 days is plenty of time."
For individuals... why would it take somebody longer than 28 days to either
download and restart their bitcoind, or to patch and then re-run (the patch
can be a one-line change MAX_BLOCK_SIZE from 1000000 to 2000000)?
For the Bitcoin Core project:  I'm well aware of how long it takes to roll
out new binaries, and 28 days is plenty of time.
I suspect there ARE a significant percentage of un-maintained full nodes--
probably 30 to 40%. Losing those nodes will not be a problem, for three
1) The network could shrink by 60% and it would still have plenty of open
connection slots
2) People are committing to spinning up thousands of supports-2mb-nodes
during the grace period.
3) We could wait a year and pick up maybe 10 or 20% more.
I strongly disagree with the statement that there is no cost to a longer
grace period. There is broad agreement that a capacity increase is needed
To bring it back to bitcoin-dev territory:  are there any TECHNICAL
arguments why an upgrade would take a business or individual longer than 28
Responding to Luke's message:
On Sat, Feb 6, 2016 at 1:12 AM, Luke Dashjr via bitcoin-dev
I'll rename the section and expand it a little. I think standards documents
like BIPs should be concise, though (written for implementors), so I'm not
going to recreate the entire blog post there.
After implementing static counting and accurate counting... I was wrong.
Accurate/dynamic counting/limiting is quick and simple and can be
completely safe (the counting code can be told the limit and can
"early-out" validation).
I think making scripts commit to a total accurate sigop count is a bad
idea-- it would make multisignature signing more complicated for zero
benefit.  E.g. if you're circulating a partially signed transaction to that
must be signed by 2 of 5 people, you can end up with a transaction that
requires 2, 3, 4, or 5 signature operations to validate (depending on which
public keys are used to do the signing).  The first signer might have no
idea who else would sign and wouldn't know the accurate sigop count.
It is slightly more hashing than was required to validate block number
There are a couple of advantages to a very high limit:
1) When the fork is over, special-case code for dealing with old blocks can
be eliminated, because all old blocks satisfy the new limit.
2) More importantly, if the limit is small enough it might get hit by
standard transactions, then block creation code (CreateNewBlock() /
getblocktemplate / or some external transaction-assembling software) will
have to solve an even more complicated bin-packing problem to optimize for
fees paid.
In practice, the 20,000 sigop limit will always be reached before
"The economy" does support this.
Happy to add words about economic majority.
Classic will not implement a command-line option (the act of running
Classic is "I opt in"), but happy to add one for a pull request to Core,
assuming Core would not see such a pull request as having any hostile
Is there an explanation of SPV versus "Light Client" written somewhere more
permanent than a reddit comment or forum post that I can point to?
Happy to remove.
Those would be separate BIPs. (according to BIP 1, smaller is better)
After this 2MB bump, I agree we need to agree on a process for the next
hard fork to avoid all of the unnecessary drama.
I haven't been paying attention to all of the
"soft-hardfork/hard-softfork/etc" terminology so have no idea what you
mean. Is THAT written up somewhere?

@_date: 2016-02-06 12:45:14
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIP proposal: Increase block size limit to 2 
Containing what?  I'm not aware of any security considerations that are any
different from any other consensus rules change.
(I can write a blog post summarizing our slack discussion of SPV security
immediately after the first greater-than-1mb-block if you like).
That testing is happening by the exchange, library, wallet, etc providers
themselves. There is a list on the Classic home page:
The only voting in this BIP is done by the miners, and that cannot be faked.
Are you talking about people spinning up pseudo-full-nodes that fake the
As I said, there are people who have said they will spin up thousands of
full nodes to help prevent possible Sybil attacks which would become
marginally easier to accomplish immediately after the first >1mb block was
produced and full nodes that hadn't upgraded were left behind.
Would Blockstream be willing to help out by running a dozen or two extra
full nodes?
I can't imagine any even-remotely-likely sequence of events that would
require a rollback, can you be more specific about what you are imagining?
Miners suddenly getting cold feet?
I don't plan to monitor or manage anything; the Bitcoin network is
self-monitoring and self-managing. Services like statoshi.info will do the
monitoring, and miners and people and businesses will manage the network,
as they do every day.

@_date: 2016-02-07 09:16:02
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIP proposal: Increase block size limit to 2 
On Sat, Feb 6, 2016 at 3:46 PM, Luke Dashjr via bitcoin-dev <
There will be approximately zero percentage of hash power left on the
weaker branch of the fork, based on past soft-fork adoption by miners (they
upgrade VERY quickly from 75% to over 95%).
So it will take a week to get 6 confirmations.
If you are a full node, you are warned that your software is obsolete and
you must upgrade.
If you are a lightweight node, it SHOULD tell you something is wrong, but
even if it doesn't, given that people running lightweight nodes run them so
they don't have to be connected to the network 24/7, it is very likely
during that week you disconnect and reconnect to the network several times.
And every time you do that you increase your chances that you will connect
to full nodes on the majority branch of the chain, where you will be told
about the double-spend.
All of that is assuming that there is no OTHER mitigation done. DNS seeds
should avoid reporting nodes that look like they are in the middle of
initial block download (that are at a block height significantly behind the
rest of the network), for example.

@_date: 2016-02-07 12:09:46
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIP proposal: Increase block size limit to 2 
As I feared, request on feedback for this specific BIP has devolved into a
general debate about the merits of soft-forks versus hard-forks (versus
semi-hard Kosher Free Range forks...).
I've replied to several people privately off-list to not waste people's
time rehashing arguments that have been argued to death in the past.
I do want to briefly address all of the concerns that stem from "what if a
significant fraction of hashpower (e.g. 25%) stick with the 1mb branch of
the chain."
Proof of work cannot be spoofed. If there is very little (a few percent) of
hashpower mining a minority chain, confirmations on that chain take orders
of magnitude longer.  I wrote about why the incentives are extremely strong
for only the stronger branch to survive here:
 ... the debate about whether or not that is correct doesn't belong here in
bitcoin-dev, in my humble opinion.
All of the security concerns I have seen flow from an assumption that
significant hashpower continues on the weaker branch. The BIP that is under
discussion assumes that analysis is correct. I have not seen any evidence
that it is not correct; all experience with previous forks (of both Bitcoin
and altcoins) is that the stronger branch survives and the weaker branch
very quickly dies.
As for the argument that creating and testing a patch for Core would take
longer than 28 days:
The glib answer is "people should just run Classic, then."
A less glib answer is it would be trivial to create a patch for Core that
accepted a more proof-of-work chain with larger blocks, but refused to mine
larger blocks.
That would be a trivial patch that would require very little testing
(extensive testing of 8 and 20mb blocks has already been done), and perhaps
would be the best compromise until we can agree on a permanent solution
that eliminates the arbitrary, contentious limits.

@_date: 2016-02-07 15:20:27
@_author: Gavin 
@_subject: [bitcoin-dev] Hardfork bit BIP 
Soft forks affect the security of low-confirmation (zero or one) transactions sent to SPV wallets even more than hard forks, and because many users and businesses choose convenience over airtight security I would argue transaction validation rule changes are a VERY big concern for lightweight clients.

@_date: 2016-02-09 11:54:14
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] BIP proposal: Increase block size limit to 2 
I love seeing data!  I was considering 0.10 nodes as 'unmaintained' because
it has been a long time since the 0.11 release.
That is my estimate of the worst-case-- not 'sane default.'
My point is that even if the number of nodes shrank by 60%, we would not
see any issues (SPV nodes would still have no problem finding a full node
to connect to, full nodes would not have any problem connecting to each
other, and we would not be significantly more vulnerable to Sybil attacks
or "governments get together and try to ban running a full node" attacks).
There are over a thousand people subscribed to the Classic slack channel,
many of whom have privately told me they are willing and able to run an
extra node or three (or a hundred-and-eleven) once there is a final release.
I'm not going to name names, because
 a) these were private communications, and
 b) risk of death threats, extortion, doxxing, DoS attacks, etc.  Those
risks aren't theoretical, they are very real.
To be clear: I will discourage and publicly condemn anybody who runs
'pseudo nodes' or plans to spin up lots of nodes to try to influence the
debate. The only legitimate reason to run extra nodes is to fill in a
possible gap in total node count that might be caused by old, unmaintained
nodes that stop serving blocks because the rest of the network has upgraded.
The adoption curve for a new major release is exponential: lots of adoption
in the first 30 days or so, then it rapidly tapers off.  Given that
people's nodes will be alerting them that they must upgrade, and given that
every source of Bitcoin news will probably be covering the miner adoption
vote like it was a presidential election, I expect the adoption curve for
the 2mb bump to be steeper than we've ever seen.  So my best guess is
70-80% of nodes will upgrade within 30 days of the miner voting hitting 50%
of blocks and triggering the automatic 'version obsolete; upgrade required'
Wait a year, and my guess is you might reach another 10-20% (80 to
90-something percent).

@_date: 2016-01-07 14:02:05
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or not? 
I'm hoisting this from some private feedback I sent on the segregated
witness BIP:
I said:
"I'd also use RIPEMD160(SHA256()) as the hash function and save the 12
bytes-- a successful preimage attack against that ain't gonna happen before
we're all dead. I'm probably being dense, but I just don't see how a
collision attack is relevant here."
Pieter responded:
"The problem case is where someone in a contract setup shows you a script,
which you accept as being a payment to yourself. An attacker could use a
collision attack to construct scripts with identical hashes, only one of
which does have the property you want, and steal coins.
So you really want collision security, and I don't think 80 bits is
something we should encourage for that. Normal pubkey hashes don't have
that problem, as they can't be constructed to pay to you."
... but I'm unconvinced:
"But it is trivial for contract wallets to protect against collision
attacks-- if you give me a script that is "gavin_pubkey CHECKSIG
arbitrary_data OP_DROP" with "I promise I'm not trying to rip you off, just
ignore that arbitrary data" a wallet can just refuse. Even more likely, a
contract wallet won't even recognize that as a pay-to-gavin transaction.
I suppose it could be looking for some form of "gavin_pubkey
somebody_else_pubkey CHECKMULTISIG ... with the attacker using
somebody_else_pubkey to force the collision, but, again, trivial contract
protocol tweaks ("send along a proof you have the private key corresponding
to the public key" or "everybody pre-commits pubkeys they'll use at
protocol start") would protect against that.
Adding an extra 12 bytes to every segwit to prevent an attack that takes
2^80 computation and 2^80 storage, is unlikely to be a problem in practice,
and is trivial to protect against is the wrong tradeoff to make."
20 bytes instead of 32 bytes is a savings of almost 40%, which is
The general question I'd like to raise on this list is:
Should we be worried, today, about collision attacks against RIPEMD160 (our
160-bit hash)?
Mounting a successful brute-force collision attack would require at least
O(2^80) CPU, which is kinda-sorta feasible (Pieter pointed out that Bitcoin
POW has computed more SHA256 hashes than that). But it also requires
O(2^80) storage, which is utterly infeasible (there is something on the
order of 2^35 bytes of storage in the entire world).  Even assuming
doubling every single year (faster than Moore's Law), we're four decades
away from an attacker with THE ENTIRE WORLD's storage capacity being able
to mount a collision attack.

@_date: 2016-01-07 16:06:30
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
Maybe I'm asking this question on the wrong mailing list:
Matt/Adam: do you have some reason to think that RIPEMD160 will be broken
before SHA256?
And do you have some reason to think that they will be so broken that the
nested hash construction RIPEMD160(SHA256()) will be vulnerable?
Adam: re: "where to stop"  :  I'm suggesting we stop exactly at the current
status quo, where we use RIPEMD160 for P2SH and P2PKH.
Ethan:  your algorithm will find two arbitrary values that collide. That
isn't useful as an attack in the context we're talking about here (both of
those values will be useless as coin destinations with overwhelming
Dave: you described a first preimage attack, which is 2**160 cpu time and
no storage.

@_date: 2016-01-07 18:39:58
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
Thanks, Ethan, that's helpful and I'll stop thinking that collision attacks
require 2^(n/2) memory...
So can we quantify the incremental increase in security of SHA256(SHA256)
over RIPEMD160(SHA256) versus the incremental increase in security of
having a simpler implementation of segwitness?
I'm going to claim that the difference in the first case is very, very,
very small-- the risk of an implementation error caused by having multiple
ways of interpreting the segwitness hash in the scriptPubKey is much, much
And even if there IS some risk of collision attack now or at some point in
the future, I claim that it is easy for wallets to mitigate that risk. In
fact, the principle of security in depth means wallets that don't
completely control the scriptPubKeys they're creating on behalf of users
SHOULD be coded to mitigate that risk (e.g. not allowing arbitrary data
around a user's public key in a Script so targeted substring attacks are
eliminated entirely).
Purely from a security point of view, I think a single 20-byte segwitness
in the scriptPubKey is the best design.
"Keep the design as simple and small as possible"
Add in the implied capacity increase of smaller scriptPubKeys and I still
think it is a no-brainer.

@_date: 2016-01-07 20:00:42
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
Our message may have crossed in the mod queue:
"So can we quantify the incremental increase in security of SHA256(SHA256)
over RIPEMD160(SHA256) versus the incremental increase in security of
having a simpler implementation of segwitness?"
I believe the history of computer security is that implementation errors
and sidechannel attacks are much, much more common than brute-force breaks.
KEEP IT SIMPLE.
(and a quibble:  "do a 80-bit search for B and C such that H(A and B) = H(B
and C)"  isn't enough, you have to end up with a C public key for which you
know the corresponding private key or the attacker just succeeds in burning
the funds)

@_date: 2016-01-07 20:54:00
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
On Thu, Jan 7, 2016 at 8:26 PM, Matt Corallo I'm saying we can eliminate one somewhat unlikely attack (that there is a
bug in the code or test cases, today or some future version, that has to
decide what to do with "version 0" versus "version 1" witness programs) by
accepting the risk of another insanely, extremely unlikely attack.
Reference for those who are lost:
My proposal would be to just do a version 0 witness program now, that is
And ten or twenty years from now, if there is a plausible attack on
RIPEMD160 and/or SHA256, revisit and do a version 11 (or whatever).
It will simplify the BIP, means half as many test cases have to be written,
means a little more scalability, and is as secure as the P2SH and P2PKH
everybody is using to secure their bitcoin today.
Tell you what:  I'll change my mind if anybody can describe a plausible
attack if we were using MD5(SHA256), given what we know about how MD5 is
I'm really disappointed with the "Here's the spec, take it or leave it"
attitude. What's the point of having a BIP process if the discussion just
comes down to "We think more is better. We don't care what you think."

@_date: 2016-01-08 07:38:50
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
It feels like we've gone over that before, but I can never remember where
or when. I believe consensus was that if we were using the broken MD5 in
all the places we use RIPEMD160 we'd still be secure today because of
Satoshi's use of nested hash functions everywhere.
Lets see if I've followed the specifics of the collision attack correctly,
Ethan (or somebody) please let me know if I'm missing something:
So attacker is in the middle of establishing a payment channel with
somebody. Victim gives their public key, attacker creates the innocent
fund-locking script  '2 V A 2 CHECKMULTISIG' (V is victim's public key, A
is attacker's) but doesn't give it to the victim yet.
Instead they then generate about 2^81scripts that are some form of
pay-to-attacker ....
... wait, no that doesn't work, because SHA256 is used as the inner hash
function.  They'd have to generate 2^129 to find a cycle in SHA256.
Instead, they .. what? I don't see a viable attack unless RIPEMD160 and
SHA256 (or the combination) suffers a cryptographic break.

@_date: 2016-01-08 10:46:53
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
Thanks, Anthony, that works!
How many years until we think a 2^84 attack where the work is an ECDSA
private->public key derivation will take a reasonable amount of time?
And Ethan or Anthony:  can you think of a similar attack scheme if you
assume we had switched to Schnorr 2-of-2 signatures by then?
And to everybody who might not be reading this closely:  All of the above
is discussing collision attacks; none of it is relevant in the normal case
where your wallet generates the scriptPubKey.

@_date: 2016-01-08 10:50:06
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
And to fend off the messag that I bet somebody is composing right now:
Yes, I know about a "security first" mindset.  But as I said earlier in the
thread, there is a tradeoff here between crypto strength and code
complexity, and "the strength of the crypto is all that matters" is NOT
security first.

@_date: 2016-01-08 10:59:21
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
On Fri, Jan 8, 2016 at 10:50 AM, Gavin Andresen I should be more explicit about code complexity:
The big picture is "segwitness will help scale in the very short term."
So the spec gives two ways of stuffing the segwitness hash into the
scriptPubKey -- one way that uses a 32-bit hash, but if used would actually
make scalability a bit worse as coins moved into segwitness-locked
transactions (DUP HASH160 EQUALVERIFY pay-to-script-hash scriptpubkeys are
just 24 bytes).
And another way that add just one byte to the scriptpubkey.
THAT is the code complexity I'm talking about.  Better to always move the
script into the witness data, in my opinion, on the keep the design as
simple as possible principle.
It could be a 32-byte hash... but then the short-term scalability goal is
Maybe I'm being dense, but I still think it is a no-brainer....

@_date: 2016-01-08 11:06:34
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
On Fri, Jan 8, 2016 at 10:46 AM, Gavin Andresen Don't answer that, I was being dense again, Anthony's scheme works with

@_date: 2016-01-12 07:08:18
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
I'm convinced-- it is a good idea to worry about 80-bit collision attacks
Thanks to all the people smarter than me who contributed to this
discussion, I learned a lot about collision attacks that I didn't know
Would this be a reasonable "executive summary" :
If you are agreeing to lock up funds with somebody else, and they control
what public key to use, you are susceptible to collision attacks.
It is very likely an 80-bit-collision-in-ten-minutes attack will cost less
than $1million in 10 to twenty years (possibly sooner if there are crypto
breaks in that time).
If you don't trust the person with whom you're locking up funds and you're
locking up a significant amount of money (tens of millions of dollars
today, tens of thousands of dollars in a few years):
Then you should avoid using pay-to-script-hash addresses and instead use
the payment protocol and "raw" multisig outputs.
Have them give you a hierarchical deterministic (BIP32) seed, and derive a
public key for them to use.
Following the security in depth and validate all input secure coding
principles would mean doing both-- avoid p2sh AND have all parties to a
transaction exchange HD seeds, add randomness, and use the resulting public
keys in the transaction.

@_date: 2016-01-23 16:38:44
@_author: Gavin 
@_subject: [bitcoin-dev] Three Month bitcoin-dev Moderation Review 
Yes, comments should contribute to the discussion, with either technical discussion or additional relevant data. I think a +1 like the following should be encouraged:
"+1: we had eleven customer support tickets in just the last week that would have been prevented if XYZ.
Jane Doe, CTO CoinBitChainBasely.com"

@_date: 2016-01-29 11:39:14
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Best (block nr % 2016) for hard fork activation? 
Block timestamps are in the 80-byte block header, so activation is
completely deterministic and can be determined from just the sequence of
block headers. There are no edge cases to worry about.
But even more so I would expect there to be significant differences in
It doesn't matter much where in the difficulty period the fork happens; if
it happens in the middle, the lower-power fork's difficulty will adjust a
little quicker.
Example:  (check my math, I'm really good at screwing up at basic
Fork at block%2016:  25% hashpower will take 8 weeks to produce 2016
blocks, difficulty drops by 4.
Fork one-week (halfway) into difficulty period:  25% hashpower will take 4
weeks to adjust, difficulty drops by 5/2 = 2.5
It will then take another 3.2 weeks to get to the next difficult adjustment
period and normal 10-minute blocks.
That's an unrealisitic scenario, though-- there will not be 25% of hash
power on a minority fork. I wrote about why in a blog post today:
If you assume a more realistic single-digit-percentage of hash power on the
minority fork, then the numbers get silly (e.g. two or three months of an
hour or three between blocks before a difficulty adjustment).

@_date: 2016-10-16 12:35:58
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Start time for BIP141 (segwit) 
I asked a lot of businesses and individuals how long it would take them to
upgrade to a new release over the last year or two.
Nobody said it would take them more than two weeks.
If somebody is running their own validation code... then we should assume
they're sophisticated enough to figure out how to mitigate any risks
associated with segwit activation on their own.

@_date: 2017-01-26 12:21:37
@_author: Gavin Andresen 
@_subject: [bitcoin-dev] Anti-transaction replay in a hardfork 
Compatibility with existing transaction-signing software and hardware
should be considered.
I think any hard fork proposal should support a reasonable number of
reasonable-size old-sighash transactions, to allow a smooth transaction of
wallet software and hardware and to support anybody who might have a
hardware wallet locked away in a safe deposit box for years.
