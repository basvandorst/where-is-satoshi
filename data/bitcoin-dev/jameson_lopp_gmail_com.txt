
@_date: 2013-12-09 18:23:17
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Monetary Authority for Bitcoin 
To piggyback on Jeff,
Any proposal that is going to add reliance upon data from third parties
outside of the Bitcoin network itself is likely going to be rejected
outright. This opens far too many potential vulnerabilities.
"The exchanges that are kept track of could be hard coded into Bitcoin
or the miner could choose, how this works is not something I'm
personally focused on."
Yeah... you can't just gloss over a little detail like that. There must
be consensus between the miners, otherwise a solved block will be
rejected by a miner's peers.
Jameson Lopp
Software Engineer
Bronto Software, Inc

@_date: 2013-12-10 11:27:26
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Popularity based mining (variable block 
"no reliance on external data" ... "depending on various factors (coin
valuation/exchange rate"
Jameson Lopp
Software Engineer
Bronto Software

@_date: 2013-11-05 14:33:14
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] BIP proposal - patch to raise selfish 
The conversations that spawned from this paper have been fascinating to read, but I have a problem with the conclusions. To quote the paper:
"The Bitcoin ecosystem is open to manipulation, and potential takeover, by miners seeking to maximize their rewards. This paper presented Selfish-Mine, a mining strategy that enables pools of colluding miners
that adopt it to earn revenues in excess of their mining power. Higher revenues can lead new rational miners to join selsh miner pools, leading to a collapse of the decentralized currency."
Please explain to me why any rational miner would collude to earn slightly higher short term profits at the expense of then wiping out the value of all their bitcoins in the long term.
Also, if you felt that this vulnerability is an immediate danger to the Bitcoin network, why publish the vulnerability publicly rather than first disclosing it privately to the core developers? Apologies if you did disclose it privately in the past; I've seen no mention of it.
Jameson Lopp
Software Engineer
Bronto Software

@_date: 2014-04-07 08:19:04
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
I'm glad to see that I'm not the only one concerned about the consistent dropping of nodes. Though I think that the fundamental question should be: how many nodes do we really need? Obviously more is better, but it's difficult to say how concerned we should be without more information. I posted my thoughts last month: I have begun working on my node monitoring project and will post updates if it results in me gaining any new insights about the network.
- Jameson

@_date: 2014-04-07 08:34:49
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
I agree, but if we don't quantify "demand" then we are practically blind. What is the plan? To wait until SPV clients start lagging / timing out because their requests cannot be handled by the nodes?
For all I know, the network would run just fine on 100 nodes. But not knowing really irks me as an engineer.
- Jameson

@_date: 2014-04-07 09:58:37
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
The Bitnodes project updated their counting algorithm a month or so ago. It used to be slower and less accurate - prior to their update, it was reporting in excess of 100,000 nodes.
- Jameson

@_date: 2014-04-07 12:02:49
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Why are we bleeding nodes? 
I would point to bandwidth as the most important issue to the casual user who runs a node at home. Few casual users have the know-how to set up QoS rules and thus become quite annoyed when their Internet connection is discernibly slowed.
- Jameson

@_date: 2014-04-19 18:41:43
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Update alert false positives 
Looks like Matt just pushed out new builds to the Ubuntu PPA, so this issue should resolve itself shortly.
- Jameson

@_date: 2014-04-30 13:13:50
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Coinbase reallocation to discourage 
Perhaps I missed it somewhere, but I don't recall it ever being a goal of Bitcoin to act as a stable long-term store of value.
- Jameson

@_date: 2014-02-10 13:45:58
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] MtGox blames bitcoin 
You have plenty of good points, but they are not relevant to this mailing list. I suggest you take them elsewhere.
Jameson Lopp
Software Engineer
Bronto Software, Inc

@_date: 2014-07-31 08:59:17
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Abusive and broken bitcoin seeders 
Hash: SHA1
I may be able to provide some insight regarding request volume / abuse via my public node at My node receives a 'getaddr' request about every 50 seconds: In terms of the 'addr' messages that it sends out, the volume is also low. This graph has 'inv' and 'tx' sent messages for comparison. Now, these are just message volume and not actual resource usage, but I have a feeling that 'getaddr' requests are not resource intensive since it shouldn't be reading from disk. I could look into adding timing metrics around these requests if you think it could be useful.
- - Jameson

@_date: 2014-05-07 15:12:18
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Announcing the Statoshi fork 
Hash: SHA1
In order to gain more insight into what messages and requests a node is processing, I've created a Bitcoin Core fork that outputs statistics to StatsD. I hope that some of you will find this interesting and potentially useful.
Feedback is appreciated!
- - Jameson

@_date: 2014-05-07 15:57:32
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Announcing the Statoshi fork 
Hash: SHA1
The next logical step may be for us to offer a public instance of these graphs; I'd be happy to work with you to set one up.
I agree that it would be awesome to offer these types of stats with the installer; unfortunately the route I've taken has dependencies on several other other pieces of software to do all the heavy lifting of stats aggregation and chart rendering. I'm assuming that you would not want to build any of that processing into Bitcoin Core itself; would you be opposed to packaging other software along with the installer?
- - Jameson

@_date: 2014-05-07 16:00:44
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Announcing the Statoshi fork 
Hash: SHA1
I completely agree that this setup is far too difficult to reasonably expect anyone to implement it. You're correct that we could run a single StatsD daemon and have quite a few nodes sending statistics to it - this is really what StatsD was designed for - sampling small amounts of stats from high volume systems. There would be an issue of trust, however - StatsD was also only really designed to be run inside of highly secure infrastructure where you trust all of the machines that are talking to it.
- - Jameson

@_date: 2014-05-07 16:35:06
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Announcing the Statoshi fork 
Hash: SHA1
The charts are generated on-demand by Graphite, which is a Django app.
I will note that one reason I chose StatsD is because it sends the stats via UDP rather than TCP, which is a non-blocking operation. I didn't want the sending of stats to affect the node's performance.
- - Jameson

@_date: 2014-05-11 13:14:18
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] statoshi.info is now live 
Hash: SHA1
Since it seems unlikely that we'll be able to ship an integrated stats / monitoring feature in the short term, I went ahead and set up a public Statoshi instance and threw a nicer interface on top of it.
You can also view the raw Graphite stats at If there are any metrics that you think would be helpful for development or monitoring purposes, just let me know and I'll take a shot at adding them.

@_date: 2014-05-14 07:38:48
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] statoshi.info is now live 
Hash: SHA1
Thanks; I've received several suggestions for other metrics to collect that I hope to implement soon, but you're right in that tracking per-peer pings is a different type of metric than what I'm currently collecting. I actually noted the lack of pong messages in a post I made a few weeks ago: Once I added metrics for sent messages, it validated my theory: my node has never sent a single ping request to a peer and thus has never received a pong message. I can't even add sent pings or received pongs to this chart because they don't exist in my graphite instance. I guess my question regarding ping stats is how useful that information would be - it seems to me that if we are trying to quantify the cohesiveness of the network, we should instead be observing the message propagation times. Though that's outside the scope of my project; there are other people who are doing just that.

@_date: 2014-11-08 16:47:03
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Running a full node 
Hash: SHA1
I host charts of my node's system metrics at Note that the CPU spikes are abnormal as I'm making automated RPC calls to query the UTXO set.
My node's bandwidth usage chart can be found at - - Jameson

@_date: 2014-10-12 15:13:06
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Request for review/testing: headers-first 
Great work, Pieter. I've been spooling up several nodes per week lately and can testify that stalled downloads during initial syncing are a pain. I usually forgo bootstrapping on VPSes because I don't want to have to adjust the disk space allocation.
With headers-first I'm saturating my home cable connection with download rates of 4 MB/s until block 295,000 at which point CPU becomes the bottleneck and it settles down in the 1 MB/s range.
It took 6 minutes for my node to sync to block height 100,000
22 minutes to reach height 200,000
62 minutes to reach height 250,000
125 minutes to reach height 295,000
144 minutes to reach height 300,000
248 minutes to reach height 325,000
- Jameson

@_date: 2015-08-07 14:05:29
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Fwd: Block size following technological growth 
Anecdotally I've seen two primary reasons posed for not running a node:
1) For enthusiasts who want to altruistically run a node at home, it's
usually a bandwidth / quality of service problem. There are tools to help
work around this, but most users aren't sysadmins and would prefer a simple
configuration option in bitcoind and a slider / selector in the QT client
to throttle the total bandwidth usage. This issue has been open for years:
 - if you want to make it
easier for enthusiasts to run nodes, I'd start there.
2) For businesses, it's not so much an issue with the resources of
installing / running / maintaining a node, it's an issue with the lack of
indexing options offered by bitcoind. Thus the business will also need to
run their own indexing solution - an out-of-the-box solution such as
Insight or Toshi might work, but for more custom indexing you have to roll
your own software - this is where it actually becomes expensive.
Depending upon the query volume / latency needs of the business, it may not
make sense to bother administering bitcoind instances, the indexing
software, and its databases - using a third party API will probably be more
- Jameson
On Fri, Aug 7, 2015 at 1:50 PM, Gavin Andresen via bitcoin-dev <

@_date: 2015-08-19 07:42:06
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] A solution to increase the incentive of running a 
node operator to prove to the rest of the network that they are running an
honest full node that hosts the entire blockchain, then you can move
forward with a direct monetary incentivization proposal. To my knowledge no
one has been successful in that endeavor. To be more clear, your proposal
would need to be able to differentiate between a full node and a
pseudonode. The incentives for running a node may not be obvious to the average user,
but they are there. Rather than direct monetary incentives, they are
indirect. For one, it allows you to have a local copy of the blockchain
that you validated yourself - trustlessness is the entire point of this
system. Having local self-validated blockchain data is also essential for
any enterprise that needs to quickly access large volumes of it. The other
incentive is it supports the network. Users may feel that this is necessary
out of altruism or they may feel incentivized to protect their investments
in Bitcoin.
- Jameson

@_date: 2015-08-19 08:08:13
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] A solution to increase the incentive of running a 
If operating as an SPV node then it can check the transactions by querying
other nodes.
On an unrelated note, it sounds like your proposal will significantly
increase the data size of every transaction, which will create even more
contention for block space.
- Jameson

@_date: 2015-08-19 08:44:03
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] A solution to increase the incentive of running a 
without having any blockchain data available; are you referring to a
different type of validation?
If you're running an SPV node that is listening to full nodes on the
network, you can request an unconfirmed transaction from connected peers
after receiving the inventory message they send - that's how unconfirmed
transactions propagate through the node network. This is not 100% proof
that the transaction is valid for inclusion in the blockchain, but it's a
very good indicator.
- Jameson

@_date: 2015-08-29 10:22:01
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Variable Block Size Proposal 
I don't think you'll find much support for introducing a mandatory minimum
block size. It's quite wasteful to "pad" blocks with transactions that the
miner is just sending back to themself. If you want to solve the block
propagation issue, I'd recommend instead working on O(1) block propagation.
The Bitcoin Relay Network already allows miners to relay blocks much
faster: The next step would be getting O(1) block propagation into the Bitcoin
protocol. Check out Gavin's proposal:
- Jameson
On Sat, Aug 29, 2015 at 1:41 AM, Justin M. Wray via bitcoin-dev <

@_date: 2015-12-16 18:06:08
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Block size: It's economics & user preparation & 
Indeed, because I sometimes find these statements to be confusing as well -
I can completely understand what you mean if you're speaking from a moral
standpoint. If you're saying that it's unacceptable for the Bitcoin Core
developers to force consensus changes upon the system, I agree. But
thankfully the design of the system does not allow the developers to do so.
Developers can commit amazing code or terrible code, but it must be
voluntarily adopted by the rest of the ecosystem. Core developers can't
decide these changes, they merely propose them to the ecosystem by writing
and releasing code.
I agree that Core developers have no authority to make these decisions on
behalf of all of the network participants. However, they are in a position
of authority when it comes to proposing changes. One of my takeaways from
Hong Kong was that most miners have little interest in taking
responsibility for consensus changes - they trust the Core developers to
use their expertise to propose changes that will result in the continued
operation of the network and not endanger their business operations.
A non-trivial portion of the ecosystem is requesting that the Core
developers make a proposal so that the network participants can make a
choice. Jeff noted that we can expect for the economic conditions of the
network to change significantly in 2016, barring higher throughput
capacity. If the year+ deployment timeframe for hard forks proposed by Matt
on another thread is what we can expect for any proposed consensus change,
then it should be non-contentious to announce that there will be no hard
fork in 2016. This will give clarity to the rest of the ecosystem as to how
they should prepare.

@_date: 2015-12-16 13:51:47
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Segregated Witness in the context of Scaling 
On Wed, Dec 16, 2015 at 12:50 PM, Matt Corallo via bitcoin-dev <
Over a year seems to be an extraordinarily long time frame is for deploying
a hard fork. It looks like  75%
of reachable nodes have upgraded in the past 6 months while as much as 25%
may not have been upgraded in over a year. However, viewing historical
stats of version upgrades doesn't seem to be an appropriate comparison
because node operators have never been faced with the same incentive to
upgrade. We can point to unintentional forks in the past that have been
resolved fairly quickly by reaching out to miners, but it's also a poor
comparison. Unfortunately, we have no way of knowing what percentage of
nodes are economically important - a great deal of them may be running and
not even be used by the operators.
Perhaps it would be better if we were to formalize the expectations for
full node operators, but it seems to me that node operators have a
responsibility to keep themselves informed and decide when it is
appropriate to update their software. I'm not so sure that it's the rest of
the ecosystem's responsibility to wait around for laggards.
- Jameson
On December 16, 2015 12:38:30 PM PST, Jeff Garzik via bitcoin-dev <

@_date: 2015-02-24 09:54:17
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Request for comments on hybrid PoW/PoS 
This is an interesting idea from the standpoint of trying to incentivize
people to run nodes, though from a high level it seems to just be adding
complexity to the current process by which nodes 'endorse' blocks. When a
node receives and validates a block it then informs its peers of the new
inventory, thus offering to send the block that 'endorses' as valid.
"Because there is an incentive to include endorsers, there is an incentive
to broadcast mined blocks as soon as possible." - I'd say that this is
already the case due to the incentive for a miner's block to get propagated
around the network first.
My first question would be whether or not your proposal would include a
change to how nodes propagate new blocks. At the moment, a node that hears
about a second valid block at the tip of the chain will ignore it and not
propagate it to its peers. Wouldn't your proposal necessitate a change to
this logic so that blocks with 'better' endorsements get propagated even if
they are received after non-endorsed or lesser-endorsed blocks?
I'd also be interested to know more how endorsements would be limited
(fairly) to only a subset of nodes.
I'm a bit fuzzy on the endorsement timing. You're saying that a miner will
add endorsement payouts in their block based upon nodes that endorsed the
previous block? Which means they're paying nodes to endorse a block that
they probably didn't even mine? Or would a miner only include payouts to
endorsers for the last block that they mined that was accepted by the
- Jameson

@_date: 2015-07-04 08:19:09
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] List of approved pools 
You can open an issue or submit a pull request on GitHub:
- Jameson
On Sat, Jul 4, 2015 at 7:54 AM, Geir Harald Hansen

@_date: 2015-07-23 11:55:14
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Bitcoin Node Speed Test 
Are you willing to share the code that you used to run the test?
- Jameson
On Thu, Jul 23, 2015 at 10:19 AM, slurms--- via bitcoin-dev <

@_date: 2015-07-23 14:10:22
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Bitcoin Core and hard forks 
On Thu, Jul 23, 2015 at 1:43 PM, Eric Lombrozo via bitcoin-dev <
Increasing block size only temporarily addresses one significant issue -
Larger block sizes don't scale the network, they merely increase how much
load we allow the network to bear. On the flip side, the scalability
proposals will still require larger blocks if we are ever to support
anything close to resembling "mainstream" usage. This is not an either/or
proposition - we clearly need both.
- Jameson

@_date: 2015-07-23 15:52:11
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Bitcoin Core and hard forks 
Running a node certainly has real-world costs that shouldn't be ignored.
There are plenty of advocates who argue that Bitcoin should strive to keep
it feasible for the average user to run their own node (as opposed to
Satoshi's vision of beefy servers in data centers.) My impression is that
even most of these advocates agree that it will be acceptable to eventually
increase block sizes as resources become faster and cheaper because it
won't be 'pricing out' the average user from running their own node. If
this is the case, it seems to me that we have a problem given that there is
no established baseline for the acceptable performance / hardware cost
requirements to run a node. I'd really like to see further clarification
from these advocates around the acceptable cost of running a node and how
we can measure the global reduction in hardware and bandwidth costs in
order to establish a baseline that we can use to justify additional
resource usage by nodes.
- Jameson

@_date: 2015-07-30 12:23:17
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Block size following technological growth 
I find it to be an admirable goal to try to keep node operation costs low
and accessible to the average user. On the other hand, if we are able to
keep the resource requirements of nodes at the level of, say, whatever the
latest Raspberry Pi model on a residential Internet connection can handle,
I'm not sure how helpful it will be if the demand for inclusion in blocks
results in transaction fees prices out more users. Stated differently, if
the cost or contention of using the network rises to the point of excluding
the average user from making transactions, then they probably aren't going
to care that they can run a node at trivial cost.
If we're approaching the block size from a resource usage standpoint, it
seems to me that someone is going to be excluded one way or another. Not
raising the block size will exclude some users from sending transactions
while raising the block size will exclude some users from running nodes.
The latter seems preferable to me because more users will grow the
ecosystem, which should increase the value of the ecosystem, which should
increase the cost that entities are willing to pay to run nodes.
I see two primary points of view / objectives clashing in this debate:
1) Decentralization and stability even if it retards growth of the ecosystem
2) Push the system's load as far as we are comfortable in order to
accommodate the growth it is experiencing
It's clear to me that Core developers have a responsibility to maintain a
stable platform for the ecosystem. I think it's less clear that they have a
responsibility to grow it or ask node operators to expend more resources in
order to support more users. As an operator of several nodes, I can
anecdotally state that I find their resource usage to be trivial and I
welcome more load.
- Jameson
On Thu, Jul 30, 2015 at 11:12 AM, Jorge Tim?n <

@_date: 2015-07-30 12:43:56
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Block size following technological growth 
I fully expect that new layers will someday allow us to facilitate higher
transaction volumes, though I'm concerned about the current state of the
network and the fact that there are no concrete timelines for the rollout
of aforementioned high volume networks.
As for reasoning behind why users will still need to settle on-chain even
with the existence of high volume networks, see these posts:
Point being, the scalability proposals that are currently being developed
are not magic bullets and still require the occasional on-chain settlement.
Larger blocks will be necessary with or without the actual scalability
- Jameson

@_date: 2015-06-01 09:41:50
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
The overlapping consensus mechanisms between the Core Developers, the
miners, the block chain based businesses, and the end users make it such
that the very definition of Bitcoin is not just what any single one of
those groups comes to a consensus about. We must ALL be in consensus about
just what Bitcoin actually is and what its goals should be. As such, the
onus is on the Core Developers to convince the other groups to either
accept or reject major changes to the protocol.
Greg made a great point regarding the difficulty in determining the
definition of Bitcoin:
My point being that Bitcoin is inherently a political phenomenon; we're
just trying to describe the human politics behind Bitcoin with computer
code that is reasonably secure against attack.
- Jameson

@_date: 2015-06-19 14:34:21
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Remove Us Please 
You are free to remove yourself; the URL is at the bottom of every email:
On Fri, Jun 19, 2015 at 12:41 PM, Gigas Gaming Inc. <

@_date: 2015-06-19 16:27:05
@_author: Jameson Lopp 
@_subject: [Bitcoin-development] Remove Us Please 
You're only strengthening Gigas' point about the mailing list by posting
derisive emails. Take your nonconstructive comments elsewhere.
- Jameson
On Fri, Jun 19, 2015 at 4:01 PM, Brian Hoffman

@_date: 2015-06-24 15:36:33
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Announcing Individual User Accounts at statoshi.info 
Hash: SHA1
I'm pleased to announce support for creating individual accounts on  so that devs can create, save, and share their own dashboards. If you want to create an account for yourself, follow these instructions: If you're unfamiliar with Statoshi, check out these two posts:
My goal with Statoshi is to provide insight into the operations of Bitcoin Core nodes. If there are any metrics or instrumentation that you think should be added to Statoshi, please submit an issue or a pull request at

@_date: 2015-06-27 14:02:05
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] A Proposed Compromise to the Block Size Limit 
Why does it matter what the "total work" of the network is? Anyone who is
participating as a node on the network only cares about the resources
required to run their own node, not the resources everyone else needs to
run their nodes.
Also, no assumption needed, it is quite clear that the number of nodes is
not scaling along with the number of users. If anything it appears to be
inversely proportional.

@_date: 2015-06-27 14:22:01
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Upcoming DOS vulnerability announcements for 
According to the release notes, the 0.10.2 release only had notable changes
for Windows. It's not clear that there were any vulnerability patches in 0.10.2 itself
that apply to Ubuntu.
- Jameson

@_date: 2016-01-08 10:35:27
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] SegWit testnet is live 
BitGo also intends to support SegWit transactions as soon as possible.
- Jameson
On Thu, Jan 7, 2016 at 9:17 PM, Matthieu Riou via bitcoin-dev <

@_date: 2016-03-06 15:04:32
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] BIP44 & BIP32 chain address look-ahead limits 
I recently ran into an issue while importing a Mycelium HD wallet where it
was not finding all of my funds - upon further investigation with Mycelium
devs we realized that the wallet was following the BIP44 spec correctly,
but BIP44 may have a flaw.
The problem was a result of my creating 16 transactions in Mycelium in a
fairly short timeframe, but the first 15 transactions ended up never
confirming while the 16th was confirmed. As a result, when I later
reimported the account from the master seed, the chain derivation stopped
upon hitting this large gap of unused addresses on the internal / change
BIP44 recommends that there need not be a lookahead on internal chains
"because internal chains receive only coins that come from the associated
external chains."
BIP32 also notes that "the look-ahead for internal chains can be very
small, as no gaps are to be expected here."
It seems to me that there /is/ an edge case that can result in significant
gaps in internal chain address usage and as such, the recommendation should
be to look ahead on both external and internal chains when performing
account discovery. On a related note, the recommended look-ahead of 20 may
not be safe enough - perhaps it should be raised to 100 if not higher.
In addition to recommending a larger look-ahead, it may also be advisable
for BIP44 to recommend that wallets "fill in" gaps of unused chain
addresses by "looking back" from the current tip of the internal chain's
index when the wallet decides to create a new change address. This could
help mitigate the size of gaps caused by failed transactions.
- Jameson

@_date: 2016-05-17 10:03:22
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Making UTXO Set Growth Irrelevant With 
Great post, Peter.
4) By fixing the problem (or possibly just "fixing" the problem) are
we encouraging/legitimising blockchain use-cases other than BTC value
transfer? Should we?
I don't think it would encourage non-value-transfer usage more
because, as you noted, many such use cases are valuable enough that
people are willing to pay much higher transaction fees in order to
have their data timestamped. I think it's more an issue of the block
space / transaction fee market since the cost of making a transaction
is directly borne by users, as opposed to the cost of the UTXO set
which may not be borne by them if they don't run a full node.
I'm of the opinion that if the world decides that Bitcoin is more
valuable as a trustworthy generalized timestamping mechanism than as a
value transfer system, protocol developers shouldn't try to steer the
ship against the wind. As more people and use cases enter the
ecosystem, the most valuable ones ought to survive - I hope that this
market will be fostered by the developers.
- Jameson
On Tue, May 17, 2016 at 9:23 AM, Peter Todd via bitcoin-dev <

@_date: 2016-11-16 08:29:41
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
Since "buried deployments" are specifically in reference to historical
consensus changes, I think the question is more one of human consensus than
machine consensus. Is there any disagreement amongst Bitcoin users that
BIP34 activated at block 227931, BIP65 activated at block 388381, and BIP66
activated at block 363725? Somehow I doubt it.
It seems to me that this change is merely cementing into place a few
attributes of the blockchain's history that are not in dispute.
- Jameson
On Tue, Nov 15, 2016 at 5:42 PM, Eric Voskuil via bitcoin-dev <

@_date: 2017-12-21 17:02:37
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Total fees have almost crossed the block reward 
I'd hope that the incentives are in place to encourage high volume senders
to be more efficient in their use of block space by batching transactions
and implementing SegWit, though this may not be the case for providers that
pass transaction fees along to their users.
We've been trying to be more proactive about outreach regarding efficient
use of block space to our own customers at BitGo - when we break down the
cost savings of implementing a new technique, it generally helps to hasten
their adoption. I suspect that in many cases this is an issue of education
- we should be more proactive in calling out inefficient uses of block
Good resources to bookmark and share:
- Jameson
On Thu, Dec 21, 2017 at 4:30 PM, Melvin Carvalho via bitcoin-dev <

@_date: 2017-02-26 12:34:57
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Moving towards user activated soft fork activation 
You've made many salient points, Shaolin, though I have a few questions:
1) How well does this model work under adversarial conditions? Fair point
about signaling not being reliable, though it seems more vague in terms of
safety given that you can't actually know what percentage of hashrate that
is /not/ signaling for the soft fork has taken the necessary precautions to
avoid mining an invalid block and potentially causing a hard fork. It's
probably safe to say that if a flag-day soft fork is activated, there will
be at least a few parties who will attempt to trigger a chain fork by
crafting transactions that are valid via non-fork rules but invalid via the
soft fork rules.
2) If the flag day soft fork is activated with only a minority of hashrate
support + safely opted-out hashrate, isn't it possible for the rest of
miners to coordinate orphaning any soft fork compatible blocks to kill the
soft fork chain? This would be a major difference from a miner-activated
soft fork, correct? Unless perhaps many miners colluded to signal soft fork
support while not actually supporting it...
3) In terms of complexity for mining pool operators, how well does this
model scale if there are N soft forks and the pool doesn't want to opt-in
to any of them? Couldn't this result in those pool operators having to run
not just one border node, but a multitude of "chained" border nodes if the
soft forks are spread across different software implementations?
It seems to me that this type of user-driven approach would preferably be
coupled with assurances from major Bitcoin wallets / exchanges / payment
processors that they will not honor coins from a chain fork that results
from invalid spends of outputs encumbered by soft fork rules. Though on the
other hand, I don't see such an assurance being possible given that
exchanges have an incentive to take the first mover advantage in listing a
new coin.
- Jameson
On Sat, Feb 25, 2017 at 6:55 PM, shaolinfry via bitcoin-dev <

@_date: 2017-07-13 12:35:46
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] how to disable segwit in my build? 
On Thu, Jul 13, 2017 at 12:19 PM, Dan Libby via bitcoin-dev <
If you mean you wish to avoid receiving UTXOs that have value that was at
one point previously encumbered by a SegWit output then no, you can't avoid
that. No more than you can currently avoid receiving BTC that were at one
point in time encumbered by a P2SH output.

@_date: 2017-07-21 15:54:26
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] UTXO growth scaling solution proposal 
Sounds like demurrage to me, which has been implemented in other
cryptocurrencies such as Freicoin - While it's an interesting to apply this line of thinking from a scaling
perspective, I suspect most would find it untenable from a monetary policy
You have touched on a scaling issue, the cost of node operation, that I
think is really the root cause of a lot of the debate. Thus even if your
proposal was implemented, we'd still have to solve the problem of finding a
consensus for CONOP.
I think you may have misapplied your logic to the total size of the
blockchain, however. Are you suggesting that pruning of the old UTXOs would
also enable pruning of old blocks from all nodes? Those things aren't
really related, plus someone would still have to keep old blocks around in
order to facilitate new nodes syncing from genesis.
- Jameson
On Fri, Jul 21, 2017 at 3:28 PM, Major Kusanagi via bitcoin-dev <

@_date: 2017-06-14 10:20:32
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Proposal: Demonstration of Phase in Full Network 
To be clear, Bitcoin is not a democracy - if you find yourself using the
term "voting" then you may be misunderstanding how consensus forms. Once a
feature has been vetted and the code is deployed, miners may signal that
they are ready to enforce new rules. If for some reason miners are too
"passive or lazy" or wish to "veto" the activation of the new rules, users
may choose to circumvent said veto by refusing to accept blocks that do not
show readiness for enforcing the new rules.
There is a fundamental misconception regarding this point - the white paper
refers to majority hashpower needing to be honest with regard to
determining the correct chain within the context of many possible /valid/
chain forks. It is not referring to using hashpower to determine the
correct chain amongst an infinitely variable number of currently invalid
chain forks. Bitcoin ecosystem participants should not have faith in miners
(or any other entity) when it comes to choosing the consensus rules they
wish to enforce.

@_date: 2017-06-14 11:55:04
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Proposal: Demonstration of Phase in Full Network 
of communication platforms. Though if you're looking for a way for users to
signal their intentions at the protocol level, every proposal for doing
that to date has been arguably flawed. Measuring meatspace consensus is
pretty tricky if not completely impossible, especially given the fact that
the vast majority of Bitcoin users do not voice any opinions on the matter
of consensus rules.
Most attempts at measuring user consensus would probably be best described
as signaling rather than voting given that the act of doing so has no
actual power to affect consensus. Every user who runs a fully validating
node is free to enforce the rules with which the agree regardless of what
rules other entities are enforcing.
confirming transactions that have a version less than X then it should be a
soft fork, yes.

@_date: 2017-06-14 13:11:07
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Proposal: Demonstration of Phase in Full Network 
network-wide consensus changes. Even if someone spooled up 100 times more
nodes than currently exist and they all "signal" for some consensus rule
change, that doesn't compel the rest of the "genuine" nodes to change the
rules they enforce.
The users always have a choice with regard to what consensus rules to
enforce and what software to run. Everyone is welcome to propose changes
and write software that they make available to users.
should be a non-breaking change.

@_date: 2017-03-27 12:29:05
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Encouraging good miners 
Bitcoin chooses the "best chain" based upon the one that has the most
cumulative proof of work behind it. Are you proposing that the cumulative
proof of work be ignored if two blocks are within a certain threshold of
each others' work and if so, the number of transactions in the block / the
size of the block should be used as a "tie breaker?"
I think this idea needs more fleshing out of exactly how it would work,
with careful consideration that adding complexity to the best chain logic
could introduce exploitable flaws.
On Mon, Mar 27, 2017 at 12:12 PM, Btc Ideas via bitcoin-dev <

@_date: 2018-12-23 16:08:13
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] BIP39 seeds 
I believe it would depend upon the entropy used for the seed, as that would
affect how many bits the checksum represents.
So for a 24 word / 256 bit mnemonic the checksum is 8 bits, thus there are
8 valid checksums and if you picked a random checksum from the wordlist of
2048 words you'd have a 1 in 256 chance of picking a valid one.
On Sun, Dec 23, 2018 at 1:44 PM Aymeric Vitte via bitcoin-dev <

@_date: 2018-02-13 10:24:55
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Possible change to the MIT license 
If I'm understanding the problem being stated correctly:
"Bitcoin is under a branding attack by fork coins."
The proposed solution is to disincentivize fork coins from using the word
Bitcoin by altering the license terms. I'm not a lawyer, but it seems to me
that the words of the license are basically useless unless there is an
entity that intends to make use of court systems to threaten noncompliant
projects into submission.
In my opinion, the perceived attack on Bitcoin here is social /
marketing-based, thus it makes sense that any defense against said attack
should also be social / marketing-based. I don't think that Bitcoin should
be reliant upon courts or governments to defend itself against attacks of
any form.
On Tue, Feb 13, 2018 at 9:25 AM, Natanael via bitcoin-dev <

@_date: 2018-02-13 10:45:55
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Possible change to the MIT license 
Anyone who feels so inclined is free to "pick up the mantle" and defend
Bitcoin against perceived social attacks. I don't think that Bitcoin
protocol developers have any particular responsibility to do so, and as
such this particular discussion is likely going to quickly veer off-topic
for this mailing list.
On Tue, Feb 13, 2018 at 10:37 AM, Brian Lockhart

@_date: 2018-06-28 13:33:58
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Testnet block generation 
This is normal behavior due to a special rule on testnet. For a detailed
explanation you can read
- Jameson
On Thu, Jun 28, 2018 at 9:22 AM Mattia Rossi via bitcoin-dev <

@_date: 2020-05-27 14:52:03
@_author: Jameson Lopp 
@_subject: [bitcoin-dev] Transaction size & weight calculation tooling 
Hi all,
Anyone who has built a Bitcoin wallet / service has to deal with a variety
of challenges when it comes to transaction construction. One of these
challenges is around determining an appropriate fee; aside from block space
market volatility and the inherent problems of forecasting the future, you
need to know how much block space for which your transaction needs to "bid."
Every time I've run into the problem of calculating the size of a
transaction with specific attributes I've ended up having to sift through
answers scatter across stack overflow posts, so I finally got around to
building a user friendly tool at
As I was looking for more data on constants to use in the calculation I was
informed that the folks at Bitcoin Optech have also been working on a
calculator: It seems clear that this is a common problem for which we could use better
tooling. I'm also about 99% certain that there's at least 1 or 2 bugs in my
current calculator code.
Please bookmark and share these tools; if you're capable and so inclined,
code reviews would be greatly appreciated!
- Jameson
