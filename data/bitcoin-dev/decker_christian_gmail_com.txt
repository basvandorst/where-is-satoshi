
@_date: 2011-08-03 16:37:12
@_author: Christian Decker 
@_subject: [Bitcoin-development] DNS seeds returning gone peers 
I'm curious whether my Non-Blocking network stack (BitDroid) isn't better
suited for detecting and tracking available peers. I have implemented
several benchmarks, including a simple peer counter listener, which would
have to be adapted to fit the DNS needs (open and check if a real peer is
listening). Being non-blocking it can open several hundreds of connections
to check reachability of the peers and at the same time keep a pool of peers
connected to listen for address broadcasts, with minimal overhead (single
thread, close to no context switches).
Just an idea :-)
On Wed, Aug 3, 2011 at 4:18 PM, Rick Wesson

@_date: 2011-08-05 14:58:53
@_author: Christian Decker 
@_subject: [Bitcoin-development] Blitcoin? (Black Hat 2011) 
While I do think that anonymity (or pseudonymity) is a nice feature, I don't
think it deserves the full focus of the developers. The core of the protocol
is about making transactions in a secure and fast way, not allowing
everybody to be anonymous, whether they want to or not. TOR already is a
good options for those that want to stay anonymous, and there is no need to
pull support into the main client, if only a few will use it. I think very
few of the developers actually claimed that Bitcoin is anonymous, and has
never been a big advertising point from the "official" side of Bitcoin,
network analysis has been always known to break anonymity.
I see no need for action from the developer side.
On Fri, Aug 5, 2011 at 2:01 PM, Joel Joonatan Kaartinen <

@_date: 2011-08-11 14:01:33
@_author: Christian Decker 
@_subject: [Bitcoin-development] Change to multiple executables? 
On Thu, Aug 11, 2011 at 1:45 PM, Joel Joonatan Kaartinen <
I personally would welcome alternative clients as a vulnerability in the
main client right now has the potential to kill the entire network.
Changes to the protocol are hard, mainly because hashes of packets are used
to identify transactions and blocks, and even the target hash is a hash of a
As for your proposal to eliminate some parts of the protocol, I have to
agree (the magic bytes seem an ugly hack by satoshi as I discussed with
Mike, and the double SHA256 hashes as checksums are incredibly wasteful, and
seem to have been chosen simply because a double hashing was already
Changes should be implemented with backward compatibility in mind, even if
it restricts the freedom of what can be changed.
Having a Wiki or a single Wikipage to list proposed changes, with all pro
and cons, maybe pointing back to the original discussion would be nice. But
don't forget that situations change, and features that have been shot down
way back might become reachable/desirable at a later time, so please don't
just use it as a method to shoot down ideas, but as a way to bring people up
to speed and, if necessary, continue the discussion where it left.
- cdecker

@_date: 2011-08-24 21:05:42
@_author: Christian Decker 
@_subject: [Bitcoin-development] New standard transaction types: time to 
Sorry for keeping this short but I'm in holiday and reading/writing on my
phone is a pain.
It's a great way for companies to secure their assets.
Since. we have the possibility o add other signature schemes to the protocol
we could add an rsa-like scheme which allows m-out-of-n signatures. It works
by distributing shares of the key which are points on a curve having the
actual key as 0-value. It does not require special length for the key so if
ecdsa allows something similar there need not be anything changed.
Would be a first step.
Just wanted to point you in that alternative direction as it would possibly
keep backward compatibility and allow multisignature.

@_date: 2011-08-25 23:30:56
@_author: Christian Decker 
@_subject: [Bitcoin-development] New standard transaction types: time to 
If I remember the details correctly you could combine (lagrange
interpolation) the results of m smaller encryptions/signatures without ever
sharing the secret key share itself. No idea if that is possible with ecdsa
at all, but it sure would solve quite a few problems, as it would allow
several independent servers to share a secret key, sign transactions with
it, but no m-1 compromised machines would endanger the whole balance.
I will definitely look into it when I'm back from holidays.

@_date: 2011-12-13 12:42:17
@_author: Christian Decker 
@_subject: [Bitcoin-development] Fwd: [BIP 15] Aliases 
I think the scope of this BIP is not so well defined right now. We need a
way for merchants to translate a human readable, and more importantly
human-writeable, address into a bitcoin address. I agree with Mike that a
fixed address is not the way to go, because addresses should be used once
for a single transaction to be able to track payments.
While firstbits sounds attractive at first, I think we can all agree that
it just isn't feasible and would not allow per-transaction addresses. DNS
sounds interesting for fixed addresses, but caching and propagation make it
difficult to use for per-transaction addresses that are to be generated
HTTP(S) is the best option I think, merchants are probably using HTTP
anyway for their shops. So something like
 sounds reasonable. But I think it
should not be over-engineered, it should be a simple HTTP(S) request to a
merchant specified URL that returns an ASCII document containing either a
bitcoin: URI or simply the bitcoin address or even a 301 redirect. It's no
use to start defining URL schemes, it should be left to the merchants to
define how to structure them.
This would allow a merchant to decide if he prefers per-transaction
addresses, per-user transactions, fixed addresses or any combination.

@_date: 2011-12-15 12:22:29
@_author: Christian Decker 
@_subject: [Bitcoin-development] Fwd: [BIP 15] Aliases 
Exactly, I think we should starting separating the minimal protocol that is
to be supported by everybody, and the rest can be summed up in a few best
practices, no need to standardize the part that to the user is transparent.
I was on the same lines as Andy, which is that in order to have require a
payment I probably have an order/transaction pending with my vendor or have
an account to be filled, so there's a 1-to-1 mapping between the details
page and the bitcoin address I have to send to.
As a further possibility we could use  tags like the OpenID server
delegation mechanism. It would allow customers to open the transaction
details page, see that everything is ok, then paste the same URL into the
bitcoin client, the bitcoin client retrieves the URL, parses the meta tag
and knows what to send where. Alternatively the Bitcoin Client sends an
Accept header which tells the server to return just the address.
As for the format I'd say either a Bitcoin address or a Bitcoin URI [1]
which ought to be flexible enough as it includes amount and messages, for
the customer to be able to track transactions.
[1]

@_date: 2011-12-17 14:37:21
@_author: Christian Decker 
@_subject: [Bitcoin-development] Protocol extensions 
A while back I had proposed a similar idea to the DHT, although my main
goal was to reduce the need for broadcasts.
My idea was to structure the network in a hypercube and use prefixes to
address different parts of the network, and use those prefixes also to find
the location where an item (transaction, block, ...) should be stored. Each
vertex in the hypercube is a small, highly connected, cluster of nodes. The
storage would be distributed, messages are routed on behalf of others,
which makes finding the origin of the query hard to find (think Tor), each
node would have to store only O(log(p)) items, with p being the prefix
length, maximum number of hops is equal to the dimension of the hypercube
Newly created transaction will be sent directly to the location they'll be
stored and miners retrieve new transactions at regular intervals. It might
increase delays to the confirmations, but it reduces the number of
broadcasts and storage requirements on nodes greatly.

@_date: 2011-12-17 21:34:14
@_author: Christian Decker 
@_subject: [Bitcoin-development] Protocol extensions 
Criticism accepted, although I'd appreciate it if you supply some reasons
about why it's such a bad idea :-)
The idea was never really popular and before starting work on a real
implementation I wanted to test the water, and should it turn out it's
complete non-sense I'm happy to accept that.
I don't want to have a DHT for the DHTs sake, I was more interested in
reducing the number of messages that need to be sent around the network,
since network load is going to be a major problem if we ever grow beyond a
certain point.
Just wanting to brainstorm.

@_date: 2011-12-21 17:10:45
@_author: Christian Decker 
@_subject: [Bitcoin-development] Protocol extensions 
For the future evolution without considering DHTs:
While I think we will sooner or later have supernodes, I don't think they
will need to be trusted too much.
Supernodes will be those nodes that verify all transactions and make them
available to miners. Since miners will become more and more specialized
these supernodes are likely to be owned by the miners themself. To be a
miner either you need to verify all the transactions you include (otherwise
others might be able to find an error in your block and thus drop it) or
have someone that verifies them for you. In the end I think we'll end up
with a hierarchical network, with the miners/supernodes tighly
interconnected at the top and the lightweight clients that simply verify
transactions (or their inputs to be precise) that are destined for them at
the bottom.
As for the DHT we had a few brainstorming sessions a while back on the
forum  (gmaxwell didn't like it then either :D)
Forcing someone to participate in a fixed position in the block storage
network is a good way to reduce the risk of a sybil attack as Michael said.
The hash should include only information that cannot be changed by the
user, so IP can be used, but including the port is risky.
Broadcasting the transactions would not need to be done, since miners fetch
them from their storage place, alternatively we could use the inv broadcast
to notify peers about a new block/transaction and let it retrieve them from
the permanent storage (DHT or block storage network). If we route traffic
internally in the DHT we could even start caching at nodes leading to the
real location, since announcements would lead to flashcrowds, putting heavy
load on the responsible nodes. Caching is not a risk since the hash of the
object to be retrieved is already known.

@_date: 2011-12-22 13:26:07
@_author: Christian Decker 
@_subject: [Bitcoin-development] Protocol extensions 
At first the idea of using negative announces seems attractive, but
remember that a malicious node might trigger verification for every
transaction, which may lead to a DoS.
On Thu, Dec 22, 2011 at 1:14 PM, Joel Joonatan Kaartinen <

@_date: 2011-07-01 18:03:52
@_author: Christian Decker 
@_subject: [Bitcoin-development] Useful bitcoin patches... 
Some appear to be beneficial to everybody.
Multithreading the RPC will certainly speed up quite a few services and I
see no downside in adding it. The same is true for Keep-Alive.
I'm against including the long polling support because incredibly few people
will benefit from it (pool providers) and yet it is included for everyone.
The Hub mode is good, and I would go a step further and optimize the
connection logic for all nodes by default.
Just IMHO

@_date: 2011-06-13 10:55:04
@_author: Christian Decker 
@_subject: [Bitcoin-development] Bootstrapping via BitTorrent trackers 
Hi all.
Just wanted to carry the discussion from the Forum over to the dev-list.
We have quite a few bootstrapping mechanisms, starting with the overly
complex (IMHO) IRC bootstrapping, which is often suspected as bot-activity.
Then we have a few hardcoded nodes and some fallback nodes. I was wondering
why we didn't adopt BitTorrent tracker bootstrapping until now? It's
basically all it does. Given a hash (SHA1 hash of the genesis bloc would be
nice ^^) it gives you a list of other nodes with the same hash.
Given that there are quite a few open trackers (accepting and tracking any
hash you throw at them) we could just decide to use 2-3 of those to
The downside would be that they return bencoded data, which has to be
interpreted first, but it's easier than implementing the IRC stuff, I think.
Any comments?

@_date: 2011-06-13 11:38:13
@_author: Christian Decker 
@_subject: [Bitcoin-development] Bootstrapping via BitTorrent trackers 
Don't get me wrong, DNS Seeding is an excellent way to bootstrap via trusted
nodes, I'm not trying to replace it.
What I'm trying to get rid of is the IRC bootstrapping and the hardcoded
nodes in the client, they're easy targets.
BitTorrent trackers are used to handle several thousands of requests, so
they would probably scale well enough. I'm not even talking about using the
DHT trackers, but using old fashioned HTTP based trackers. The fact that
each bitcoin client would contact the tracker would make it very hard for an
attacker to get bootstrapping clients to exclusively connect to his
compromised clients. I would say that using a tracker such as OpenBittorrent
provides the same advantages as using an IRC channel.

@_date: 2011-06-13 13:48:38
@_author: Christian Decker 
@_subject: [Bitcoin-development] Bootstrapping via BitTorrent trackers 
Yes, those trackers would be hard coded, just like the IRC servers and
channels are hardcoded right now.
The advantages over IRC and DNS Seeds are:
 - sporadic HTTP requests to a tracker, as opposed to keeping an IRC
connection open at all times
 - no virus/botnet like behaviour (automatically join IRC channel with
cryptic name), ISPs tend to bother network admins (like myself) with alerts
when they see this...
 - adapts faster than DNS Seeds which require configuration changes on seed
should the nodes become unreachable
 - we already use HTTP to determine our external IP, so it would be a
consolidation of transports
 - more peers than DNS Seeds (better load balancing)
As for Vladimirs proposal, seems like an extreme measure, that is not really
practical. Also it leads to network partitions since nodes will prefer their
own /8 and /16 networks. IPv6 will also soon be a problem for this method.
On Mon, Jun 13, 2011 at 12:54 PM, Vladimir Marchenko <

@_date: 2011-06-15 14:46:24
@_author: Christian Decker 
@_subject: [Bitcoin-development] Protocol versioning 
Looking back I have to agree that binding the protocol to the client version
was in fact good, since it allowed for a fast evolution along with the then
only client. My proposal to split the both may have come too early, but I
personally grew frustrated when implementing my own networking stack. With
the protocol having matured, and changes becoming ever less frequent, I'd be
happy for the split to happen.
I called it Mainline client (like the original Bittorrent client) as a hint
that this is the reference implementation everybody should refer to, but
Satoshi Client has a nice sound too :-)
The version number being incremented each time a breaking change to the
protocol has been made? Mike and I discussed that quite a while back, and
using the String as client specific identifier with a version number (mainly
for statistical purposes) sounds like a good idea, similar to User Agent
strings in HTTP.
Yeah, sorry for that one :-)
I posted the request to the issue tracker before that pull, and I was asked
to submit a pull request with the needed changes, which sounded a bit
strange for a conceptual change like this one. Isn't a gradual switch
possible? I'd leave the version number as is and simply don't increment it,
so if the code does not rely on specific values for pszSubVer it shouldn't
break at all.
So we could consider version 40000 the first "stable" protocol release?
Sounds good.
Always happy to hear you like my idea :D
All in all I'm really looking forward to this.

@_date: 2011-11-02 22:32:10
@_author: Christian Decker 
@_subject: [Bitcoin-development] Lock protocol version numbers 
I don't really get what you want to achieve with this. The protocol will be
slow down evolution (hopefully) soon, while the clients will continue
releasing at a similar rhythm. It took long enough to decouple the protocol
version from being bumped each client release, now doing the inverse
coupling makes no sense.

@_date: 2011-11-02 23:42:31
@_author: Christian Decker 
@_subject: [Bitcoin-development] Lock protocol version numbers 
Just for reference: The issue resulted in my most useless pull request fixing two variables :-)
I second the use of sub_version_num as a Client and Version identifier.

@_date: 2011-11-03 00:22:38
@_author: Christian Decker 
@_subject: [Bitcoin-development] Lock protocol version numbers 
The mainline client (independently from the GUI) has been referenced to as
"Satoshi" client. I personally like the name as a homage, but I guess it
all comes down to the decision of the maintainers.

@_date: 2011-11-05 15:45:54
@_author: Christian Decker 
@_subject: [Bitcoin-development] Lock protocol version numbers 
On BitDroid I stopped updating the protocol version at 31700 and set the
string to be both Version and Client, just like BitcoinJ :-)

@_date: 2011-11-05 17:17:58
@_author: Christian Decker 
@_subject: [Bitcoin-development] Lock protocol version numbers 
Sorry for shooting this approach down, but I'm against it. User-agent
strings are an extremely bad idea as it would lead developers to start
making communication choices depending on the client type. User-Agents in
HTTP are only useful if the clients (browsers) do not adhere to a well
defined behavior. I see the version string more as a kind of vanity point
(xyz peers are using my network code) and it would be bad to base choices
on it.
For protocol choices we already have a good mechanism in place (nServices)
to negotiate capabilities.
I for one vote for keeping it as simple as possible, just a simple string,
without any further meaning.

@_date: 2011-11-14 13:09:23
@_author: Christian Decker 
@_subject: [Bitcoin-development] [RFC] BIP 14 - Protocol Version and User 
Same here of course, but I'll keep the String short and fixed. I still
don't think there should be any reason for others to know my OS in order to
communicate with me :-)

@_date: 2011-11-23 13:10:55
@_author: Christian Decker 
@_subject: [Bitcoin-development] Addressing rapid changes in mining power 
First of all I do agree that a method for adjusting the difficulty in a
huge power drop is needed (I don't see it so much in power rises).
The current block generation with a fixed difficulty was chosen because it
it clear when to adjust and to what target difficulty it has to be
adjusted. If we were to use synchronized time windows and select the
hardest block it gets incredibly complicated as synchronization is not
possible in distributed systems. Even the smallest drift would allow for
forks in the chain all over the place. Furthermore the delay in propagation
will also cause forks.
If 1/2 of the network see one block as the hardest, and for the rest of the
network it came too late then we'll have a fork that stays with us quite a
The block chain is described as a timestamp server in the paper, but it is
more of a proof-of-existence before, as the contained timestamp cannot be
trusted anyway.
2011/11/23 Jorge Tim?n

@_date: 2011-11-23 15:38:55
@_author: Christian Decker 
@_subject: [Bitcoin-development] Addressing rapid changes in mining power 
Just brainstorming here, no idea if this would work:
   - Pick any old block
   - Create a chain fork by creating simpler blocks on top of your chosen
   one
   - The chain will not be accepted by others
   - At some point you might find an incredibly hard block that makes your
   forked chain the hardest one in the network
   - Suddenly all your blocks are valid and you force people to switch to
   your forked chain
If this is possible it would allow you to revoke all transactions and claim
all the mined coins since you forked. My point is that the notion of
hardest chain is not so simple.
The difficulty of invalidating a chain is dramatically reduced with your
time window approach, by not requiring a given difficulty, and relying on
synchronized time windows.

@_date: 2011-10-08 23:25:17
@_author: Christian Decker 
@_subject: [Bitcoin-development] Help wanted: translations 
Damn, german is already contributed :-)
Well I can still do the italian one and check german then.

@_date: 2011-10-20 13:27:08
@_author: Christian Decker 
@_subject: [Bitcoin-development] BIP process 
Does it have to be wiki pages if we're going through an editorial process
anyway, and there will be few who can actually edit the pages directly? I'd
go for simple HTML documents in a repository.
Definitely. I don't think too many requests will come right away, and by
posting them here we make sure that the most knowledgeable people are there
to check and improve what might eventually end up in the clients.

@_date: 2011-10-24 13:24:53
@_author: Christian Decker 
@_subject: [Bitcoin-development] Help wanted: translations 
Actually no, the same string may have to be translated in different ways
depending on the context they appear in. That sometimes happens for italian,
and I'm sure it happens in other cases too. Not sure whether this is the
cause for duplicate strings for now, but it might.
On Sat, Oct 22, 2011 at 6:14 PM, Geir Harald Hansen

@_date: 2011-09-06 10:36:19
@_author: Christian Decker 
@_subject: [Bitcoin-development] Building a node crawler to map network 
Hi Steve,
before attempting to hack BitcoinJ to use NIO you might want to take a look
at BitDroid ( which is my
attempt to build an easily extensible network client (no crypto stuff so
far) on top of NIO and a simple publish-subscribe architecture. I build a
crawler like yours with just a single class that subscribes to events
published and closes and opens connections to crawl.

@_date: 2011-09-09 11:15:38
@_author: Christian Decker 
@_subject: [Bitcoin-development] Alert System 
Resending to mailing list as I replied directly...
On Thu, Sep 8, 2011 at 11:03 PM, Christian Decker <

@_date: 2011-09-14 18:06:08
@_author: Christian Decker 
@_subject: [Bitcoin-development] Difficulty adjustment / time issues 
Am I the only one to think putting pools at a disadvantage is actually
Back when pools started to appear we all had huge reservations about putting
so much control into the hands of a few pool operators, but nowadays it
seems that having pool operators control a vast majority of the
computational power is desired.
I do like pools (I use them myself), but we should put the security of the
protocol in first place and then only think about individual players.
Always remember that the problems pool operators encounter are likely also
the ones of a potential attacker that tries to accumulate 50%+ of the
network power :-)

@_date: 2011-09-15 12:43:20
@_author: Christian Decker 
@_subject: [Bitcoin-development] Request review: drop misbehaving peers 
I'd be happy with a sort of BitTorrent like snubbing, and dropping in
extreme cases.
Sharing blacklist decisions would be dangerous. We could even extend the
protocol to include some sort of choking/unchoking in order to warn peers
that we might drop him if he continues to misbehave.
In general I think that we have to be careful in what we consider
misbehaving, it should be really conservative to begin with, and extend the
rules over time. Making them too restrictive might make future development
difficult, not to speak of alternative clients.

@_date: 2012-01-02 14:31:19
@_author: Christian Decker 
@_subject: [Bitcoin-development] does "stubbing" off Merkle trees reduce 
It can speed up the initial chain download. A newly created wallet will
have only new key-pairs, hence no incoming transactions (unless we have a
key collision, which is unlikely). So there is no need for a bootstrapping
node to download the chain with transactions. The chain itself can be
verified without the transactions. Later full blocks would be required to
detect usable inputs for future outgoing transactions. As long as you
verify the very last blocks in the chain you can be sure that all
preceeding blocks were also valid.

@_date: 2012-05-25 09:47:23
@_author: Christian Decker 
@_subject: [Bitcoin-development] Punishing empty blocks? 
How about a simple proof of work test? This one though does not ask for CPU
work but asks the miner for a random old transaction. If the miner really
stores the entire blockchain he will not have any problem answering to that
getdata request, whereas a botnet would have to ask someone else for it,
which could be detected if the response time deviates too much from what
has been previously measured (compare it against getdata for the block they
advertise). It's not perfect but it allows an estimate of whether it is a
chainless miner.
Christian Decker

@_date: 2012-10-15 00:09:48
@_author: Christian Decker 
@_subject: [Bitcoin-development] Hosting of compiled bitcoin client 
Being an international team I'm pretty sure we can find someone who is in a
more permissive country.
Would someone knowledgeable point us to the specific laws, so that we can
look it up in our respective jurisdiction?

@_date: 2013-03-12 20:53:55
@_author: Christian Decker 
@_subject: [Bitcoin-development] Some PR preparation 
Just a quick and dirty check if something bad actually happened. 430
transactions that were confirmed in the alt-chain, are not confirmed
in the true blockchain. The good news is that as far as I can tell
most of them are low volume transactions destined for SD.
7 transactions were true double spends, or to be more precise
transactions in which an conflicting transaction was confirmed in the
new chain (with their respective amount):
12814b8ad57ce5654ba69eb26a52ddae1bff42093ca20cef3ad96fe7fd85d195 261 BTC
cb36ba33b3ecd4d3177d786209670c9e6cdf95eb62be54986f0b49ca292714af 0.06 BTC
7192807f952b252081d0db0aa7575c4695b945820adaf7776b7189e6b3d86f96 0.01 BTC
355d4ea51c3b780cf0b10e8099a06a31484e0060bc140b63f3d6e5fb713ace5e 0.05 BTC
b961bc0c663a46893afd3166a604e7e2639533522d9fec61fdb95eb665e86f5a 0.61 BTC
138063e4bdb76feaa511f1e7f9c681eb468ef9140c141671741c965e503b84c6 1.62 BTC
a10bd194cdbf9aa4c12eb0b120056998a081a9b0d93d70570edff24dec831f90 0.81
So the one transaction that really hurt was the one published on
BitcoinTalk. We're not yet out of the woods as some of the 423
transactions still have a chance of being doublespent, but looks like
it's not that bad after all.
P.S.: For a complete list of transactions see Christian Decker

@_date: 2013-11-24 17:20:22
@_author: Christian Decker 
@_subject: [Bitcoin-development] Network propagation speeds 
Since this came up again during the discussion of the Cornell paper I
thought I'd dig up my measurement code from the Information
Propagation paper and automate it as much as possible.
The result is the Network Propagation page on bitcoinstats.com
( It takes a daily
snapshot of the situation, then calculates the time until blocks and
transactions reach a certain percentile of the nodes in the network.
There is also a detailed page showing the density function describing
at what times nodes learn about the existence of a block/transaction
(for example yesterdays distribution:
I intend to add more information and plots over time, but I wanted to
push this out quickly as there were some people asking for it. Hope
this helps getting the blockchain fork rate down :-)
Christian Decker

@_date: 2013-11-24 17:37:25
@_author: Christian Decker 
@_subject: [Bitcoin-development] Network propagation speeds 
Sure thing, I'm looking for a good way to publish these measurements,
but I haven't found a good option yet. They are rather large in size,
so I'd rather not serve them along with the website as it hasn't got
the capacity. Any suggestions? If the demand is not huge I could
provide them on a per user basis.
Christian Decker

@_date: 2013-11-25 20:27:09
@_author: Christian Decker 
@_subject: [Bitcoin-development] Network propagation speeds 
Thanks Mike for the Tip :-)
I will definitely extend the calculations to include a size-normalized
version. As for transaction propagations, being much smaller the
measurements tend to be much noisier, but given enough samples we
might be able to reconstruct some of the system parameters.
Good idea to attempt to correlate propagation speed and number of
inputs/outputs, might be interesting to see whether processing at the
nodes has an influence.
Christian Decker

@_date: 2013-11-27 21:46:50
@_author: Christian Decker 
@_subject: [Bitcoin-development] Network propagation speeds 
============================== START ==============================
Damn, that happens if I do the overview as an afterthought. Fixed :-)
Real time (last 24 hours, last week, last month) are in the pipeline,
just need to find the time to implement access to the collector from
the webpage.
Christian Decker

@_date: 2013-10-24 13:11:05
@_author: Christian Decker 
@_subject: [Bitcoin-development] Revisiting the BIPS process, a proposal 
I'd like to add some historical background about how the "protocol
specification" came to be in the first place.
A bit over three years [1] ago I started an attempt to document the
network protocol, by reverse engineering it from the satoshi
client. My goal, back then, was to enable like-minded engineers to
create alternative clients and move away from the client-monoculture
that is still predominant today. It was clear from the beginning that
it would merely be a reverse engineering effort, and that it would
likely lag a bit behind the changes in the main client. It was meant
as a help for engineers that are not well versed in C/C++ to enable
them to contribute by creating new clients, but the satoshi client
would always be the de-facto standard.
With the move from Google Code to the Bitcoin.it wiki somehow this
notion of it being a reverse engineering effort was lost and people
started assuming that if the behavior of the satoshi client did not
match the protocol description it was a bug on the client
side. Instead it is because the reverse engineering of the protocol is
incorrect or simply missing some details. Although the protocol
description is far more complete than it was back when we started, I
still don't feel comfortable giving it the name specification.
I still believe that a client monoculture is bad for the system as a
whole, because a single bug might bring down the whole network. Giving
people the necessary tools to implement new clients brings
stability. I do understand the criticism that writing a specification
might hinder future development as it restricts the possible changes
to the protocol, but isn't this already the case as long as we have
legacy versions of the client participating in the network? I would
also argue that having a specification allows an application
independent review of the protocol to identify possible improvements
and bugs.
I think the protocol description has an important place in the
development of Bitcoin, so much so that we pushed a long time ago to
separate protocol version from the client version. I would love to see
the protocol specification becoming official part of the bitcoin
github repository, which would ideally be maintained alongside the
satoshi client to keep it up to date.
Christian Decker
[1] Christian Decker

@_date: 2014-08-06 16:17:02
@_author: Christian Decker 
@_subject: [Bitcoin-development] deterministic transaction expiration 
+1 for the new field, overloading fields with new meaning is definitely not
a good idea.
Something like nExpireAt with a block height sounds reasonable to me, but
we need to document that the usual caveats with blockchain reorgs apply.

@_date: 2014-08-08 11:41:38
@_author: Christian Decker 
@_subject: [Bitcoin-development] NODE_EXT_SERVICES and advertising related 
I wonder whether we actually want to support this kind of advertisement in
the P2P protocol. We have a working mechanism for protocol extensions in
the P2P network (service flags) so this is obviously only for services that
are not P2P extensions, so why have them in there at all?
I'd argue that a parallel network, external to Bitcoin, could take over the
task of advertising external services.
Christian Decker

@_date: 2014-12-20 19:27:53
@_author: Christian Decker 
@_subject: [Bitcoin-development] Area of Focus 
Thanks for bringing this to my attention.
I added a safety check to my crawler and seed.bitcoinstats.com should
not return IPs that also run HTTP or HTTPS, hopefully this'll keep it
off blacklists :-)
Christian Decker

@_date: 2014-07-21 14:53:51
@_author: Christian Decker 
@_subject: [Bitcoin-development] Policy for DNS seeds 
How about research projects into node distribution? Specifically I
wonder whether the collection and analysis of DNS query origin is
allowed when queries are anonymized and aggregated. This would prevent
the identification of a single user, which I assume is the rationale
for point 4.
Other than that I'm perfectly fine with accepting the rules for
Christian Decker

@_date: 2014-03-02 22:11:01
@_author: Christian Decker 
@_subject: [Bitcoin-development] 0.9.0 release candidate two 
The domain bitcoin.org resolves to that IP address. Could it be some
update check together with a circular redirect? That could at least
explain the large number of connection attempts.
Christian Decker

@_date: 2015-08-21 13:24:28
@_author: Christian Decker 
@_subject: [bitcoin-dev] RE : Visualizations of Votes 
I hacked together a simple tracking page for the 'block votes', it
currently includes the 8MB vote and XT, as well as the /BV\d+/ vote for
generic size:
On Fri, Aug 21, 2015 at 7:25 AM odinn via bitcoin-dev <

@_date: 2015-08-25 08:46:57
@_author: Christian Decker 
@_subject: [bitcoin-dev] RE : Visualizations of Votes 
Yes, the two dimensions are orthogonal: BIP 100 support and actual size
voting. However there seem to be a few pools which simply vote to support
BIP100, without specifying a desired block size [1], hence I started
tracking both on the same chart, maybe I'll split them into different
charts to clarify.

@_date: 2015-05-11 12:34:43
@_author: Christian Decker 
@_subject: [Bitcoin-development] Reducing the block rate instead of 
The propagation speed gain from having smaller blocks is linear in the size
reduction, down to a small size, after which the delay of the first byte
prevails [1], however the blockchain fork rate increases superlinearly,
giving an overall worse tradeoff. A high blockchain fork rate is a symptom
of inefficient use of the network's mining resources and may give an
advantage to an attacker that is more efficient in communicating internally.
I'd strongly against increasing the block generation rate in Bitcoin, it'd
be a very controversial proposal and would not solve anything.

@_date: 2015-05-13 12:48:04
@_author: Christian Decker 
@_subject: [Bitcoin-development] [BIP] Normalized Transaction IDs 
Hi All,
I'd like to propose a BIP to normalize transaction IDs in order to address
transaction malleability and facilitate higher level protocols.
The normalized transaction ID is an alias used in parallel to the current
(legacy) transaction IDs to address outputs in transactions. It is
calculated by removing (zeroing) the scriptSig before computing the hash,
which ensures that only data whose integrity is also guaranteed by the
signatures influences the hash. Thus if anything causes the normalized ID
to change it automatically invalidates the signature. When validating a
client supporting this BIP would use both the normalized tx ID as well as
the legacy tx ID when validating transactions.
The detailed writeup can be found here:
 I'd like to request a BIP number, unless there is something
really wrong with the proposal.
In addition to being a simple alternative that solves transaction
malleability it also hugely simplifies higher level protocols. We can now
use template transactions upon which sequences of transactions can be built
before signing them.
I hesitated quite a while to propose it since it does require a hardfork
(old clients would not find the prevTx identified by the normalized
transaction ID and deem the spending transaction invalid), but it seems
that hardforks are no longer the dreaded boogeyman nobody talks about.
I left out the details of how the hardfork is to be done, as it does not
really matter and we may have a good mechanism to apply a bunch of
hardforks concurrently in the future.
I'm sure it'll take time to implement and upgrade, but I think it would be
a nice addition to the functionality and would solve a long standing
problem :-)
Please let me know what you think, the proposal is definitely not set in
stone at this point and I'm sure we can improve it further.

@_date: 2015-05-13 15:24:34
@_author: Christian Decker 
@_subject: [Bitcoin-development] [BIP] Normalized Transaction IDs 
Glad you like it, I was afraid that I missed something obvious :-)
The points the two of you raised are valid and I will address them as soon
as possible. I certainly will implement this proposal so that it becomes
more concrete, but my C++ is a bit rusty and it'll take some time, so I
wanted to gauge interest first.
minimum, there needs to be a legacy txid to normalized txid map in the
could require a SPV proof of the spending transaction to be included with
legacy transactions.  This would allow clients to verify that the
normalized txid matched the legacy id.
which use a normalized txid don't need the SPV proof.
It does and I should have mentioned it in the draft, according to my
calculations a mapping legacy ID -> normalized ID is about 256 MB in size,
or at least it was at height 330'000, things might have changed a bit and
I'll recompute that. I omitted the deprecation of legacy IDs on purpose
since we don't know whether we will migrate completely or leave keep both
options viable.
which opcodes does this affect, and how, exactly, does it affect them? Is
the merkle root in the block header computed using normalized transaction
ids or normalized ids?
I think both IDs can be used in the merkle tree, since we lookup an ID in
both indices we can use both to address them and we will find them either
As for the opcodes I'll have to check, but I currently don't see how they
could be affected. The OP_*SIG* codes calculate their own (more
complicated) stripped transaction before hashing and checking the
signature. The input of the stripped transaction simply contains whatever
hash was used to reference the output, so we do not replace IDs during the
operation. The stripped format used by OP_*SIG* operations does not have to
adhere to the hashes used to reference a transaction in the input.
proposal before getting a BIP number. At least, I find that actually
writing the code often turns up issues I hadn't considered when thinking
about the problem at a high level. And I STRONGLY believe BIPs should be
descriptive ("here is how this thing works") not proscriptive ("here's how
I think we should all do it").
We can certainly split the proposal should it get too large, for now it
seems manageable, since opcodes are not affected. Bloom-filtering is
resolved by adding the normalized transaction IDs and checking for both IDs
in the filter. Since you mention bundling the change with other changes
that require a hard-fork it might be a good idea to build a separate
proposal for a generic hard-fork rollout mechanism.
If there are no obvious roadblocks and the change seems generally a good
thing I will implement it in Bitcoin Core :-)
On Wed, May 13, 2015 at 3:44 PM Gavin Andresen

@_date: 2015-05-13 18:04:54
@_author: Christian Decker 
@_subject: [Bitcoin-development] [BIP] Normalized Transaction IDs 
If the inputs to my transaction have been long confirmed I can be
reasonably safe in assuming that the transaction hash does not change
anymore. It's true that I have to be careful not to build on top of
transactions that use legacy references to transactions that are
unconfirmed or have few confirmations, however that does not invalidate the
utility of the normalized transaction IDs.
The resource doubling is not optimal, I agree, but compare that to dragging
around malleability and subsequent hacks to sort-of fix it forever.
Additionally if we were to decide to abandon legacy transaction IDs we
could eventually drop the legacy index after a sufficient transition period.
I remember reading about the SIGHASH proposal somewhere. It feels really
hackish to me: It is a substantial change to the way signatures are
verified, I cannot really see how this is a softfork if clients that did
not update are unable to verify transactions using that SIGHASH Flag and it
is adding more data (the normalized hash) to the script, which has to be
stored as part of the transaction. It may be true that a node observing
changes in the input transactions of a transaction using this flag could
fix the problem, however it requires the node's intervention.
Compare that to the simple and clean solution in the proposal, which does
not add extra data to be stored, keeps the OP_*SIG* semantics as they are
and where once you sign a transaction it does not have to be monitored or
changed in order to be valid.
There certainly are merits using the SIGHASH approach in the short term (it
does not require a hard fork), however I think the normalized transaction
ID is a cleaner and simpler long-term solution, even though it requires a
On Wed, May 13, 2015 at 7:14 PM Pieter Wuille

@_date: 2015-05-13 19:14:57
@_author: Christian Decker 
@_subject: [Bitcoin-development] [BIP] Normalized Transaction IDs 
If we are building a long running contract using a complex chain of
transactions, or multiple transactions that depend on each other, there is
no point in ever using any malleable legacy transaction IDs and I would
simply stop cooperating if you tried. I don't think your argument applies.
If we build our contract using only normalized transaction IDs there is no
way of suffering any losses due to malleability.
The reason I mentioned the confirmation is that all protocols I can think
of start by collaboratively creating a transaction that locks in funds into
a multisig output, that is committed to the blockchain. Starting from this
initial setup transaction would be using normalized transaction IDs,
therefore not be susceptible to malleability.
In that case I don't think I heard this proposal before, and I might be
missing out :-)
So if transaction B spends an output from A, then the input from B contains
the CHECKSIG operator telling the validating client to do what exactly? It
appears that it wants us to go and fetch A, normalize it, put the
normalized hash in the txIn of B and then continue the validation? Wouldn't
that also need a mapping from the normalized transaction ID to the legacy
transaction ID that was confirmed?
A client that did not update still would have no clue on how to handle
these transactions, since it simply does not understand the CHECKSIG
operator. If such a transaction ends up in a block I cannot even catch up
with the network since the transaction does not validate for me.
Could you provide an example of how this works?
As I mentioned before, this is a really long term strategy, hoping to get
the cleanest and easiest solution, so that we do not further complicate the
inner workings of Bitcoin. I don't think that it is completely out of
question to eventually upgrade to use normalized transactions, after all
the average lifespan of hardware is a few years tops.
How could I change the transaction IDs if I am a relayer? The miner decides
which flavor of IDs it is adding into its merkle tree, the block hash locks
in the choice. If we saw a transaction having a valid sigScript, it does
not matter how we reference it in the block.
Yes, hard forks are hard, I'm under no illusion that pushing such a change
through takes time, but in the end the advantages will prevail.
I didn't want to put it in the initial proposal, but we could also increase
the transaction version which signals to the client that the transaction
may only be referenced by the normalized transaction ID. So every
transaction would be either in one index or the other, reducing the
deployment cost to almost nothing.

@_date: 2015-05-14 11:01:56
@_author: Christian Decker 
@_subject: [Bitcoin-development] [BIP] Normalized Transaction IDs 
Ok, I think I got the OP_CHECKAWESOMESIG proposal, transactions keep
referencing using hashes of complete transactions (including signatures),
while the OP_CHECKAWESOMESIG looks up the previous transaction (which we
already need to do anyway in order to insert the prevOut pubkeyScript),
normalizes the prevout and calculates its normalized transaction ID. It
then inserts the normalized transaction IDs in the OutPoint before
calculating its own hash which is then signed. Is that correct so far?
Let me try to summarize the discussion so far:
I think we have consensus that transaction malleability needs to be
addressed, and normalized transaction IDs seem to be the way to go forward.
The discussion now is how to use normalized transaction IDs and we have two
approaches to implement them:
   - OP_CHECKAWESOMESIG which continues to use the current hashes to
   reference a specific signed instance of a class of semantically identical
   transactions. Internally only the semantic class is enforced. Transactions
   can be fixed to reference the correct signed instance if the transaction
   has been changed along the way.is a softfork using the "if I don't know
   this opcode the TX is automatically valid" trick
On Thu, May 14, 2015 at 2:40 AM Pieter Wuille

@_date: 2015-05-14 11:26:44
@_author: Christian Decker 
@_subject: [Bitcoin-development] [BIP] Normalized Transaction IDs 
Sorry about that, sometimes I hate keyboard shortcuts :-)
Ok, I think I got the OP_CHECKAWESOMESIG proposal, transactions keep
referencing using hashes of complete transactions (including signatures),
while the OP_CHECKAWESOMESIG looks up the previous transaction (which we
already need to do anyway in order to insert the prevOut pubkeyScript),
normalizes the prevout and calculates its normalized transaction ID. It
then inserts the normalized transaction IDs in the OutPoint before
calculating its own hash which is then signed. Is that correct so far?
Let me try to summarize the discussion so far:
I think we have consensus that transaction malleability needs to be
addressed, and normalized transaction IDs seem to be the way to go forward.
The discussion now is how to use normalized transaction IDs and we have two
approaches to implement them:
   - OP_CHECKAWESOMESIG which continues to use the current hashes to
   reference a specific signed instance of a class of semantically identical
   transactions. Internally only the semantic class is enforced. Transactions
   can be fixed to reference the correct signed instance if the transaction
   has been changed along the way.
   - The second proposal advocates using the normalized transaction IDs
   directly in the transactions, requiring no further intervention to fix an
   eventually malleated transaction.
Both approaches have their own advantages and problems:
OP_CHECKAWESOMESIG is a soft-fork which makes it somewhat less problematic
to roll-out and does not break existing software. The normalized
transaction ID can be computed on the fly (possibly increasing lookup
times) or stored alongside the UTXO (increasing storage needs). If the
normalized transaction IDs really need to be recomputed down to the
coinbase then the increased storage is the only option, and would add 32
byte to every transaction metadata in the UTXO.
My proposal is harder to migrate to, as it requires a hardfork, and will
require more storage (64 byte raw data for a normalized to legacy
transaction ID) for every transaction in the UTXO set. At 6 million
distinct transactions which unspent outputs this boils down to 384 MB
(though this may change in future by introducing an aggregation strategy or
fragment further). Some of that space may be reclaimed. There is absolutely
no interaction required to fix up transactions if a dependency has been
malleated, since we address a semantic class, not the specific instance. We
limit the use of normalized transaction IDs to the OutPoint in
transactions, since there we want to reference the semantic class not the
actual signed instance. At protocol message level (inv, getdata) and blocks
we continue to use the legacy ID. This is not as nice as having one ID for
every transaction that is used everywhere.
Both solutions solve malleability, just with different tradeoffs.
I don't see them as mutually exclusive, if we adopt the OP_CHECKAWESOMESIG
as short term fix, that can be rolled out and applied, then my proposal can
be seen as long-term goal that is semantically cleaner and easier to
Personally I think hard-forks shouldn't be the dreaded boogeyman everybody
makes them out to be, we have never really tested rolling out a hardfork
and they might just turn out to be possible. I don't thing we loose
anything by attempting this, except maybe reduce the urgency to apply some
perfect future thing.
On Thu, May 14, 2015 at 1:01 PM, Christian Decker <

@_date: 2015-05-19 08:28:58
@_author: Christian Decker 
@_subject: [Bitcoin-development] [BIP] Normalized Transaction IDs 
Thanks Stephen, I hadn't thought about BIP 34 and we need to address this
in both proposals. If we can avoid it I'd like not to have one transaction
hashed one way and other transactions in another way.
Since BIP 34 explicitly uses the scriptSig to make the coinbase transaction
unique, simply removing the scriptSig is not an option as it would
potentially cause collisions. I don't remember why the scriptSig was
chosen, but we also have the option of putting the blockchain height in the
sequence number of the coinbase input or the locktime of the transaction,
restoring the uniqueness constraint in normalized transaction IDs (for both
proposals). Is there a specific reason why that was not chosen at the time?

@_date: 2015-05-19 10:43:39
@_author: Christian Decker 
@_subject: [Bitcoin-development] [BIP] Normalized Transaction IDs 
Well in the case of coinbase transactions we want them to be dependent on
the height they are included in, which is not a problem since they are only
valid in conjunction with the block that mined them.
No need to add an extra field to the transaction just to include the
height. We can just add a rule that the height specified in the scriptSig
in coinbase transactions (and only coinbase transactions) is copied into
the locktime of the transaction before computing the normalized transaction
ID and leave the locktime untouched for all normal transactions
Sounds reasonable :-)

@_date: 2015-05-28 07:51:39
@_author: Christian Decker 
@_subject: [Bitcoin-development] Version bits proposal 
Agreed, there is no need to misuse the version field as well. There is more
than enough variability you could roll in the merkle tree including and
excluding transactions, and the scriptSig of the coinbase transaction,
which also influences the merkle root.
I have a fundamental dislike of retroactively changing semantics, and the
version field should be used just for that: a version. I don't even
particularly like flagging support for a fork in the version field, but
since I have no better solution, count me as supporting Sipa's proposal. We
definitely need a more comfortable way of rolling out new features.
On Thu, May 28, 2015 at 3:08 AM Patrick Strateman <

@_date: 2015-11-03 20:37:44
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
Ok, getting the ball rolling again after some downtime. I amended the
proposal to use a simple version number instead of the binary flags, added
the normalization of inputs before computing the signaturehash and added
Schnorr signatures as requested.
The BIP has also been assigned number 130 :-)
I am still very much intrigued by Luke's idea of having empty scriptsigs
and ship the signatures in external scripts, however the proposal uses the
on-the-fly normalization because we have no good way of relaying the
external scripts. Since we are still in the drafting phase I am open to
suggestions and if there is a good/working solution I can amend/withdraw
the proposal.
As for open venues for malleability, I'm not sure we can fix them at all,
after all the ability of a single signer to doublespend by
appending/replacing inputs/outputs in an arbitrary fashion is not fixable
IMHO and will cause any future transaction building on its outputs to be
orphaned. What would the perfect properties for such a fix be?

@_date: 2015-11-03 21:44:02
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
Ok, so assuming we can get a connected component of upgraded nodes that
relay both the transaction and the associated external scripts then we
could just piggyback the external scripts on top of the normal messages.
Non-upgraded nodes will read the entire two-part message but only parse the
classical transaction, dropping the external script. Validation rules for
upgraded nodes are the same as before: if the attached signatures are
invalid the entire TX is dropped. We have to commit to the external scripts
used during the creation of a block. I think the easiest way to add this
commitment is the coinbase input I guess, and following the transaction
list a new list of signature lists is shipped with the rest of the block.
Non-upgraded will ignore it as before.
Would that work? It all hinges on having upgraded miners in a connected
component otherwise non-upgraded nodes will drop the external scripts on
the way (since they parse and then reconstruct the messages along the
path). But if it works this could be a much nicer solution.
So this is indeed a form of desired malleability we will likely not be able
to fix. I'd argue that this goes more into the direction of double-spending
than a form of malleability, and is mostly out of scope for this BIP. As
the abstract mentions this BIP attempts to eliminate damage incurred by
malleability in the third party modification scenario and in the multisig
scenario, with the added benefit of enabling transaction templating. If we
can get the segregated witnesses approach working all the better, we don't
even have the penalty of increased UTXO size. The problem of singlesig
users doublespending their outputs to update transactions remains a problem
even then.
Sounds very interesting. That would then be a new signature checking opcode
I guess that would allow the transaction hash in the input be replaced by
the hash of the serialized output it is spending? That way the transaction
would not be detached from the coins unless the amount or the scriptpubkey
(containing the address) is modified. So a user may add new outputs and
inputs to an existing transaction like you mentioned. This does not help
someone receiving funds from a sender to build new transactions on top
since the sender may simply doublespend its output before it is confirmed.
I think this is probably best addressed in a separate proposal.

@_date: 2015-11-05 09:38:03
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
This does indeed sound reasonable. The chances of having a cut in the
network consisting of non-upgraded nodes partitioning the network and not
forwarding the segregated witnesses should be minimal, given a long rollout
phase before the activation.
If everybody agrees that this is a better way to approach the normalization
issue we should probably start writing it up and see if we can get critical
mass behind it :-)

@_date: 2015-11-06 14:52:49
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
Yes, your differentiation is spot on. My main goal is to eliminate the risk
of detaching transactions in  off-blockchain protocols that rely on a
number of transactions being chained, hence solving signature malleability
might be the correct term. Canonical encodings do address part of the
problem, however they do nothing in the case of one of the signers
re-signing a transaction and detaching any followup transaction. Also
having transaction templates is a nice way to reduce the complexity of
protocols by eliminating some of the "who signs what when" gotchas.
Segregated witnesses would be a perfect solution, we just need to find a
good migration plan for Bitcoin :-)
Sorry for the confusion caused by me misusing the term malleability, I'll
use signature malleability in the future :-)

@_date: 2015-10-19 14:01:04
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
After spending some more time on the normalized transaction ID proposal and
reworking it to be a soft-fork (thanks sipa for helping me figuring out
how), I'd like to propose the BIP again.
As with the previous version, which was using a hard-fork, the normalized
transaction ID is computed only considering the non-malleable parts of a
transaction, i.e., stripping the signatures before computing the hash of
the transaction. This ensures that if a transaction is modified, either by
a third party fishing transactions from the network and re-injecting
modified versions or by one of the signers re-signing it, any transaction
that builds on top of it still remains valid. Furthermore it allows the use
of template transactions, unsigned transactions upon which further
transaction can be built before signing the template transaction and
locking the contract.
Unlike the previous proposal, this is a softfork proposal that redefines
OP_NOP4 with an extensible and parameterized version of the signature
checking opcodes, called OP_CHECKSIGEX. Among other things the parameters
allow to specify that an output with an OP_CHECKSIGEX is to be referenced
by the normalized transaction ID that created it, instead of the instance
transaction ID containing malleable signatures. This BIP uses the
normalized transaction IDs exclusively while signing or checking
signatures, they are not used in any network level message as the previous
version would have done, hence there is no change at network level and old
clients should be able to exchange transactions as before and blocks still
reference the transaction instances.
The proposal is implemented (see below), by computing the normalized
transaction ID when adding them to the UTXO and storing them along with the
coin state. OP_CHECKSIGEX mostly duplicates OP_CHECKSIG and
OP_CHECKMULTISIG, but I'm hoping somebody can give me some pointers into
how to best refactor the common functionality into reusable blocks. And the
annotating incoming transactions with their normalized inputs is a bit
cumbersome, maye somebody has some pointers here as well?
BIP Pull request: Implementation: I think in the discussion of my previous proposal, most of you welcomed the
introduction of normalized transaction IDs, were it not for the hardfork. I
hope this proposal adresses the previous concerns and that we can move
forward in adding the normalized transaction IDs to the bitcoin protocol.
That being said, I'm always open to suggestions :-)

@_date: 2015-10-19 19:28:49
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
Yes, this has been pointed out in the PR as well. Transactions inputs must
also be normalized by replacing malleable hashes with the normalized
hashes. I will fix the spec and the implementation to reflect this :-)
On Mon, Oct 19, 2015 at 5:24 PM Tier Nolan via bitcoin-dev <

@_date: 2015-10-20 10:30:33
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
On Tue, Oct 20, 2015 at 12:23 AM s7r via bitcoin-dev <
The normalization involves two steps:
 - strip the scriptSig scripts in the inputs, i.e., the only part whose
integrity is not guaranteed by the signature itself, by replacing the
scripts with empty strings (var length string of size 0)
 - replace the hashes referencing the outputs being spent with the
normalized hashes of the transaction that created the outputs. This is done
recursively down to the first v2 transactions.
The second part is not yet explained in the draft, but I will amend it as
soon as possible.
Non-coinbase transactions can still not be replayed since the normalized
transaction still includes a the normalized transaction hashes of claimed
outputs, hence any attempt to replay a transaction would fail since the
outputs were already spent. For coinbase transactions it is indeed possible
that we create multiple transactions with the same hash (only one of which
would be spendable), hence we do not strip coinbase transactions and rely
on BIP 34 to make the coinbase transactions unique (except for blocks 91842
and 91880 which are the reason we introduced BIP 34 in the first place).
Clarifying the way the normalized transaction ID is computed should remove
any ambiguities I hope.
Yes, if the computation of the normalized transaction ID includes replacing
input hashes with their normalized counterpart makes a chain of any depth

@_date: 2015-10-21 07:39:45
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
As far as I see it the only remaining venues for malleability are the use
of sighash flags that are not SIGHASH_ALL, as mentioned in the BIP. Any use
of non-sighash_all flags is already an explicit permission to modify the
transactions, by adding and removing inputs and outputs, so I don't see how
these can be made non-malleable. Am I missing something?
Yes, this is my mistake and has been pointed out in the PR, I will amend
the PR to make the verify flag mandatory, which also guarantees that the
top of the stack contains a non-null element, thus resulting in a
successful evaluation on non-updated clients.

@_date: 2015-10-21 08:31:42
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
How is signer malleability still a problem if we remove the signatures from
the transaction ID of the transaction and all preceding transactions? The
signer can re-sign a transaction but it won't change the transaction ID.
It is still possible to double-spend transactions that do not have enough
fees, so just starting a new round of CoinJoin is sufficient to bump fees
for all parties that participate, and that would also result in the
double-spent low fee transaction to be discarded, resolving the state of
all coins in the first CoinJoin tx.

@_date: 2015-10-21 08:44:53
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
Hm, that is true as long as the signer is the only signer of the
transaction, otherwise he'd be invalidating the signatures of the other
signers. That can however be fixed by having a canonical ordering of Inputs
and Outputs, which has been discussed before in order to decrease
information that can be gained about the spender. Maybe we can defer to
that effort?

@_date: 2015-10-21 08:49:26
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
Isn't that sort of what this BIP describes as well? Except that we use the
scriptSig to transport the signatures internally to the transactions and
strip them when it comes to signing/checking? The wire format and transport
of transactions do not change so old clients continue to fetch and process
transactions as before, they just can't verify the TX. Blocks still
reference the instance but verification uses the stripped TX with the
signatures on the side, etc.

@_date: 2015-10-21 08:50:45
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
Ok, so the normalization step could add a sorting step for inputs/outputs
(which is going to be nasty for SIGHASH_SINGLE), that would solve the issue.
On Wed, Oct 21, 2015 at 10:49 AM Christian Decker <

@_date: 2015-10-22 08:26:58
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
I think the scenario of the single signer re-ordering the outputs and
inputs and then re-signing the transaction is in the same category of
simple double-spends. The signer could just as well sign a completely
different transaction spending the same coins to somewhere else, so I don't
think there is a lot we can do about it even if we instate a canonical
ordering. Even if we order the inputs and outputs the signer can just add a
new input and output and we would have a different transaction.
Normalized transaction IDs do help in the case that the single signer wants
to immediately follow up its transaction with another transaction spending
the first one's change output, and it prevents any modification in the
multi-signer scenario.

@_date: 2015-10-22 11:54:17
@_author: Christian Decker 
@_subject: [bitcoin-dev] [BIP] Normalized transaction IDs 
Indeed the reason I got started with all of this is the use of normalized
transaction IDs within smart contracts with multiple signers. Sorry if I
was perceived as overselling it :-)
So to summarize the discussions that have been on-going here as well as in
the PR so far, most people seem to agree that the BIP is an improvement for
smart-contracts as well as the third-party modification scenario. It comes
at the cost of increased UTXO size due to the additional hash being stored
per transaction with unclaimed outputs and some additional computations.
The additional computation is for the normalized ID computation and the
swapping in of normalized IDs during verification. No additional coin
lookups are needed as they are retrieved and cached anyway when verifying
the transaction. Would everybody agree with this assessment so far?
On the PR there were some additional suggestions of treating singlesig
transactions as 1-of-1 transactions and using Schnorr signatures for the
new opcode. Schnorr has been in the works for a long time and gives a
multitude of advantages, e.g., batch validation, and seems like a good
addition. Since the verify flag is mandatory due to the soft-fork migration
and we might merge singlesig and multisig into a single opcode we can
replace the bitmap of flags with a simple version number. Clients would
fall back to OP_NOP behaviour for versions they do not implement,
maintaining soft-fork semantics to build more future signing and
verification methods.

@_date: 2016-08-25 16:27:32
@_author: Christian Decker 
@_subject: [bitcoin-dev] Capital Efficient Honeypots w/ "Scorched Earth" 
That strongly depends on the value of the compromised machine to the
attacker. If he has syphoned all the data from it and has no further
use for it then the he will probably trip the tripwire to get the
coins even though this will make the compromise apparent. If however
he is planning to use it as a foothold to further compromise your
company, send spam or similar, he will likely try to avoid these
tripwires. In which case a classic honeypot, that attempts to look
like a regular system is what you're looking for.

@_date: 2016-09-22 13:10:49
@_author: Christian Decker 
@_subject: [bitcoin-dev] Requesting BIP assignment; Flexible Transactions. 
I think BIPs should be self-contained, or rely on previous BIPs,
whenever possible. Referencing an external formatting document should
be avoided and requiring readers to reverse engineer a reference
implementation doesn't seem too user friendly either. Publishing a BIP
with CMF would certainly help, and completing this spec with the
details that are missing, or only "defined" in the implementation,
would be better.
So the presence is signaled by encountering the tag, which contains
both token type and name-reference. The encoder and decoder operations
could be described better.
Minor nit: that table is not well-formed. As was pointed out in the
normalized transaction ID BIP, your proposal only addresses
third-party malleability, since signers can simply change the
transaction and re-sign it. This is evident from the fact that inputs
and outputs do not have a canonical order and it would appear that
tokens can be re-ordered in segments. Dependencies of tokens inside a
segment are also rather alarming (TxInPrevHash <-> TxInPrevIndex,
TxOutScript <-> TxOutValue).
Finally, allowing miners to reject transactions with unknown fields
makes the OP_NOPs unusable since they'd result in forks: non-upgraded
nodes would reject blocks from upgraded nodes.

@_date: 2016-09-23 13:42:36
@_author: Christian Decker 
@_subject: [bitcoin-dev] Requesting BIP assignment; Flexible Transactions. 
Nope, just clarifying how presence or absence is indicated :-)
It's just some rows have 3 columns, others have 2. It's a minor nit
Same thing I was arguing back then, however Luke pointed out that
malleability just refers to the possibility of modifying a transaction
after the fact. Always referring to "third-party malleability" avoids
this ambiguity.
Nope, that is exactly the kind of dependency I was talking
about. Instead of nesting a construct like the current transactions
do, you rely on the order of tokens to imply that they belong
Ah, thanks for clearing that up. However, the problem persists, if we
add new fields that a non-upgraded node doesn't know about and it
rejects transactions containing it, we'll have a hard-fork. It should
probably not reject transactions with unknown fields if the
transaction is included in a block.

@_date: 2016-09-23 13:55:50
@_author: Christian Decker 
@_subject: [bitcoin-dev] Requesting BIP assignment; Flexible Transactions. 
Not sure if the comparison to XML and HTML holds: the lack of closing
tags makes the meaning of individual tokens ambiguous, like I pointed
out before. The use of segments gives at most two levels of nesting,
so any relationship among tokens in the same segment has to rely on
their relative position, which could result in ambiguities, like
whether a tag refers to a single input or the transaction as a whole.

@_date: 2017-04-18 18:07:25
@_author: Christian Decker 
@_subject: [bitcoin-dev] Transaction signalling 
I really like the idea of extending signalling capabilities to the
end-users. It gives stakeholders a voice in the decisions we take in
the network, and are a clear signal to all other involved parties. It
reminds me of a student thesis I supervised some time ago [1], in
which we explored various signalling ideas.
I think we have a number of fields that may be used for such a
signalling, e.g., OP_RETURN, locktime, and output scripts. I think
OP_RETURN is probably not the field you'd want to use though since it
adds data that needs to be transferred, stored for bootstrap, and
outputs in the UTXO would need to be tagged with additional
information. Locktime has the advantage of being mostly a freeform
field for values in the past, but it clashes with other uses that may
rely on it. Furthermore, it is the transaction creator that specifies
the locktime, hence the signal trails one hop behind the current
owner, i.e., the actual stakeholder.
I think probably the best field to signal would be the output
script. It is specified by the recipient of the funds, i.e., the
current owner, and is already stored in the UTXO, so a single pass can
tally up the votes. We could for example use the last 4 bits of the
pubkey/pubkeyhash to opt in (3 leading 0 bits) and the vote (0/1
depending on the stakeholders desired signal). We'd need to define
similar semantics for other script types, but getting the standard
scripts to be recognized should be simple.
In the spirit of full disclosure I'd like to also mention some of the
downsides of voting this way. Unlike the OP_RETURN proposal, users
that do not intend to signal will also be included in the tally. I'd
expect the signals of these users to be random with a 50% chance of
either outcome, so they should not influence the final result, but may
muddy the water depending on what part of the population is
signalling. The opt-in should make sure that the majority of votes are
actually voluntary votes, and not just users that randomly select a
pubkey/pubkeyhash, and can be adjusted as desired, though higher
values require more grinding on behalf of the users.
The grinding may also exacerbate some problems we already have with
the HD Wallet lookahead, since we now skip a number of addresses, so
we should not require too many opt-in bits.
So there are some problems we'd need to tackle, but I'm really excited
about this, as it could provide data to make informed decisions, and
should put an end to the endless speculation about the will of the
economic majority.
[1]

@_date: 2017-01-05 15:48:33
@_author: Christian Decker 
@_subject: [bitcoin-dev] Committed bloom filters for improved wallet 
And it's a great way to tell every miner who you are and what
transactions you are sending/receiving. An absolute privacy

@_date: 2017-01-27 22:28:10
@_author: Christian Decker 
@_subject: [bitcoin-dev] Three hardfork-related BIPs 
As one of the authors of that paper and the source of the measurement
data I'd also like to point out that the 4MB number is indeed intended
as an optimistic upper bound on todays network capacity.
More importantly it's not a black and white situation, where there is
a magic number beyond which Bad Things (TM) happen, it's a spectrum on
which we can see a few threshold beyond which we _know_ Bad Things
definitely happen. Miner centralization pressure is felt earlier.

@_date: 2017-09-28 12:43:19
@_author: Christian Decker 
@_subject: [bitcoin-dev] Revising BIP 2 to expand editorial authority 
Agreed, I think a sign-off mechanism might be desirable. Currently it must
be the original author(s) signing off, but we can probably widen that to be
any 2-3 community members. They'd basically be attesting that the meaning
did not change.
- cdecker
On Wed, Sep 27, 2017 at 9:02 PM Bryan Bishop via bitcoin-dev <

@_date: 2018-04-14 16:14:04
@_author: Christian Decker 
@_subject: [bitcoin-dev] BloomFilter issue with segwit addresses 
Note that this would compound the privacy leak that Jonas Nick used to
identify address clusters via the bloom filters in one of his publications.
By reducing the false positives when matching you can get very detailed
clusters. Then again we know that bloom filters aren't good for privacy
anyway, so this might be a non-issue.
On Sat, Apr 14, 2018, 00:17 Jim Posen via bitcoin-dev <

@_date: 2018-04-30 17:41:38
@_author: Christian Decker 
@_subject: [bitcoin-dev] eltoo: A Simplified update Mechanism for Lightning 
(cross-posting to bitcoin-dev since this serves as motivation behind the
sighash_noinput proposal)
A little over a year ago, the three Lightning Network implementation
teams joined forces to work on a common specification for the protocol
stack. Now that both that specification and our three implementations
are becoming stable and usable, it is time to look forward: to further
improve the protocol, to add new features, to simplify, and to fix
One of the core innovations that enabled Lightning in the first place was an
off-chain update mechanism to renegotiate a new state and ensure that the old
state can not be settled on-chain. Today, we're excited to release our latest
research paper on a new, simplified, update mechanism for layer 2 protocols,
called eltoo.
eltoo is a drop-in replacement for the penalty based invalidation
mechanism that is used today in the Lightning specification. It is
similar in many ways to the sequence number mechanism that was already
present in the original Bitcoin implementation. But, while sequence
numbers were unenforceable on the blockchain, eltoo is enforceable by
overriding subsequent states on-chain.
Unlike the current mechanism used in Lightning so far, it is not penalty
based, i.e., publishing an old state does not result in the faulty node
to automatically lose funds, and is most similar to the duplex
micropayment channels construction. It is a symmetric scheme, i.e., all
participants share an identical set of transactions, and it ensures that the
last agreed upon state is settled on-chain, with similar tradeoffs as
today's Lightning (timelock vs. online requirement).
eltoo addresses some of the issues we encountered while speficying and
implementing the Lightning Network. For example outsourcing becomes very
simple since old states becoming public can't hurt us anymore. We
completely remove the need to estimate fees ahead of time. The
construction allows us to attach fees when settling, and even allows for
fees to be bumped using CPFP or RBF.
Beyond Lightning, eltoo can be used as a generic update mechanism for an
off-chain contract, for a larger number of participants. This was not
possible in the current update mechanism since reactions to a
misbehaving participant needed to be tailore to that participant. This
enables other protocols such as the channel factories, and in
combination with Schnorr signatures allows for very large off-chain
contracts with minimal on-chain footprint.
Before we can implement eltoo, we need a minor change to Bitcoin: the
introduction of the SIGHASH_NOINPUT flag for signatures. This was first
discussed a few months ago in the context of watchtowers to help secure
Lightning channels, but was not formally proposed. A formal proposal may
now be found in the eltoo paper.
We invite the community to consider our proposal and to participate in
its discussion. We hope to arrive at a consensus for the usage of
SIGHASH_NOINPUT, so that it can be accepted and included in a future
soft fork of Bitcoin Script. Doing so will put us on the road to a more
reliable and simpler Lightning Network, incorporating a new update
mechanism that can also be used for many other applications.
The full official announcement can be found at [1] and the paper with the full
details can be found at [2].
Looking forward to the communities feedback,
[1] [2]

@_date: 2018-04-30 18:29:53
@_author: Christian Decker 
@_subject: [bitcoin-dev] BIP sighash_noinput 
Hi all,
I'd like to pick up the discussion from a few months ago, and propose a new
sighash flag, `SIGHASH_NOINPUT`, that removes the commitment to the previous
output. This was previously mentioned on the list by Joseph Poon [1], but was
never formally proposed, so I wrote a proposal [2].
We have long known that `SIGHASH_NOINPUT` would be a great fit for Lightning.
They enable simple watch-towers, i.e., outsource the need to watch the
blockchain for channel closures, and react appropriately if our counterparty
misbehaves. In addition to this we just released the eltoo [3,4] paper which
describes a simplified update mechanism that can be used in Lightning, and other
off-chain contracts, with any number of participants.
By not committing to the previous output being spent by the transaction, we can
rebind an input to point to any outpoint with a matching output script and
value. The binding therefore is no longer explicit through a reference, but
through script compatibility, and the transaction ID reference in the input is a
hint to validators. The sighash flag is meant to enable some off-chain use-cases
and should not be used unless the tradeoffs are well-known. In particular we
suggest using contract specific key-pairs, in order to avoid having any unwanted
rebinding opportunities.
The proposal is very minimalistic, and simple. However, there are a few things
where we'd like to hear the input of the wider community with regards to the
implementation details though. We had some discussions internally on whether to
use a separate opcode or a sighash flag, some feeling that the sighash flag
could lead to some confusion with existing wallets, but given that we have
`SIGHASH_NONE`, and that existing wallets will not sign things with unknown
flags, we decided to go the sighash way. Another thing is that we still commit
to the amount of the outpoint being spent. The rationale behind this is that,
while rebinding to outpoints with the same value maintains the value
relationship between input and output, we will probably not want to bind to
something with a different value and suddenly pay a gigantic fee.
The deployment part of the proposal is left vague on purpose in order not to
collide with any other proposals. It should be possible to introduce it by
bumping the segwit script version and adding the new behavior.
I hope the proposal is well received, and I'm looking forward to discussing
variants and tradeoffs here. I think the applications we proposed so far are
quite interesting, and I'm sure there are many more we can enable with this
[1] [2] [3] [4]

@_date: 2018-08-30 22:51:15
@_author: Christian Decker 
@_subject: [bitcoin-dev] SIGHASH2 for version 1 witness programme 
Thanks for the update Johnson, just wanted to give a really quick NACK
on the SIGHASH_NOINPUT variant: the whole idea of BIP 118 is to have
floating transactions that can be bound to predecessors, and still
enforce some application logic. In eltoo's case this is the fact that
the state number needs to be smaller than the state number of the
transaction that is being rewritten. The state number that we bind to is
part of the `scriptPubKey`, so we can't commit to the `scriptPubKey` in
the signature since we don't know which output (and thus it's
scriptPubKey`) is at the time we sign.
If we are committing to `scriptPubKey` this whole way of enforcing order
in updates is no longer possible, and the only thing we actually get
from this change is a (very weak) malleability fix. The same argument
goes for `scriptCode`.

@_date: 2018-12-19 23:09:50
@_author: Christian Decker 
@_subject: [bitcoin-dev] Safer NOINPUT with output tagging 
Ruben Somsen via bitcoin-dev I'm not aware of a way to combine the setup and trigger transaction. The
trigger transaction was introduced in order to delay the start of the
timeouts until a later time, to avoid having an absolute lifetime limit
and having really huge timeout. If we were to combine the trigger
transaction with the setup transaction (which is broadcast during
channel creation), all of those timeouts would start counting down
immediately, and we could just skip the trigger transaction
altogether. It'd be more interesting to combine update and trigger
transactions in a sort of cut-through combination, but that doesn't seem
possible outside of Mimblewimble.

@_date: 2018-12-20 18:20:54
@_author: Christian Decker 
@_subject: [bitcoin-dev] Safer NOINPUT with output tagging 
If we are using a trigger transaction the output of the setup
transaction would simply be `2 Au Bu 2 OP_CMS`. If we were to use a CLTV
in there we would not have an option to later attach a collaborative
close transaction that is valid immediately. Furthermore the timeout of
the CLTV would start ticking down the exact moment the setup transaction
is confirmed, hence whatever effect we are trying to achieve with that
timelock is limited, and we have a limit to the total lifetime of the
Update 0 is usually what I call the trigger transaction. It takes the
2-of-2 multisig from the setup transaction and translates it into the
two-branch output that further updates or settlements can be attached
to. The settlement transaction attached to the trigger / update 0
reflects the initial state of the channel, i.e., if A added 2 BTC and B
added 1 BTC then settlement 0 will have 2 outputs with value 2 and 1
respectively, with the user's keys (this can also be considered the
refund in case of one party disappearing right away).
The second branch in the script you posted is the update branch, which is
not encumbered by a CSV, while the first branch is the one encumbered
with the CSV and is called the settlement branch since we'll be
attaching settlement txs to it.
The CLTV looks correct to me and ensures that we can only attach any
state >= s+1.
So just to show the output script for state `i` how I think they are
   OP_CSV 2   2 OP_CHECKMULTISIG
   OP_CLTV OP_DROP 2   2 OP_CHECKMULTISIG And the input scripts for the update tx and the settlement tx
respectively would be:
OP_FALSE  OP_TRUE  If I'm not mistaken the CSV needs to be in the scriptPubkey (or P2WSH
equivalent) since segwit witnesses only allow pushes. Hence the script
in point 3 needs to add that :-)
They also need to sign (but not broadcast) update_0, in order to allow
either party to initiate the closure if the counterparty become
unresponsive. The order in which settlement_0 and update_0 are signed is
not important by the way, so we can just batch these. The important part
is that signing the setup acts as a commitment.
The output script of the updates are identical to the ones in the
trigger or update_0 transaction, so they'd also need a CSV (this is why
committing to the script structure with masking still works).
We have to differentiate 2 cases: collaborative close and unilateral
close. In the collaborative close we come to a mutual agreement that
we'd like to take this latest state and settle. So we create a new
transaction that spends the setup output, and add outputs according to
the state we agreed upon, and we sign it. This transaction is
immediately valid, and does not need to be signed with NOINPUT. So all
the chain sees is a setup transaction with some inputs and one multisig
output (singlesig with Schnorr) and a collaborative close transaction
that spends the setup (also not signed with NOINPUT). About as normal as
transactions in Bitcoin can get.
In the unilateral case, one party isn't there anymore, or refuses to
sign. So we take the trigger transaction (not signed with NOINPUT) and
the latest update_n transaction (signed with NOINPUT) and broadcast
them. Then we wait for the CSV timeout to expire, and then send the
settlement transaction, which gives us the enforcement of the latest
state that we agreed on. The chain sees a setup transaction and a
trigger transaction (normal transactions for all intents and purposes,
except for the output script of the trigger, but we can hide that with
taproot), followed by two more transactions which are signed with
NOINPUT. So 4 transactions in the worst case, of which 2 are special,
and 2 transactions in the good case.
So all in all I think it's a tradeoff between having a larger on-chain
footprint (4 txs vs 3 txs in the worst case) and putting a fixed
lifetime on the channel for the refund case if one party disappears
right away. We'll probably find out what acceptable parameters are for
these and where the cutoff points are :-)

@_date: 2018-12-21 12:15:37
@_author: Christian Decker 
@_subject: [bitcoin-dev] Safer NOINPUT with output tagging 
Correct, we're using the CLTV here as a weird "compare two numbers that
are committed to in the signatures" operation, by using locktimes in the
past as you correctly point out.
I keep forgetting about BIP68, but you're right, that should be
sufficient for our use-case and would safe us a few bytes.
I seem to keep mentally mixing different variants of the protocol in my
head. You are of course correct that the trigger and the update can be
considered the same, hence the 3 txs limit is right. Sorry for the
confusion :-(

@_date: 2018-02-12 20:41:39
@_author: Christian Decker 
@_subject: [bitcoin-dev] Total fees have almost crossed the block reward 
Peter Todd via bitcoin-dev My guess they simply collect the short_channel_ids which point to
on-chain outputs that funded a channel. This relies on the channels
being public, non-public channels can still be identified on settlement.

@_date: 2018-07-03 14:05:09
@_author: Christian Decker 
@_subject: [bitcoin-dev] BIP sighash_noinput 
Absolutely agree that we should be signaling the danger of using noinput
as clearly as possible to developers, and I'm more than happy to adopt
the _unsafe suffix suggested by jb55. I think using non-sighash_all
sighashes is always a huge danger, as you have correctly pointed out, so
maybe we should be marking all of them as being unsafe, or make sure to
communicate that danger on a higher level (docs).

@_date: 2018-07-13 13:07:48
@_author: Christian Decker 
@_subject: [bitcoin-dev] [Lightning-dev]  BIP sighash_noinput 
This point is pretty much moot since these are scripts, that are used in
very specialized contexts, and should not be shown to any
end-user. Sure, if you go through the blockchain looking for these
addresses, and send the exact same value to it, and create a matching
script then you could end up exposing those funds to this, however
that'd be very silly of you, and you'd have jumped through a lot of
hoops to lose money :-)
You cannot force the counterparty to sign with a sighash-flag that they
don't chose themselves. We are very clear in the BIP that you should
only use sighash_noinput_unsafe in the context of protocols, that need
to be designed in such a way that these issues are excluded. In
particular, eltoo uses a public key, provided by the signing party,
which they can ensure is not reused (ensuring script
uniqueness). Finally, wallets that are not part of LN or eltoo, won't
even know how to sign with sighash-noinput (try signing anything but
sighash-all on a hardware wallet for example).
The kind of editing you describe also doesn't work, since sighash-single
is used for the late fee binding, not sighash-noinput. sighash-single
makes sure that the input is only valid if the matching output is still
intact, so redirecting funds away from the desired output doesn't work.
Again, this is only to be used in the context of applications that
require it, which also means that they know how to deal with this
malleability (in fact this malleability is wanted here). If you squint
at it you can probably see that sighash-noinput is also a poor-man's
malleability fix, allowing you to take a transaction that is based on a
malleated output, and rebind it to re-establish the connection.
It seems people believe that we are advocating the use of
sighash-noinput-unsafe in general purpose wallets and in everyday
transactions, this couldn't be further from the truth: sighash-noinput
is a sharp tool, that should only be used in very specific situations,
to enable a bit more flexibility, and it can improve the safety of
off-chain protocols a lot, however general purpose wallets should not
even allow signing with it.

@_date: 2018-06-13 15:33:33
@_author: Christian Decker 
@_subject: [bitcoin-dev] Why not archive the backend of Bitcoin blockchain? 
Kulpreet Singh via bitcoin-dev Yes, Lightning nodes need to monitor the network for transactions that
they need to react to. This is basically tailing the blockchain and
looking for anything suspicious. The `bitcoind` sitting next to the
lightning node however does not need to keep an index of the
transactions, at least for c-lightning, because we just ask for the full
block that then gets scanned for transactions of interest and then we
discard the rest of the block. We never ask for a specific transaction
from `bitcoind` and therefore we don't need to run with `-txindex`.
Pruned nodes should work, as long as the current blockchain head that
the lightning node has seen does not fall into the pruned range, since
in that case it won't be able to fetch and process the blocks anymore.
I don't think we should ever require `-txindex` to run a lightning node
(I know some implementations did in the past), since that'd be a very
onerous requirement to run a lightning node. Tailing the blockchain is
more than sufficient to get the necessary data, and hopefully we can get
our reliance on `bitcoind` down to a minimum in the future.
Absolutely no problem, it is a common misconception that `-txindex` is
required to run a lightning node in all cases :-)

@_date: 2018-06-13 18:17:20
@_author: Christian Decker 
@_subject: [bitcoin-dev] Why not archive the backend of Bitcoin blockchain? 
Certainly, that's supported by all 3 implementations:
 - With c-lightning you can either configure `bitcoin-cli` to connect to
   a remote node with the `rpcconnect`, `rpcuser`, and `rpcpassword`
   options in the `bitcoin.conf` file (at which point all calls to
   `bitcoin-cli` will use that node) or you can use the following
   command line options when starting `lightningd`: `--bitcoin-rpcuser`,
   `--bitcoin-rpcpassword` and `--bitcoin-rpcconnect`
 - lnd allows you to specify the node to connect to using the command
   line options `--bitcoind.rpchost`, `--bitcoind.rpcuser`, and
   `--bitcoind.rpcpass`.
 - Eclair requires you to edit the configuration file [1] before
   compiling afaik
[1]

@_date: 2018-05-01 13:36:32
@_author: Christian Decker 
@_subject: [bitcoin-dev] eltoo: A Simplified update Mechanism for 
That's a good point Jim. We need to make sure that the CLTVs are far
enough in the future for the CSV timeout to expire and to grab any
preimage downstream and insert it upstream. Overall this results in an
offset of all the CLTVs to (less than) the maximum CSV timeout along the
path. This would be a fixed offset for each channel and can be announced
using the gossip protocol, so senders can take it into consideration
when computing the routes. Notice that this is not really the CLTV
delta, which would accumulate along the path, but an offset on which the
CLTV deltas build on.
In today's network we have many nodes that have a CLTV delta of 144
blocks, which quickly results in HTLC funds unavailable for several days
depending on the route length, so I don't think that adding a fixed
offset is much worse. Once we have watch-towers we can reduce both the
offset as well as the CLTV deltas. Since eltoo makes watch-towers less
expensive, given the reduced storage costs, I'd argue that it's a net
positive for the Lightning network (but then again I'm biased) :-)

@_date: 2018-05-01 13:38:12
@_author: Christian Decker 
@_subject: [bitcoin-dev] [Lightning-dev] eltoo: A Simplified update 
Darn last minute changes! Yes, you are right, I seem to have flipped the
two definitions. I'll fix that up and push a new version.

@_date: 2018-05-01 18:29:09
@_author: Christian Decker 
@_subject: [bitcoin-dev] eltoo: A Simplified update Mechanism for 
Sure. Let's assume we have chosen a path `A->B->C->D->E`. For simplicity
let's assume they all have a CLTV delta of 144 blocks (lnd's default
setting). Furthermore let's assume that the CSV timeout for the channels
is also 144.
This means that with the current LN-penalty mechanism you'd have the
following CLTV deltas in the HTLC:
A -(576)-> B -(432)-> C -(288)-> D -(144)-> E
Meaning that if the current time is approaching the absolute CLTV we
need initiate a channel closure to safely fetch the preimage on-chain,
and be able to turn around and send it on the upstream channel.
This is minimal, but can be arbitrarily higher, if you follow the best
practice of obfuscating the final destination by building a shadow route
behind the real recipient, and add it's CLTV deltas and fees to your
With eltoo you'd need to make sure that you have the settlement
transaction confirmed before your desired CLTV timeout delta begins to
count down. So if the CLTV of the HTLC is `now + CSV timeout + CLTV
delta` you need to initiate a close, whereas Lightning allows you to
wait for time `now + CLTV delta`. Effectively this results in the
following time deltas:
A -(576+144)-> B -(432+144)-> C -(288+144)-> D -(144+144)-> E
Taking the last hop for example, if we had a CLTV of 1000 with eltoo
we'd need to start closing at height 712, instead of 856 with
LN-penalty. However, this increased delta does not accumulate along the
path, it's just a fixed offset. The longer the route, the smaller the
actual impact of this offset.

@_date: 2018-05-01 19:31:28
@_author: Christian Decker 
@_subject: [bitcoin-dev] eltoo: A Simplified update Mechanism for 
That'd be a purely reactionary behavior, i.e., chosing the delta in such
a way that I can both settle the channel and have enough time to react
to turn around and reveal the preimage. So with the assumptions we had
before (CSV = 144 and CLTV delta = 144) you'd have an effective delta of
288 on each hop, yes. That's basically the case in which each channel
reacts serially.
You can trivially parallelize these closures by looking ahead and
noticing that each hop really just cares about its own closure deadline,
i.e., each node just cares to close 288 blocks before the CLTV expires,
not that its delta w.r.t. to the downstream channel is that far in the
future. So all we care about is that once we are due to give the
upstream hop the preimage we've already closed the downstream channel
and can now read the HTLC preimage from that channel.
The CSV timeout isn't part of the delta on each hop, but we need to
implement the deadline computation as:
CLTV - CLTV delta - CSV
instead of LN-penaltiy's
CLTV - CLTV delta

@_date: 2018-05-01 19:32:32
@_author: Christian Decker 
@_subject: [bitcoin-dev] BIP sighash_noinput 
Good catch, must've missed that somehow. I'll amend the BIP accordingly.

@_date: 2018-05-04 13:09:09
@_author: Christian Decker 
@_subject: [bitcoin-dev] BIP sighash_noinput 
Depends on which end of a transaction the existing wallet is: existing
wallets will refuse to sign a transaction with an unknown sighash flag,
but if the wallet is creating the output that'll later be spent using a
`SIGHASH_NOINPUT` transaction it won't (and shouldn't) care.
I consider `SIGHASH_NOINPUT` to be a poor-man's malleability fix, since
it comes with some baggage. Without trying to undermine my own proposal,
but address reuse in combination with binding through script, can lead
to very unexpected results. You need to be very careful about where you
allow rebinding, hence the warnings in the proposal.
I was wondering whether we could actually skip one communication round
w.r.t. the previously described CoinSwap protocol, but it turns out we
need to at least exchange public keys before actually moving any
funds. Would have been nice to do spontaneous CoinSwaps.
By providing a new use-case you are contributing to the obfuscation of
this technique. The more normal the use of `SIGHASH_NOINPUT` becomes the
less an observer can learn from it being used. In combination with MAST,
Taproot or Graftroot we can further hide the details of the executed
protocol :-)

@_date: 2018-05-07 21:40:46
@_author: Christian Decker 
@_subject: [bitcoin-dev] BIP sighash_noinput 
Given the general enthusiasm, and lack of major criticism, for the
`SIGHASH_NOINPUT` proposal, I'd like to formally ask the BBEs (benevolent
BIP editors) to be assigned a BIP number. I have hacked together a
simple implementation of the hashing implementation in Bitcoin Core [1]
though I think it's unlikely to sail through review, and given the lack
of ground-work on witness V1 scripts, I can't really test it now, and
only the second commit is part of the implementation itself.
One issue that was raised off list was that some fork coins have used
sighash 0x40 as FORKID. This does not conflict with this proposal since
the proposal only applies to segwit transactions, which the fork coins
have explicitly disabled :-)
I'm looking forward to discussing how to we can move forward to
implementing this proposal, and how we can combine multiple proposals
into the next soft-fork.
[1]

@_date: 2018-05-10 15:57:30
@_author: Christian Decker 
@_subject: [bitcoin-dev] eltoo: A Simplified update Mechanism for 
Olaoluwa Osuntokun via bitcoin-dev
It's worth mentioning that the requirement for extremely large CLTV deltas
would already create incredibly long CLTV deltas between the endpoints,
since the endpoint delta accumulates along the path. This is true for
LN-Penalty as well as eltoo. eltoo's requirement to settle before the
HTLCs touch the blockchain adds a stage in which need to start on-chain
settlement to ensure the HTLC hits the chain before its CLTV
expires. We can imagine this as a separate timewindow, that does not
accumulate across multiple hops (settlement ordering is not an issue,
CLTV resolution is).
My hope is that indeed with the simpler watch-towers we can reduce both
the CLTV deltas as well as the settlement timeouts for eltoo, so that
they become negligible.
Not exactly costless, since the breaching party will have to pay the
on-chain fees, and we may be able to reintroduce the reserve in order to
add an additional punishment on top of the simple update mechanism
(selectively introducing asymmetry).
In addition to this it is worth pointing out that the old/replaced HTLCs
have no way of ever touching the blockchain, so we can throw away a
whole heap of data about these HTLCs, that we would have to carry around
indefinitely if this were not the case. The same reason the HTLCs start
ticking when a settlement touches the chain in LN-penalty is also the
reason we need to carry all that data around. eltoo can be said to
contain the two stage HTLC commit we added on top of LN-penalty.

@_date: 2018-05-10 16:12:21
@_author: Christian Decker 
@_subject: [bitcoin-dev] BIP sighash_noinput 
Yeah, we removed the script commitment out of necessity for eltoo, but
it seems to add a lot of flexibility that might be useful. One
additional use-case that came to mind is having a recovery transaction
for vault-like scenarios, i.e., a transaction that can short-circuit a
thawing process of frozen funds. You'd keep that transaction in a vault,
pre-signed and bind it to whatever action you'd like to interrupt.
I purposefully made the proposal as small and as well defined as
possible, with a number of possible applications to back it, since I
think this might be the best way to introduce a new feature and make it
as uncontroversial as possible. I'm not opposed to additional flags
being deployed in parallel, but they'll need their own justification and
analysis, and shouldn't be rushed just "because we're doing noinput".
Going for a separate op-code is definitely an option we considered, but
just for noinput it'd be duplicating quite a lot of existing
functionality. With additional sighash flags it might become necessary,
but I don't think it is necessary just for noinput.

@_date: 2018-05-15 10:28:22
@_author: Christian Decker 
@_subject: [bitcoin-dev] [Lightning-dev]  BIP sighash_noinput 
`SIGHASH_NOINPUT` is a rather powerful tool, but has to be used
responsibly, which is why we always mention that it shouldn't be used
lightly. Then again all sighash flags can be dangerous if not well
understood. Think for example `SIGHASH_SINGLE` with it's pitfall when
the input has no matching output, or the already mentioned SIGHASH_NONE.
difference between a new opcode or a new sighash flag, with the
activation being the one exception. I personally believe that a segwit
script bump has cleaner semantics than soft-forking in a new opcode
(which has 90% overlap with the existing checksig and checkmultisig
That's a good point, I'll try looking for it once I get back to my full
node :-) And yes, `SIGHASH_NONE` should also come with all the warning
signs about not using it without a very good reason.
That's true for today's uses of `SIGHASH_NOINPUT` and others, but there
might be other uses that we don't know about in which noinput isn't just
used for the contingency, handwavy I know. That's probably not the case
for graftroot/taproot, but I'm happy to be corrected on that one.
Still, these opcodes and hash flags being mainly used for contingencies,
doesn't remove the need for these contingency options to be enforced
The main reason I went for the sighash flag instead of an opcode is that
it has clean semantics, allows for it to be bundled with a number of
other upgrades, and doesn't use up NOP-codes, which I was lectured
for my normalized tx BIP (BIP140) is a rare resource that should be used
sparingly. The `SIGHASH_NOINPUT` proposal is minimal, since it enhances
4 existing opcodes. If we were to do that with new opcodes we'd either
want a multisig and a singlesig variant, potentially with a verify
variant each. That's a lot of opcodes.
The proposal being minimal should also help against everybody trying to
get their favorite feature added, and hopefully streamline the
I think the same can be addressed by simply having the wallet use a
different derivation path for keys that it is willing to sign with
NOINPUT. I sort of dislike having a direct dependency on taproot, i.e.,
allowing noinput only in taproot scripts, since that isn't a done deal
either. Without that direct dependency, having the noinput path and the
sighash_all path be differentiated in the script leaks the details
on-chain, bloating the UTXO set, and leaking details about our contract.
Also isn't the same issue true for a separate opcode?
Totally agree, however one could argue that increased code complexity
is a major contributor to security issues, and I'm still convinced that
the hashflag is the simplest and cleanest approach to getting this
feature implemented.
That being said, I think the soft-forked opcode is also a good option,
if we can get agreement on the details in a reasonable amount of time.
That can both be a positive as well as a negative, since a bundle of
complementing features likely is easier to get reviewed and activated.
That's moving the fanout for sighash_all vs sighash_none from the opcode
up to the interpreter, right.

@_date: 2018-05-17 13:35:53
@_author: Christian Decker 
@_subject: [bitcoin-dev] Making OP_TRUE standard? 
This would only really help in the case of the funding tx not having a
change output, which I believe will be very rare. In the case of a
change output we can simply do a CPFP which includes the change output.

@_date: 2018-11-21 12:15:44
@_author: Christian Decker 
@_subject: [bitcoin-dev] Safer sighashes and more granular SIGHASH_NOINPUT 
Hi Pieter,
great proposal, I think this may address some of the (perceived)
downsides of BIP118, by committing to the script when possible
(always?). One minor thing that I noticed a while ago and that I meant
to fix on BIP118 is that `hashSequence` does not need to be blanked for
eltoo to work (since where it is needed we also use `sighash_single`),
so I'm tempted to remove that redundant blanking. It may not make a lot
of difference but it'd limit the ability to change the number of inputs
to a NOINPUT transaction (this now being the only field that commits to
the set of inputs).
As for your proposal, I really like the `sighash_scriptmask` proposal,
and committing to the fees (with the `nofee` escape hatch) also works
seems also a nice fix. My one concern is that introducing a new opcode
to mask things in the sighash looks like a similar layering violation as
`codeseparator` was, but that's just a minor issue imho.
Pieter Wuille via bitcoin-dev

@_date: 2018-11-21 12:20:44
@_author: Christian Decker 
@_subject: [bitcoin-dev] Safer sighashes and more granular SIGHASH_NOINPUT 
Anthony Towns via bitcoin-dev I mentioned this in my reply to Pieter, but this may not be true if we
remove the blanking of the `hashSequence` field. Anyonecanpay would
allow changing the number of inputs in an arbitrary fashion, while
`noinput` without the blanking would (in a weird roundabout way) still
commit to the number of inputs. Maybe we want to make that more explicit
by also hashing the number of inputs? But I can't think of a good
usecase for keeping that, with noinput.

@_date: 2018-11-23 10:40:20
@_author: Christian Decker 
@_subject: [bitcoin-dev] Safer sighashes and more granular SIGHASH_NOINPUT 
It's a really roundabout way of committing to the inputs, I
agree. I'm actually wondering if it makes sense to correct that
additional blanked field in BIP118 at all since it seems there is no
real use-case for NOINPUT that doesn't involve blanking the
`hashSequence` as well.
BIP118 still commits to the value of the input being spent, i.e.,
6. value is not being blanked in the current proposal. This is on
purpose since we commit to the outputs, not committing to the input
values could end up with unexpected fees.
Agreed, that makes more sense :-)

@_date: 2018-11-29 18:00:09
@_author: Christian Decker 
@_subject: [bitcoin-dev] Safer sighashes and more granular SIGHASH_NOINPUT 
Pieter Wuille via bitcoin-dev So the final proposal would be to append a new `hashValues` field to the
hashed representation, with `hashValues` just being the double SHA256 of
all values? In that case SINGLE needs to blank that hash, otherwise we'd
be committing to all inputs again.
Once we have that detail, we can start thinking about what it means to
commit to the fee vs. committing to the values. Since the fee is given
by the output values and the input values we only need to consider the
cases in which they can be modified.
 - NOINPUT (as in BIP118) commits to the value (and I can't think of a
   usecase where we'd want to change that), and that transparently
   extends to all other inputs.
 - For ANYONECANPAY can't really commit to a fee anyway so ANYONECANPAY
   would likely imply NOFEE.
 - With NONE all bets are off anyway, so no need to consider that :-)
 - SINGLE is a bit special, and for value commitments it reduces to the
   current commitment to its own value, for fee commitment it's hard to
   see a use of that commitment at all afaik (I think the combination
   SINGLE|NOFEE would always be used).
Single cannot commit to other the sequence of other inputs, otherwise
we're breaking SINGLE completely. As mentioned before NOINPUT doesn't
need to blank `hashSequence`, but I'm happy to make it match if that
makes implementations handle fewer cases.
So we'd end up enumerating the combinations rather than having
independent bits for each of them? This might save us storage bits, but
it'd also result in uglier code imho, not a strong feeling but might
come back to haunt us if we ever come up with something new :-)
This needs to be partially blanked for SINGLE as well, otherwise we
break SINGLE.
I assume the sequence number here refers to the input being signed, not
the sequence number of the transaction output being spent :-) Might be
easier if we consider 3 parts: the spending transaction, the input being
signed, and the output (or TX) being spent.

@_date: 2018-11-29 19:29:10
@_author: Christian Decker 
@_subject: [bitcoin-dev] Safer sighashes and more granular SIGHASH_NOINPUT 
I'd like to retract my comments regarding SINGLE.
I was contacted in private and it was pointed out to me that I was
confusing `sighash_single` with `sighash_single|sighash_anyonecanpay`. I
appreciate the correction and would like to avoid creating confusion
with my previous comments, hence the retraction :-)

@_date: 2018-09-03 15:53:33
@_author: Christian Decker 
@_subject: [bitcoin-dev] SIGHASH2 for version 1 witness programme 
There is the poor man's malleability fix that you get if you make only
the previous outpoint rewritable, but that use-case is better covered by
segwit already, and since both of our proposals would be for segwit
outputs only, I don't see a point in doing that.
What do we effectively gain by committing to the scriptPubkey type? Is
the concern here that we might run into ambiguity about whether this is
a MAST, P2SH, or similar output, allowing an attacker to sideload
unwanted effects?
Agreed on compatibility :-)
That's a very strange concept, but it strongly relies on the structure
of the commitment, having two outputs. As soon as we have HTLCs included
in the commitment we no longer have 2 outputs (2 for the endpoints, and
1 as a base for the two-phase HTLC resolution), so this would be a
rather brittle fix or would require major restructuring of LN imho.

@_date: 2019-03-14 13:00:56
@_author: Christian Decker 
@_subject: [bitcoin-dev] [Lightning-dev] More thoughts on NOINPUT safety 
I might be missing something here, but how do you bind update 3 to the
funding tx output, when that output is not tagged? Do we keep each
update in multiple separate states, one bound to the funding tx output
and another signed with noinput? If that's the case we just doubled our
storage and communication requirements for very little gain. An
alternative is to add a trigger transaction that needs to be published
in a unilateral case, but that'd increase our on-chain footprint.

@_date: 2019-10-01 16:20:25
@_author: Christian Decker 
@_subject: [bitcoin-dev] Continuing the discussion about noinput / 
That is a bit reductive if you ask me. Taproot brings a number of
improvements such as the reduction of on-chain footprint in the
collaborative spend case, the hiding of complex logic in that case, and
yes, the uniformity of UTXOs that you mentioned. I do agree that it'd be
to make everything look identical to the outside observer, but saying
that separating outputs into two coarse-grained domains is equivalent to
throwing the baby out with the bath-water :-)
That being said, I should clarify that I would prefer not having to make
special accomodations on top of the raw sighash_noinput proposal, for
some perceived, but abstract danger that someone might shoot themselves
in the foot. I think we're all old enough not to need too much
handholding :-)
Output tagging is my second choice, since it minimizes the need for
people to get creative to work around other proposals, and minimizes the
on-chain footprint, and finally chaperone signatures are my least
preferred option due to its heavy-handed nature and the increased cost.
That is very much how I was planning to implement it anyway, using a
trigger transaction to separate timeout start and the actual
update/settlement pairs (cfr. eltoo paper Section 4.2). So for eltoo
there shouldn't be an issue here :-)
Exactly, why introduce the extra burden of chaperone signatures or
output tagging if we're just going to sidestep it?
While I do agree that we should keep outputs as unidentifiable as
possible, I am starting to question whether that is possible for
off-chain payment networks since we are gossiping about the existence of
channels and binding them to outpoints to prove their existence anyway.
Not the strongest argument I know, but there's little point in talking
ideal cases when we need to weaken that later again. Great, good to know that I'm not shouting into the void, and that I'm
not just that crazy guy trying to get his hairbrained scheme to work :-)
Definitely agreed :+1:

@_date: 2019-10-01 16:26:39
@_author: Christian Decker 
@_subject: [bitcoin-dev] Continuing the discussion about noinput / 
That would certainly be another possibility, which I have not explored
in detail so far. Due to the similarity between the various signature
checking op-codes it felt that it should be a sighash flag, and it
neatly slotted into the already existing flags. If we go for a separate
opcode we might end up reinventing the wheel, and to be honest I feared
that proposing a new opcode would get us into bikeshedding territory
(which I apparently failed to avoid with the sighash flag anyway...).
The advantage would be that with the sighash flag the spender is in
charge of specifying the flags, whereas with an opcode the output
dictates the signature verification modalities. The downside is the
increased design space.
What do others think? Would this be an acceptable opt-in mechanism that
addresses the main concerns?

@_date: 2019-10-03 11:42:00
@_author: Christian Decker 
@_subject: [bitcoin-dev] Continuing the discussion about noinput / 
This is the case in which we don't have a pre-signed settlement
transaction (or in this case refund transaction) that uses a relative
timelock. In order to have a refund transaction we would need to have
the first update and settlement pair be signed before funding (otherwise
the funder isn't sure she is getting her funds back). Since that first
update and settlement pair do not need to be rebound (they can only ever
be bound to the funding transaction) they can be signed without
noinput/anyprevoutanyscript. If we use output tagging we would mandate
that this first update must be published, so that the funding output is
indistinguishable from a normal output, and the first update switches
from non-noinput/anyprevoutanyscript to enabling it. Collaborative
closes are still indistinguishable, unilateral closes require the
switch, but then would be identifiable anyway.
The one downside I can see is that we now mandate that unilateral closes
also publish the first update, which is a bit annoying.
That is true, we do however selectively tell others about the channel's
existence (in invoices, our peers, ...) so I wouldn't consider that to
be the most secret information :-)
As for why they exist: nodes need to have the option of not announcing
their channels to reduce the noise in the network with channels that are
unlikely to be useable in order to forward payments. If every node were
to announce their channels we'd have a much larger routing table, mostly
consisting of unusable channels going to leafs in the
network. Furthermore, the sheer threat that there might be unannounced
channels adds uncertainty for attackers trying to profile nodes: "I see
only my channel with my peer, but he might have unannounced channels, so
I can't really tell whether the payment I forwarded to it is destined
for it or one of its unannounced peers".
Good point, it requires storing the ephemeral data from gossip, that's
not all that hard, but I agree that it puts up a small barrier for

@_date: 2019-10-03 11:57:05
@_author: Christian Decker 
@_subject: [bitcoin-dev] [Lightning-dev] Continuing the discussion about 
Thanks for sharing your concerns Chris, I do agree that noinput and
friends are a very sharp knife that needs to be treated carefully, but
ultimately it's exactly its sharpness that makes it useful :-)
Totally agreed, and as you point out, BIP118 is careful to mandate
separate private keys be used for off-chain contracts and that the
off-chain contract never be mixed with the remainder of your funds. The
way eltoo uses noinput we selectively open us up to replay attacks
(because that's what the update mechanism is after all) by controlling
the way the transactions can be replayed very carefully, and any other
use of noinput would need to make sure to have the same guarantees.
However, once we have separated the two domains, we can simply use a
separate (hardened) derivation path from a seed key, and never mix them
afterwards. We never exchange any private keys, so even leaking info
across derived keys is not an issue here.
This is already the case: off-chain systems always require access to the
signing key in real-time in order to be useful. If any state change is
performed in a channel, even just adjusting fees or receiving a payment,
requires the signature from the key associated with the channel. With
high security on-chain systems on the other hand you should never have a
hot key that automatically signs off on transfers without human
intervention. So I find it unlikely that mandating the on-chain keys to
be kept separate from off-chain keys is any harder than what should be
done with the current systems.
Good point, but if the key hygiene is maintained as detailed in BIP118,
i.e., off-chain keys must be kept separate from on-chain keys, and that
each off-chain contract instance uses a separate set of keys, that
property is maintained.

@_date: 2019-10-03 12:01:58
@_author: Christian Decker 
@_subject: [bitcoin-dev] [Lightning-dev] Continuing the discussion about 
Intriguing idea, this would be an invisible tagging, since the opt-in to
noinput and friends is hidden inside the committed script, which only
gets revealed whenever we actually need it.
For eltoo this would mean that the funding output would be invisibly
tagged, and the cooperative close would use the taproot pubkey, while
the uncooperative close, which would require noinput opt-in, reveals the
script, proving prior opt-in, and provides a matching signature.
If I'm not mistaken this would require AJ's alternative pubkey encoding
(0x01 or 0x00 prefixed pubkey) to make the opt-in visible, correct?

@_date: 2019-10-03 12:30:03
@_author: Christian Decker 
@_subject: [bitcoin-dev] [Lightning-dev] Continuing the discussion about 
In this case I'd hope that the custom wallet designers/developers are
well-versed in the issues they might encounter when implementing their
wallet. This is especially true if they decide to opt into using some
lesser known sighash flags, such as noinput, that come with huge warning
signs (I forgot to mention that renaming noinput to noinput_dangerous is
also still on the table).
It's worth pointing out that the transaction malleability issue and the
introduction of a new sighash flag are fundamentally different: a wallet
developer has to take active measures to guard against transaction
malleability since it was present even for the most minimal
implementation, whereas with sighash flags the developers have to
actively add support for it. Where transaction malleability you just had
to know that it might be an issue, with noinput you actively have to do
work yo expose yourself to it.
I'd argue that you have to have a very compelling reason to opt into
supporting noinput, and that's usually because you want to support a
more complex protocol such as an off-chain contract anyway, at which
point I'd hope you know about the tradeoffs of various sighash flags :-)
I do share the feeling that we better make a commonly used sighash flag
as useable and safe as possible, but it's rather unrealistic to have a
developer that is able to implement a complex off-chain system, but
fails to understand the importance of using the correct sighash flags in
their wallet. That being said, I think this concern would be addressed
by any form of explicit opt-in on the output side (whether hidden or
not), right?

@_date: 2019-10-03 13:08:29
@_author: Christian Decker 
@_subject: [bitcoin-dev] Continuing the discussion about noinput / 
Excellent points, I had missed the hidden nature of the opt-in via
pubkey prefix while reading your proposal. I'm starting to like that
option more and more. In that case we'd only ever be revealing that we
opted into anyprevout when we're revealing the entire script anyway, at
which point all fungibility concerns go out the window anyway.
Would this scheme be extendable to opt into all sighash flags the
outpoint would like to allow (e.g., adding opt-in for sighash_none and
sighash_anyonecanpay as well)? That way the pubkey prefix could act as a
mask for the sighash flags and fail verification if they don't match.
That'd be great, however even that will not ensure that every possible
corner case is handled and from experience it seems that people are
unwilling to invest a lot of time testing on a network unless their
money is on the line. That's not to say that we shouldn't try, we
absolutely should, I'm just not sure it alone is enough to dispell all
remaining doubts :-)

@_date: 2019-09-06 15:18:03
@_author: Christian Decker 
@_subject: [bitcoin-dev] Reconciling the off-chain and on-chain models with 
With the recently published proof-of-concept of eltoo on signet by
Richard, I thought it might a good time to share some thoughts on ho I
think we can build this system. I think there are a few properties of
eltoo that allow us to build a nicely layered protocol stack, which
improves flexibility and simplifies the reasoning about their relative
Since I don't like huge e-mails myself and I'm about to write one,
here's a quick TL;DR:
 Clean separation of protocol layers
One of te big advantages of eltoo over other off-chain update mechanisms
is that it provides strong guarantees regarding the state that will
eventually end up confirmed on-chain. If parties in an eltoo off-chain
contract agree on an update, we can be certain (within eltoo's security
assumptions) that this is the state that will eventually confirm
on-chain, if no newer states are agreed.
In particular it means that we are guaranteed no earlier state can leak
onto the chain, keeping anything we build on top of the update layer
unencumbered since it doesn't have to deal with this case.
This is in stark contrast to the penalty update mechanism, where
old/revoked states can leak on-chain, resulting in anything built on top
of the penalty mechanism having to deal with that eventuality. For
example if we look at HTLCs as specified [1] we see that it needs an
additional revokation path for the case the commitment transaction that
created this HTLC output is confirmed:
# To remote node with revocation key
OP_DUP OP_HASH160  OP_EQUAL
    OP_CHECKSIG
     OP_SWAP OP_SIZE 32 OP_EQUAL
    OP_IF
        # To local node via HTLC-success transaction.
        OP_HASH160  OP_EQUALVERIFY
        2 OP_SWAP  2 OP_CHECKMULTISIG
    OP_ELSE
        # To remote node after timeout.
        OP_DROP  OP_CHECKLOCKTIMEVERIFY OP_DROP
        OP_CHECKSIG
    OP_ENDIF
The update mechanism bleeding into the other layers is rather cumbersome
if you ask me, and complicates the reasoning about security. Having to
thread the penalty through outputs created by the off-chain contract may
also not work if we deal with more than 2 parties, since penalties
always steal all the funds, regardless of whether the output belonged to
the cheater or not (see asymmetry vs symmetry argument from the paper
With the clean separation we get from eltoo we can concentrate on
building the output scripts we'd like to have without having to thread
penalties through them. This reduces the complexity and our on-chain
The update layer now exposes only two very simple operations:
`add_output` and `remove_output` (this should sound very familiar :-p).
 Ownership and atomic update model
Now that we have a solid update layer, which ensures that agreed upon
states will eventually be reflected on-chain, we can turn our attention
to the next layer up: the negotiation layer. Each output in our
agreed-upon state needs to be assigned one or more owners. The owners
are the participants that need to sign off on removal of an output and
the creation of new outputs which redistribute the funds contained in
the removed outputs to newly created outputs.
In addition we need to ensure that multiple `remove_output` and
`add_output` are guaranteed to be applied atomically. By creating a
datastructure that lists a number of operations that are to either be
applied to the current state or discarded, we can have arbitrary complex
changes of ownership, and the newly created outputs can have arbitrary
If all of this sounds familiar that's because this is exactly the UTXO
model and the transaction structure we have in Bitcoin. We
collaboratively manage funds bound to some outputs (UTXO) and can change
their ownership and allocation over time (transactions).
This means that a subset of the participants in an off-chain contract
can negotiate among themselves how to redistribute funds, join and split
them in an arbitrary fashion, without the rest of the contract being
involved. The end result is a valid Bitcoin transaction that spends some
outputs of the current state, and is signed by the owners. The
transaction can then be presented to the entire group, and applied to
the state. Applying the transaction flattens multiple transactions built
on top of the current state into a new state (similar to transaction
cut-through in mimblewimble).
Using transactions as a means to represent off-chain negotiations, and
then applying them to the off-chain state via cut-through has a number
of advantages over similar schemes:
- Even if we failed to update the off-chain state, the transactions
  building on top of it are valid transactions, so once we tear down
  the channel, our negotiated new state can still be reached by
  broadcasting the transaction after settlement (this is basically
  what the channel factory paper [3] was using).
- We can reuse a lot of tools that we have already built for on-chain
  transactions, including things like miniscript and hardware wallets,
  without explicitly requiring them in our own specification. The
  Bitcoin object model is our interface here.
- It allows for experimentation even inside a running eltoo instance. If
  you can find another participant that supports a fancy new protocol,
  you can use that protocol even though some of the other participants
  may not know anything about it. As long as you can understand the
  Bitcoin transaction model you can participate in a multi-party
  channel.
I think this reconciliation between the off-chain model and the on-chain
model, with many concepts cleanly mapping from one context to another
(state outputs = UTXO, off-chain update = on-chain transactions,
cut-through = confirmation, operation batching = block creation) is
rather nice :-)
That should be enough rambling on my side. I'm interested in what others
think about this. Is it completely off, does it make no sense at all, or
is this something we should be looking into going forward?
[1] [2] [3]

@_date: 2019-09-18 15:44:47
@_author: Christian Decker 
@_subject: [bitcoin-dev] [Lightning-dev] Reconciling the off-chain and 
Indeed this is something that I think we already mentioned back in the
duplex micropayment channel days, though it was a bit hidden and only
mentioned HTLCs (though the principle carries over for other structures
built on the raw update mechanism):
Notice that in the case of eltoo the settlement transaction is already
the same as the teardown transaction in DMC.
Indeed this is the first proposal I had back at the Milan spec meeting,
and you are right that it requires stashing the funds in a temporary
co-owned output to make sure the transition once we splice in is
atomic. Batching could help here, if we have 3 participants joining they
can coordinate to set the funds aside together and then splice-in at the
same time. The downside is the added on-chain transaction, and the fact
that the funds are not operational until they reach the required depth
(I don't think we can avoid this with the current security guarantees
provided by Bitcoin). Notice that there is still some uncertainty
regarding the confirmation of the splice-in even though the funds were
stashed ahead of time, and we may end up in a state where we assumed
that the splice-in will succeed, but the fees we attached turn out to be
too low. In this case we built a sandcastle that collapses due to our
foundation being washed away, and we'd have to go back and agree on
re-splicing with corrected fees (which a malicious participant might
sabotage) or hope the splice eventually confirms.
This is the more complex variant we discussed during the last
face-to-face in Australia, and it seemed to me that people were mostly
in favor of doing it this way. It adds complexity since we maintain
multiple variants (making it almost un-implementable in LN-penalty),
however the reduced footprint, and the uncertainty regarding
confirmations in the first solution are strong arguments in favor of
this option.
Aside from a bit more coordination I don't see any roadblocks to do
this, and it'd be an awesome improvement. It even allows sub-dust
transfers between channels, as long as the total funds in the channel
remain above dust :-)
Not necessarily. If we have an escape hatch in the scripts that allows
to spend any output attached to the settlement transaction by n-1
participants we could reclaim these into a new open right away. The
footprint would be 1 unilateral close, n outputs for participants, m
outputs for contracts built on top, and 1 open transaction that
recollects all outputs in which the non-responding participant is not a
co-signer. The main advantage is that we can avoid downtime.
Just spit-balling here, since it'd leak some of the update logic back
into the contracts built on top of the update mechanism, which for me is
enough to discard this idea again.
If we allow generic contracts on top of the base update mechanism it'll
be rather difficult to identify the beneficiary of an update, so it's
hard to know who should pay a fee. I'd rather argue that cooperating is
in the interest of all participants since they'd eventually want to
create an update of their own, and there is no upside to become
Notice that the fees we leverage in LN are because we expose our funds
to the risk of not being available by allocating them to an HTLC, not
for the updates themselves. Since in the forwarding scenario we're only
exposing the funds of the forwarding nodes to this risk it's only
natural that they'd be the ones leveraging a fee, not the other
participants that simply sign off on the change.
Notice that we are negotiating whether or not to apply generic
transactions to a shared state. This also means that there is no direct
relationship between the ownership of an output and the ID signing off
on a change.
The privacy guarantees are identical to Bitcoin on-chain, with the one
caveat that we may identify the proposing participant, but we can defend
against this by mixing as you propose.
We could theoretically play this game, having each participant create
two updates with the same state-number at each update:
 1) A normal one that just keeps them in the contract
 2) A fallback splice all outputs they own (direct ones, HTLCs, ...) and
    putting the rest back into a channel without them.
In case of one user becoming inactive the others can sign the splice,
dropping the inactive participant and continue like nothing
happened. The worst case scenario is that the normal update gets
broadcast and confirmed instead, which means we are back to the
unilateral close that we'd have to do anyway without this mechanism.
Notice however that this only works if participants drop off one by one,
otherwise we get a combinatorial explosion for the fallback cases where
each combination of inactive participants needs to splice themselves
out. It also adds the complexity of having to identify which participant
is the co-owner of an output, otherwise I can claim ownership of an
unrelated output and force that to move on-chain by including it in my
fallback and then becoming unresponsive (added rounds of communication
can help here, but are cumbersome).
It may be a bit much added complexity for a small complexity to be
honest, hopefully this won't be needed too often :-)

@_date: 2019-09-19 12:26:13
@_author: Christian Decker 
@_subject: [bitcoin-dev] [Lightning-dev] Reconciling the off-chain and 
Just to be clear, I do *not* want to support uncooperative splice-outs.
This is due to their need to either pre-sign a splice-out of the party
like I explained further down, or it requires encumbering whatever we
build on top in order to do a fast-reopen.
But I do think there is value in exploring what the options are :-)
That is indeed the issue I explained further down:
Claiming ownership would then involve providing a valid input script
(disregarding any timelocks) that could spend the output under some
condition. Others would have to verify this proof-of-ownership before
accepting the node's self-splice-out before accepting it.
Indeed, that was a weird sentence :-) I did mean that it is a lot of
complexity for very little benefit :-)

@_date: 2019-09-30 15:23:56
@_author: Christian Decker 
@_subject: [bitcoin-dev] Continuing the discussion about noinput / anyprevout 
With the recently renewed interest in eltoo, a proof-of-concept implementation
[1], and the discussions regarding clean abstractions for off-chain protocols
[2,3], I thought it might be time to revisit the `sighash_noinput` proposal
(BIP-118 [4]), and AJ's `bip-anyprevout` proposal [5].
(sorry for the long e-mail. I wanted to give enough context and describe the
various tradeoffs so people don't have to stitch them together from memory. If
you're impatient there are a couple of open questions at the bottom)
Both proposals are ways to allow rebinding of transactions to new outputs, by
adding a sighash flag that excludes the output when signing. This allows the
transaction to be bound to any output, without needing a new signature, as
long as output script and input script are compatible, e.g., the signature
matches the public key specified in the output.
BIP-118 is limited to explaining the details of signature verification, and
omits anything related to deployment and dependency on other proposals. This
was done in order not to depend on bip-taproot which is also in draft-phase
currently, and to allow deployment alongside the next version of segwit
script. `bip-anyprevout` builds on top of BIP-118, adding integration with
`bip-taproot`, chaperone signatures, limits the use of the sighash flag to
script path spends, as well as a new pubkey serialization which uses the first
byte to signal opt-in.
I'd like to stress that both proposals are complementary and not competing,
which is something that I've heard a couple of times.
There remain a couple of unclear points which I hope we can address in the
coming days, to get this thing moving again, and hopefully get a new tool in
our toolbox soon(ish).
In the following I will quote a couple of things that were discussed during
the CoreDev meeting earlier this year, but not everybody could join, and it is
important that we engage the wider community, to get a better picture, and I
think not everybody is up-to-date about the current state.
 Dangers of `sighash_noinput`
An argument I have heard against noinput is that it is slightly less complex
or compute intensive than `sighash_all` signatures, which may encourage wallet
creators to only implement the noinput variant, and use it indiscrimi-
nately. This is certainly a good argument, and indeed we have seen at least
one developer proposing to use noinput for all transactions to discourage
address reuse.
This was also mentioned at CoreDev [6]:
Another issue that is sometimes brought up is that an external user may
attempt to send funds to a script that was really part of a higher-level
protocol. This leads to those funds becoming inaccessible unless you gather
all the participants and sign off on those funds. I don't believe this is
anything new, and if users really want to shoot themselves in the foot and
send funds to random addresses they fish out of a blockexplorer there's little
we can do. What we could do is make the scripts used internally in our
protocols unaddressable (see output tagging below), removing this issue
 Chaperone signatures
Chaperone signatures are signatures that ensure that there is no third-party
malleability of transactions. The idea is to have an additional signature,
that doesn't use noinput, or any of its variants, and therefore needs to be
authored by one of the pubkeys in the output script, i.e., one or more of the
participants of the contract the transaction belongs to. Concretely in eltoo
we'd be using a shared key known to all participants in the eltoo instance, so
any participant can sign an update to rebind it to the desired output.
Chaperone signatures have a number of downsides however:
-   Additional size: both the public key and the signature actually need to be
    stored along with the real noinput signature, resulting in transfer,
    computational and storage overhead. We can't reuse the same pubkey from the
    noinput signature since that'd require access to the matching privkey which
    is what we want to get rid of using noinput in the first place.
-   Protocols can still simply use a globally known privkey, voiding the
    benefit of chaperone signatures, since third-parties can sign again. I
    argue that third-party malleability is a subset of first-party
    malleability, and we should protect against first-party malleability first
    and foremost. My counterparty has the incentive to trick me, a third-party
    may not.
On the plus side chaperone signatures certainly address the lazy-wallet-dev
scenario, and as AJ points out in [bip-anyprevout] we get back the same
security guarantees as we had without noinput.
by the way), there was no strong support for chaperone signatures during the
meeting [6], but feedback from people that were not present is needed:
 Output tagging
One proposal that I found rather fascinating during the discussion in
Amsterdam was that we could achieve the same disincentive to use on
non-smart-contract cases by simply making the output scripts
unaddressable. This can be done by specifying a version of taproot outputs for
which the bech32 addressing scheme simply doesn't have a representation [6]:
We don't need addresses in our contract constructions because we deal directly
with the scripts. This would also have the desired effect of no allowing
generic wallets to send to these addresses, or users accidentally sending
funds to what was supposed to be a one-off script used internally in the
off-chain contract.
Notice that this idea was already used by Russell O'Connor when performing a
transaction on elements using his new scripting language simplicity
The concern with output tagging is that it hurts fungibility, marking outputs
used in a contract as such and making them identifiable. But maybe it would be
a good idea to create two domains anyway: one for user-addressable
destinations which users can use with their general purpose wallets, and one
domain for contracts, which users cannot send to directly.
This also came up during the CoreDev meeting [ams-coredev]:
 Open questions
The questions that remain to be addressed are the following:
1.  General agreement on the usefulness of noinput / anyprevoutanyscript /
    anyprevout. While at the CoreDev meeting I think everybody agreed that
    these proposals a useful, also beyond eltoo, not everybody could be
    there. I'd therefore like to elicit some feedback from the wider community.
2.  Is there strong support or opposition to the chaperone signatures
    introduced in anyprevout / anyprevoutanyscript? I think it'd be best to
    formulate a concrete set of pros and contras, rather than talk about
    abstract dangers or advantages.
3.  The same for output tagging / explicit opt-in. What are the advantages and
    disadvantages?
4.  Shall we merge BIP-118 and bip-anyprevout. This would likely reduce the
    confusion and make for simpler discussions in the end.
5.  Anything I forgot to mention :-)
[1] [2] [3] [4] [5] [6] [7]

@_date: 2020-08-04 12:38:20
@_author: Christian Decker 
@_subject: [bitcoin-dev] BIP 118 and SIGHASH_ANYPREVOUT 
This is indeed part of the reason why we chose to describe the protocol
on-chain first in the paper and lift it off-chain after showing the
basic functionality. This means that the protocol is still correct even
if executed solely on information derived from blocks and confirmed
transactions in those blocks. The timeouts have to be chosen carefully
to allow reacting in a timely fashion, however that is true for all
off-chain protocols.
Correct, it might be desirable to give a misbehaving node a papercut by
letting their update transaction confirm (taking their fee along with
it) and then reacting to the outdated update by overriding the effects
with a new update-settlement pair.
So, while being able to react to a transaction in the memory pool early
might be a nice addition, it is not strictly required for safety of the
protocol. I say nice addition, because it can allow replacing the
outdated transaction directly, thus saving the misbehaving node from the
fee papercut, but also save a bit of blockspace which that fee would
have paid for, and leave it available for other transactions.

@_date: 2020-07-10 09:46:54
@_author: Christian Decker 
@_subject: [bitcoin-dev] BIP 118 and SIGHASH_ANYPREVOUT 
No worries, it's a common character twist I find myself doing from time to
time :-)
On Fri, 10 Jul 2020, 00:31 Anthony Towns via bitcoin-dev <

@_date: 2020-03-26 18:12:44
@_author: Christian Decker 
@_subject: [bitcoin-dev] Statechain implementations 
Ruben Somsen via bitcoin-dev It might be worth adopting the late fee binding we have in eltoo by
having the kickoff transaction input spending the funding tx signed with
sighash_single. This works because we only have 1 input and 1 output
that we really care about, and can allow others to attach fees at
will. That'd at least remove the need to guess the feerate days or
months in advance and thus having to overestimate.  Wouldn't that result in a changing pubkey at each update, and thus
require an onchain move to be committed?
That'd indeed be great :-)
