
@_date: 2014-04-21 14:58:45
@_author: Rodney Morris 
@_subject: [Bitcoin-development] Mailing list abuse 
What is the procedure for dealing with it? Is it considered abuse to reply
to and quote the entire digest for the sake of a few lines of content? Am I
the only one annoyed by this (if so I'll just shut right up).

@_date: 2014-04-21 16:02:21
@_author: Rodney Morris 
@_subject: [Bitcoin-development] Mailing list abuse 
Not a bad idea. Semantics of the word abuse not withstanding.
I don't want to become the self appointed mailing list cop, but I notice it
maybe more than others because I almost exclusively read this mailing list
on a mobile device. Hence my asking for feedback without publicly calling
anyone out.
Thanks for taking the time to reply.

@_date: 2015-08-17 21:57:47
@_author: Rodney Morris 
@_subject: [bitcoin-dev] Dynamically Controlled Bitcoin Block Size Max Cap 
Words cannot capture how much I wish Satoshi had put logic like this (or
even just a simple block size doubling every reward halving) in place when
he put in the "temporary" 1MB anti-spam block size limit...
I see problems to this approach.  The biggest one I see is that a miner
with 11% of hash power could sabotage block size increases by only ever
mining empty blocks.
I haven't run any statistics or simulations, but I'm concerned that the
interplay between the random distribution of transaction arrival and the
random distribution of block times may lead to false signals.
A 90% full block 1 minute after the previous block is a more "serious"
problem than a 90% full block 30 minutes after the previous block.  A 90%
full block after a 90% full block is a more "serious" problem than a 90%
full block after an empty block.
I would expect a robust approach in this manner to look at block sizes
weighted by block times, but this is an interesting proposal regardless.
But I think you'll run up against one of the great schisms in this debate -
those that believe blocks should always be full (or close to it), to
encourage a "fee market" and to encourage off-chain transactions, and those
that think that the blockchain should be useable by almost anyone for
almost anything, implying there should always be spare space in blocks,
with off-chain transactions reserved for microtransactions and zero-conf
(and possibly low-fee transactions).  At least, that's my take on it.

@_date: 2017-04-01 12:41:58
@_author: Rodney Morris 
@_subject: [bitcoin-dev] Hard fork proposal from last week's meeting 
I didn't say typical, I said every. Currently a raspberry pi on shitty adsl
can run a full node. What's wrong with needing a high end pc and good
connectivity to run a full node?
People that want to, can. People that don't want to, won't, no matter how
low spec the machine you need.
If nobody uses bitcoin, all the security in the world provides no value.
The value of bitcoin is provided by people using bitcoin, and people will
only use bitcoin if it provides value to them.  Security is one aspect
only. And the failure to understand that is what has led to the block size
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
The cause of the block size debate is the failure to understand the
Bitcoin security model. This failure is perfectly exemplified by the
above statement. If a typical personal computer cannot run a node
there is no security.

@_date: 2017-08-23 08:58:54
@_author: Rodney Morris 
@_subject: [bitcoin-dev] UTXO growth scaling solution proposal 
Thomas et.al.
So, in your minds, anyone who locked up coins using CLTV for their child to
receive on their 21st birthday, for the sake of argument, has effectively
forfeit those coins after the fact?  You are going to force anyone who took
coins offline (cryptosteel, paper, doesn't matter) to bring those coins
back online, with the inherent security risks?
In my mind, the only sane way to even begin discussing an approach
implementing such a thing - where coins "expire" after X years - would be
to give the entire ecosystem X*N years warning, where N > 1.5.  I'd also
suggest X would need to be closer to the life span of a human than zero.
Mind you, I'd suggest this "feature" would need to be coded and deployed as
a future-hard-fork X*N years ahead of time.  A-la Satoshi's blog post
regarding increasing block size limit, a good enough approximation would be
to add a block height check to the code that approximates X*N years, based
on 10 minute blocks.  The transparency around such a change would need to
be radical and absolute.
I'd also suggest that, similar to CLTV, it only makes sense to discuss
creating a "never expire" transaction output, if such a feature were being
seriously considered.
If you think discussions around a block size increase were difficult, then
we'll need a new word to describe the challenges and vitriol that would
arise in arguments that will follow this discussion should it be seriously
proposed, IMHO.
I also don't think it's reasonable to conflate the discussion herein with
discussion about what to do when ECC or SHA256 is broken.  The
weakening/breaking of ECC poses a real risk to the stability of Bitcoin -
the possible release of Satoshi's stash being the most obvious example -
and what to do about that will require serious consideration when the time
comes.  Even if the end result is the same - that coins older than "X" will
be invalidated - everything else important about the scenarios are
different as far as I can see.

@_date: 2017-04-01 08:23:01
@_author: Rodney Morris 
@_subject: [bitcoin-dev] Hard fork proposal from last week's meeting 
You guessed wrong. Multiple data centres are as much about redundancy and
resiliency, and latency.
As for the cost, data centre space, business grade communication lines, and
staff are orders of magnitude more expensive than the physical hardware
they support.
I'd like to call you out on your continuing reduction to absurdity and
slippery slope arguments. Just because we can't handle 4GB blocks today,
doesn't mean we shouldn't aim in that direction. Doesn't mean we shouldn't
be taking our first second and third baby steps in that direction.
If the obsession with every personal computer being able to run a fill node
continues then bitcoin will be consigned to the dustbin of history, a
footnote to the story of the global crypto currency that eventually took
over the world.
Then explain why PayPal has multiple datacenters. And why Visa has multiple
datacenters. And why the banking systems have multiple datacenters each.
I'm guessing it's because you need that much juice to run a global payment
system at the transaction volumes that they run at.
Unless you have professional experience working directly with transaction
processors handling tens of millions of financial transactions per day, I
think we can fully discount your assessment that it would be a rounding
error in the budget of a major exchange or Bitcoin processor to handle that
much load. And even if it was, it wouldn't matter because it's extremely
important to Bitcoin's security that it's everyday users are able to and
are actively running full nodes.
I'm not going to take the time to refute everything you've been saying but
I will say that most of your comments have demonstrated a similar level of
ignorance as the one above.
This whole thread has been absurdly low quality.
