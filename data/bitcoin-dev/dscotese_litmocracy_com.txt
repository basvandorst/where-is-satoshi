
@_date: 2015-08-02 15:07:22
@_author: Dave Scotese 
@_subject: [bitcoin-dev] A compromise between BIP101 and Pieter's proposal 
It will help to assume that there is at least one group of evil people who
are investing in Bitcon's demise.  Not because there are, but because there
might be.  So let's assume they are making a set of a billion transactions,
or a trillion, and maintaining currently-being-legitimately-used hashing
power.  When block size is large enough to frustrate other miners, this
hash power (or some piece of it) will be experimentally shifted to solving
a block containing an internally consistent subset of the prepared
trasnsactions to fill it - experimentally at first, but on the active
Bitcoin network.  One seemingly random, bloated, useless (except for the
universal timestamp) block will be created and the evil group will measure
the effect on the mining community - client takedowns, market exits, and
whatever else interests them.  Then they lie in wait, perhaps let out one
more to do another experiment, but with the goal of eventually catching us
unawares and doing as much damage to morale as possible.
Good concrete descriptions of the threats against which we want to guard
will be very helpful.  Maybe there are already unit tests for such things
or requests for miners' reactions to them (as opposed to just the
software's behavior).  My description might be a bit too long and perhaps
not a very good example, but do we have a place where such examples can be
While we will do our best to guard against such nightmares, it's also
helpful to imagine what we will do if and when one of them ever actually
occurs.  Yes, I'm paranoid; because those who like to control everything
are losing it.
On Sun, Aug 2, 2015 at 3:38 AM, Venzen Khaosan via bitcoin-dev <

@_date: 2015-08-06 16:26:47
@_author: Dave Scotese 
@_subject: [bitcoin-dev]  Wrapping up the block size debate with voting 
"Miners can do this unilaterally" maybe, if they are a closed group, based
on the 51% rule. But aren't they using full nodes for propagation?  In this
sense, anyone can vote by coding.
If and when we need to vote, a pair-wise runoff ("condorcet method") will
find an option that is championed by a majority over each other option.
There may not be any such option, in which case no change would make the
most sense.
The voting proposal has several appeals to authority (which no one has)
like "People with certain amount of contribution" and "Exchanges operated
for at least 1 year with 100,000BTC 30-day volume may also apply": who
decided what amount or whether or not the application is approved?  It also
doesn't specify how many btc equates to one vote.
I think we should wrap up the endless debate with voting by different
stakeholder groups.
which are ready to merge immediately. They must first go through the usual
peer review process and get approved by the developers in a technical
standpoint, without political or philosophical considerations. Any fine
tune of a candidate proposal may not become an independent candidate,
unless it introduces some ?real? difference. ?No change? is also one of the
voting options.
independently. (The time frames mentioned below are just for example.)
eligible to vote. One block one vote. Miners will cast their votes by
signing with the bitcoin address in coinbase. If there are multiple
coinbase outputs, the vote is discounted by output value / total coinbase
output value.
digitally sign their votes. In case there is any dispute, the digitally
signed vote will be counted.
early September) are eligible to vote. The total ?balance? of each
scriptPubKey is calculated and this is the weight of the vote. People will
cast their votes by digital signature.
to vote in general. May be judged case-by-case
in Bitcoin Core or other open sources wallet / alternative implementations.
One person one vote.
Winkdex, or NYSE Bitcoin index, with 30 days volume >100,000BTC are
invited. This includes Bitfinex, BTC China, BitStamp, BTC-E, itBit, OKCoin,
Huobi, Coinbase. Exchanges operated for at least 1 year with 100,000BTC
30-day volume may also apply to be a voter in this category. One exchange
one vote.
accepting business that is not centralized fiat-currency exchange, e.g.
virtual or physical stores, gambling sites, online wallet service, payment
processors like Bitpay, decentralized exchange like Localbitcoin, ETF
operators like Secondmarket Bitcoin Investment Trust. They must directly
process bitcoin without relying on third party. They should process at
least 100BTC in the last 30-days. One merchant one vote.
(1 week) in July 2015 are eligible to vote, determined by the log of
Bitnodes. Time is set in the past to avoid manipulation. One IP address one
vote. Vote must be sent from the node?s IP address.
 Voters are
required to rank their preference with ?1?, ?2?, ?3?, etc, or use ?N? to
indicate rejection of a candidate.
fewest votes is eliminated and those votes are transferred according to
their second choice. This process repeats until only one candidate is left,
which is the most popular candidate. The result is presented as the
approval rate: final votes for the most popular candidate / all valid votes
process is repeated by eliminating this candidate, which will find the
approval rate for the second most popular candidate. The process repeats
until all proposals are ranked with the approval rate calculated.
approval rate. However, ranking is more important than the approval rate,
unless the difference in approval rate is really huge. 90% support would be
excellent; 70% is good; 50% is marginal; <50% is failed.
the easiest. We need a trusted person to verify the voters? identity by
email, website, or digital signature. The trusted person will collect votes
and publish the named votes so anyone could verify the results.
interface to vote. The votes with IP address will be published.
automatic system to collect and count the votes. If people are worrying
about reduced security due to exposed raw public key, they should move
their bitcoin to a new address before voting.
after voting, especially for anonymous voters like bitcoin holders and solo
miners. A double voting attempt from these classes will invalidate all
related votes.
I believe they should be allowed to vote in all applicable categories since
they are contributing more than other people.

@_date: 2015-08-08 09:54:04
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Fwd: Block size following technological growth 
Bitcoin is an irreversible payment system.  When you pay someone using its
main selling point, which is removing the need for physical presence, you
are trusting that person.  Bitcoin doesn't obviate trust.  It obviates
authority.  Centralization of trust is what creates the authority that we
all recognize as bad for our species.  It does this by making the
authority's use of coercion acceptable.
Bitcoin removes the need for authority, not trust.  It replaces trust in a
single body with trust in a majority.  We want that majority to be healthy
and varied (as opposed to largely co-opted by some authority). The
replacement has two effects.  1) It is very difficult for any single body
to become the (coercive) authority that everyone has to trust (like central
banks). 2) It is very easy for a person to find a different single body to
trust if they don't like the one they are trusting now - or even stop
trusting one body and trust the majority instead, relying on  for
protection, and taking on the responsibility of running a full node.
The philosophical foundation of a thing is ultimately the basis of its
value, so I thought it useful to point out the distinction between
authority and trust in the bitcoin ecosystem.  I welcome disagreements with
my philosophical position, as that is how I learn.
On Fri, Aug 7, 2015 at 3:53 PM, Adam Back via bitcoin-dev <

@_date: 2015-08-08 15:45:28
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Fees and the block-finding process 
I see value in lowering the block size or leaving it where it is. We expect
to run out of space, and I think it's a good idea to prepare for that,
rather than avoid it.  When we run out of space and the block size is low,
we will see problems.  If we raise the block size, we will NOT see these
problems until bitcoin is bigger and more important and the pressure is
Someone mentioned that when the backlog grows faster than it shrinks, that
is a real problem.  I don't think it is.  It is a problem for those who
don't wait for even one confirmation, but backlogs in the past have already
started training users to wait for at least one confirmation, or go
off-chain.  I am comfortable leaving those zero-conf people in a little bit
of trouble.  Everyone else can double-spend (perhaps that's not as easy as
it should be in bitcoin core) and use a higher fee, thus competing for
block space.  Yes, $5 transactions suck, but $0.15 is not so bad and about
twice the average right now.
Meanwhile, the higher fees everyone starts feeling like paying, along with
the visibility of the problems caused by full-blocks, will provide
excellent justification and motivation for increasing the limit.  My
favorite thing to do is to have a solution ready for a problem I expect to
see, see the problem (so I can measure things about it) and then implement
the solution.
In my experience, the single biggest reason not to run a full node has to
do with starting from scratch: "I used to run a full node, but last time I
had to download the full blockchain, it took ___ days, so I just use (some
wallet) now."  I think that has been improved with headers-first, but many
people don't know it.
I have some ideas how a "full node" could postpone being "full" but still
be nearly completely operational so that the delay between startup and
having a full blockchain is nearly painless.  It involves bonded
representation of important not-so-large pieces of data (blocks that have
my transactions, the complete UTXO as of some height, etc.).  If I know
that I have some btc, I could offer it (say, 100 or 1000 transaction fees'
worth) to anyone who will guarantee good data to me, and then when I have
the whole blockchain, I will know if they were honest.  If done right, the
whole network could know whether or not they were honest and enforce the
bond if they weren't.  Credit the Lightening paper for parts of this idea.
On Fri, Aug 7, 2015 at 4:06 PM, Adam Back via bitcoin-dev <

@_date: 2015-08-09 13:43:48
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Fees and the block-finding process 
On Sun, Aug 9, 2015 at 3:42 AM, Thomas Zander via bitcoin-dev <
That is a real problem then.  While emptying the mempool faster with bigger
blocks will help to reduce the occurrence of that problem, I propose a
user-configurable default limit to the size of the mempool as a permanent
solution regardless of block size.  "This software has stopped consuming
memory necessary to validate transactions.  You can override this by ..."
If anyone feels that protecting those running full nodes from bitcoind
eating more and more memory this way is a good idea, I can make a BIP out
of it if that would help.
I concluded that because I don't think I'm all that different than others,
and that is what I have done.  The "training" of which I speak is not
always recognized by the bitcoiner on whom it operates.  A similar
"training" is how we all learn to ignore teachers because governments force
our attendance at school.
I don't know what you meant to say is false.  I agree with the other stuff
you wrote.  Thanks for confirming that it is difficult.
I did some research on replace by fee (FSS-RBF) and on
Child-pays-for-parent (CPFP).  You point out that these solutions to paying
too-low fees are "not supported in the vast majority...".  Do you mean
philosophically or programmatically?  The trend seems to me toward
improvements, just as I insinuated may be necessary ("perhaps that's not as
easy as it should be in bitcoin core"), so, once again, I have to reiterate
that transaction backlog has valuable solutions other than increasing the
block size.
I also realized that we have already been through a period of full blocks,
so that tremendously reduces the value I see in doing it again.  It was
that "spam" test someone ran that did it for us, and I love that.  It seems
to have kicked the fee-increasability efforts in the butt, which is great.
I now place a higher priority on enabling senders to increase their fee
when necessary than on increasing the Txns per second that the network can
handle.  The competition between these two is rather unfair because of how
easy it is to apply the "N MB-blocks bandaid".

@_date: 2015-08-17 21:37:44
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Annoucing Not-BitcoinXT 
Three things:
1) Hostility is generally the result of perceived hostility.  If you assume
the best intentions of another person, you will eventually find yourself in
one of two places.  Either you will find truth with that person (becuase
they are also seeking it), or you will drive them away (because you will
ask questions that can't be answered by someone trying to deceive).
2) The Wiki says "The current Core developers are Wladimir J. van der Laan,
Gavin Andresen, Jeff Garzik, Gregory Maxwell, and Pieter Wuille."  I've
seen no hostility from any of these people.
3) The people who are threatened by Bitcoin aren't stupid enough to ignore
  Can anyone imagine that they have not hired highly skilled
psychological warfare agnts to do everything they can to "help" assault
what we decentralization enthusiasts have been working for?
About  I'm actually blind to hostility, and that is an intentional
affectation in response to my recognition of  and  together.  If you
feel another person has expressed a bad idea, just ignore it.  If you feel
they might be misleading others, post a reply about what you know to clear
up any possible misconceptions.  There is no point in identifying
individuals who are being hostile, or pointing out hostility, or being
divisive.  Let the rest of us recognize it on our own.  Maybe send
something like what I'm writing now.
PS: If anyone is interested in conspiracy theories, I had written this into
my gmail compose window and (presumably) hit a wrong key which caused the
thread to be marked as spam and deleted my whole reply.  It hadn't even
saved a draft.  I've never seen gmail not save a draft before.
On Mon, Aug 17, 2015 at 9:55 AM, Eric Lombrozo via bitcoin-dev <

@_date: 2015-08-17 21:56:47
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Bitcoin XT Fork 
section 200.3(c)(2) lists "consumers that utilize Virtual Currency solely
for the purchase or sale of goods or services or for investment purposes"
as "Persons [who] are exempt from the licensing requirements".
Who else is left?
On Mon, Aug 17, 2015 at 1:24 PM, Theo Chino via bitcoin-dev <

@_date: 2015-08-17 22:33:45
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Annoucing Not-BitcoinXT 
check out the  podcast in higher education on podomatic.com, you may find
that it's more awareness than paranoia.  There are other resources too,
like GnosticMedia, SchoolSucksProject, and Corbett Report.  These programs
are not addressing bitcoin specifically or even generally.  They simply
show that people with high intelligence do not always have the best
interests of the rest of their species in mind when they engineer
solutions.  For example, taxation is a form of parasitic human cannibalism,
not in the eating of flesh, but in the consuming of life force.  The
methods of farming humans to tolerate such a system are quite advanced.
Learning is the answer.  Defend yourself for the sake of everyone else.

@_date: 2015-08-19 16:16:27
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Separated bitcoin-consensus mailing list (was Re: 
I guess every mailing list should have its own internal SNR discussions.
My answer is to respond when something is off-topic and offer a different
place for the topic.  I haven't been doing that, partly because no one else
has, but mostly because I figured I don't have a strong handle on what is
off-topic and what isn't.  Let's all start doing that.  Of course, someone
can object to the claim, "No, I don't think this is off-topic... blah blah
blah," and people can respond.  The norms will develop.  It just requires
some relative humility, courage, and honesty.
On Wed, Aug 19, 2015 at 12:28 PM, Warren Togami Jr. via bitcoin-dev <

@_date: 2015-08-27 12:42:50
@_author: Dave Scotese 
@_subject: [bitcoin-dev] BIPS proposal for implementing AML-KYC in bitcoin 
You write about OFAC, KYC, and AML.
The *Office of Foreign Assets Control* (*OFAC*) is a financial intelligence
 and enforcement
agency of the U.S. government charged with planning and execution of
economic and trade sanctions
 in support of U.S. national
and foreign
policy KYC means "Know Your Customer" which is something every intelligent
businessman does when his deals are significant.  Support for "KYC" is
built into reality and needs no qualification, compliance, or control.
AML means "Anti-Money-Laundering" which smacks of overreach.  Laundering
money serves to hide behaviors that authorities dislike, many of which are
actually helping the world.  Neomoney says it best
: "Indeed, money laundering describes a wide
range of activities that are undertaken by innocent participants in the
economy. Authorities? growing expectation of a right to violate our privacy
to enforce their laws, and an expectation that we do nothing to protect
ourselves from that violation of privacy, lie at the heart of money
laundering propaganda."
So your work comes across as that of someone who has been duped into doing
the bidding of the largest and most successful criminal organization on
Earth.  I do not accuse you of being deceived because no one can be blamed
for the damage done to them by such a powerful parasite.  I wish only to
open your eyes, or, at least what worked for me, your ears

@_date: 2015-08-30 11:10:39
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Proof of Work algorithm vs mining centralization 
Before miners get angry, consider that whatever the community does will
attempt to preserve the efforts you have made to make Bitcoin a success.
Paragraph five, below, includes a provision to protect you, so please don't
write me off.
The competition is essential to protecting the data in the blockchain.  I
worry that any time (eg all time so far) the rules of that competition
remain static, a group of people willing to develop and optimize hardware
that performs the work will form, and their products will find a following
- the miners.  These miners and hardware producers will advance the
technology until the cost of competing in the space is so high that mining
bitcoin is, for all practical purposes, centralized.
I propose that the proof of work algorithm be scheduled to change
periodically.  The current definition is pretty simple and there's no
reason not to continue using simple definitions.  We could develop a list
of hash algorithms which could be indexed so that the first few bits of the
difficulty-change block's hash (or even *every* block's hash) could be used
to select one to be used for the next block.  The principle is to
discourage specialization of hardware designed for what we must admit is an
arbitrary computing exercise, intended only to enable competition.
Of course chip designers could start working on hardware that can handle
all the algorithms defined, but the protocol can also warn them that from
time to time, the community will alter the content of the list of hash
algorithms, specifically to ensure that *general purpose *computing
machines (ie, what the average tech aficionado will have) is the best
device for mining bitcoin.
If such a variable PoW were to be used, I recommend that most of the
elements in the initial list of algorithms be the current PoW algorithm so
that most blocks can be solved by the existing mining community, and only
one every now and then will be available to everyone else.  Over time, that
ratio would fall, giving the miners time to convert their expertise into
more productive activities.
I refer you to the stories at the beginning of each chapter of Douglas
G?del, Escher, Bach: an Eternal Golden Braid, a few of which describe a
competition between a record-player-making tortoise and Achilles, who works
on making records that break the record players.  It offers some through
provoking musings that can easily be related to this thing Satoshi made.

@_date: 2015-12-02 21:52:20
@_author: Dave Scotese 
@_subject: [bitcoin-dev] [BIP Draft] Datastream compression of Blocks and 
Emin's email presents to me the idea of dictionaries that already contain
the data we'd want to compress.  With 8 bytes of indexing data, we can
refer to a TxID or a Public Key or any existing part of the blockchain.
There are also data sequences like scripts that contain a few variable
chunks and are otherwise identical.  Often, the receiver has the
blockchain, which contains a lot of the data that is in the message being
First, the receiver must indicate that compressed data is preferred and the
height of latest valid block it holds, and the sender must express the
ability to send compressed data.  From this state, the sender sends
messages that are compressed.  Compressed messages are the same as
uncompressed messages except that:
   1. Data read is copied into the decompressed message until the first
   occurrence of 0x00, which is discarded and is followed by compressed data.
   2. Compressed data can use as a dictionary the first 16,777,215 blocks,
   or the last 4,244,635,647 ending with the block at the tip of the
   receiver's chain, or it can specify a run of zero bytes.  The sender and
   receiver must agree on the *receiver's* current block height in order to
   use the last 4B blocks as the dictionary.
   3. Within compressed data, the first byte identifies how to decompress:
      1. 0xFF indicates that the following three bytes are a block height
      with most significant byte 0x00 in network byte order.
      2. 0xFE indicates that the following byte indicates how many zero
      bytes to add to the decompressed data.
      3. 0xFD is an error, so compressed messages are turned off and the
      recipient fails the decompression process.
      4. 0x00 indicates that the zero byte by itself should be added to the
      decompressed data, and the data following is not compressed
(return to step
      1).
      5. All other values represent the most significant byte of a number
      to be subtracted from the receiver's current block height to identify a
      block height (not available until there are least 16,777,216
blocks so that
      this byte can be at least 0x01, since 0x00 would indicate a single zero
      byte, end compressed data, and return to step 1).
   4. If decompression has identified a block height (previous byte was not
   0xFD, 0x00, or 0xFE), then the next four bytes identify a *size *(one
   byte) and a byte index into the block's data (three bytes), and *size *bytes
   from that block are added to the decompressed data.
   5. Steps 3 and 4 process a chunk of compressed data.  If the next byte
   is 0xFD, then decompression goes back to step 1 (add raw bytes until it
   hits a 0x00).  Otherwise, it proceeds through steps 3 (and maybe 4) again.
In Step 3.3, 0xFD causes an error, but it could be used to indicate a
parameterized dictionary entry, for example 0xFD, 0x01 followed by eight
more bytes to be interpreted according to steps 3.1 or 3.5 could mean
OP_DUP OP_HASH160 (20 bytes from the blockchain dictionary) OP_EQUALVERIFY
OP_CHECKSIG, replacing that very common occurrence of 24 bytes with 10
bytes.  Well, 11 if you include the 0x00 required by step5.  But that only
works on addresses that have spent inputs.  Or 0xFD, 0x02 could be
shorthand for the four zeroes of lock_time, followed by Version (1),
followed by 0x01 (for one-input transactions), turning nine bytes into two
for the data at the end of a normal (lock_time = 0) Txn and the beginning
of a single-input Txn.  But I left 0xFD as an error because those gains
didn't seem as frequent as the others.
On Wed, Dec 2, 2015 at 3:05 PM, Peter Tschipper via bitcoin-dev <

@_date: 2015-12-09 20:08:04
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Scaling by Partitioning 
If we partition the work using bits from the TxID (once it is no longer
malleable) or even bits from whatever definition we use for "coin," then
every transaction may have to use all the other partitions to verify that
the incoming coin is good.
If all partitions are involved in validating and storing every transaction,
then we may be doing more work in total, but any one node will only have to
do (and store) a fraction of what it is now.  We would want the current
situation to be identical to one in which all the participants are handling
all the partitions.  So how can we break up the work so that any
participant can handle whatever fraction of the work he or she wants?  One
idea is to use the last bits of the address that will receive the subsidy
and fees.  You solve the block for your partition by determining that all
transactions in the block are valid against the subset of blocks whose
hashes end with the same bits.
This solution is broadcast in the hope that others will start attempting to
validate that same block on their own partition. If they are mining the
same partition, they simply change their subsidy address to work on a
different partition.  Each time a new-but-not-last partition is solved,
everyone working on the block adds the new solver's output address to their
generation transaction with the appropriate fraction of the
reward-plus-subsidy.  In this way, several miners contribute to the
solution of a single block and need only store those blocks that match the
partitions they want to work on.
Suppose we use eight bits so that there are 256 partitions and a miner
wishes to do about 1/5 of the work. That would be 51 partitions.  This is
signaled in the generation transaction, where the bit-pattern of the last
byte of the public key identifies the first partition, and the proportion
of the total reward for the block (51/256) indicates how many partitions a
solution will cover.
Suppose that the last byte of the subsidy address is 0xF0.  This means
there are only 16 partitions left, so we define partition selection to wrap
around.  This 51/256 miner must cover partitions 0xF0 - 0xFF and 0x00 -
0x23. In this way, all mining to date has covered all partitions.
The number of bits to be used might be able to be abstracted out to a
certain level.  Perhaps a miner can indicate how many bits B the
partitioning should use in the CoinBase. The blocks for which a partition
miner claims responsibility are all those with a bit pattern of length B at
the end of their hash matching the the bits at the end of the first
output's public key in the generation transaction, as well as those blocks
with hashes for which the last B bits match any of the next N bit patterns
where for the largest integer N for which the claimed output is not less
than (subsidy+fees)*(N/(2^B)).
If you only store and validate against one partition, and that partition
has a solution already, then you would start working on the next block
(once you've validated the current one against your subset of the
blockchain).  You could even broadcast a solution for that next block
before the previous block is fully solved, thus claiming a piece of the
next block reward (assuming the current block is valid on all partitions).
It seems that a miner who covers only one partition will be at a serious
disadvantage, but as the rate of incoming transactions increases, the
fraction of time he must spend validating (being about half of all other
miners who cover just one more partition) makes up for this disadvantage
somewhat.  He is a "spry" miner and therefore wins more rewards during
times of very dense transaction volume.  If we wish to encourage miners to
work on smaller partitions, we can provide a difficulty break for smaller
fractions of the work.  In fact, the difficulty can be adjusted down for
the first solution, and then slowly back up to full for the last
This proposal has the added benefit of encouraging the assembly of blocks
by miners who work on single partitions to get them out there with a
one-partition solution.
On Wed, Dec 9, 2015 at 2:35 PM, Andrew via bitcoin-dev <

@_date: 2015-12-09 20:14:17
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Scaling by Partitioning 
"... as well as those blocks with hashes for which the last B bits match
any of the next N bit patterns where *N is largest* integer for which the
claimed output is not *greater* than (subsidy+fees)*(N/(2^B)).
On Wed, Dec 9, 2015 at 8:08 PM, Dave Scotese

@_date: 2015-12-16 22:12:41
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Block size: It's economics & user preparation & 
On Wed, Dec 16, 2015 at 1:11 PM, Pieter Wuille via bitcoin-dev <
I'm not a core dev, so maybe I have the power to change the consensus
rules.  No one has that power, actually, at least not legitimately.  All we
can do is build it and hope enough people find it acceptable to adopt.  Who
doesn't want to hard fork to 2MB blocks on May 5th and why not?
I have a bitcoin to be split up among all those who suffer from a May 5,
2016 hardfork to 2MB blocks if they can prove it to me, or prove it to
enough engineers that I succumb to peer pressure.  I would have to respect
the engineers though.
Now that we've agreed to have a hard fork on May 5th, 2016, we might decide
to implement some other methods of avoiding the FFM, like braiding the
blockchain or flexcap, or just let anyone mining on top of a block make one
that is a five or ten Kb larger.
On Wed, Dec 16, 2015 at 2:27 PM, Jeff Garzik via bitcoin-dev <

@_date: 2015-12-19 11:04:01
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Block size: It's economics & user preparation & 
I've already publicly declared that I offer one bitcoin to "those who
suffer from a May 5, 2016 hardfork to 2MB blocks" but that's probably way
too sloppy.  Here's a better idea that transmits the economic power of
merchants and customers (well, anyone with bitcoin) to the miners on whom
they must rely for confirmations:
The bitcoin I offer is part of a fund that, when it reaches 25 BTC, will be
pledged to a miner.  Here is how that miner earns the reward:
   1. Wait until a core dev signs a release of bitcoin core in which the
   limit is double it's current level.
   2. Use the new release to mine, but use a soft limit on the blocksize to
   produce only blocks that are valid according to the old software.
   3. Wait until May 5th, 2016.
   4. Remove the soft limit on blocksize.
   5. Create a block that breaks the old limit and is valid according to
   the new signed release.
   6. Wait for the new large block to be orphaned.
Hopefully, the reward will be greater than 25 bitcoins and therefore cover
the transaction fees.  Of course, if they wait until after the halving in
step 3, then they will get twice the (new, 12.5 btc) reward if they can
arrange for the orphaning of their own block.
Any core dev could do this but I guess it would be playing with fire.  So
maybe Satoshi will do it.  He played with fire (right?) and look how that
worked out.  Come on, someone, be a hero.  Mike and Gavin tried, but I
think they went a little overboard.
Another way to do this is to identify the position in each binary where the
hard limit is stored, and write a little script that will (check the date
first, and then) alter the data at that position so that currently running
bitcoin software can be hot-patched on May 5th without the help of any core
devs (if that would work).  Obviously, the little script should be signed
by a competent programmer whom the user trusts, a slightly less stringent
requirement than being an actual core dev.
On Fri, Dec 18, 2015 at 7:48 AM, Pieter Wuille via bitcoin-dev <

@_date: 2015-12-19 15:03:20
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Segregated Witness in the context of Scaling 
A couple observations:
   - The consensus block limit is different than the disk space required to
   do validation.  Some participants are worried about one and some about the
   other, and sometimes they feel what amounts to an imaginary contention
   because they perceive these two different things as the same.  They are
   both addressed by scaling solutions, but to different degrees.  This is the
   most concrete I can get about my impression whenever someone writes "not
   correct."  Less concrete is my usual impression, "you're both right."
   - "Kicking the can" has value, but no one has connected the value to the
   phrase, so here it is: The more time we have to make changes, the better
   the changes will be.  Of course it's a trade-off (because we suffer through
   that extra time with the unsolved problem), but using (or thinking of)
   "kicking the can" as bad is a mistake.
   - Whether or not there is a massive campaign targeting *current
   bitcoiners* has a very strong effect on upgrade rates.
It seems that a hardfork to a 2MB limit on 5/5/16 is a tad more than one
LOC, since we want an if-then around it so it doesn't happen til the agreed
date.  But I still support it.
On Fri, Dec 18, 2015 at 11:50 PM, Mark Friedenbach via bitcoin-dev <

@_date: 2015-12-29 10:59:58
@_author: Dave Scotese 
@_subject: [bitcoin-dev] We need to fix the block withholding attack 
There have been no decent objections to altering the block-selection
mechanism (when two block solutions appear at nearly the same time) as
described at
Key components are:
   - Compute BitcoinDaysDestroyed using only transactions that have been in
   your mempool for some time as oBTCDD ("old BTCDD").
   - Use "nearly the same time" to mean separated in time by your guess of
   the average duration of block propagation times.
   - When two block solutions come in at nearly the same time, build on the
   one that has the most oBTCDD, rather than the one that came in first.
The goal of this change is to reduce the profitability of withholding block
solutions by severely reducing the chances that a block solved a while ago
can orphan one solved recently.  "Came in first" seems more easily gamed
than "most oBTCDD".  As I wrote there, "*old coins* is always a dwindling
resource and *global nodes willing to help cheat* is probably a growing
I will write a BIP if anyone agrees it's a good idea.
On Mon, Dec 28, 2015 at 12:26 PM, Ivan Brightly via bitcoin-dev <

@_date: 2015-12-29 13:51:29
@_author: Dave Scotese 
@_subject: [bitcoin-dev] We need to fix the block withholding attack 
It cannot possibly be enforced.  Enforcement is not important when you're
setting defaults.  In fact, you don't want to enforce defaults, but rather
allow anyone who cares to deviate from them to do so.
The importance of default behavior is proportional to the number of folks
who mess with the defaults, and that, among miners, is pretty small as far
as I know, at least in the area of deciding how to decide which block to
build on when two show up at nearly the same time.
On Tue, Dec 29, 2015 at 11:25 AM, Allen Piscitello <

@_date: 2015-07-23 19:57:12
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Bitcoin Roadmap 2015, or "If We Do Nothing" Analysis 
I used Google to establish that there is not already a post from 2015 that
mentions "roadmap" in the subject line.  Such would be a good skeleton for
anyone new to the list (like me).
1. Increase the 7 Tx per second - by increasing block size.
2. Do something about the trend toward centralization.  This is really two
issues in my mind:
A) Mining is falling to an ever shrinking number of businesses with the
infrastructure to run a datacenter.
B) The protocol as it is will soon make common computing machines
inadequate for running full nodes, and as a result they will not be able to
contribute to the ecosystem in meaningful ways.
Feel free to copy and then remove or alter any of that.

@_date: 2015-07-24 08:08:24
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Bitcoin Roadmap 2015, 
Regardless of why node count is falling, many people who used to run a full
node stopped doing so.  To mitigate that, their chances of getting
something out of it have to be greater.  What if propagating a valid
transaction generated a small chance of earning a piece of the fee?

@_date: 2015-07-24 09:32:34
@_author: Dave Scotese 
@_subject: [bitcoin-dev] bitcoin-dev Digest, Vol 2, Issue 95 
That is a great idea, and not too hard to implement.  A bit of code can
determine over the last N blocks, how many blocks that were at the current
depth of the present transaction were orphaned and divide that by the total
number of blocks solved (orphaned or not) while those N blocks were
solved.  That's the historical number (H), and then the "51% attack" number
(A) can make an explicit assumptions like "Assuming a bad actor has 51% of
the hashing power for 24 hours starting right now, the block holding this
transaction has an X% chance of being orphaned."  Report "# confirmations"
as "99.44% confidence" using [100% - max(H,A)].

@_date: 2015-07-24 19:23:00
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Bitcoin Roadmap 2015, 
Incentivize investigations for public consumption.  The people on this list
are the ones who probably care the most.
When I looked up that IP address, the Whois info names "OVH" and "Octave
Klaba" (who founded OVH, according to Wikipedia) as the owner.  "
blockchain.info" appears in the HTML header as retrieved by the
"Anti-Hacker Alliance" (
Blockchain.info itself returns IP addresses managed by CloudFlare whenever
I try it.
On Fri, Jul 24, 2015 at 2:12 PM, Slurms MacKenzie via bitcoin-dev <

@_date: 2015-07-31 09:22:58
@_author: Dave Scotese 
@_subject: [bitcoin-dev] A compromise between BIP101 and Pieter's proposal 
Here are some books that will help more people understand why Adam's
concern is important:
Kicking the Dragon (by Larken Rose)
The State (by Franz Oppenheimer)
Like he said, it isn't much about bitcoin.  Our crypto is just one of the
defenses we've created, and understanding what it defends will help us
maintain its value.
On Fri, Jul 31, 2015 at 6:16 AM, Adam Back via bitcoin-dev <

@_date: 2015-11-13 18:10:29
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Bitcoin Core 0.11.2 released 
I decided to try to certify Wladimir's PGP keys (the old one (2346C9A6)
first, and then the new one (36C2E964), since it was signed with the old
I visited
to see that the new key was referenced in a message signed by the old one.
I figure it's safe to assume that if the old key actually signed that
message, then the core dev using > is an
actual core dev (that's all I'd be worried about).  So I copied the text
from ------BEGIN PGP SIGNED MESSAGE----- to -----END PGP SIGNATURE----- to
my clipboard and asked Kleopatra (on Windows) to verify it.  It says the
signature is bad.  If I alter the text of the email (so the signature would
be have to be different to be valid), it says exactly the same thing.  So
maybe something is wrong with Kleopatra on Windows.
However, the SHA256SUMS.asc file I got from the magnet link posted in the
email (below)  verifies just fine using the new key (36C2E964).  So I
figure Kleopatra is not broken.  It recognizes that the old key was used to
create the signature in that old email, but it says it's invalid.  Has
Wladimir been secretly replaced by someone who doesn't have access to the
private key for 2346C9A6?  Can you make a (bad) signature look like it was
made using a key you don't have? The whole reason for signing is so that we
will know if something like that happened.  So did I do something wrong?
(I mean, besides using Windows).
I believe this is the expected result if someone took something Wladimir
signed and ripped off the signature and pasted it below this new message to
make everyone think the new message was genuine.  Maybe Wladimir made an
edit after the signature was attached.  Or maybe it got changed when it
went through the email system.  It would be nice to know.  Anyway, I fell
back on Windows security and ran the install because it said it verified
that the publisher was "The Bitcoin Foundation".
On Fri, Nov 13, 2015 at 5:13 AM, Wladimir J. van der Laan via bitcoin-dev <

@_date: 2015-11-24 15:28:33
@_author: Dave Scotese 
@_subject: [bitcoin-dev] OP_CHECKWILDCARDSIGVERIFY or "Wildcard Inputs" or 
What is required to spend bitcoin is that input be provided to the UTXO
script that causes it to return true.  What Chris is proposing breaks the
programmatic nature of the requirement, replacing it with a requirement
that the secret be known.  Granted, the secret is the only requirement in
most cases, but there is no built-in assumption that the script always
requires only that secret.
This idea could be applied by having the wildcard signature apply to all
UTXOs that are of a standard form and paid to a particular address, and be
a signature of some kind of message to that effect.  I imagine the cost of
re-scanning the UTXO set to find them all would justify a special extra
mining fee for any transaction that used this opcode.
Please be blunt about any of my own misunderstandings that this email makes
On Tue, Nov 24, 2015 at 1:51 PM, Bryan Bishop via bitcoin-dev <

@_date: 2015-11-25 09:03:32
@_author: Dave Scotese 
@_subject: [bitcoin-dev] OP_CHECKWILDCARDSIGVERIFY or "Wildcard Inputs" or 
The message could specify:
{ stib: 0x01,
  TxnCount: (# of entries in the Indexes array)
  Indexes: [{BLK: Block
  NewUTXO: (The script that will spend these coins)
*stib *is a Script Template Index Bitfield: Must (currently) be the byte
0x01, to indicate the "vanilla" script Chris identified.  If other scripts
appear to fit the bill in the future, they can be assigned to other bits.
*Indexes *is a list of pairs that identify a block by its height and a list
of indexes into the block.  This puts the onus on the transactor to
identify all the inputs instead of requiring the miner to scan for them.
If block heights and transaction indexes are 32-bit integers, this reduces
the per-input size cost by at least 100 bytes, if I did my math right.
On Wed, Nov 25, 2015 at 6:16 AM, Erik via bitcoin-dev <

@_date: 2015-11-26 20:08:35
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Alternative name for CHECKSEQUENCEVERIFY (BIP112) 
I was curious about there being only 10 single-byte opcodes left.  There
are ten single-byte OP_NOPx opcodes defined, but there are 15 opcodes that
"simply *do not exist anymore* in the protocol" because they are scary (had
bugs that "could crash any Bitcoin node if exploited" or "allowed anyone to
spend anyone's bitcoins").  There are also 66 single-byte values that are
currently reserved, 186 - 252 (0xba - 0xfc).
If the name OP_CHECKSEQUENCEVERIFY should not be changed, each of us has a
single best reason not to change it.  Finding other reasons suggests that
one's top reason isn't good enough.  See Nassim Taleb's book, Antifragile,
if that claim makes you curious.  The same goes for changing it.  In any
case, it is 178 (0xb2) and app developers can call it whatever they want.
It seems trivial to me since the following, in script.h, would neither slow
compilation nor confuse anyone, but could lead the curious to explore the
history and expand their knowledge:
OP_NOP3 = 0xb2,
OP_CHECKSEQUENCEVERIFY = OP_NOP3,
OP_CHECKMATURITYVERIFY = OP_NOP3, // A comment defending the alternative
I don't know the consensus here on leaving breadcrumbs in code comments
(and enum/variable names) for curious coders to use as inspiration for
studying the history, but I advocate it, since modern IDEs are fairly
well-equipped to make skipping or hiding comments easy.
On Wed, Nov 25, 2015 at 3:05 PM, Mark Friedenbach via bitcoin-dev <

@_date: 2015-09-30 21:04:32
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Design Competition 
I am waiting for the bitcoin (not bitcoin-dev) mailing list so that anyone
who writes "That's off-topic" can also include a link to it.
Someone else mentioned that they read all these emails in about 15
minutes.  I'm a bit slower than that, but I'm reading the vitcoin-xt stuff
too.  It isn't too much for me, but it will be nice to have a more open
list, such as is planned.  What's the hold up?  Don't answer here, at least
not until the list is ready :-)
On Wed, Sep 30, 2015 at 6:38 AM, Benjamin via bitcoin-dev <

@_date: 2015-10-02 14:37:09
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Dev-list's stance on potentially altering the PoW 
If the PoW function is changed, it ought to change slowly so as not to drop
a brick wall in front of the miners speeding toward the ever-receding goal
of protecting the blockchain.  Who's going to get on that path if the
bitcoin community does that?
But it can be done slowly.  If most of the entries is the list of possible
PoW functions are double-SHA256, then the few that aren't will offer the
healthy goal sought by those who like the idea of changing it.  The healthy
goal is for general computing machines to help protect the blockchain in an
incentivized way.  There's a sick goal too, which is to destroy large
investments in mining.  I hope no one has that goal.
I proposed that ongoing competitions for the creation of new hash
algorithms could feed an ASIC-resistant PoW, defined using the
as-yet-unknowable winners of such competitions.  It is possible to make an
ASIC resistant algorithm, but it isn't a programmable algorithm - it's one
that requires human intervention.  The hash of the next block is a good
example - there's no programmable algorithm that can find it because too
much human intervention is required, but it's an algorithm well-enough
defined for us to build a billion dollar system on top of it.
That being said, I've started looking at two different kinds of
decentralization.  The literal actually-in-different-places kind is
categorically different than the much more important, virtual
impervious-to-coercion kind.  The behavior of the "centralized" oil cartel
is a good example.  The participants cheat.  This is a fundamental
principle in the debate between free-marketeers and authoritarians
regarding the emergence of monopoly.  Without coercion, monopolies fall
apart.  There's nothing coercive about our use of the double-SHA256, so in
my mind, the centralization it has so far produced is not dangerous.  It's
scary, sure, but until coercion is used to prevent me and my friends from
buying our own ASICs, it remains impervious to coercion.
Sorry for the long email that didn't make any apparent progress.  The
thinking is what matters to me, and seeing two kinds of decentralization
and recognizing that a change in PoW can be slow enough to avoid hurting
existing miners are items I haven't seen anyone else recognize, so I had to
bring them up.
On Fri, Oct 2, 2015 at 9:45 AM, Gregory Maxwell via bitcoin-dev <

@_date: 2015-10-05 13:54:38
@_author: Dave Scotese 
@_subject: [bitcoin-dev] This thread is not about the soft/hard fork 
I prefer the hard fork because the complexity introduced by soft forks
scares me.
 "Security requires a bit of vigilance, inherently." and
[A non-upgraded miner will end up] "*> producing invalid blocks forever
until** the owner shuts it down and upgrades. * This is the outcome
guaranteed for absentee miners with a hard fork, but it is not guaranteed
for a soft fork."
It seems that the main benefit of a soft-fork is that it allows
participants on the network to keep participating even if they aren't
vigilant enough to notice and upgrade when that is safest.  Are there other
reasons that might entice me if that one by itself is not enough?
Gregory provided two more: [Using soft-forks] "radically lowers (in most of
our experience and
opinion) the cost of deployment; again-- making them different. They
prevent a industry wide flag day, and tight release synchronization  which
is harmful to decentralization promoting software diversity."
I understand these benefits.  The cost in complexity is still too high for
me, and I think most of the pain in "cost of deployment", "industry-wide
flag days," and "tight release synchronization," as well as the
centralizing effect of those things can be minimized with waiting periods.
The promotion of software diversity offered by soft-forks is pretty cool,
but that gets close to messing with fungibility.

@_date: 2015-10-10 14:41:24
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Masked bits and isStandard 
Thanks again.  The description of bits 16..29 as "can take any value"
suggests to me an improvement for isStandard: if any bits "can take any
value" without affecting the script then they must be off for the script to
pass isStandard.
If I understand it correctly, this requirement will serve as a backup to
future uses of those bits if such uses are deployed as soft forks.
I'm sorry if my suggestion reflects a poor understanding of isStandard, but
I offer it as evidence on whether the mechanism is as well understood as it
should be, since we use soft forks.  If I have misunderstood, feel free to
educate me with a reply.
On Oct 10, 2015, at 8:22 AM, G1lius Caesar via bitcoin-dev <
bits 16..29 are masked off and can take any value.

@_date: 2015-10-13 16:52:05
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Memory leaks? 
"size" : 1085,
"bytes" : 16151768
It has been running about a day.  I'll report tomorrow too.  This is a
Windows 8.1 box.
16 million divided by 1085 transactions is almost 15Kb per transaction =
unlikely, right?
On Tue, Oct 13, 2015 at 4:14 PM, Jonathan Toomim (Toomim Bros)

@_date: 2015-10-13 17:25:29
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Memory leaks? 
It was about 360MB (30 minutes ago?), but is now about 460MB.  I'm sure it
won't keep going up that fast.
"size" : 3413,
"bytes" : 41892350
On Tue, Oct 13, 2015 at 5:08 PM, Jonathan Toomim (Toomim Bros)

@_date: 2015-09-02 21:45:38
@_author: Dave Scotese 
@_subject: [bitcoin-dev] BIP 100 specification 
Hash: SHA1
I suggest revising these items for clarity (and I'm guessing on the first
    Calculate hardLimit by examining the coinbase scriptSig votes of the
previous 12,000 blocks, and taking the 20th percentile.
    A new hardLimit may not increase or decrease by more than 1.2x beyond
the prior hardLimit.
    The new hardLimit is calculated by sorting the coinbase scriptSig votes
of the last 12,000 blocks from lowest to highest and using the vote of the
2400th block.
    If the vote of the 2400th block is a change of less than 20%, use it as
the new hardLimit.  Otherwise, change the hardLimit to be closer to that
vote, to either 120% or 80% of the current hardLimit.
I don't understand  75% rule.  Shouldn't invalid version 4 blocks always
be rejected?
On Wed, Sep 2, 2015 at 8:33 PM, Jeff Garzik via bitcoin-dev <

@_date: 2015-09-03 13:34:54
@_author: Dave Scotese 
@_subject: [bitcoin-dev] BIP 100 specification 
I have seen "1M" mean 1,000,000 bytes as well as 1,048,576bytes and
1,024,000 bytes.  I believe the best policy is to use "megabyte" to mean
2^20 (1,048,576) bytes.  Kb always means 1024 bytes, even when a lot people
round it, so I like the K spec best.  I also see value in having human
readable data.  The spec should nail down these details.

@_date: 2015-09-11 09:27:25
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Bitcoin Days Destroyed as block selection heuristic 
Rather than (promising to, and when they don't actually, at least
pretending to) use the first-seen block, I propose that a more
sophisticated method of choosing which of two block solutions to accept.
Essentially, a miner receiving two solutions at the same height would
compute a weighted sum of bitcoin-days-destroyed (transactions received
earlier get higher weights) of whatever transactions are in a block *and
also* were in the miner's mempool *before* the first solution arrived.
Whichever block has more wins.
This strategy avoids allowing miners to use private transactions to mess
with the blockchain.  It also makes an empty block far less attractive
because it is easily replaced, all the way until the next block locks it
in.  Any block-selection heuristic can be gamed, but I believe that using a
weighted sum of BTCDD is harder to game than using block propagation timing.
I asked Can Bitcoin Days Destroyed be a better resolution mechanism for
competing blocks?
on the stackexchange bitcoin site in order to collect objections to and
problems with this idea, and have not found any that I haven't addressed.
The best objection is that *maybe* empty blocks and selfish mining are
either good for bitcoin, or else they are so minimally bad that no effort
ought to be expended in preventing them.
If anyone here thinks this is a good idea, and no one can offer reasons
it's a bad idea, I will probably start working on an implementation.  I'm
really slow though, so ping me if it looks like fun to you.

@_date: 2015-09-11 12:26:20
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Bitcoin Days Destroyed as block selection 
Yes, this proposal is a policy that everyone would be free to ignore.  I
should have introduced the situation in which this *unenforceable* policy
makes sense to me.  Here it is:
Every miner is listening for valid block solutions but might receive two
valid blocks and then they have to decide which one to use.  Choosing the
one you saw first is the default behavior.  In that situation, we'd all
like everyone to choose the same block.  I propose that a better heuristic
than "first seen" is to compare the BTCDD, *but only of transactions you
already have in your mempool*, and
*weight the BTCDD so that txns you got earlier are more important.*
The heuristic is most useful when the two blocks are received within a
small window of time, opting for the first-seen rule otherwise.  I assume
many miners have an idea of how long it takes for anyone's new block to get
across the network, and more specifically, the range of times it takes for
new solutions to get to themselves.  During this little time window, the
chances are 50/50 that they'll choose the right block.  If the default
behavior were to use BTCDD during that time window (one second? I have no
idea!), then the chances would be significantly better.
I think Jorge is right that it doesn't benefit miners.  It doesn't hurt
them either, unless they are trying to do selfish mining.  Well, it
benefits them in terms of increased bitcoin stability by A) making it
easier for clients to decide which block is valid when they see two
competing with each other, B) motivating miners to add transactions instead
of mining empty blocks, C) severely decreasing the utility of any global
private network of nodes intended to spread selfishly-mined blocks, and D)
motivating miners to stay well-connected so that they get transactions
I sent this to the list because it is only useful if it is set as default
behavior since most miners leave the defaults alone, and the benefits don't
materialize unless a majority follows the policy.

@_date: 2015-09-12 11:55:03
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Bitcoin Days Destroyed as block selection 
If I read that correctly, that is directly proportional to BTCDD, so
whatever effect concerns you has already been built into the code.
On Fri, Sep 11, 2015 at 3:21 PM, Vincent Truong <

@_date: 2015-09-18 10:10:08
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Scaling Bitcoin conference micro-report 
"But if a metric were chosen that addressed my concerns (worst case
propagation and validation time), then I could be in favor of an initial
bump that allowed a larger number of typical transactions in a block."
+1.  A ratio is much more valuable than a simple metric.  It seems clearly
difficult to identify a reasonable limit to block size, but the ratio
between any one of several possible metrics and bytes in a block would work
well and may already have a very good reasonable expected range.
I like BTCDaysDestroyed (BTCDD) best.  If it might be time consuming to
compute, then it need only be computed for all blocks less than or equal in
size to the average size of the largest 200 or so blocks in the previous
difficulty period.  To exceed that limit, a miner would have to ensure that
the block has enough BTCDD per byte.  "Enough" could be hardcoded in each
release, or if it's simple enough, use the ratio as computed over all the
blocks in the previous difficulty period as the lower limit.
On Thu, Sep 17, 2015 at 10:55 PM, Mark Friedenbach via bitcoin-dev <

@_date: 2015-09-18 16:29:42
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Weekly development meetings on IRC 
I am in a timezone that uses DST (currently PDT), but I would like us to
use a timezone that does NOT use DST.  It will be nice to have something
that reflects the seasonal patterns like my own body does.  I hate the time
change in both ways.
On Fri, Sep 18, 2015 at 2:50 PM, Luke Dashjr via bitcoin-dev <

@_date: 2015-09-19 17:48:19
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Hash of UTXO set as consensus-critical 
It seems there should be a practical limit to the size of a re-org - I mean
a practical limit that is smaller than the current height.  Vincent's
proposal suggests that a year's worth of blocks is such a practical limit.
I agree.  There are probably lower limits that are practical too, but I
like an entire year just to be conservative.  As Vincent points out, "An
attacker will need to have hidden hashing power to overwrite a years worth
of blocks."
TL;DR for the rest of this: Txns that lose confirmations from a reorg and
then show up in the mempool but not in any of the next few blocks indicate
malicious mining.
I see a blind spot here.  We are seeing the rule that says the longest
chain is the valid chain as impossible to break, but it isn't.  We broke it
to fix the BerkelyDB problem.  The code itself would have prevented us from
doing that IF 51% of the hashpower had been used to build on the wrong
chain, but it wasn't.
Justus' question about what malicious means is key here.  The blind spot is
a bit more complex than just viewing the longest chain as impossible to
break except with more than 51% of the hash power.  The blind spot is our
inability to distinguish between malicious blocks and honest blocks.
Rune suggests that empty blocks indicate malice.  I like that (which is why
I advocate using BitcoinDaysDestroyed to decide between blocks at the same
height that appear at nearly the same time, rather than first-seen).  There
are other methods we can use to distinguish between malicious blocks and
honest ones.  I'm inventing one right now, but I'm sure better ones can be
Here's mine: Once a transaction has been confirmed, its originator
generally takes on the responsibility of re-broadcasting it if it gets
re-org'd out of its confirmation(s).  Many mempools will see that
re-broadcast, *if it happens*.  Any malice in a 51% attack would come in
the form of failing to include such transactions.  If we have a history of
orphaned blocks, then we can check to see which ones have been included in
non-orphaned blocks since they got reorg'd out.  Such transactions should
be top-priority after a reorg, even if they have zero fees.  When there is
a transaction that doesn't appear in a new block within a couple hours of a
reorg, that indicates dishonesty, usually in the sender (but that could be
negligence), but possibly in the miner.  Looking at the mempool would
determine which, wouldn't it?
On Sat, Sep 19, 2015 at 1:11 PM, Rune K. Svendsen via bitcoin-dev <

@_date: 2015-09-19 18:26:48
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Scaling Bitcoin conference micro-report 
phm got most of this, but...
On Sat, Sep 19, 2015 at 2:53 PM, phm via bitcoin-dev <
Pot is used as money, and they do jail people for it, but it doesn't have
the effect to which you refer. It has the opposite effect, partially
because it enriches suppliers.
The 51% attack is a good point, but they would be taking a huge risk.
Ideas don't die, just people.  For example, they got Ross Ulbricht, not DPR.
Government is the group of people that does things that are not acceptable
if anyone else does them, and that is because people cheer for them when
they do those things, rather than pointing out that they are not
acceptable.  The movie "The Deep Web" shows how bitcoin helps to turn this
misfortune around.

@_date: 2015-09-20 17:11:46
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Scaling Bitcoin conference micro-report 
... Obama would like to restrict guns, but can't, because they are too
popular (in the USA).
... Governments tolerate this sort of abuse [black markets] only because
they believe, I think correctly, that Bitcoin can have great benefits for
their ordinary voters and for now are willing to let the tech industry
Those two reasons must be recognized for their differences.  What does it
mean that something is "too popular" if the ultimate goal of government is
"great benefits for their ordinary voters"?  It means the government
assumes that some things are bad for people even though they are popular.
Crystal meth and heroin come to mind.  This is a natural concern of all
decent parents for their children, and the reason that cultures for
millennia have had rites of passage, wherein the child takes on the
responsibility of determining for him or her self whether or not a popular
thing provides great benefits.  That responsibility is the birthright of
every human being. Why is there an institution that usurps it?  How do the
people within that institution benefit from being part of it?
Some history to study and answer these questions includes:
   - The origination of public schooling as motivated by Johann Fichte's
   public letters to his king in response to Prussia's loss to Napolean at
   Jena.
   - Franz Oppenheimer's book, The State, tracing the origination of the
   idea of a state, or group of people who make up and enforce laws.
   - Carroll Quigley's history book, Tragedy and Hope.
   - Larken Rose's book, Kicking the Dragon.
   - The Republic, by Plato, but only once you understand those other books.
   - If you want a shortcut, John Taylor Gatto did a five-hour interview
   which is now titled "The Ultimate History Lesson with John Taylor Gatto."
   It is heavily sourced by its producer in case anyone wants to verify the
   information he provides.
I'm "notplato" for a reason.

@_date: 2015-09-22 16:49:11
@_author: Dave Scotese 
@_subject: [bitcoin-dev] libconsensus and bitcoin development process 
If I'm reading this situation correctly, Jeff is basically pointing out
that developers need more links (hooks, rungs, handholds, data points,
whatever you want to call them) so that they can see all the things his
email insinuated are missing (a plan, order, sense, etc.).  He didn't say
these things were missing, but that it kind of feels like it from the
10,000 foot view.
If you use Google to search the list, as in <> you DO NOT get the page Jorge gave.  He wrote that
page, so he had a good idea what to search for to find it again.  I just
want to recommend that when you describe the work you're doing on bitcoin,
imagine several different ways people might try to find this description in
the future and make them work.  In other words, Jorge could have put "A
plan for abstracting out libconsensus" in the email where he wrote "Here
are some things that need to happen first..."
Likewise, if Jeff had searched for <> (maybe he did, but he didn't list any results), he may
have found enough clues to see Jorge's overall plan.  The "site:" keyword
on Google fascinated me when I discovered it, so I let it inspire this
email :-)
Maybe someone can explain this if I have it wrong: A few people are able to
pull code into Bitcoin/bitcoin.  Isn't is possible that those few people
can agree to merge in a lot of refactor-hell PRs for those making the
requests, but postpone them to that one-week-per-month that someone
suggested?  The idea of letting that "hell" come in (predictable) waves is
excellent and I was hoping to see some agreement.  But I don't know who
those few are, so even if they all wrote "Yeah, we'll do that," I wouldn't
recognize that I got what I wanted.
On Tue, Sep 22, 2015 at 11:12 AM, Jorge Tim?n <

@_date: 2015-09-28 15:16:42
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Let's deploy BIP65 CHECKLOCKTIMEVERIFY! 
Why are they called soft forks when they are really hidden forks?  Isn't
the point of a soft fork to prevent old clients from rejecting what they
don't have the code to validate?  That seems dangerous.
On Mon, Sep 28, 2015 at 2:12 PM, odinn via bitcoin-dev <

@_date: 2016-02-01 21:50:29
@_author: Dave Scotese 
@_subject: [bitcoin-dev] BIP Process: Status, comments, 
The section that starts "Should two software projects need to release"
addresses issues that are difficult to ascertain from what is written
there.  I'll take a stab at what it means:
Would bitcoin be better off if multiple applications provided their own
implementations of API/RPC and corresponding application layer BIPs?
   - While there is only one such application, its UI will be the obvious
   standard and confusion in usability will be avoided.
   - Any more than a single such application will benefit from the
   coordination encouraged and aided by this BIP and BIP 123.
"To avoid doubt: comments and status are unrelated metrics to judge a BIP,
and neither should be directly influencing the other." makes more sense to
me as "To avoid doubt: comments and status are intended to be unrelated
metrics. Any influence of one over the other indicates a deviation from
their intended use."  This can be expanded with a simple example: "In other
words, a BIP having  the status 'Rejected' is no reason not to write
additional comments about it.  Likewise, overwhelming support for a BIP in
its comments section doesn't change the requirements for the 'Accepted' or
'Active' status."
Since the Bitcoin Wiki can be updated with comments from other places, I
think the author of a BIP should be allowed to specify other Internet
locations for comments.  So "link to a Bitcoin Wiki page" could instead be
"link to a comments page (strongly recommended to be in the Bitcoin
Wiki)".  Also, under "Will BIP comments be censored or limited to
particular participants/"experts"?" You could add:
   - The author of a BIP may indicate any commenting URL they wish.  The
   Bitcoin Wiki is merely a recommendation, though a very strong one.
On Mon, Feb 1, 2016 at 2:53 PM, Luke Dashjr via bitcoin-dev <

@_date: 2016-02-02 08:00:03
@_author: Dave Scotese 
@_subject: [bitcoin-dev] BIP Process: Status, comments, 
Yes, that is much better.  The mention of "only one is insufficient" and
"two are sufficient" in the bullets clarifies them well too.
BIP acceptance hinges on accessibility and discussion.  Wherever discussion
happens, someone can mention the Wiki page they created to sidestep such an
unfortunate abuse.  I have always been in favor of allowing people to do
stupid things simply because that helps them learn not to do them.  The
result is often some (at least slight) embarrassment of the bad actor and a
lesson for everyone paying attention.  The censorship of BitcoinXT
discussion had this effect and has softened the enthusiasm many had for...
let's call it: guarding against their own cognitive dissonance through
censorship and intimidation.
In fact this last item is probably what raised a flag for me when thinking
about the specification that they should "link to a Bitcoin Wiki page with
a summary tone of the comments." I have too often seen great discussions of
controversy lose a lot of valuable input because they lived in an
environment controlled by someone who let bias infect their moderation
decisions.  I know that even I might do that, so encouraging others to have
access to my competitors feels right.

@_date: 2016-01-07 12:56:33
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Time to worry about 80-bit collision attacks or 
Maybe I'm being dense, but I don't see why 2**80 storage is required for
this attack.  Also, I don't see why the attacker ever needs to get the
victim to accept "arbitrary_data".  Perhaps I'm wrong about how the
collision attack works:
   1. Create a script which is perfectly acceptable and would pass the
   sniff test Gavin proposed (no arbitrary_data).
   2. Set off CPU power to construct a second script that lets attacker
   keep his coins and has the same hash. (This is where you get
   "arbitrary_data").
   3. Send a transaction with the first script to the seller as payment.
   4. Wait for the transaction to be included in a block.
   5. Redeem the transaction with the second script, thus stealing the
   coins back.
So the seller would never see the I'd appreciate any correction to my
understanding here.  Where do you need 2**80 storage?  And when does the
seller have to accept "arbitrary_data"?
On Thu, Jan 7, 2016 at 11:19 AM, Adam Back via bitcoin-dev <

@_date: 2016-01-18 22:07:52
@_author: Dave Scotese 
@_subject: [bitcoin-dev] [BIP/Draft] BIP Acceptance Process 
This seems like a good place to point out that attempts to identify
individuals (either by name or simply as an individual human being) are
futile as well as destructive.  "1%" usually means "one out of every 100
people" but this requires identification of individuals as individuals.
One person can look like many in Bitcoin, which is why such an effort is
futile.  Additionally, one person may be far more affected by a decision
than others, which is why it's destructive.
I like the idea of measuring consensus, and there are proto-ideas in my
head about how that can be done, based not on individual people, but on
amounts of bitcoin.  Many will argue that we don't want the system to be
controlled by those who hold the most bitcoin.  I understand that
sentiment, but A) I simply disagree, and B) Finding something better seems
impossible to me.
A simple method is the following:
A message can be constructed saying: "As of block X, the holder(s) of Y BTC
controlled by [public key] agrees that Z," where X, Y, Z, and the [public
key] are the only things that change.  This message can be signed by the
private key matching the [public key] in the message.  Anyone interested in
measuring consensus on anything relative to bitcoin holders can advertise
for such signed messages to be sent to a repository of their choice which
would validate each message (that [public key] (still) holds Y BTC and that
the signature is valid) and provide a measure of agreement about Z.  Change
your mind?  Just move your BTC to a different address.
On Mon, Jan 18, 2016 at 6:12 PM, Luke Dashjr via bitcoin-dev <

@_date: 2016-01-20 20:35:39
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Three Month bitcoin-dev Moderation Review 
I agree with the prohibition of +1s.  The core competency of those who
provide this list are moderation and technology, not managing a process
through which "involved people [indicate] whether they're for or against
That is certainly an excellent function, but it can be offered by anyone
who wants to run a system for collecting and displaying those indications.
The email list itself is intended to be information rich, and such
"approval voting" is not information-rich enough in my view.
It is a shame that the moderated messages require so many steps to
retrieve.  Is it possible to have the "downloadable version" from
 for each month
contain the text of the moderated emails?  They do contain the subjects, so
that helps.
On Wed, Jan 20, 2016 at 6:25 PM, xor--- via bitcoin-dev <

@_date: 2016-01-23 17:06:23
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Three Month bitcoin-dev Moderation Review 
The distinction we are making importantly requires that contributors
provide readers with another thing to say in favor of something - another
thing which is different than "X people support this instead of only X-1
people."  Evidence trumps votes.
On Sat, Jan 23, 2016 at 1:38 PM, Gavin via bitcoin-dev <

@_date: 2016-03-02 21:11:16
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Hardfork to fix difficulty drop algorithm 
It makes sense to me that there might be objective conditions under which
we would want to use a number smaller than 2016.  A good example would be a
mean time between blocks of more than 20 minutes over the last 144 blocks
(one  - two days).  If such an occurrence ever happened, and the software
then cut the retarget interval to 1008 (triggering an immediate retarget if
the counter is over 1008), the only problem I see is how to measure the
mean time between blocks.
In fact, has anyone examined the potential problems of reducing the
retarget period, even to one?  Not Really.
That question includes a suggestion of retargeting on every block, but
using the same 2016 block window for the calculation, so difficulty changes
would be very smooth, and still as unpredictable and how long till we find
the next block.
On Wed, Mar 2, 2016 at 3:02 PM, Peter Todd via bitcoin-dev <

@_date: 2016-03-03 08:38:17
@_author: Dave Scotese 
@_subject: [bitcoin-dev] consensus rule change for TX fee safety 
It would be a shame to prohibit someone from rewarding whoever mines their
transaction.  A good example would be a transaction designed to record some
information which is damning to powerful authorities, sort of like the
service cryptograffiti offers.  When we try to protect others by
prohibiting behavior we think is foolish, we may save some fools, but at
the same time, we hurt the best of us.
On Thu, Mar 3, 2016 at 7:36 AM, Jorge Tim?n <

@_date: 2016-03-07 21:14:15
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Services bit for xthin blocks 
I think a BIP is a good idea, but rather than making such a specific
proposal as "Let's use bit 4 to indicate communication of thin blocks," how
about a more general one like "Let's use bit(s?) 4(-5?) as user-agent
specific service bits so that if you customize your user-agent string, you
can use them for whatever you want"? That way, other clients can choose to
follow suit by saying so, or simply recognize the meaning (or lack thereof)
of those bits based on the user-agent setting.  This relieves future
development from the burden of agreeing on where to put what, and allows
time and utility to show when such a user-agent-specific service bit should
be moved into the protocol section of service bits.
PS I am not well versed in the creation of standards, but the reservation
of digital real estate for self-identified customization (bits, bytes, or
whatever that will never be used by the standard) such as what I'm
proposing seems like something that probably has a standard name.  "Public
provisioning" or something like that?
On Mon, Mar 7, 2016 at 12:51 PM, Gregory Maxwell via bitcoin-dev <

@_date: 2016-10-10 08:34:17
@_author: Dave Scotese 
@_subject: [bitcoin-dev] 1 Year bitcoin-dev Moderation Review 
I sent my previous email ONLY to bitcoin-discuss at lists.linuxfoundation.org
and it waited in the moderation queue.  I don't know when moderation was
added to this list, but it seems to me that it's a misstep.
On Mon, Oct 10, 2016 at 12:38 AM, Henning Kopp via bitcoin-dev <

@_date: 2016-09-23 17:08:24
@_author: Dave Scotese 
@_subject: [bitcoin-dev] BIP draft: OP_CHECKBLOCKATHEIGHT 
If Alice knows enough to see that she needs CHECKBLOCKATHEIGHT to avoid
paying Bob twice, then she also knows that Fred owes her 4BTC.  If Bob
complains about getting paid faster, Alice can let him know that Fred
essentially stole his coins and that when she is certain he (and she) can't
get them back, she will send a different four coins to Bob.  If she can
establish trust with Bob (She'd trust Bob to pay her back if he gets back
the coins Fred stole), then she can pay him again.  Bob could also make a
transaction to send the first input from Alice back to her (since he
doesn't have those coins anyway), sign it, and send that to her.  She can
then keep it instead of having to use the new opcode.
Or she can let her wallet use the new opcode so that the logic is built in,
if we add this opcode.  Wallet makers who want to help solve this problem
can either implement the new opcode, or they can offer people like Bob the
ability to refund orphaned transactions so that they can be duplicated in
the valid chain without any risk to the original sender.
With the opcode, Alice can solve the problem by herself.  Without it, Bob
can solve it for Alice.
While the opcode adds complexity, it enables victims of double-spends to
pay untrusted creditors (Bob) without the risk that orphaned chains create
of paying them twice.  I'm not sure the added complexity is worth the
reward. The reward is to protect Bitcoiners (Alice) from people we'd call
"untrusted creditors" (Bob) and I think that might be a mistake.  Getting a
refund transaction signed and sent back to Alice is similar to how the LN
will work (where wallets hold transactions that they don't broadcast).
Am I understanding this correctly?
On Fri, Sep 23, 2016 at 3:34 PM, Luke Dashjr via bitcoin-dev <

@_date: 2017-02-02 17:32:34
@_author: Dave Scotese 
@_subject: [bitcoin-dev] [Pre-BIP] Community Consensus Voting System 
There are two ideas here for "on-chain" voting, both of which require
changes to the software.  I agree with David that on-chain solutions
complicate things.  Both proposals can be effected without any software
Those who wish to use proof of stake can provide a service for making
vanity addresses containing some indicator of the proposal to be supported
- 1bigblock or 12mbblk or whatever - based on a supporter-provided secret
key, and then supporters can move their bitcoin into their own vanity
address and then whoever wants to can create a website to display the
matching addresses and explain that this is the financial power in the
hands of supporters and how to add your "financial power vote."
Those who simply want to "buy votes" can use their funds in marketing
efforts to promote the proposal they support.
This second method, of course, can be abused.  The first actually requires
people to control bitcoin in order to represent support.  Counting actual,
real people is still a technology in its infancy, and I don't think I want
to see it progress much. People are not units, but individuals, and their
value only becomes correlated to their net worth after they've been alive
for many years, and even then, some of the best people have died paupers.
If bitcoin-discuss got more traffic, I think this discussion would be
better had on that list.
On Thu, Feb 2, 2017 at 4:24 PM, Luke Dashjr via bitcoin-dev <

@_date: 2017-02-25 13:21:56
@_author: Dave Scotese 
@_subject: [bitcoin-dev] SHA1 collisions make Git vulnerable to attakcs by 
I was under the impression that RIPEMD160(SHA256(msg)) is used to turn a
PUBLIC key (msg) into a bitcoin address, so yeah, you could identify
ANOTHER (or the same, I guess - how would you know?) public key that has
the same bitcoin address if RIPEMD-160 collisions are easy, but I don't see
how that has any effect on anyone.  Maybe I'm restating what Peter wrote.
If so, confirmation would be nice.
On Sat, Feb 25, 2017 at 1:04 PM, Peter Todd via bitcoin-dev <

@_date: 2018-12-03 12:37:17
@_author: Dave Scotese 
@_subject: [bitcoin-dev] How much is too much time between difficulty changes? 
The last difficulty change took about 20% longer than expected.  How large
does the time between difficulty changes have to get for us to make
changes?  In other words, if, at some point, block confirmation times are
averaging, say, hours or days, will we hardfork to speed things up?
One option is NO.  When enough economic interests align to amass the
computing power to get important bitcoin transactions into a block, then
they will work out a way to get that block confirmed.  This allows other
cryptocurrencies and technologies like LN to fill in.
There may be a group that will fork the code in order to adjust the
difficulty more rapidly, and bitcoin holders will put a value on
bitcoin-FDA ("Faster-Difficuly-Adjustment"), which is fine with me.  We can
learn how to fork peacefully from what we learned when BCH was born, and
what we learned when it split.
I think some insight into how core developers will handle increasing
demands to use faster difficulty adjustments (if they respond at all) will
be helpful, and this is why I'm asking.
Dave Scotese

@_date: 2018-05-21 13:03:37
@_author: Dave Scotese 
@_subject: [bitcoin-dev] [bitcoin-discuss] Checkpoints in the Blockchain. 
Our wetware memory is faulty at details, but a rendering that provides
features at which it isn't faulty makes it a decent backup in situations
where technology has been used to hide important differences from us. Some
of us may recall being in a situation where something seems off, and we
start to investigate, and then we discover that something was off.  April
Fools jokes are good examples, as well as satire and news reports from The
The point of storing the entire blockchain history is to prevent any of
that history being changed in a way that illicitly alters the UTXO Set.
Whenever a memorable enough rendering of the UTXO Set is produced (which
has happened exactly once - when Bitcoin started, it was empty, and after
that, it just looks like a bunch of random computer data), the risk of
altering the history before it goes up, even if you have the computing
power to make subsequent block headers follow all the rules (and even to
successfully execute a 51% attack!).  In this announcement
the first item under "new features" has this, which follows the same
principle as my idea:
Introduce experimental SSH Fingerprint ASCII Visualisation to ssh(1) and
On Sat, May 19, 2018 at 10:12 PM, Damian Williamson

@_date: 2018-09-21 18:49:47
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Proposal to replace full blockchain with recent 
I've been working on an idea that relieves full nodes of storing the entire
blockchain. Open source software generally relies on the fact that "enough"
people agree that it's secure. Bitcoin software works that way too. So if
you understand enough to see that a UTXO set is valid at a certain block
height, and there are enough other people who agree and that set is
recognizable by humans, then we can use that UTXO set and ditch the
blockchain that existed up to that point. It would save a lot of storage
and make it a lot easier to run a full node.
Have you reviewed the source code from which your wallets were compiled?
At some point, we all trust third parties, but generally (at least among
people who understand Bitcoin) they are large composite groups so that no
small group or individual can profit from cheating.
I look forward to answering any concerns and also to any offers of help.   I
used block 542324 of the Bitcoin blockchain to make a memorable experience
using the game of life. I wrote a script for the open-source Game-of-Life
software Golly and shared it in the paste at It produces the image at  If someone can tell
me how to get a UTXO Set from the bitcoin client, I'll send them $50 of
bitcoin. Then I could get the SHA256 hash of that set and try to make a
recognizable checkpoint for the Bitcoin blockchain. If someone runs Golly
and shares a video of the game playing out (into the apron-shaped image),
I'll send them $50 of bitcoin too.
In a few decades when the blockchain has grown to a few terabytes and the
UTXO Set is still just a few gigabytes, I'd like to see more people start
running full nodes without the hassle of a long wait and loads of storage
space. That's what stops me from running one.

@_date: 2018-09-25 08:47:28
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Proposal to replace full blockchain with recent 
The image at imgur and the pastebin both reference block 542324 but the
correct block is 542322.  As the pastebin shows, the decimal and hex
representations I gave for the block height did not match, and this is
why.  If you use the Merkle root for block 542322 instead of 542324, you'll
be able to see the correct Game of Life play out and make the apron image.
On Fri, Sep 21, 2018 at 6:49 PM Dave Scotese

@_date: 2019-03-31 20:04:18
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Softfork proposal for minimum price of $50k 
I think EXACTLY ONE YEAR is the perfect time.  Well, a year and a day for
me because I'm on the wrong side of the date line, apparently.
On Sun, Mar 31, 2019 at 6:04 PM Ricardo Filipe via bitcoin-dev <

@_date: 2019-04-03 14:39:32
@_author: Dave Scotese 
@_subject: [bitcoin-dev] assumeutxo and UTXO snapshots 
Every block's hash is smaller than the difficulty at that time.  Block
569927's hash was VERY small (started with 21 zeros).  The ratio of block
hash to difficulty requirement (0xffffffff - difficulty, I think) could be
used to identify blocks as "special," thus providing the opportunity to
popularize unimportant but memorable-and-therefore-useful details.  How can
they be useful if they are unimportant?  They are useful for sanity
checking.  For example, if the drunken bishop walk (or some other popular
randomart) produced by block 569927's hash looked like a face, that would
be memorable: "The block with the smallest hash in 2019 (maybe ever?) looks
like a face after the drunken bishop walk."
If a few of these showed up each year, then Bob and/or Alice would have a
good chance of seeing that something was wrong if and when they checked.
It would not be surprising, given Ethan's assumption that the invalid block
Bob found contributed to Alice's UTXOs, that at some point, the history one
of them has would be missing the memorable things beginning at some block
height because, clearly, one of them has been forked.
Luke's comment that it could "lead to users trusting third parties (like
developers) way too much" is pertinent too, but I think an honest abatement
of that concern is impossible without teaching everyone C++.  "Developers"
as an open group (anyone can fork the github repo, find a problem, and make
an issue) deserve the trust we put in them, and that's because they're
accountable (any such error found in the repo will have been put there by
someone).  The same thing goes for making it possible to download (*not
just the compiled software*, but) the entire UTXO Set if a commitment of it
is hardcoded into the software, as James suggests.  We all trust
"developers" like that, and it's okay.  No one holds the "ring of power."
On Wed, Apr 3, 2019 at 8:39 AM Ethan Scruples via bitcoin-dev <

@_date: 2019-04-14 17:44:51
@_author: Dave Scotese 
@_subject: [bitcoin-dev] assumeutxo and UTXO snapshots 
No piece of data that does have significance to the Bitcoin consensus can
be memorable because it occurs (about) every ten minutes. In order to get
something memorable to provide sanity (let's say, anti-sybil-attack)
checking, it has to be rare, but recurrent.  The opportunity is actually
already there, but it usually goes by without providing the benefits.
For example, I found this blog post
by Ken Shirriff who describes artifacts that can be found in the
blockchain. These artifacts are not intimately tied to their location in
the blockchain, so anyone building an alternative blockchain can relatively
easily add the artifacts with the same timestamp and at the same height,
masking the counterfeit.  In order to prevent that, the memorable thing has
to be intimately tied to work-intensive results, like the ratio of the hash
to the target.  Nelson Mandela's image appearing in the blockchain does NOT
prove to me it's the blockchain I can see at blockchain.com right now, but
if the smallest block hash in that blockchain, on 12/13/13, after all the
zeroes, starts with 3da1 (144 * 65536 times as much work) and is one of the
three block hashes from that day that have two occurrences of a double-e
(about 256 times more work), then it will.  The problem is that I'll
probably forget most of those details - but not that Mandela's image went
in the blockchain near the end of 2013.

@_date: 2019-10-03 18:37:33
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Smaller "Bitcoin address" accounts in the blockchain. 
Currently, bitcoin must be redeemed by providing input to a script which
results in the required output.  This causes the attached amount of bitcoin
to become available for use in the outputs of a transaction.  Is there any
work on creating a shorter "transaction" which, instead of creating a new
output, points to (creates a virtual copy of) an existing (unspent) output
with a larger amount attached to it?  This would invalidate the smaller,
earlier UTXO and replace it with the new one without requiring the earlier
one to be redeemed, and also without requiring the original script to be
duplicated.  It is a method for aggregating bitcoin to a UTXO which may
otherwise not be economically viable.
The idea is that there already exists a script that must be satisfied to
spend X1, and if the owner of X1 would like to have the same requirements
for spending X2, this would be a transaction that does that using fewer
data bytes.  Since the script already exists, the transaction can simply
point to it instead of duplicating it.
This would also enable the capacity of lightning channels to be increased
on the fly without closing the existing channel and re-opening a new one.
The LN layer would have to cope with the possibility that the "short
channel ID" could change.

@_date: 2020-03-21 11:40:24
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Block solving slowdown question/poll 
It seems that many on this list think deeply enough to imagine the scenario
where we have  few days left before a difficulty adjustment comes up but we
also see mining power dropping off at a rate that suggests the few days
might become a few weeks, and then, possibly, a few months or even the
unthinkable, a few eons.  I'm curious to know if anyone has ideas on how
this might be handled because I'm sure we're not going to let it happen.

@_date: 2020-03-22 11:17:26
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Block solving slowdown question/poll 
The software currently allows up to a two hour difference between the
system clock and the time implied by a fresh block's timestamp (if I
remember correctly).  This reliance on realtime system clocks can be used
in a much weaker form to justify a plan for a difficulty adjustment to be
built into the software for when the expected block production rate is far
enough behind its expected value.
We would have to agree on how far behind mining should be to justify
expediting the adjustment.  The sooner we decide on and implement this
second difficulty adjustment trigger, the better.  It cuts off a nightmare
scenario made possible by collusion between states through regulation and
fiat, as well as any other external factors.  I propose that miners
detecting that the expected 2016 blocks have not been mined after twice the
expected wait time (4032 * 10 minutes = 28 days) ought to signal their
recognition in any block they produce, to be rejected by any miner whose
clock disagrees (after taking into account the 2-hour leeway), and that any
block produced on top of one with such a signal should reflect an expedited
difficulty adjustment (and also include the signal), which is then in
effect for the rest of the 2016 blocks and the entire following difficulty
period.  Every block from there until the modulo 2016 block should have the
same signal, which not only indicates that a difficulty adjustment was
expedited, but also that the next modulo 2016 block should not make one,
but rather turn off the signal.
If anyone thinks it's a good enough idea for a BIP, I will consider writing
one unless someone else wants to.
On Sun, Mar 22, 2020 at 9:54 AM Eric Voskuil via bitcoin-dev <

@_date: 2020-03-23 11:39:05
@_author: Dave Scotese 
@_subject: [bitcoin-dev] Block solving slowdown question/poll 
I believe this isn't something we need to address.  The fact is that every
byte stored in the blockchain is already valuable to everyone who downloads
the blockchain because of what it allows them to prove - by adding more
bytes to it.  Over time, the value per byte will increase.  Perhaps there
will be holding companies with specialized scripts that cost $500 - $1000
to add to the blockchain and allow those companies to handle transactions
for thousands of customers, kind of like a community lightning channel.
Anyway, yes, your idea is fundamentally broken because a zero block reward
happens because creating even one more satoshi will push the amount of
bitcoin over 21,000,0000, breaking the meaning of "bitcoin," or, if you
like, creating a fundamental contradiction in our use of the term.
