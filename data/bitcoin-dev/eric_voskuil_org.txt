
@_date: 2015-08-03 10:29:43
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Incentivising full nodes by having SPV nodes to 
The typical interpretation of the "tragedy of the commons" scenario is
based on the presumption that a limited resource is controlled by the state.
In a free market there is no such idea, a limited resource becomes
property and is therefore allocated by customer preference and
maintained by self-interest.
Validation is not a resource controlled by the state, which is of course
the point of Bitcoin.
It is inaccurate to think of Bitcoin validation a limited resource. The
scenario in which fewer people validate does not reduce the amount of
validation available. It increases the risk of loss to those who fail to
validate. The gain to those who do validate comes from avoiding that loss.

@_date: 2015-08-10 14:12:12
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Off-chain transactions and miner fees 
Hi Anthony,
No belief can be shown to be universally held, and an appeal to
authority is also a logical fallacy for good reason.
The blog you quote is littered with flawed economic ideas. It's become a
pet peeve of mine that people refer to mining (and/or validation) as a
"tragedy of the commons" problem, or a "public good" subject to a "free
rider" problem. This betrays a fundamental misunderstanding of both
money and Bitcoin.
I'm not commenting on the other merits of your argument or others in
this thread, I mean just to dispute the validity of this particular
reference. Even the portion you quoted is quite absurd:
We don't "really need" to prevent "printing money" - Bitcoin could
somehow get by without that constraint? Preventing the printing of money
is the only reason that Bitcoin exists.
The tragedy of the commons scenario properly applies only to property
controlled by the state. In the quoted blog the analogy is so misapplied
that it fundamentally misrepresents the forces at work in Bitcoin.
Bitcoin is not at all "like a lighthouse". State run lighthouses are
financed via taxation. That may be taxation of anything, whether or not
related to the shipping the lighthouse purports to protect. It may in
fact protect no shipping at all, since payment is generally completely
divorced from benefit, and the benefits may be completely divorced from
shipping. For example, preservation of jobs for lighthouse keepers and
the Coast Guard, or even nostalgia. Just as with a private grazing
field, a truly private lighthouse would not have a "commons problem" at all.
Bitcoin mining is financed by a fixed schedule of inflation and
transaction fees. State inflation is a tax on all holders of currency
and a form of default on state debt. This and other taxes fund
lighthouses. A tax is the seizure of someone else's property through
force. Bitcoin inflation is predictable, so the inflation cost is
factored in to its value before it is acquired, according to the
depreciation schedule, just like bond valuation for example. This means
it is NOT a tax, is merely a cost that is paid to miners for use of
their security services.
Bitcoin transaction "fees" are not fees in the state use-fee (taxation)
sense, since the fees are priced based on voluntary trade. The blog
misinterprets who is paying the cost of securing a transaction when it
claims, "it's the sender who pays." Both parties to a transaction bear
the cost of using any given medium of exchange. If the receiver is
concerned about double spending risk, it's the sender who will have to
compensate with time and/or money. But this is just as much a cost to
the receiver as it has raised the effective price of his sales with the
difference in money accruing to the third party.
Finally, transaction fees *are* mining contracts. Creating *another*
system of mining contracts initiated by a receiver would do nothing to
change the economics, but it would significantly complicate the
implementation (raising costs generally). The cost of paying a mining
contract would of course be paid by the sender, in terms of increased
price charged by the receiver.
I believe that a fundamental misunderstanding of the important
distinction between voluntary trade and state-controlled trade is
underpinning a lot of confusion and misunderstanding with respect to the
block size debate. Bitcoin does not have a commons problem specifically
because it's designed to resist state control. It's only in the loss of
that independence that such a problem would arise (and effectively kill
Bitcoin altogether).
Ironically the desire to fix a non-existent commons problem in Bitcoin
seems to be a driving force behind what may in fact weaken its only
defence against eventually becoming a commons.

@_date: 2015-08-11 18:18:10
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Fees and the block-finding process 
Hi Michael,
What you seem to be missing is *why* bitcoin is better money. Have you
considered why is it comparatively inexpensive to transact in a medium
that is based on such a highly inefficient technology?
You might want to consider that these two considerations are not
independent. The reduced cost of transacting (and carrying) Bitcoin is a
direct consequence of its trustless nature. Any compromise in that
nature will eliminate that advantage, and therefore Bitcoin.
Bitcoin is designed to solve only one problem that other systems do not.
To accomplish this it makes significant compromises in other areas. The
benefit of this solution is that it cannot be effectively controlled by
the state. As a result, all of the associated overhead is eliminated.
Hence the net cost benefit despite high technical costs.
So this is a case where you should be careful what you wish for.

@_date: 2015-08-16 13:27:41
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Bitcoin XT 0.11A 
[cross-posted to libbitcoin]
I applaud this effort not for the merits of the hard fork but on the
effects of the code fork. We have been witnessing the self-destruction
of Bitcoin's central authority. This is a necessary outcome.
Understandably, many are concerned that if consensus settles on a larger
block size Bitcoin will suffer greater centralization. The point of
Bitcoin however is that nobody is in control of consensus. If a
consensus decision leads to centralization, the consensus will move.
Yes, when this happens people who bet on the losing fork will lose
money. This is how Bitcoin works. One bets not on personal desires but
on what others will accept. That is how consensus is built.
Some fret that if this process evolves Bitcoin will suffer a
catastrophic loss of "value" and not recover. This may come to pass, but
there is no avoiding the possibility.
The ease with which consensus can move when it wants to is important. In
other words, friction is weakness and a single overly complex codebase
is high friction.
Amir saw this coming before most. While we are posting manifestos, I
thought it more than appropriate to quote from the libbitcoin manifesto:

@_date: 2015-08-18 14:40:27
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] libconsensus assertion fails if used in multiple 
If performance was the only trade-off with Java, and if C++ was frozen
in time, I would say you have a point.
Thanks for submitting, and Cory, thanks for working this out.

@_date: 2015-08-19 16:07:01
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Bitcoin XT Fork 
[cross-posted to libbitcoin]
> On Wed, Aug
policies?and we should make an effort to separate the two clearly. And
we should find a way to communicate the difference succinctly and
clearly to laypeople (which is something I think the XT opponents have
been horrible at doing so far).
I applaud your efforts and objectives WRT libconsensus independence. But
as you know I differ with you on this point:
I do not consider Bitcoin Core just another implementation as long as
libconsensus is built directly out of the bitcoind repository. It's a
finer point, but an important one. Eric makes this point emphatically as
policies...and we should make an effort to separate the two clearly.
As you have implied, it's not likely to happen in the Bitcoin Core repo.
Taking a dependency on Bitcoin Core is a metaphorical deal with the
devil from our perspective. So my question is, how do you expect other
implementations to transition off of that repository (and commit
policies)? Or do you expect the dependency to be perpetual?
In our discussion leading up to libbitcoin building libbitcoin-consensus
we disagreed on whether intentional hard forks would (or even could)
happen. I think that issue is now settled. So my question remains how do
stakeholders (users/miners) maintain consensus when it's their
individual intent (the first objective of libconsensus), and diverge
when intended (which a direct dependency on libconsensus makes harder)?
IMO it's unreasonable to operate as if this won't happen, given that it has.
There are a very small number of implementations that rely on consensus
(fewer that aren't also forks of Bitcoin Core). I think it's time we
discuss how to work together to achieve our mutual goal. I assume you
have been in contact with all of us. If you would like to facilitate
this I'd be happy to join in an offline discussion.

@_date: 2015-08-19 17:08:30
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Bitcoin XT Fork 
I don't see this happening any time soon, and I'm not sure why we should
wait for it.
You might consider this as feedback from your customer base.
That's a false dichotomy. We never would have considered forking Bitcoin
Core, and still wouldn't. Why would we set ourselves up for this
disruption, which would inevitably lead to us factoring the consensus
portions of libconsensus out of /bitcoin at the 11th hour?
We have to operate as if it can happen at any time. Otherwise we have
relinquished control of this vote and failed our users. Given that
operating assumption, it is much safer for us to have already done this
work (which we did). [It also provides a forcing function for us to
review in detail any consensus changes that get pushed out.]
My question is why you would not embrace an independent consensus
repository? Your work to evolve it doesn't change.

@_date: 2015-08-25 14:28:11
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Dynamically Controlled Bitcoin Block Size Max Cap 
One should be clear that Bitcoin is by no possible measure a democracy.
The proposed vote is on what goes into a particular github repository.
The outcome is ultimately controlled by those with control of that
Bitcoin is an anarchy by design. People will use whatever they want.
the max
those, what fraction have the technical knowledge to make an informed
vote? It would be like polling Toyota truck owners to see whether the
2017 Tacoma should increase its engine's cylinder displacement by 10%.
Ordinary users just aren't going to be able to vote meaningfully, and
most won't respond to the poll at all.
mechanisms. An equivalent process for Bitcoin would be that the max
block-size limit (and other fundamental economic parameters) would be
determined via a process of forking off altcoins (such as Bitcoin XT
will do) and allowing the market to decide which coin is most valuable.
This is the "default" mechanism for change (because it's what naturally
happens when there is a lack of internal consensus), but it's not the
least painful mechanism.
voters are really in no position to cast informed votes, nor should they
be (cf. "rational ignorance" [1]). I do not oppose opening up the
determination of the max block-size limit to a popular "check" via
stakeholder vote ? actually, I think this is an important check on
miners' power ? but I do argue that the vote is likely to have
drastically little participation and very low-quality results.
"rational" when the cost of educating oneself about the issue
sufficiently to make an informed decision can outweigh any potential
benefit one could reasonably expect to gain from that decision, and so
it would be irrational to waste time doing so.?

@_date: 2015-02-02 11:05:57
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
In sending the first-signed transaction to another for second signature, how does the first signer authenticate to the second without compromising the  independence of the two factors?
Sent from my iPhone

@_date: 2015-02-02 11:45:49
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
Confusing or not, the reliance on multiple signatures as offering greater security than single relies on the independence of multiple secrets. If the secrets cannot be shown to retain independence in the envisioned threat scenario (e.g. a user's compromised operating system) then the benefit reduces to making the exploit more difficult to write, which, once written, reduces to no benefit. Yet the user still suffers the reduced utility arising from greater complexity, while being led to believe in a false promise.

@_date: 2015-02-02 14:54:25
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
Sorry for the slow reply, traveling.
My comments were made in reference to this proposal:
In the multisig scenario the presumption is of a user platform compromised by malware. It envisions a user signing a 2 of 3 output with a first signature. The precondition that the platform is compromised implies that this process results in a loss of integrity of the private key, and as such if it were not for the second signature requirement, the malware would be able to spend the output. This may be extended to all of the keys in the wallet.
The scenario envisions sending the signed transaction to an another ("third") party. The objective is for the third party to provide the second signature, thereby spending the output as intended by the user, who is not necessarily the first signer. The send must be authenticated to the user. Otherwise the third party would have to sign anything it received, obviously rendering the second signature pointless. This implies that the compromised platform must transmit a secret, or proof of a secret, to the third party.
The problem is that the two secrets are not independent if the first platform is compromised. So of course the malware has the ability to sign, impersonate the user and send to the third party. So the third party *must* send the transaction to an *independent* platform for verification by the user, and obtain consent before adding the second signature. The user, upon receiving the transaction details, must be able to verify, on the independent platform, that the details match those of the transaction that user presumably signed. Even for simple transactions this must include amount, address and fees.
The central assumptions are that, while the second user platform may be compromised, the attack against the second platform is not coordinated with that of the first, nor is the third party in collusion with the first platform.
Upon these assumptions rests the actual security benefit (increased difficulty of the coordinated attack). The strength of these assumptions is an interesting question, since it is hard to quantify. But without independence the entire security model is destroyed and there is thus no protection whatsoever against malware.
So for example a web-based or other third-party-provisioned implementation of the first platform breaks the anti-collusion assumption. Also, weak comsec allows an attack against the second platform to be carried out against its network. So for example a simple SMS-based confirmation could be executed by the first platform alone and thereby also break the the anti-collusion assumption. This is why I asked how independence is maintained.
The assumption of a hardware wallet scenario is that the device itself is not compromised. So the scenario is not the same. If the user signs with a hardware wallet, nothing can collude with that process, with one caveat.
While a hardware wallet is not subject to onboard malware, it is not inconceivable that its keys could be extracted through probing or other direct attack against the hardware. It's nevertheless an assumption of hardware wallets that these attacks require loss of the hardware. Physical possession constitutes compromise. So the collusion model with a hardware wallet does exist, it just requires device possession. Depending on the implementation the extraction may require a non-trivial amount of time and money.
In a scenario where the user signs with HW, then sends the transaction to a third party for a second of three signatures, and finally to a second platform for user verification, a HW thief needs to collude with the third party or the second platform before the owner becomes aware of the theft (notifying the third party). This of course implies that keeping both the fist and second platforms in close proximity constitutes collusion from a physical security standpoint. This is probably sufficient justification for not implementing such a model, especially given the cost and complexity of stealing and cracking a well-designed device. A device backup would provide comparable time to recover with far less complexity (and loss of privacy).
Incidentally the hardware wallet idea breaks down once any aspect of the platform or network to which it connects must be trusted, so for these purposes I do not consider certain hybrid models as hardware wallets at all. For example one such device trusts that the compromised computer does not carry out a MITM attack between the signing device and a shared secret entered in parts over time by the user. This reduces to a single factor with no protection against a compromised platform.
Of course these questions address integrity, not privacy. Use of a third party implies loss of privacy to that party, and with weak comsec to the network. Similarly, use of hardware signing devices implies loss of privacy to the compromised platforms with which they exchange transactions.

@_date: 2015-02-02 16:41:20
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
One clarification below.
My comments below start out with the presumption of user platform
compromise, but the same analysis holds for the case where the user
platform is clean but a web wallet is compromised. Obviously the idea is
that either or both may be compromised, but integrity is retained as
long as both are not compromised and in collusion.

@_date: 2015-02-02 23:38:07
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal to address Bitcoin malware 
No, that's not it. Sorry for not being clear. Independence of control is
the central issue in the analysis of a multiple factor system. If an
attack compromises one factor there must be no way for that attack to
reduce the difficulty of obtaining the other factors.
Some factors (secrets), like a fingerprint, aren't very secret at all.
But getting someone's fingerprint doesn't also help the attacker get a
PIN. That factor must be attacked independently. But if the PIN is
encrypted with the fingerprint in a public store, then the PIN is not
independent of the fingerprint and there is really only one secret.
If multiple factors are coincident (located within the same security
perimeter) they are compromized coincidentally. Coincidence has the same
effect as dependence. Consider a credit card with a "security code"
printed on the back. A successful attack on the leather wallet yields
both secrets.
Individual environments can be compromised with some difficulty (e.g.
desktop malware, fingerprint lift, dictionary attack, brute force PIN,
etc.). For the sake of simplicity, let that chance of successful
independent attack on any factor be 1 in 2 and the resulting probability
of successful concurrent attack on any n factors be 1 in 2^n. If m
factors are dependent/coincident on others the relation becomes 1 in
Any multi-factor web wallet that handles the user's keys in the browser
and authenticates the user in the browser to authorize service signing
is effectively single factor. One attack may be launched by an insider,
or externally, against the web app, executing in the browser, gaining
coincident access to two secrets. Browser/desktop malware can accomplish
the same. The difficulty is 1 in 2 vs. the expected 1 in 4.
I'm not questioning the motive, I agree it's worth trying. But trying is
not succeeding. Increasing user (and/or system) complexity without
increasing integrity or privacy is a poor trade, and worse if the user
is misled.

@_date: 2015-02-03 17:03:53
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Subject: Re: Proposal to address Bitcoin 
Using the Bitcoin network would be a convenience, certainly not a
requirement. Any public store (or other channel accessible to all
signers) would do.
Absolutely, there is no need for a trusted third party in the case of
MFA unless that party has independent judgement in the decision to sign.
For example, if the third party is the trustee of a fund from which a
beneficiary wants to withdraw.
If you are just routing a decision back to yourself a third party makes
no sense. Oddly most of the services in operation today are doing just
that. You will end up authenticating to the third party from a platform
you control, which means that the platform must be trusted as much as
the third party. Why not just trust the platform and no third party? It
doesn't reduce the number of factors but it certainly reduces the attack
There's no need for the devices to be on independent networks. You can
safely remove that constraint. The partially-signed transaction can be
encrypted to the other signatories (for privacy) or it can be sent in
the clear. And ultimately all platforms in the scheme are connected to
the Internet, even if it's via sneakernet.
The important requirement is that the signing platforms are independent
and that the signers inspect the transactions on those platforms. This
preserves the benefit of MFA, which is that the signing platforms must
be compromised independently.
Once you've done this you are talking about two independent signing
platforms. Plug two trustworthy signing devices into a PC and you've
done it. This is because the host environment (the PC in this case) is
not trusted in the first place. Two untrusted environments are no better
than one. It's only if the environments are trusted that they must be
But therein lies the problem. The physical proximity of two trusted
hardware devices exposes them to a single attack in the case of physical
theft or loss. So to guard against that threat the devices must be
independently stored. This presents a problem when it comes to usage.
This is the central problem of MFA. It's not possible to control
multiple factors while not exposing them to compromise. This is true
whether we are talking about multiple physical devices or a remote
service, since in the remote case the secret must still be accessible to
the person in control.
In the case of truly independent decisions MFA is strongest. But short
of that there's no reason for a remote third party. One can probably
accept the risk of securing multiple devices with the home, etc - and
needs to do this even if using a third party. On the other hand, walking
around with all necessary factors, or keeping them in the same safe, is
tantamount to having just one factor.

@_date: 2015-02-05 12:44:38
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
I'm not sure you could assume this, even if the payer only received one
broadcast. And if the payer receives multiple, it constitutes a DOS on
the scenario, potentially unintentional.
Agree, the problem of the payer strongly identifying the receiver
requires either proximity (NFC or QR code scan from the known-good
source) or PKI/WoT. The problem can't be resolved through a broadcast.
I'm imagining myself walking around broadcasting my photo and MAC
address while hucksters push payment requests to me for approval, while
recording my photo and correlating it to my address. It will pretty
quickly turn in to a scenario where I need to touch something before
this is turned on.

@_date: 2015-02-05 13:23:48
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
Yes, a stellar device for mass surveillance coupled with transaction tainting.

@_date: 2015-02-05 12:59:48
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
Interesting take on privacy. But the market will of course decide.
Would the merchant be broadcasting payment requests in the clear, or
would they be encrypted with a public key of the spender?
Not sure I'd shoot for a system that's guaranteed to require PKI with
blacklisting and spam filtering.

@_date: 2015-02-05 13:46:10
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
BLE has an advertised range of over 100m. In the case of mass surveillance that range could most likely be extended dramatically by the reviewer. I've seen  WiFi ranges of over a mile with a strong (not FCC approved) receiver.
WiFi hotspots don't have strong identity or a guaranteed position, so they can't be trusted for location.

@_date: 2015-02-05 14:05:39
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
Hi Paul,
The issue is in the establishment of trust. Anyone can broadcast the initial information.

@_date: 2015-02-05 14:10:51
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
A MITM can receive the initial broadcast and then spoof it by jamming the original. You then only see one.

@_date: 2015-02-05 15:22:50
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
I agree that with manual verification between the parties the worst
problem becomes DOS, which is certainly not catastrophic.
But the objective is to the extent possible improve upon the cumbersome
process of QR code, NFC signal, or textual address scanning. Given that
there would be no way to know you are under attack, with the exception
of manual confirmation, it would seem unwise to ever rely on the
automation. If the automation cannot be relied upon, it may actually
make matters worse. People would either take their chances by relying on
it or go through a more complex process.
In terms of the difficulty of an attack, it's important to recognize
that all attacks (DOS, privacy, integrity) in this scenario can be
fully-automated and executed over the air by a black box at some distance:
* DOS is possible by rebroadcasting a similar request.
* Privacy is compromised by monitoring for payment requests and
correlating them to location and potentially images of parties.
* Integrity is compromised by either:
(1) Rebroadcasting a similar transaction with a bogus address but with
the same leading characters; can't be spent but you lose your money.
(2) Rebroadcasting with a valid address that doesn't match the leading
characters, in the expectation that the user doesn't check manually.
Regarding possible mitigation via BIP-70:
A BIP-70 signed payment request in the initial broadcast can resolve the
integrity issues, but because of the public nature of the broadcast
coupled with strong public identity, the privacy compromise is much
worse. Now transactions are cryptographically tainted.
This is also the problem with BIP-70 over the web. TLS and other
security precautions aside, an interloper on the communication, desktop,
datacenter, etc., can capture payment requests and strongly correlate
transactions to identities in an automated manner. The payment request
must be kept private between the parties, and that's hard to do.
So the initial broadcast needs privacy, but then of course it cannot be
a broadcast - it need to be a narrow cast. That brings us back to
proximity-based establishment.
I think that you could get away with this for a while, simply because of
the narrow fields we are working in presently. But in a bitcoin world it
would be very problematic. For this reason I wouldn't want to encourage
standardization on this approach.

@_date: 2015-02-05 15:46:56
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
Hi Martin,
The problem is that you need to verify the ownership of the public key.
A MITM can substitute the key. If you don't have verifiable identity
associated with the public key (PKI/WoT), you need a shared secret (such
as a secret phrase). But the problem is then establishing that secret
over a public channel.
You can bootstrap a private session over the untrusted network using a
trusted public key (PKI/WoT). But the presumption is that you are
already doing this over the web (using TLS). That process is subject to
attack at the CA. WoT is not subject to a CA attack, because it's
decentralized. But it's also not sufficiently deployed for some scenarios.

@_date: 2015-02-05 15:59:33
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
In this case there is no need for P2P communication, just pay to an
address you already have for the other party. If you want to avoid
address reuse, use stealth addressing.
But yes, if you don't have a stealth address for the other party you can
certainly communicate in private as peers where you trust that you share
a public key. The core issue here is really bootstrapping of that trust
in an ad hoc manner.
Yes, proximity is practically the universal solution to the problem of
the payer identifying the correct seller in any face-to-face scenario.
When identification is required (show me some id before I pay you) it
equates to the BIP-70 scenario in the bitcoin model. This is also
required in order guard against repudiation (give me a signed receipt).

@_date: 2015-02-05 16:22:23
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
I was analyzing the model as you described it to me. A formal analysis
of the security model of a particular implementation, based on inference
from source code, is a bit beyond what I signed up for. But I'm
perfectly willing to comment on your description of the model if you are
willing to indulge me.
How do they compare words if they haven't yet established a secure channel?
So the assumption is that there exists a secure (as in proximity-based)
communication channel?

@_date: 2015-02-05 16:36:13
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Two Proposed BIPs - Bluetooth 
Hi Andy,
This is good stuff. I've spent quite a bit of time on this question, but
set aside most of it earlier in the year in order to make some progress
in other areas. I did review what I found available at the time
pertaining to the Schildbach implementation and these questions.
Skimming the links now I'm encouraged, but I see several things that I'd
like to discuss at greater length than is appropriate here.
The main advantage of BLE over BT is that it uses much less power, with
a trade-off in lower bandwidth (100 kbps vs. 2 mbps). The BLE range can
be even greater and connection latency lower than BT. For payment
purposes the lower bandwidth isn't much of a hit.

@_date: 2015-02-05 17:05:23
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
Another (unspendable) address can trivially match the prefix. Imagine
someone walking around in a mall with a phone in the pocket with a
malicious app, just disrupting business by causing money to be burned.
Manual verification doesn't fix this attack.
I don't think it would be great to constrain a standard implementation
to low cost purchases or the need for manual verification, but again
manual prefix verification isn't actually a solution.
An appeal to the security of BT bootstrapping isn't exactly flattering.
You know I love Airbitz, and I know you guys are extremely privacy
conscious. I personally would have no problem using this feature under
certain circumstances. My question is only whether it would be wise to
standardize on the proposal as-is.

@_date: 2015-02-05 17:29:03
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
Notice from my original comment:
I said this could only be accomplished using a shared secret or a
trusted public key. Exchanging a value that is derived from a pair of
public keys is a distinction without a difference. The problem remains
that the parties must have a secure/out-of-band channel for
communicating this value.
The fact that they are face-to-face establishes this channel, but that
brings us back to the original problem, as it requires manual
verification - as in visual/audible scanning of the two values for
comparison. At that point the visual comparison of the address, or some
value derived from it, is simpler.
This is reasonable, but wouldn't help in the case of an ad-hoc
connection between parties who don't know each other well.
I appreciate the offer. I really don't trust *any* smartphone as a
platform for secure communication/data. But encrypting on the wire does
of course shrink the attack surface and increase the attacker's cost.
 nap?sal:

@_date: 2015-02-05 18:14:22
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Two Proposed BIPs - Bluetooth 
Agree, range is not an issue. The trade-off is in battery vs. total
time, which would be influenced primarily by the battery sensitivity of
the platform. I'll send you a note to follow up.

@_date: 2015-02-06 01:00:40
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Two Proposed BIPs - Bluetooth 
Hi Andreas,
I haven't expressed any preference for BLE, just answering questions
that were raised about it. The main thing that BLE brings to the table
is increased battery life, but with larger transfers that benefit is

@_date: 2015-02-06 01:13:10
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
Certainly, which brings us back to proximity.
Which reminds me - it's important to keep in mind the scenario that
arises when there is no person present to represent the receiver. Such
as a vending machine purchase.
Proximity in these cases is insufficient, as the receiver is not able to
prevent application of a fraudulent NFC device or replacement of a
static QR code. In these cases BIP-70 becomes essential.

@_date: 2015-02-10 02:59:21
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Standardizing automatic pre-negotiation 
all merchants)
Hi Natanael,
BIP70 exists for seller non-repudiation (i.e. a cryptographically signed
receipt for payment) and establishing strong seller identity in a
face-to-face or other non-web scenario (since TLS doesn't help).
Anything else is incidental.
There's quite a bit that can be done with wallets and web sites, but
personally I'd freak out if my wallet prompted me because I visited a
web site.

@_date: 2015-02-10 08:55:58
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
I like your idea for the commit protocol in that it resolves the
vandalous address substitution attack. However, I don't see a way to
prevent privacy loss without adverse impact to the scenario.
Anyone could perform the handshake and thereby obtain the payment
request. Therefore to prevent inadvertent disclosure the customer must
visually confirm the "phrase" and then verbally tell the merchant to
proceed by sending the payment request.
One might argue that it's sufficient to preserve the integrity of the
transaction while suffering the privacy loss, especially given that a
hijacked handshake should never result in a completed transaction -
unless of course the hijacker pays.
But imagine someone purchasing their meds. HIPAA requires the checkout
queue to form behind a yellow line. That speaks directly to this question.

@_date: 2015-02-10 09:56:39
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposal for P2P Wireless (Bluetooth LE) 
Yes, I think this was clear from your description.
Yes, for each handshake the payment request would need to contain a
different address, mitigating some of the privacy loss.
It can be done securely and privately by transfer of a shared secret
through a private channel.
I think for a broadcast model (e.g. Bluetooth only) that is the only
want to ensure integrity and privacy. A narrow cast can use proximity to
establish trust.

@_date: 2015-02-22 14:39:42
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
Hi Jan,
This is really nice work.
WRT the Schroder and Schildbach proposal, the generalization of the "r"
and "payment_url" parameters makes sense, with only the potential
backward compat issue on payment_url.
Yes, this design is problematic from a privacy standpoint. Anyone within
the rather significant range of the Bluetooth terminal is able to
capture payment requests and correlate them to people. In other words it
can be used to automate tainting.
The problem is easily resolved by recognizing that, in the envisioned
face-to-face trade, proximity is the source of trust. Even in the above
proposal the "h" parameter is trusted because it was obtained by
proximity to the NFC terminal. The presumption is that this proximity
produces a private channel.
As such the "tap" should transfer a session key used for symmetric block
cipher over the Bluetooth channel. This also resolves the issue of
needing to formulate the payment request before the NFC.
As an aside, in other scenarios, such as an automated dispenser, this
presumption does not hold. The merchant is not present to guard against
device tampering. Those scenarios can be secured using BIP70, but cannot
guarantee privacy.
The other differences I have with the proposal pertain to efficiency,
not privacy or integrity of the transaction:
The proposed resource name is redundant with any unique identifier for
the session. For example, the "h" parameter is sufficient. But with the
establishment of a session key both as I propose above, the parties can
derive a sufficiently unique public resource name from a hash of the
key. An additional advantage is that the resource name can be
fixed-length, simplifying the encoding/decoding.
The MAC address (and resource name) should be encoded using base58. This
is shorter than base16, is often shorter than base64, better
standardized and does not require URI encoding, and is generally
available to implementers.
There is no need for the establishment of two Bluetooth services.
I would change the payment_url recommendation so that the list order
represents a recommended ordering provided by the terminal for the wallet.
I wrote up my thoughts on these considerations last year and recently
revised it by adding a section at the end to incorporate the "r" and
"payment_url" generalizations from Andreas and Andy.

@_date: 2015-02-22 14:48:20
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
One correction inline below.
The MAC address (and session key) should be encoded using base58. This

@_date: 2015-02-22 15:06:01
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
Yes, this should be a prerequisite issue to all others.
There is no reason to add this significant complexity. The purpose of
SSL/TLS is to establish privacy over a *public* channel. But to do so
requires verification by the user of the merchant's public certificate.
Once we rely on the channel being *private*, the entire SSL process is
Presumably we would not want to require PKI for privacy, since that's a
bit of a contradiction. But if one wants to do this NFC is not required,
since the private session can be established over the public (Bluetooth)

@_date: 2015-02-22 16:05:06
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
If the NFC communication is not private then there is no reason to use it.
See my comments on an unmonitored terminal.
My point is that you are not solving that problem by creating a more
complex system. Either you establish trust via proximity or you don't.
If you don't, it's a public network. If you do, then keep it simple.
There's nothing holy about a session key in this scenario. It's not
derived from long-lived keys and is itself used only once. There is
nothing wrong with the URL carrying the secret. If you want to secure
this channel without manual intervention, there is ultimately no other

@_date: 2015-02-22 16:46:28
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
I don't think there is another option. The point of the NFC terminal is
to establish trust based on proximity.
I don't agree that it's insufficiently private. It's no less private
than if the customer pulled out an R2-D2 interface arm and plugged into
the merchant's terminal. The terminal connection can still be compromised.
IOW the merchant trusts that the person who just tapped on the NFC
terminal is the one who he/she is going to hand the product to, and both
parties trust that because of this handshake, no non-proximate
interlopers can monitor the content of the transaction. In the absence
of BIP70 (quite real in some scenarios) the payer also relies on
proximity to establish the identity of the receiver.
Otherwise, without proximity establishment, an *independent* secure
channel is required (see the Airbitz/RedPhone discussion). You end up
with an infinite regression problem. RedPhone terminates this regression
by relying on each party's ability to recognize the other's voice, and
in the difficulty of spoofing a voice. PKI deals with it by trusting
root CAs on presumed-trusted platforms (and a troublesome revocation
process). WoT establishes this by unspecified means (e.g. Peter Todd has
produced a nice video of him reading out his PGP key fingerprint).
If interlopers are so close to the NFC terminal that they can join the
session, they have effectively compromised an endpoint, so the privacy
problem becomes moot. Both endpoints must secure their devices to
achieve privacy in any design.
Understood, it just isn't entirely clear to me that the backward compat
in this case doesn't depend on implementation choices of existing
systems. In any case it may be worth the small potential risk to achieve
the more elegant design.
Understood, but it is more flexible to provide the recommendation that
the payment_url set be priority-ordered as well. This allows the seller
to deviate from the protocol (URL scheme) coupling, while also allowing
it to be established, as desired. Presumably it's the merchant's
priority that we want the wallet to honor where possible.

@_date: 2015-02-23 01:40:00
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
We have the same objective. Privacy loss is my primary concern with the
existing proposal.
I realize you are postulating a situation where an interloper monitors
but doesn't substitute the NFC communication. But clearly if you can do
one you have the potential to do the other, so if one is going to rely
on the assumption that the NFC tap can be monitored one must also accept
that it can be modified. Once one accepts this premise there is no point
in using NFC.
You can send a public cert over a public channel but before it can be
used it must be validated and verified to belong to the party that you
intend to communicate with privately. Otherwise the interloper can
substitute a public cert and subvert the payment process.
The reduces to the system requiring PKI just to establish private
communication. One might argue that BIP-70 already contemplates PKI.
However the above approach is significantly different in that it would
*require* all NFC/BT communication to use PKI just to be private.
Furthermore, to establish a private channel between *both* intended
parities, public certs must be exchanged in both directions. Otherwise,
if the customer isn't validated by the merchant, a distant interloper
can trivially use the merchant's public cert to obtain the payment
request from the Bluetooth terminal. This is the privacy breach that we
are trying to prevent in the first place.
Any requirement for PKI, in either direction, itself creates privacy
problems. But a requirement for customer certificates really gets hairy.
The PKI requirement can be dropped by instead exchanging self-generated
public keys, in the RedPhone model. However that requires out-of-band
secure communication of a common derived value by the parties. This
could be as simple as a number on each screen that one or both of the
parties compares. But this requires no private communication, and
therefore NFC is entirely unnecessary. This is in fact what I would
recommend for the BT-only scenario.
The value added by NFC is that proximity can be used to establish trust.
If that does not meet one's threshold for privacy then the parties need
to establish this trust through some presumably more private channel
(such as visual or voice confirmation).
Note that payment integrity can be reasonably ensured by relying on PKI
as established by BIP-70 (which also offers the seller non-repudiation
benefit). So this question is strictly about privacy.
In this case the attacker hijacks the subsequent BT connection, sends a
payment request and gets paid. The only thing to prevent it would be
BIP-70/PKI, as mentioned above.
In a more complex attack the interloper can sit in the middle of all
communications between payer and receiver. Since the payer is not
validated by the receiver the interloper can impersonate the payer in
all communication with the receiver. As such he can also impersonate the
receiver in all communications with the payer. If the NFC communication
is compromized there is no saving privacy without an alternate private
The motive and privacy loss remain unchanged.
If the NFC tap is sufficiently private, privacy is easy to achieve for
the subsequent communication. If it is not, privacy can be completely
compromised. The question is only how much more difficult is the attack.
With the public cert tap, the level of difficulty is much lower for
capturing selected payment requests. The interloper no longer needs to
invade the space of the NFC terminal and can instead impersonate the
payer from a safe distance. Nobody gets paid, but privacy is compromised.
The level of difficulty in the case where the interloper wants to taint
transactions may appear lower, but it is not:
With the session key tap the interloper must compromise the NFC location
and then monitor the BT traffic. Monitoring BT traffic without being
party to the connection is presumably not rocket surgery, but not
standard BT design either.
With the public cert tap the interloper must also compromise the NFC
location and communicate over BT. Therefore the hardware and physical
attack requirements are similar. The only added difficulty is that the
attack on the NFC terminal attack is active (modifying the MAC address
directing the payer to the BT service).
However impersonating the payer is just a matter of software - no more
difficult than the session key attack. In fact it may be much easier to
implement, as the attack can use supported BT features because the
attacker has directed the payer to connect to him and is connecting to
the receiver as if he was a payer.
But it gets worse for the public cert tap, since a more sophisticated
attacker can set himself up in the same position without subverting the
NFC terminal at all. By broadcasting a more powerful BT service on the
same advertised MAC address, the attacker can capture traffic and relay
it to the intended service.
So in sum, reliance on a public cert makes the communication less
private under the same physical set of constraints. The difference
results from the receiver allowing non-proximate payers to impersonate
proximate payers from a distance by generating their own session keys
and submitting them over BT.
Attacks against wires do not require tampering with (as in damaging)
wires. The distinction between a wired connection and a wireless
connection is in many ways imaginary.
I think I addressed this above but let me know if not.
Yes, ultimately both endpoints must be secured. My point is that (when
intended) NFC is practically the equivalent of a wired connection.
Baseband attacks against buyers' phones or subversion of the entire POS
terminal may be easier than interloping on a monitored NFC terminal. But
that's the point, once the attack is easier at the endpoints that is
where it will go. Further attempts to secure the gap between the devices
will not help after that point.
No need for apology, it's a good discussion, and there are precious few
experts here.
This discussion should make people very wary of any terminal system that
doesn't use signed payment requests :).

@_date: 2015-02-23 02:08:28
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
Hi Andreas,
DHKE will not improve the situation. Either we use a simple method to
transfer a session key or a complex method.
DHKE doesn't offer greater forward secrecy than private transfer of a
session key, in fact it's lesser.
I don't see that there is a dilemma. The current proposal has a
significant privacy problem that can be easily resolved, and the
resolution actually makes the implementation simpler.

@_date: 2015-02-23 15:00:29
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
Before addressing other issues I could use some clarification on your
In one statement you refer to derivation of a session key from a bitcoin
address (passed via NFC):
In another statement you refer to derivation of a session key from a
public key (passed via  BT):
I don't see how you propose to treat the bitcoin address as a secp256k1
public key, or do you mean something else?

@_date: 2015-02-23 16:10:47
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
No problem, we don't all have the same context. I may have missed prior
Does this not also require the BT publication of the script for a P2SH

@_date: 2015-02-23 18:55:05
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
Andy, adding to my previous post below:
This problem in the preceding paragraph can be resolved by sending a
unique public key on each NFC tap. In that case an attacker would need
to monitor the NFC communication.
The talk of wrapping the connection in SSL led me to believe you were
talking about a static public certificate. However that's not a
necessary assumption here and may not be what you intended.
I believe your central claim was that the difference in the two
bootstrapping approaches (public key vs. session key) is that by using a
unique public key per tap, the attack requires an active vs. passive
attack on the NFC terminal. I just wanted to make clear here that I
agree with that assessment.
The symmetric key approach is based on the idea that these attacks are
comparable in difficulty and otherwise identical in privacy loss.
However, the difference in implementation amounts to about +23
additional encoded characters for the BT/LE URL, assuming use of the
secp256k1 curve for DHE. This is really not a material issue in the case
of the NFC tap. The entire URI+URL could be as small as:
In comparison to a symmetric key:
It also does not change the protocol design or complexity at all - it
would just swap out an AES key for a secp256k1 public key.
If that gets us aligned I'm all for it.
I'm retracting the last paragraph, since the interloper, without
invading the NFC connection (by substituting the public cert), could not
read the relayed traffic. It was getting late :/

@_date: 2015-02-24 03:28:27
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
Because the presumption was that there was not an additional secret in
the URI. If the public key is reused then anyone can spoof a payer and
obtain payment requests.
Adding a secret to the URI can resolve this, as long as it is encrypted
with the public key before being transmitted back to BT. Otherwise the
secret can be intercepted and replayed to the terminal, encrypted with
the well-known public key.
So if you want to treat the "resource" as a secret this would work.
However the resource was designed as a public session identifier,
leading the byte stream. This changes it to private session identifier,
which loses some utility.
Also, reuse of the public key introduces a forward secrecy problem and
the potential for persistent seller impersonation in the case of
undiscovered key compromise.
But there's really no benefit to reusing the key. An ephemeral key
resolves these issues and can also seed the public resource name.
Don't you have someone stop by the pump once a week and empty out the
addresses? :)
With a secure channel that identifies the parties by proximity, the
reason for the payment request signature is for the payer to obtain a
non-repudiation guarantee. But it also serves as a defense-in-depth
solution to a compromise of the channel (though does not offer a benefit
in the case of seller terminal/cert compromise).
In that case the cert provides no benefit. A self-signed cert can be
repudiated and if the channel is compromised anyone can sign the payment
This was not a serious proposal, it was to point out what would become
necessary if the payer could not be identified by proximity.
In the case where a public key is reused, any payer can contact the BT
terminal and obtain the payment request. If the merchant can't rely on
proximity (i.e. can't trust the integrity of the NFC connection) then he
would have to fall back on some other means of identifying the payer. A
mutual verbal/visual confirmation could work, but the point of of NFC+BT
is elimination of that hassle.
Yes, it sounds a bit wild, but I have seen on this list a serious
proposal to have people broadcast their photo, having the merchant
select them and push to them the payment request. Of course anyone can
spoof another's image, so at some point your image would need to be
certified, and hence a CA.
I wouldn't go there, but was just making the point.
When you go to a web site you first establish a private communication.
The site doesn't know who you are (hopefully). Then you log on with your
secret, or proof of it, establishing who you are. Customer identity
problem solved.
Or you create an account, providing your relevant identity information
which effectively becomes who you are to the site.
Or you shop anonymously and when you go to check out they know that if
you pay, you get permission to direct the product shipment. And only you
can see the bill. This because your session binds your shopping to your
bill and payment.
However when you go to the local adult shop to pick up some love toys,
the person at the counter has no idea who's asking their terminal for a
payment request. You having the shop's public cert doesn't help them
with that problem (nor does some anonymous signal sending them a photo
of you). Protecting your privacy ironically requires that they know who
you are - electronically. That means some sort of crazy consumer cert
(not sure that would fly in the love shop)... or trust in
(electronically anonymous) proximity.
The payment request is private. It's a (potentially signed) proposal to
contract. It can contain interesting information.
Very much so, but in that case your neighbors can't read your potential
transactions because your session is secured.
It can work, but you just end up putting an additional value on the URI
(for watchers), requiring legacy addresses (for non-watchers), adding
P2SH scripts to the BT broadcast of the public key, and adding another
BT round trip to obtain a public key before establishing the session.
A few bytes on the NFC tap is a non-issue, especially in comparison to
the additional complexity and BT traffic. Those choices are really all
based on providing private offline transaction support originating from
generally not private QR code scanning. But QR+BT is not the same as NFC+BT.
Honestly I think it would be reasonable to use the technique with QR+BT,
accepting the limitations for the legacy system while not unduly
burdening NFC+BT just for an unachievable cross-consistency goal. Always
passing the key on the URL for NFC but giving a non-NFC wallet the
option to ask a BT terminal for a public key seems not just reasonable
but optimal if we want to support the QR+BT scenario.
Note also that the BT-only scenario is different as well (see recent
discussion on Airbitz BLE wallet, resulting in the RedPhone-based
proposal). And finally, QR-only and NFC-only are also different. The
URIs can be consistent, but the communication protocol will vary.
Yes, but even with a manual button you could have these problems. The
data transfer needs to be proximate as well.
I think this question is covered above.
It doesn't actually add another step to the protocol, just some
different but simple code on each end. The only downside is that it
extends the NFC URL about 23 characters.
Absolutely, and I believe Mike ack'd this on a previous post today.
Others may not be aware of the encoding squabble (not sure if it
qualifies as debate). In the proposed URL, it affects the mac address
and the key:
I prefer base58 because it's available to all bitcoin libraries, nearly
as compact as base64 (+1 byte in our example) and better standardized.
Some embedded device people might care about having to incorporate
base64 as well as base58.
It's also better looking (no - or _ characters) and more consistent in
the proposed URL (all three values would be base58, as opposed to one
base58 and two base64url). There may be some idea that base58 is just
for bitcoin addresses (not true) or designed for humans... that's sort
of the point, but it's also good for URLs.

@_date: 2015-02-24 14:14:51
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
It's an interesting thought. As you say, it may be more of a cultural
than technical issue.
This would be the simple model, which just tacks on another parameter to
the bitcoin URL:
But we should also look at the more flexible "r approach from your
existing TBIPs, which would yield:
and incorporate the "payment_url" list.
Yes, it is not necessary on the URL. But an id is useful in helping the
BT terminal identify the session without having to try all of its
outstanding keys until it finds one that works.
I proposed that the resource name ("session id" may be a better name) be
deterministically derived from the session key. Given the design change
to pass an EC public key it would need to be derived from that key (not
from the session key because the receiver would not have a copy before
decrypting the first BT message). So any function on the public key that
reduces it to a smaller length, fixed width should be fine. Hashing it
first may be better as is prevents disclosure of any bits of the public
key, which should be treated as a secret during the session.
Yes, since there would be no other way to distinguish between customers
in some scenarios and this is the safest approach. We certainly won't
run out of numbers, and unused sessions can be discarded based on any
number of criteria, including discarding all but the most recent. That
may may be sufficient for your vending machines given there's little if
any call for parallelism.

@_date: 2015-02-24 18:09:42
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
This is a question of proper URL semantics, as applied to the "bt" scheme.
From rfc3986 [Uniform Resource Identifier (URI): Generic Syntax]:
"The path component contains data, usually organized in hierarchical
form, that, along with data in the non-hierarchical query component
(Section 3.4), serves to identify a resource within the scope of the
URI's scheme and naming authority (if any)."
"The query component contains non-hierarchical data that, along with
data in the path component (Section 3.3), serves to identify a resource
within the scope of the URI's scheme and naming authority (if any). The
query component is indicated by the first question mark ("?") character
and terminated by a number sign (" character or by the end of the URI."
The question therefore is whether  is (1) relative to the path
(hierarchical) or (2) independent of the path and instead relative to
the scheme and naming authority.
The "bt" scheme does not include a naming authority, and as such the
question is simply whether  is relative to "bt" or relative to the
path, which is . Quite clearly  is valid only in the context
of , not relevant to all s.
As such one must conclude that the proper form is:
I don't believe that the BIP-70 protocol over https has any need for the
parameter. It was only useful because the NFC/BT session wasn't secured.
So I don't think anything is lost.
Yes, but that is not the problem that non-reuse is designed to resolve.
Reuse of the public key creates a forward secrecy problem. If 1000
sessions are recorded, and later the private key associated with the
reused public key is compromized, all of the sessions are retroactively
Another problem is persistent impersonation. If the one associated
private key is compromised, and nobody knows it, the attacker can not
only monitor all transactions but can selectively steal payments (if
they aren't signed and verified). This is BTW also a good reason to not
use HD generation of these session keys.
Another problem is that any payer can use the well-known public key to
obtain payment requests.
Another problem is that without a unique public key there is no unique
session id, so that would need to be added explicitly on the URI.
Could you spell this out, I'm not familiar with the implementation, just
the proposals.
That may be necessary depending on the implementation of existing
terminals, but I'm not familiar enough to speculate.

@_date: 2015-07-22 09:30:36
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Making Electrum more anonymous 
Hi Thomas,
The scheme is essentially onion routing. The set of {M} are entry nodes
and the set of {S} are exit nodes. The weaknesses are as you would see
in an analogous TOR implementation:
(1) The lack of relay nodes {R} make collaboration between any subset of
{M} and {S} trivial.
(2) OR is a mixnet, so the size of the network matters a lot.
(3) The directory is a perpetual weakness.
(4) Content is visible to the exit node (or the final service). This
means each address must be passed via a distinct route to prevent

@_date: 2015-07-22 15:20:33
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Making Electrum more anonymous 
I should add that the obvious resolution to this set of problems is to
use a distinct Tor route for each Bitcoin address, not to reinvent Tor
and reproduce its community. So ultimately this is easy to implement,
but the downside is performance.
But it's important to keep in mind that poor-performing perfect privacy
for address monitoring is trivial to achieve - just sync the full
Presumably if you don't trust a server to protect your privacy, you also
don't trust it with your money. So any robust privacy optimization would
at least be designed to support partial (SPV) chain clients. It would
also need to support wallet restoration from backup.
The level of privacy will always be a performance trade-off. The ideal
solution would allow a client to balance privacy against performance.

@_date: 2015-07-22 17:07:14
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Making Electrum more anonymous 
This is a good point. I didn't delve into the specifics of
implementation due to the larger issues that I raised. Libbitcoin Server
uses CurveZMQ, an implementation of CurveCP.

@_date: 2015-07-22 17:49:54
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Bitcoin Core and hard forks 
modularized codebase that swapping out consensus rules is fairly
straightforward and easy to test...
We (libbitcoin) have taken the time to publish and maintain bitcoind's
"libbitcoinconsensus" source files as an independent C++ library (with
Java and Python bindings).
It can be easily verified against bitcoind sources and in builds of
libbitcoin-blockchain it can be swapped out for libbitcoin's native
consensus checks.
So there is really no reason to consider the original client synonymous
with consensus. I initially argued for this library to be natively
isolated from bitcoind, but that didn't seem to be in the cards so we
did it independently.
In any case I agree with your stated need for this isolation (if not the
means) for the reasons you state. The community needs to move beyond a
largely singular and monolithic codebase that is holding that position
in part due to fear about consensus bug forks.
To make choice regarding consensus an actual choice (and thereby actual
consensus) the modularity you suggest is essential. One must be able to
take new developments without having to take consensus changes. The
option to fork the codebase is not reasonable for most people. At this
point there is no defensible reason for coupling consensus checks with
other features.

@_date: 2015-07-23 11:21:17
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Electrum Server Speed Test 
Hash: SHA1
Does "to process into the index" include time for transport and/or
block validation (presumably by bitcoind) or this this exclusively the
time for Electrum Server to index a validated block?
look at how the Electrum server software handles under load. The
Electrum wallet is extremely popular, and the distributed servers
which power it are all hosted by volunteers without budget. The server
requires a fully indexed Bitcoin Core daemon running, and produces
sizable external index in order to allow SPV clients to quickly
retrieve their history.
takes this server (Xeon, lots of memory, 7200 RPM RAID) approximately
3.7 minutes per megabyte of block to process into the index. This
seems to hold true through the 10 or so blocks I have in my scroll
buffer, the contents of blocks seem to be of approximately the same
processing load. Continuing this trend with the current inter-block
time of 9.8 minutes, an electrum-server instance running on
modest-high end dedicated server is able to support up to 2.64 MB
block sizes before permanently falling behind the chain.

@_date: 2015-07-23 19:26:28
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Making Electrum more anonymous 
I've looked at IT-PIR for Libbitcoin. It's certainly more elegant than
onion routing for query privacy, but doesn't improve on the collusion
problem. As a result the related directory problem would also remain.
"This protocol sacrifices some level of privacy to gain robustness.
Because of this  we need to assume that there is no collusion between
some number of servers. In some  settings, it is unclear how this
requirement can be enforced or detected. This uncertainty  may make this
protocol less desirable than others with different privacy guarantees."
From the same source, regarding aforementioned options:
"An assumption used in many PETs, including mix networks, secret
sharing, onion routing and some voting protocols, is that no more than
some threshold of agents are colluding against the user to discover the
private information."
Another option is computationally-bounded CPIR, but from the same source:
"The main problem with the CPIR protocols already  discussed is that
they do not generally perform queries faster than the trivial protocol."
Where the "trivial protocol" in our problem is full blockchain download.
WRT an alternative CPIR proposed in 2007:
"The idea behind their protocol is to add noise to the query in a way
that the server  cannot discover which record the client is interested
in, but with the secret information  that the client has, she can remove
the noise from the server?s response."
This is the idea behind stealth prefix queries:
From our perspective, another important objective of query privacy is
allowing the caller make the trade-off between the relative levels of
privacy and performance - from absolute to non-existent. In some cases
privacy is neither required nor desired.
Prefix filtering accomplishes the client-tuning objective. It also does
not suffer server collusion attacks nor is it dependent on computational
bounds. The primary trade-off becomes result set (download) size against

@_date: 2015-07-23 21:44:18
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Making Electrum more anonymous 
Yes, quite true. And without the ability to search using filters there
is no private restore from backup short of downloading the full chain,
rendering the idea rather pointless.
This is why privacy remains a significant issue. Privacy is an essential
aspect of fungibility. This is a central problem for Bitcoin. The
correlation of addresses within transactions is of course problematic.
Possibly zero knowledge proof will at some point come to the rescue. But
the correlation of addresses via search works against the benefits of
address non-reuse, and the correlation of addresses to IP addresses
works against the use of private addresses.
Solving the latter two problems can go a long way to reducing the impact
of the former. But currently the only solution is to run a full chain
wallet. This is not a viable solution for many scenarios, and getting
less so.
This is not a problem that can be ignored, nor is it unique to Electrum.
The Bloom filter approach was problematic, but that doesn't preclude the
existence of valid solutions.
Well because of presumed relationship in time these are not actually
separated requests. Which is why even the (performance-unrealistic)
option of a distinct Tor route for each independent address request is
*still* problematic.
Introducing truly-random timing variations into the mixnet solutions can
mitigate timing attacks, but yes, this just makes the already
intolerable performance problem much worse.

@_date: 2015-07-27 10:22:29
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Bitcoin Core and hard forks 
Thanks for the triggering warning, if not for that I may have gone into

@_date: 2015-07-27 23:40:42
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Libconsensus separated repository (was Bitcoin 
libsecp256k1 has it's own repository, libbitcoinconsensus doesn't.  A
separate repository was what I considered as a requirement for us to use it.
If it's not certain whether this would even be accepted, the commitment
to a community consensus library is too weak to take a strong dependency
on. But for us it's moot, as we have made the already accomplished that
In our earlier discussion I believe you said that the library would not
be undergoing significant change or feature creep. If this is the very
least that's projected it would seem that constraint will not hold.
I don't think it's a question of whether it *should* use its own library
as it is published for others - this is a practically self-evident
We use a fork of libsecp256k1 and would probably do the same with the
consensus library if it was cleanly isolated.
It's a performance sacrifice, and then there's the OpenSSL dependency,
but these are both optional within our stack - so the application
developer has the option. So the only downside is that we are
maintaining the conditional compilation.
I think it's worthwhile work, especially if you are passionate about the
longer term objectives. I haven't been involved in these reviews as I
spend very little time with the satoshi client
Well a cynic might observe that fear of consensus bugs is what keeps
people on the satoshi client, and therefore accelerating the development
of a clean and independent consensus library would be a very low priority.
Software is never finished, but this exists and we are using it.
It is using the same source files, but AFAICT not the library.
I haven't looked at any of these commits, but I'll make some time to at
least give a cursory review.
Yes, of course. We've already done it. For each release of the satoshi
client since we made libbitcoin-consensus I've copied the sources. It's
pretty much automated and easy to visually verify that the sources
match. That would be quite a bit more difficult if there wasn't an
independent build.
Useful specifications often have two reference implementations. It's the
idea that there can be only one legitimate implementation that's
I don't think we disagree on anything fundamental. My issues with the
library were (1) the lack of isolation, (2) the fact that the satoshi
client wouldn't actually use the library, and (3) backtracking to use
OpenSSL, which we had recently removed from libbitcoin.
This is already done.
I don't disagree, but you previously argued that *everyone* had to agree
on consensus. Above you are making the argument that people can choose
to disagree. Yes, this is important. Yet it's unrealistic for any
alternative consensus to overcome inertia unless there are widely
deployed independent implementations.
I'm maintain our fork of the consensus sources until they are (1)
properly isolated from the satoshi client and (2) the satoshi client
uses the actual library.
I don't see it as important or even productive to try and wedge the
consensus library into the repository/build for bitcoind and Bitcoin-QT.
It's straightforward to maintain the consensus library independently.
Always willing to work with you on it, although we're all busy, and this
isn't my top priority presently.

@_date: 2015-07-29 13:38:39
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Libconsensus separated repository (was Bitcoin 
Oh, I misunderstood your ask then. I don't have a preference on
prioritizing VerifyTx vs VerifyHeader.
I'm not sure how you mean to expose it, could you clarify?
I don't see any reason to expose checkpoints in this library. They are
trivial to implement and are not part of consensus.
Nothing can eliminate all consensus risk, not even a common full node
Maybe I wasn't sufficiently explicit. It is problematic. That is the
core issue we are dealing with. That doesn't mean I disagree with the
objectives of an independent community consensus library.
The premise of the "one true library" idea is that there is *no way* to
sufficiently test for consensus bugs in any software release. That of
course means that each release of the satoshi client poses a significant
risk to the network. This risk is presently greater than that posed by
other implementations simply because of adoption. That is the basis of
the red herring argument:
The bottom line is that nobody has control over this process. There are,
and will always be, a multitude of consensus implementations that intend
to target the same coin. Presently there are multiple versions of the
satoshi client, and this has produced forks, and will continue to do so.
Isolating the satoshi consensus checks to an independent library serves
not to eliminate that risk, but can reduce it somewhat. Importantly it
will allow various implementations to overcome a perception problem,
which will improve implementation diversity and developer participation.
For the sake of clarity, this is now a non-issue for us.
Again, I consider this a requirement for us to link directly to it as a
library. If the sources are isolated into an independent repo, but the
satoshi client is embedding its own copies, one must continue to diff
the client sources against the library sources. We are doing this
already, so the benefit to having the independent repo is in no longer
having to do this.
There are also differences in the build system that can affect outcome.
Comparing those differences across repos can be more challenging. For
this reason I consider it important to your objective that the satoshi
client actually use the library - as I assume it will at some point.
If the satoshi client folks are to maintain a consensus library for the
community it's also important to show a commitment to its independence.
Dogfooding is of course a software engineering best practice. But there
is also the cynical perspective - the independent library in some ways
works against an advantage of the satoshi client.
I personally don't think the committers are parochial enough to let this
become an issue. We are all after something bigger. But if there was
push-back against using the library it would be a red flag. So until
that point passes I would just maintain our independent library, cloning
the sources from the satoshi client.
Yes, I've seen this as a temporary setback.
No, I see it as less significant to the adoption of libbitcoin-server
than other issues we are working on, especially given the existence of
libbitcoin-consensus. I also trust you will make progress regardless.

@_date: 2015-06-01 17:09:10
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
that's what gives Bitcoin its value.
Visa, Dollar, Euro, Yuan, Peso have usage.
The value in Bitcoin is *despite* it's far lesser usage.
Yes, the price is a function of demand, but demand is a function of
utility. Despite orders of magnitude less usage than state currencies,
Bitcoin has utility. This premium *only* exists due to its lack of
centralized control. I would not work full time, or at all, on Bitcoin
if it was not for decentralization; nor would I hold any of it. I doubt
anyone would show an interest in Bitcoin if it was not decentralized. If
it centralized even you would be forced to find something else to do,
because Bitcoin "usage" would drop to zero.
is a means to an end.
No, it was/is the primary objective. Paypal had already been done. If
anything is maddening it's that you of all people can't see this. When
people talk about the core innovation of Bitcoin, it's a conversation
about Byzantine Generals, not wicked growth hacking.
was a full node and every computer was capable of mining. So if you
believe what you just wrote [...] Bitcoin's value has gone down every
day since
An obvious non sequitur. By way of example, if 10 of 10 participants are
capable of mining it is not more decentralized than if 1,000 in 100,000
are doing so. 1,000 *people* in control vs. 10 is two orders of
magnitude more decentralized. The *percentage* of the community that
mines is totally irrelevant, it's the absolute number of (independent)
people that matters.
I'm not making a statement on block size, just trying to help ensure
that ill-considered ideas, like this inversion of the core value
proposition, stay on the margins.

@_date: 2015-06-02 09:18:56
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Proposed alternatives to the 20MB step 
A mining pool is not a person, a full node is not a miner, and
cooperation is not control.
The entire Bitcoin ecosystem cooperates, that is what consensus means.
Establishing proof of that cooperation is the purpose of Bitcoin.
Decentralization is about keeping control out of the hands of the state
(any entity that would substitute violence for consensus). Nobody has
the power to compel the cooperation of individual miners in a pool. When
state power is applied to a pool operator the miners (people) retain
their vote.

@_date: 2015-03-02 16:54:18
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] Bitcoin at POS using BIP70, 
Agree. The amount of bitcoin URI space in question isn't a material
issue when it comes to NFC. The more significant considerations here are
the additional BT round trip to establish a session, greater complexity,
and the potential lack of a correlating address (as you point out above).
On the other hand I think the approach has merit in a scenario where the
bitcoin URI is read from a QR code and BT is available (IOW no NFC).
Generalizing it to the NFC-based bitcoin URI is the problem.
A much cleaner generalization is to rationalize the two approaches
*after* the bitcoin URI has been read (from either NFC or QR). In the QR
scenario the wallet can obtain a verifiable public key from the BT
terminal (subject to some limitations as discussed above). In the NFC
scenario the public key is just passed in the URI. The scenarios come
together at the point where they both have the public key (and the mac
This of course implies that the the BT URL scheme, in order to be used
in both places, would have to allow the public key to be optional. But
in an NFC tap it would be present and in a QR scan it would not.
As you say, this prevents the NFC scenario from perpetuating the
fallback address as a requirement, which eventually shortens the bitcoin
Making the public key a requirement when used with NFC would simplify
wallet development for NFC only wallets. But if a wallet supported both
NFC and QR scanning it wouldn't make much difference. So it's not
unreasonable to think of it like this:
This provides greater generality, but it creates a situation where
NFC-only wallets need to support the more complex approach, and where
use in QR codes would have scanning issues. So I think it's better to
specify limits on each as in the first example.

@_date: 2015-03-25 01:04:48
@_author: Eric Voskuil 
@_subject: [Bitcoin-development] On Rewriting Bitcoin (was Re: 
You seriously made me laugh out loud with this one Peter.

@_date: 2015-11-05 15:33:26
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] summarising security assumptions (re cost metrics) 
This side of the security model seems underappreciated, if not poorly
understood. Weakening is not just occurring because of the proliferation
of non-validating wallet software and centralized (web) wallets, but
also centralized Bitcoin APIs.
Over time developers tend to settle on a couple of API providers for a
given problem. Bing and Google for search and mapping, for example. All
applications and users of them, depending on an API service, reduce to a
single validator. Imagine most Bitcoin applications built on the
equivalent of Bing and Google.

@_date: 2015-11-06 16:44:48
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] summarising security assumptions (re cost metrics) 
Nobody has advocated a golden ratio.
This is a false dichotomy. Both scenarios are poor for security, as
nobody with a wallet is validating. It's entirely possible, even
probable, that one person controls all of the nodes.
Fewer people independently validating their own transactions means trust
is placed in fewer people. The degenerate case of one validator and
everyone trusting it is dispositive, and equates roughly to the Federal

@_date: 2015-09-01 11:37:18
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Your Gmaxwell exchange 
Whether intended or otherwise this is an attack on the idea of
decentralized bitcoin development. The option to fork or roll your own
is open source, not decentralization. Decentralization requires
*actually doing so*. One step down that path, even for a fork, is a
major commitment.
Common consensus check code is now available in several bitcoin
implementations. The claim that this is outrageously difficult is
misleading. It's just engineering work that needs to get done if Bitcoin
is to survive.
These are issues that affect the satoshi client as much as other
implementations, and therefore don't support your premise.

@_date: 2015-09-14 12:54:39
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP-38 issue and altchain support 
In the integration of BIP-38 into libbitcoin we ran into two issues.
First, the scenario that justifies the "confirmation code" is flawed. We
have implemented full support for this, but have also marked it as
I am seeking counter arguments, in case there is some scenario that we
haven't imagined where it might be useful. Details here:
[TLDR: the confirmation code cannot prove anything about the owner's
ability to spend from the public-key/address that it confirms.]
Second, BIP-38 envisions altchain integration but doesn't specify it. We
have implemented the capability, documented here:
[TLDR: incorporate the payment address version into the last byte of the
encoded encrypted key prefixes, with backward compatibility]
If there is sufficient support I'll write up a Proposal that modifies
Thanks to Neill Miller for the libbitcoin and bx BIP-38 pull requests.

@_date: 2015-09-18 23:56:55
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Scaling Bitcoin conference micro-report 
The state is the threat in the Bitcoin threat model. You comments below
acknowledge it. The assumption of hostile state actors is the only
rational starting point. That which is regulated (and regulatable) in
Bitcoin is the attack surface.
While of course there are various degrees of weakness, the reference to
"legal/regulated service provided by a highly trusted mining" as the
threat is by no means irrational or misdirecting. This threat represents
the difference between Bitcoin and Fedcoin.
I found Mike's threat model downright disturbing. All benefits of
Bitcoin arise from its resistance to this threat. Anyone investor in
this space should be paying attention... the apparent benefits of
Bitcoin will vaporize with regulation.
This is extremely naive. At a minimum, getting popular/successful (and
regulated) is the formula for regulatory capture.
I assume you are referring some marginal and largely irrelevant effort.
False dichotomy.
[cross-posted to libbitcoin]

@_date: 2015-09-19 00:39:14
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Scaling Bitcoin conference micro-report 
Your vision of censorship resistance is to become such a strong central
authority that you can resist it in direct physical confrontation. If
you succeed at this, you are the threat.
And your alternative is to lurk in dark corners.
The inability to see another option is the inability to understand what
Satoshi created.

@_date: 2015-09-19 01:52:43
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Scaling Bitcoin conference micro-report 
Your argument is that the state is not a threat to a system designed to
deprive the state of seigniorage, because the state will see that system
as too important?
Bitcoin cannot be both decentralized and reliant on being, "too
important to close". If it can be closed there is insufficient
I was concerned that this was going off topic for a technical forum.
However this is the central technical issue of Bitcoin. If one does not
understand the threat then one cannot model it or design systems to
defend against it. On the other hand, this is unfortunately not new
territory, so I'll leave it at this, which is also not news to most of us...
Google do.
"The National Security Agency paid millions of dollars to cover the
costs of major internet companies involved in the Prism surveillance
program after a court ruled that some of the agency's activities were
unconstitutional, according to top-secret material passed to the Guardian.
The technology companies, which the NSA says includes Google..."

@_date: 2016-12-10 21:29:08
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Managing block size the same way we do difficulty 
The presumption of the mining aspect of the Bitcoin security model is that the mining majority is a broadly distributed set of independent people, not one person who controls a majority of the hash power. You seem to have overlooked a qualifier in your Satoshi quote: "...by nodes that are not cooperating to attack the network". A single miner with majority hash power is of course cooperating with himself. At that point the question of whether he is attacking the network is moot, it's his network.
I believe that Pieter's point is that a system optimized for orphan rate may in effect be optimized for a single entity providing all double spend protection. That works directly against the central principle of Bitcoin security. The security of the money is a function of the number of independent miners and sellers.

@_date: 2016-01-12 11:17:20
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Libconsensus phase 2 
Jorge, first, thanks again for your work on this.
Without creating and using a public blockchain interface in phase 2, how
will you isolate the database dependency from consensus critical code?
Is it that the interface will exist but you will recommend against its use?
This work presumes that the users of the library reject the argument
that the database implementation is consensus critical code. Faithful
reproduction of stored data is a prerequisite for a validity. But a
common store implementation is only slightly more reasonable for this
library than a common RAM implementation.

@_date: 2016-01-13 14:47:44
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Libconsensus phase 2 
Generalization of the store interface may be more challenging than you
anticipate, but the objective makes sense.
We would not offer libbitcoinconsensus integration if it required us to
incorporate the store. These are distinct logical components, as are p2p
networking and client-server networking (e.g. RPC), for example. I would
not think of these as multiple versions of libbitcoinconsensus but
instead as distinct components of a bitcoin node. It doesn't make sense
to me that you would ship this as two consensus variants. I would work
toward shipping independent component libraries (i.e. consensus and store).

@_date: 2016-06-28 09:17:31
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
Hash: SHA256
I haven't seen much discussion here on the rationale behind BIP 151. Apologies if I missed it. I'm trying to understand why libbitcoin (or any node) would want to support it.
I understand the use, when coupled with a yet-to-be-devised identity system, with Bloom filter features. Yet these features are client-server in nature. Libbitcoin (for example) supports client-server features on an independent port (and implements a variant of CurveCP for encryption and identity). My concern arises with application of identity to the P2P protocol (excluding Bloom filter features).
It seems to me that the desire to secure against the weaknesses of BF is being casually generalized to the P2P network. That generalization may actually weaken the security of the P2P protocol. One might consider the proper resolution is to move the BF features to a client-server protocol.
The BIP does not make a case for other scenarios, or contemplate the significant problems associated with key distribution in any identity system. Given that the BIP relies on identity, these considerations should be fully vetted before heading down another blind alley.

@_date: 2016-06-28 18:45:58
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
Hi Jonas, I'll follow up in your second reply as well. Responses inline:
1) creation of a false sense of security
2) as a tradeoff against anonymity
3) benefit does not justify cost
Encryption alone cannot protect against a MITM attack in an anonymous and permissionless network. This is accepted in the BIP (and your follow-up reply).
I do not challenge the usefulness and appropriateness of encryption with authentication in a client-server blockchain protocol.
We do.
This is the assumption that I'm questioning.
The question arises from concern over the security of the network in the case where encryption (and therefore authentication) is pervasive.
As you point out, anyone can set up a private network of nodes today. These nodes must also connect to the permissionless network to maintain the chain. These nodes constitute a trust zone within Bitcoin. This zone of exclusion operates as a single logical node from the perspective of the Bitcoin security model (one entity controls the validation rules for all nodes).
Widespread application of this model is potentially problematic. It is a non-trivial problem to design a distributed system that requires authentication but without identity and without central control. In fact this may be more challenging than Bitcoin itself. Trust on first use (TOFU) does not solve this problem.
In my opinion this question has not received sufficient consideration to warrant proceeding with a network encryption scheme (which concerns me as well, but as I consider it premature I won't comment).
Bloom filters can (and IMO should) be isolated from the P2P protocol. Also, if the proposal creates an insecurity its ease of deployment is moot.
I would not consider this a performance enhancing proposal. Simply dropping the checksum seems like a better option. But again, it is moot if it creates an insecurity.
At a minimum I would propose that you modify BIP151 to declare a dependency on a future BIP, making BIP151 incomplete without it. I think we can agree that it would be unadvisable to deploy (and therefore to implement) encryption alone.
I'll respond to the question of authentication in your follow-up post.

@_date: 2016-06-28 19:39:41
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
continued from previous post...
No problem. Thanks for the detailed replies.
I have referred to the Bloom filters messages. These are clearly asymmetric in nature. Despite being possible it is not a valid use case for a full node to make BF requests to another node.
One client to multiple servers is still client-server for the sake of this discussion. The nature of the P2P protocol is synchronization of content between all nodes/peers. If the protocol is asymmetric the semantics, and therefore use cases, are different.
FWIW posting a transaction to the network can be done using the P2P protocol, connecting for a short period of time. But this is also a client-server scenario and is a hack when done (full disclosure, bx provides both P2P and client-server commands for tx posting). Broadcasting is naturally the behavior of a full node.
Yes, this is necessarily the case in order to prevent a MITM attack. This is the basis of my concern.
Sure, but then let us not make assumptions about it in the context of this discussion. Libbitcoin provides fee estimation by monitoring broadcast penetration using a client-server protocol with an optional subscription mechanism.
TOFU cannot prevent MITM attacks (the goal of the encryption). Authentication requires a secure (trusted) side channel by which to distribute public keys. This presents what I consider a significant problem. If widespread, control over this distribution network would constitute control over who can use Bitcoin.
The effort to prevent censorship could actually enable it. I don't think it would get that far. Someone would point this out in the process of vetting the authentication BIP, and the result would be the scrapping of BIP151.
BIP 151 is incomplete without authentication.
Agree, but my problem is that I do not believe we can assume this is a solvable problem.
Understood, yet this is the basis of my blind alley comment.

@_date: 2016-06-28 20:35:26
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
Hi Peter,
What in this BIP makes a MITM attack easier (or easy) to detect, or increases the probability of one being detected?

@_date: 2016-06-28 22:29:54
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
PGP requires a secure side channel for transmission of public keys. How does one "check" a key of an anonymous peer? I know you well enough to know you wouldn't trust a PGP key received over an insecure channel.
All you can prove is that you are talking to a peer and that communications in the session remain with that peer. The peer can be the attacker. As Jonas has acknowledged, authentication is required to actually guard against MITM attacks.

@_date: 2016-06-28 23:22:23
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
An "out of band key check" is not part of BIP151. It requires a secure channel and is authentication. So BIP151 doesn't provide the tools to detect an attack, that requires authentication. A general requirement for authentication is the issue I have raised.

@_date: 2016-06-28 23:59:54
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
Passing the session ID out of band is authentication. As this is explicitly not part of BIP151 it cannot be that BIP151 provides the tools to detect a attack (the point at issue).
The sarcasm is counterproductive Greg. By the same token I could ask how you ever use Bitcoin given that the P2P protocol is not encrypted or authenticated.
It doesn't matter who I am, maybe I am the NSA. I don't argue from a position of authority. Signing my emails while traveling on holiday with only my phone gets a little tedious.
The blockchain and mempool are a cache of public data. Transmission of a payment address to a payer is not a comparable scenario.
The possibility that authentication may become required to participate in this trustless network is a legitimate concern, and one that has not been addressed.

@_date: 2016-06-29 00:07:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
Hi Cameron, good to hear from you!
This is not really the case with Bitcoin. A MITM attack does not require that the attacker find a way to inject traffic into the communication between nodes. Peers will connect to the attacker directly, or accept connections directly from it. Such attacks can be easier than even passive attacks.
It is the implication of widespread authentication that is at issue. Clearly there are ways to implement it using a secure side channels.

@_date: 2016-06-29 01:29:10
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
Your description of the two scenarios reduces to one. They both require authentication, and if you intend to connect to potentially evil nodes you aren't securing anything with link level security except the knowledge that your potentially evil node connection remains so.

@_date: 2016-06-29 01:31:19
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
The relevant question would be to ask whether encryption would prevent an ISP from doing so (which it would not). This is a good example of false sense of security.
FWIW I was just answering your question comprehensively. Relationship to BIP151 is incidental (though apparently applicable).
Keep in mind my specific concern is not with the design of BIP151, it is with the implication of its dependency on an unspecified authentication proposal.
The security tradeoff would arise from widespread deployment of authentication - which is necessary to make encryption useful against envisioned MITM attacks. See my previous discussion of trust zones below.
Simply put, any code that is unnecessary does not justify its cost.
TOFU (trust on first use) was a reference to what was discussed on IRC as a potential solution to the (deferred) authentication problem. I didn't mean to imply that it was part of BIP151.
This is a restatement of what I have accepted as a premise - that authentication, and as such, key distribution, will be a necessary part of making any encryption scheme effective. "Preshared" implies a secure side channel for key distribution.
Whether or not there are multiple schemes is not relevant to the point I have raised. The issue is that authentication is necessary.
We should contemplate what the distributed permissionless network of anonymous peers looks like once every node authenticates every one of its peers using one or more key distribution side channels.
I fully appreciate the significant security risk arising from the proliferation of web wallets. This can only be resolved by people validating using code under their own control.
Encryption/authentication are orthogonal to this question, assuming people have wallets directly attached to full nodes. Remoting a wallet from a full node does not require use of the P2P protocol, and can use encryption/authentication without the concerns I've raised. It properly places the trust boundary around a wallet and its trusted node(s), as opposed to spanning (independent) nodes.
This is an unfair statement. You have acknowledged that BIP151 requires authentication to accomplish its sole objective.
As I pointed out.
Again, it's the fact that authentication is required that produces the issue, not that there are multiple ways to implement it.
I don't see how this is relevant.
It seems that we are talking past each other. You haven't yet addressed the issue that I have raised.
It is the requirement for authentication of any node that any other node may wish to connect to that is the issue. We end up with something that looks like WoT or PKI. And if not fully controlled by PKI (so using WoT) we will have hybrid nodes that accept untrusted connections and propagate information between trusted and untrusted nodes.

@_date: 2016-06-29 01:33:53
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
I don't follow this comment. The BIP aims quite clearly at "SPV" wallets as its justifying scenario.
And they won't get it with BIP151 either. Being a peer is easier than observing the network. If one can observe the encrypted traffic one can certainly use a timing attack to determine what the node has sent.
As will remain the case until all connections are encrypted and authenticated, and all participants are known to be good guys. Starting to sound like PKI?
If we trust the manual links we don't need/want the other links. In fact retaining the other links enables the attack you described above. Of course there is no need to worry about Sybil attacks when all of your peers are authenticated. But again, let us not ignore the problems of requiring all peers on the network be authenticated.
Maybe I was insufficiently explicit. By "relies on identity" I meant that the BIP is not effective without it. I did not mean to imply that the BIP itself implements an identity scheme. I thought this was clear from the context.
Please read more carefully what I wrote. I did not characterize authentication as an identity system. I proposed that key distribution has significant problems, and used identity systems as an example of systems with such problems. I could just have easily written "authentication systems", (and probably should have).
This is the only legitimate scenario that I am aware of. Doing this by IP address (as we do) is weak if there is no VPN.
Yet this scenario is very different than general authentication. This scenario is a set of nodes that is essentially a single logical node from the perspective of the Bitcoin security model. One entity controls the validation rules, or is collaborating with another entity to do so.
My concern is that a general authentication requirement expands this single logical node and gives control over if to the entity that controls key distribution - the hard problem that hasn't been addressed.
If there is no such entity restricting access to the network (which hopefully we can assume) then there is no reason to expect any effective improvement, since nodes will necessarily have to connect with anonymous peers. Anyone with a node and the ability to monitor traffic should remain very effective.
Defining an auth implementation is not a hard problem, nor is it the concern I have raised.

@_date: 2016-06-29 01:34:33
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
The rest is "authentication".
You were perfectly clear. Did I give some indication that I did not understand what you meant?
Posting txs to the network is a client-server scenario. The set of txs arriving at an arbitrary node, including the order of arrival, is by definition public information. The only possible way it could be considered private is if the entire network was private.
So where does the private timing become public? First hop, second, third?
Encryption and authentication cannot prevent timing attacks against a person posting txs to the network unless the entire network is "secured". That is not possible without centralized access control.
Encrypting the P2P network doesn't resolve this problem, nor does authentication, nor does Tor. I would prefer we advance an actual solution to this significant problem than advance a false sense of security while creating both complexity and the likely evolution of node identity.

@_date: 2016-06-30 11:57:02
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
The Bitcoin network does not encrypt communication between peers today. This opens up security issues (eg: traffic manipulation by others) and allows for mass surveillance / analysis of bitcoin users. Mostly this is negligible because of the nature of Bitcoins trust model, however for SPV nodes this can have significant privacy impacts [1] and could reduce the censorship-resistance of a peer."
This is not an example, this is the exception that is described as "significant" in comparison to the other issues, which are described as "negligible".
The Bloom filters messages are of course the unique aspects of the protocol as it pertains to "SPV".
The RISKS section declares that the BIP cannot prevent MITM attacks and that "identity authentication" will  be defined in a forthcoming BIP.
The obvious implication (accepted by the author) is that authentication is required to prevent a MITM attack, and furthermore establishment of identity will be required to ensure that the authenticated party is not a bad actor.
This is a straw man, as the BIP does not state that its objective is to moderately raise the cost of passive attack against large numbers of users.
It is also a red herring, as passivity is not itself a benefit. It implies that the attack is easier and therefore less costly. But a trivial active attack may be a larger security problem than a complex passive attack. Attacks against privacy under this BIP (and with authentication) can be carried out by passively monitoring traffic and operating one or more nodes. Operating a node may be considered "active" because the node communicates, but technically it is not. In either case the activeness itself hardly raises the difficulty, especially for a global (thousands of users) passive attacker.
Depending on the attacker, cost may not be an issue at all, so raising it can have zero effect. Certainly we are not talking about prohibitive (cryptographically hard) cost. Raising the cost *any* amount is not likely a reasonable cost-benefit tradeoff.
Privacy attacks would remain entirely undetectable under this proposal, and under any additional proposal that required authentication in the absence of identity. Only with all users of the network identified as "good" would such proposals be effective. Until that point any bad actors can become an integral part of the network. I will investigate the question of identity in a follow-up to an independent post.
It cannot be both impossible ("not against Bitcoin Core") and limited in effectiveness ("obviously there are limits").
We should be clear at this point that the transaction-posting security provided against a privacy attack, based on the assumption of "good" (identified) peers in the first few hops, derives entirely from the ability of the good peers to break the timing attack, which is itself "limited".
This is a compound pair of weak assumptions, that to be made stronger will require widespread use of identity (not just authentication).
The proliferation of node identity is my primary concern - this relates to privacy and the security of the network. Secondarily I am concerned about users operating under a false assumption about the strength of privacy. Thirdly I am concerned about the risk of vulnerability introduced by the integration into the P2P network layer of an totally new network security scheme. Fourthly I'm concerned about the cost of the above based on the belief that the benefit may not be material and that it may lead to increased centralization.
Described as "limited" in effectiveness, and clearly useful only if these hops are not attacker nodes.
So back to my comment on how we maintain a pool of "good" nodes for people to connect to, and raising the question of how effective is this strategy (which is itself unspecified and so cannot be assumed to even exist in the context of the BIP).
Don't want them as peers for the purpose of tx relay. As I said this, "enables the attack you described above."
This whitelisting is simply a stand-in for a more formal identity system. One doesn't whitelist anonymous peers, one whitelists peers controlled by trusted parties. Preferring trusted peers is another aspect of trying to break the timing attack. So I would lump this under the same analysis as above (batching).
This is true but not relevant. The parties with whom we transact are not in the same space as the nodes with which we connect. The fact that I am face-to-face with a counterparty does not help me find a "good" node, nor does my ability to PGP email a payment address or to send a stealth address in the clear.
But the fact that you raise this point is itself instructive. The solution that was devised to resolve the problem of verifying that a counterparty is who one thinks it is ended up being based on the use of certificate authorities - despite the fact the the BIP did not require this. Some people consider this extremely dangerous for Bitcoin, enough so that Peter Todd recently proposed scrapping the BIP.
It's not clear to me how the Bitcoin community intends to establish what nodes are good nodes. But one thing is certain, any anonymous node may be an undetectable attacker.
As a minimum requirement, it implies that only need only to connect to one or more "good" peers. Anonymous peers are gravy for partition resistance, yet they are potential attackers for tx tainting. In other words the logical topology is to only connect to good peers. That is a problem.
See above commentary on the irrelevance of this distinction.
I don't get your point here. It seems like you are just trying to antagonize.
At this point I think it's fair for me to say that nobody needs your permission.
Have you ever debated an optional feature proposal?

@_date: 2016-06-30 13:56:42
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
Hi Alfie,
Yes, this is exactly what I meant. The complexity of the proposed construction is comparable to that of Bitcoin itself. This is not itself prohibitive, but it is clearly worthy of consideration.
A question we should ask is whether decentralized anonymous credentials is applicable to the authentication problem posed by BIP151. I propose that it is not.
The core problem posed by BIP151 is a MITM attack. The implied solution (BIP151 + authentication) requires that a peer trusts that another is not an attacker. Authentication of an anonymous peer cannot achieve this objective, since the peer may be anyone and an attack on privacy can be undetectable. The identity of a peer must be known to the relying peer, either directly or transitively.
DAC is applicable in cases where identity is never required.  The prime example in the paper is that of first-come-first-served name registration. No identity is required in that scenario, just proof that a party in question is the original registrant. All participants are presumed to be "good".
I believe that a distributed anonymous system is fundamentally at odds with isolation of "good" vs. "bad" participants who comply with protocol rules (DoS considerations aside), and that any attempt to resolve this conflict will result in the system no longer allowing anonymous participation.
I may be mistaken, but I haven't found a way out of this realization.

@_date: 2016-06-30 14:27:30
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
It is not clear to me why you believe an attack on privacy by an anonymous peer is detectable.

@_date: 2016-06-30 17:10:52
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
Pieter, these are in my opinion very reasonable positions. I've made some observations inline.
Yes, libbitcoin also provides these options on an IP basis.
I explicitly exclude client-server behavior as I believe the proper resolution is to isolate clients from the P2P protocol. Libbitcoin does this already.
Of course, the network operates just fine without universal trust. My concern is not that it is required, but that it may grow significantly and will have a tendency to gravitate towards more effective registration mechanisms for what is a "good" peer. Even an informal but pervasive web of trust may make it difficult for untrusted parties to connect.
We agree, and the ease of this attack must be acknowledged. And given that the protection is weak it is not unreasonable to consider the potential downside of creeping node identity.
I agree, and I doubt this proposal will have much impact on an advanced persistent threat, or even lesser threats. People should understand that there is both a risk and a limited benefit to this proposal.
I agree - I consider tunneling the legitimate use case for this proposal. Yet when nodes become closely coupled they are not fully independent. I have a concern with these practices being promoted for general use while at the same time being strongly implemented.
With this I disagree. There is no way to know that a node is one you have connected to previously unless that node wants you to know (apart from relying on the IP address). This is of no value in detecting misbehaving nodes that do not want to be detected. Ones that don't care (eg broken nodes) can be sufficiently managed by IP address.
Yes, let's not make it worse. This is a secondary concern. I remain primarily concerned about growth of node identity in a vain attempt to make transaction submission private in the P2P protocol (and to patch the other client-server features, specifically Bloom filters). As you imply, we cannot stop people from turning Bitcoin into a private network - but let's not facilitate it either.
I believe you have misinterpreted my comments on distributed anonymous credentials (and the like) as commentary on the construction of BIP151 (and a subsequent auth proposal). As such your observation that it is exaggerated would make sense, but it is not what I intended. Encryption and auth are straightforward. Preventing bad nodes from participating in an anonymous distributed system is not.

@_date: 2016-06-30 17:22:08
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
I understand the mechanics of a tunnel between trusting parties that have a secure side channel. But this assumes that no other peer can connect to these two nodes. How then do they maintain the chain?
The "middle" in this sense does not have to be the wire directly between these two peers. It can be between either of them and any anonymous connection they (must) allow.
Of course this creates pressure to expand their tunnel. Hence the problem of expanding node identity in an effort to preserve privacy. The protection will remain weak until the entire network is "secure". At that point it would necessarily be a private network.
As Pieter rightly observes, there are and always will be tunnels between trusting nodes. Often these are groups of nodes that are in collaboration, so logically they are one node from a system security standpoint. But if people become generally reliant on good node registration, it will become the registrar who controls access to the network. So my concern rests I this proposal becoming widely adopted.

@_date: 2016-06-30 20:25:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
BIP151 is self-admittedly insufficient to protect against a MITM attack. It proposes node identity to close this hole (future BIP required). The yet-to-be-specified requirement for node identity is the basis of my primary concern. This is not self-authentication.
The orthogonal question of whether Tor is safe for use with the Bitcoin P2P protocol is a matter of existing research.

@_date: 2016-06-30 22:26:48
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP 151 
============================== START ==============================
Neither Tor nor Bitcoin Core are part of this BIP (or its proposed dependency on node identity).
But again, given that node identity is not part of the Bitcoin Core Tor integration, my objection to the presumption of node identity by BIP151 is unrelated to Bitcoin Core's Tor integration.

@_date: 2016-03-02 11:01:36
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Hardfork to fix difficulty drop algorithm 
Yes, this is the essential point. All capital investments are made based on expectations of future returns. To the extent that futures are perfectly knowable, they can be perfectly factored in. This is why inflation in Bitcoin is not a tax, it?s a cost. These step functions are made continuous by their predictability, removing that predictability will make them -- unpredictable.
Changing these futures punishes those who have planned properly and favors those who have not. Sort of like a Bitcoin bail-in; are some miners are too big to fail? It also creates the expectation that it may happen again. This infects the money with the sort of uncertainty that Bitcoin is designed to prevent.
Sent: Wednesday, March 2, 2016 10:08 AM
For example, it is theoretically possible that 100% of miners (not 50%
or 10%) will shut off their hardware. This is because it is revenue
which ~halves, not profit.
It depends on how much is sunk costs and how much is marginal costs too.
If hashing costs are 50% capital and 50% marginal, then the entire network will be able to absorb a 50% drop in subsidy.
50% capital costs means that the cost of the loan to buy the hardware represents half the cost.
Assume that for every $100 of income, you have to pay $49 for the loan and $49 for electricity giving 2% profit.  If the subsidy halves, then you only get $50 of income, so lose $48.  But if the bank repossesses the operation, they might as well keep things running for the $1 in marginal profit (or sell on the hardware to someone who will keep using it).
Since this drop in revenue is well known in advance, businesses will spend less on capital.  That means that there should be less mining hardware than otherwise.
A 6 month investment with 3 months on the high subsidy and 3 months on low subsidy would not be made if it only generated a small profit for the first 3 and then massive losses for the 2nd period of 3 months.  For it to be made, there needs to be large profit during the first period to compensate for the losses in the 2nd period.

@_date: 2016-03-02 12:44:07
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Hardfork to fix difficulty drop algorithm 
Not sure how you interpret a tautology as doublespeak.
I'm addressing the hard fork proposal (see subject line).
Changes to consensus rules change the value of coins, which are property
of their owners. Nobody owes a miner a promise of consistent revenue for
future work. Cost or benefit to miners is relevant only to the extent
that those who hold money believe it will affect their value and
therefore consider it in their decision to consent.
How is the small group of experts today different from the small group
of experts tomorrow?
This is precisely the issue. The precedent of hard-forking to "fix" the
money is a precedent for establishing authority over the money.
But of course the losses would not be entirely operational, since
hardware (at a minimum) does not depreciate to zero because of a
halving. The ability to plan does not change this fact. There are
certainly similar considerations for labor, bandwidth, space and even
electrical/cooling costs (contracts). To the extent that these costs are
sunk (as Tier said) *any* earnings are better than none.
Of course, how could they not?
... which also ignores fees.

@_date: 2016-03-03 12:54:24
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Hardfork to fix difficulty drop algorithm 
I agree, this is a perfectly rational interpretation. I also agree that
this particular instance is academic. But I see more to this than
accepting what is possible.
In the case of Federal Reserve Notes the gold obligation was abrogated.
This was (at least) a contract default, implemented by force of arms.
This contentious hard fork was clearly an attack.
But in a system with no authority and in which nobody has formed a
contractual obligation with anyone else, what would constitute an attack
on the money? There is no difference between state attacks on (or
collusion with) miners and miners acting on self interest.
One answer is that nothing is an attack, it's up to the market to
decide. But to the extent that there can be an attack on the money, the
attempt to move the value of the coin to an altcoin (hard fork) is it.
Though the choice of the term "attack" isn't essential.
The importance of recognizing an attack is that it affords one the
opportunity to defend against it. People holding "dollars" in 1933 were
ill equipped to defend against a system level attack (monetary policy),
in part because many did not recognize it as such, and in part because
there was insufficient preparation by those who did.
I see us building the tools and awareness necessary for defense. As you
say, nobody has to buy into an altcoin forked from their coin. This much
is simple to achieve. The more difficult problem is preserving the
utility of the original coin. Clearly the purpose of a hard fork (as
opposed to a new coin) is to transfer this value.
We've all seen arguments for contentious hard fork deployment that
explicitly depend on the fear of monetary loss to drag people to
acceptance. While this may be the nature of the technology, it's
important that we develop effective defense against it.
Ultimately the only defense is individual validation. The collusion of
banks (web wallets) with miners in attacking consensus is obvious. But
even without active collusion, the surrender of validation leaves people
just as defenseless as *being* unarmed while retaining a right to
*become* armed.
Even if every person mines at the same level, the system amounts to
little more than majority rule if validation is not decentralized. There
are people perfectly willing to exploit this weakness.

@_date: 2016-03-23 14:40:50
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] p2p authentication and encryption BIPs 
Agree, P2P and client-server protocols are distinct use-cases. Missing
this distinction is the root cause of problems with the bloom filters
Privacy cannot currently be achieved unless the server is trusted. In
most wallet scenarios that's not a reasonable assumption unless one
controls the full node. So this is only useful in the case where the
wallet is trusting a remote server, and as you point out - message
encryption is weak in this case. In a trustless server scenario
encryption would be unnecessary overhead.
Agree, denial of service protection can and should be much more flexible
than this. It's not necessary to incorporate DoS protection into a
protocol. I think maybe this stems from the ill-advised attempt at
messaging reliability.
Also, this gets into the area of messaging reliability. This is
certainly not something I would recommend for a P2P protocol optimized
for maintaining a cache of public data.

@_date: 2016-11-14 10:47:35
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
Horrible precedent (hardcoding rule changes based on the assumption that large forks indicate a catastrophic failure), extremely poor process (already shipped, now the discussion), and not even a material performance optimization (the checks are avoidable once activated until a sufficiently deep reorg deactivates them).

@_date: 2016-11-15 14:42:05
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
Actually this does nothing to provide justification for this consensus rule change. It is just an attempt to deflect criticism from the fact that it is such a change.

@_date: 2016-11-16 05:58:57
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
This sort of statement represents one consequence of the aforementioned bad precedent.
Are checkpoints good now? Are hard forks okay now?
What is the maximum depth of a reorg allowed by this non-machine consensus?
Shouldn't we just define a max depth so that all cruft deeper than that can just be discarded on a regular basis?
Why are there activation heights defined by this hard fork if it's not possible to reorg back to them?
The "BIP" is neither a Proposal (it's been decided, just documenting for posterity), nor an Improvement (there is no actual benefit, just some tidying up in the notoriously obtuse satoshi code base), nor Bitcoin (a hard fork defines an alt coin, so from Aug 4 forward it has been CoreCoin).

@_date: 2016-11-16 14:21:53
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
I would suggest that, before discussing how best to fork the chain to meet this objective, we consider the objective.
The implementers have acknowledged that this does not represent a performance improvement. Especially given that this was apparently not initially understood, that alone is good reason for them to reconsider.
The remaining stated objective is reduction of code complexity. Let us be very clear, a proposal to change the protocol must be considered independently of any particular implementation of the protocol. While the implementation of BIP34 style activation may be hugely complex in the satoshi code, it is definitely not complex as a matter of necessity.
Activation constitutes maybe a dozen lines of additional code in libbitcoin. The need to hit the chain (or cache) to obtain historical header info will remain for proof of work, so this change doesn't even accomplish some sort of beneficial isolation from blockchain history.
So, at best, we are talking about various ways to introduce a consensus fork so that a well designed implementation  can remove a tiny amount of already-written code and associated tests. In my opinion this is embarrassingly poor reasoning. It would be much more productive to reduce satoshi code complexity in ways that do not impact the protocol. There are a *huge* number of such opportunities, and in fact activation is one of them. Once that is done, we can talk about forking to reduce source code complexity.
These fork suggestions actually increase *necessary* complexity for any implantation that takes a rational approach to forks. By rational I mean *additive*. Deleting rules from Bitcoin code is simply bad design. Rules are never removed, they are added. A new rule to modify an old rule is simply a new rule. This is new and additional code. So please don't assume in this "proposal" that this makes development simpler for other implementations, that is not a necessary conclusion.

@_date: 2016-11-16 16:00:33
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
This is a misinterpretation of BIP30. Duplicate transaction hashes can
and will happen and are perfectly valid in Bitcoin. BIP34 does not
prevent this.

@_date: 2016-11-16 16:10:07
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
No, BIP30 prevents duplicate tx hashes in the case where the new tx hash
duplicates that of a preceding tx with unspent outputs.
There was one such case that had already become buried in the chain at
the time, so it was exempted from validation. There was another case of
a duplicate hash, but it's predecessor was spent so it complied with the
new rule.
Both of these cases resulted from exact duplicate txs, which BIP34 now
precludes. However nothing precludes different txs from having the same

@_date: 2016-11-16 16:13:42
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
BIP30 was the resolution to a catostrophic protocol flaw that would
impact any block whether above or below the point where the rule was
applied. Applying it to all future blocks, regardless of whether there
is a reorg back to genesis, was the only option as far as I can tell. So
the comparison to an unnecessary fork is hardly apt.
BIP50 documents the release of an "unexpected" hard fork to a large
number of users. Given that Core code is considered by some to be the
*definition* of the true protocol, this led to two "legitimate" Bitcoin
chains. Leveraging the centralized state of Bitcoin mining, the
development team was able to kill the newer chain. This was simply an
altcoin that didn't survive because people stopped using it.
Anyone can create an altcoin - the question here is specifically, why
would we want to do so in this case.
There didn't seem to be any confusion among the implementers that it is
a hard fork.
I will correct one implication I made below. The heights in the proposal
are required in the absence of BIP34-style activation so that the soft
fork validation rules can be properly enforced at those points (whether
or not a deep reorg happens).

@_date: 2016-11-16 16:43:08
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
rules do guarantee it.
No, it means that the chance is small, there is a difference.
If there is an address collision, someone may lose some money. If there
is a tx hash collision, and implementations handle this differently, it
will produce a chain split. As such this is not something that a node
can just dismiss. If they do they are implementing a hard fork.

@_date: 2016-11-16 16:53:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
Also, it's important to take note of the motivation behind not banning
duplicate tx hashes outright. Doing so would require that spent tx
hashes are retained forever. A pruning node will have no way of knowing
whether a new tx duplicates the hash of a preceding tx. Any
implementation that does retain such hashes and dismisses new txs on
that basis would fork against pruning nodes.

@_date: 2016-11-16 17:41:51
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
"The pigeonhole principle arises in computer science. For example,
collisions are inevitable in a hash table because the number of possible
keys exceeds the number of indices in the array. A hashing algorithm, no
matter how clever, cannot avoid these collisions."

@_date: 2016-11-16 18:16:23
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
Yes, that was my point.
misunderstood as a security feature rather than as an optimization.
Or maybe because they place control of the "true chain" in the hands of
those selecting the checkpoints? It's not a great leap for the parties
distributing the checkpoints to become the central authority.
I recommend users of our node validate the full chain without
checkpoints and from that chain select their own checkpoints and place
them into config. From that point forward they can apply the
optimization. Checkpoints should never be hardcoded into the source.
I find "buried softfork" a curious name as you are using it. You seem to
be implying that this type of change is itself a softfork as opposed to
a hardfork that changes the activation of a softfork. It was my
understanding that the term referred to the 3 softforks that were being
"buried", or the proposal, but not the burial itself.
Nevertheless, this proposal shouldn't have "that problem" because it is
clearly neither a security feature nor an optimization. That is the
first issue that needs to be addressed.

@_date: 2016-11-17 01:58:38
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
Almost certainly is not certainly. Hash collisions happen because of chance.
BIP30 is quite explicit:
hinder pruning at some point in the future. Not allowing any transaction
to be duplicated would require evidence to be kept for each transaction
ever made."
BIP34 motivations:
block validation."
But it only specifies making collisions harder, not impossible (i.e.
explicitly rejected by consensus).
Are you proposing that we draft a new BIP that allows us all to not have
to code for this? If we do so it will be impossible to guard against a
chain split due to pruning, but you seem to think that's unimportant.

@_date: 2016-11-17 02:10:30
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] [BIP Proposal] Buried Deployments 
Certainly, but embedding them in the code makes that a practical
certainty. People cannot be prevented from doing dumb things, but let's
not make it hard for them to be smart.
I was out at a Bitcoin meetup when I read this and I think beer actually
came out of my nose.
It's either possible or it is not. If it is not there is no reason for a
proposal - just make the change and don't bother to tell anyone. The
reason we are having this discussion is because it is not impossible.
I'll call straw man on the question. It is not important to avoid the
activation checks. The question is whether there is a material
performance optimization in eliminating them. This would have to be
significant enough to rise to the level of a change to the protocol.
Having said that there are a few options:
1. The naive approach to activation is, for each new block, to query the
store for the previous 1000 block headers (to the extent there are that
many), and just do so forever, summing up after the query. This is the
most straightforward but also the most costly approach.
2. A slightly less costly approach is, for each new block, to reverse
iterate over the store until all decisions can be made. This would be an
improvement below activation in that it would take it takes as little as
251 vs. 1000 queries to make the determinations.
3. A further improvement is available by caching the height of full
activation of all three soft forks. Unless there is a subsequent reorg
with a fork point prior that height, there is never a need to make
another query. Once fully activated the activation height is cached to
the store (otherwise just query the last 1000 versions at startup to
determine the state), eliminating any ongoing material cost.
4. We may also be interested in optimizing initial block download. A
cache of the last 1000 block versions can be maintained by adding each
to a circular buffer as they are committed. This eliminates *all*
querying for block versions unless:
(1) there is a restart prior to full activation - in which case there is
a query of up to 1000 versions to prime the cache.
(2) there is a potential reorg after full activation, and the fork point
precedes the saved full activation height - in which case the cache must
be reprimed.
(3) there is a potential reorg. before reaching full activation - in
which case the cache must be backfilled with a query for a number of
versions equal to the depth of the fork point.
During initial block download potential reorgs are exceedingly rare
(reorgs don't have potential unless they have sufficient work to
overcome the long chain) and the cost of handling them as described
above is trivial. The cost of priming the cache is immaterial in the
context of a restart.
So even with a full chain validation one is not likely to *ever* need to
query the store. The memory cost of the cache is strictly 3 bits per
block (375 bytes total). A simpler less memory-sensitive approach is to
use one byte (1,000 bytes total). The computational cost is trivial.
This should already be implemented. A protocol fork (or "change that
modifies the validity of a theoretically construable chain from invalid
to valid") to avoid doing so is not a performance optimization.
I find it to be completely unsupportable as there is no security,
performance, or feature benefit in it.

@_date: 2016-11-17 03:22:03
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
Sure, if you accept that mostly is not fully - just as unlikely is not
That's like saying, as long as we exclude car accidents from
consideration, car accidents are impossible.
I generally try to avoid speaking in tautologies :)
This is not the case.
Block hash duplicates within the same chain are invalid as a matter of
consensus, which is the opposite of assuming impossibility.
Tx hash collisions are explicitly allowed in the case that preceding tx
with the same hash is unspent. This is also not a reliance on the
impossibility of hash collision. Core certainly implements this distinction:
Address hashes and script hashes can collide without harming the
security of Bitcoin (although address owner(s) may experience harm).
Rare in this case is sufficient because of this distinction.
Compact blocks contemplates hash collisions:
Checkpoints aren't part of Bitcoin security, so even the remote
possibility of two different potential blocks, with the same hash, at
the same height in the same chain, does not indicate a problem.
There is no case where the security of Bitcoin assumes that hashes never
collide. Consensus rules have specific handling for both block hash
collisions and tx hash collisions.

@_date: 2016-11-17 04:22:09
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
If this discussion is not appropriate for the Bitcoin Protocol
Discussion list then the list is pointless.
So the protocol change that I suggested to Peter an hour or so ago was
actually implemented, a year ago, by you:
Given that hash collisions are unquestionably possible, this is a clear
break with BIP30 (irrespective of BIP34) and constitutes a hard fork. Is
there going to be a retroactive BIP for this one at some point as well?
I'm aware that the block hash check is performed against the full chain,
as opposed to the candidate block fork height, and as a result is
insufficient to guard against a block hash collision causing a chain
split (though until now I assumed this was a bug).
Would you care to share the other consensus critical reliances on the
impossibility of hash collision that you are implying?

@_date: 2016-11-17 09:01:20
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
So... you think hash collisions are not possible, or that it's moot
because Core has broken its ability to handle them.
I suppose if you take fairly recent un-BIPped consensus changes in Core
to be the definition of consensus, you would be right about that.
And those changes could definitely result in a chain split. So right
about that too.
create 2 different versions of UTXOs (if the colliding tx is valid), or
make some nodes to accept a fork with less PoW (if the colliding tx is
invalid, or making the block invalid, such as being to big).
Not in accordance with BIP30 and not according to the implementation of
it that existed in Core until Nov 2015. A tx was only valid as a
"replacement" if it did not collide with the hash of an existing tx with
unspent outputs. The collision would have been rejected. And an invalid
colliding tx would not be accepted in any case (since nodes presumably
validate blocks and don't rely on checkpoints as a security measure).
A transaction duplicating the hash of another and taking its place in a
block would not only have to collide the hash, but it would have to be
fully valid in the context of the block you are suggesting it is
substituted into. In that case it's simply a fully valid block. This is
not just the case of a hash collision, this is the case of a hash
collision where both transactions are fully valid in the context of the
same block parent. Even if that unlikely event did occur, it's not a
hard fork, it's a reorg. The chain that builds on this block will be
valid to all nodes but necessarily deviates from the other block's valid
chain. This is true whether the magical block is assembled via compact
blocks or otherwise.
Transaction "replacement" is an implementation detail of Core. Once Core
accepted a replacement of a previously spent transaction it would be
unable to provide the previous block/spent-tx, but that would be a
wallet failure and an inability to provide valid historical blocks, not
a consensus/validation failure. The previously spent outputs no longer
contribute to validation, unless there is a reorg back to before the
original tx's block, and at that point it would be moot, since neither
transaction is on the chain.
You are referring to the *current* behavior ("replacement" without
concern for collision). That was an unpublished hard fork, and is the
very source of the problems you are describing.
Bitcoin Core and any implementation of the Bitcoin protocol should
assume SHA256 collision is unquestionably **impossible**.
I'm not disagreeing with you that it is broken. I'm pointing out that it
was broken by code that was merged recently - an undocumented hard fork
that reverted the documented BIP30 behavior that was previously
implemented correctly, based on the assumption that hash collisions
cannot occur, for the modest performance boost of not having to check
for unspent duplicates (sounds sort of familiar).
alternative hash algorithm and somehow run it in parallel with SHA256 to
prevent the consensus failure.
No hash algorithm can prevent hash collisions, including one that is
just two running in parallel. A better resolution would be to fix the
There is no need to replace the BIP30 rule. That resolves the TX hash
collision problem from a consensus standpoint. In order to serve up
whole blocks in the circumstance requires a more robust store than I
believe is exists in Core, but that has nothing to do with validity.
The block hash check and signature validation caching splits caused by
collision can easily be avoided, and doing so doesn't break with
consensus. I'm not aware of any other aspects of consensus that are
effected by an implementation assumption of non-colliding hashes. But in
any case I'm pretty sure there aren't any that are necessary to consensus.

@_date: 2016-11-17 09:49:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
Actually both possibilities were specifically covered in my description. Sorry if it wasn't clear.
If you create a new valid block out of an old one it's has potential to cause a reorg. The blocks that previously built on the original are still able to do so but presumably cannot build forever on the *new* block as it has a different tx. But other new blocks can. There is no chain split due to a different interpretation of valid, there are simply two valid competing chains.
Note that this scenario requires not only block and tx validity with a tx hash collision, but also that the tx be valid within the block. Pretty far to reach to not even get a chain split, but it could produce a deep reorg with a very low chance of success. As I keep telling people, deep reorgs can happen, they are just unlikely, as is this scenario.
If you create a new invalid block it is discarded by everyone. That does not invalidate the hash of that block. Permanent blocking as you describe it would be a p2p protocol design choice, having nothing to do with consensus. Libbitcoin for example does not ban invalidated hashes at all. It just discards the block and drops the peer.

@_date: 2016-11-17 22:20:52
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
You are suggesting that, since a node implements a denial of service policy that actually denies itself otherwise valid blocks, those blocks are conditionally invalid. And that, since the validity condition is based on order of arrival and therefore independently unverifiable, Bitcoin consensus is broken in the face of a hash collision.
I am aware of two other hash collision scenarios that cause Core to declare blocks invalid based on ordering. The block hash duplicate check (it's not fork-point relative) and signature verification caching. Like the "block banning" issue above, the latter is related to an internal optimization. I would categorize the former as a simple oversight that presumably goes way back.
What then is the consequence of validity that is unverifiable? You believe this means that Bitcoin consensus is broken. This is incorrect. First understand that it is not possible for consensus rules to invalidate blocks based on order of arrival. As such any *implementation* that invalidates blocks based on order of arrival is broken. It is an error to claim that these behaviors are part of consensus, despite being implemented in the satoshi node(s).
Validity must be verifiable independent of the state of other nodes. Consensus is a function of block history and time alone. Time is presumed to be universally consistent. To be a consensus rule all nodes must be able to independently reach the same validity conclusion, given the same set of blocks, independent of order. If this is not the case the behavior is not a consensus rule, it is simply a bug. Deviating from such bugs is not a break with consensus, since such non-rules cannot be part of consensus. One node implementation can behave deterministically while others are behaving non-deterministically, with the two nodes remaining consistent from a consensus standpoint (deterministic produces a subset of non-deterministic results). But, unlike arbitrary nodes, deterministic nodes will not cause disruption on the network.
You imply that these determinism bugs are necessary, that there is no fix. This is also incorrect.
The block banning hash collision bug is avoided by not using non-chain/clock state to determine validity. Doing otherwise is clearly a bug. The hash of a block is not the block itself, a logically-correct ban would be to compare the wire serialization of the block as opposed to the hash, or not maintain the feature at all.
The signature verification caching hash collision bug is the same problem, an optimization based on an invalid assumption. A full serialization comparison (true identity), or elimination of the feature resolves the  bug.
The block hash check collision bug is trivially resolved by checking at the fork point as opposed to the tip. This prevents arbitrary (and irrational) invalidity based on conflict with irrelevant blocks that may or may not exist above the fork point.
Libbitcoin is deterministic in all three cases (although the third issue is not made consistent until v3). I am not aware of any other non-determinism in Core, but I don't spend a lot of time there. There is no need to study other implementations to ensure determinism, as that can be verified independently.
Any situation in which a node cannot provide deterministic validation of unordered blocks constitutes a non-consensus bug, as the behavior is not consistently verifiable by others under any conditions. Fixing/preventing these bugs is responsible development behavior, and does not require forks or BIPs, since Bitcoin doesn't inherently contain any such bugs. They are the consequence of incorrect implementation, and in two of the three cases above have resulted from supposed optimizations. But any code that creates non-determinism in exchange for speed, etc. is not an optimization, it's a bug. A node must implement its optimizations in a manner that does not alter consensus.
The BIP30 regression hard fork is not a case of non-determinism. This will produce deterministic results (apart from the impact of unrelated bugs). However the results are both a clear break from previous (and documented) consensus but also produce a very undesirable outcome - destruction of all unspent outputs in the "replaced" transaction for starters. So this is a distinct category, not a determinism bug but a hard fork that produces undesired consequences.
The BIP30 regression hard fork actually enables the various pathological scenarios that you were describing, where no such issues existed in Bitcoin consensus previously. It is now possible to produce a block that mutates another arbitrarily deep block, and forces a reorg all the way back to the mutated block. This was done to save microseconds per block. Despite the improbability of hash collisions, I find this deplorable and the lack of public discussion on the decision concerning.
With respect to the original post, the point at issue is the introduction of another hard fork, with some odd behaviors, but without any justification apart from tidying up the small amount of necessary code. These issues are related in that they are both consensus forks that have been introduced as supposed optimizations, with no public discussion prior to release (or at least merging to master with the presumption of shipping in the latter case). Two of the three hash collision issues above are also related in that they are bugs introduced by a desire to optimize internals.
The engineering lesson here should be clear - watch out for developers bearing optimizations. A trade against correctness is not an optimization, it's a break. Satoshi was clearly a fan of the premature optimization. FindAndDelete is a howler. So this is a tradition in Bitcoin. My intent is not to sling mud but to improve the situation.
It is very possible to produce straightforward and deterministic code that abides consensus and materially outperforms Core, without any of the above optimization breaks, even avoiding the utxo set optimization. Even the tx (memory) and block (orphan) pools are complex store denormalizations implemented as optimizations. Optimizing before producing a clean conceptual model architecture and design is a software development anti-pattern (premature optimization). The proposed fork is a premature optimization. There are much more significant opportunities to better organize code (and improve performance). I cannot support the decision to advance it.
I was unaware Core had regressed BIP30. Given that the behavior is catastrophic and that it introduces the *only* hash-collision consensus misbehavior (unless we consider a deep reorg sans the otherwise necessary proof of work desirable behavior), I strongly recommend it be reverted, with a post-mortem BIP.
Finally I recommend people contemplate the difference between unlikely and impossible. The chance of random collision is very small, but not zero. Colliding hashes is extremely difficult, but not impossible. But Bitcoin does not rely on impossibility for correct behavior. It relies of difficulty. This is a subtle but important distinction that people are missing.
Difficulty is a knowable quantity - a function of computing power.  If hash operations remain difficult, Bitcoin is undeterred. Collisions will have no impact, even if they happen with unexpected frequency (which would still be vanishingly infrequent). If the difficulty of producing a collision is reduced to the point where people cannot rely on addresses (for example), then Bitcoin has a problem, as it has become a leaky ship (and then there's mining). But with the unnecessary problems described above, a single hash collision can be catastrophic. Unlike difficulty, which is known, nobody can know when a single collision will show up. Betting Bitcoin, and potentially the world's money, on the unknowable is poor reasoning, especially given that the cost of not doing so is so very low.

@_date: 2016-11-18 10:47:09
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP30 and BIP34 interaction (was Re: [BIP 
What is the difference between downloading a hash and comparing it to a hash vs downloading a hash and then a block and comparing it to a block?
You are talking about breaking a system in order to make it run faster. Using the hash is an non-optimization trade against correctness.
There is no "first seen" rule, there is only valid and invalid. Even the name exposes the error of this thinking as "first" requires order.
Caching invalidity for DOS protection is fine. It should be quite obvious that the blockchain is nothing more than a coach of validity. If it's faster in some cases to store both validity and all invalidity that you are aware of it is fine, you are trading space for time.
But caching information that is neither validity nor invalidity, and using it to validate blocks is a break.
I cannot emphasize this point enough. A technique that provides varied results based on communication history, such as this "rule", is an attack vector. It allows the attacker to place information into your cache and read it back later from another connection. Even optimizing correct results based on communication history exposes the node in this manner. These sort of attacks have been shown to be very effective at deanonymizing hidden nodes.
The p2p protocol actually makes this sort of attack a matter of communication standard via the sharing of address information, but this can be disabled without impacting correctness. Due to such non-optimizations as the first seen "rule" however, a node becomes a candy store of fingerprinting attack vectors.
Bitcoin provides the mechanism to reject cheaply-produced invalid blocks quickly. This is after all the fundamental principle of hash cash - force the attacker to pay to spam attack. By obtaining headers first a node can obtain proof of work and perform correct and fast validation before ever obtaining the block's transactions. This technique is probably no more time-costly than the incorrect technique of checking a cache of hashes (ironically, a "hash cache" is an incorrect "hash cash"), and avoids the extra space of a secondary cache (the blockchain is the primary cache). It also avoids the varied time response that a secondary cache creates.
So once again, premature optimization erupts from the underlying design flaw, and creates more problems than proper design. The p2p network standard didn't have headers first at one point, making correct checks more costly. That is no longer the case. But nevertheless, one cannot trade correctness for time.
The tx pool, like the orphan pool, as I mentioned previously, is an optimization. It is not a part of consensus, so it isn't relevant to a discussion about forks. It is also a design flaw that nodes are expected to hold invalid transactions. It exposes nodes to both DOS and fingerprinting attacks. Proper tx handling implies that a tx connect to a valid block. There is no "header" for a transaction so correctness requires that the tx be downloaded before it can be validated.

@_date: 2016-10-16 09:42:49
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Start time for BIP141 (segwit) 
If somebody is not "running their own validation code"  then they aren't actually using Bitcoin, so their ease in transition is irrelevant. For all they know they are accepting random numbers.

@_date: 2016-09-09 17:54:28
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Completing the retirement of the alert system 
libbitcoin defines the message and includes the public key but only for completeness and reference purposes. It has never been used in the node.

@_date: 2017-04-01 00:41:46
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Hard fork proposal from last week's meeting 
Hash: SHA256
"Governments are good at cutting off the heads of a centrally
controlled networks..."

@_date: 2017-04-06 16:38:23
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Using a storage engine without UTXO-index 
Hash: SHA256
Hi Tomas,
This is the approach that genjix used in libbitcoin version2. With the
exception of de-linking (not deleted) in the case of reorgs, the
entire store is append only, implemented in a small set of memory
mapped files. The downsides to the approach are:
(1) higher than necessary storage space requirement due to storing the
indexing data required for correlate the spends, and
(2) higher than necessary validation complexity and cost in terms of
computing the spent-ness (including spender height) of an output.
His implementation used a hash table, so performance-wise it did quite
well and would theoretically outperform a tree, O(1) vs. O(log2(N)).
I was successful in parallelizing input validation (across the inputs
of an unconfirmed tx and across the set of all inputs in a block)
using the v2 store. However, it is not the case that the spends
approach is necessary for concurrency.
To resolve the above two problems the version3 store does not use a
spends table/index. Nor does it store any table of UTXOs. Yet
validation is highly parallelized. Instead of additional indexes it
uses the tx hash table, augmented with 32 bits per output for spender
height. So there is a O(1) cost of finding the tx and a O(N) cost of
finding the spender height where N is the number of outputs in the tx.
But because the number of outputs in a tx is bounded (by block size)
this is constant time in the number of transactions.
This works out much faster than the spends table, and without the
storage cost or complexity disadvantages. It also scales with
available hardware, as the memory mapped files become in-memory hash
tables. For low memory machines we found it was important to implement
an opaque UTXO cache to limit paging, but for higher end systems zero
cache is optimal.
I don't follow this part, maybe you could clarify. A spends index
grows with the size of the spend set (forever) as it cannot be pruned,
which certainly exceeds the size of the UTXO set (unless nothing is
spent). The advantage is that you don't have to keep rewriting the
store when you use a spends set (because the store can be append only).
Feel free to message me if you'd like to discuss in more detail, or to
continue on the libbitcoin mailing list (copied).

@_date: 2017-04-07 12:55:58
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Using a storage engine without UTXO-index 
Hash: SHA256
While this may seem to be the case it is not generally optimal. The
question is overly broad as one may or may not be optimizing for any
combination of:
startup time (first usability)
warm-up time (priming)
shutdown time (flush)
fault tolerance (hard shutdown survivability)
top block validation (read speed)
full chain validation (read/write speed)
RAM consumption
Disk consumption
Query response
Servers (big RAM)
Desktops (small RAM)
Mining (fast validation)
Wallets (background performance)
SSD vs. HDD
But even limiting the question to input validation, all of these
considerations (at least) are present.
Ideally one wants the simplest implementation that is optimal under
all considerations. While this may be a unicorn, it is possible to
achieve a simple implementation (relative to alternatives) that allows
for the trade-offs necessary to be managed through configuration (by
the user and/or implementation).
Shoving the entire data set into RAM has the obvious problem of
limited RAM. Eventually the OS will be paging more of the data back to
disk (as virtual RAM). In other words this does not scale, as a change
in hardware disproportionately impacts performance. Ideally one wants
the trade between "disk" and "memory" to be made by the underlying
platform, as that is its purpose. Creating one data structure for disk
and another for memory not only increases complexity, but denies the
platform visibility into this trade-off. As such the platform
eventually ends up working directly against the optimization.
An on-disk structure that is not mapped into memory by the application
allows the operating system to maintain as much or as little state in
memory as it considers optimal, given the other tasks that the user
has given it. In the case of memory mapped files (which are optimized
by all operating systems as central to their virtual memory systems)
it is possible for everything from zero to the full store to be memory
Optimization for lower memory platforms then becomes a process of
reducing the need for paging. This is the purpose of a cache. The seam
between disk and memory can be filled quite nicely by a small amount
of cache. On high RAM systems any cache is actually a de-optimization
but on low RAM systems it can prevent excessive paging. This is
directly analogous to a CPU cache. There are clear optimal points in
terms of cache size, and the implementation and management of such a
cache can and should be internal to a store. Of course a cache cannot
provide perfect scale all the way to zero RAM, but it scales quite
well for actual systems.
While a particular drive may not support parallel operations one
should not assume that a disk-based store does not benefit from
parallelism. Simply refer to the model described above and you will
see that with enough memory the entire blockchain can be
memory-resident, and for high performance operations a fraction of
that is sufficient for a high degree of parallelism.
In practice a cache of about 10k transactions worth of outputs is
optimal for 8GB RAM. This requires just a few blocks for warm-up,
which can be primed in inconsequential time at startup. Fault
tolerance can be managed by flushing after all writes, which also
reduces shutdown time to zero. For higher performance systems,
flushing can be disabled entirely, increasing shutdown time but also
dramatically increasing write performance. Given that the blockchain
is a cache, this is a very reasonable trade-off in some scenarios. The
model works just as well with HDD as SSD, although certainly SSD
performs better overall.

@_date: 2017-04-07 16:51:08
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Using a storage engine without UTXO-index 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
It's a reasonable assumption, and given that the no-explicit-cache
implementation is a subset of the optionally-cached implementation,
was of course the initial implementation.
In practice this is not the case. The Bitcoin data model is neither
continuous nor strictly segregated by usage.
It is true that with sufficient RAM a cache is totally
counterproductive. It is also my experience that an independent UTXO
store is not a reasonable/necessary trade of disk space, memory
scalability, and/or code complexity in exchange for speed.
But on lower memory systems a explicit cache is beneficial. The
difference is clearly measurable in production code by simply changing
the cache limit and testing on various configurations.

@_date: 2017-04-08 11:51:32
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] A Small Modification to Segwit 
Hash: SHA256
Electric power is not an abstraction, it's the output of machines.
What you are referring to as Power Cost typically consists of a higher
rent component than computing hardware, where rent is the sharing of a
resource by multiple people. So by your reasoning you appear to have
drawn the wrong conclusion.

@_date: 2017-04-08 15:37:50
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Using a storage engine without UTXO-index 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
My point was that "Using a storage engine without UTXO-index" has been
done, and may be a useful reference, not that implementation details
are the same.
Below you addressed two points I made regarding the downside of the
original libbitcoin implementation. These were initial learnings that
informed future implementations (also without a UTXO index). These
were not comparisons to your implementation.
The references to "higher than necessary storage" and "higher than
necessary validation cost" are explicitly relative statements,
comparing earlier and later libbitcoin implementations.
It is not clear to me how you are relating both the storage cost
("Hmm. No. ... Neither impose significant storage requirements.") and
code complexity ("... resulting code is actually much less complex")
of your tx ordering software to my statements. Do you think I am wrong
and libbitcoin v3 is not actually more space and code efficient than
libbitcoin v2?
But given that you have thrown some numbers and ideas out in a request
for feedback, I'm happy to give you some based on several years of
experience working closely with these issues.
First, I remain confused on your comments pertaining to UTXO growth
and network protocol. I followed your conversation with Greg and it
remains unclear to me. From what I understand you have isolated order
(double spend) from script validation. I think we all understand that
script validation requires inputs and outputs while double spend
detection requires correlation of inputs. What I do not understand is
your choice of optimization axis.
Detection of double spend is not useful in isolation. One must also
validate scripts, which requires outputs. I can see that there is an
opportunity to reject blocks (within the same branch) faster by
validating for double spends before validating script. But unconfirmed
transactions do not exist in a branch, and are therefore not truly
conflicting, until they are mined. And even after they are mined
conflicting txs remain potentially valid in other branches. So
rejecting txs due to conflict comes down to a denial of service
policy, which ultimately must be based on fee increment (e.g. RBF).
But fees are based on the amount of the output value that remains
unspent in the transaction. So this in turn requires the retrieval of
And yet the remaining scenario of fast rejection of invalid blocks is
not a meaningful optimization. Optimizing for the case where a block
has valid and sufficient PoW and yet is invalid (for double spend) is
counterproductive. And even so, the txs within the invalid block may
be entirely valid independent of the block, so you are back to looking
up their outputs to obtain fees in the case of a double spend or to
validate script otherwise. In all cases you need to get the outputs.
I realize that you see the implementation of the ordering validation
as interesting detail, but I find it hard to justify contemplating the
implementation in isolation from the output lookup requirement. And if
one must looking up both outputs and spends for each validation, it
makes more sense to co-locate that data.
Recovering in one step all data necessary to validate a tx has real
advantages over either interleaving queries and validation or
splitting input vs. output validation queries into two steps. It is a
significantly more test-friendly approach, has better performance
characteristics, and simplifies code. I cannot see any reason to
perform the data read for double spend validation in isolation of that
for script validation.
I think the conversation with Greg resolved my questions in this area.
What I find interesting is the reliance on Core's UTXO store to
implement script validation. This is not, "a storage engine without a
UTXO-index" as it has a dependency on Core's UTXO index.
On the other hand the initial libbitcoin implementation that I
described to you is *actually* a bitcoin store with no UTXO index. The
current implementation is as well, however it is implemented
differently and is much more efficient than the original. How it
compares to your design is not really the point and impossible to
measure until you have production code.
I can say however that your assumptions about the storage (and
performance) superiority of the design, or at least its
implementation, seem unfounded. If you are storing more index data
(5.6gb) than 32 bits per output, you are using more space than
production implementations. As for complexity, I don't think you'll
get any simpler than a loop to populate spend heights from a hash
table and a loop to test their integer values.
If by results you are referring to performance numbers, it's very hard
to draw any conclusions without a full benchmark. It's great that if
you are able to boost Core, but from my perspective the numbers aren't
especially compelling.
As for some of the site's comments, these again cause me to question
the optimization choices:
"Blocks can be verified in parallel..."
Despite the site's explanation I cannot think of any reason to ever
validate two blocks at the same time. You would always prioritize the
block with the greatest PoW. Doing otherwise just slows down the net
validation in all but the pathological case where a miner has produced
an *invalid* block with *more* PoW than another valid block which
arrived at the node within the same second. Rejecting a *valid* block
with more PoW in favor of one with *less* "processing" is a hard fork,
so you probably wouldn't want to do that either. But with compact
block validation times approaching 25ms it's hard to justify stopping
a block validation for any reason.
That's not to say parallel block validation difficult to do. If you
can validate one block's full set of inputs in parallel (which is not
novel) doing the same with additional blocks has trivial additional
"The storage engine is optimized from ground up for
xthin/compact-block synchronization. This ensures that when the
majority of transactions are already synced, incoming blocks can be
verified at minimal resources using order-validation only."
There are two distinct considerations here. One is pre-validation of
txs and the other is compact announcements. Just to be clear, the
former does not require the latter. Libbitcoin for example fully
exploits the former, independent of compactness. With a low min fee
setting and a few peers it is typical for the node to have
pre-validated 100% of non-coinbase txs. Averages at 1 satoshi per byte
are about 99.9%, effectively amortizing all script validation cost. So
this optimization is neither novel nor limited to compactness (which
is about reducing latency).
I am also interested in your previous comments about soft forks. These
are material considerations that Greg touched on but it doesn't sound
like you fully appreciate just yet. When a tx is pre-validated the
rules applied must be the same rules as those of some future block.
Yet a tx can be included in more than one block (different branches).
Across branches and even in one branch, validation rules change, and
can change back. The changes are based on accumulated branch history.
Pre-validation can later become invalidated, and differently in
different branches. And maintaining proper context requires either
storing state that you are apparently not storing, or invalidating
optimizations. Based on your comments you do not seem to be accounting
for this in your storage assumptions or in your results. A recent post
by Greg highlights the complexity and consensus criticality of these
By "order-validation only" I believe you are referring to a
determination of whether the txs organized into a candidate block
double spend internal to the block or in the ancestry. Assuming that
one recovers outputs at the same time (and presumably from the same
location) as spender height (which is required both for validating
spends of a coinbase and for determination of whether the spend is
above the fork point), this determination is straightforward. One
simply loops over the spender records and invalidates a tx that has a
spender height not above the fork point (while also validating
coinbase maturity using the same height). A loop over the set of
in-memory spend heights of each output a tx is certainly fast enough
to not be worthy of any further optimization. And as previously
discussed, the population of the spender heights is not even a
material additional cost over obtaining the (necessary) output scripts.
The hash table store that I described can fully navigate the block
tree and transaction DAG, since the stored tx, parent and point hashes
are also natural keys and each link is navigable in constant time. It
is also lock-free, can concurrently write any number of blocks during
initial block download and supports read/write concurrency. It has
successfully indexed and stored the entire blockchain from the P2P
network in 16 minutes (locally). It also stores both confirmed and
unconfirmed transactions in the same store, so there is nothing to
write when a block is confirmed except for the block header/hashes and
updates to spender heights for any output spent by the new block's
txs. It is similarly capable of storage in the block table of weak
chain blocks...
But one thing it does *not* do is maintain spender and fork state for
multiple branches. In other words it is optimized for one long chain,
not multiple long branches. Your approach has a limited (in terms of
double spend identification) optimization for reorganization (i.e. a
change to the strong chain identity). However, applying that
optimization to the full store and supportive of soft forks, as
opposed to just input ordering, is a much larger task than it appears
you have attempted. I know, as I created a design for that approach
and after some time scrapped it. The cost of performing the
reorganization in the above store is low enough and very long reorgs
infrequent enough, for the optimization to be counterproductive. It's
elegant in theory, but in practice it increases storage requirements,
impacts general performance and significantly increases complexity.
Bitcoin's data model pushes one away from a tree design in that it is
always pruning the tree. Having the tree is necessary, but it's not
something to optimize for.

@_date: 2017-04-10 18:44:57
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Using a storage engine without UTXO-index 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
Maybe it's an issue of terminology. I have never used the terms
base/peak load. However I've been trying to get across, poorly I
suppose, that this is actually implemented in libbitcoin. I generally
refer to it as tx pre-validation. I've also tried to relate that you
are unnecessarily relating pre-validation to compactness. These are
unrelated ideas and better considered independently. One can get
nearly all of the benefit of pre-validation while still receiving
blocks (vs. compact blocks). The advantage of compactness is reduced
latency of the block announcement. The reason for pre-validation is
amortization of the validation and/or storage cost of a block.
As I understand it you would split tx inputs and outputs and send them
independently, and that you intend this to be a P2P network
optimization - not a consensus rule change. So my comments are based
on those inferences. If we are talking about consensus changes this
conversation will end up in an entirely different place.
I don't agree with the input/output relevance statements above. When a
tx is announced the entire tx is relevant. It cannot be validated as
outputs only. If it cannot be validated it cannot be stored by the
node. Validating the outputs only would require the node store invalid
I do accept that a double-spend detection is not an optimal criteria
by which to discard a tx. One also needs fee information. But without
double-spend knowledge the node has no rational way to defend itself
against an infinity of transactions that spend the minimal fee but
also have conflicting inputs (i.e. risking the fee only once). So tx
(pool) validation requires double-spend knowledge and at least a
summary from outputs.
Inputs that are already valid against prevouts remain valid assuming
consensus rules have not changed. But any input that spends a coinbase
must be validated for prevout height once there is a block context for
validation. Additionally the set of txs must be validated for total
size, sigops, and fee claim. So it's not true that conflict detection
alone is sufficient. Yet one can cache a tx's size, sigops, fee and
minimum height in a graph so that when a block appears that contains
that tx the input validation can be skipped.
Ignoring the (actual) requirement for the full tx on the pool
validation, the required "order" validation at (compact or other)
block arrival basically consists of traversing each tx, ensuring none
are confirmed in a block below the fork point; traversing each each of
its confirmed inputs, ensuring that none are spent in a block below
the fork point; and ensuring the block's set of transactions do not
contain missing inputs and do not double spend internal to the block.
This and the above-mentioned other required per-transaction block
validation data can be cached to an in-memory structure as a potential
optimization over navigating the store, and as you say, does not
therefore require the actual outputs (script/value). But the original
issue of needing full transactions for independent transaction
validation remains.
A reorg is conceptual and cannot be engineered out. What you are
referring to is a restructuring of stored information as a consequence
of a reorg. I don't see this as related to the above. The ability to
perform reorganization via a branch pointer swap is based not on the
order or factoring of validation but instead on the amount of
information stored. It requires more information to maintain multiple
Transactions have confirmation states, validation contexts and spender
heights for potentially each branch of an unbounded number of
branches. It is this requirement to maintain that state for each
branch that makes this design goal a very costly trade-off of space
and complexity for reorg speed. As I mentioned earlier, it's the
optimization for this scenario that I find questionable.
Full separation of concerns allows all validation to be performed in
isolation from the store. As such validation state can be faked and
provided to a tx, block or chain, for the purpose of test. Validation
that interacts with a complex store during validation is harder to
fake and tests can be hard to verify.
It's not really the "one-step" approach that make this possible. In
fact that's not an accurate description. Validation and storage of txs
and blocks consists of four steps:
(1) context free
(2) contextual (chain-based)
(3) expensive (script eval)
(4) storage and notification
So we have:
...where "chain" is the store, from which "state" is derived. The
state for an unconfirmed tx is based on the presumption that the tx
would be mined in the next block. If that is not the case then its
pre-validation can become invalidated. So from my perspective, this
discussion is all about populating state. Anything that cannot be
placed into that pattern would complicate both the conceptual model
and testing. We've also seen that this isolation also has performance
advantages, as it facilitates optimizations that are otherwise
Because choosing the lesser amount of work is non-consensus behavior.
Under the same circumstances (i.e. having seen the same set of blocks)
two nodes will disagree on whether there is one confirmation or no
confirmations for a given tx. This disagreement will persist (i.e. why
take the weaker block only to turn around and replace it with the
stronger block that arrives a few seconds or minutes later). It stands
to reason that if one rejects a stronger block under a race condition,
one would reorg out a stronger block when a weaker block arrives a
little after the stronger block. Does this "optimization" then apply
to chains of blocks too?
Implementations are free to choose no blocks. That's not really the issu
Accepting a block that all previous implementations would have
rejected under the same circumstance could be considered a hard fork,
but you may be right.
Yet the classification is not essential to my point. Nor is any
material change required to validate blocks in parallel. We can do it
using current design, but it doesn't make sense to do so.
This is not an optimization, since it should always be optimal to
validate blocks independently. Performing multiple together inherently
slows both of them. And the advantage to not validating *either* would
Hope is a bug.
You cannot have a useful performance measure without full compliance.
If you intend this to be useful it has to help build the chain, not
just rely on hardwiring checkpoints once rule changes are presumed to
be buried deeply enough to do so (as the result of other implementations
I understand this approach, it was ours at one time. There is a
significant difference, and your design is to some degree based on a
failure to fully consider this. I encourage you to not assume any
consensus-related detail is too small.
It's worth noting that many of your stated objectives, including
modularity, developer platform, store isolation, consensus rule
isolation (including optional use of libbitcoinconsensus) are implemente
It seems like you are doing some good work and it's not my intent to
discourage that. Libbitcoin is open source, I don't get paid and I'm
not selling anything. But if you are going down this path you should
be aware of it and may benefit from our successes as well as some of
the other stuff :). And hopefully we can get the benefit of your
insights as well.

@_date: 2017-04-11 02:41:34
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Using a storage engine without UTXO-index 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
It's not the headers/tx-hashes of the blocks that I'm referring to, it
is the confirmation and spend information relative to all txs and all
outputs for each branch. This reverse navigation (i.e. utxo
information) is essential, must be persistent and is branch-relative.
That's not your concurrent validation scenario. In the scenario you
described, the person chooses the weaker block of two that require
validation because it's better somehow, not because it's his own
(which does not require validation).
Consistency is reached, despite seeing things at different times,
because people use the same rules. If the economy ran on arbitrary
block preference consistency would be elusive.
This line of reasoning has me a bit baffled. Yet as I said, it's not
important to the question at hand. It is not likely to be optimal to
validate concurrently even if you consider selection of a weaker block
Storing the validation flags with each tx is exactly what libbitcoin
does (otherwise pre-validation would be infeasible). But that was not
the full point. You said on this in response previously:
adequate and safe.
I read this as encoding the height at which a fork historically
activated. If you intend to track activation for each branch that will
not be "height-based" it will be history based.

@_date: 2017-12-18 07:43:58
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Why not witnessless nodes? 
Why run a full node if you are not going to verify the chain?

@_date: 2017-12-18 11:19:34
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Why not witnessless nodes? 
You can't know (assume) a block is valid unless you have previously validated the block yourself. But in the case where you have, and then intend to rely on it in a future sync, there is no need for witness data for blocks you are not going to validate. So you can just not request it. However you will not be able to provide those blocks to nodes that *are* validating; the client is pruned and therefore not a peer (cannot reciprocate). (An SPV client is similarly not a peer; it is a more deeply pruned client than the witnessless client.)
There is no other reason that a node requires witness data. SPV clients don't need it as it is neither require it to verify header commitment to transactions nor to extract payment addresses from them.
The harm to the network by pruning is that eventually it can become harder and even impossible for anyone to validate the chain. But because you are fully validating you individually remain secure, so there is no individual incentive working against this system harm.

@_date: 2017-12-18 16:58:58
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Why not witnessless nodes? 
How does one know what consensus has formed (around a UTXO set)?

@_date: 2017-02-07 12:32:46
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Three hardfork-related BIPs 
The semantics of a necessarily secure and private client-server protocol differ from that of a necessarily distributed and public P2P protocol. I realize you refer to the C/S as a distinct API, but this point is worthy of clarification and emphasis.
The introduction of client-server sub-protocols into the Bitcoin P2P protocol has resulted in large scale privacy loss, weakened end-user security and reduced access to the public network. Plans to mitigate these issues stand to make matters worse by restricting access to the public network through the introduction of strong identity to the P2P protocol.
It is not the case that C/S APIs against private full nodes do not exist. Electrum (stratum) and Libbitcoin (zeromq) are notable examples. The management difficulties are not small, but there are also fundamental issues that must first be addressed.
In your example you imagine pluggsble SSD space, but Satoshi derivatives have scale deficiencies unrelated to storage. If we are going to get to reliable, cheap, performant personal full nodes (which I agree is essential to Bitcoin survival) we need nodes that scale (i.e. to the available hardware). We also require a robust, reliable and performant node/server development stack, not just the impossible choice between a fragile monolith and centralizing web APIs/wallets.
All centralized interfaces to Bitcoin (wallets, web APIs, payment services) shrink the economic consensus and thereby weaken its defense of sound and fungible money. The only solution is personally-controlled full nodes, as you say. The incentives for running a full node are sufficient if the cost of doing so is low. Getting there requires a node/server architecture intended for this outcome. Then maybe appliances are feasible.

@_date: 2017-02-12 21:18:41
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP151 protocol incompatibility 
The BIP151 proposal states:
the encinit messages.
This statement is incorrect. Sending content that existing nodes do not
expect is clearly an incompatibility. An implementation that ignores
invalid content leaves itself wide open to DOS attacks. The version
handshake must be complete before the protocol level can be determined.
While it may be desirable for this change to precede the version
handshake it cannot be described as backward compatible.

@_date: 2017-02-13 01:36:21
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP151 protocol incompatibility 
As I said, it *may* be desirable, but it is *not* backward compatible,
and you do not actually dispute that above.
There are other control messages that qualify as "optional messages" but
these are only sent if the peer is at a version to expect them -
explicit in their BIPs. All adopted BIPs to date have followed this
pattern. This is not the same and it is not helpful to imply that it is
just following that pattern.
As for DOS, waste of bandwidth is not something to be ignored. If a peer
is flooding a node with addr message the node can manage it because it
understands the semantics of addr messages. If a node is required to
allow any message that it cannot understand it has no recourse. It
cannot determine whether it is under attack or if the behavior is
correct and for proper continued operation must be ignored.
This approach breaks any implementation that validates traffic, which is
clearly correct behavior given the existence of the version handshake.
Your comments make it clear that this is a *change* in network behavior
- essentially abandoning the version handshake. Whether is is harder to
maintain is irrelevant to the question of whether it is a break with
existing protocol.
If you intend for the network to abandon the version handshake and/or
promote changes that break it I propose that you write up this new
behavior as a BIP and solicit community feedback. There are a lot of
devices connected to the network and it would be irresponsible to break
something as fundamental as the P2P protocol handshake because you have
a feeling it's going to be hard to maintain.

@_date: 2017-02-13 02:30:14
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP151 protocol incompatibility 
No. This is what I was referring to. These messages are enabled by
protocol version. If they are received by a node below the version at
which they are activated, they are unknown messages, implying an invalid
peer. The above messages cannot be sent until *after* the version is
negotiated. BIP151 violates this rule by allowing the new control
message to be sent *before* the version handshake.
There are already nodes out there breaking connections based on the BIP.
Yes, the ordering of the messages. New messages can only be added after
the handshake negotiates the higher version. Otherwise the handshake is
both irrelevant (as Pieter is implying) and broken (for all existing
protocol versions).
You may be more familiar with non-validating peers. If a message type is
not known it is an invalid message and the peer is immediately dropped.
We started seeing early drops in handshakes with bcoin nodes because of
this issue.
Sure, a peer can do what it wants. It can send photos. But I'm not sure
what makes you think it would be correct to maintain the connection when
an *invalid* message is received.
different for messages specified in BIP151?
Because it properly validates the protocol.
More than that it supports a configurable protocol range. So by setting
the min protocol (below which the node won't connect) and the max
protocol (at which it desires to connect) we can observe the behavior of
the network at any protocol levels (currently between 31402 and 70013).
This is very helpful for a development stack as it allows one to easily
test against each protocol level that one wishes to support.

@_date: 2017-02-13 02:54:23
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP151 protocol incompatibility 
handshake and protocol negotiation is the exchange of otherwise-ignored
messages to set up optional features.
Only if the peer is at the protocol level that allows the message:
compact blocks:
fee filter:
send headers:
had indicated they wouldn't support it, see, eg BIP 152's handshake. Not
sure why you consider this backwards incompatible, as I would say it's
pretty clearly allowing old nodes to communicate just fine.
No, it is not the same as BIP152. Control messages apart from BIP151 are
not sent until *after* the version is negotiated.
I assume that BIP151 is different in this manner because it has a desire
to negotiate encryption before any other communications, including version.

@_date: 2017-02-13 03:17:11
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP151 protocol incompatibility 
In the interest of perfect clarity, see your code:
Inside of the VERACK handler (i.e. after the handshake) there is a peer
version test before sending SENDCMPCT (and SENDHEADERS).
I have no idea where the fee filter message is sent, if it is sent at
all. But I have *never* seen any control messages arrive before the
handshake is complete.
are ignored by old peers amounts to a lack of backward compatibility.
See preceding messages in this thread, I think it's pretty clearly
spelled out.

@_date: 2017-02-14 11:54:37
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP151 protocol incompatibility 
The issue I raised is that it is not backward compatible. It sounds like
you agree but consider it a fair trade. My suggesting was that the BIP
be updated to reflect the lack of compatibility.
It doesn't need to be specified, most of Bitcoin is unspecified. The
version handshake establishes the negotiated version. It is not possible
to determine if a message is of the negotiated version before the
version is negotiated. All messages apart from this one have followed
that rule.
An incoming connection will be dropped due to invalid protocol and
potentially banned depending on the implementation.
Not working with peers not supporting BIP151 is the compatibility issue.
But it sort of seems the intent in this case is to rely on that
incompatibility (expecting connections to nonsupporting peers to fail as
opposed to negotiating).
I did consider the possibility, but there's this:
"Encryption initialization must happen before sending any other messages
to the responding peer (encinit message after a version message must be
The BIP does not define "responding" and "requesting" peers, but:
"A peer that supports encryption must accept encryption requests from
all peers... The responding peer accepts the encryption request by
sending a encack message."
This implies the requesting peer is the peer that sends the message. You
seem to be saying that the requesting peer is the one that initiated
the connection and the responding peer is the connection receiver. If
this is the case it should be more clearly documented. But in the
case I experienced the "requester" of an encrypted session was also
the "receiver" of the connection.
Flexible is certainly one word for it. Another way to describe it is
dirty. Allowing invalid messages in a protocol encourages protocol
incompatibility. You end up with various implementations and eventually
have no way of knowing how they are impacted by changes. There could be
a range of peers inter-operating with the full network while running
their own sub-protocols. Given the network is public and strong
identification of peers is undesirable, the invalid messages would
reasonably just get sent to everyone. So over time, what is the
protocol? Due to certain "flexibility" it is already a hassle to
properly implement.
There is no reason to treat invalid messages differently based on where
they occur in the communication. After the handshake the agreed version
is known to both peers. As a result there is never a reason for an
invalid message to be sent. Therefore it is always proper to drop a peer
that sends an invalid message.
This was previously addressed (immediately below).
See above.
This is a misinterpretation. The failure to validate did not enable
anything except possibly some broken peers not getting dropped. None of
the protocol changes previously deployed require the older version peer
to allow invalid messages. While it may appear otherwise, due to a
particular implementation, it is never necessary to send a message to a
peer that the peer does not understand. The handshake gives each peer
the other peer's version. That obligates the newer peer to conform to
the older (or disconnect if the old is insufficient). That's the nature
of backward compatibility.
Yes, this is the purpose of version negotiation, which is why there are
version and verack messages. And this is also why, in the satoshi
client, two of the above messages are sent from the verack handler. The
feefilter message is sent dynamically but only if the peer's version
allows it.
I'm not sure I follow your question. The BIP should presumably declare a
version number if one is necessary.
In general you should set a version before it's ever live on the
network. But if it precedes the protocol version negotiation the
protocol version number is moot.
I've been asked to throttle the discussion in the interest of reducing
list volume. I think the issue is pretty clearly addressed at this
point, but feel free to follow up directly and/or via the libbitcoin
development list (copied).

@_date: 2017-02-27 08:50:07
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Moving towards user activated soft fork activation 
The relationship between a codebase and chain fork implementations is similar to vendor lock-in, and is being used in a similar manner.
There is nothing preventing a single codebase from implementing all forks and exposing the option to apply any non-conflicting combination of them.
While this has not been the norm libbitcoin now utilizes this approach. Currently the options to apply any activated Bitcoin forks are exposed via config. I personally am not working to implement non-activated forks at this point, but that's just prioritization.
Recently I objected to BIP90. This hard fork is presented as a code simplification and a performance optimization. I showed in the discussion that it was neither. Nevertheless we implemented this additional code and give the user the option to apply it or not. It's application produces no performance benefit, but it ensures that the choice of forks remains in the hands of the user.

@_date: 2017-01-03 22:06:31
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Committed bloom filters for improved wallet 
Credit card reversals involve an escrow agent with control over the entire network and with a strong interest in preserving the network. A better analogy would be blind acceptance of any slip of paper under the assumption that it is sufficient currency. It may or may not be so, but you are on your own in either case.

@_date: 2017-01-04 23:45:18
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Committed bloom filters for improved wallet 
A world connected up to a few web services to determine payment validity
is an example of a bitcoin security catastrophe.

@_date: 2017-01-06 13:50:47
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Committed bloom filters for improved wallet 
It is a useful aspect of discussion at this level as it helps higher lever developers understand the actual tradeoffs. Clearly some do not. The market will eventually sort them out, but the discussion both gives developers the necessary information.
It also helps core development prioritize resources. I personally would not prioritize core work to facilitate zero conf. I would even spend time to discourage it, as others have done.
I think the cautions in this thread about doing privacy and system security damaging things (like checking mining pools for zero conf transactions) will prevent some wasted time, which benefits everyone.

@_date: 2017-01-07 15:49:10
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Bitcoin Classic 1.2.0 released 
The level of control over a majority of full nodes is irrelevant. If
this was truly a measure of control over Bitcoin someone would simply
spin up a bunch of nodes and take control at trivial cost.

@_date: 2017-01-07 16:32:25
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Bitcoin Classic 1.2.0 released 
While I agree with the sentiment, to be fair one should acknowledge that
Bitcoin Core has intentionally implemented two hard forks since Nov
2015. The earlier is released, and I assume the latter will be.
Neither was subject to activation, or prior public debate (see Buried
Deployments threads):
There was at least some internal discussion about whether a BIP should
document the latter having occurred, and that question was put to the list:
Some have argued that these are inconsequential changes. I disagree, as
the arguments is base on provably invalid assumptions. Nevertheless, if
hard fork is the threshold criteria here, Core has not met it.

@_date: 2017-01-29 11:37:07
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Three hardfork-related BIPs 
============================== START ==============================
It is true, there is no question. The fact that an attack does not appear to have occurred does not mean that the vulnerability exists. It is as you say a trivial exploit, which means it will happen when the economic incentive is great enough. Analogous attacks on other points of centralization are already well underway.

@_date: 2017-07-06 10:41:52
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Height based vs block time based thresholds 
Just as an implementation consideration, time basis creates complexity. There are no other reasons to index by time, but many to index by height. The time-based activation window of BIP9 forces nodes to either index by time or scan the chain.

@_date: 2017-06-15 08:04:30
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Proposal: Demonstration of Phase in Full Network 
There is exactly one way to express one's opinion on consensus at the protocol level - participation. The method is neither flawed nor inequitable in the context of Bitcoin.
The only "problem" with it is that people are not satisfied with having a voice limited to their participation. People are used to political systems in which they vote using their existence as power, not their participation, and they expect some subset of existing human bodies to control all others. This is the concept of some ruling over others, which gives the rulers a more powerful voice than either their proportional existence or individual participation would allow.
Bitcoin exists in defiance of political models. It is a market, not a state. The only choice you have is to participate or leave. If you are satisfied with others participating in your stead, you have left the consensus - you have no say.
Most people who think they are participating in Bitcoin have either never participated or long ago left the consensus. Having surrendered it, these people now grope for a way to have their say. You can always reclaim your say on consensus, but you cannot take it away from others.
To have your say regarding hard forks, you must validate Bitcoin received in exchange for something else of economic value. To have your say regarding soft forks you must mine. Everyone has these options. Hard forks cannot control miners' selection of transactions and miners cannot control the economy's determination of what is valid. If one wants a say in either one must participate in the respective operation.

@_date: 2017-06-16 06:09:33
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Proposal: Demonstration of Phase in Full Network 
Seems functional as a way for the economy to signal, but signaling is only an expression of intent to participate, not actual participation. One can signal and then not participate, as we see with hash rate signaling.
Today we see people complaining about miner control, because hash rate is centralized. Tomorrow we are likely to see people complaining about economic control, as its centralization continues.
So imagine a few web wallets/APIs signaling based on their ownership of the major fraction of value. Can potential splitters safely rely on these signals? The wallets have a voice because they participate.
Consider also that user activated soft forks are not followed by unmodified nodes (on the presumption of minority hash rate support that necessitated the economic activation). In other words, they exhibit the categorical behavior of hard forks (incompatibility). So to the extent that the economy has control, it is only over the ability to hard fork (split the chain).

@_date: 2017-06-20 09:03:43
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP Proposal: Compact Client Side Filtering for 
The reason that BIP37 presents a long list of problems is that it is a client-server scenario wedged into a peer-to-peer network. The only possible excuse for this design was implementation shortcut.
As this thread and others demonstrate, reproducing this design flaw will not eliminate the problems. The fact that there are many wallets dependent upon it is an unfortunate consequence of the original sin, but is not likely to last. There is no rationale for node operators to support wallets apart from their own. As a node implementer interested in privacy, security and scalability, I would never waste the time to code BIP37, or and client-server feature into the P2P protocol, especially one that delegates some aspect of validation.
Other nodes (servers) provide independent, securable, client-server interfaces. Many of these are made available as community servers for use at no charge. They could also provide mechanisms for operator payment without polluting the P2P network.
However as a community we should be working toward full node wallets. A secured personal node/server can support remote mobile wallets with security, privacy and no wasted bandwidth. And if we avoid counterproductive increases in blockchain growth rate, full nodes will eventually be able to run on mobile platforms with no difficulty whatsoever. A wallet that delegates full validation to node operators is just another centralization pressure that we do not need.

@_date: 2017-03-05 10:48:33
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Moving towards user activated soft fork activation 
There are two aspects of system security in Bitcoin, mining (hash power) and payment validation (economy). The security of each is a function of its level of decentralization. Another way to think of it is that a system with less decentralization has a smaller community (consensus). A large consensus is more secure in that it is more resistant to change (forks) than a system with a small consensus.
The fact that mining is highly centralized makes it relatively easy to enforce a fork via miner collaboration, and hard to do so without it.
So clearly the other option, as being discussed here, is to enforce a fork via the economy. Given the highly centralized nature of the economy, described below as "economic hubs", it is also relatively easy as well.
Independent of one's opinion on the merits of one fork or another, the state of centralization in Bitcoin is an area of great concern. If "we" can sit down with 75% of the economy and/or 90% of the hash power (which of course has been done) and negotiate a change to any rule, Bitcoin is a purely political money.
If "we" can do this, so can "they".

@_date: 2017-03-07 09:37:15
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Moving towards user activated soft fork activation 
transactions, in response to a user activated soft fork that the
majority of hashpower disagrees with.
This definition of censorship would apply to all validation.
A miner is free to select whatever transactions he wants, for whatever
reasons he wants. Bitcoin's defense against censorship (and disruption)
is in the broad distribution of over 50% (anecdotally) of the hash power
among a large number of people.
Exactly, a soft fork expects that people start rejecting a previously
valid style of transaction, or that they ignore it. It's perfectly
reasonable to conclude that some miners may continue to accept the
soft-fork-invalidated transactions and instead reject the new style of
transactions as invalid. Reliance on their acceptance of the soft fork
is based on the weak assumption that they won't change their software or
that they live in fear of a retaliatory POW change.
Honesty in this context refers to double spending. Selecting a different
rule set effectively moves one to another coin, which is not dishonest
(hostile to anyone).  Miners have zero technical or ethical obligation
to follow any particular set of rules. Bitcoin has one golden rule, run
whatever code you want. Security is based on decentralization, not
well-behaved people (or well-behaved software).
Again spot on. Users of the money purchase security from miners. Miners
are under no obligation to provide that service nor are users under any
obligation to purchase it.
One thing to consider is how different the landscape would look if every
person on the planet was a miner, and the economy was similarly
distributed. Would it be easier to get 51% hash power on board with a
soft fork, or some much higher percentage on board with a hard fork? It
seems likely that any proposed material change would fail. Regardless of
how one feels about that, it is the nature of a sound money that it
doesn't change.

@_date: 2017-03-07 10:13:36
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Moving towards user activated soft fork activation 
mine blocks every 10 minutes.
Presumably a POW hard fork would be accompanied by a difficulty reset, so that the deployment didn't have *both* of these problems from the outset.  There's really little difference between 10 minutes at little/no security and zero conf. See testnet. But people might feel better about still seeing blocks.
But in any case it's not clear to me why you assume a loss of security in the "short term" is something that can be overcome. The short term can presumably prevent the long term from ever becoming.

@_date: 2017-03-07 10:44:07
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Unique node identifiers 
This is of course my objection to BIP150 ("a way for peers to ... guarantee node ownership").
Anonymous node identity is pointless, and is why I object to BIP151. It provides no actual security/privacy benefit and is a stepping stone to non-anonymous node identity (e.g. BIP150).
Bitcoin does not require node counts, and this proposal is redundant with BIP150.

@_date: 2017-03-08 13:09:05
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Unique node identifiers 
I'm always willing to debate this issue. I'm generally a little
suspicious of one who demands another person to stop arguing. I got at
least one such demand (along with a threat) on this subject privately
last summer from a notable Core dev. There is a lengthy thread on this
subject in which I raised these issues. Everyone is free to review that
The "presharing" of keys is how provable identity works, and is
precisely what this new proposal is also promoting. And in response to
that, the above statement was made by a Core dev (and not disputed):
I'm calling out the obvious relationship between BIP150 and this new
proposal. Restating how identity works, or that its use is optional does
not refute my position. It's not FUD.

@_date: 2017-03-08 17:08:04
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Unique node identifiers 
BIP150 will lead to every node being identifiable.
My argument against BIP150 (and 151) is based on the very real concern
that it provides a built-in mechanism to partition the network (while
also providing no meaningful privacy benefit).
The only actual argument that I have seen from *anyone* to date is that
this is *unlikely* to happen. That was specifically Pieter's position
last summer. That argument is not technical but instead based on blind
trust in people.
The common refrain, which Pieter has penned again in a follow-up to this
post, is that we already have identity in terms of IP addresses, so
what's the harm. I find this argument ironic given that one of the
arguments in favor of this proposal is that IP address identification is
insufficient to establish identity. I assume that you both understand
there is a very meaningful distinction between strong identity and weak
The other argument that is often given is that, because we are talking
about privately shared as opposed to published identifiers, there is no
reason for concern. This entirely misses the point. The ability to
establish strong identity makes it trivial for someone to (strongly)
require the identity of anyone with who he/she allows a connection. This
is the *stated purpose* of BIP150. This turns the Bitcoin security model
on its head. Instead of validating content this validates people.
Given the current level of economic and hash power centralization it is
not at all hard to imagine that through fear/consequences of regulatory
controls or even poor scalability, that these points of centralization
will eventually start by establishing private connections, and
eventually require anyone connecting to them to "preshare" an identifier
(which of course identifies the person). At that point Bitcoin P2P will
have become a private network. I know you have the right motivation, but
I do not understand why you would ignore this risk in exchange for a
false sense of privacy.
There is a very clear path to this happening. So please explain to me
how this concern is "wrong". This is *not* a technical question, I know
perfectly well how the scheme works.
but I will ask you to stop if I see you attacking BIP150/151 at every
occasion with FUDish arguments like this.
Take a step back and consider that there may in fact be serious
consequences to what you are proposing. Calling may arguments
"attacking" and "FUD" is unproductive.

@_date: 2017-03-21 17:04:47
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Unique node identifiers 
Hash: SHA256
Reposting this response since this made it neither to distribution nor
to the moderation archive.

@_date: 2017-03-23 18:58:37
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Issolated Bitcoin Nodes 
Hash: SHA256
Juan's statement pertains to incompatibility, not mysterious causation.
Clearly it's a material consideration. Is it an oversight that this is
not documented as an incompatibility in any of the segwit BIPs?
I don't recall any discussion on the importance of segwit bridge
nodes. Is there a plan for bridging mainnet?

@_date: 2017-03-25 20:00:51
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Two altcoins and a 51% attack (was: Defending 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
primary concern [...] is the possibility of a blockchain split and the
associated confusion, replay risk, etc.
ruleset enforced by the majority could change the proof-of-work and
start a spin-off from the existing Bitcoin ledger [...]
The "spin off" to which you refer is an altcoin. The "network upgrade"
to which you refer is also an altcoin. Both are hard forks from
Bitcoin. I'm having a hard time imagining how a plan to create two new
altcoins from Bitcoin avoids either a split or confusion.
Application of hash power toward the disruption of Bitcoin presumes
participating miners are willing to accept a total loss on these
operations. I can imagine a significant portion of the hash power
deciding to let their competitors donate to "confusion reduction".
Eventually those thrifty miners will put the philanthropists out of
business. Maybe you can get Coinbase and Bitpay to finance the operation
This plan seems to be a response to the industry call for replay
protection. Actually writing the code is another option.
Despite the fact that nobody (miners included) has any way to measure
what software the economy (or hash power) is running, or what is the
economic weight of that portion of the economy.

@_date: 2017-03-26 14:12:20
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Defending against empty or near empty blocks from 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
Given the protocol requirements of the segwit proposal this is not the
case. A miner running pre-segwit code will produce blocks that no
segwit node will ever receive. It matters not whether these blocks
contain transactions that are invalidated by the soft fork. Despite
being valid to other pre-segwit nodes they will never be built upon by
the majority hash power once segwit activates.
At the same time, Peter's comment above is also incorrect. A "minority
branch" *is* a set of blocks that have been orphaned (the term orphan
being a misnomer, since these blocks of course have an ancestry all
the way to the genesis block). That's precisely what is implied by the
word "minority". So his description contradicts itself.

@_date: 2017-03-26 15:15:54
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Defending against empty or near empty blocks from 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
The repeated use of the term "network upgrade" in place of the
accepted technical term (hard fork) is misleading. This and the
presupposition that the hard fork is coming, and the claims that it's
not your proposal, make me feel like I'm shopping for a used car...
It's not used it's pre-owned, everyone's getting the warranty, let me
see what my manager has to say about the price - it's not my decision.
This is a development list. Avoidance of standardized terminology and
use of the presumptive close diminishes your message.
"tightening of the rule set" == soft fork
This implies that the minority hash power is producing blocks that are
valid according to rules in existence prior to the soft fork. You are
referring to these as invalid, but because this has already confused
one commentator, let's be clear. The blocks you are referring to are
valid blocks being orphaned because the majority hash power is
rejecting them because of soft fork activation. This of course
produces a minority chain, so this statement is incorrect.
"loosening of the consensus rule set" == hard fork
This is also incorrect. In the case of a hard fork old nodes reject
the new blocks that are invalid according to old rules and continue to
accept other old blocks. This produces a second distinct chain. It is
neither a majority nor a minority chain with respect to the original.
It is simply a new coin that happens to share history with the old
coin. This doesn't imply confusion, since both chains continue to
operate under the rules of their nodes. The only confusion arises from
people wanting to transaction across *both* chains. It is only in this
context that replay becomes an issue.
Stopping people from transacting on the old chain due to an ongoing
51% attack (again, using proper terminology) is one way to make it
hard for people to transact on both chains. But if you don't care that
people are able to transact on both chains, there's no reason to spend
the money on the attack.
So let me point to the elephant in the room. The proposed 51% attack
is more obviously an attempt to transfer economic activity from BTC to
BTU, not a benevolent measure to prevent confusion. It can clearly be
viewed as elimination of competition through an electronic attack on
BTC operations. Given that they are all regulated entities, I'm not
sure how the envisioned large miner collaborators (or others who might
fund it) will feel about participation in the scheme.
You are right that this is not about Core and BU. These are
implementations, not protocols. However, please do not presume that
other implementations are enlisted in your scheme, or that this is
about making the network more bug-resistant.
I feel like making the block size a configuration option in Libbitcoin
just to emphasize the gross error of this idea. It has never been
about the inability of users to compile the code. It's about the
purposeful difficulty in changing the rules when everyone has a say.
The idea was so powerful you were converted (another sales tactic).
Who's proposal is this? Can they not speak for themselves?
These are not ethical questions. These are development questions,
built on economic concepts, backed by individual financial decisions.
There is no equivalence of ideas based on one's arbitrary perspective.
The "split" is always by the one that hard forks. The splitter is the
one who changes what exists and therefore creates something new.
Please fix your terminology.
A hard fork, including changing the PoW algorithm, requires the
purposely improbable coordination of the economy in the creation of a
new coin and the abandonment of the old. This should be apparent from
the ongoing block size hard fork attempts.

@_date: 2017-03-27 13:01:41
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Encouraging good miners 
Hash: SHA256
All transactions being publicly available is not something that can be
With no opportunity cost for a miner to generate withheld
transactions, a larger miner still maintains the economic advantage of
latency as a function of block size. Fast relay works to reduce
latency in relation to the opportunity cost created by the space
constraint. IOW, the more fees a miner must give up to mine withheld
transactions, the greater the economic disadvantage of doing so. So
there is a "downside" (i.e. centralization pressure) up to the point
where the advantage gained from withholding transactions turns negative.
The rational competing miner must presume that a block is valid upon
confirming the announcement's PoW. He then has the choice of mining on
top of the (partially-visible) block, or ignoring it until it can be
fully populated. The former *eliminates fee opportunity*, since the
next block must remain free of all public fee-generating transactions
until all of the preceding block's transactions are visible. The
latter increases orphaning probability, since it implies mining on the
weak chain, which *increases total reward loss*.
One can conclude that no matter how much space is created, it will
always be filled by a rational miner, as a competitive necessity,
given the centralizing effect of latency. Making blocks big enough to
include low cost transactions nullifies the benefits of fast relay
techniques based on your above assumption, since a rational miner will
simply substitute withheld transactions.

@_date: 2017-03-27 14:03:08
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Segregated witness p2p layer compatibility 
Hash: SHA256
I agree, and thanks for the detailed clarification. Clearly it is
possible for segwit blocks to be relayed. It is the implementation of
Bitcoin Core (at least), in the absence of sufficient relay, that
produces this outcome.
IOW Bitcoin Core has been implemented so that it will not see valid
blocks announced by certain of its peers. Forcing it to see such
blocks requires the p2p network work around its implementation. I
agree that this is not inherent in the specifications for segwit, but
it reads more like a bug than an "implementation detail" to me.

@_date: 2017-03-31 11:58:44
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Hard fork proposal from last week's meeting 
As an independently verifiable, decentralized store of public information, the Bitcoin block tree and transaction DAG do have an advantage over systems such as Visa. The store is just a cache. There is no need to implement reliability in storage or in communications. It is sufficient to be able to detect invalidity. And even if a subset of nodes fail to do so, the system overall compensates.
As such the architecture of a Bitcoin node and its supporting hardware requirements are very different from an unverifiable, centralized store of private information. So in that sense the comparison below is not entirely fair. Many, if not most, of the high costs of a Visa datacenter do not apply because of Bitcoin's information architecture.
However, if the system cannot remain decentralized these architectural advantages will not hold. At that point your considerations below are entirely valid. Once the information is centralized it necessarily becomes private and fragile. Conversely, once it becomes private it necessarily becomes centralized and fragile. This fragility requires significant investment by the central authority to maintain.
So as has been said, we can have decentralization and its benefit of trustlessness or we can have Visa. We already have Visa. Making another is entirely uninteresting.
e

@_date: 2017-03-31 16:13:09
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Hard fork proposal from last week's meeting 
============================== START ==============================
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
The cause of the block size debate is the failure to understand the
Bitcoin security model. This failure is perfectly exemplified by the
above statement. If a typical personal computer cannot run a node
there is no security.

@_date: 2017-05-09 16:11:31
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Network-layer attacks 
Hash: SHA256
I draw a very different conclusion.
The paper states:
?Our work underscores the importance of proposed modifications which
argue for encrypting Bitcoin traffic or traffic exchanged among miners.?
The phrase, ?encrypting ... traffic exchanged among miners,? is not
merely about encryption, since if one cannot identify the peer as the
intended miner it could just as well be an attacker. This is about
(presumably encrypted) authenticated connections.
Indeed, encryption of traffic among miners is referred to again here:
?Finally, an attacker cannot intercept (possibly encrypted) private
connections, corresponding to peering agreements between mining pools.
- From the attacker?s point of view, these connections can be treated as
intra-pool connections and the corresponding pair of pools can be
considered as one larger pool.?
So the encryption-based defense for miners is to use authentication to
create, ?one larger pool,? consisting of, ?private connections.?
Additionally it states, ?we show that hijacking fewer than 100
prefixes is enough to isolate a large amount of the mining power due
to Bitcoin?s centralization.?
In other words the proposed solution, to what is largely a problem of
miner centralization, is to create one miner. The paper doesn?t
attempt to investigate the downside to that apparent centralization
The paper investigates routing attacks on the p2p protocol,
specifically partitioning and delay. Regarding traffic encryption it
*stresses* the caution:
?Yet, we stress that not all routing attacks will be solved by such
measures since attackers can still disrupt connectivity and isolate
nodes by dropping Bitcoin packets instead of modifying them.?
In other words it recognizes that encryption is both centralizing and
ineffective. Along these lines it also observes:
* A smaller set of nodes will be easier to isolate for extended periods.
* All incoming connection slots can be occupied by connections from
attacker nodes.
* Outgoing connections can be biased via a traditional eclipse attack.
Notice that none of these issues are mitigated by encryption, since in
each case the encrypted connection may just as easily be the attacker.
The presumed powerful attacker (one with the ability to modify
Internet routing tables) is not deterred by encryption. Instead of
modifying or dropping packets he can simply redirect traffic to his
own node(s) and carry on the attack on an encrypted connection with
the victim. As such all calls for encryption in the P2P protocol
ultimately end in calls for authentication.
It is true that if all connections are authenticated these attacks are
mitigated. But as the ?one larger pool? discussion shows, this is
simply a regression to a private network.
As for the two scenarios analyzed, the summary on delay attacks includes
* Delay attackers intercepting 50% of a node?s connection can waste
63% of its mining power.
* Due to pools multi-homing, Bitcoin (as a whole) is not vulnerable to
delay attackers, even powerful ones.
* Even a small degree of multi-homing is enough to protect Bitcoin
from powerful attackers.
Furthermore, the delay attack scenario explicitly relies on, ?the fact
that a [Core] Bitcoin node waits for 20 minutes after having requested
a block from a peer before requesting it again from another peer.? The
waste of mining power above is a function of that delay. So delay is
not a material concern for the entire network, and there are
mitigations that hang much lower than making the network private.
Regarding partitioning, clearly neither encryption nor authentication
can ensure that one is seeing the strongest chain unless the network
is fully private (and trustworthy). The paper states, ?Increase
partition persistence: ... Intuitively, the attacker needs to suppress
the effect of churn in order to keep the victim nodes isolated.? In
other words, simply rotating connections is presumed to be effective.
There are other useful countermeasures listed in the paper:
* Increase the diversity of node connections
* Select Bitcoin peers while taking routing into account
* Monitor round-trip time (RTT)
* Monitor additional statistics
* Embrace churn
* Use gateways in different ASes
* Prefer peers hosted in the same AS and in /24 prefixes
* Use distinct control and data channels
* Use UDP heartbeats
* Request a block on multiple connections
The single recommendation that includes encryption is heavily qualified:
* Encrypt Bitcoin Communication and/or adopt MAC
"While encrypting Bitcoin connections would not prevent adversaries
from dropping packets, it would prevent them from eavesdropping
connections and modifying key messages. Alternatively, using a Message
Authentication Code (MAC) to validate that the content of each message
has not been changed would make delay attacks much more difficult."
First, it should be widely understood that eavesdropping on the relay
of public information is not an attack. Secondly, the paper clearly
states, ?attackers can still disrupt connectivity and isolate nodes by
dropping Bitcoin packets instead of modifying them.? So the
distinction between dropping and modifying messages is immaterial. And
thirdly, the paper recognizes that eclipse attacks remain effective
short of authentication.
Taken alongside the risk of centralization though the widespread use
of authentication, which the paper does not contemplate, encryption is
anything but low hanging fruit. Several of the other above mitigations
are described as effective, and it is the case that some nodes already
employ some of them. Libbitcoin for example embraces churn by
providing both configurable and partially-randomized connection
timeout and a configurable block withholding timeout.
The paper is a valuable contribution in assessing risks to the P2P
network and individual nodes, and suggesting mitigations, but it is
not comprehensive. As with block size, the most obvious answer is not
always the right answer. Bitcoin is a public cache of independently
verifiable information shared anonymously over a P2P network. The
primary threat is centralization. Authentication is a necessary aspect
of centralizing the network.

@_date: 2017-05-11 14:05:09
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP proposal: NODE_NETWORK_LIMITED service bits 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
I agree. Every full node operator should (and likely would at some
point) simply never connect to, or relay the address of, any "peer"
advertising itself as diminished. Why on earth would a full node
operator want to encourage shrinking support for bootstrapping and
deep reorgs, resulting in greater load for himself. That's a race to
the bottom.
We are literally talking about $7.50 for the *entire chain* with
breathing room. If someone wants to save a few dollars they are better
off attempting to hide their pruning.
But maybe I?m confused.

@_date: 2017-05-12 20:26:08
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP: Block signal enforcement via tx fees 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
If people want to influence the decisions of miners, all they need to
do is mine.
I do not see why any person would want to pay, and then trust, another
to mine accordingly. Each person can mine and attain their level of
influence. This not only avoids the side payment, but earns the person
There is nothing inherently wrong with paying people to run nodes or
signal "readiness", but there is no reason whatsoever to consider
these ideas beneficial from a personal/economic or
security/decentralization standpoint.
If you are not running a node you are not part of the economic
consensus. If you are not mining you have no say in transaction
ordering. The "solution" is both obvious and necessary to secure Bitcoin
If a person does not want to bother then he/she clearly does not have
a strong opinion. As developers we should be focused on reducing the
complexities of mining and of validation, not finding ways for people
to avoid participating in these necessarily distributed roles.

@_date: 2017-05-12 22:36:43
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP: Block signal enforcement via tx fees 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
Despite the tedious explanation of absolute advantage, this is simply
an argument for all people to pay one person to mine, as there is
presumably always one person who will be able to mine more efficiently
than all others.
The argument fails to recognize that mining for one's self may (or may
not) result in a net loss, but donating to a miner in the hope of some
action is comparatively a total loss. One is an expense in exchange
for the intended social outcome, and the other is payment for
representative government.
And in this form of representative government that you propose, if we
assume that miners are somehow bound to honor the payments (votes),
how are the votes distributed? Is this supposed to be democratic in
the sense of one person one vote? Your argument below is clearly based
on that idea. However the result would be very different. The
wealthier would of course exert the greater influence. So the idea
fails by its own standard.
You are making a political argument wrapped in appeal to emotion. Both
are pointless in this context.

@_date: 2017-05-12 23:43:59
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP: Block signal enforcement via tx fees 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
You seem to be suggesting that in order to decentralize mining nobody
should mine. I'm having a hard time making sense out of that.
So maybe you are just saying that nobody should mine because it's a
zero sum game that one miner will always win and therefore we should
not push up the hash rate by trying to compete because the same miner
just makes more money on the hardware. Apparently it is economically
impossible for anyone else to compete in hardware as well.
I agree that there is a serious problem of mining centralization (and
economic/validation centralization). If these problems are not solved
Bitcoin will fail. It will rise again, with people a little wiser, but
the disruption will be unfortunate for many.
I don't want to see that, so I tend to not advocate for solutions that
run counter to the security model. Many people must mine, there is no
way around it. And if people want a say with respect to mining, they
should mine. As a developer I would rather work toward fixing that
problem than putting a band-aid over it that basically tells people
that the way they get their say is by donating to the big mining
personality of their choice.
No, really?
If it wasn't clear, I was relating two sets of proposals. One aims to
find ways to fund node operation and the other aims to fund miner
signaling. The former fails to understand the economics and security
model of full node operation and the latter fails to understand that
distributed mining is as essential to Bitcoin survival as distributed
I assumed that people understand how markets work. Miners compete for
fees. By eliminating a subset of potential sellers (currently by ~70%)
the buyer raises his own price. Presumably the price is raised even
further by increasing the size of the transaction. This is either a
donation to the cause or a purchase of the signal, depending on how
you want to describe it (all donations are purchases of a sort).
So there is a cost increase that could alternatively be incurred by
mining (i.e. assuming a lossy operation). If one is going to spend
money on influencing mining one might as well not do it in a way that
contributes to centralization while training people to rely on it.
Miners absolutely "control Bitcoin in some way" - that is their
purpose. They control the ordering of transactions, and with
sufficient hash power can double-spend and therefore make the network
unusable. Why would you bother to make me type this?
Absolute nonsense, a miner incurs no obligation to the "greater
economy". He is offering a service in voluntary trade. He is likely to
do what it takes to spend his coinbase, assuming he wants to. This
gives the economy strong economic control over his behavior. But
nothing whatsoever obligates him to signal soft forks (or not optimize
his operations).
Double spending is an attack, on the person who has been robbed. The
state enforcing a patent is an attack, on the person against whom it
is enforced. These are called attacks **because they are actually
theft**. You are conflating normal operation (despite disagreement
with some unmeasurable "wishes") with robbery.

@_date: 2017-05-26 01:15:56
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Emergency Deployment of SegWit as a partial 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
Hi Cameron,
Presumably the "very serious security vulnerability" posed is one of
increased centralization of hash power. Would this danger exist
without the patent risk?
wonderful upgrade for Bitcoin. It seems to me that virtually the
entire Bitcoin Ecosystem agrees with me.  Except for around 67% of the
mining hash-rate who very conspicuously refuse to signal for it?s
of the mining hash-rate holding a position that isn?t at-all
represented in the wider Bitcoin Community. My study of ASICBOOST lead
to a ?bingo? moment:  If one assumes that the 67% of the hash rate
that refuse to signal for SegWit are using ASICBOOST. The entire
picture of this political stalemate became much more understandable.
SegWit great, it partially mitigates a very serious security
and will attract criticism of self serving motivation.?
that SegWit has not been activated yet is directly because of
for the attackers who it would frustrate.
regarded as a legitimate security vulnerability.  This would suggest
that it is not contentious in the wider technical community.
is NOT contentious to regard CVE-2017-9230 as a credible security
vulnerability. Then using it as partial security fix for a security
vulnerability SHOULD NOT be contentious.
community.  Or you believe CVE-2017-9230 should not be regarded as a
credible security vulnerability. Then I would logically agree with you
that we should separate the issues so that we may gain consensus.
However, I just don?t see this as the case.
my name was mentioned...
(only) with a segwit-like commitment to the coinbase which does not
obligate miners to signal Segwit or implement Segwit, thus disarming
any suspicion that the issue is being exploited only to activate Segwit.
and will attract criticism of self serving motivation.
and to its security. Not claiming that is the intent here, but the
damage is done by the mere appearance of motive.
(3) (4) and actively exploited (5) security vulnerability.
detailed report:
is dangerous:
without negative feedback, that SegWit be used as a partial-mitigation
of CVE-2017-9230.
assumption that any block that doesn?t include a witness commit in
it's coinbase transaction was mined using covert asicboost.  Making
the use of covert asicboost far more conspicuous.
strengthened via another soft-fork that makes the inclusion of witness
commits mandatory, without negative feedback.
CVE-2017-9230 quickly vs more slowly but more conservatively is under
intense debate.  The author of this post has a strong preference to
the swiftest viable option.
Ryan Grant:
Tier Nolan:

@_date: 2017-05-27 13:07:58
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Emergency Deployment of SegWit as a partial 
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
For the sake of argument:
(1) What would the situation look like if there was no patent?
(2) Would the same essential formulation exist if there had been a
patent on bitcoin mining ASICs in general?
(3) Would an unforeseen future patented mining optimization exhibit
the same characteristics?
(4) Given that patent is a state grant of monopoly privilege, could a
state licensing regime for miners, applied in the same scope as a
patent, but absent any patent, have the same effect?

@_date: 2017-05-30 23:17:59
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Emergency Deployment of SegWit as a partial 
I didn't meant to imply that the point was academic, just to ask your
indulgence before making my point. Thanks for the detailed and
thoughtful reply.
I don't accept that the ease (absolute cost) of implementing the
ASICBOOST optimization is relevant. The cost of implementation is offset
by its returns. Given that people are presumed to be using it profitably
I consider this point settled.
The important point is that if people widely use the optimization, it
does not constitute any risk whatsoever.
I realize that the term "same essential formulation" was misleading, but
my aim was the *source* of harm (unblocked) in an ASIC patent as
compared to an ASICBOOST patent. It seems that you agree that this harm
in both cases results from the patent, not the optimization.
Nobody is suggesting that ASICs are a problem despite the significant
optimization. It is worth considering an alternate history where ASIC
mining had been patented, given that blocking it would not have been an
option. More on this below.
I agree that the optimizations differ in that there is no known way to
block the ASIC advantage, except for all people to use it. But correctly
attributing the source of harm is critical to useful threat modeling. As
the ASIC example is meant to show, it is very possible that an
unblockable patent advantage can arise in the future.
Quite clearly then there is a possibility (if not a certainty) that
Bitcoin will eventually be faced with an unblockable mining patent
Precisely. This is a proper generalization of the threats above. A
patent is a state grant of monopoly privilege. The state's agent (patent
holder) extracts licensing fees from miners. The state does this for its
own perceived benefit (social, economic or otherwise). Extracting money
in exchange for permission to use an optimization is a tax on the
This is an important point. Consider also that a subsidy has the same
effect as a tax. A disproportionate tax on competing miners amounts to a
subsidy. A disproportionate subsidy amounts to a tax on competitors.
If the state wants to put its finger on the scale it can do so in either
direction. It can compel licensing fees from miners with no need for a
patent. It can also subsidize mining via subsidized energy costs (for
example), intentionally or otherwise.
That sounds more like a central authority than a solution.
So, my point:
Mis-attributing the threat is not helpful. This is not an issue of an
unforeseen bug, security vulnerability, bad miners, or evil
patent-holders. This is one narrow example of the general, foreseen,
primary threat to Bitcoin - or any hard money.
Bitcoin's sole defense is decentralization. People parrot this idea
without considering the implication. How does decentralization work? It
works by broadly spreading the risk of state attack. But this implies
that some people are actually taking the risk.
By analogy, BitTorrent is estimated to have 250 million active users in
a month, and 200,000 have been sued in the US since 2010.
Decentralization works because it reduces risk through risk-sharing.
Bitcoin cannot generally prevent state patent/licensing/tax regimes.
Licensing is a ban that is lifted in exchange for payment. What is the
Bitcoin solution to a global ban on mining? On wallets? On exchange?
The Bitcoin defense against a patent is to ignore the patent. Berating
people for doing so seems entirely counterproductive.

@_date: 2017-11-06 12:55:29
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Introducing a POW through a soft-fork 
If a block that would be discarded under previous rules becomes accepted after a rule addition, there is no reason to not simply call the new rule a hard fork. IOW it's perfectly rational to consider a weaker block as "invalid" relative to the strong chain. As such I don't see any reason to qualify the term, it's a hard fork. But Peter's observation (the specific behavior) is ultimately what matters.

@_date: 2017-11-09 10:18:17
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Centralizing mining by force 
It is not the case in practice that there exists no incentive to disrupt the market for transaction confirmation. Statism is profitable, and a primary source of revenue is seigniorage. Given Bitcoin's threat to that privilege, its destruction presents a hefty incentive.
The security model of Bitcoin is not based on balancing power between miners (those who confirm) and merchants (those who validate). It is based on these parties defending their mutually-beneficial market from the state.
Neither technology nor incentives resolve this conflict. People must be willing to defend their mines and their economic nodes. This requires personal risk. The risk to each individual is mitigated by broad decentralization, but remains nonetheless.
Even in a highly-decentralized system, overpowering taxpayer-funded disruption of the confirmation market will require that merchants pay aggregate fees exceeding the mining subsidy expended by the taxpayer to disrupt it. Who prevails in that tug of war is unclear, but working on Bitcoin implies one believes it is possible for individuals to do so.

@_date: 2017-11-11 11:51:04
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Introducing a POW through a soft-fork 
As Peter pointed out, that is the case here.
That is not a condition of the hard fork concept.
A consensus fork wherein everything that was previously invalid remains invalid while blocks that would have previously considered valid become invalid. A hashrate majority of miners can impose the new rules. They have some deployment advantages like backward compatibility.
A consensus fork that makes previously invalid blocks valid. Hardforks require all users to upgrade.
The essential element of a hard fork is that the new rule may cause rejection of blocks that are not rejected by old rules (thereby requiring that all users adopt the new rule in order to avoid a split). The reason a hard fork is interesting is that it can create a chain split even if it is enforced by majority hash power.
That is not the case with a soft fork and it is not the case here. A split can occur. The fact that it is possible for the split to also eventually orphan the old nodes does not make it a soft fork. A soft fork requires that a hash power majority can impose the rule. However, under the proposed new rule the hash power majority (according to the new rule) cannot impose the rule on existing nodes.
Nothing about this proposal implies an attack. From the Motivation section:
Mitigate centralization pressures by introducing a POW that does not have economies of scale
Introduce an intermediary confirmation point, reducing the impact of mining power fluctuations
Presumably this preference exists because it implies the new rule would not cause a chain split, making it more acceptable to a risk-averse economy. This is precisely why it should be described correctly.
In reality you have no way to know if/when people would adopt this rule. What matters in the proposal is that people who do adopt it are well aware of its ability to split them from the existing economy.

@_date: 2017-11-30 04:03:30
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] BIP Idea: Marginal Pricing 
Bitcoin is neutral on how miners are paid. The benefit of on-chain fee
payment is that a fee can be paid with no communication between the
miner and the merchant, preserving anonymity. It also serves as a
convenience that anonymous fees are published, as it provides a basis
for anonymous fee estimation. There is no centralization pressure that
arises from side fees.

@_date: 2018-08-05 22:29:31
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Capping the size of locators [trivial protocol 
Libbitcoin has implemented a 11 + log2(height) limit since version3 for
this reason. This message can be very costly if not constrained.
The presumed protocol inherently limits valid locator size for a given
recipient. IMO it's worth considering instead describing the expected
semantics of the message and thereby its *inherent* limits. Doing so
gives the recipient an upper bound on valid locator size, eliminating
the need to introduce an arbitrary limit.
I have commonly seen locators with 100 elements, I believe from
BitcoinJ. I recall posting a query on the issue to their IRC but got no
response. So it would seem that a quick survey and a limit of 64 would
not have prevented the issue of concern.
But in any case, I agree that implementations should enforce a limit.

@_date: 2018-08-29 07:40:16
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Building a Bitcoin API and query system. 
The API implementation is not what is centralizing, nor is full indexation non-scalable. The centralization is in not running the API from a node under your own control. This is of course implied by the comment, ?without the need for syncing?. In other words it is the deployment cost of the node that is centralizing.
Yet if people relied only on bitcoind and never centralized services there would be *no* block explorers (and no secure light wallets), because it does not provide remote query and does not fully index.
Block explorers and light wallets are pretty useful, so presumably some API must provide these features (ideally with reduced deployment cost). That will either be centralized or decentralized services. As such it seems wise to encourage the latter, as opposed to questioning whether there is any valid block explorer use case.

@_date: 2018-08-29 11:45:56
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Building a Bitcoin API and query system. 
You have created a straw man.
And light clients working against the P2P network (anonymous nodes) implies they are not fully validating, so you are contradicting yourself.

@_date: 2018-02-14 15:57:10
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Amend the BIP 123 process to include buried 
Sufficient for what, specifically?
Remain valid in the case where the depth assumption is "sufficient" to
ensure that a chain split is not possible?
If this was true (which it is not), it would imply that there is no
reason to validate any block deeper than the most recent 25,000.
Presumably this means that people may continuously rely on some
authority (like Bitcoin Core?) to determine the checkpoint for tip-25,000.
They can only avoid this requirement based on the assumption that the
hard fork cannot result in a chain split. This is not the case.
In other words a "buried deployment" is a hard fork that is not likely
to cause a chain split. This is a subjective subcategory of hard fork,
not an independent category - unless maybe you can show that there is
the 25,000 blocks number is an objective threshold.
This is untrue. The "security assumptions" of Bitcoin do not preclude
deep reorganizations.

@_date: 2018-02-18 10:39:09
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Increased blockspace enabled by SegWit limited to 
As a soft fork, all preceding rules remain in effect. No rule has been ?replaced?. Blocks must validate against pre-segwit rules or are invalid. Additional rules are applied that further restrict validity, and consider additional (witness) data in the context of the block.

@_date: 2018-02-18 11:14:22
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Increased blockspace enabled by SegWit limited to 
If the new rule is more restrictive the original limit remains.

@_date: 2018-02-21 09:27:53
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Amend the BIP 123 process to include buried 
You seem to have missed the point. Either the "buried deployment" is a
consensus rule, and requires a BIP, or it is not a consensus rule, and
does not warrant a BIP.
You are arguing that it is not a consensus rule, yet requires a BIP. You
also strongly imply that it is a consensus rule ("consensus is important").
If it is a consensus rule it is either a hard fork (valid tx set
expansion) or a soft fork (valid tx set contraction). You are attempting
to create an independent category that violates this clear engineering
definition. The category you desire is actually a subcategory of hard
fork (employing an arbitrary threshold for likelihood of causing a chain
The arbitrary threshold. It seems it could be anything. Such a
definition has no clear *engineering* usefulness.
You are arguing a point that I did not make. The issue is that you argue
a "buried deployment" hard fork cannot create a chain split. This itself
implies that the chain is "frozen" at the depth below which the chain
cannot be split. In other words, by accepting your logic, we must
conclude there is no reason whatsoever to validate the chain prior to
that depth. This would lead to the conclusion that check-pointing the
chain to that depth is always sufficient validation.
Not sure why you are making this obvious but seemingly-irrelevant point.
No, it cannot. Removal of an activated soft fork (valid tx set
contraction) is a hard fork (valid tx set expansion), and a new
activation rule for an active soft fork creates a path to that removal.
Given this error you may want to reconsider your proposal.

@_date: 2018-01-18 13:22:47
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Proposal to reduce mining power bill 
The energy cost of mining cannot be reduced, nor is it rational to consider it ?too high?.

@_date: 2018-01-22 14:43:22
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Blockchain Voluntary Fork (Split) Proposal 
All other things being equal, the money with the larger network is more useful due to the cost of exchange between them, which can only be eliminated by one absorbing the network of the other. According the Thiers? law (i.e. in the absence of currency controls), the more useful money will get used. It is not the case that they will just become the same value.
However, all other things are not equal. As a Bitcoin becomes more useful its use rises. Rising use implies rising fees, which in turn reduces usefulness (stability property). While the better money prices out certain scenarios, they remain viable in the lesser money. But eventually this will happen there as well, and the better money will absorb the lesser.
The perpetual creation of new monies with exchange between them and the best money (largest network) could certainly exist, but layering proposes an approach that doesn?t require all merchants to perpetually be accepting different monies. It has a similar security trade-off (lower security for transacting off of the better money), which is the source of decreased transaction cost. But without the exchange and overhead cost the layered money can be better than multiple monies.
Also, all splits are voluntary.

@_date: 2018-01-22 14:52:23
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Blockchain Voluntary Fork (Split) Proposal 
This is true but confuses people because obviously miners must commit capital to mining before any block space can exist to have value. The reason for the misunderstanding is that miners don?t simply respond, they anticipate. All production, and therefore capital investment, is the result of anticipation of future returns, not an attempt to chase past returns.
The first miner anticipated that the then-worthless ?tokens? he was mining would have a future value. Turns out he was right. Others have been wrong, which is the nature of betting on future prices. But if nobody does it, there are no products.

@_date: 2018-01-22 20:57:46
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Blockchain Voluntary Fork (Split) Proposal 
This is irrelevant as miners don't determine the utility of a money,
they anticipate it. However you don't have to accept this to recognize
the error of the argument below...
Mining difficulty controls the block period, not miner return on capital.
This is the consequence of the presumed common regulation of the block
period. It matters not how useful are either of the monies.
You are conflating difficulty with profitability. These are not the same
thing. A chain can be more difficult and less profitable and the
reverse. Profitability is controlled by competition, as it is in all
markets. Competition is controlled by the cost of capital, which is in
turn controlled by time preference. Mining seeks the same level of
profitability for any coin, regardless of how difficultly. This applies
to all industry - difficulty does not regulate profit, it's just a cost.
Actually the opposite is the case. Even if we could start at a point of
perfect equality, the smallest change in the number of merchants or
human perception of the money (as examples), would lead one to be
slightly better. All things being equal that alone would lead to
elimination of one money in favor of the other.
One money is inherently better than two, as there is an exchange cost
between them. In the absence of exchange controls the better money gets
used, and in this case that can simply be the result of a slightly
larger network (or perception of it).

@_date: 2018-01-27 15:48:10
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Proposal: rewarding fees to next block miner 
The OP premise is flawed:
as is the idea that side fees are incentive incompatible:

@_date: 2018-01-28 16:46:51
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Proposal: rewarding fees to next block miner 
Miners accept less than the optimal (i.e. highest net fee) set of
transactions all the time. The reason is that it takes too much time to
compute the optimal set. All other things being equal, the miner who is
more efficient at computing a set is more profitable.
Intentionally not accepting the most optimal set possible is a cost, not
a source of increased returns. Miners can raise the historical fee level
by paying this real cost, just as can any other person (by submitting a
competitive-fee transaction). They cannot "recover" this cost. They have
no place of advantage in terms of competing for block space.
Finally, historical prices do not determine future prices. Current
competition for block space determines future prices.

@_date: 2018-01-28 20:49:10
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Proposal: rewarding fees to next block miner 
Your statements contradict each other.
This is not a question of whether it is a "huge" cost, but whether there
is an problem of incentive compatibility, which there is not. Miners
incur the opportunity cost of the space that they mine that does not
include the most optimal fees, which is equal in value to those forgone
If miners exclude available higher-fee transactions, or mine empty
space, or mine their own "recovery" transactions, they are merely
purchasing block space at market rates, just like everyone else.
The only difference is that they are getting nothing in return, while
everyone else is presumably getting a useful monetary transfer. In other
words, they are losing value to do this. Therefore the incentive is to
not do so. But again, the option to do so is perfectly incentive compatible.
I'm not sure who cooked up this myth about miners gaining advantage over
those who buy block space by mining empty space, rejecting higher-fee
transactions, and/or mining "recovery" transactions, but the idea is
complete nonsense.

@_date: 2018-01-29 15:21:48
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Proposal: rewarding fees to next block miner 
It's not clear to me what would be the reason for retaliation, given
there is no more harm in a miner purchasing a block than Coinbase
submitting enough transactions to fill a block. Both pay the market rate
for the space. But since the former results in a loss, a financial
consequence ("retaliation") is inherent.
If a farmer destroys his/her own apple crop he loses money. It may be
very conspicuous, but nobody would retaliate as only the farmer's own
property was affected. Customers would just get their apples elsewhere.
Block space created by a miner is property that belongs to the miner, it
can be sold or not sold.

@_date: 2018-01-29 19:52:21
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Proposal: rewarding fees to next block miner 
The miner who creates a block owns the block, he/she has selected the
transactions and directs the reward. The case for this could hardly be
The fact that there is subsidy implies that *part* of the cost of
creating the block is offset. But by not accepting the highest fee
transactions the miner is still accepting a net loss by purchasing the
space for himself. The hash power generated by the miner to create the
block contributes to confirmation security to a greater degree than for
which he has been rewarded.
You seem to be implying that there is dishonesty involved in purchasing
block space, or that it is somehow possible to earn reward while not
complying with the protocol. There is no honest or dishonest compliance
with a protocol, there is just compliance or non-compliance.
Everyone can do whatever they want with their own machines, and I
haven't argued otherwise. As far as "rights" go, Bitcoin doesn't care.
I'm not one who has regularly raised hard fork fears while at the same
time threatening them. My objective is to dispel flawed reasoning, not
to negotiate for the rights of some group over another.
Some economic theories that get thrown around are baffling, this idea of
"retaliation" among them. Presumably the objective is to reduce
transaction confirmation costs. The theory would be that mining empty
blocks or mining own transactions is "unfairly" increasing revenue to
miners. Despite the incorrectness of this theory, the proposed cure
attempts to reduce returns to miners. However the consequence of
reducing returns to miners is simply a reduction of hash power (as the
least efficient miners become insolvent). Miners will continue to earn
the same rate of return on their capital as always. And the cost of
transactions will remain the same...
The presumed mechanism of the proposed retaliation is also baffling. A
miner (or anyone) can always create transactions, pay fees, and send
them out to the network. Given that we presume transactions without
identity, it is not possible (or desirable) to detect the source of
transactions. Maybe the assumption is that sending such transactions out
to the network would not satisfy the miner's objective, since the fees
cannot be "recovered". But this is the original flaw. Fees spent to
one's self cannot be recovered either! So if a miner wants to blow money
by filling up blocks with market fee transactions, they will be able to
do so at the same cost no matter how one tries to "retaliate".

@_date: 2018-03-08 23:50:02
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] version.relay behavior change 
version.relay=false flag (BIP37). Could someone familiar with the change
please explain the rational?

@_date: 2018-03-15 10:17:22
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] version.relay behavior change 
Thanks for the reply Andrew. I?ve reviewed the relevant Core sources and I do not see any problem. We have also synced against a Core node locally and not seen the problem.
The reason I suspected it was Core is that it is very common and all of the User Agents are consistent (with an occasional exception for forked nodes). So there?s no easy way to determine what sort of nodes we are seeing. We tend to cycle through many more connections during sync than a Core node, so may just be seeing it more frequently, but I assume Core would log this behavior as well. Even so, seeing that wouldn?t help much. I?m as certain as I can be at this point that we are setting the flag and version correctly (and that we do not set bip37 filters).
This behavior started infrequently with 0.14.0 peers and has become more common over time. Just wondering at this point what fork would report as Core and be that common? We used to drop peers that did this (for protocol noncompliance), and I?m considering reinstating that behavior.

@_date: 2018-03-18 19:59:28
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] feature: Enhance privacy by change obfuscation 
Without commenting on the merits of this proposal, I?d just like to correct this common misperception. There is no necessary additional cost to the network from the count of unspent outputs. This perception arises from an implementation detail of particular node software. There is no requirement for redundant indexing of unspent outputs.

@_date: 2018-09-04 10:37:30
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Overhauled BIP151 
Without commenting on the other merits of either proposal, the addition of the service flag resolves bip151?s previously-discussed lack of backward compatibility.

@_date: 2018-09-16 16:20:05
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Selfish Mining Prevention 
Hash rate cannot get ?more uneconomical?. Mining will always seek a return equal to the cost of capital, as does all production, and the energy expended will always be fundamentally a function of the fee level and energy price. Fee level is determined by variable demand for a fixed supply of confirmation.
When you say greed you are simply referring to economically-rational behavior. It canny be eliminated, nor would that be a benefit.
WRT energy consumption, there is nothing that can be done to reduce it except for people to stop using Bitcoin or for energy to get more expensive.

@_date: 2018-09-17 08:40:30
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Selfish Mining Prevention 
Proof of memory (space) is just proof of work with extra steps. It does not reduce energy consumption.
Merge mining is non-dedicated cost, so also does not improve energy efficiency. The irreducible *cost* is what matters.

@_date: 2018-09-17 12:36:15
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Selfish Mining Prevention 
hashrate) will want to join since their share of the hashrate is too
small to make a profit.
The share (hash power) of a miner is proportional to capital investment, not the newness of that investment. The efficiency of a new mine (inclusive of pooling pressures) can certainly be sufficient to outperform other miners, resulting in the departure of the latter, thus not preventing the entry of the former.
The point you should be making here is that energy consumption is regulated by the cost of capital (in addition to reward value and the cost of energy).
Note that higher efficiency mining does not reduce energy consumption, nor does variation in the necessary cost of mining hardware. The total energy cost is the control, not the hash rate. This is of course why proof-of-memory (space) is pointless. It simply shifts most of the energy cost to hardware manufacture, shipment, etc.

@_date: 2019-08-16 13:44:47
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Burying CSV and segwit soft fork activations 
Thanks for adding this to the record.
And for the record I?ll reiterate here, as I did with BIP90, that this is a hard fork.

@_date: 2019-07-01 11:52:57
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
It?s an exceedingly poor example. First, value is subjective. It matters not what other people may consider, only those who act. Given that people trade them (ICO tokens), they have value to those people. Second, the scenario would not function given that the value, as with money, is based on the ability to trade perpetually.
I said that I would make no further comment given the belief that no new ideas were surfacing. However, after giving it some more thought on my own, I believe I have found the one case in which a person could value such encumbered coins.
In the case of tracking an asset that becomes worthless at a specific time, one could value a record of ownership, and the ability to trade ownership of the asset during the period. Consider colored coin type tracking of a theater ticket for a specific show, where the ticket is worthless by the end of the show.
Now consider the value attributable to renting coin (e.g. to the tick issuer) in order to track the ticket. First, there is no net value in renting coin to pay confirmation (mining) fees on transfers. The cost of a fee is driven by competition and remains the same whether the coin used for payment is encumbered or not. In other words, even with value in tracking there is no *cost advantage* to renting of such coins for use as money.
But tracking an asset in this manner has required not only a fee for each trade, but also the burning of coin. By allowing the lender to recover the coin when the asset expires, this part of the cost of on-chain tracking can be time-shared (rented), and without depreciation of the coin.
In this case the lender is achieving both a time-locked hoard/speculation and a pre-paid rental return. The return to the lender would be the rental price minus the opportunity cost of not investing (ie, in production) this coin otherwise during that period. This is of course based on the economic principle that both hoarding and speculation are expected to produce no predictable return. As such the cost of the rental would be driven (by competition) toward the cost of capital (e.g. annualized 10% of the coin price) for the same period. Depending on the term, rental will be cheaper than the outright cost of burning the same minimum amount of coin (i.e. dust+1, assuming policy compliance) as required for tracking. As soon as the rental cost exceeds the minimum tracking burn, rental becomes more expensive than just purchasing the coin. So, for example, at 10% market return on capital (rental cost), purchasing the coin is cheaper than rental at any tracking term beyond 7.2 years.
As discussed previously, there can be no monetary value of such encumbered coins. And as shown above, the non-monetary (tracking) scenario is limited to fixed-term tracking. This use of Bitcoin would of course reduce the average cost of non-monetary blockchain storage. I?m not sure that is a use people want to facilitate with a protocol change, but that?s for the community to decide.

@_date: 2019-07-03 17:30:55
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
In other words I discovered a potentially-valid use case for you. The concern I expressed was that you had not presented one.
My goal is never to discourage, but understanding of provable behavior and utility. Our space is replete with unsupportable conjecture and hyperbole. There are no sides, just discovery of truth.
Actually you have a single potentially-valid use case, the one I have presented. The others I have shown to be invalid (apart from scamming) and no additional information to demonstrate errors in my conclusions have been offered.
I?ve noticed that in subsequent posts you continue to imply that there is economic value in such tracking of any asset, and of course here imply the validity of your other use case, monetary lending. This, as I have shown, is not the case. Tracking of an asset of value beyond the net compound interest cost of dust is more cheaply accomplished by burning than by renting, and as I have shown, it is not accurate to claim that the encumbered coin can be used as money (or to track any asset of perpetual value). When the coin expires the money/asset holder becomes a bag holder, invalidating any initial value apart from scamming.
In the valid use case that I have demonstrated (tracking of expiring assets), the marketable value of the rented coin is not the market price of that coin, but the price paid for it. So for example, 1 coin rented at 10% APR for one year is worth .1 coin. And when a renter resells this tracking coin it is worth the fraction of this amount for the time remaining. The coin itself (i.e. its face value) cannot be used by the renter to purchase anything.
As such this is truly not a loan in the financial or economic sense. Given an actual loan the borrower can use the full value of the amount borrowed to purchase goods that can be used in production. Subsequent generation of products and thereby revenue is the source of yield on a loan (economically equivalent to dividend on an equity contract). This allows the borrower to repay the loan with interest. Without *any* usable capital over the term of the rental, there is no investment possible and the time value of the rented coin cannot be realized by the renter.
So the one potentially-valid scenario, a fixed-term tracking rental, is entirely an *expense*, not a loan. A financial loan incurs an interest expense, but also implies the value of the amount loaned is fully usable (i.e., consumed or traded) during the term (the reason to pay interest). That is money over time, yielding the time value of money. In this case the value of the loan at any time to the renter is simply the amortized interest remaining. This implies that no income can be generated from the rental ?principle? by the renter. A price is paid for the rental and that value of the rental is fully exhausted by the end of the term, with no other benefit than the tracking that was purchased.
The person renting the fixed-term tracking coin (i.e. ?owner?) can earn income by selling dust+1 outputs at the cost of capital, limited to a maximum term dictated by the cost of capital and the dust limit (as shown previously). Economically speaking, all business returns gravitate toward the cost of capital, including lending, and this is no different. But it cannot be said that the owner is a financial lender. The owner is simply selling non-depreciating (from his perspective) fixed-term tracking space.
The owner can of course trade rights to the controlling output. The rental contract has been prepaid (by your design, in order to shift counterparty risk). As such the traded contract has no yield and therefore contracting for its sale is a currency future, not an interest rate future as would be implied by a debt market. Yet FX speculation already exists for Bitcoin, requiring no covenant or rental market. This would seem to undermine any secondary market for these more complex and limited currency futures.
Finally, valuation is based on the assumption of a non-zero dust+1, which BTC enforces as a 0 satoshi dust limit (i.e. 0 sats is considered dust and is not valid). Anything above this is policy-enforced only. As such a miner can undercut the cost of tracking an individual asset down to 1 sat. Given that there is no financial incentive to a higher dust limit for a miner, but a positive financial incentive to undercut the rental price for the same return, this is economically rational and therefore must be assumed.
One might argue that a lower dust policy would hurt BTC and therefore its miners collectively, creating an offsetting negative financial pressure. However given that the apparent cost is socialized in relation to individual benefit, this is not an economically rational conclusion. Furthermore, as the tracking outputs become unspendable due to the nature of the covenant, there is no actual dust accumulation (implementation dependent).
As such the return on any fixed-term tracking output, given a 10% APR, would become as low as .1 sat per year, assuming such a market could continue to function at that level. But it is also the case that a 1 sat output can be burned directly by the tracker and used indefinitely. This would presumably undermine any robust market for fixed-term tracking rental.

@_date: 2019-07-04 11:43:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
Hi ZmnSCPxj,
Generalizing a bit this appears to be the same with one exception. The amount of encumbered coin is relevant to an external observer. Of course the effective dust limit is the maximum necessary encumbrance otherwise.
In the case of simple tracking, the market value of the coin is not relevant, all that is required is a valid output. Hence the devolution to 1 sat tracking. In your scenario the objective is to establish a meaningful cost for the output.
A community of people using this as a sort of hashcash spam protection can raise the amount of encumbered coin (i.e. advertising threshold price) required in that context. The cost of this encumberance includes not only at least one tx fee but market cost of the coin rental.
At a 1 year advertisement term, 10% APR capital cost, and threshold of 1 encumbered coin, the same is achieved by burning .1 coin. In other words the renter (advertiser) has actually paid to the coin owner .1 coin to rent 1 coin for one year.
As with Bitcoin mining, it is the consumed cost that matters in this scenario, (i.e., not the hash rate, or in this case the encumbered coin face value). Why would the advertiser not simply be required to burn .1 coin for the same privilege, just as miners burn energy? Why would it not make more sense to spend that coin in support of the secondary network (e.g. paying for confirmation security), just as with the burning of energy in Bitcoin mining?

@_date: 2019-07-04 13:31:03
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
Burning is not an economic concern and cannot be prevented. As there are fewer coins, all things being equal, the cost of each increases, and thus fewer must be burned to achieve the same cost. So assuming sufficient divisibility (an existing Bitcoin assumption) it is sustainable. But as I demonstrated, it?s not necessary.
This is essentially what I suggested, though presumably you mean Bitcoin fees not secondary network.
Another reason why simply spending or burning them is preferential.
This implies additional complexity with no benefit to anyone required by the scenario, which was my implication.
The terms lend/borrow are misleading here, as I have previously shown. The coin is neither spendable nor consumable. This is why I have used the terms owner/renter. Yes, the renter can sell the remaining rental expense to another.
Yes, the potential incremental value over the other scenarios is transferability of the output, but this accrues to both to the advertiser/renter and the owner (trade always benefits both parties trading). This transfer incurs a fee if on chain, and in the tracking scenario may easily overwhelm the effective benefit (fraction of the rental, no higher than dust, not yet expired), making it economically non-transferrable.
In the advertising scenario this transfer can be achieved independent of Bitcoin, by simply changing the advertisement (e.g. publish a provably-superseding ad for the same output), avoiding the material on-chain fee. Recall that the value of the coin cannot be captured by the advertiser through transfer, just the tracking cost.

@_date: 2019-07-04 14:31:12
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
I meant to point out that a voluntarily trade cannot represent ?damage? to the person making it. The person chooses the action because it is preferred over alternatives (i.e. it is beneficial). Such choices are the only objective expression of preference, a fundamental principle of praxeology.

@_date: 2019-07-05 12:27:59
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
Good morning ZmnSCPxj,
This is a materially different concept than proposed by Tamas.
?...he gives up his control of the coins until maturity, he can not use them elsewhere until then.?
You appear to be proposing a design whereby either the owner or the renter (not entirely clear to me which) can spend the ?locked up? coin at any time (no maturity constraint), by dropping the covenant.
If the renter can do this he can simply steal the coin from the owner.
If the owner can do this there is no value to the renter (or as a proof of cost), as the owner retains full control of the coin.
If you mean that the age of the encumbrance is the proof of cost, this requires no covenant. I don?t believe this is what you intended, just covering all bases.
And as I have shown above, nor can a ?locked-up? coin be unlocked to do the same.
Well that?s the point, money spent is no longer under one?s control. The provable cost of this surrender was your stated objective. Renting at a fractional cost of coin face value is a non-recoverable spend by the renter to the owner. Burning or spending the same amount in a way that is provably not to one?s self achieves the exact same result.
The advertiser can presumably trade control of as space on the ad network. It?s not clear to me why this is not simply an independent chain of limited ad space ownership. It might as well be namecoin.
If an output is provably unspendable (burned) it is not a UTXO.
It is worth noting that not all full node implementations require a store of UTXOs, this is an implementation detail. For example, libbitcoin uses a flag on each output to indicate its spentness on the strong branch. As such the store size is linear by height.
I don?t believe you have shown this.

@_date: 2019-07-05 16:20:17
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
I forgot to add that it is certainly possible to burn using a nonstandard script, such as the non-zero OP_RETURN you suggested, without a consensus change. This can be, as you say, made more practical with a policy change. But such changes are up to individual node operators as they require no deviation from consensus. Yet ultimately this is a miner preference, and anyone can mine. Finally, as I pointed out, burning is not necessary. Simply spending the coin as a fee is sufficient.

@_date: 2019-07-05 16:44:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
Not any UTXO then, one that with sufficient time-locked coin.
So how does one get the owner to sign off on the multisig release? Presumably the renter cares because he wants to recover the remaining value of rental. So he not only needs to contact the owner, he also needs to negotiate with the owner for a pro-rated refund. In other words, he must sell the remaining portion of the rental return - essentially how I described it previously. He might as well just sell the marketable ad space that he controls through the remainder of the term (the same value).
Certainly the owner could given him a partially-signed transaction, returning the coin, allowing the renter to exit at any time, but the renter has no reason to sign it without a refund, which must be pro-rated in some way, implying later contact/negotiation with the owner.
But it?s worth noting that early recovery of the UTXO entirely eliminates the value of the time lock cost to the ad market. The most obvious example is one encumbering the coin to himself, then releasing it with his own two signatures whenever he wants. In other words, there is no encumbrance at all, just a bunch of pointless obscurantion.
I think I understand the implications of it clearly. Feel free to point out what I?m missing. But I don?t spend any time in implementation details until I can justify those implications.
A multisig doesn?t fix the central economic issue, which it is not clear that you understand. If so it hasn?t been demonstrated. A cost created by making coin unusable for a term is not an actual cost if that lock can be released at any time before maturity of that term. Furthermore, cost is most easily demonstrated by simply spending. By analogy, proof of work is simply proof of a spend (incurred cost). Imagine if one demonstrated that cost by ?locking up? coin for a year, and then after the block was accepted, he unlocked that coin after just one day.

@_date: 2019-07-05 18:28:03
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
I am responding to the cryptoeconomic principles, not the implementation details. Based on your comments here I am not misrepresenting those principles.
For example, I have shown that the multisig unlock implementation reduces the presumably-encumbered UTXO to simply a UTXO. You have not disputed that. In fact below you have accepted it (more below).
The term ?locked? here is misused. A unspent output that can be spent at any time is just an unspent output. The fact that you can ?unencumber? your own coins should make this exceedingly obvious:
As I have shown, there is no *actual* encumbrance.
Exactly, which implies *any* UTXO is sufficient. All that the ad network requires is proof of ownership of any UTXO.
Unspentness is not actually a necessary cost (expense). All coin is always represented as UTXOs. If one has a hoard of coin there is no necessary incremental cost of identifying those coins to ?back? ads.This isn?t altered by the proposed design.
The only cost would be to have a hoard that one does not otherwise desire, representing an opportunity cost. Yet, as I have also pointed out, the amount of that opportunity cost can simply be spent (or burned) by the advertiser, representing the same cost. So covering the case where one cannot raise the capital to ?back? one?s ad does not require rental, as the cost of the otherwise rental can just be spent outright.
Presumably it would be ideal to transfer the value of those spends to people who provably present the ads for effective viewing (i.e., the AdWords business model). It is of course this market-driven cost of presenting an ad that provides the spam protection/definition for AdWords.

@_date: 2019-07-05 18:46:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
It?s worth pointing out at this point that this implies Google, etc. would achieve the same result by simply accepting Bitcoin for ad placement. In your model the advertiser is paying only for access to people who wish to avoid spam, not for targeted and actual placement. In other words your ad system would be directly competing with others that provide material additional value for the advertiser beyond anti-spam. If nothing else this implies the return on coin ?lock-up? would be exceeded by its opportunity cost.

@_date: 2019-07-06 15:21:59
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
My use of ?encumbrance? in this thread has been consistently a reference to a covenant. When the covenant can be released at any time it serves no purpose whatsoever, being an encumbrance in name only.
I gave a detailed explanation of opportunity cost, and gave you a scenario where that opportunity cost could actually be used - to purchase a tracking output (i.e., a fixed term asset tracked for that term). And I have discussed at length the use of opportunity cost in the hash-cash-like anti-spam ad scenario.
So it?s not clear to me why you continue to imply that the nature of either covenants or opportunity cost is the point at issue, and by implying I don?t understand them.
**The central issue in your proposal is that constrained coins can neither be used as borrowed money nor the tracking of perpetual assets.** This conclusion is not based on a failure to understand the nature of covenants or the concept of opportunity cost. It is the necessary consequence of attempting to trade something today that will provably disappear tomorrow. The sole possible value of such an instrument is to scam the eventual bag-holders.
A secondary issue, in the valid fixed-term asset tracking scenario, is that the cost of tracking is dust (and at least one transfer fee). The cost of such tracking is a function only of the market price of a satoshi. The financial value of renting one dust output is also limited in time by economic  interest (i.e., at 10% it is cheaper to buy than rent if the fixed term exceeds 7.2 years). So while valid, is not likely to be demanded until one satoshi becomes worth the overhead of renting it.
The opportunity of interest represents opportunity cost when forgone. This can be used to show proof-of-cost (ad scenario), and that level can float as a price on the anti-spam market. This is a perfectly valid scenario, as I have said.
The issue with that specific proposal is that it uses covenants in an irrational manner. The ability to release the covenant at any time eliminates the cost it would otherwise represent. One could either simply burn or spend coin outright, or use an actual encumbrance (as you propose) to ?burn? (provably destroy) the opportunity, but a non-encumbrance adds nothing except complexity.
Not significant, which is arbitrary, but sufficient - a result of supply and demand. Clearly my intent here is that no covenant on the UTXO is required in the scenario. As the preceding discussions conclude, without disagreement, all that is required is that the (sufficient) output remains unspent, not that it be encumbered.

@_date: 2019-07-06 15:37:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
No, it would not. I have seen no proposal requiring identity in the two roles, which is necessary to show that two distinct individuals operate in the roles. Furthermore, even identity would be insufficient, as two individuals can clearly collude in these roles.
Agree, and it is the unremovable time constraint that ensures the opportunity cost. This is why in your proposal it is of no consequence that both roles can be the same person.
Loss is perpetual, so this implies Bitcoin is unsustainable.
No, you do not. This is not the point at issue. See my previous response.
No, it isn?t. Ownership must be perpetually (actually) transferable, not just known. The use of a covenant breaks this transferability, see previous posts.
For the same reason this cannot work for money, it cannot work for any perpetual asset. See previous posts.
Only if the asset expires at or before the covenant maturity.
Of course.
Only 1 satoshi is required for tracking. It is only the scarcity of a satoshi that creates this scarcity, not the covenant on it. The covenant represents only the destruction of opportunity of the value represented by the 1 satoshi, not a new system of scarcity.
Yes, opportunity cost.
But of no value to anyone as money.

@_date: 2019-07-06 18:30:16
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
I have published a summary here:
Barring any new consequential inputs I?ll refrain from further comment.

@_date: 2019-07-17 05:02:29
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Secure Proof Of Stake implementation on Bitcoin 
Bad precedent set by Bitcoin, just like retroactively hardcoding soft fork activation checkpoints.
That?s nonsense, one is a feature (systemic trust), the other is a bug (code accident). But there is a way to minimize actual forks - try not to change the consensus rules in the code you ship.
Consensus rules are the social consensus. If you have an objective way to do this, write the rule.
Censorship can steal everybody?s money.
Political money.
True, but this is at least limited proportionally.
The ability to introduce new power to the chain is the only way to evict a censor. In PoS a well capitalized individual or state can buy total control over the system forever at no ongoing cost. PoW allows any number of individuals to pay higher fees on censored txs and evict the censor, who must then maintain the cost of subsidizing censorship.
The state doesn?t care because there is no material impact from it? It hasn?t started attacking Bitcoin yet either.
Just another nail in the coffin.

@_date: 2019-07-18 22:10:30
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Secure Proof Of Stake implementation on Bitcoin 
But also long term economic power, since leaving implies a lower proportional hash power, until another comparably-sized pool exists, but this is not the case when there is a majority hash power pool, which is economically inevitable until the majority miner starts censoring.
This is why PoW is necessary, and why fee-based confirmation is necessary. It?s the only economically-rational way that the censor can be overpowered. But keep in mind the only net cost to the censor is the *premium* on censored transactions.
While this proposal may introduce engineering improvements, it does not change any of the economic forces at work and therefore does not mitigate this issue. The pool controls the payout, and therefore retains power over tx selection regardless of who selects and grinds on them.
Yes, and of course stealing the value in the chain is not the only way to profit from the destruction of its usefulness. PoS offers no defense against the primary threat to permissionless money.
Capital cost isn?t the source of this defense, it?s the ability to introduce as much power as necessary to evict the censor, paid for by the rising premium on censored txs. Without this the majority miner can mine indefinitely and be the most profitable. This is of no consequence to confirmation until censorship begins.
In PoS, once a miner achieves necessary stake (also profitably) it can censor indefinitely. It?s a big difference.
Yes, and of course the same scenario as described above can also occur with PoW. Gather up the victims, invest in mining a stronger chain, get the profit from the mining investment, and get your money back.
It?s sort of like Bitcoin?s nonlinear hash power to hash rate ratio, on steroids. The nonlinearity hasn?t been shown to be avoidable, but certainly something to minimize.
Let?s all be nice. But WRT energy waste... see last paragraph for a consideration of waste in relation to any other monetary options.

@_date: 2019-06-28 10:25:22
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
Hi Tamas,
There are a number of economic assumptions contained herein. While I understand you would like to focus on implementation, the worst bugs are requirements bugs. IMO these should be addressed first. I?ve addressed some possible issues inline.
I?m not aware of the basis of this statement. While people use the term ?risk free rate of return? there has never actually been such a thing. It?s not clear to me how a unicorn has been the foundation of ?financial engineering?, but I?m not also clear and what is intended by ?engineering? in this sense. Generally engineering is the implementation of higher level concepts. It is those concepts that constitute requirements here.
At a minimum, interest cannot be guaranteed by this proposal, which implies that at best it guarantees, setting aside changes in purchasing power, a return of principle minus economic interest on that principle (ie opportunity cost). Given that purchasing power changes over time, risk increases with the term of the loan. As such this is not riskless - both volatility and opportunity cost remain as risks.
This is not a systemic problem, this is the very nature of lending. Fractional reserve is simply a state banking term used to describe the fact that people invest (lend) a fraction of their savings and hoard the rest. It matters not that banks or individuals do this, credit expansion is inherent in economy. Without it there is no investment and therefore no production whatsoever.
You seem to be conflating state banking with the effects of investing. Taxpayer support for bank investment creates both a moral hazard (and the resulting misallocation of capital to state-favored projects, creating the famed economic ?business cycle?) and is a manifestation of persistent monetary inflation (ie seigniorage is a source taxation. Investment implies credit expansion, and the level of this expansion is controlled by time preference alone.
Interest cannot be paid in advance. This implies nothing more than a smaller amount of principle.
At a minimum, money that predictably depreciates (to zero in this case) must be discounted accordingly. How much is money worth today that is worth zero tomorrow? This can be observed with both inflation and demurrage money. This also implies that each encumbered coin is not fungible with any other of a distinct discount schedule.
What is the economic consequence of lending discounted money? Lower interest rates. How much lower? The rate of depreciation. This can also be observed with inflation and demurrage, but observation isn?t required. This is a necessary outcome.
So when one lends 1 demurrage coin for a term one cannot earn interest on 1 coin, one is earning interest on a fraction of a coin. That fraction creates credit expansion and reduces return in direct proportion to the risk that has been offset. In other words, the risk cost has been converted to opportunity cost. The discounted fraction earns no interest.
So credit expansion and risk remain, in the same proportions as without such a system. However lack of fungibility introduces an additional overhead cost.

@_date: 2019-06-29 14:21:20
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
As I implied, I am well aware of the concept of risk free rate of return, which is a hypothetical.
Which implies you have created an actual instance of this heretofore purely hypothetical concept.
Why would Alice pay for this at all?
What loan? Alice has paid Bob for something of no possible utility to her, or anyone else.
Bitcoin is a money, not consumable in any way. Its utility arises strictly from the possibility of eventually being traded for something else. The only reason to accept it in trade is that expectation. Removing that possibility, even transitively and over time, removes all utility immediately. In my previous comments I described a necessary discount to NPV, but it?s safe to say that must be 100%.
Value is of course subjective, and is determined by individual preferences. Yet what is the value one might place on something of no use? Economically speaking it must be zero, since value is a subjective evaluation of utility (i.e. service to a person).
Consider the case of the 1000 and 500 rupee demonetization. Long lines of people formed at banks to convert to notes to others of equivalent denomination.
Of course, upon announcement of the demonetization, existing 1000/500 rupee notes were discounted for the cost/risk of accomplishing this conversion (several people are reported to have died in the effort). If there was no such conversion possible, making the notes worthless at the future date, the *immediate* effect would necessarily have been 100% discount.
This of course sets aside any consumable value of the ?paper? notes, such as burning for heat or trading as novelties (e.g. demonetized Zimbabwean 100T notes currently trading), as Bitcoin is not capable of being consumed. It also sets aside the possibility that some people were unaware of the demonetization.
Who would accept such a note today that was known to be worthless at a future date? If they did, who would would accept it from them? It?s literally an on-chain scamcoin, where the first sucker must find another, and he another, an so on, as soon as possible, before it expires, leaving the last sucker holding the bag. Given an efficient market (i.e perfect knowledge of the scam), zero initial value is implied.
Giving up control of money for a period does not imply the money is useful to someone else. Bob might as well lock his coins in a time capsule, for which he has the only key, and ask Alice to pay him for it.
I didn?t say that it does. Lending implies no ?mandate?. But the nature of fractional reservation is inherent in every loan/investment. Fractional reservation is not a consequence of statutory or market controls. The level of hoarding vs. lending is a consequence of individual time preference.
I don?t believe I called full reserve a fiction. With full reserve there is no possible investment, production or products. Unlikely, and disastrous for humanity, but not provably impossible.
A hazard of viewing economic concepts through a financial lens is that those higher order concepts become obscured by a morass of economically-irrelevant regulation and implementation details.
At this point we are going to end up in a discussion on what fractional reserve actually is. I?d be happy to have a discussion on the topic, but this list is clearly not a good forum for that.
Furthermore the question of whether or not this proposal is relevant to fractional reserve is moot unless it can be shown that the assumed utility actually exists. So I suggest we take this interesting but secondary question on fractional reserve somewhere else.
It shows the breadth of economic ignorance which is not surprising given its counterintuitive nature.

@_date: 2019-06-30 10:41:33
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
For something to become property (and therefore have marketable value) requires that it be both scarce and useful. Bitcoin is useful only to the extent that it can be traded for something else that is useful. Above you are only dealing with scarcity, ignoring utility.
I was careful to point out that bitcoin is not in any way consumable. Occupying scarce land is a service to people. Units of bitcoin encumbered such that they cannot be traded for something of service to a person do not constitute property. You cannot even polish them, stack them on the floor, and roll around on them.
Yet it has been established that these encumbered coins cannot purchase anything of value except to the extent that an imperfect market is unaware of the scam.
Your goal is clear and not at issue.
I?m not sure what is meant here by respect, or how much of it is necessary. I am merely explaining the market.
It seems to me you have reversed the meaning of temporary and final. Bitcoin is useful because of the presumption that there is no finality of control. One presumes an ability to trade control of it for something else. This is temporary control. Final control would be the case in which, at some point, it can no longer be traded, making it worthless at that point. If this is known to be the case it implies that it it worthless at all prior points as well.
These are distinct scenarios. The fact that temporary (in my usage) control implies the possibility of value does not imply that finality of control does as well. The fact that (renowned or otherwise) people have made errors does not imply that I am making an error. These are both non-sequiturs.
The analogy to rental of a consumable good does not apply to the case of a non-consumable good. If it cannot be traded and cannot be consumed it cannot obtain marketable value. To this point it matters not whether it exists.

@_date: 2019-06-30 11:54:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
Could you please explain the meaning and utility of ?unforgeable register? as it pertains to such encumbered coins?
The meaning in terms of Bitcoin is clear - the ?owner? of outputs that represent value (i.e. in the ability to trade them for something else) is recorded publicly and, given Bitcoin security assumptions, cannot be faked. What is not clear is the utility of a record of outputs that cannot be traded for something else. You seem to imply that a record is valuable simply because it?s a record.

@_date: 2019-06-30 13:13:02
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalized covenants with taproot enable 
ICO tokens can be traded (indefinitely) for other things of value, so the comparison isn?t valid. I think we?ve both made our points clearly, so I?ll leave it at that.

@_date: 2019-03-07 19:30:51
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Removal of reject network messages from Bitcoin 
This implies the reject message is valid only when it is expected (i.e. the sender is knowingly sending invalid transactions), which is presumably useful only in a local development environment.

@_date: 2019-03-24 23:32:58
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] New BIP - v2 peer-to-peer message transport 
============================== START ==============================
This proposal does not provide mitigation for BGP hijacking, message
tampering or delaying, between anonymous peers.
This is only possible if the peers have access to a secure/trusted side
channel between them. In other words, this does not benefit anonymous
peers. It also seems like quite a stretch to consider it creating "high
risk" for the attacker, since the chances of any given pair of peers
actually comparing session IDs over a secure channel seems extremely remote.
Authentication helps mitigate attacks by requiring the identity of the
peer (based only on the presumption that a trusted peer wouldn't
attack). This provides no benefit to anonymous peers.
Data communicated between peers is entirely public. Unlike other systems
that maintain data integrity through encryption, Bitcoin relies on
validation. Encrypting public data between anonymous peers is pointless,
and thus counterproductive from an engineering and software security
More importantly Bitcoin system security *requires* widespread anonymous
participation. It's generally not a good idea to implement features that
backfire if they actually get widespread use. While we cannot prevent
people from using VPNs, incorporating them into the protocol is
counterproductive from a system security standpoint.
The proposal overlooks the simple alternatives of (1) not validating the
checksum, which is never necessary, and (2) proposing a protocol change
to drop the checksum altogether. The former requires no protocol change
and the latter can allow the checksum to be dropped in all messages
except "version" given a simple protocol version number increment (i.e.
no need to consume a service bit), saving not only the CPU resource but
also network bandwidth.
The only such method described is manual comparison of session ID's
between trusted parties over a secure side channel.
Yet this is exactly what a secure side channel is. Furthermore, being
manual, not only would it also suffer from not being widely deployed,
but also widely ignored.
The shortening of message identifiers hardly seems worth the effort.
Dropping the checksum seems a much easier way to save more on the wire
(and in the CPU).
Then to be clear it cannot prevent MITM attacks. The only actual
mitigation requires manual comparison of session IDs after each
connection (and reconnection).
This scenario presumes that the two peers are operated by individuals
who know and trust each other and have the ability to communicate over a
secure side channel, and will each extract the session ID from their
respective peers and use the side channel to compare them.
Not only does this not support anonymous peering, it's not clear what
process would exist to make this actually useful in practice.
Kudos for making this second attempt backward compatible.

@_date: 2019-11-08 12:15:53
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Bech32 weakness and impact on bip-taproot 
As an implementer of both the address encoding and script validation, I agree.

@_date: 2019-10-17 13:16:47
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Removal of reject network messages from Bitcoin 
As this is a P2P protocol change it should be exposed as a version increment (and a BIP), not just as a conditional service. If the intent is to retain this protocol indefinitely, exposing it conditionally, then a service bit would make sense, but it remains a protocol change.
BIP61 is explicit:
?All implementations of the P2P protocol version 70,002 and later should support the reject message.?

@_date: 2019-10-20 01:03:09
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Trustless hash-price insurance contracts 
Hi Lucas,
I would question the assumption inherent in the problem statement. Setting aside variance discount, proximity premium, and questions of relative efficiency, as these are presumably already considered by the miner upon the purchase of new equipment, it?s not clear why a loss is assumed in the case of subsequently increasing hash rate. The assumption of increasing hash rate implies an expectation of increasing return on investment.  There are certainly speculative errors, but a loss on new equipment implies *all miners* are operating at a loss, which is not a sustainable situation.
If any miner is profitable it is the miner with the new equipment, and if he is not, hash rate will drop until he is. This drop is most likely to be precipitated by older equipment going offline.

@_date: 2019-10-20 01:13:12
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Removal of reject network messages from Bitcoin 
I agree, thanks.
FWIW I?ve never been a fan of the ?reject? message, or its implementation.

@_date: 2019-10-20 10:57:37
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Trustless hash-price insurance contracts 
This is a restatement of the assumption I questioned. Hash rate increase does not imply unprofitability. The new rig should be profitable.
What is being assumed is a hash rate increase *without* a proportional block reward value increase. In this case if the newest equipment is unprofitable, all miners are unprofitable.

@_date: 2019-10-20 12:16:57
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Trustless hash-price insurance contracts 
So we are talking about a miner insuring against his own inefficiency.
Furthermore a disproportionate increase in hash rate is based on the expectation of higher future return (investment leads returns). So the insurance could end up paying out against realized profit.
Generally speaking, insuring investment is a zero sum game.

@_date: 2019-10-20 16:17:03
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Trustless hash-price insurance contracts 
Hi Lucas,
This can all be inferred from the problem statement. In other words this doesn?t change the assumptions behind my comments. However this is an unsupportable assumption:
?Difficulty would only go down in this case at the end of life of these equipment, if there isn't a new wave of even more efficient equipment being adopted before that.?
Operating at a loss would only be justifiable in the case of expected future returns, not due to sunk costs.

@_date: 2019-10-20 20:34:12
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Trustless hash-price insurance contracts 
Hi Lucas,
You are assuming that all miners operate at equal efficiency. The least efficient miners are expected to drop offline first. Even with identical hardware and operational efficiency, the necessary variance discount and proximity premium create a profitability spread. The relation between hash rate and reward value is not only predictable, it is easily observed.
There is an error in your sold hardware scenario. When equipment is sold at a loss, the remaining operating miners have a reduced capital cost, which means, despite higher hash rate, miners are profitable. The least efficient miners have written down their expected losses and hash rate becomes consistent with market returns despite being higher.
With respect to the contract, I don?t yet see this working, but there are several gaps and I don?t want to make assumptions. More detailed specification would be helpful. Even a full scenario with numbers and justifications would be something.

@_date: 2020-08-16 12:06:55
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
A requirement to ignore unknown (invalid) messages is not only a protocol breaking change but poor protocol design. The purpose of version negotiation is to determine the set of valid messages. Changes to version negotiation itself are very problematic.
The only limitation presented by versioning is that the system is sequential. As such, clients that do not wish to implement (or operators who do not wish to enable) them are faced with a problem when wanting to support later features. This is resolvable by making such features optional at the new protocol level. This allows each client to limit its communication to the negotiated protocol, and allows ignoring of known but unsupported/disabled features.
Sorry I missed your earlier post. Been distracted for a while.

@_date: 2020-08-17 14:21:53
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
Hi Suhas,
It seems to me that your first two paragraphs contradict each other, so I?m not sure we have understanding. As you say in the first paragraph, a peer would never get messages that it does not understand, so there is no chance that missing a protocol change would matter.
In case it?s not understood, version negotiation provides each peer with the maximum supported protocol version of the other. Once complete both have negotiated to the highest common version. No message not supported at that version may be sent by either.
If the protocol was to accept *any* message traffic then it will cease to be a protocol. People will drop in their changes without obtaining broad support, and peers will evolve to the point of no longer being peers. They won?t speak the same language and the ?network? will be little more than a broadcast transport, broadcasting all traffic to all peers, whether it?s for them or not.
People need to either build support or build a distinct network. That?s the actual coordination issue, which is inherent to protocol development.

@_date: 2020-08-18 09:54:58
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
?Bitcoin protocol has always expected clients to ignore unknown messages?
This is not true. Bitcoin has long implemented version negotiation, which is the opposite expectation. Libbitcoin?s p2p protocol implementation immediately drops a peer that sends an invalid message according to the negotiated version. The fact that a given client does not validate the protocol does not make it an expectation that the protocol not be validated.
Features can clearly be optional within an actual protocol. There have been post-handshake negotiations implemented for optional messages which are valid at the negotiated version. The protocol may be flexible while remaining validateable. There is no reason to force a client to accept unknown message traffic.
A generalized versioning change can be implemented in or after the handshake. The latter is already done on an ad-hoc basis. The former is possible as long as the peer?s version is sufficient to be aware of the behavior. This does not imply any need to send invalid messages. The verack itself can simply be extended with a matrix of feature support. There is no reason to complicate negotiation with an additional message(s).
FWIW, bip37 did this poorly, adding a feature field to the version message, resulting in bip60. Due to this design, older protocol-validating clients were broken. In this case it was message length that was presumed to not be validated.

@_date: 2020-08-18 11:11:12
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
Such as?
You are misrepresenting ?historical precedent?. I?ve seen several attempts to require arbitrary traffic over the years and none have been realized.
Not to be pedantic, but I don?t know what that means.
I have shown below how that already works.
For the reasons previously given.
Presumably this is why we have a standards process. Any new message implies ownership. Deconflicting that is required, which implies it can easily be version associated (as it has been).
This presumes an implementation. As part of the handshake, collection of an arbitrary set of messages is a significant and unnecessary complication *of the protocol*. Extension of the verack is not. It is the simplest change possible to implement the desired behavior. Each peer simply supplies the matrix of sub-protocols it supports and only those supported by both are allowed. There is no reason for the protocol to split that matrix up into multiple messages, requiring termination. Independent messages exist because of timing or ordering requirements. Implementing dependent messages as if they were independent is wasteful and complicating.
I?m well aware of the inefficiency produced by version linearity in the face of optional sub-protocols. The protocol must negotiate to the version where it can then negotiate support, which has been done. I support creating a simpler system, eliminating these extra messages. The existing numeric version can be reserved exclusively for ?must? implement, and can be used to signal an extension to the verack. The verack can then carry a list of ?may? or ?should? sub-protocols for final negotiation.
The format of the matrix is arbitrary, but the requirement is to list a set of optional sub-protocols. This implies a namespace. This implies ?ownership? of names. In other words, that coordination requirement is not eliminated.

@_date: 2020-08-18 11:56:13
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
When the discussion centers on backward compatibility, and there is confusion over what that actually implies, this is a central question. You snipped the bit about what actually constitutes the existing protocol. I have implemented every aspect of the protocol that is widely deployed, and I can say without question that the protocol does not require a peer to accept arbitrary messages. In other words, your statement on the subject was a very relevant factual error. Furthermore no reason has been demonstrated here to accept arbitrary traffic.
As I have shown, this is not the case. While I have given my support to simplifying the process, we should not proceed based on an incorrect understanding of actual behavior.
Actually the protocol has not done this. It has used the version to signal a new sub-protocol, and then in some cases that sub-protocol has been made optional through subsequent negotiation. What is being proposed here is to simplify that process by collapsing the secondary negotiation into the handshake.
In fact I argued against this secondary ad-hoc negotiation when it began. Now we are coming around to recognizing that it?s a handshake issue, as I said at the time. I?m glad to see that.
This is a moot point. Whether a list of supported optional sub-protocols is listed in one or multiple messages in the handshake would not change this.
There is no difference between a constrained set of key-value pairs and a distinct set of options, so there is no additional complexity here.
To be clear this does not increase flexibility, it reduces communication and therefore complexity, and allows peers to lock in allowed message semantics by the end of the handshake, as opposed to allowing them to change at any time.
Hashes don?t prevent collisions. Someone can just use the same hash. Bitcoin uses names (message names) and numbers (version, service, relay...). It?s a protocol, coordination is the whole point.

@_date: 2020-08-20 21:25:08
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
Hi Anthony,
This is what I was implying in my last post (the reference to the unnecessary overload of message typing). However, if one imagines a sequence diagram for this communication it becomes obvious that all such messages are 100% redundant with verack.

@_date: 2020-08-21 09:42:46
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
I?m pretty sure one can run whatever they want even without a BIP. There is nobody here to do any ?allowing?. On the other hand, standards development is tedious for good reason.
Generally speaking, overloading is a primary source of complexity (creating more branches in code and human explanation). Nevertheless this is verack payload, no additional messages are necessary or helpful.

@_date: 2020-08-21 14:17:55
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
Service bits are advertised, protocol support is not.

@_date: 2020-08-23 10:45:45
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
I agree. In fact all proposals I?ve seen on this are over engineered.
Correct me if I?m wrong, but this pattern is what the proposal aims to eliminate. There is no reason whatsoever for a message per indication. The appropriate pattern is already established in the implementation of service bits. In fact in this discussion it has been pointed out that the problem with service bits is simply too few bits.
As does any other proposal, including passage of the full set of optional sub-protocols in the verack.
This is neither true nor relevant. Maybe the Segwit 2X guys should have used this argument.

@_date: 2020-08-23 10:49:35
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
This seems to imply a security benefit (I can?t discern any other rationale for this complexity). It should be clear that this is no more than trivially weak obfuscation and not worth complicating the protocol to achieve.

@_date: 2020-08-24 13:17:17
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
I said security, not privacy. You are in fact exposing the feature to any node that wants to negotiate for it. if you don?t want to expose the buggy feature, then disable it. Otherwise you cannot prevent peers from accessing it. Presumably peers prefer the new feature if they support it, so there is no need for this complexity.

@_date: 2020-08-24 13:33:46
@_author: Eric Voskuil 
@_subject: [bitcoin-dev] Generalizing feature negotiation when new p2p 
I see no requirement for anything here apart from exchanging a list of supported ?features?. Conditionally hiding a feature provides no benefit. Any peer that wants it can get it (obfuscation being weak security), and otherwise it?s a non-issue.

@_date: 2020-11-30 17:06:13
@_author: eric@voskuil.org 
@_subject: [bitcoin-dev] Out-of-band transaction fees 
Hi Sebastian,
It's important to consider here that anonymity is the reason fees are incorporated into transactions. One must generally trust the party with whom one transacts. But since integral fees are paid to any miner, this does not apply to fees. In paying fees externally one must find another way to associate a fee with its transaction. This of course increases the possibility of taint, as you describe in part here:
It is also the case that the "bounty" must be associated with the transaction. Even with miner and payer mutual anonymity, the fee inputs and outputs will be associated with the transaction inputs and outputs by the miner, rendering the proposal counterproductive.
Total transaction sizing is not reduced by paying fees externally, in fact it would be increased. The only possible reduction would come from aggregation of fees. Yet it is not clear how that aggregation would occur privately in less overall block space. At least with integral fees, it's *possible* to spend and pay a fee with a single input and output. That is not the case with externalized fees.
-----Original Message-----
Sent: Monday, November 30, 2020 3:03 PM
Hi all,
the possibility of out of band transaction fee payments is a well known fact. Yet it has been mostly discussed as an annoying inevitability that can be problematic if on-chain fees are to be used as a consensus parameter. The potential use cases have seen little interest though (please correct me if I'm wrong).
One such use case is sending UTXOs "intact". Let's assume we get to a point where Bitcoin is primarily a settlement layer for L2 systems.
These L2 systems might want to protect their privacy and keep UTXOs of a common sizes (e.g. 1 BTC, 10 BTC, ?). For certain settlement applications these can be transferred as a whole, but currently fee requirements force the system to add another input for fees which will introduce taint (because it's used repeatedly). If instead a fee could be paid out of band in a privacy preserving way the TXO chain would leak little about the intermediate holders.
Taking this concept even further CoinJoin-like protocols could also be used to introduce further ambiguity without leaking that a certain entity took part in the CJ (which fee inputs/reused "toxic waste"
inevitably do afaik). Such a mechanism would probably also make CJ transactions much smaller as _no_ fee inputs had to be provided (assuming the inputs already have the right size).
Out-of-band transaction "accelerators" already exist and taking fee payment out-of-band can not be effectively prevented. So even though any such proposal will probably have slight centralizing effects I believe that having a standard for it is preferable to having every pool implement their own API making it harder for small pools to get into the market.
Imo the central questions are:
 * how to build such a out-of-band "transaction bounty" system
 * how to standardized it
 * how can the centralizing effects from it be mitigated
Imo fees are small enough to not really care about counter party risk that much. It's more important that it is easy to run so that there is some choice for users and miners. In that sense I consider single-operator services providing both standardized user and miner APIs as well as an optional UI suitable. I would still take into account that this could change and might consider the needs of federated services in the protocol.
Each such service would need to announce which means of payment it supports and allow users and miners to choose when paying/redeeming fees. Users should be able to submit transactions and either be presented with a single payment method dependent "invoice" or one per input (for the CoinJoin use case). As soon as all invoices are paid the bounty goes live and is visible to miners through an API.
Miners that included a transaction need a way to authenticate when claiming the bounty. One possibility would be to optionally include a unique public key e.g. in the coinbase scriptsig after the height push (is this feasible?). This could be used to claim any bounties after 100, 120, or even a user-defined confirmation threshold is met. If the key is unique for every block there won't be a problem with pool accountability which might become a risk down the road (so this should also be enforced at least in the bounty protocol to avoid lazy implementations leading to dangerous precedents).
Any feedback is welcome :)
tl;dr Out-of-band fee payment services are inevitable and useful, so we should at least standardize them and mitigate negative effects as much as possible.
bitcoin-dev mailing list
bitcoin-dev at lists.linuxfoundation.org
