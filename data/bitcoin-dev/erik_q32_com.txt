
@_date: 2016-08-02 10:53:59
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP Number Request: Open Asset 
wild since 2014. We can't easily modify the protocol by now for improving
You can, however, provide a new OA2.0 protocol that improves upon these
issues, and assure that upgraded wallets maintain support for both
It seems like OA's stance has *always *been to focus on integration, rather
than fixing the core protocol and then, by virtue of having the largest
integration, saying things like "it's too late to turn back now".    Colu
and Chromaway/EPOBC also have stuff "in the wild".
I would love to see an RFC-style standard "multiple-colored-coin-protocol"
written by reps from all of the major protocols and that meta-merges the
features of these implementations - in collaboration with feedback from
core developers that understand the direction the protocol will be taking
and the issues to avoid.   HTTP/TCP/IP MCCP/BTC
As it stands, investors have to install multiple wallets to deal with these
varying implementations.   Merging them into one "meta-specification"
fairly soon might be in the best interests of the community and of future

@_date: 2016-08-04 08:43:34
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP clearing house addresses 
On Thu, Aug 4, 2016 at 12:53 AM, Matthew Roberts via bitcoin-dev <

@_date: 2016-08-07 18:59:34
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP clearing house addresses 
I still feel like you're better off getting rid of "hot wallets" and use
lightning-esqe networks to route orders.  I don't think either speed or
flexibility is an issue there.
IMO, the point of Bitcoin is to avoid the centralization that seems to be
happening on the network now.   By making "hot wallets" more "secure", we
encourage things to keep heading downhill with massive centralized
crappy-security exchanges.
Because, ultimately, there's no security that will prevent an inside job.
And all of these thefts have, in my opinion, been at least partly inside
And centralization is the actually demon that needs slaying here.
A client-side library with P2P order routing, tether.to + bitcoin ....  and
you've got a decentralized exchange... with orders matched to users
directly, and channel-trades executed instantly.   And "market makers"
running nodes to facilitate routing, etc.
No center... nothing to shut down or sue... and no one holds your funds.
That's a real Bitcoin exchange.
On Sun, Aug 7, 2016 at 1:35 AM, Matthew Roberts via bitcoin-dev <

@_date: 2016-08-08 06:09:24
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP clearing house addresses 
I'm not convinced you need to hold people's funds to provide those
features. Maybe the millisecond thing.   But 99 out of 100 traders would
accept a 100 millisecond latency in exchange for 0 counterparty risk.

@_date: 2016-08-10 07:42:57
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP Number Request: Addresses over Audio 
Addresses aren't really meant to be broadcast - you should probably be
encoding BIP32 public seeds, not addresses.
OR simply:
- Send btc to rick at q32.com
- TXT record _btc.rick.q32.com is queried (_..)
- DNS-SEC validation is *required*
- TXT record contains addr:[]
Then you can just say, in the podcast, "Send your bitcoin donations to
rick at q32.com".   And you can link it to your email address, if your
provider lets you set up a TXT record.   (By structuring the TXT record
that way, many existing email providers will support the standard without
having to change anything.)
This works with audio, video, web and other publishing formats... and very
little infrastructure change is needed.
On Wed, Aug 10, 2016 at 6:41 AM, Tier Nolan via bitcoin-dev <

@_date: 2016-08-11 09:55:51
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP Number Request: Addresses over Audio 
Sorr, I thought there was some BIP for a public seed such that someone can
generate new random addresses, but cannot trivially verify whether an
address was derived from the seed.
On Wed, Aug 10, 2016 at 1:38 PM, Pieter Wuille

@_date: 2016-08-11 16:37:04
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP Number Request: Addresses over Audio 
Can't have shared secrets or interactivity for a public address to have the
love it needs.
Still not sure how you can take a BIP32 public seed and figure out if an
address was derived from it though.   I mean, wouldn't I have to compute
all 2^31 possible public child addresses?
On Thu, Aug 11, 2016 at 11:13 AM, Tier Nolan via bitcoin-dev <

@_date: 2016-08-12 08:36:31
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP Number Request: Addresses over Audio 
I'm imagining a "publishable seed" such that:
 - someone can derive a random bitcoin address from it -  and send funds to
 - the possible derived address space is large enough that generating all
possible addresses would be a barrier
 - the receiver, however, knowing the private key, can easily scan the
blockchain fairly efficiently and determine which addresses he has the keys
 - another interested party cannot easily do so
Perhaps homomorphic encryption may need to be involved?

@_date: 2016-07-26 13:27:22
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Reasons to add sync flags to Bitcoin 
- Flags will be mined selfishly, and not published until the advantage
   gained from withholding is less than the mining reward.  This effect may
   kill the decentralization features, since big miners will be the only ones
   that can selfish-mine flags.  Indeed, collusion would be encouraged... just
   ship the flag to the miners you do business with, and no one else.   At the
   expense of loss of flag revenue, your in-group would gain a massive
   advantage in main-chain mining.
On Tue, Jul 26, 2016 at 9:51 AM, Tom via bitcoin-dev <

@_date: 2016-06-20 17:33:32
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Even more proposed BIP extensions to BIP 0070 
BIP 0070 has been a a moderate success, however, IMO:
- protocol buffers are inappropriate since ease of use and extensibility is
desired over the minor gains of efficiency in this protocol.  Not too late
to support JSON messages as the standard going forward
- problematic reliance on merchant-supplied https (X509) as the sole form
of mechant identification.   alternate schemes (dnssec/netki), pgp and
possibly keybase seem like good ideas.   personally, i like keybase, since
there is no reliance on the existing domain-name system (you can sell with
a github id, for example)
- missing an optional client supplied identification
- lack of basic subscription support
*Proposed for subscriptions:*
- BIP0047 payment codes are recommended instead of wallet addresses when
establishing subscriptions.  Or, merchants can specify replacement
addresses in ACK/NACK responses.   UI confirms are *required *when there
are no replacement addresses or payment codes used.
- Wallets must confirm and store subscriptions, and are responsible for
initiating them at the specified interval.
- Intervals can *only *be from a preset list: weekly, biweekly, or 1,
2,3,4,6 or 12 months.   Intervals missed by more than 3 days cause
suspension until the user re-verifies.
- Wallets *may *optionally ask the user whether they want to be notified
and confirm every interval - or not.   Wallets that do not ask *must *notify
before initiating each payment.   Interval confirmations should begin at *least
*1 day in advance of the next payment.
*Proposed in general:*
- JSON should be used instead of protocol buffers going forward.  Easier to
use, explain extend.
- "Extendible" URI-like scheme to support multi-mode identity mechanisms on
both payment and subscription requests.   Support for keybase://, netki://
and others as alternates to - Support for client as well as merchant multi-mode verification
- Ideally, the identity verification URI scheme is somewhat
orthogonal/independent of the payment request itself
Should this be a new BIP?  I know netki's BIP75 is out there - but I think
it's too specific and too reliant on the domain name system.
Maybe an identity-protocol-agnostic BIP + solid implementation of a couple
major protocols without any mention of payment URI's ... just a way of
sending and receiving identity verified messages in general?
I would be happy to implement plugins for identity protocols, if anyone
thinks this is a good idea.
Does anyone think https:// or keybase, or PGP or netki all by themselves,
is enough - or is it always better to have an extensible protocol?
- Erik Aronesty

@_date: 2016-06-21 13:09:41
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Even more proposed BIP extensions to BIP 0070 
I like protobuf, personally, for C++ stuff.  I just imagined it would be
harder on mobile, or in some languages, to implement.   I'll focus on the
scheduling issue.  Really, that's the only thing I want hashed out.
I think the intervals should *not* be flexible, even at the protocol level,
to prevent attacks designed to confuse users  - plus for shorter intervals,
you need payment channels anyway.  Also, I think the spec should be rigid
with respect to response times, retry periods, etc.... to encourage
consistency among wallet vendors.   Not sure how anyone else feels about
that.  I suspect the netki guys should have opinions, since they are
working on similar UI-stuff.
Should UI standards go somewhere else - not in a BIP?  I do think there
need to be UI standards.  Something with RFC-style should/must/will/wont
language, like "Wallet software *must* show unconfirmed transactions as
distinct from confirmed", and "Wallet software *should *show some visual
indication of other levels of confirmation" ....  stuff like that.

@_date: 2016-06-21 17:42:39
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Even more proposed BIP extensions to BIP 0070 
good point about keybase spam, but i think it's limited to once hash per
hour (?), not really too bad... the tx's are just root signatures, so you
can verify a whole keybase tree (up to the last hour) with very minimal
bitcoin blockchain impact.
"Replacement addresses" would take the place of BIP 32/47 support, if
someone thought maybe that was too difficult to deal with.   So each time i
paid Alice, Alice could generate a new payment address for the next monthly
payment.   If you support BIP 32 pub seed, then there's no need for this.
I don't know any wallets that support a BIP 32 pub seed (and then what,
some random number generator?) as a destination address yet.
service providers.
I think mandating is a harsh word here, but i I'm a strong believer in
providing strict guidelines that if people break, others can call them
on.   Giving someone a 12.3 +/- 5 day interval for payments using this
protocol would suck.   You should use payment channels for that stuff.
The idea is a lightweight protocol for getting monthly subscriptions

@_date: 2016-06-22 10:25:03
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Even more proposed BIP extensions to BIP 0070 
Payment protocol is for when you buy stuff from purse.io, not really needed
for face-to face transfers, end users, IMO.
I agree.  A TXT record at that name could contain the pubkey.
The problem is that there's no way for a merchant to *refuse *a payment
without a direct communication with the merchant's server.    Verify first
the payment on the way out the door.
Also, as a merchant processing monthly subscriptions, you don't want the
first time you hear about a user's payment to be *after *it hits the
blockchain.  You could add a refund address to deal with it after the
fact... stuff a refund address int OP_RETURN somehow?
... But what if the merchant simply goes out of business.  No OP_RETURN
will help you here.   You'll be posting transactions into a dead wallet.
You could have some way of posting a "ping" transaction, and then
monitoring for a valid response.   But this is "spamming the blockchain for
No, I think BIP075 is fine.   You just need to extend the *PaymentAck *with
a single field, instead of just having a memo.
next_payment_days : integer
The wallet, when it sees this field, re-initiates an invoice request after
the selected number of days, after presenting the user with the content of
the memo field which will presumably explain the subscription.   Wallet
vendors can let users "auto approve" vendors as needed.
This is, I think, the absolute minimum needed to update BIP0070/0075 for

@_date: 2016-06-22 11:30:55
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Even more proposed BIP extensions to BIP 0070 
everything. Also, why do you want to bloat the blockchain with unnecessary
refund transaction data?
I don't, sorry -  I was just kind of thinking out loud and explaining what
happens when you stuff that into a URL.
My conclusion at the bottom of that post was to keep BIP 75 the same, don't
change a bit, and stick any subscription information (future payment
schedule) in the PaymentACK.   Then the wallet then re-initiates an invoice
(unattended or attended.. up to the user), after the subscription interval
is passed.  Subscriptions are pretty important for Bitcoin to be used as a
real payment system.

@_date: 2016-06-22 13:07:21
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Even more proposed BIP extensions to BIP 0070 
- Payment channels seem clearly inappropriate for things like monthly
subscriptions, the use of nlocktime, etc.
- Merchants cannot send requests to users for future payments, because
users don't run servers that they can connect to.  That's why BIP0070 works
the way it does.
- Need to have an interval for subscriptions, at a minimum, and stored in
the wallet so next months payment can go out on time
- Support for varying currency conversion needs to be baked in to
wallets.   Fortunately, by adding advisory subscription info to the
paymentrequest, this is left up to the wallet to
secure/validate/repeat/convert/etc. as needed for each subscription.
- The UI you describe is nice - but not unique to the solution.
On Wed, Jun 22, 2016 at 12:20 PM, Andy Schroder

@_date: 2016-06-22 16:37:06
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Even more proposed BIP extensions to BIP 0070 
Simple: Because the PaymentRequest is somewhat counter-intuitively a
merchant can initiate (of course, logically this makes sense... how can a
merchant know how to connect to some random android app).
Customers initiate all InvoiceRequests  BIP0075 clarifies this.   BIP0070
merely says that the customer "somehow indicates they are ready to pay".
BIP0075 formalizes a standard way to do this.
In no way do merchants initiate anything (of course).   Subscription
information must reside in the customers wallet, in response to a
merchant's advice to set up subscription.   Tacking parameters on to a
PaymentRequest or PaymentAck is the only good way to do this within BIP
The only thing to hash out is exactly what fields to tack on and what they
mean.  ( subscription amount / currency / interval / interval_type ...
can't think of anything else )
Wallets are responsible for initiating the subscriptions on behalf of the
user.  Recommendations on how to do this should go into the spec.
Of course any wallet can, with BIP0075 add support for subscriptions
without any spec - just let the user set them up manually.   But it would
be nice if a user didn't have to enter the main parameters for
subscriptions... too easy to get times amounts, etc wrong.

@_date: 2016-06-23 09:03:36
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Even more proposed BIP extensions to BIP 0070 
AML/KYC is a *side-effect *of a some very important features of BIP0075.
Features that have nothing to do with public names for wallet seeds,
and moniker *consistency *should be scrapped.
BIP 75 formalises what someone could do today with a bunch of PGP emails
back and forth.
I create a public key, and I exchange it via QR code with you.   From then
on, You can initiate invoice requests with me, knowing my moniker is the
same as it was the last time.   I publish this key to a server (via DNSSEC)
so anyone can obtain it.   Sounds exactly like PGP.
Identity in BIP 75 is merely "moniker consistency".  Nothing says that
identity has to be "real"... only publicly verifiably consistent and
accessible.  This consistency and the ability to have public names for both
merchants and users are the important features of BIP 075.
Other features linking monikers to real-world identity should be surgically
removed from the standard.
- Users need to be able to send Bitcoin to an address without MITM attacks
during the address exchange.
- Merchants need to be able to supply memorable names linked to internet
services, like web servers and email addresses.
- Merchants and users both need to be able to initiate transaction
off-chain, with a workflow that allows things like rejection, subscription,

@_date: 2016-06-23 22:26:52
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Even more proposed BIP extensions to BIP 0070 
Sometimes I think there's concerted resistance to making Bitcoin usable for
the average person.   Clearly the primary purpose of BIP0075 is to enshrine
a DNSSEC protocol for giving wallet addresses memorable names.
On Thu, Jun 23, 2016 at 6:44 PM, Justin Newton via bitcoin-dev <

@_date: 2016-06-26 08:12:11
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] parallel token idea & question 
token miners who will work to the a new token signal readiness to secure
that token by posting a public key to the bitcoin blockchain along with a
collateral and possibly a block mined from a side chain, or some other
signal proving sufficient participation (allows for non-blockchain tokens).
coin moved to the new token set is sent to a multisig wallet consisting of
miners who have signaled readiness, with nlocktime set to some time in the
coin sits in that wallet - the new token doesn't even have to be a chain,
it could be a DAG, or some other mechanism - following whatever rules it
any time, miner of the new system can move coin back to the main chain...
trivially and following whatever rules are need.  also, any time a miner
fails to follow the rules of the new system, they lose their collateral
any sufficient consortium of miners/participants in the side chain can, of
course, steal that coin...but that is true for all sidechains - and to some
extent bitcoin - anyway
does this seem too simplistic or weak in some way?

@_date: 2016-06-30 09:36:57
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP 151 
I agree.
Encrypting links in a network without identity doesn't really seem to help
enough for the costs to be justified.
I would like to see a PGP-like "web of trust" proposal for both the
security of the bitcoin network itself /and/ (eventually) of things like
transmission of bitcoin addresses.
Something where nodes of any kind (full, spv, mobile wallets) can
identity of other nodes in that web.
*Then* you can slap an encryption layer on top of it.   Once you have
identity & P2P verified pub keys for nodes, encryption becomes easy.
On Thu, Jun 30, 2016 at 5:57 AM, Eric Voskuil via bitcoin-dev <

@_date: 2017-04-07 09:28:13
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP proposal: Inhibiting a covert attack on the 
It is *not proof of stake.* when:
a) burn happens regardless of whether you successfully mine.
b) miner cannot know which tx are burns
c) the majority of burns cannot be used for mining and are simply lost
(poisson discovery distribution)
d) burn involves real risk: *every bit as much at stake *
(It's the difference between a computer secured by not being connected to
the internet, and a computer secured by re-imaging from a computer that
was, in the past, not connected to the internet.)
It is possible to craft a burn-network such that the only way for a miner
to prevent a burn is to prevent all transactions other than his own.
This is still a weakness, and I can't see a way around it though.
On Fri, Apr 7, 2017 at 8:59 AM, Jannes Faber via bitcoin-dev <

@_date: 2017-04-09 14:44:47
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] A Small Modification to Segwit 
Curious: I'm not sure why a serious discussion of POW change is not on the
table as a part of a longer-term roadmap.
Done right, a ramp down of reliance on SHA-256 and a ramp-up on some of the
proven, np-complete graph-theoretic or polygon manipulation POW would keep
Bitcoin in commodity hardware and out of the hands of centralized
manufacturing for many years.
Clearly a level-playing field is critical to keeping centralization from
being a "defining feature" of Bitcoin over the long term.   I've heard the
term "level playing field" bandied about quite a bit.   And it seems to me
that the risk of state actor control and botnet attacks is less than
state-actor manipulation of specialized manufacturing of "SHA-256 forever"
hardware.   Indeed, the reliance on a fairly simple hash seems less and
less likely a "feature" and more of a baggage.
Perhaps regular, high-consensus POW changes might even be *necessary* as a
part of good maintenance of cryptocurrency in general.   Killing the
existing POW, and using an as-yet undefined, but deployment-bit ready POW
field to flip-flop between the current and the "next one" every 8 years or
or so, with a ramp down beginning in the 7th year....  A stub function that
is guaranteed to fail unless a new consensus POW is selected within 7
Something like that?
Haven't thought about it *that* much, but I think the network would respond
well to a well known cutover date.   This would enable rapid-response to
quantum tech, or some other needed POW switch as well... because the
mechanisms would be in-place and ready to switch as needed.
Lots of people seem to panic over POW changes as "irresponsible", but it's
only irresponsible if done irresponsibly.
On Fri, Apr 7, 2017 at 9:48 PM, praxeology_guy via bitcoin-dev <

@_date: 2017-04-09 20:20:49
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] A Small Modification to Segwit 
Have you read the cuckoo cycle paper?  Finding cycles in massive graphs is
just about the worst thing to use an ASIC for.
It might be a hitherto before unknown emergent property of cryptocurrencies
in general that POW *must* change every 7-9 years.  Could bake that into
the protocol too...

@_date: 2017-04-10 14:17:03
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] A Small Modification to Segwit 
I own some miners, but realistically their end of life is what, 6 months
from now if I'm lucky?    If we used difficulty ramps on two selected
POW's, then the migration could be made smooth.   I don't think changing
the POW would be very challenging.  Personally, I would absolutely love to
be back in the business of buying GPU's instead of ASICs which are
uniformly sketchy.   Does anyone *not* mine their own equipment before
"shipping late" these days?
Maybe sample a video game's GPU operations and try to develop a secure hash
whose optimal implementation uses them in a similar ratio?   Ultimately, I
think it would very challenging to find a POW that doesn't make a bad
problem worse.  I understand that's why you suggested SHA3.
Hopefully, the "nanometer race" we have will work more smoothly once the
asicboost issue is resolved and competition can return to normal.   But
"waiting things out" rarely seems to work in Bitcoin land.

@_date: 2017-04-17 03:47:48
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Malice Reactive Proof of Work Additions (MR 
The write time for configuring a FPGA with a fresh bitstream is measured in
tens of milliseconds.
I have no objections to the use of FPGA or any other commercially available
ASIC will never beat this - because it will be 8x more expensive to
Unused circuits don't consume power, which is the main cost in running a
They make GPUs or FPGAs (as u mentioned) far more affordable.  The problem
is centralized manufacturing, which, in turn, is a side effect of a covert
hardware mining optimization leading to a monopoly.
A rotating POW seems to make ASIC manufacture impractical compared to
generalized, commercially available hardware.
It's too bad we can't make the POW somehow dynamic so that any specialized
hardware is impossible, and only GPU / FPGA is possible.

@_date: 2017-04-17 11:50:51
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Transaction signalling 
If users added a signal to OP_RETURN, might it be possible to tag all
validated input addresses with that signal.
Then a node can activate a new feature after the percentage of tagged input
addresses reaches a certain level within a certain period of time?
This could be used in addition to a flag day to trigger activation of a
feature with some reassurance of user uptake.

@_date: 2017-04-18 14:01:52
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Transaction signalling 
Just to be clear, the tagging would occur on the addresses, and the
weighting would be by value, so it's a measure of economic significance.
Major exchanges will regularly tag massive amounts of Bitcoins with their
Just adding a nice bit-field and a tagging standard, and then charting it
might be enough to "think about how to use it later".   The only problem
would be that this would interfere with "other uses of op_return" ...
colored coins, etc.
Personally, I think that's OK, since the purpose is to tag economically
meaningful nodes to the Bitcoin ecosystem and colored coins, by definition,
only have value to "other ecosystems".
(Counterargument: Suppose in some future where this is used as an
alternative to BIP9 for a user-coordinated code release - especially in
situations where miners have rejected activation of a widely-regarded
proposal.  Suppose also, in that future, colored coin ICO's that use
op-return are regularly used to float the shares of major corporation.  It
might be irresponsible to exclude them from coordinating protocol changes.)

@_date: 2017-04-19 12:17:39
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] I do not support the BIP 148 UASF 
The "UASF movement" seems a bit premature to me - I doubt UASF will be
necessary if a WTXID commitment is tried first.   I think that should be
first-efforts focus.
On Sat, Apr 15, 2017 at 2:50 PM, Gregory Maxwell via bitcoin-dev <

@_date: 2017-04-20 11:48:21
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] I do not support the BIP 148 UASF 
Bitcoin must level the playing field for mining or it is fundamentally
broken.   And there are two obvious solutions:
1. WTXID commitment has as a flag day upgrade. It's a fix to a fairly
serious security issue - made even worse by the existence of patents on the
2. Embed the code for performing a covert ASICBOOST into Bitcoin core's
reference implementation.   But, since this would violate patents held in
China and the U.S., it could be a problem.
Of these, I think the first should be far less controversial.
One or the other must be done - if we can't fix security and licensing
problems in Bitcoin, what can we fix?
On Thu, Apr 20, 2017 at 10:23 AM, Alphonse Pace

@_date: 2017-04-20 11:50:24
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Small Nodes: A Better Alternative to Pruned Nodes 
Try to find 1TB dedicated server hosting ...
If you want to set up an ecommerce site somewhere besides your living room,
storage costs are still a concern.
On Mon, Apr 17, 2017 at 3:11 AM, Danny Thorpe via bitcoin-dev <

@_date: 2017-04-20 12:14:18
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Transaction signalling 
I agree, addresses create vulnerability, an OP_RETURN signal seems the
safest way to go for UA signalling.   I can model a BIP after BIP9, with
some discussion of how to properly collect statistics, and the ability for
nodes to activate features based on an "economic majority" defined in this
On Tue, Apr 18, 2017 at 6:29 PM, Tim Ruffing via bitcoin-dev <

@_date: 2017-08-13 14:46:37
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Would anyone object to adding a dlopen message hook 
I was thinking about something like this that could add the ability for
module extensions in the core client.
When messages are received, modules hooks are called with the message data.
They can then handle, mark the peer invalid, push a message to the peer or
pass through an alternate command.  Also, modules could have their own
private commands prefixed by "x:" or something like that.
The idea is that the base P2P layer is left undisturbed, but there is now a
way to create "enhanced features" that some peers support.
My end goal is to support using lightning network micropayments to allow
people to pay for better node access - creating a market for node services.
But I don't think this should be "baked in" to core.   Nor do I think it
should be a "patch".   It should be a linked-in module, optionally compiled
and added to bitcoin conf, then loaded via dlopen().    Modules should be
slightly robust to Bitcoin versions changing out from under them, but not
if the network layer is changed.   This can be ensured by a) keeping a
module version number, and b) treating module responses as if they were
just received from the network.   Any module incompatibility should throw
an exception...ensuring broken peers don't stay online.
In general I think the core reference would benefit from the ability to
create subnetworks within the Bitcoin ecosystem.   Right now, we have two
choices... full node and get slammed with traffic, or listen-only node, and
do nothing.
Adding a module/hook system would allow a complex ecosystem of
participation - and it would seem to be far more robust in the long term.
Something like this???
class MessageHookIn {
    int hookversion;
    int64_t nodeid;
    int nVersion;
    int64_t serviceflags;
    const char *strCommand;
    const char *nodeaddr;
    const char *vRecv;
    int vRecvLen;
    int64_t nTimeReceived;
class MessageHookOut {
    int hookversion;
    int misbehaving;
    const char *logMsg;
    const char *pushCommand;
    const unsigned char *pushData;
    int pushDataLen;
    const char *passCommand;
    CDataStream passStream;
class MessageHook {
    int hookversion;
    std::string name;
    typedef bool (*HandlerType)(const MessageHookIn *in, MessageHookOut
    HandlerType handle;

@_date: 2017-08-14 21:33:34
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Would anyone object to adding a dlopen message 
Actually the more I think about it, the more I realize that all I need is
to listen on a new port, and use the RPC api to affect Bitcoin:
- ban a peer (# of hours)
- unban a peer (# of hours)
As long as I have those two functions, I can do everything I need.
On Sun, Aug 13, 2017 at 4:56 PM, Mark Friedenbach

@_date: 2017-08-15 00:44:52
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Would anyone object to adding a dlopen message 
The idea is that some peers, when you connect to them will work fine for
some time, but you need to find out the rate for services and send a
micropayment to maintain the connection.   This creates an optional pay
layer for high quality services, and also creates DDOS resistance in this
fallback layer.

@_date: 2017-08-21 13:24:09
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] UTXO growth scaling solution proposal 
1. If it only affects "old dust" UTXO's where the # of coins in the UTXO
aren't sufficient to pay some lower quantile of transaction fees, then
there can be little argument of theft or loss.
2. There's another use-case for demurrage as well.
Computation power may grow rapidly if quantum computing becomes more
common.  At some point, Bitcoin may have to change the public key format
for coins and the POW used.
In order to do this, old coins will have to transact on the network, moving
their value to a new format, with many more bits in the public key, for
example.   But since quantum computing isn't bounded by moore's law, so
this may need to be a regular upgrade every X years.   Rather than a
regular "bit widening hard fork", the number of bits needed in a public
address format could be scaled to the difficulty of the new quantum hashing
algorithm that *also must *now grow in the # of bits over time.   To ensure
that coins are secure, those with too few bits must drop off the network.
So the timing for old coin demurrage can effectively be based on the
quantum POW difficulty adjustments.   As long as the subsequent exponential
rate of computation increase can be reasonably predicted (quantum version
of moore's law), the new rate of decay can be pegged to a number of years.
On Mon, Aug 21, 2017 at 10:26 AM, Moral Agent via bitcoin-dev <

@_date: 2017-08-22 10:29:26
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] UTXO growth scaling solution proposal 
I agree, it is only a good idea in the event of a quantum computing threat
to the security of Bitcoin.
On Tue, Aug 22, 2017 at 9:45 AM, Chris Riley via bitcoin-dev <

@_date: 2017-08-22 16:06:01
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] UTXO growth scaling solution proposal 
Yes, 3 years is silly.  But coin expiration and quantum resistance is
something I've been thinking about for a while, so I tried to steer the
conversation away from stealing old money for no reason ;).   Plus I like
the idea of making Bitcoin "2000 year proof".
- I cannot imagine either SHA256 or any of our existing wallet formats
surviving 200 years, if we expect both moores law and quantum computing to
be a thing.   I would expect the PoW to be rendered obsolete before the
Bitcoin addresses.
 - A PoW change using Keccak and a flexible number of bits can be designed
as a "future hard fork".  That is:  the existing POW can be automatically
rendered obsolete... but only in the event that difficulty rises to the
level of obsolescence.   Then the code for a new algorithm with a flexible
number of bits and a difficulty that can scale for thousands of years can
then automatically kick in.
 - A new addresses format and signing protocols that use a flexible number
of bits can be introduced.   The maximum number of supported bits can be
configurable, and trivially changed.   These can be made immediately
available but completely optional.
 - The POW difficulty can be used to inform the expiration of any addresses
that can be compromised within 5 years assuming this power was somehow used
to compromise them.   Some mechanism for translating global hashpower to
brute force attack power can be researched, and consesrvative estimates
made.   Right now, it's like "heat death of the universe" amount of time to
crack with every machine on the planet.   But hey... things change and 2000
years is a long time.   This information can be used to inform the
expiration and reclamation of old, compromised public addresses.
- Planning a hard fork 100 to 1000 years out is a fun exercise

@_date: 2017-08-30 13:14:22
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP103 to 30MB 
============================== START ==============================
If you use this formula, with a decaying percentage, it takes about 100
years to get to 30MB, but never goes past that.
Since it never passes 32, we don't have to worry about going past that
ever... unless another hard fork is done.   A schedule like this could
allow block size to scale with tech growth asymptotically.   Might be nice
to include with other things
P=17%, Pn = P*0.95 X = 1, Xn = X * (1+P)

@_date: 2017-12-07 16:39:56
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP Proposal: UTWFOTIB - Use Transaction Weight 
You can feel free to write this version and try to get miners to use it.
 That's the nice thing about Bitcoin.
On Thu, Dec 7, 2017 at 3:49 PM, Damian Williamson via bitcoin-dev <

@_date: 2017-01-06 17:07:36
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Committed bloom filters for improved wallet 
- N \log_2 \epsilon * 1.44
N = 41000 blocks
epsilon = 1/41000 (fp rate)
= 904689.8bits
~ 1 MB
On Thu, Jul 28, 2016 at 5:07 PM, Leo Wandersleb via bitcoin-dev <

@_date: 2017-07-08 02:30:03
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] A Segwit2x BIP 
- The BIP91 portion of the fork seems OK to me.  There are some issues with
timing, but since this is for miner coordination of segwit activation, and
has little to do with other network users, it could be included as an
option.   (I'm a fan of adding options;plugins, etc. to Bitcoin... some
others aren't.)
- This hard fork portion of the proposal is being deployed with "emergency"
speed... even though there is not an emergency on the network today that I
am aware of.   If enacted, it will certainly result in two chains - and
with no replay protection..  The results of this will be confusing - two
ledgers with many transactions appearing on both and others appearing only
on one.
- The BIP should be modified to provide evidence and justification for the
timeline that is consistent with the level of risk the network would bear
if it were enacted.
- The coercion used to drive production of this BIP is mired in a
misinterpretation of BIP9 and sets a precedent for Bitcoin that may
undermine the value prospect of all cryptocurrency in general.   For this
reason alone - even if all of the engineering concerns and timelines are
improved - even assigning this BIP a number could be considered
- If you still want to code up a fork for the Bitcoin network, consider
starting with Luke's hard fork code and changing the rates of growth as
needed for your desired effect.   Also you might want to read this first
(code references are in there):
 .
Plans are already underway for a hard fork, for reasons that have nothing
to do with block size, but could include a timeline for a block size growth
consistent with global average residential bandwidth growth.

@_date: 2017-07-14 09:50:14
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] A Segwit2x BIP 
While BIP91 is probably not terribly harmful, because the vast majority of
nodes and users are prepared for it - the hard fork portion of this BIP is
being deployed like an emergency patch or quick bug fix to the system.
Please consider updating the BIP to include some justification for the
urgency of the consensus change, and the reasons for not delaying until a
better engineered solution (spoonet, BIP103, etc.) can be deployed.
On Thu, Jul 13, 2017 at 3:19 PM, Sergio Demian Lerner via bitcoin-dev <

@_date: 2017-06-02 16:04:16
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Segwit2Mb - combined soft/hard fork - Request For 
merge it with some small pushback - allow segwit to activate in Aug, then
"upgrade" the hard fork to be "spoonet in 18 months" instead.
On Fri, Mar 31, 2017 at 11:03 PM, Samson Mow via bitcoin-dev <

@_date: 2017-06-02 16:04:25
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Segwit2Mb - combined soft/hard fork - Request For 
merge it with some small pushback - allow segwit to activate in Aug, then
"upgrade" the hard fork to be "spoonet in 18 months" instead.
On Sat, Apr 1, 2017 at 8:33 AM, Jorge Tim?n via bitcoin-dev <

@_date: 2017-06-02 20:53:55
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Segwit2Mb - combined soft/hard fork - Request For 
What I mean is that spoonet and other HF improvements, and a slower
timeline needs to be folded in ...before the HF activation date - to make
it far more likely that the community adopts the whole proposal and the
chain doesn't fragment.
If you try to push a 2mb with no safety checks and nothing else improved -
nothing will happen.
Take a quick look at the COOP proposal...it gets us to 4mb blocks in 4
years....gradually, no massive fee swings.
On Fri, Jun 2, 2017 at 5:51 PM, Sergio Demian Lerner <

@_date: 2017-06-07 10:10:48
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] User Activated Soft Fork Split Protection 
This is, by far, the safest way for miners to quickly defend against a
chain split, much better than a -bip148 option.   This allows miners to
defend themselves, with very little risk, since the defense is only
activated if the majority of miners do so. I would move for a very rapid
deployment.   Only miners would need to upgrade.   Regular users would not
have to concern themselves with this release.
On Wed, Jun 7, 2017 at 6:13 AM, James Hilliard via bitcoin-dev <

@_date: 2017-06-07 14:05:52
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] User Activated Soft Fork Split Protection 
Without this option, a miner has to guess whether a split will be
economically impacting.   With this option, his miner will automatically
switch to the chain least likely to get wiped out... as soon as a simple
majority of miners supports it.
On Wed, Jun 7, 2017 at 12:44 PM, Jacob Eliosoff

@_date: 2017-06-07 15:59:23
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] User Activated Soft Fork Split Protection 
I get it, a threshold could be put in place, but something like 33% would
more accurately reflect the risks miners run.
I'm not aware of a good signal to indicates someone is planning to run
BIP148 and orphan a miner's blocks.
On Wed, Jun 7, 2017 at 3:39 PM, Jacob Eliosoff

@_date: 2017-06-15 14:38:57
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Proposal: Demonstration of Phase in Full Network 
what remains will be united. Are you afraid of the united users or the fork?
I had proposed earlier and maintain that "UTXO bits" can be used to allow
coordinated user participation activation thresholds akin to other
hashpower thresholds.
While I'm not certain that my implementation was correct (or was just too
complicated and concerned with compression at the expense of readability),
I am fairly certain that this mechanism - or a similar one - would be a
reasonable way for users to coordinate changes independently of miners and
with very high consensus levels.
On Thu, Jun 15, 2017 at 1:04 AM, Eric Voskuil via bitcoin-dev <

@_date: 2017-06-20 09:38:59
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Drivechain RfD -- Follow Up 
- a proof-of-burn sidechain is the ultimate two-way peg.   you have to burn
bitcoin *or* side-chain tokens to mine the side chain.   the size of the
burn is the degree of security.    i actually wrote code to do randomized
blind burns where you have a poisson distribution (non-deterministic
selected burn).    there is no way to game it... it's very similar to
algorand - but it uses burns instead of staking
- you can then have a secure sidechain that issues a mining reward in
sidechain tokens, which can be aggrregated and redeemed for bitcoins.   the
result of this is that any bitcoins held in the sidechain depreciate in
value at a rate of X% per year.   this deflation rate pays for increased
- logically this functions like an alt coin, with high inflation and cheap
transactions.   but the altcoin is pegged to bitcoin's price because of the
pool of unredeemed bitcoins held within the side chain.

@_date: 2017-06-20 11:44:36
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Miners forced to run non-core code in order to get 
Are we going to merge BIP91 or a -BIP148 option to core for inclusion in
the next release or so?
Because a large percentage of miners are indifferent, right now miners have
to choose between BIP148 and Segwit2x if they want to activate Segwit.
Should we be forcing miners to choose to run non-core code in order to
activate a popular feature?
- Erik

@_date: 2017-06-20 21:36:49
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Miners forced to run non-core code in order to 
# Jacob Eliosoff:
Correct.  There are 2 short activation periods in BIP91 either of which
would avoid a split.
# Gregory Maxwell:
This is the relevant pull req to core:
Seems OK.  It's technically running now on testnet5.   I think it (or a
-bip148 option) should be merged as soon as feasible.
apples vs oranges, imo.   segwit is not a contentious feature.   the
"bundling" in segwit2x is, but that's not the issue here.   the issue is we
are indirectly requiring miners that strongly support segwit to install
consensus protocol changes outside of bitcoin's standard reference.   80%
of them have signaled they will do so.   these are uncharted waters.
On Tue, Jun 20, 2017 at 6:57 PM, Jacob Eliosoff via bitcoin-dev <

@_date: 2017-06-22 09:45:33
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Drivechain RfD -- Follow Up 
Users would tolerate depreciation because the intention is to have a cheap
way of transacting using a two-way pegged chain that isn't controlled by
miners.   Who cares about some minor depreciation when the purpose of the
chain is to do cheap secure transactions forever?
Add in UTXO commitments and you've got a system that is cheap and
secure-enough for transfer. storage and accumulation of a ledger... before
moving in to the main chain.
Seems better to me than messing with the main chain's incentive structure
via merged mining.

@_date: 2017-06-23 10:19:18
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Drivechain RfD -- Follow Up 
expensive due to the extra depreciation cost.
This depends on how long you expect to keep money on a side chain and how
many transactions you plan on doing.   Inflation is a great way of paying
PoS / PoB  miners - that cannot introduce issues with consolidation.   If
you design the inflation schedule correctly, it should be balance
transaction costs *precisely*.   Indeed, you can calculate the exact amount
of inflation needed to guarantee that a side chain is always exactly 10
times cheaper than bitcoin.
Indeed, I think side chain nodes should always be fast-synced from 6 month
old commitments and thus be ephemeral, cheap, and *never *appropriate for
long term storage.  This would provide the best possible incentive
structure to keep the main chain secure, paid for with high clearing fees,
incentive structure
The critical issue is that we cannot introduce protocol changes that
*further *incentivize geographical and institutional consolidation.  Miners
who are able to deal with the bandwidth caused by drivechain coffee
transactions will profit from these transactions, whereas smaller and more
geographically distributed miners will not.   Those miners will, in turn,
build faster ASICs and buy more electricity and drive out smaller players.
  I think this is *abundantly *clear, and is the primary motivation behind
preserving block size limits.
If this premise is false (which it may be), or is skewed so as to damage
bitcoin as a whole (could be as well), then that needs to be demonstrated
The lightning model does the opposite of this.   Miners watch fees increase
and coming from an *orthoganal* protocol that cannot cause further
One problem is that the main chain also *must* grow in response to
bandwidth, or the disadvantages of using the main chain will weaken
financial support and hashrate securing it.   I believe this is also true,
and that a "balancing act" will be Bitcoin's norm until we adopt something
like BIP103 - which provides a steady and appropriate growth.

@_date: 2017-06-27 15:26:35
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Miners forced to run non-core code in order to 
There's a pull req to core already for part of it:
On Tue, Jun 27, 2017 at 12:31 PM, Jorge Tim?n via bitcoin-dev <

@_date: 2017-03-08 14:42:11
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] High consensus fork system for scaling without limits 
I woudl like to propose a BIP that works something like this:
1. Allow users to signal readiness by publishing an EB. This EB is an
absolute upper bound, and cannot be overridden by miners. Current EB is
1MB, the status-quo.   Maybe EB can be configured in a config file, not a
UI, since it's an "advanced" feature.
2. Miners can also signal readiness by publishing their own EB in a block.
3. If 95% of blocks within a one month signalling period contain an EB
greater than the previous consensus EB, a fork date is triggered at 6
months using the smallest 5th percentile EB published. (Other times can be
selected, but these are fairly conservative, looking for feedback here).
Miner signalling is ignored during the waiting period.
4. Block heights used for timing
5. After 6 months, any users which already have the new EB or greater begin
actually using it to validate transactions. Users use the EB or the latest
95% consensus triggered value - whichever is less.   This means that the
portion of users that originally signaled for the increase do not have to
upgrade their software to participate in the hard fork.
6. Core can (optionally) ship a version with a default EB in-line with
their own perceived consensus.
7. Some sort of versioning system is used to ensure that the two networks
(old and new) are incompatible... blocks hashed in one cannot be used in
the other.
Any users which don't already have the new EB or greater should update
their EB within the 6 month period - or they will be excluded from the
majority fork.
It would be in the best interests of major exchanges and users would to
publicly announce their EB's.
Users are free to safely set very high EB levels, based on their current
hardware and network speeds. These EB levels don't cause those users to
accept invalid blocks ever. They are safe because block size transitions
behave like normal hard forks with high miner consensus (95%).
No code changes will be needed to fork the network as many times as both
users and miners feel the need to do so.  (Bitcoin core is off the hook for
"scaling" issues...forever!)
If a smaller block size is needed, a reduced size can also be published and
agreed upon by *both* users and miners using a the same mechanism, but the
largest 5th percentile is used.   In other words... the requires broad
consensus to deviate from status quo and fork.
Any new node can simply follow these rules to validate all the blocks in a
chain... even if the sizes changes a lot (at most twice per year).

@_date: 2017-03-09 10:29:07
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] High consensus fork system for scaling without 
absolute upper bound, and cannot be overridden by miners. Current EB is
1MB, the status-quo.   Maybe EB can be configured in a config file, not a
UI, since it's an "advanced" feature.
Excessive block size.
determine what to set theirs to? If so, what about sybil attacks with fake
nodes publishing EBs?
You can't trivially fake coinbase's full node, or gemini's, etc.   Large
users would also be encouraged to report their EB's publically as well.
that goes into the User Agent?
Same way a version string is published by a node.   Maybe *in* the version
Maybe 4MB for now?   Seems fine.   Trivial to change it later, since it's
not a fork to do so.
their own perceived consensus.
I would say that Core /should/ ship new versions with new default EB's
in-line with both miner and the economic majority after a 95% consensus
(old and new) are incompatible... blocks hashed in one cannot be used in
the other.
such a system.
I thought versionbits could handle this?   Can't they?  ALP pointed out
that it was important for a fork to be fully incompatible.
publicly announce their EB's.
So miners can have a more reliable signal to go on.   No reasonable miner
would start mining signal for a fork unless they were confident that they
are doing so in-line with users and exchanges.
more to scaling than just increasing the block size.
Yes, which is why I used air-quotes.   The primary idea is to remove a
political issue from affecting core developers.   There is a perception
among some people that "if only core would....".   Plus, fees are
*inherently* political because it is a barrier for low-net-worth
individuals transacting using this technology.   Even if lightning worked
perfectly, how can a small business in Africa afford to set up a full node
and being to participate as a hub if fees are $50?   OMG blame core.
Miners and users should be free to wrangle each other over fees any time
they want without the involvement of developers.   I suspect the status quo
would be even *more* stable in that scenario... not less.
Then it is only used for signal unless a fork occurs that results in a
reduction <= EB... in which case the EB becomes a hard upper bound, just
like any other.   When an EB is set by a user a block-height needs to be
recorded along with it, so it can be handled correctly.   EB set to <
active seems to me to be a special case.   Likewise the percentile shoudl
be the upper 5% in the case of EB < active.
This essentially partitions signalling into "< active" and "> active".

@_date: 2017-03-14 19:20:48
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Solution for blockchain congestion and 
- no quadratic hashing solution
- no way to prevent spamming the network to blow up block sizes
- no mention of release schedule/consensus levels, etc.   should be
- this is similar to other BIP already in place... see BIP107
On Mon, Mar 13, 2017 at 9:08 AM, ashish khandekar via bitcoin-dev <

@_date: 2017-03-14 19:26:17
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Quadratic hashing solution for a post-segwit hard fork 
Some discussion today led me to believe that a post segwit hard fork could
1MB old tx non-witness segment
XMB new segwit non-witness segment
XMB witness segment
By partitioning off old transactions, it allows users of older, more
expensive validation transactions to continue using them, albeit with
higher fees required for the restricted space.
New segwit blocks, which don't have the hashing problem could be included
in the new non-witness segment of the block.

@_date: 2017-03-16 20:44:27
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Quadratic hashing solution for a post-segwit hard 
Yeah, it does make things harder, and it's easy enough to soft fork to
handle arbitrary opt-in protocol improvements, new much larger block sizes,
whatever you want.   Even OK to migrate to a new system by not allowing
old->old or new->old transactions.

@_date: 2017-05-02 12:54:35
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] I do not support the BIP 148 UASF 
If the flag day for a wtxid commitment is timed before the current segwit
period end, I suspect segwit would activate within the current period.
On Tue, Apr 25, 2017 at 2:46 PM, Luke Dashjr via bitcoin-dev <

@_date: 2017-05-03 10:03:58
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Small Nodes: A Better Alternative to Pruned Nodes 
Wouldn't the solution be for nodes to use whatever mechanism an attacker
uses to determine less commonly available blocks and choose to store a
random percentage of them as well as their deterministic random set?
IE X blocks end of chain (spv bootstrap), Y% deterministic random set,  Z%
patch/fill set to deter attacks

@_date: 2017-05-03 15:41:07
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Transaction signalling 
BIP XXXX : User activated features (ROUGH OVERVIEW)
A proposed change to a usage of the 'OP_RETURN' script opcode in Bitcoin
transactions, allowing multiple changes (features) to be deployed in
parallel. It relies on interpreting the output field as a bit vector, where
each bit can be used to track an independent change. Like BIP9, once a
consensus change succeeds or times out, there is a "fallow" pause after
which the bit can be reused for later changes.
BIP 9 introduced a mechanism for doing soft-forking changes, relying on
measuring miner support indicated by version bits in block headers. As it
relies on miner support, any change which may conflict with miners but is
acceptable to users may be difficult to deploy.   The alternative, a
flag-day deployment can cause issues for users of a feature that has failed
to achieve adequate miner support.
BIP XXXX, if used for deployment, can be used in conjunction with BIP 9, in
order to more safely deploy soft-forking changes that do not require a
supermajority of miners, but do require a large percentage of active
Alternatively, BIP XXXX signalling can be used to gauge user support for
"features" - independent of its use as a direct deployment mechanism.   In
this document a "feature" can be considered synonymous with "soft fork",
but since this mechanism is "user activated", it is not necessarily
restricted to soft-forks.
Each "feature" is specified by the sames set of per-chain parameters as in
BIP9, with the same usage and meaning (name, bit, starttime and timeout).
===Bit flags===
If the outputs contain a zero valued OP_RETURN, and the length of the key
is 2 bytes, and if the first byte (prefix) of that OP_RETURN's key
parameter is 0x012, then the remaining byte is to be interpreted as an
8-bit little-endian integer, and bits are selected within this integer as
values (1 << N) where N is the bit number.  This allows up to 8 features to
be in the STARTED state at a time.
===Array determination===
In order for this to successfully be used for deployment, a lightweight
UTXO must be maintained in memory.   For each bit in STARTED state, a
corresponding bit is set in a map entry for each input address.   Each
input address is hashed to a 24 bit value using SHA3-256(input)[0:24].  An
array with 16777216 2-byte entries (~32MB RAM) is used to record the
current activation state.   The first byte contains the bit flags most
recently associated with an entry.
The second byte contains the log base 2 of the number of "1/100th" bitcoins
most recently associated with this entry.   This is computed by taking the
value, multiplying by 100, converting to an unsigned 32 bit integer, and
using the log2_32 function below (.... log2_32 func defined below ....).
This array is initialized to zero.   The array must be stored and
maintained for each block.  When a block is in the STARTED state for any
bit, the array is updated for each transaction in the block according to
the rules above: a[i][0]=bits, a[i][1]=log2_32(....)
===State transitions===
State transitions work the same as BIP9, however, the determination of the
LOCKED_IN tally is as follows:
For each bit in STARTED state, using the array above, the values are
totaled (unsigned int)(2 << a[i][1]) for each entry where this bit is set
in a[i][0].  In addition the total of all the entries in a, irrespective of
bit, are computed.   This can be done in a single pass, resulting in a
vector of up to 8 32 bit entries containing the "feature totals" for the
array, and one extra 32 bit entry for the sum total of observations since
the start time.
The percentage of observations is computed for each bit.   Up to 8 features
can be computed at a time, with reuse similar to BIP9.
If 2016 sequential blocks have a value of 95% or greater, a feature is
"LOCKED_IN", (75% on testnet)
Similar to BIP9, a block's state never depends on its own transactions set;
only on that of its ancestors.  ACTIVE and FAILED are terminal states, etc.

@_date: 2017-05-03 17:08:35
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Full node "tip" function 
- Full nodes advertise a bitcoin address.   Users that need to download the
block chain from that node can be encouraged to send a tip to the peers
that served them (by % served).   Recommended tip of 10mbit should be fine.
- A full nodes can *require* a tip to download the blockchain.  If they do,
users that don't specify a tip cannot use them.
For some people, this may represent a barrier to hosting their own full
node.   After all, if you have to pay $15 just to get a copy of the
blockchain, that just adds to the already expensive prospect of hosting a
full node.
As long as you manage to stay online, you should get your money back and
more.   This is the an incentive for quality, long term hosting.
In the long term, this should cause stable nodes to stick around longer.
It also discourages "installation spam" attacks on the network.
Fees for other node operations can be considered if this is successful.

@_date: 2017-05-04 09:15:02
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Full node "tip" function 
I cannot imagine the benefit to replicating an ip address in this case,
except maybe you think that you would be more likely to be selected as a
peer?   But there would be no actual advantage since download peers are
selected based on throughput and actual blocks served.
Also, since this makes the network far more resistant to DDOS attacks, it
has added benefits.
I agree, if lightning networks were baked in, then the tips could be as
granular as "per block downloaded", or even (outlandish seeming now, but
maybe not in a future where there is a "public rpc api") "per rpc call".
Miners and business users would certainly pay for high quality services.
Spinning up new nodes without a tip and relying on the "free network" would
probably take more time, for example.
I suspect that if income were even a small possibility the number of full
nodes would vastly increase.
Sybil attacks seem irrelevant as long as reasonable QOS metrics are stored
per peer.

@_date: 2017-05-04 09:47:45
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Full node "tip" function 
- Full nodes already perform many valuable services, and simply allowing
people to pay for better service is something operators can do now - even
without it being baked into bitcoind.   Paying for access to a higher-speed
relay network, for example, is something that many operators would do.
- Baking in the ability to add service fees could make more people *want*
to run more high quality, highly available full nodes... which is really
one of the most important things developers can be doing.
On Thu, May 4, 2017 at 9:37 AM, Aymeric Vitte via bitcoin-dev <

@_date: 2017-05-04 15:28:10
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Full node "tip" function 
Yes, micro-payments for online network services is precisely what LN is
best at.
Establishing a channel with each peer is too expensive.   But using LN to
micro-pay for high-quality peer services seems like it would aggregate very
It would be great if this protocol was in-place and ready to go in or
around the same time LN is ready.   It would incentivize full nodes even
further than LN does, and allow the network to be strongly DDOS resistant.

@_date: 2017-05-08 14:58:54
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP Proposal: Rate Limiting with server specified 
- It would be cool if any rate-limiting POW was specified as bytecode ...
so nodes can plug in as many "machine-captcha" things as they please, and
solvers can choose to solve... or just say "nope too hard".
- Alternately, it would be a lot nicer if you just required people to pay a
nanobit .... that could prevent DDOS even better, and generate a revenue
stream for nodes.
On Sun, May 7, 2017 at 10:48 PM, Karl Johan Alm via bitcoin-dev <

@_date: 2017-05-23 19:07:41
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Hypothetical 2 MB hardfork to follow BIP148 
Personally, I would prefer if a 2MB lock-in that uses BIP103 for the
I think up to 20% per year can be absorbed by averages in bandwidth/CPU/RAM
growth, of which bandwidth seems the most constraining.
- Erik
On Tue, May 23, 2017 at 4:23 PM, Luke Dashjr via bitcoin-dev <

@_date: 2017-05-24 12:44:55
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Reduced signalling threshold activation of 
Yes, 75% seems fine - given that there is a already a wide deployment of
segwit enforcing nodes
This implementation is 100% compatible with a "UASF movement" since, if
triggered, it essentially turns all supporting miners into equivalent
BIP148 enforcers.   This should allay any fears that this would subvert a
The proposed "agreement" which was reached without input from the
development community also apparently requires that a hard fork be locked
in on the same bit (bit 4).
Ideally, such a 2MB increase should be scheduled using BIP103-esqe logic:
Gradually increasing from 1MB to 2MB over the course of at least a couple
years, beginning 6 months from lock-in.
This will give developers ample time to evaluate and react to network
On Wed, May 24, 2017 at 12:02 PM, Wang Chun via bitcoin-dev <

@_date: 2017-05-26 10:39:30
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Emergency Deployment of SegWit as a partial 
Linking a bit4 MASF with a bit4 "lock in of a hard fork in 6 months" is
something that will simply never happen for basic engineering reasons.
Spoonet, an oft-quoted hard fork that actually has some strong support, is
a much better candidate for the code base - but not of the supposed
supporters of bit4 MASF seem to be ready to roll up their sleeves and do
any work at all.   I mean, if they really had "millions" for development,
they could just hire dome developers and built it correctly, right?   But
they aren't ... instead they are pumping money into "bcoin", which doesn't
yet have any of the protections needed to get consensus.   Maybe it will
some day.
Claiming that miners support segwit is disingenuous ... considering that if
they supported it, they would be signaling for it today... instead of
distracting the community with fake proposals that have no peer-reviewed
On Fri, May 26, 2017 at 5:21 AM, Tom Zander via bitcoin-dev <

@_date: 2017-05-30 11:51:17
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Compatibility-Oriented Omnibus Proposal 
- We now are witnessing this... COOP vs LukeJr COOP, vs BIP148 vs BIP149 vs
BIP91 ... how many are there?:
- If some miners and exchanges collude to enact a rapid 2MB+Segwit hard
fork coin... and calling it "bitcoin" on major exchanges this could swiftly
fragment the network.
- If this fork fails to contain an ASICBOOST defense, then this is
essentially an example of core failing to appropriately respond to the CVE
security vulnerability in time.
- A swift BIP148 release in core seems necessary to defend against this.
I am no longer in favor of adding a BIP148 option with default "false"..
I think it should be merged in...enabled, and released ASAP to defend
against these attacks.
On Mon, May 29, 2017 at 7:49 PM, Oliver Petruzel via bitcoin-dev <

@_date: 2018-08-29 07:28:56
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multisignature for bip-schnorr 
It's cool but
- there's a lot of online steps.
- it's not a threshold system
Using a shamir scheme solves this and isn't subject to birthday attacks:
On Mon, Aug 13, 2018 at 7:08 AM nakagat via bitcoin-dev <

@_date: 2018-08-29 08:09:36
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Schnorr signatures BIP 
This spec cannot be used directly with a shamir scheme to produce
single-round threshold multisigs, because shares of point R would need to
be broadcast to share participants in order to produce valid single
(R, s) schemes can still be used "online", if share participants publish
the R(share).... but, not sure if it matter much, this choice eliminates
offline multiparty signing in exchange for batch validation.
On Sun, Aug 12, 2018 at 12:47 PM Andrew Poelstra via bitcoin-dev <

@_date: 2018-01-22 15:40:58
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Blockchain Voluntary Fork (Split) Proposal 
Without enforcement liquidity will diverge.
On Mon, Jan 22, 2018 at 1:46 PM, Chaofan Li via bitcoin-dev <

@_date: 2018-07-08 10:19:52
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
To save space, start with the wiki terminology on schnorr sigs.
Consider changing the "e" term in the schnorr algorithm to hash of message
(elligator style) to the power of r, rather than using concatenation.
I don't think this changes the security.   An attacker would need to know k
to either way to compromise the private key.
This would allow m of n devices to sign a transaction without any of them
knowing a private key at all.
IE: each device can roll a random number as a share and the interpolation
of that is the private key.
The public shares can be broadcast and combines.  And signature shares can
be broadcast and combined.
The net result of this is it really possible for an arbitrary set of
devices to create a perfectly secure public-private key pair set.
At no point was the private key anywhere.

@_date: 2018-07-09 00:29:02
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
Because it's non-interactive, this construction can produce multisig
signatures offline.   Each device produces a signature using it's own
k-share and x-share.   It's only necessary to interpolate M of n shares.
There are no round trips.
The security is Shamir + discrete log.
it's just something I've been tinkering with and I can't see an obvious
It's basically the same as schnorr, but you use a threshold hash to fix the
need to be online.
Just seems more useful to me.

@_date: 2018-07-09 11:02:30
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
Actually, it looks like in order to compute a multiparty signature you will
need to broadcast shares of r first, so it's not offline :(
It is still seems, to me, to be a simpler mechanism than musig - with
security assumptions that match the original Schnorr construction more
closely, and should therefore be easier to prove secure in a multiparty
Shamir/Schnorr threshold multi-signature scheme:
Each party:
- Has a public key g*x', where x' is their private key, and where H(g*x)
can be considered their public index for the purposes of Shamir polynomial
- Rolls a random k' and compute r' = g*k'
- Broadcast r' as a share
- Computes g*k, via lagrange interpolation across shares.   At this point k
is not known to any party unless Shamir is vulnerable or DL is not hard
- Computes e' = H(M) * r'
- Computes s' = k'-x*e'
- Share of signature is (s', e')
Verification is the same as Scnhorr, but only after using interpolation to
get the needed (s, e, g*x) from shares of s', e' and g*x':
- Using lagrange interpolation, compute the public key g*x
- Again, using lagrange interpolation, compute (s, e)
- Verify the signature as per standard Schnorr
Security assumptions:
 - Because this is not additive, and instead we are using Shamir
combination, the additional blinding and masking steps of musig are not
needed to create a secure scheme.
 - The scheme is the same as Schnorr otherwise
 - The only thing to prove is that H(M) * r does not reveal any information
about k ... which relies on the same DL assumptions as Bitcoin itself
 - Overall, this seems, to me at least, to have a smaller attack surface
because there's fewer moving parts

@_date: 2018-07-09 12:33:01
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
More closely than musig.
In fact there's no need to distribute the hash at all if you have the first
round, you can leave the schnorr construction... thanks for the feedback.
I literally can't think about this stuff without someone asking questions.
1. For those who asked, the construction from section 7.1 of this paper
describes how to use lagrange interpolation in a group context:
        2. Using shamir interpolation is cleaner than the additive multisig
3. Taking your comments into consideration, I think it's possible to remove
the point multiplication instead of a hash and stick to Schnorr "as is",
and still cut out all but one online round:
OK, so this is a new Multisig variant of schnorr with fewer rounds... I
know this is possible, I just needed to have that back and forth... sorry:
For sake of terminology and typing in ascii, I'm using ^ to mean "point
Each party:
1. Has a public g^x
2. Computes and broadcasts g^k' ... where k' is a random number
3. Computes r = g^k using lagrange interpolation (see
4. Computes H(r || M), as per standard schnorr
5. Computes s' = k' - xe , as per standard schnorr .. except k' is a "share"
6. Publish (s', e)
With m of n share-signatures:
1. Use lagrange interpolation on m of n s' shares to get s
2. Standard schnorr verification
- Erik

@_date: 2018-07-09 13:59:23
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
- Adaptive r choice shouldn't be possible since r is derived from the
original threshold prf and it's not possible for a party to have any
adaptive impact on the value of r
 - I'm guess I don't see how an attacker can use adaptive key choice in
this context either.   Any modification of the key should be useless
I forgot to include some assumptions.   The important part here is that
each party only has a share of the private key and publishes a share of the
public key.
This hopefully should preclude any sort of adaptive key attack.
1. Has a public g^x'
2. Computes and broadcasts g^k' ... where k' is a random number
3. Computes r = g^k using lagrange interpolation (see
4. Computes H(r || M), as per standard schnorr
5. Computes s' = k' - xe , as per standard schnorr .. except k' is a "share"
6. Publish (s', e, g^x')
With m of n share-signatures:
1. Interpolation on m of n s' shares to get s
2. Interpolation on m of n g^x' shares to get g^x
3. Standard schnorr verification
The actual public key of the "set of signers" is interpolated.

@_date: 2018-07-10 07:46:17
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
Basically you're just replacing addition with interpolation everywhere in
the musig construction.
But maybe I just don't understand how Wagner's algorithm is relevant here.

@_date: 2018-07-11 10:45:58
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
OK, so you're going with this scenario:
1. I know Apub and Bpub,
2. I know M is 3
3. I'm choosing a random number for C's private key
Cpub is g^C
The equation I am solving for .. and trying to factor myself out of is g^Ax
+ g^B*2 + g^C*3
I don't know A or B... I only know their public keys.
I don't think it's possible to adaptively choose C for an attack on the
multisig construction, when using hash of the public key as the X
coordinate in the polynomial, because in order to satisfy the equation and
factor out C, you would need to be able to break the hash.
With an additive construction, yes... adaptive attacks are possible.   But
in a shamir secret sharing interpolation, you need a public X coordinate as
well as a secret share.   Choosing hash(pub) as X, prevents this attack.

@_date: 2018-07-19 08:16:04
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
Also Wagner's algorithm shouldn't be applicable for a number of reasons.
you can't birthday attack something where there's only a single variable
that you can modify.    And when you change the equation from additive you
now have a multi-dimensional equation we're partitioning won't function.
this is the basis of the perfect security of Shamir secret sharing.

@_date: 2018-07-19 08:24:39
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
Probably because my descriptions are a bit vague and rambling.
but I can't help but think that a SMC of a bitcoin private key, followed by
a secure multiparty computation of a signature is going to be more secure
I couldn't figure out how to do it offline.  But one round of exchange
seems to work.
It comes down to the blinding factor (k).  All parties need to agree to it
... which creates the second round.

@_date: 2018-07-20 12:25:34
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
That's a great point.  It's been solved in musig and that doesn't change
the m of n multisig construction.
You use the same musig construction where you hash all keys and sum the
multiples....and use that when computing k ... the shared blinding
factor.... you're still improving the system .... Getting a nice Shamir m
of n multisig.... with a single signature...and all the same properties
On Thu, Jul 19, 2018, 9:11 AM Russell O'Connor

@_date: 2018-07-20 13:34:29
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
Hi, thanks for all the help.   I'm going to summarize again, and see if
we've arrived at the correct solution for an M of N "single sig" extension
of MuSig, which I think we have.
- Using MuSig's solution for the blinding to solve the Wagner attack
- Using interpolation to enhance MuSig to be M of N instead of M of M
 - MuSig
 - HomPrf  (sections 7.1
and 7.4)
Each party:
1. Publishes public key G*xi
3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of
3. r = G*x = via interpolation of Gx1, Gx2... (see HomPrf)
4. L = H(X1,X2,?) (see MuSig)
5. X = sum of all H(L,Xi)Xi (see MuSig)
6. Computes e = H(r | M | X) .... standard schnorr e... not a share
7. Computes si = xi - xe ... where si is a "share" of the sig, and xi is
the private data
8. Publishes (si, e, G*Xi)
Any party can then derive s from m of n shares, by interpolating, not

@_date: 2018-07-20 16:18:47
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
Sorry there were typos:
- Using MuSig's solution for the blinding factor (e)
- Using interpolation to enhance MuSig to be M of N instead of M of M
 - MuSig  - HomPrf  (sections 7.1
and 7.4)
Each party:
1. Publishes public key G*xi, G*ki, where ki is a random nonce
3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of
3. R = G*k = via interpolation of r1=Gk1, r2=Gk2... (see HomPrf)
4. L = H(X1,X2,?) (see MuSig)
5. X = sum of all H(L,Xi)Xi (see MuSig)
6. Computes e = H(R | M | X) .... standard schnorr e... not a share
7. Computes si = ki *e+ xi * e ... where si is a "share" of the sig, and xi
is the private data, and e is the blinding factor
8. Publishes (si, e) as the share sig
If an attacker has multiple devices, e is safe, because of the musig
But what protects k from the same multiparty birthday attack?
If an attacker has multiple devices, by carefully controlling the selection
of private keys, the attacker can try to solve
the polynomial equation to force the selection of a "known k".
A "known k" would allow an attacker to sign messages on his own.
To fix this, we need to somehow "blind k as well".
Does this work?
The revision below seems to solve this problem.
1. Publishes public key G*xi, G*ki, where ki is a random nonce
3. Xi = H(G*xi) ... Xi is the parties x coordinate, for the purposes of
3. R = G*k = via interpolation of r1=Gk1, r2=Gk2... (see HomPrf)
4. L = H(X1,X2,?) (see MuSig)
5. L2 = H2(XN,XN-1,?) (see MuSig... H2 is a "second hash")
6. X = sum of all H(L,Xi)Xi (see MuSig)
7. Computes e = H(R | M | X) .... standard schnorr e... not a share
8. Computes e2 = H(R | M | X2) ... a second blinding factor
9. Computes si = ki *e2 + xi * e ... where si is a "share" of the sig, and
xi is the private data, and e, e2 are blinding factors
10. Publishes (si, e, e2) as the share sig
The final signature is computed via interpolation, and e2 is can be
subtracted to recover a "normal" schnor sig for the set of participants.
Now there's no mechanism for a birthday attack on k.

@_date: 2018-07-25 22:05:05
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Multiparty signatures 
Also we don't need any new opcodes to support this.  Done right this could
literally go out into clients immediately.

@_date: 2018-09-05 08:26:14
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Schnorr signatures BIP 
Why would you call it FUD?   All the weird hemming and hawing about it is
really strange to me.  The more I look into it and speak to professors
about i, the more it seems "so trivial nobody really talks about it".
1. Generate an M of N shared public key (done in advance of signing ....
this gets you the bitcoin address)
2. Generate signature fragments (this can be done offline, with no
communication between participants)
Detailed explanation with code snippets:
On Sun, Sep 2, 2018 at 8:05 PM Andrew Poelstra

@_date: 2018-09-05 09:14:55
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Schnorr signatures BIP 
Correct, there is an interaction step to deduce G*k, when signing, each
participant has to publishes G*ki. I didn't talk about it.   That doesn't
break it, but you're correct, it's not non-interactive.
On Wed, Sep 5, 2018 at 9:06 AM Andrew Poelstra

@_date: 2018-09-11 12:34:11
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Schnorr signatures BIP 
To answer points:
- I switched to the medium article so that I could correct, edit and
improve things to make them more clear.
- I responded to feedback by modifying the protocol to make it work - not
by ignoring it.
- I coded it up in python so I could be sure it worked, because I was
concerned that it was broken
- Yes, coding it up showed me that it's definitely interactive, and no
different than a "standard shnorr sig" in any meaningful way regarding the
- No special protocol support is needed over Schnorr signing itself.  The
e, s version can be made at least as secure as schnorr + DLP.  I haven't
researched the R,s version.
- An M-1 rogue-key attack would require the attacker would to either
  - attack the hash function to produce a predictable R based on a known
  - attack the DLP to influence x or k
Neither attack gives any particular advantage to someone who has M-1 keys.
I haven't tested whether the R,s version is susceptible though.
On Thu, Sep 6, 2018 at 9:15 AM Gregory Maxwell via bitcoin-dev <

@_date: 2018-09-11 13:20:01
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Schnorr signatures BIP 
I added, stripped out, and added analogous musig delinearization 3 times in
response to stuff posted here.  I'm adding it back now. Not sure why my
head is thick around that issue.
The security advantages of a redistributable threshold system are huge.
If a system isn't redistributable, then a single lost or compromised key
results in lost coins... meaning the system is essetntially unusable.
I'm actually worried that Bitcoin releases a multisig that encourages loss.

@_date: 2018-09-11 13:37:59
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Schnorr signatures BIP 
- Musig, by being M of M, is inherently prone to loss.
- Having the senders of the G*x pubkey shares sign their messages with the
associated private key share should be sufficient to prevent them from
using wagner's algorithm to attack the combined key.   Likewise, the G*k
nonce fragments should also be signed with the pubkey shares.

@_date: 2018-09-11 14:30:13
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Schnorr signatures BIP 
delinearization can be used it's a better option.
I agree, communication efficiency is a concern for some applications, and I
can think of cases where delinearization is the better option as well.
For users that want an "M of N" scheme that
a) doesn't cost more to send funds
b) allows them to lose a device and keep their coins
c) allows them to establish and validate the scheme safely
...  a simple, "verified signer" threshold scheme is probably the best

@_date: 2018-09-13 16:20:36
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Schnorr signatures BIP 
The paper refers to either:
  a) building up threshold signatures via concatenation, or. implicitly -
in Bitcoin -
  b) by indicating that of M of N are valid, and requiring a validator to
validate one of the permutations of M that signed - as opposed to a scheme,
like a polynomial function, where the threshold is built in to the system.
Maybe there's another mechanism in there that I'm not aware of - because
it's just too simple to mention?
- Erik
On Thu, Sep 13, 2018 at 2:46 PM Andrew Poelstra

@_date: 2019-10-24 11:34:14
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Transition to post-quantum 
- It would be hard to prove you have access to an x that can produce
H(g^x) in a way that doesn't expose g^x and isn't one of those slow,
interactive bit-encryption algorithms.
- Instead a simple scheme would publish a transaction to the
blockchain that lists:
     - pre-quantum signature
     - hash of post-quantum address
- Any future transactions would require both the pre *and*
post-quantum signatures.
That scheme would need to be implemented sufficient number of years
before quantum became a pressing issue, but it's super simple,
spam-proof (requires fees), and flexible enough that it can change as
post-quantum addressing improves.
Imagine there are 2 quantum addressing schemes in order of discovery.
1. Soft-fork 1 accepts the first scheme and people begin publishing
PRE/POST upgrades.
2. Discovery is made that shows a second scheme has smaller
transactions and faster validation.
3. Soft-fork 2 refuses to accept upgrades to the first scheme in
transactions beyond a certain block number in order to improve
On Thu, Feb 15, 2018 at 6:44 PM Tim Ruffing via bitcoin-dev

@_date: 2020-12-23 16:13:29
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] BIP Proposal: Wallet Interface 
Obviously Bitcoin has a wallet api, intermingled with other protocol APIs:
For security, a standard wallet API should write a token/port to a
local file where the user can grab that token and use it (that's
basically how the existing bitcoind does it, with a username/password
living in a file... not as nice as a token/port, IMO)
Probably any such standards document should do its best to be
compatible with the existing APIs that so many are already familiar
with.   Or maybe I misunderstand the proposal.
- Erik
On Tue, Dec 22, 2020 at 9:48 AM monokh via bitcoin-dev

@_date: 2020-02-23 02:27:39
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Composable MuSig 
One solution is to add a signature timeout to the message (say a block
height) .
A participant refuses to sign if that time is too far in the future, or is
at all in the past, or if a message M is the same as any previous message
within that time window.
Seems to resolve the attacks on 2 round musig.
On Mon, Nov 25, 2019, 6:00 AM ZmnSCPxj via bitcoin-dev <

@_date: 2020-02-24 10:30:54
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Composable MuSig 
Basically just some mechanism for preventing repeated signings of the
same message, and using a "validity" time window so that the amount of
state you need to enquire about isn't unbounded.
The Drijvers, et al paper is specifically concerned with parallel and
aborted signings, where ksums can be used.  In general, the more
variables that an attacker can control ,the more "k" lists they can
form, and the more likely they can find collisions.
If signers refused to sign "stale" messages, refused to sign in
parallel beyond a certain limit, and refused to sign the same message
twice, it should help reduce the attack surface.
On Mon, Feb 24, 2020 at 6:41 AM Tim Ruffing via bitcoin-dev

@_date: 2020-03-05 14:01:27
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] Schnorr sigs vs pairing sigs 
Schnorr sigs rely so heavily on the masking provided by a random
nonce.   There are so many easy ways to introduce bias (hash + modulo,
for example).
Even 2 bits of bias can result in serious attacks:
Maybe pairing based sigs  - which are slower - might be both more
flexible, and better suited to secure implemetnations?

@_date: 2020-05-27 10:12:26
@_author: Erik Aronesty 
@_subject: [bitcoin-dev] hashcash-newhash 
Bitcoin's primary value proposition is that it's the most resistant to
change:   All other coins are these malleable things centrally
controlled and easily moved about by politics and nonsense.   So
discussions of POW changes... open up this can of worms (myself being
one of them).
 - should also discuss "proof-of-burn", where a burn is performed as a
similar investment-over-time with true loss/risk.
 - should discuss moving to sha3 (or something like it) for
everything, not just POW
Yeah, a hard fork like this would be a massive undertaking, with a
zillion "improvements" argued about for years and the final version
some minimal thing that just changes the hash algo and invalidates
legacy stuff (since back compat is not a concern).
