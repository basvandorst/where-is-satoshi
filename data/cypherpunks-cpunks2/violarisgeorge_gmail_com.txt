
@_date: 2017-11-06 23:02:55
@_author: George Violaris 
@_subject: mesh networking 
The tech definitely exists - they have some power specs on their site

@_date: 2017-11-06 23:02:55
@_author: George Violaris 
@_subject: mesh networking 
The tech definitely exists - they have some power specs on their site

@_date: 2017-10-05 13:30:59
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
I'm trying to understand what kind of crypto algorithm is being used in Zcoin. Is it any similar to cryptonote/bytecoin's ring signatures and such? I understand that transmitted coins are burnt and new ones replace them, but IMO this doesn't cover privacy fully - it's mostly the way the transactions/coins are transmitted that matters, is it not?
In short my question is, how does zero knowledge proof compare to ring signatures employed i.e. by Monero?

@_date: 2017-10-05 16:50:59
@_author: George Violaris 
@_subject: I'm off to Prague, Czech Republic, for the Parallel Polis 
CryptoCzechs accept only cryptocheques now
George V

@_date: 2017-10-06 09:03:39
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
I believe the issue with this, such as in Bitcoin and any coin, is that the blockchain eventually grows to an enormous size. It's all nice when it's at around 200GB of data and it only takes a few days to synchronize to the network. But think about a blockchain that is 2 TB. That is not only a huge blockchain, that would be huge for a relational DB that is stored on central server or cluster. When databases get to that size, companies divide the schema. They'll either divide it per system, per department, per branch or however it suits them best. Then they'll use some sort of business intelligence tool to make sense of all that data.
Nodes need to be able to be useful by storing smaller chunks of a blockchain instead of having to store the entire thing, something like how sharing a bittorrent file works. The downside is that this may lead into centralization as full nodes would have an advantage, but it's not worse off than what it is now.

@_date: 2017-10-06 14:36:23
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
Visa handles an average of 150 million transactions per day. Bitcoin currently handles around 350,000 transactions per day. Bitcoin has a total of 250 million transaction all time. The bitcoin blockchain is at 135GB and growing. So if Bitcoin is to reach Visa volume with it's current algorithm it will need upwards of 120GB of new storage DAILY!
Bitcoin doesn't scale AT ALL.

@_date: 2017-10-07 00:56:29
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
Supposedly, LN will allow nodes to store only the transactions that concern them. Which to me sounds like a way to mess with the original double-spend prevention mechanism. What if the nodes witnessing the transactions behave badly? Wouldn't this be prone to attack?
In any case I believe it is better to have a balance-out and archive mechanism rather than do transactions on a side chain. Transactions should happen in the main, wide open chain. It would make more sense to keep only balances and prune transactions older than x confirmations. Or something along those lines, I haven't given this enough thought to truly make up my mind about specifics; but the pruned transactions can be synchronized to archive nodes for historicity, research and verification purposes.
1. transactions older than x confirmations move to archive nodes and are deleted from main blockchain
2. main blockchain keeps transactions that are being confirmed until x blocks and keeps the balance amount for each public key
3. In order for this to work, we'd probably need to have a pseudo-genesis block upon each archive session. It will be like a fork but the pseudo-genesis block will have a pointer to the previous archived block. So if we're archiving 3 times a day (i.e. can be a const every x amount of blocks), this would mean that we're doing a chain fork 3 times a day. However, each time we fork we keep all the balances, unconfirmed (less than x times) transactions and confirmed transactions (equal to x confirmations) public to the new chain.
Of course the transaction signatures still need to be dealt with to remove any malleability issues and the block size would need to, in my opinion, become entirely dynamic - something like how CryptoNote defines it.

@_date: 2017-10-08 02:41:09
@_author: George Violaris 
@_subject: Distributed Tweet 
Let Julian Assange know about this, he was saying earlier on Twitter that he was looking for a decentralized form of Twitter

@_date: 2017-10-08 12:14:26
@_author: George Violaris 
@_subject: Bypassing Intel Boot Guard, EdDSA 
This is exceptional work, I am looking forward to loading it on Arduino. Did you use a specific Arduino image by the way?

@_date: 2017-10-08 17:33:30
@_author: George Violaris 
@_subject: Timelock encryption 
Some interesting reading regarding timelock encryption. Given crypto breakthroughs through cryptocurrency and smart contracts, it is interesting to be able to apply such techniques in fields such as insurance, bonds, trading, etc.
The big issue up to now with these is that a trusted third party, e.g, a server, was required to keep track. However now with bitcoin and blockchain technologies, this kind of research is starting to change.
Gwern.net - Self-Decrypting Files: Rabin & Thorpe - Time-Lapse Cryptogrpahy:  / Tibor Jager - How to Build Time-Lock Encryption: Jia Liu and Saqib A. Kakvi and Bogdan Warinschi - Extractable Witness Encryption and Timed-Release Encryption from Bitcoin

@_date: 2017-10-08 18:55:16
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
I believe you were the first person to actually point this out to Satoshi. He replied by saying that 100GB per day is required to be processed every day by full nodes. However I am confused by his explanation of server farms. Wouldn't at one point result to a small number of full nodes due to costs? Isn't that preventive of decentralization? I fail to understand how Satoshi would think that the entire world can connect to let's say 50 worldwide server farms and this would somehow scale and be considered decentralized. The point of decentralization is that everyone can verify all transactions. This is done by verifying each transaction against all transactions back to genesis by yourself, not by trusting 50 centralized For all we can know, in 20 years from now only banking institutions will have the capital and benefit of running full nodes.

@_date: 2017-10-10 08:33:06
@_author: George Violaris 
@_subject: Timelock encryption 
Peter Todd did some coding on this concept, based on Gwern's explanation of self-decrypting files.

@_date: 2017-10-10 09:00:20
@_author: George Violaris 
@_subject: "the Jim Bell effect" on Bitcoin price 
Sorry for being irrelevant, does Jim Bell have a website? I've considered him an extraordinary individual but never found him on the internet (except these lists of course)

@_date: 2017-10-10 11:00:59
@_author: George Violaris 
@_subject: "the Jim Bell effect" on Bitcoin price 
Get off Facebook... full of shilling, lies and shallow minds. Have you tried Steemit?

@_date: 2017-10-23 15:56:59
@_author: George Violaris 
@_subject: Decoding Simon and Speck: Block Ciphers for the Internet of Things 
I wonder what the real story behind Jacob Appelbaum and Tor is. Is Jacob a member of this list? Maybe he can give us some insight as to what actually goes on in Tor. Maybe it's time to use alternatives.

@_date: 2017-10-27 22:01:35
@_author: George Violaris 
@_subject: Graph theory question 
What if you only have two good connections but each of your two connections have 3+ connections - how would good peers with only two connections be able to gain reputation in such a system? i.e. if the connections can be laterally traversed in order to reach any connected node, how would the other nodes be able to know if a peer is honest or if it has been spoofed?
I believe this is actually how the recent ransomware spread in networks. They use systems that trust other systems. In order to prevent such attacks, the networking protocols need to be amended. An additional negotiation sublayer can be created which asks the other peer a question only they can know the answer to. This can be something such as encrypting all connections at the tcp/ip level, or applying something like proof of work to make it uneconomical for sybils (but this actually only solves the issue in a probabilistic way).

@_date: 2017-10-05 13:30:59
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
I'm trying to understand what kind of crypto algorithm is being used in Zcoin. Is it any similar to cryptonote/bytecoin's ring signatures and such? I understand that transmitted coins are burnt and new ones replace them, but IMO this doesn't cover privacy fully - it's mostly the way the transactions/coins are transmitted that matters, is it not?
In short my question is, how does zero knowledge proof compare to ring signatures employed i.e. by Monero?

@_date: 2017-10-05 16:50:59
@_author: George Violaris 
@_subject: I'm off to Prague, Czech Republic, for the Parallel Polis 
CryptoCzechs accept only cryptocheques now
George V

@_date: 2017-10-06 09:03:39
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
I believe the issue with this, such as in Bitcoin and any coin, is that the blockchain eventually grows to an enormous size. It's all nice when it's at around 200GB of data and it only takes a few days to synchronize to the network. But think about a blockchain that is 2 TB. That is not only a huge blockchain, that would be huge for a relational DB that is stored on central server or cluster. When databases get to that size, companies divide the schema. They'll either divide it per system, per department, per branch or however it suits them best. Then they'll use some sort of business intelligence tool to make sense of all that data.
Nodes need to be able to be useful by storing smaller chunks of a blockchain instead of having to store the entire thing, something like how sharing a bittorrent file works. The downside is that this may lead into centralization as full nodes would have an advantage, but it's not worse off than what it is now.

@_date: 2017-10-06 14:36:23
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
Visa handles an average of 150 million transactions per day. Bitcoin currently handles around 350,000 transactions per day. Bitcoin has a total of 250 million transaction all time. The bitcoin blockchain is at 135GB and growing. So if Bitcoin is to reach Visa volume with it's current algorithm it will need upwards of 120GB of new storage DAILY!
Bitcoin doesn't scale AT ALL.

@_date: 2017-10-07 00:56:29
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
Supposedly, LN will allow nodes to store only the transactions that concern them. Which to me sounds like a way to mess with the original double-spend prevention mechanism. What if the nodes witnessing the transactions behave badly? Wouldn't this be prone to attack?
In any case I believe it is better to have a balance-out and archive mechanism rather than do transactions on a side chain. Transactions should happen in the main, wide open chain. It would make more sense to keep only balances and prune transactions older than x confirmations. Or something along those lines, I haven't given this enough thought to truly make up my mind about specifics; but the pruned transactions can be synchronized to archive nodes for historicity, research and verification purposes.
1. transactions older than x confirmations move to archive nodes and are deleted from main blockchain
2. main blockchain keeps transactions that are being confirmed until x blocks and keeps the balance amount for each public key
3. In order for this to work, we'd probably need to have a pseudo-genesis block upon each archive session. It will be like a fork but the pseudo-genesis block will have a pointer to the previous archived block. So if we're archiving 3 times a day (i.e. can be a const every x amount of blocks), this would mean that we're doing a chain fork 3 times a day. However, each time we fork we keep all the balances, unconfirmed (less than x times) transactions and confirmed transactions (equal to x confirmations) public to the new chain.
Of course the transaction signatures still need to be dealt with to remove any malleability issues and the block size would need to, in my opinion, become entirely dynamic - something like how CryptoNote defines it.

@_date: 2017-10-08 02:41:09
@_author: George Violaris 
@_subject: Distributed Tweet 
Let Julian Assange know about this, he was saying earlier on Twitter that he was looking for a decentralized form of Twitter

@_date: 2017-10-08 12:14:26
@_author: George Violaris 
@_subject: Bypassing Intel Boot Guard, EdDSA 
This is exceptional work, I am looking forward to loading it on Arduino. Did you use a specific Arduino image by the way?

@_date: 2017-10-08 17:33:30
@_author: George Violaris 
@_subject: Timelock encryption 
Some interesting reading regarding timelock encryption. Given crypto breakthroughs through cryptocurrency and smart contracts, it is interesting to be able to apply such techniques in fields such as insurance, bonds, trading, etc.
The big issue up to now with these is that a trusted third party, e.g, a server, was required to keep track. However now with bitcoin and blockchain technologies, this kind of research is starting to change.
Gwern.net - Self-Decrypting Files: Rabin & Thorpe - Time-Lapse Cryptogrpahy:  / Tibor Jager - How to Build Time-Lock Encryption: Jia Liu and Saqib A. Kakvi and Bogdan Warinschi - Extractable Witness Encryption and Timed-Release Encryption from Bitcoin

@_date: 2017-10-08 18:55:16
@_author: George Violaris 
@_subject: Cryptocurrency Privacy: Evolving... Zerocash (ZEC, ZCL, ZEN) vs 
I believe you were the first person to actually point this out to Satoshi. He replied by saying that 100GB per day is required to be processed every day by full nodes. However I am confused by his explanation of server farms. Wouldn't at one point result to a small number of full nodes due to costs? Isn't that preventive of decentralization? I fail to understand how Satoshi would think that the entire world can connect to let's say 50 worldwide server farms and this would somehow scale and be considered decentralized. The point of decentralization is that everyone can verify all transactions. This is done by verifying each transaction against all transactions back to genesis by yourself, not by trusting 50 centralized For all we can know, in 20 years from now only banking institutions will have the capital and benefit of running full nodes.

@_date: 2017-10-10 08:33:06
@_author: George Violaris 
@_subject: Timelock encryption 
Peter Todd did some coding on this concept, based on Gwern's explanation of self-decrypting files.

@_date: 2017-10-10 09:00:20
@_author: George Violaris 
@_subject: "the Jim Bell effect" on Bitcoin price 
Sorry for being irrelevant, does Jim Bell have a website? I've considered him an extraordinary individual but never found him on the internet (except these lists of course)

@_date: 2017-10-10 11:00:59
@_author: George Violaris 
@_subject: "the Jim Bell effect" on Bitcoin price 
Get off Facebook... full of shilling, lies and shallow minds. Have you tried Steemit?

@_date: 2017-10-23 15:56:59
@_author: George Violaris 
@_subject: Decoding Simon and Speck: Block Ciphers for the Internet of Things 
I wonder what the real story behind Jacob Appelbaum and Tor is. Is Jacob a member of this list? Maybe he can give us some insight as to what actually goes on in Tor. Maybe it's time to use alternatives.

@_date: 2017-10-27 22:01:35
@_author: George Violaris 
@_subject: Graph theory question 
What if you only have two good connections but each of your two connections have 3+ connections - how would good peers with only two connections be able to gain reputation in such a system? i.e. if the connections can be laterally traversed in order to reach any connected node, how would the other nodes be able to know if a peer is honest or if it has been spoofed?
I believe this is actually how the recent ransomware spread in networks. They use systems that trust other systems. In order to prevent such attacks, the networking protocols need to be amended. An additional negotiation sublayer can be created which asks the other peer a question only they can know the answer to. This can be something such as encrypting all connections at the tcp/ip level, or applying something like proof of work to make it uneconomical for sybils (but this actually only solves the issue in a probabilistic way).
