
@_date: 2013-05-08 19:45:15
@_author: Riad S. Wahby 
@_subject: (test, please ignore) 
I suspect something is haywire. Please ignore this message.

@_date: 2013-11-28 15:19:44
@_author: Riad S. Wahby 
@_subject: bitcoin as a global medium of exchange 
Interesting to see this mentioned here. Mike Walfish and Andrew Blumberg
have written a nice survey on the work in this area:
    Justin Thaler provides another perspective:
    I can also add a little context to this conversation---I've actually
done an independent re-implementation of the work of Ben-Sasson et al
that Sean linked above.
At a high level, my take is that this area has huge potential, but
neither this work nor other projects in the area (summarized below) are
really practical---yet. The overhead for the party constructing the
proof is at least 3 orders of magnitude more than the cost of running
the computation directly. The work of Ben-Sasson et al costs more like 6
orders of magnitude! (In principle, though, they are paying this price
to achieve greater computational generality.)
The work required of the party verifying the computation is also non-trivial: while *checking* the answer is quick, these systems (with
one exception) require pre-processing work on the computation being
verified, and the cost of this is several orders of magnitude larger
than simply computing the result directly. (Note, however, that this
cost can be amortized by outsourcing the same computation over many
different inputs.)
But there is some real hope here: the rate at which progress is being
made is impressive (two years ago overhead was more like 20 orders of
magnitude than three!), and there are contexts where the extra work is
worth the cost. Perhaps one of these is a cryptocurrency that relies on
proof of "useful" work.
With regard to smooth difficulty adjustment: since the goal of most of
these projects is to encode arbitrary computations, the problems of
difficulty adjustment and proof of work become orthogonal.
For those wanting a bit more detail:
Broadly speaking, there are four research groups working on this stuff:
  - Ben-Sasson et al at Technion/Tel Aviv/MIT
          - Parno et al at Microsoft Research
          - Thaler et al at Harvard
          - Walfish et al at UT Austin/NYU (full disclosure: I work with these guys)
        The work of Thaler et al is somehat distinct from the other three
because, while it is extremely efficient for certain computations,
it is not general: the efficiency improvements it offers are limited
to computations with a regular underlying structure. However, when
this requirement is met, it has very low overhead compared to the
other three systems, and it involves no costly pre-processing.
The three other groups have built systems that compile from a subset of C to a form whose result can be encoded into a probabilistically
checkable proof. The resulting PCP is huge, so in all three systems the
result is not the proof itself. Rather, the proof is queried and the
result used for verification. The method of querying is one
distinguishing factor between these systems.
Ben-Sasson et al and Parno et al share common ancestry in the work of
Gennaro et al, also at Microsoft Research.
    In both cases, the query/response take the form of a noninteractive
argument. Basically, the queries are encrypted and bundled into the
description of the computation ahead of time, after which the
computation can be run by providing an input and requesting an answer.
These systems also support public verifiability, allowing the answer to
be checked by anyone holding the public verification key.
The work of Ben-Sasson et al achieves more generality by encoding
computations as the execution of a virtual microprocessor, then
verifying correct execution of the processor. This system supports full C semantics and achieves an efficient abstraction for verified RAM
(again, at a penalty of 3 *additional* orders of magnitude beyond the
other systems).
The UT/NYU group have also adapted a simplification of Gennaro et al,
but their system really rests upon refinements of the efficient argument
systems of Ishai et al.
    In this case, verification involves two separate interactions, one that
establishes a commitment to the proof and one that queries it. Though it
requires interaction, the advantage of this approach is that it is
cryptographically simpler. Concretely, the crypto is one of the most
expensive parts of the system, so this simplification results in good
performance relative to the other systems.
The UT/NYU group have also developed verifiable storage abstractions,
including the ability to verify computations (in zero knowledge) on
hidden state for which you hold a cryptographic commitment.

@_date: 2013-11-28 15:19:44
@_author: Riad S. Wahby 
@_subject: bitcoin as a global medium of exchange 
Interesting to see this mentioned here. Mike Walfish and Andrew Blumberg
have written a nice survey on the work in this area:
    Justin Thaler provides another perspective:
    I can also add a little context to this conversation---I've actually
done an independent re-implementation of the work of Ben-Sasson et al
that Sean linked above.
At a high level, my take is that this area has huge potential, but
neither this work nor other projects in the area (summarized below) are
really practical---yet. The overhead for the party constructing the
proof is at least 3 orders of magnitude more than the cost of running
the computation directly. The work of Ben-Sasson et al costs more like 6
orders of magnitude! (In principle, though, they are paying this price
to achieve greater computational generality.)
The work required of the party verifying the computation is also non-trivial: while *checking* the answer is quick, these systems (with
one exception) require pre-processing work on the computation being
verified, and the cost of this is several orders of magnitude larger
than simply computing the result directly. (Note, however, that this
cost can be amortized by outsourcing the same computation over many
different inputs.)
But there is some real hope here: the rate at which progress is being
made is impressive (two years ago overhead was more like 20 orders of
magnitude than three!), and there are contexts where the extra work is
worth the cost. Perhaps one of these is a cryptocurrency that relies on
proof of "useful" work.
With regard to smooth difficulty adjustment: since the goal of most of
these projects is to encode arbitrary computations, the problems of
difficulty adjustment and proof of work become orthogonal.
For those wanting a bit more detail:
Broadly speaking, there are four research groups working on this stuff:
  - Ben-Sasson et al at Technion/Tel Aviv/MIT
          - Parno et al at Microsoft Research
          - Thaler et al at Harvard
          - Walfish et al at UT Austin/NYU (full disclosure: I work with these guys)
        The work of Thaler et al is somehat distinct from the other three
because, while it is extremely efficient for certain computations,
it is not general: the efficiency improvements it offers are limited
to computations with a regular underlying structure. However, when
this requirement is met, it has very low overhead compared to the
other three systems, and it involves no costly pre-processing.
The three other groups have built systems that compile from a subset of C to a form whose result can be encoded into a probabilistically
checkable proof. The resulting PCP is huge, so in all three systems the
result is not the proof itself. Rather, the proof is queried and the
result used for verification. The method of querying is one
distinguishing factor between these systems.
Ben-Sasson et al and Parno et al share common ancestry in the work of
Gennaro et al, also at Microsoft Research.
    In both cases, the query/response take the form of a noninteractive
argument. Basically, the queries are encrypted and bundled into the
description of the computation ahead of time, after which the
computation can be run by providing an input and requesting an answer.
These systems also support public verifiability, allowing the answer to
be checked by anyone holding the public verification key.
The work of Ben-Sasson et al achieves more generality by encoding
computations as the execution of a virtual microprocessor, then
verifying correct execution of the processor. This system supports full C semantics and achieves an efficient abstraction for verified RAM
(again, at a penalty of 3 *additional* orders of magnitude beyond the
other systems).
The UT/NYU group have also adapted a simplification of Gennaro et al,
but their system really rests upon refinements of the efficient argument
systems of Ishai et al.
    In this case, verification involves two separate interactions, one that
establishes a commitment to the proof and one that queries it. Though it
requires interaction, the advantage of this approach is that it is
cryptographically simpler. Concretely, the crypto is one of the most
expensive parts of the system, so this simplification results in good
performance relative to the other systems.
The UT/NYU group have also developed verifiable storage abstractions,
including the ability to verify computations (in zero knowledge) on
hidden state for which you hold a cryptographic commitment.

@_date: 2013-11-28 15:19:44
@_author: Riad S. Wahby 
@_subject: bitcoin as a global medium of exchange 
Interesting to see this mentioned here. Mike Walfish and Andrew Blumberg
have written a nice survey on the work in this area:
    Justin Thaler provides another perspective:
    I can also add a little context to this conversation---I've actually
done an independent re-implementation of the work of Ben-Sasson et al
that Sean linked above.
At a high level, my take is that this area has huge potential, but
neither this work nor other projects in the area (summarized below) are
really practical---yet. The overhead for the party constructing the
proof is at least 3 orders of magnitude more than the cost of running
the computation directly. The work of Ben-Sasson et al costs more like 6
orders of magnitude! (In principle, though, they are paying this price
to achieve greater computational generality.)
The work required of the party verifying the computation is also non-trivial: while *checking* the answer is quick, these systems (with
one exception) require pre-processing work on the computation being
verified, and the cost of this is several orders of magnitude larger
than simply computing the result directly. (Note, however, that this
cost can be amortized by outsourcing the same computation over many
different inputs.)
But there is some real hope here: the rate at which progress is being
made is impressive (two years ago overhead was more like 20 orders of
magnitude than three!), and there are contexts where the extra work is
worth the cost. Perhaps one of these is a cryptocurrency that relies on
proof of "useful" work.
With regard to smooth difficulty adjustment: since the goal of most of
these projects is to encode arbitrary computations, the problems of
difficulty adjustment and proof of work become orthogonal.
For those wanting a bit more detail:
Broadly speaking, there are four research groups working on this stuff:
  - Ben-Sasson et al at Technion/Tel Aviv/MIT
          - Parno et al at Microsoft Research
          - Thaler et al at Harvard
          - Walfish et al at UT Austin/NYU (full disclosure: I work with these guys)
        The work of Thaler et al is somehat distinct from the other three
because, while it is extremely efficient for certain computations,
it is not general: the efficiency improvements it offers are limited
to computations with a regular underlying structure. However, when
this requirement is met, it has very low overhead compared to the
other three systems, and it involves no costly pre-processing.
The three other groups have built systems that compile from a subset of C to a form whose result can be encoded into a probabilistically
checkable proof. The resulting PCP is huge, so in all three systems the
result is not the proof itself. Rather, the proof is queried and the
result used for verification. The method of querying is one
distinguishing factor between these systems.
Ben-Sasson et al and Parno et al share common ancestry in the work of
Gennaro et al, also at Microsoft Research.
    In both cases, the query/response take the form of a noninteractive
argument. Basically, the queries are encrypted and bundled into the
description of the computation ahead of time, after which the
computation can be run by providing an input and requesting an answer.
These systems also support public verifiability, allowing the answer to
be checked by anyone holding the public verification key.
The work of Ben-Sasson et al achieves more generality by encoding
computations as the execution of a virtual microprocessor, then
verifying correct execution of the processor. This system supports full C semantics and achieves an efficient abstraction for verified RAM
(again, at a penalty of 3 *additional* orders of magnitude beyond the
other systems).
The UT/NYU group have also adapted a simplification of Gennaro et al,
but their system really rests upon refinements of the efficient argument
systems of Ishai et al.
    In this case, verification involves two separate interactions, one that
establishes a commitment to the proof and one that queries it. Though it
requires interaction, the advantage of this approach is that it is
cryptographically simpler. Concretely, the crypto is one of the most
expensive parts of the system, so this simplification results in good
performance relative to the other systems.
The UT/NYU group have also developed verifiable storage abstractions,
including the ability to verify computations (in zero knowledge) on
hidden state for which you hold a cryptographic commitment.

@_date: 2014-08-12 22:30:22
@_author: Riad S. Wahby 
@_subject: SSL cert expired for cpunks.org 
Sorry about that---got busy and lost track of it. I'll get it fixed in
the next day or two.
Thanks for the heads-up (and the kind offer),

@_date: 2014-08-12 22:30:22
@_author: Riad S. Wahby 
@_subject: SSL cert expired for cpunks.org 
Sorry about that---got busy and lost track of it. I'll get it fixed in
the next day or two.
Thanks for the heads-up (and the kind offer),

@_date: 2014-08-12 22:30:22
@_author: Riad S. Wahby 
@_subject: SSL cert expired for cpunks.org 
Sorry about that---got busy and lost track of it. I'll get it fixed in
the next day or two.
Thanks for the heads-up (and the kind offer),

@_date: 2014-02-12 14:52:34
@_author: Riad S. Wahby 
@_subject: Snowden and Compilers 
Way before 2010. Couple buddies of mine built a backdoor into a network
card circa 2003. Ditto a SCSI card, loading via the BIOS at boot and
injecting itself in several stages via the bootloader into the kernel.

@_date: 2014-02-12 14:52:34
@_author: Riad S. Wahby 
@_subject: Snowden and Compilers 
Way before 2010. Couple buddies of mine built a backdoor into a network
card circa 2003. Ditto a SCSI card, loading via the BIOS at boot and
injecting itself in several stages via the bootloader into the kernel.

@_date: 2014-02-12 14:52:34
@_author: Riad S. Wahby 
@_subject: Snowden and Compilers 
Way before 2010. Couple buddies of mine built a backdoor into a network
card circa 2003. Ditto a SCSI card, loading via the BIOS at boot and
injecting itself in several stages via the bootloader into the kernel.

@_date: 2014-01-19 12:09:18
@_author: Riad S. Wahby 
@_subject: anonymous remailer whitelisting 
I received an anonymous request to expand the whitelist for remailers.
Requester: thank you for keeping me honest! I have updated the list.

@_date: 2014-01-19 13:15:07
@_author: Riad S. Wahby 
@_subject: [OT] Note to new-ish subscribers: you joined a mailing list, not 
is deprecated. Apologies: I should have announced this
on-list before I made the related configuration changes.
In case anyone suspects censorship, chilling effects, et cetera, the
explanation is actually much more innocuous: I'm trying to cut down the
amount of spam my poor little VPS has to handle, and as you might
imagine the amount that goes to  is *staggering*.
(More to the point, after running the list  for more than
ten years, this small gesture isn't going to somehow erase the
internet's long memory.)

@_date: 2014-01-20 12:48:42
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
It was around 2005 that the last few nodes dropped off the old CDR, so
it's been quite a while since we've been distributed.
I went back through the list archives late last year in search of the
history of the CDR. While I'm sure others can add more to the skeleton,
what I found went into the Cypherpunk Wikipedia entry (with references
to archived emails where possible).
To be honest, I'm not sure distribution is a response to any real
threat: to the extent that the Cpunks list is of interest, isn't it more
sensible to keep it alive and monitored than to shut it down? Of course,
as J.A. points out, there are plenty of other reasons, viz., different
list policies at different nodes (reply-to:, subject modification,
sender whitelisting, etc.)---and these create some problems that we'll
have to address in designing CDRv2.
So let's talk a bit about the CDR architecture.
One obvious issue with the old one is that it was a bit rickety: at its
heart it was a bandaid fractal built on top of procmail and Majordomo,
and getting it set up took enough work that most people didn't want to
do it. To this end, I suggest we build upon mailman this time around:
the codebase is reasonably well maintained, plenty of people feel
comfortable hacking in Python, and we automatically get more user
friendliness in the subscriber and administrative interfaces.
(In principle, an even better way to do this would be to cleanly
separate the CDR functionality from the list management functionality so
that individual nodes can decide on their own what list software to run.
This probably ends up expanding the time cost of the project well in
excess of the utility it generates, so my vote would be against making
this a requirement.)
One major question we need to address is the topology of the CDR network
itself. From an implementation point of view it would be most
straightforward if every node knew about every other node, but one could
argue that this is too fragile. If we take that position, we have to
solve a broadcast repeater problem: when a node receives a message, it
needs to have some way of deciding what other nodes it forwards messages
to. Obviously we'd like to do this in a way that doesn't result in a lot
of useless echoes. (Recognizing that perfect is the enemy of good may be
the better part of valor here; after all, we don't expect to have more
than a handful of CDR nodes.)
As before, we want to be able to have independent policies at each node
at least with respect to:
    - subject line modification
    - header mangling (reply-to: etc)
    - attachments
    - sender whitelisting
    - other things I'm forgetting
As far as I can tell, the ones that will require the most work are
subject line modification and sender whitelisting.
Mangling the subject line becomes a problem because eventually we end up
with subjects like "[CDR] Re: [Cpunks] Re: [Cypherpunks] foo", which
confuses a lot of mail clients. This isn't a problem for monolithic
mailman setups because mailman knows not to add another prefix to
outgoing messages that already have one, but the problem becomes more
difficult when each node potentially has its own (possibly empty)
prefix. This problem would have a trivial solution in the case that all
nodes knew the tagging policy at all other nodes, but (as I point out
above) we may prefer not to require nodes to know all other nodes in the
CDR. (The fallback solution is the old one: manually construct an
appropriate filter to demangle subject lines. Yech.)
In the old CDR (possibly after the LNE.com modifications circa 2001),
nodes had to expose their sender lists (at least to other nodes) to
allow for member whitelisting. Obviously this is ripe for abuse, and I'd
prefer to achieve this in a different way if possible. The goal here is
to make it easy to verify that a given sender is subscribed to *some*
node but difficult to enumerate all list subscribers. I can see how one
might think of this as coddling the supposedly savvy and internet-
hardened subscribers of the list, but I just don't see any reason to
expose users to more abuse than necessary, especially when solutions to
this problem have already been described and are nominally right in the
cpunks wheelhouse!
I have a skeleton architecture in mind that can be beaten into a shape
capable of addressing the above issues, but as this email is getting
long and I've doubtless forgotten several other important problems,
let's discuss a bit more first.

@_date: 2014-01-20 12:58:21
@_author: Riad S. Wahby 
@_subject: Welcome to the Asylum! 
And a poor one indeed :)
Lest anyone misinterpret the quotes, I assure you I do nothing of the
sort. The *only* filtering that goes on is subscriber whitelisting.
I've been subscribed to cpunks in one form or other since the early 90s,
and thinking back to those days makes the worries about SNR on the list
now seem like nothing. By my recollection it wasn't until circa 2001
that any of the distributed remailer nodes even had sender whitelisting;
even with the worst flaming the SNR now is an order of magnitude better
than what we'd get prior to Ericm's LNE.com node.

@_date: 2014-01-20 14:44:15
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
As far as I can tell this doesn't (yet) solve the problem of
whitelisting subscribers to other nodes.
However, we can add one more step and solve this: when a node receives
an email from the repeater whose sender is a member of the node's local
subscriber list, it bounces the message back to the repeater with an
added header saying, in effect, "I vouch for this sender."
Other nodes employing sender whitelisting would ignore the first email,
since its sender isn't locally whitelisted and it lacks the
aforementioned node-auth header, but would presumably forward the second
email, assuming they chose to trust the node that is vouching for the
sender. Nodes with no whitelisting policy could safely ignore the second
email by filtering out duplicate msgids or something similar.
I'm not totally in love with the master repeater scheme, though.
Notwithstanding my previous comments regarding the supposed threat model
behind the CDR's original conception, as long as we're paying the fixed
cost of setting up a new system we may as well get *some* additional
reliability out of it, right?

@_date: 2014-01-20 16:46:34
@_author: Riad S. Wahby 
@_subject: anonymous remailer whitelisting 
I received another query regarding remailer whitelisting; it seems that
some dropping may still be going on. I will double check the logs later
tonight to be sure that such messages are actually getting through, and
post any findings.

@_date: 2014-01-24 22:07:29
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
In CDRv1, all nodes would in principle forward all messages to other
nodes, only filtering the feed going to that node's own users according
to the local filtering policy.
It makes sense to ask nodes to publish details of their local policies.
I think personally I would hesitate to peer with any node that didn't
forward everything and let me apply my own filter. I assume most other
operators would as well, so practically speaking no one would run a node
that didn't (claim to) forward everything.
Next question: how paranoid are we, i.e., do we attempt to enforce this
policy somehow? This goes beyond fault tolerance towards attempting to
solve the problem of enforcing peering contracts with untrusted CDRv2
nodes, which is clearly a more... intersting one.
I have been busy with real life, and haven't dedicated much more time to
thinking about this. I'm hopeful that tomorrow I will have the
opportunity to do so at least a little bit.

@_date: 2014-01-25 20:04:44
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
I'm not sure if you mean on the backend (between nodes) or on the
frontend (local delivery to node subscribers).
In the former case, I agree: it makes sense to just have a blanket
policy that peered nodes are expected to forward everything they receive
at their ingress address (allowing other nodes to apply their own local
filtering policies).
If you mean the latter, I disagree that zero filtering is a good
approach to running a node (but the whole point is that we can make both
available and let the users choose). In practice, I'm quite certain that
readership on the present cypherpunks envisagement would drop
precipitously if I turned off sender whitelisting. There's a difference
between "I can do this" and "I will do this because it is worth my
time." The fact is, once the cost of being a subscriber exceeds its
utility, a rational person will unsubscribe; a node with sender
whitelisting (with explicit whitelisting for anonymous remailers)
achieves a balance that, empirically, is worthwhile for most people:
recall the rush to LNE.com when Eric introduced this. More to the point,
the willingness of a person to sink time into wading through list
detritus is no indication of his or her value as a contributor.
Fundamentally, subscriber lists are a good metric by which to judge
whether a particular message should or should not be delivered; it is
therefore useful to build the notion of cross-node sender whitelisting
into CDRv2 in a way that cannot be trivially abused. Of course, all
sender whitelisting leaks *some* information about subscribers; the goal
is just to do no worse than a monolithic list.
No doubt about it; I'm certainly not volunteering to do any such thing!

@_date: 2014-01-27 00:49:38
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
I'm nailing down a few last details of a proposed CDRv2 architecture.
I'll follow up with details tomorrow evening-ish and then we can beat up
on it a bit.

@_date: 2014-01-27 09:53:44
@_author: Riad S. Wahby 
@_subject: Good books on algorithm design? 
All the books you've been recommended so far are good ones.
Another to consider is Skiena's Algorithm Design Manual. Note, however,
that its focus leans toward application over theory.

@_date: 2014-01-28 00:45:41
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
As proposed, a description of my proposed architecture. I actually have
a bit more of the details worked out in my head already, but let's
start here.

@_date: 2014-01-19 12:09:18
@_author: Riad S. Wahby 
@_subject: anonymous remailer whitelisting 
I received an anonymous request to expand the whitelist for remailers.
Requester: thank you for keeping me honest! I have updated the list.

@_date: 2014-01-19 13:15:07
@_author: Riad S. Wahby 
@_subject: [OT] Note to new-ish subscribers: you joined a mailing list, not 
is deprecated. Apologies: I should have announced this
on-list before I made the related configuration changes.
In case anyone suspects censorship, chilling effects, et cetera, the
explanation is actually much more innocuous: I'm trying to cut down the
amount of spam my poor little VPS has to handle, and as you might
imagine the amount that goes to  is *staggering*.
(More to the point, after running the list  for more than
ten years, this small gesture isn't going to somehow erase the
internet's long memory.)

@_date: 2014-01-20 12:48:42
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
It was around 2005 that the last few nodes dropped off the old CDR, so
it's been quite a while since we've been distributed.
I went back through the list archives late last year in search of the
history of the CDR. While I'm sure others can add more to the skeleton,
what I found went into the Cypherpunk Wikipedia entry (with references
to archived emails where possible).
To be honest, I'm not sure distribution is a response to any real
threat: to the extent that the Cpunks list is of interest, isn't it more
sensible to keep it alive and monitored than to shut it down? Of course,
as J.A. points out, there are plenty of other reasons, viz., different
list policies at different nodes (reply-to:, subject modification,
sender whitelisting, etc.)---and these create some problems that we'll
have to address in designing CDRv2.
So let's talk a bit about the CDR architecture.
One obvious issue with the old one is that it was a bit rickety: at its
heart it was a bandaid fractal built on top of procmail and Majordomo,
and getting it set up took enough work that most people didn't want to
do it. To this end, I suggest we build upon mailman this time around:
the codebase is reasonably well maintained, plenty of people feel
comfortable hacking in Python, and we automatically get more user
friendliness in the subscriber and administrative interfaces.
(In principle, an even better way to do this would be to cleanly
separate the CDR functionality from the list management functionality so
that individual nodes can decide on their own what list software to run.
This probably ends up expanding the time cost of the project well in
excess of the utility it generates, so my vote would be against making
this a requirement.)
One major question we need to address is the topology of the CDR network
itself. From an implementation point of view it would be most
straightforward if every node knew about every other node, but one could
argue that this is too fragile. If we take that position, we have to
solve a broadcast repeater problem: when a node receives a message, it
needs to have some way of deciding what other nodes it forwards messages
to. Obviously we'd like to do this in a way that doesn't result in a lot
of useless echoes. (Recognizing that perfect is the enemy of good may be
the better part of valor here; after all, we don't expect to have more
than a handful of CDR nodes.)
As before, we want to be able to have independent policies at each node
at least with respect to:
    - subject line modification
    - header mangling (reply-to: etc)
    - attachments
    - sender whitelisting
    - other things I'm forgetting
As far as I can tell, the ones that will require the most work are
subject line modification and sender whitelisting.
Mangling the subject line becomes a problem because eventually we end up
with subjects like "[CDR] Re: [Cpunks] Re: [Cypherpunks] foo", which
confuses a lot of mail clients. This isn't a problem for monolithic
mailman setups because mailman knows not to add another prefix to
outgoing messages that already have one, but the problem becomes more
difficult when each node potentially has its own (possibly empty)
prefix. This problem would have a trivial solution in the case that all
nodes knew the tagging policy at all other nodes, but (as I point out
above) we may prefer not to require nodes to know all other nodes in the
CDR. (The fallback solution is the old one: manually construct an
appropriate filter to demangle subject lines. Yech.)
In the old CDR (possibly after the LNE.com modifications circa 2001),
nodes had to expose their sender lists (at least to other nodes) to
allow for member whitelisting. Obviously this is ripe for abuse, and I'd
prefer to achieve this in a different way if possible. The goal here is
to make it easy to verify that a given sender is subscribed to *some*
node but difficult to enumerate all list subscribers. I can see how one
might think of this as coddling the supposedly savvy and internet-
hardened subscribers of the list, but I just don't see any reason to
expose users to more abuse than necessary, especially when solutions to
this problem have already been described and are nominally right in the
cpunks wheelhouse!
I have a skeleton architecture in mind that can be beaten into a shape
capable of addressing the above issues, but as this email is getting
long and I've doubtless forgotten several other important problems,
let's discuss a bit more first.

@_date: 2014-01-20 12:58:21
@_author: Riad S. Wahby 
@_subject: Welcome to the Asylum! 
And a poor one indeed :)
Lest anyone misinterpret the quotes, I assure you I do nothing of the
sort. The *only* filtering that goes on is subscriber whitelisting.
I've been subscribed to cpunks in one form or other since the early 90s,
and thinking back to those days makes the worries about SNR on the list
now seem like nothing. By my recollection it wasn't until circa 2001
that any of the distributed remailer nodes even had sender whitelisting;
even with the worst flaming the SNR now is an order of magnitude better
than what we'd get prior to Ericm's LNE.com node.

@_date: 2014-01-20 14:44:15
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
As far as I can tell this doesn't (yet) solve the problem of
whitelisting subscribers to other nodes.
However, we can add one more step and solve this: when a node receives
an email from the repeater whose sender is a member of the node's local
subscriber list, it bounces the message back to the repeater with an
added header saying, in effect, "I vouch for this sender."
Other nodes employing sender whitelisting would ignore the first email,
since its sender isn't locally whitelisted and it lacks the
aforementioned node-auth header, but would presumably forward the second
email, assuming they chose to trust the node that is vouching for the
sender. Nodes with no whitelisting policy could safely ignore the second
email by filtering out duplicate msgids or something similar.
I'm not totally in love with the master repeater scheme, though.
Notwithstanding my previous comments regarding the supposed threat model
behind the CDR's original conception, as long as we're paying the fixed
cost of setting up a new system we may as well get *some* additional
reliability out of it, right?

@_date: 2014-01-20 16:46:34
@_author: Riad S. Wahby 
@_subject: anonymous remailer whitelisting 
I received another query regarding remailer whitelisting; it seems that
some dropping may still be going on. I will double check the logs later
tonight to be sure that such messages are actually getting through, and
post any findings.

@_date: 2014-01-24 22:07:29
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
In CDRv1, all nodes would in principle forward all messages to other
nodes, only filtering the feed going to that node's own users according
to the local filtering policy.
It makes sense to ask nodes to publish details of their local policies.
I think personally I would hesitate to peer with any node that didn't
forward everything and let me apply my own filter. I assume most other
operators would as well, so practically speaking no one would run a node
that didn't (claim to) forward everything.
Next question: how paranoid are we, i.e., do we attempt to enforce this
policy somehow? This goes beyond fault tolerance towards attempting to
solve the problem of enforcing peering contracts with untrusted CDRv2
nodes, which is clearly a more... intersting one.
I have been busy with real life, and haven't dedicated much more time to
thinking about this. I'm hopeful that tomorrow I will have the
opportunity to do so at least a little bit.

@_date: 2014-01-25 20:04:44
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
I'm not sure if you mean on the backend (between nodes) or on the
frontend (local delivery to node subscribers).
In the former case, I agree: it makes sense to just have a blanket
policy that peered nodes are expected to forward everything they receive
at their ingress address (allowing other nodes to apply their own local
filtering policies).
If you mean the latter, I disagree that zero filtering is a good
approach to running a node (but the whole point is that we can make both
available and let the users choose). In practice, I'm quite certain that
readership on the present cypherpunks envisagement would drop
precipitously if I turned off sender whitelisting. There's a difference
between "I can do this" and "I will do this because it is worth my
time." The fact is, once the cost of being a subscriber exceeds its
utility, a rational person will unsubscribe; a node with sender
whitelisting (with explicit whitelisting for anonymous remailers)
achieves a balance that, empirically, is worthwhile for most people:
recall the rush to LNE.com when Eric introduced this. More to the point,
the willingness of a person to sink time into wading through list
detritus is no indication of his or her value as a contributor.
Fundamentally, subscriber lists are a good metric by which to judge
whether a particular message should or should not be delivered; it is
therefore useful to build the notion of cross-node sender whitelisting
into CDRv2 in a way that cannot be trivially abused. Of course, all
sender whitelisting leaks *some* information about subscribers; the goal
is just to do no worse than a monolithic list.
No doubt about it; I'm certainly not volunteering to do any such thing!

@_date: 2014-01-27 00:49:38
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
I'm nailing down a few last details of a proposed CDRv2 architecture.
I'll follow up with details tomorrow evening-ish and then we can beat up
on it a bit.

@_date: 2014-01-27 09:53:44
@_author: Riad S. Wahby 
@_subject: Good books on algorithm design? 
All the books you've been recommended so far are good ones.
Another to consider is Skiena's Algorithm Design Manual. Note, however,
that its focus leans toward application over theory.

@_date: 2014-01-28 00:45:41
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
As proposed, a description of my proposed architecture. I actually have
a bit more of the details worked out in my head already, but let's
start here.

@_date: 2014-01-19 12:09:18
@_author: Riad S. Wahby 
@_subject: anonymous remailer whitelisting 
I received an anonymous request to expand the whitelist for remailers.
Requester: thank you for keeping me honest! I have updated the list.

@_date: 2014-01-19 13:15:07
@_author: Riad S. Wahby 
@_subject: [OT] Note to new-ish subscribers: you joined a mailing list, not 
is deprecated. Apologies: I should have announced this
on-list before I made the related configuration changes.
In case anyone suspects censorship, chilling effects, et cetera, the
explanation is actually much more innocuous: I'm trying to cut down the
amount of spam my poor little VPS has to handle, and as you might
imagine the amount that goes to  is *staggering*.
(More to the point, after running the list  for more than
ten years, this small gesture isn't going to somehow erase the
internet's long memory.)

@_date: 2014-01-20 12:48:42
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
It was around 2005 that the last few nodes dropped off the old CDR, so
it's been quite a while since we've been distributed.
I went back through the list archives late last year in search of the
history of the CDR. While I'm sure others can add more to the skeleton,
what I found went into the Cypherpunk Wikipedia entry (with references
to archived emails where possible).
To be honest, I'm not sure distribution is a response to any real
threat: to the extent that the Cpunks list is of interest, isn't it more
sensible to keep it alive and monitored than to shut it down? Of course,
as J.A. points out, there are plenty of other reasons, viz., different
list policies at different nodes (reply-to:, subject modification,
sender whitelisting, etc.)---and these create some problems that we'll
have to address in designing CDRv2.
So let's talk a bit about the CDR architecture.
One obvious issue with the old one is that it was a bit rickety: at its
heart it was a bandaid fractal built on top of procmail and Majordomo,
and getting it set up took enough work that most people didn't want to
do it. To this end, I suggest we build upon mailman this time around:
the codebase is reasonably well maintained, plenty of people feel
comfortable hacking in Python, and we automatically get more user
friendliness in the subscriber and administrative interfaces.
(In principle, an even better way to do this would be to cleanly
separate the CDR functionality from the list management functionality so
that individual nodes can decide on their own what list software to run.
This probably ends up expanding the time cost of the project well in
excess of the utility it generates, so my vote would be against making
this a requirement.)
One major question we need to address is the topology of the CDR network
itself. From an implementation point of view it would be most
straightforward if every node knew about every other node, but one could
argue that this is too fragile. If we take that position, we have to
solve a broadcast repeater problem: when a node receives a message, it
needs to have some way of deciding what other nodes it forwards messages
to. Obviously we'd like to do this in a way that doesn't result in a lot
of useless echoes. (Recognizing that perfect is the enemy of good may be
the better part of valor here; after all, we don't expect to have more
than a handful of CDR nodes.)
As before, we want to be able to have independent policies at each node
at least with respect to:
    - subject line modification
    - header mangling (reply-to: etc)
    - attachments
    - sender whitelisting
    - other things I'm forgetting
As far as I can tell, the ones that will require the most work are
subject line modification and sender whitelisting.
Mangling the subject line becomes a problem because eventually we end up
with subjects like "[CDR] Re: [Cpunks] Re: [Cypherpunks] foo", which
confuses a lot of mail clients. This isn't a problem for monolithic
mailman setups because mailman knows not to add another prefix to
outgoing messages that already have one, but the problem becomes more
difficult when each node potentially has its own (possibly empty)
prefix. This problem would have a trivial solution in the case that all
nodes knew the tagging policy at all other nodes, but (as I point out
above) we may prefer not to require nodes to know all other nodes in the
CDR. (The fallback solution is the old one: manually construct an
appropriate filter to demangle subject lines. Yech.)
In the old CDR (possibly after the LNE.com modifications circa 2001),
nodes had to expose their sender lists (at least to other nodes) to
allow for member whitelisting. Obviously this is ripe for abuse, and I'd
prefer to achieve this in a different way if possible. The goal here is
to make it easy to verify that a given sender is subscribed to *some*
node but difficult to enumerate all list subscribers. I can see how one
might think of this as coddling the supposedly savvy and internet-
hardened subscribers of the list, but I just don't see any reason to
expose users to more abuse than necessary, especially when solutions to
this problem have already been described and are nominally right in the
cpunks wheelhouse!
I have a skeleton architecture in mind that can be beaten into a shape
capable of addressing the above issues, but as this email is getting
long and I've doubtless forgotten several other important problems,
let's discuss a bit more first.

@_date: 2014-01-20 12:58:21
@_author: Riad S. Wahby 
@_subject: Welcome to the Asylum! 
And a poor one indeed :)
Lest anyone misinterpret the quotes, I assure you I do nothing of the
sort. The *only* filtering that goes on is subscriber whitelisting.
I've been subscribed to cpunks in one form or other since the early 90s,
and thinking back to those days makes the worries about SNR on the list
now seem like nothing. By my recollection it wasn't until circa 2001
that any of the distributed remailer nodes even had sender whitelisting;
even with the worst flaming the SNR now is an order of magnitude better
than what we'd get prior to Ericm's LNE.com node.

@_date: 2014-01-20 14:44:15
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
As far as I can tell this doesn't (yet) solve the problem of
whitelisting subscribers to other nodes.
However, we can add one more step and solve this: when a node receives
an email from the repeater whose sender is a member of the node's local
subscriber list, it bounces the message back to the repeater with an
added header saying, in effect, "I vouch for this sender."
Other nodes employing sender whitelisting would ignore the first email,
since its sender isn't locally whitelisted and it lacks the
aforementioned node-auth header, but would presumably forward the second
email, assuming they chose to trust the node that is vouching for the
sender. Nodes with no whitelisting policy could safely ignore the second
email by filtering out duplicate msgids or something similar.
I'm not totally in love with the master repeater scheme, though.
Notwithstanding my previous comments regarding the supposed threat model
behind the CDR's original conception, as long as we're paying the fixed
cost of setting up a new system we may as well get *some* additional
reliability out of it, right?

@_date: 2014-01-20 16:46:34
@_author: Riad S. Wahby 
@_subject: anonymous remailer whitelisting 
I received another query regarding remailer whitelisting; it seems that
some dropping may still be going on. I will double check the logs later
tonight to be sure that such messages are actually getting through, and
post any findings.

@_date: 2014-01-24 22:07:29
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
In CDRv1, all nodes would in principle forward all messages to other
nodes, only filtering the feed going to that node's own users according
to the local filtering policy.
It makes sense to ask nodes to publish details of their local policies.
I think personally I would hesitate to peer with any node that didn't
forward everything and let me apply my own filter. I assume most other
operators would as well, so practically speaking no one would run a node
that didn't (claim to) forward everything.
Next question: how paranoid are we, i.e., do we attempt to enforce this
policy somehow? This goes beyond fault tolerance towards attempting to
solve the problem of enforcing peering contracts with untrusted CDRv2
nodes, which is clearly a more... intersting one.
I have been busy with real life, and haven't dedicated much more time to
thinking about this. I'm hopeful that tomorrow I will have the
opportunity to do so at least a little bit.

@_date: 2014-01-25 20:04:44
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
I'm not sure if you mean on the backend (between nodes) or on the
frontend (local delivery to node subscribers).
In the former case, I agree: it makes sense to just have a blanket
policy that peered nodes are expected to forward everything they receive
at their ingress address (allowing other nodes to apply their own local
filtering policies).
If you mean the latter, I disagree that zero filtering is a good
approach to running a node (but the whole point is that we can make both
available and let the users choose). In practice, I'm quite certain that
readership on the present cypherpunks envisagement would drop
precipitously if I turned off sender whitelisting. There's a difference
between "I can do this" and "I will do this because it is worth my
time." The fact is, once the cost of being a subscriber exceeds its
utility, a rational person will unsubscribe; a node with sender
whitelisting (with explicit whitelisting for anonymous remailers)
achieves a balance that, empirically, is worthwhile for most people:
recall the rush to LNE.com when Eric introduced this. More to the point,
the willingness of a person to sink time into wading through list
detritus is no indication of his or her value as a contributor.
Fundamentally, subscriber lists are a good metric by which to judge
whether a particular message should or should not be delivered; it is
therefore useful to build the notion of cross-node sender whitelisting
into CDRv2 in a way that cannot be trivially abused. Of course, all
sender whitelisting leaks *some* information about subscribers; the goal
is just to do no worse than a monolithic list.
No doubt about it; I'm certainly not volunteering to do any such thing!

@_date: 2014-01-27 00:49:38
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
I'm nailing down a few last details of a proposed CDRv2 architecture.
I'll follow up with details tomorrow evening-ish and then we can beat up
on it a bit.

@_date: 2014-01-27 09:53:44
@_author: Riad S. Wahby 
@_subject: Good books on algorithm design? 
All the books you've been recommended so far are good ones.
Another to consider is Skiena's Algorithm Design Manual. Note, however,
that its focus leans toward application over theory.

@_date: 2014-01-28 00:45:41
@_author: Riad S. Wahby 
@_subject: CDRv2 discussion (was: Re: Al-qaeda.net deprecated) 
As proposed, a description of my proposed architecture. I actually have
a bit more of the details worked out in my head already, but let's
start here.

@_date: 2014-05-14 13:18:44
@_author: Riad S. Wahby 
@_subject: cypherpunks administrivia: no more reply-to header stripping 
Until now, mailman has been stripping Reply-To: headers from messages
to the list. I've just turned this off.
Some webmail services (notably, Yahoo!) set the Reply-To: header and
include it in the headers signed with DKIM. Stripping Reply-To: thus
breaks the DKIM signature. In the case of Yahoo! this signature
breakage is especially problematic, because their DMARC policy is set
to reject. (In other words, messages with yahoo.com in the From:
header that fail both SPF and DKIM should be rejected by compliant
mail services, e.g., AOL, Gmail, Hotmail, Yahoo!)
Messages to the mailing list should pass SPF, since the envelope
sender domain for list messages is cpunks.org and I publish an
appropriate spf RR. However, any list subscriber who forwards mail to
another account will have broken SPF and an invalid DKIM signature,
which trips the DMARC policy and causes delivery failures.
I realize that this might cause some inconvenience, but I would prefer
to err on the side of successfully delivering messages whenever
possible. If you're using procmail and prefer the old behavior, the
following recipe should suffice:
* ^list-id.*cypherpunks.cpunks.org

@_date: 2014-05-14 13:18:44
@_author: Riad S. Wahby 
@_subject: cypherpunks administrivia: no more reply-to header stripping 
Until now, mailman has been stripping Reply-To: headers from messages
to the list. I've just turned this off.
Some webmail services (notably, Yahoo!) set the Reply-To: header and
include it in the headers signed with DKIM. Stripping Reply-To: thus
breaks the DKIM signature. In the case of Yahoo! this signature
breakage is especially problematic, because their DMARC policy is set
to reject. (In other words, messages with yahoo.com in the From:
header that fail both SPF and DKIM should be rejected by compliant
mail services, e.g., AOL, Gmail, Hotmail, Yahoo!)
Messages to the mailing list should pass SPF, since the envelope
sender domain for list messages is cpunks.org and I publish an
appropriate spf RR. However, any list subscriber who forwards mail to
another account will have broken SPF and an invalid DKIM signature,
which trips the DMARC policy and causes delivery failures.
I realize that this might cause some inconvenience, but I would prefer
to err on the side of successfully delivering messages whenever
possible. If you're using procmail and prefer the old behavior, the
following recipe should suffice:
* ^list-id.*cypherpunks.cpunks.org

@_date: 2014-05-14 13:18:44
@_author: Riad S. Wahby 
@_subject: cypherpunks administrivia: no more reply-to header stripping 
Until now, mailman has been stripping Reply-To: headers from messages
to the list. I've just turned this off.
Some webmail services (notably, Yahoo!) set the Reply-To: header and
include it in the headers signed with DKIM. Stripping Reply-To: thus
breaks the DKIM signature. In the case of Yahoo! this signature
breakage is especially problematic, because their DMARC policy is set
to reject. (In other words, messages with yahoo.com in the From:
header that fail both SPF and DKIM should be rejected by compliant
mail services, e.g., AOL, Gmail, Hotmail, Yahoo!)
Messages to the mailing list should pass SPF, since the envelope
sender domain for list messages is cpunks.org and I publish an
appropriate spf RR. However, any list subscriber who forwards mail to
another account will have broken SPF and an invalid DKIM signature,
which trips the DMARC policy and causes delivery failures.
I realize that this might cause some inconvenience, but I would prefer
to err on the side of successfully delivering messages whenever
possible. If you're using procmail and prefer the old behavior, the
following recipe should suffice:
* ^list-id.*cypherpunks.cpunks.org

@_date: 2014-11-14 01:25:37
@_author: Riad S. Wahby 
@_subject: List Administrivia: archive stripping 
I'm fairly certain the source material for the archives aren't
mangled, so upon turning off the relevant setting the original
appearance of messages will be restored.
Before I throw the switch, any thoughts on why we might not want to
make this change?

@_date: 2014-11-14 01:25:37
@_author: Riad S. Wahby 
@_subject: List Administrivia: archive stripping 
I'm fairly certain the source material for the archives aren't
mangled, so upon turning off the relevant setting the original
appearance of messages will be restored.
Before I throw the switch, any thoughts on why we might not want to
make this change?

@_date: 2014-11-14 01:25:37
@_author: Riad S. Wahby 
@_subject: List Administrivia: archive stripping 
I'm fairly certain the source material for the archives aren't
mangled, so upon turning off the relevant setting the original
appearance of messages will be restored.
Before I throw the switch, any thoughts on why we might not want to
make this change?

@_date: 2014-10-06 16:14:38
@_author: Riad S. Wahby 
@_subject: dhcpd dhclient-script shell security 
Note that OpenBSD's dhclient hasn't supported a client script since
late 2012. Even when it did, /bin/sh is ksh by default, so few if any
OpenBSD systems would be vulnerable to Shellshock-via-DHCP.
I realize this addresses symptoms rather than the meat of the question
regarding dhcp clients, but there is some evidence that the OpenBSD
folks were already concerned about the attack surface of dhclient.
It's not clear to me whether their paranoia extends to rogue DHCP
servers on the network, but since that's a pretty obvious attack it
may well be the case. Might be worth asking on the relevant OpenBSD

@_date: 2014-10-08 11:48:20
@_author: Riad S. Wahby 
@_subject: State Hash 
And yet a quantum computer efficiently solving SAT would be
substantially more surprising than P=NP!
Quantum computation is not magic; the limits of quantum mechanics
already imply relatively strong lower bounds for quantum hash
collision search.

@_date: 2014-10-06 16:14:38
@_author: Riad S. Wahby 
@_subject: dhcpd dhclient-script shell security 
Note that OpenBSD's dhclient hasn't supported a client script since
late 2012. Even when it did, /bin/sh is ksh by default, so few if any
OpenBSD systems would be vulnerable to Shellshock-via-DHCP.
I realize this addresses symptoms rather than the meat of the question
regarding dhcp clients, but there is some evidence that the OpenBSD
folks were already concerned about the attack surface of dhclient.
It's not clear to me whether their paranoia extends to rogue DHCP
servers on the network, but since that's a pretty obvious attack it
may well be the case. Might be worth asking on the relevant OpenBSD

@_date: 2014-10-08 11:48:20
@_author: Riad S. Wahby 
@_subject: State Hash 
And yet a quantum computer efficiently solving SAT would be
substantially more surprising than P=NP!
Quantum computation is not magic; the limits of quantum mechanics
already imply relatively strong lower bounds for quantum hash
collision search.

@_date: 2014-10-06 16:14:38
@_author: Riad S. Wahby 
@_subject: dhcpd dhclient-script shell security 
Note that OpenBSD's dhclient hasn't supported a client script since
late 2012. Even when it did, /bin/sh is ksh by default, so few if any
OpenBSD systems would be vulnerable to Shellshock-via-DHCP.
I realize this addresses symptoms rather than the meat of the question
regarding dhcp clients, but there is some evidence that the OpenBSD
folks were already concerned about the attack surface of dhclient.
It's not clear to me whether their paranoia extends to rogue DHCP
servers on the network, but since that's a pretty obvious attack it
may well be the case. Might be worth asking on the relevant OpenBSD

@_date: 2014-10-08 11:48:20
@_author: Riad S. Wahby 
@_subject: State Hash 
And yet a quantum computer efficiently solving SAT would be
substantially more surprising than P=NP!
Quantum computation is not magic; the limits of quantum mechanics
already imply relatively strong lower bounds for quantum hash
collision search.

@_date: 2015-08-16 13:34:59
@_author: Riad S. Wahby 
@_subject: Is https://cpunks.org CERT expired? 
As JYA said, both. But now I've fixed one of them. :)

@_date: 2015-08-16 13:34:59
@_author: Riad S. Wahby 
@_subject: Is https://cpunks.org CERT expired? 
As JYA said, both. But now I've fixed one of them. :)

@_date: 2015-08-16 13:34:59
@_author: Riad S. Wahby 
@_subject: Is https://cpunks.org CERT expired? 
As JYA said, both. But now I've fixed one of them. :)

@_date: 2015-12-01 11:40:23
@_author: Riad S. Wahby 
@_subject: The Moral Character of Cryptographic Work 
Phillip Rogaway (Professor of CS at UC Davis) has released in the
form of an essay his keynote talk from Asiacrypt. Very interesting
reflection on the politics of crypto, historically and at present.
"The Moral Character of Cryptographic Work"
Phil Rogaway
Cryptography rearranges power: it configures who can do what, from
what. This makes cryptography an inherently political tool, and it
confers on the field an intrinsically moral dimension. The Snowden
revelations motivate a reassessment of the political and moral
positioning of cryptography. They lead one to ask if our inability to
effectively address mass surveillance constitutes a failure of our
field. I believe that it does. I call for a community-wide effort to
develop more effective means to resist mass surveillance. I plea for a
reinvention of our disciplinary culture to attend not only to puzzles
and math, but, also, to the societal implications of our work.

@_date: 2015-12-01 11:40:23
@_author: Riad S. Wahby 
@_subject: The Moral Character of Cryptographic Work 
Phillip Rogaway (Professor of CS at UC Davis) has released in the
form of an essay his keynote talk from Asiacrypt. Very interesting
reflection on the politics of crypto, historically and at present.
"The Moral Character of Cryptographic Work"
Phil Rogaway
Cryptography rearranges power: it configures who can do what, from
what. This makes cryptography an inherently political tool, and it
confers on the field an intrinsically moral dimension. The Snowden
revelations motivate a reassessment of the political and moral
positioning of cryptography. They lead one to ask if our inability to
effectively address mass surveillance constitutes a failure of our
field. I believe that it does. I call for a community-wide effort to
develop more effective means to resist mass surveillance. I plea for a
reinvention of our disciplinary culture to attend not only to puzzles
and math, but, also, to the societal implications of our work.

@_date: 2015-12-01 11:40:23
@_author: Riad S. Wahby 
@_subject: The Moral Character of Cryptographic Work 
Phillip Rogaway (Professor of CS at UC Davis) has released in the
form of an essay his keynote talk from Asiacrypt. Very interesting
reflection on the politics of crypto, historically and at present.
"The Moral Character of Cryptographic Work"
Phil Rogaway
Cryptography rearranges power: it configures who can do what, from
what. This makes cryptography an inherently political tool, and it
confers on the field an intrinsically moral dimension. The Snowden
revelations motivate a reassessment of the political and moral
positioning of cryptography. They lead one to ask if our inability to
effectively address mass surveillance constitutes a failure of our
field. I believe that it does. I call for a community-wide effort to
develop more effective means to resist mass surveillance. I plea for a
reinvention of our disciplinary culture to attend not only to puzzles
and math, but, also, to the societal implications of our work.

@_date: 2015-02-18 20:03:34
@_author: Riad S. Wahby 
@_subject: List Administrivia 
I've rebuilt the archives, adding the To: and Cc: headers and
(finally!) disabling the rudimentary obscuring of email addresses that
had previously been enabled.
I was surprised to learn that (at least in the version I'm running)
Mailman has no options for retaining extra headers in the text
archives. Fortunately, adding it wasn't too annoying.
Please let me know if I've unwittingly broken anything, and thank you,
grarpamp, for suggesting the various improvements to the archive.

@_date: 2015-02-19 15:25:03
@_author: Riad S. Wahby 
@_subject: List Administrivia 
Well, there's one really straightforward way of addressing these
requests: the archive page now links to a gzipped mbox file with all
messages in original format. Enjoy!

@_date: 2015-02-19 17:13:19
@_author: Riad S. Wahby 
@_subject: List Administrivia 
In truth, the .gz files are only regenerated every few hours via cron;
the HTML archives are updated approximately in sync with mail arrival.

@_date: 2015-02-18 20:03:34
@_author: Riad S. Wahby 
@_subject: List Administrivia 
I've rebuilt the archives, adding the To: and Cc: headers and
(finally!) disabling the rudimentary obscuring of email addresses that
had previously been enabled.
I was surprised to learn that (at least in the version I'm running)
Mailman has no options for retaining extra headers in the text
archives. Fortunately, adding it wasn't too annoying.
Please let me know if I've unwittingly broken anything, and thank you,
grarpamp, for suggesting the various improvements to the archive.

@_date: 2015-02-19 15:25:03
@_author: Riad S. Wahby 
@_subject: List Administrivia 
Well, there's one really straightforward way of addressing these
requests: the archive page now links to a gzipped mbox file with all
messages in original format. Enjoy!

@_date: 2015-02-19 17:13:19
@_author: Riad S. Wahby 
@_subject: List Administrivia 
In truth, the .gz files are only regenerated every few hours via cron;
the HTML archives are updated approximately in sync with mail arrival.

@_date: 2015-02-18 20:03:34
@_author: Riad S. Wahby 
@_subject: List Administrivia 
I've rebuilt the archives, adding the To: and Cc: headers and
(finally!) disabling the rudimentary obscuring of email addresses that
had previously been enabled.
I was surprised to learn that (at least in the version I'm running)
Mailman has no options for retaining extra headers in the text
archives. Fortunately, adding it wasn't too annoying.
Please let me know if I've unwittingly broken anything, and thank you,
grarpamp, for suggesting the various improvements to the archive.

@_date: 2015-02-19 15:25:03
@_author: Riad S. Wahby 
@_subject: List Administrivia 
Well, there's one really straightforward way of addressing these
requests: the archive page now links to a gzipped mbox file with all
messages in original format. Enjoy!

@_date: 2015-02-19 17:13:19
@_author: Riad S. Wahby 
@_subject: List Administrivia 
In truth, the .gz files are only regenerated every few hours via cron;
the HTML archives are updated approximately in sync with mail arrival.

@_date: 2015-01-12 15:13:21
@_author: Riad S. Wahby 
@_subject: What is offtopic and what should be avoided on this list? 
This list has no moderation other than requiring messages to be from
either a subscriber or a known remailer exit. There's also no policy
on banning people for "misbehaving." The only addresses I remove from
the list are those that become undeliverable.
People on the list are expected to be sufficiently internet-savvy that
they're able to deal with blacklisting on their end. I suppose if a
person decided to DoS the machine running the mailing list I'd do what
I could to mitigate, though that's mostly a game of whack-a-mole and,
for a sufficiently dedicated adversary, not a game I would win.
I've given some thought to an alternative setup, i.e., a new version
of the CDR. At some point I hope to find more time for that project.

@_date: 2015-01-12 15:13:21
@_author: Riad S. Wahby 
@_subject: What is offtopic and what should be avoided on this list? 
This list has no moderation other than requiring messages to be from
either a subscriber or a known remailer exit. There's also no policy
on banning people for "misbehaving." The only addresses I remove from
the list are those that become undeliverable.
People on the list are expected to be sufficiently internet-savvy that
they're able to deal with blacklisting on their end. I suppose if a
person decided to DoS the machine running the mailing list I'd do what
I could to mitigate, though that's mostly a game of whack-a-mole and,
for a sufficiently dedicated adversary, not a game I would win.
I've given some thought to an alternative setup, i.e., a new version
of the CDR. At some point I hope to find more time for that project.

@_date: 2015-01-12 15:13:21
@_author: Riad S. Wahby 
@_subject: What is offtopic and what should be avoided on this list? 
This list has no moderation other than requiring messages to be from
either a subscriber or a known remailer exit. There's also no policy
on banning people for "misbehaving." The only addresses I remove from
the list are those that become undeliverable.
People on the list are expected to be sufficiently internet-savvy that
they're able to deal with blacklisting on their end. I suppose if a
person decided to DoS the machine running the mailing list I'd do what
I could to mitigate, though that's mostly a game of whack-a-mole and,
for a sufficiently dedicated adversary, not a game I would win.
I've given some thought to an alternative setup, i.e., a new version
of the CDR. At some point I hope to find more time for that project.

@_date: 2015-07-29 14:07:14
@_author: Riad S. Wahby 
@_subject: Open Fabs 
But that just gives away the bitstream describing the FPGA
configuration (say, a trusted CPU). Is the CPU's *design* a secret? If
not, I don't see why it matters that an evil cleaner might read out the
FPGA's configuration. (Obviously, don't store secret keys in there!)
If we really are worried about keeping the CPU's design a secret, it's
possible with many FPGAs to encrypt the configuration bitstream such
that the configuration is decrypted onboard the FPGA at power-on. This
is intended to handle the case where I want to sell a product that uses
an FPGA without revealing the contents of that FPGA's configuration to
my customers or competitors.
Of course, this doesn't really provide useful security guarantees
against a sophisticated adversary. First, since the FPGA contains or
automatically derives the secret key to decrypt this encrypted bitstream,
the manufacturer of the FPGA likely also knows the key or how to derive
it (as does anyone with sufficient dedication and a well-equipped lab).
Second, we have no idea how well this system is designed or implemented,
since the bitstream security system is itself a proprietary secret. And
third, even if it's competently built, as I pointed out above, the threat
model is "customer reads out my proprietary design," which means that,
practically speaking, the technological barrier is only there to support
a more comprehensive framework of legal recourse in the case that my
customer or competitor tries to steal the secret sauce.
Probably a reasonable evil cleaner attack against an FPGA-based
"trusted" CPU is to overwrite the contents of the configuration
ROM with a similar but subtly bugged design. This is more or less
isomorphic to "the NSA signs bugged microcode for my Intel CPU."
Cue the OTP / epoxy / physical security arms race, I guess.

@_date: 2015-07-29 15:25:28
@_author: Riad S. Wahby 
@_subject: Open Fabs 
Ah, I see. I thought the focus was on cold boot or evil maid attacks
against FPGA-based (thus, nominally trustworthy) CPUs, and how these
attacks might compare to similar attacks against a commercial CPU.
As you pointed out before, one may as well just grab the configuration
out of the ROM itself, and I agree---but my point was that either way,
what are we getting except some information that's not really secret?
So I think we're in violent agreement, at least to the extent that
we're talking about the same thing :)
Also: one assumes that cold boot attacks against the contents of
RAM are more useful than against the SRAMs that hold the FPGA's
configuration, and in that case probably it's little different from
the equivalent attack against a commercial CPU (the DRAM is more
or less the same whether we're talking about the commercial or the
FPGA-based CPU---you're using the same DIMMs either way).
On further reflection, I suppose the contents of the block RAMs inside
the FPGA (little SRAMs sprinkled through the fabric) might be a prize
worth chasing, since those are presumably acting as registers and
cache for our CPU. It *might* be possible to do so by cold booting the
FPGA with a configuration that dumps the contents of the block RAMs,
assuming that those contents aren't cleared by power-on reset or the
configuration process itself.
To your point above about auditing the configuration actually running
on an FPGA: that would be very interesting to prevent against an FPGA
manufacturer going the reflections-on-trusting-trust route.
Here's one way an evil FPGA manufacturer might proceed: the CAD
software that the manufacturer provides with the FPGA detects that
you're synthesizing a CPU. Rather than emit a flawed bitstream
(which might be detectable just by examining the bitstream itself),
perhaps the software would hide in the bitstream some instructions
that direct the FPGA's configuration state machine to introduce flaws
at config time.
(FPGA config bitstreams are big, complicated, and proprietary; so
it's not impossible that they contain enough redundancy that one
could use stego to hide such commands in the bitstream.)
(This approach also helps to get around the fact that the synthesis
and fitting process does a randomized search for a configuration
that meets your criteria (e.g., speed, size, etc.). In other words:
the best time to detect "this guy is trying to build a CPU" is when
the software is reading your Verilog, not when it's loading the
bitstream into an FPGA, because it's really really hard to decide
"this is a CPU" just by examining the bitstream itself.)
But I suppose if I were so devious as a manufacturer of FPGAs as to
detect a CPU design and introduce subtle bugs as a result, I would
probably also do my best to keep you from detecting it, even if you
*are* able to read out the config from a running FPGA. It's quite a
large haystack for hiding such a little needle...
(And regarding cold booting to read out the config SRAMs: I worry even
more here than in the case of block RAMs that these have a carefully
designed power-on reset scheme in place so that the FPGA fabric comes
up in a known state.)

@_date: 2015-07-29 14:07:14
@_author: Riad S. Wahby 
@_subject: Open Fabs 
But that just gives away the bitstream describing the FPGA
configuration (say, a trusted CPU). Is the CPU's *design* a secret? If
not, I don't see why it matters that an evil cleaner might read out the
FPGA's configuration. (Obviously, don't store secret keys in there!)
If we really are worried about keeping the CPU's design a secret, it's
possible with many FPGAs to encrypt the configuration bitstream such
that the configuration is decrypted onboard the FPGA at power-on. This
is intended to handle the case where I want to sell a product that uses
an FPGA without revealing the contents of that FPGA's configuration to
my customers or competitors.
Of course, this doesn't really provide useful security guarantees
against a sophisticated adversary. First, since the FPGA contains or
automatically derives the secret key to decrypt this encrypted bitstream,
the manufacturer of the FPGA likely also knows the key or how to derive
it (as does anyone with sufficient dedication and a well-equipped lab).
Second, we have no idea how well this system is designed or implemented,
since the bitstream security system is itself a proprietary secret. And
third, even if it's competently built, as I pointed out above, the threat
model is "customer reads out my proprietary design," which means that,
practically speaking, the technological barrier is only there to support
a more comprehensive framework of legal recourse in the case that my
customer or competitor tries to steal the secret sauce.
Probably a reasonable evil cleaner attack against an FPGA-based
"trusted" CPU is to overwrite the contents of the configuration
ROM with a similar but subtly bugged design. This is more or less
isomorphic to "the NSA signs bugged microcode for my Intel CPU."
Cue the OTP / epoxy / physical security arms race, I guess.

@_date: 2015-07-29 15:25:28
@_author: Riad S. Wahby 
@_subject: Open Fabs 
Ah, I see. I thought the focus was on cold boot or evil maid attacks
against FPGA-based (thus, nominally trustworthy) CPUs, and how these
attacks might compare to similar attacks against a commercial CPU.
As you pointed out before, one may as well just grab the configuration
out of the ROM itself, and I agree---but my point was that either way,
what are we getting except some information that's not really secret?
So I think we're in violent agreement, at least to the extent that
we're talking about the same thing :)
Also: one assumes that cold boot attacks against the contents of
RAM are more useful than against the SRAMs that hold the FPGA's
configuration, and in that case probably it's little different from
the equivalent attack against a commercial CPU (the DRAM is more
or less the same whether we're talking about the commercial or the
FPGA-based CPU---you're using the same DIMMs either way).
On further reflection, I suppose the contents of the block RAMs inside
the FPGA (little SRAMs sprinkled through the fabric) might be a prize
worth chasing, since those are presumably acting as registers and
cache for our CPU. It *might* be possible to do so by cold booting the
FPGA with a configuration that dumps the contents of the block RAMs,
assuming that those contents aren't cleared by power-on reset or the
configuration process itself.
To your point above about auditing the configuration actually running
on an FPGA: that would be very interesting to prevent against an FPGA
manufacturer going the reflections-on-trusting-trust route.
Here's one way an evil FPGA manufacturer might proceed: the CAD
software that the manufacturer provides with the FPGA detects that
you're synthesizing a CPU. Rather than emit a flawed bitstream
(which might be detectable just by examining the bitstream itself),
perhaps the software would hide in the bitstream some instructions
that direct the FPGA's configuration state machine to introduce flaws
at config time.
(FPGA config bitstreams are big, complicated, and proprietary; so
it's not impossible that they contain enough redundancy that one
could use stego to hide such commands in the bitstream.)
(This approach also helps to get around the fact that the synthesis
and fitting process does a randomized search for a configuration
that meets your criteria (e.g., speed, size, etc.). In other words:
the best time to detect "this guy is trying to build a CPU" is when
the software is reading your Verilog, not when it's loading the
bitstream into an FPGA, because it's really really hard to decide
"this is a CPU" just by examining the bitstream itself.)
But I suppose if I were so devious as a manufacturer of FPGAs as to
detect a CPU design and introduce subtle bugs as a result, I would
probably also do my best to keep you from detecting it, even if you
*are* able to read out the config from a running FPGA. It's quite a
large haystack for hiding such a little needle...
(And regarding cold booting to read out the config SRAMs: I worry even
more here than in the case of block RAMs that these have a carefully
designed power-on reset scheme in place so that the FPGA fabric comes
up in a known state.)

@_date: 2015-07-29 14:07:14
@_author: Riad S. Wahby 
@_subject: Open Fabs 
But that just gives away the bitstream describing the FPGA
configuration (say, a trusted CPU). Is the CPU's *design* a secret? If
not, I don't see why it matters that an evil cleaner might read out the
FPGA's configuration. (Obviously, don't store secret keys in there!)
If we really are worried about keeping the CPU's design a secret, it's
possible with many FPGAs to encrypt the configuration bitstream such
that the configuration is decrypted onboard the FPGA at power-on. This
is intended to handle the case where I want to sell a product that uses
an FPGA without revealing the contents of that FPGA's configuration to
my customers or competitors.
Of course, this doesn't really provide useful security guarantees
against a sophisticated adversary. First, since the FPGA contains or
automatically derives the secret key to decrypt this encrypted bitstream,
the manufacturer of the FPGA likely also knows the key or how to derive
it (as does anyone with sufficient dedication and a well-equipped lab).
Second, we have no idea how well this system is designed or implemented,
since the bitstream security system is itself a proprietary secret. And
third, even if it's competently built, as I pointed out above, the threat
model is "customer reads out my proprietary design," which means that,
practically speaking, the technological barrier is only there to support
a more comprehensive framework of legal recourse in the case that my
customer or competitor tries to steal the secret sauce.
Probably a reasonable evil cleaner attack against an FPGA-based
"trusted" CPU is to overwrite the contents of the configuration
ROM with a similar but subtly bugged design. This is more or less
isomorphic to "the NSA signs bugged microcode for my Intel CPU."
Cue the OTP / epoxy / physical security arms race, I guess.

@_date: 2015-07-29 15:25:28
@_author: Riad S. Wahby 
@_subject: Open Fabs 
Ah, I see. I thought the focus was on cold boot or evil maid attacks
against FPGA-based (thus, nominally trustworthy) CPUs, and how these
attacks might compare to similar attacks against a commercial CPU.
As you pointed out before, one may as well just grab the configuration
out of the ROM itself, and I agree---but my point was that either way,
what are we getting except some information that's not really secret?
So I think we're in violent agreement, at least to the extent that
we're talking about the same thing :)
Also: one assumes that cold boot attacks against the contents of
RAM are more useful than against the SRAMs that hold the FPGA's
configuration, and in that case probably it's little different from
the equivalent attack against a commercial CPU (the DRAM is more
or less the same whether we're talking about the commercial or the
FPGA-based CPU---you're using the same DIMMs either way).
On further reflection, I suppose the contents of the block RAMs inside
the FPGA (little SRAMs sprinkled through the fabric) might be a prize
worth chasing, since those are presumably acting as registers and
cache for our CPU. It *might* be possible to do so by cold booting the
FPGA with a configuration that dumps the contents of the block RAMs,
assuming that those contents aren't cleared by power-on reset or the
configuration process itself.
To your point above about auditing the configuration actually running
on an FPGA: that would be very interesting to prevent against an FPGA
manufacturer going the reflections-on-trusting-trust route.
Here's one way an evil FPGA manufacturer might proceed: the CAD
software that the manufacturer provides with the FPGA detects that
you're synthesizing a CPU. Rather than emit a flawed bitstream
(which might be detectable just by examining the bitstream itself),
perhaps the software would hide in the bitstream some instructions
that direct the FPGA's configuration state machine to introduce flaws
at config time.
(FPGA config bitstreams are big, complicated, and proprietary; so
it's not impossible that they contain enough redundancy that one
could use stego to hide such commands in the bitstream.)
(This approach also helps to get around the fact that the synthesis
and fitting process does a randomized search for a configuration
that meets your criteria (e.g., speed, size, etc.). In other words:
the best time to detect "this guy is trying to build a CPU" is when
the software is reading your Verilog, not when it's loading the
bitstream into an FPGA, because it's really really hard to decide
"this is a CPU" just by examining the bitstream itself.)
But I suppose if I were so devious as a manufacturer of FPGAs as to
detect a CPU design and introduce subtle bugs as a result, I would
probably also do my best to keep you from detecting it, even if you
*are* able to read out the config from a running FPGA. It's quite a
large haystack for hiding such a little needle...
(And regarding cold booting to read out the config SRAMs: I worry even
more here than in the case of block RAMs that these have a carefully
designed power-on reset scheme in place so that the FPGA fabric comes
up in a known state.)

@_date: 2015-06-10 18:01:39
@_author: Riad S. Wahby 
@_subject: Best practice for safe viewing of PDFs posted to list 
If your web browsing habits don't include NoScript, then you're likely no
worse off using pdf.js to view PDFs than you are browsing arbitrary websites.
After all, pdf.js has no more or less permissions than any other JS you might
encounter in the wild; and since pdf.js is bundled with modern versions of
Firefox, you might be inclined to think that it's likely non-malicious even if
it's exploitable by rogue PDFs. But that's no worse than some JS malware you
were fed via DNS poisoning or CDN hijacking.
(This can be seen either as an implicit endorsement of pdf.js or of NoScript.)

@_date: 2015-06-10 18:01:39
@_author: Riad S. Wahby 
@_subject: Best practice for safe viewing of PDFs posted to list 
If your web browsing habits don't include NoScript, then you're likely no
worse off using pdf.js to view PDFs than you are browsing arbitrary websites.
After all, pdf.js has no more or less permissions than any other JS you might
encounter in the wild; and since pdf.js is bundled with modern versions of
Firefox, you might be inclined to think that it's likely non-malicious even if
it's exploitable by rogue PDFs. But that's no worse than some JS malware you
were fed via DNS poisoning or CDN hijacking.
(This can be seen either as an implicit endorsement of pdf.js or of NoScript.)

@_date: 2015-06-10 18:01:39
@_author: Riad S. Wahby 
@_subject: Best practice for safe viewing of PDFs posted to list 
If your web browsing habits don't include NoScript, then you're likely no
worse off using pdf.js to view PDFs than you are browsing arbitrary websites.
After all, pdf.js has no more or less permissions than any other JS you might
encounter in the wild; and since pdf.js is bundled with modern versions of
Firefox, you might be inclined to think that it's likely non-malicious even if
it's exploitable by rogue PDFs. But that's no worse than some JS malware you
were fed via DNS poisoning or CDN hijacking.
(This can be seen either as an implicit endorsement of pdf.js or of NoScript.)

@_date: 2015-03-13 12:42:28
@_author: Riad S. Wahby 
@_subject: Computer-stored encryption keys are not safe from side-channel 
The researchers' web page
    They presented similar attacks using acoustic emanations at CRYPTO14.

@_date: 2015-03-13 12:42:28
@_author: Riad S. Wahby 
@_subject: Computer-stored encryption keys are not safe from side-channel 
The researchers' web page
    They presented similar attacks using acoustic emanations at CRYPTO14.

@_date: 2015-03-13 12:42:28
@_author: Riad S. Wahby 
@_subject: Computer-stored encryption keys are not safe from side-channel 
The researchers' web page
    They presented similar attacks using acoustic emanations at CRYPTO14.

@_date: 2015-10-29 12:22:24
@_author: Riad S. Wahby 
@_subject: Cypherpunks is broken - Welcome to Secret Admirers 
I think you left out "learn our awesome secret handshake."
Anyway, can I be a member if I volunteer to make the NO NARKZ ALLOWED
sign for the treehouse?

@_date: 2015-10-29 12:22:24
@_author: Riad S. Wahby 
@_subject: Cypherpunks is broken - Welcome to Secret Admirers 
I think you left out "learn our awesome secret handshake."
Anyway, can I be a member if I volunteer to make the NO NARKZ ALLOWED
sign for the treehouse?

@_date: 2015-10-29 12:22:24
@_author: Riad S. Wahby 
@_subject: Cypherpunks is broken - Welcome to Secret Admirers 
I think you left out "learn our awesome secret handshake."
Anyway, can I be a member if I volunteer to make the NO NARKZ ALLOWED
sign for the treehouse?

@_date: 2016-08-20 15:51:23
@_author: Riad S. Wahby 
@_subject: moving on 
After 15+ years running a cypherpunks node, it's quitting time for me.
I plan to delete the mailman aliases on September 30th.
If anyone is interested in migrating the list to his or her machine
before then, that would be great; let's discuss on-list.

@_date: 2016-08-20 20:44:31
@_author: Riad S. Wahby 
@_subject: moving on 
Done! This tarball goes back as far as 1999, though I'm not certain
it's a complete archive. Note that prior to the LNE node, the list
was 100% unfiltered, so what's below includes a decent amount of spam.
All told, it's about 95k messages in Maildir format.
Signed with 68E8B84A0ED9DDDAF60B250987C118774CBBC936,
    (This archive also reveals that I only started a node in 2004,
meaning that it's been 12 years, not 15. My mistake.)

@_date: 2016-08-22 10:18:00
@_author: Riad S. Wahby 
@_subject: moving on 
This is substantially mitigated by requiring messages to come from
a subscriber or a known remailer exit. At least, that's all I do.
Perhaps surprisingly, neither of these has been an issue for me. YMMV.

@_date: 2016-08-23 10:10:02
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
This is how cpunks was run from 1997 until mid-2005, when this
became the only node. It was called the CDR (Cypherpunks Distributed
It's a nice idea in theory, but (with all respect) the original
implementation was far from pretty; kudos to Jim Choate and Igor
Chudov for making it work at all :)
In principle it should be pretty straightforward to make a "distributed
mailman" setup work.  The high-level idea is that all the servers
accept messages, and all messages get forwarded to all servers. Then
each server decides based on local policy which messages get delivered
to users. For example, someone might decide they want to run a cpunks
node that's moderated, and the important thing is that only their
subscribers would see the moderated version of the list---subscribers
to another node could get the full feed.
The server-server forwarding stuff is like 10 lines of procmail, and
requires no changes to mailman. The part that gets slightly hairy is
implementing subscriber-only filtering [1]. In a naive setup, every
node needs to know every other node's subscriber list. In addition
to the (completely surmountable but sometimes annoying) issues with
distributed synchronization, this is potentially a privacy concern
for list subscribers.
One step toward fixing this would be for lists to blind their
whitelists. For example, a list could publish a set of SHA256 hashes
of suscriber addresses, or maybe even something more clever, e.g.,
    But this still isn't perfect. For example, when a subscriber sends an
email, each server gets to see which whitelist the subscriber matched
against, which means that servers can keep track over time and build
up a mapping from active posters to home nodes. This might not be
a problem, but it's worth considering whether there's some approach
that would fix this without too much computational overhead.
[1] I understand that there are reasons to have a fully unregulated
    list, but in my view subscriber-only filtering plus whitelisting
    known remailers gives a good balance between ease of posting
    and good SNR. If I recall correctly, the LNE.com CDR node was
    the first to implement this policy, and I followed Eric's lead
    because it was far and away better than what came before it.

@_date: 2016-08-23 10:12:23
@_author: Riad S. Wahby 
@_subject: moving on 
I'll plan to do this.
You're probably already aware of this, but just in case: the full
tarball of all messages since mid-2013 (when we switched to mailman)
is always available on the archive.

@_date: 2016-08-23 16:49:21
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
According to my notes, the last two nodes to go were minder.net and
pro-ns.net, both in 2005. At one time there were bunches of others:

@_date: 2016-08-20 15:51:23
@_author: Riad S. Wahby 
@_subject: moving on 
After 15+ years running a cypherpunks node, it's quitting time for me.
I plan to delete the mailman aliases on September 30th.
If anyone is interested in migrating the list to his or her machine
before then, that would be great; let's discuss on-list.

@_date: 2016-08-20 20:44:31
@_author: Riad S. Wahby 
@_subject: moving on 
Done! This tarball goes back as far as 1999, though I'm not certain
it's a complete archive. Note that prior to the LNE node, the list
was 100% unfiltered, so what's below includes a decent amount of spam.
All told, it's about 95k messages in Maildir format.
Signed with 68E8B84A0ED9DDDAF60B250987C118774CBBC936,
    (This archive also reveals that I only started a node in 2004,
meaning that it's been 12 years, not 15. My mistake.)

@_date: 2016-08-22 10:18:00
@_author: Riad S. Wahby 
@_subject: moving on 
This is substantially mitigated by requiring messages to come from
a subscriber or a known remailer exit. At least, that's all I do.
Perhaps surprisingly, neither of these has been an issue for me. YMMV.

@_date: 2016-08-23 10:10:02
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
This is how cpunks was run from 1997 until mid-2005, when this
became the only node. It was called the CDR (Cypherpunks Distributed
It's a nice idea in theory, but (with all respect) the original
implementation was far from pretty; kudos to Jim Choate and Igor
Chudov for making it work at all :)
In principle it should be pretty straightforward to make a "distributed
mailman" setup work.  The high-level idea is that all the servers
accept messages, and all messages get forwarded to all servers. Then
each server decides based on local policy which messages get delivered
to users. For example, someone might decide they want to run a cpunks
node that's moderated, and the important thing is that only their
subscribers would see the moderated version of the list---subscribers
to another node could get the full feed.
The server-server forwarding stuff is like 10 lines of procmail, and
requires no changes to mailman. The part that gets slightly hairy is
implementing subscriber-only filtering [1]. In a naive setup, every
node needs to know every other node's subscriber list. In addition
to the (completely surmountable but sometimes annoying) issues with
distributed synchronization, this is potentially a privacy concern
for list subscribers.
One step toward fixing this would be for lists to blind their
whitelists. For example, a list could publish a set of SHA256 hashes
of suscriber addresses, or maybe even something more clever, e.g.,
    But this still isn't perfect. For example, when a subscriber sends an
email, each server gets to see which whitelist the subscriber matched
against, which means that servers can keep track over time and build
up a mapping from active posters to home nodes. This might not be
a problem, but it's worth considering whether there's some approach
that would fix this without too much computational overhead.
[1] I understand that there are reasons to have a fully unregulated
    list, but in my view subscriber-only filtering plus whitelisting
    known remailers gives a good balance between ease of posting
    and good SNR. If I recall correctly, the LNE.com CDR node was
    the first to implement this policy, and I followed Eric's lead
    because it was far and away better than what came before it.

@_date: 2016-08-23 10:12:23
@_author: Riad S. Wahby 
@_subject: moving on 
I'll plan to do this.
You're probably already aware of this, but just in case: the full
tarball of all messages since mid-2013 (when we switched to mailman)
is always available on the archive.

@_date: 2016-08-23 16:49:21
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
According to my notes, the last two nodes to go were minder.net and
pro-ns.net, both in 2005. At one time there were bunches of others:

@_date: 2016-08-31 21:24:00
@_author: Riad S. Wahby 
@_subject: New list confirmation (Re: cpunks list relocation imminent (was: 
You can find the final archive of all messages since the changeover
to mailman in mid-2013 at:
        Signed with the same key as above.

@_date: 2016-08-31 20:58:32
@_author: Riad S. Wahby 
@_subject: New list confirmation (Re: cpunks list relocation imminent (was: 
If all has gone well, this message will reach you via the new list,
which Greg is now hosting. Thanks for stepping up, Greg.
Specifically: all mail to  or  should
now go to Greg's list instance. In the next few days, Greg and I
will work to sync up the archives so that the split brain we've been
running for the last few days is retroactively repaired.
Also, as I promised grarpamp, I will soon publish and sign a copy
of my local cypherpunks mbox going back to mid-2013. The previous
archive, which contains every message to cypherpunks I've received
since sometime in 1999, is now available from:
        You can find the corresponding PGP key at (or on most public keyservers).

@_date: 2016-08-20 15:51:23
@_author: Riad S. Wahby 
@_subject: moving on 
After 15+ years running a cypherpunks node, it's quitting time for me.
I plan to delete the mailman aliases on September 30th.
If anyone is interested in migrating the list to his or her machine
before then, that would be great; let's discuss on-list.

@_date: 2016-08-20 20:44:31
@_author: Riad S. Wahby 
@_subject: moving on 
Done! This tarball goes back as far as 1999, though I'm not certain
it's a complete archive. Note that prior to the LNE node, the list
was 100% unfiltered, so what's below includes a decent amount of spam.
All told, it's about 95k messages in Maildir format.
Signed with 68E8B84A0ED9DDDAF60B250987C118774CBBC936,
    (This archive also reveals that I only started a node in 2004,
meaning that it's been 12 years, not 15. My mistake.)

@_date: 2016-08-22 10:18:00
@_author: Riad S. Wahby 
@_subject: moving on 
This is substantially mitigated by requiring messages to come from
a subscriber or a known remailer exit. At least, that's all I do.
Perhaps surprisingly, neither of these has been an issue for me. YMMV.

@_date: 2016-08-23 10:10:02
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
This is how cpunks was run from 1997 until mid-2005, when this
became the only node. It was called the CDR (Cypherpunks Distributed
It's a nice idea in theory, but (with all respect) the original
implementation was far from pretty; kudos to Jim Choate and Igor
Chudov for making it work at all :)
In principle it should be pretty straightforward to make a "distributed
mailman" setup work.  The high-level idea is that all the servers
accept messages, and all messages get forwarded to all servers. Then
each server decides based on local policy which messages get delivered
to users. For example, someone might decide they want to run a cpunks
node that's moderated, and the important thing is that only their
subscribers would see the moderated version of the list---subscribers
to another node could get the full feed.
The server-server forwarding stuff is like 10 lines of procmail, and
requires no changes to mailman. The part that gets slightly hairy is
implementing subscriber-only filtering [1]. In a naive setup, every
node needs to know every other node's subscriber list. In addition
to the (completely surmountable but sometimes annoying) issues with
distributed synchronization, this is potentially a privacy concern
for list subscribers.
One step toward fixing this would be for lists to blind their
whitelists. For example, a list could publish a set of SHA256 hashes
of suscriber addresses, or maybe even something more clever, e.g.,
    But this still isn't perfect. For example, when a subscriber sends an
email, each server gets to see which whitelist the subscriber matched
against, which means that servers can keep track over time and build
up a mapping from active posters to home nodes. This might not be
a problem, but it's worth considering whether there's some approach
that would fix this without too much computational overhead.
[1] I understand that there are reasons to have a fully unregulated
    list, but in my view subscriber-only filtering plus whitelisting
    known remailers gives a good balance between ease of posting
    and good SNR. If I recall correctly, the LNE.com CDR node was
    the first to implement this policy, and I followed Eric's lead
    because it was far and away better than what came before it.

@_date: 2016-08-23 10:12:23
@_author: Riad S. Wahby 
@_subject: moving on 
I'll plan to do this.
You're probably already aware of this, but just in case: the full
tarball of all messages since mid-2013 (when we switched to mailman)
is always available on the archive.

@_date: 2016-08-23 16:49:21
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
According to my notes, the last two nodes to go were minder.net and
pro-ns.net, both in 2005. At one time there were bunches of others:

@_date: 2016-08-31 21:24:00
@_author: Riad S. Wahby 
@_subject: New list confirmation (Re: cpunks list relocation imminent (was: 
You can find the final archive of all messages since the changeover
to mailman in mid-2013 at:
        Signed with the same key as above.

@_date: 2016-08-31 20:58:32
@_author: Riad S. Wahby 
@_subject: New list confirmation (Re: cpunks list relocation imminent (was: 
============================== START ==============================
If all has gone well, this message will reach you via the new list,
which Greg is now hosting. Thanks for stepping up, Greg.
Specifically: all mail to  or  should
now go to Greg's list instance. In the next few days, Greg and I
will work to sync up the archives so that the split brain we've been
running for the last few days is retroactively repaired.
Also, as I promised grarpamp, I will soon publish and sign a copy
of my local cypherpunks mbox going back to mid-2013. The previous
archive, which contains every message to cypherpunks I've received
since sometime in 1999, is now available from:
        You can find the corresponding PGP key at (or on most public keyservers).

@_date: 2016-02-25 22:54:43
@_author: Riad S. Wahby 
@_subject: Cpunks censorship? 
Not at all. This is some error in either your setup or mine; if the
latter, I apologize, and will take steps to fix it asap.
If you can email me details regarding the bounces you're seeing, I'm
guessing we can get to the bottom of this quickly. I have not seen any
traffic to the administrative address indicating that there's something
wrong, but that is no assurance that the failure is not my fault.

@_date: 2016-02-25 22:57:04
@_author: Riad S. Wahby 
@_subject: Cpunks censorship? 
Well I feel dumb; I guess that's why a person reads the whole thread
I suppose all's well that ends well. Now back to your regularly
scheduled programming.

@_date: 2016-02-25 22:54:43
@_author: Riad S. Wahby 
@_subject: Cpunks censorship? 
Not at all. This is some error in either your setup or mine; if the
latter, I apologize, and will take steps to fix it asap.
If you can email me details regarding the bounces you're seeing, I'm
guessing we can get to the bottom of this quickly. I have not seen any
traffic to the administrative address indicating that there's something
wrong, but that is no assurance that the failure is not my fault.

@_date: 2016-02-25 22:57:04
@_author: Riad S. Wahby 
@_subject: Cpunks censorship? 
Well I feel dumb; I guess that's why a person reads the whole thread
I suppose all's well that ends well. Now back to your regularly
scheduled programming.

@_date: 2016-02-25 22:54:43
@_author: Riad S. Wahby 
@_subject: Cpunks censorship? 
Not at all. This is some error in either your setup or mine; if the
latter, I apologize, and will take steps to fix it asap.
If you can email me details regarding the bounces you're seeing, I'm
guessing we can get to the bottom of this quickly. I have not seen any
traffic to the administrative address indicating that there's something
wrong, but that is no assurance that the failure is not my fault.

@_date: 2016-02-25 22:57:04
@_author: Riad S. Wahby 
@_subject: Cpunks censorship? 
Well I feel dumb; I guess that's why a person reads the whole thread
I suppose all's well that ends well. Now back to your regularly
scheduled programming.

@_date: 2016-06-20 22:05:08
@_author: Riad S. Wahby 
@_subject: what 'Tor' actually stands for  - do you want a brown t-shirt? 
Juan, I like the cut of your jib, even when I don't agree with you.
But what's with all this speculation that cpunks will become moderated?
And how do you propose that a bunch of people who have no connection to
the list will be the ones to do so?
To be clear: I have no intention of moderating this list, ever. I'm too
lazy, for one :)

@_date: 2016-06-20 22:05:08
@_author: Riad S. Wahby 
@_subject: what 'Tor' actually stands for  - do you want a brown t-shirt? 
Juan, I like the cut of your jib, even when I don't agree with you.
But what's with all this speculation that cpunks will become moderated?
And how do you propose that a bunch of people who have no connection to
the list will be the ones to do so?
To be clear: I have no intention of moderating this list, ever. I'm too
lazy, for one :)

@_date: 2016-06-20 22:05:08
@_author: Riad S. Wahby 
@_subject: what 'Tor' actually stands for  - do you want a brown t-shirt? 
Juan, I like the cut of your jib, even when I don't agree with you.
But what's with all this speculation that cpunks will become moderated?
And how do you propose that a bunch of people who have no connection to
the list will be the ones to do so?
To be clear: I have no intention of moderating this list, ever. I'm too
lazy, for one :)

@_date: 2016-09-01 11:06:08
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
Yes. Really, procmail is all you need. If the local node is
mynodename.com, then make the posting address (cypherpunks go to
the procmailrc below and an internal address (_cypherpunks go to
the local mailman instance. So your /etc/aliases might have lines like:
    cypherpunks: |procmail -m /etc/procmailrcs/procmailrc_cpunks
    _cypherpunks: |mailman post cypherpunks
Note that you will have to tell mailman to accept messages addressed
to cypherpunks at somenode.com and cypherpunks at othernode.com in addition
to cypherpunks at mynodename.com.
As I said in my previous message, the harder part is sender whitelisting.
More on that below.
One more note: the scripts I used during the CDR days are available from
    See also
     /etc/procmailrcs/procmailrc_cpunks----
# This script is very similar to how the "backbone" operated in the
# original CDR, updated with the assumption that the nodes run mailman.
# NOTE that I have not tested this!!! :)
# nuke messages from MAILER-DAEMON or the local list instance
* (^From:.*MAILER-DAEMON
# keep a cache of message-IDs so that each message is only processed once
:0 Wh: msgid.lock
# maybe add a rule here to delete administrivia
# check whether this message is "backbone" traffic that we've already seen
* !^X-Loop:.*mynodename.com
! _cypherpunks at localhost
# now add an X-Loop header
# now bounce to other nodes
* !^X-Loop:.*somenode.com
! cypherpunks at somenode.com
* !^X-Loop:.*othernode.com
! cypherpunks at othernode.com
 /etc/procmailrcs/procmailrc_cpunks----
This is a nice thought, but it has two pretty major issues.
First, one of the reasons to have many nodes is so that nodes can apply
their own filtering policies to the traffic. But naively operating
the setup you describe would apply that filtering policy to mail
going from that node to other nodes, which is bad---the "backbone"
traffic should be unfiltered. It's possible to get around this issue,
but (e.g.) vanilla mailman can't do it.
Second, in the setup you describe, posting to the list instantly
reveals to everyone which node you're subscribed to, which is
information I was trying to keep hidden in the design I proposed.
If it's OK to reveal to other node operators which list a poster is
subscribed to, a simple solution is having the nodes share blinded
(e.g., hashed and salted) subscriber lists with one another (note
that this hides subscription information from everyone other than
node operators).
In my estimation, this is not a good idea. The reason is that adding
nodes to the network takes work from existing node owners. If the
incentive structure is such that it's almost no work to set up a new
node, then people will be incentivized to start nodes ("hey, that
sounds fun"), but not to keep them running ("ugh, too much work").
This will result in a bunch of node churn, which is bad.
Plus, what sane person would run a Docker image put together by a
bunch of strangers from Cypherpunks?
Finally, lowering the bar for people to run nodes sounds like a good
idea until you're subscribed to a node whose operator is ignorant or
malicious. Node operators are in a semi-trusted position. Having a
barrier to entry is probably a good thing.

@_date: 2016-09-01 11:06:08
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
Yes. Really, procmail is all you need. If the local node is
mynodename.com, then make the posting address (cypherpunks go to
the procmailrc below and an internal address (_cypherpunks go to
the local mailman instance. So your /etc/aliases might have lines like:
    cypherpunks: |procmail -m /etc/procmailrcs/procmailrc_cpunks
    _cypherpunks: |mailman post cypherpunks
Note that you will have to tell mailman to accept messages addressed
to cypherpunks at somenode.com and cypherpunks at othernode.com in addition
to cypherpunks at mynodename.com.
As I said in my previous message, the harder part is sender whitelisting.
More on that below.
One more note: the scripts I used during the CDR days are available from
    See also
     /etc/procmailrcs/procmailrc_cpunks----
# This script is very similar to how the "backbone" operated in the
# original CDR, updated with the assumption that the nodes run mailman.
# NOTE that I have not tested this!!! :)
# nuke messages from MAILER-DAEMON or the local list instance
* (^From:.*MAILER-DAEMON
# keep a cache of message-IDs so that each message is only processed once
:0 Wh: msgid.lock
# maybe add a rule here to delete administrivia
# check whether this message is "backbone" traffic that we've already seen
* !^X-Loop:.*mynodename.com
! _cypherpunks at localhost
# now add an X-Loop header
# now bounce to other nodes
* !^X-Loop:.*somenode.com
! cypherpunks at somenode.com
* !^X-Loop:.*othernode.com
! cypherpunks at othernode.com
 /etc/procmailrcs/procmailrc_cpunks----
This is a nice thought, but it has two pretty major issues.
First, one of the reasons to have many nodes is so that nodes can apply
their own filtering policies to the traffic. But naively operating
the setup you describe would apply that filtering policy to mail
going from that node to other nodes, which is bad---the "backbone"
traffic should be unfiltered. It's possible to get around this issue,
but (e.g.) vanilla mailman can't do it.
Second, in the setup you describe, posting to the list instantly
reveals to everyone which node you're subscribed to, which is
information I was trying to keep hidden in the design I proposed.
If it's OK to reveal to other node operators which list a poster is
subscribed to, a simple solution is having the nodes share blinded
(e.g., hashed and salted) subscriber lists with one another (note
that this hides subscription information from everyone other than
node operators).
In my estimation, this is not a good idea. The reason is that adding
nodes to the network takes work from existing node owners. If the
incentive structure is such that it's almost no work to set up a new
node, then people will be incentivized to start nodes ("hey, that
sounds fun"), but not to keep them running ("ugh, too much work").
This will result in a bunch of node churn, which is bad.
Plus, what sane person would run a Docker image put together by a
bunch of strangers from Cypherpunks?
Finally, lowering the bar for people to run nodes sounds like a good
idea until you're subscribed to a node whose operator is ignorant or
malicious. Node operators are in a semi-trusted position. Having a
barrier to entry is probably a good thing.

@_date: 2016-09-01 23:21:18
@_author: Riad S. Wahby 
@_subject: Fwd: [Cryptography] "Flip Feng Shui: Hammering a Needle in the 
The answer is "it depends."
Machines with ECC RAM make successful rowhammer attacks considerably
harder, and meanwhile most cloud providers use ECC (e.g., Amazon uses
ECC on all machines according to their FAQ). In fact, the Flip Feng
Shui paper obliquely acknowledges that ECC helps to prevent the attack,
but doesn't quantify beyond "we have observed that Rowhammer can
occasionally induce multiple flips in a single 64-bit word" (\S 6.1.1).
For a better idea of how much harder it makes things, let's have a
look at another paper from USENIX Security this year,
    There's a bit of decoding to do here: all of the evaluation in
this paper uses machines that *don't* have ECC. Fortunately, we can
extrapolate from figure 13(c). Remember that with ECC, one needs to
flip 3 bits in a word to undetectably change the state of RAM: ECC
will silently fix 1-bit errors and produce a machine check exception
on a 2-bit error. How much harder is it to flip 1 bit than to flip
3? According to Fig. 13(c), it's ~30x harder to flip 2 bits than 1,
and another ~30x harder to flip 3 bits than 2.
As an aside: note that the attack the Xiao paper describes only works
against Xen guests that *don't* use hardware-assisted page tables
(EPT for Intel, NPT for AMD). If you're using hardware-assisted
virtualization (e.g., most Amazon "HVM" instances), this particular
attack won't work; others might, of course.
So if you're paranoid about rowhammer in a cloud setting, one strategy
is to monitor the MCE log and shut down any instance that's getting
a lot of uncorrectable ECC errors, as this may indicate an active
rowhammer attack. But my guess is that if someone is trying to pwn
you with a cross-VM attack, they're going to use something like
cache timing: it's harder to detect and probably easier to pull off,
assuming your cloud box has ECC RAM.
But as always, new discoveries might change the whole game.

@_date: 2016-09-02 08:31:32
@_author: Riad S. Wahby 
@_subject: Fwd: [Cryptography] "Flip Feng Shui: Hammering a Needle in the 
RAM sharing is necessary for the Razavi et al. attack. The Xen attack
is from Xiao et al.

@_date: 2016-09-03 17:29:07
@_author: Riad S. Wahby 
@_subject: 4096 bit SSL keys 
Multiplying two n-bit numbers naively costs O(n^2) operations (one
can do better with Karatsuba and related tricks), and exponentiation
costs O(n) multiplications (so O(n^3) in total). So assuming the device
is using something like Montgomery multiplication you'd expect about
8x increased load. 30x sounds like there *could* be some other issue
with the implementation, but a significant slowdown is not unexpected.
Depends who you ask.
    - NSA Suite B recommends at least 3072 bits.
- BSI says 2048 bits for now, but 3072 bits for 2017 and beyond.
- ANSSI and NIST both say 2048 bits should be fine through 2030.
All of the above recommendations seem to assume the adversary is
classical rather than quantum.
Shor's algorithm runs in time O(n^2) and requires O(n) qubits to
factor an n-bit number. The first doesn't offer much help: you're
only increasing the time by 4x going from 2048 to 4096 bits. I'm not
qualified to comment on how much the second helps because it's not
at all clear to me how the expense/difficulty of building a quantum
computer scales with the number of qubits.
But if you're worried about defending against general-purpose quantum
computers, there are other weak points you should be shoring up (no pun
intended): 256-bit symmetric ciphers, preferably with 256-bit blocks
(so Rijndael-256 rather than AES-256); and ephemeral key exchanges
that don't rely on Diffie-Hellman (Google is deploying RLWE and LWE
schemes in the next coupld years; supersingular isogeny D-H also
looks promising, but there's a recent attack that suggests caution).
In sum: it's a strange and scary new world once general-purpose quantum
computers arrive. In the next few years we're going to see the rollout
of new post-quantum ciphersuites. For now, maybe we should learn to
stop worrying and love the qubit :)

@_date: 2016-09-04 21:10:58
@_author: Riad S. Wahby 
@_subject: New list confirmation (Re: cpunks list relocation imminent (was: 
I'm guessing the big change since we moved the list is TLS.
SPF is already in place.
There's a DKIM pubkey with the selector "email" to which Greg's server
(presumably) has the secret. But it is somewhat unusual, as far as
I know, for listservs to add their own DKIM signatures when passing
mail through; certainly mine never did. Usually the idea is that you
check the sender's DKIM, and the listserv should just avoid munging
headers so that the signatures can still be checked by the recipient.
I'd be surprised if DMARC changes much since I never had it set up
either, but of course I could be wrong.

@_date: 2016-09-01 11:06:08
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
Yes. Really, procmail is all you need. If the local node is
mynodename.com, then make the posting address (cypherpunks go to
the procmailrc below and an internal address (_cypherpunks go to
the local mailman instance. So your /etc/aliases might have lines like:
    cypherpunks: |procmail -m /etc/procmailrcs/procmailrc_cpunks
    _cypherpunks: |mailman post cypherpunks
Note that you will have to tell mailman to accept messages addressed
to cypherpunks at somenode.com and cypherpunks at othernode.com in addition
to cypherpunks at mynodename.com.
As I said in my previous message, the harder part is sender whitelisting.
More on that below.
One more note: the scripts I used during the CDR days are available from
    See also
     /etc/procmailrcs/procmailrc_cpunks----
# This script is very similar to how the "backbone" operated in the
# original CDR, updated with the assumption that the nodes run mailman.
# NOTE that I have not tested this!!! :)
# nuke messages from MAILER-DAEMON or the local list instance
* (^From:.*MAILER-DAEMON
# keep a cache of message-IDs so that each message is only processed once
:0 Wh: msgid.lock
# maybe add a rule here to delete administrivia
# check whether this message is "backbone" traffic that we've already seen
* !^X-Loop:.*mynodename.com
! _cypherpunks at localhost
# now add an X-Loop header
# now bounce to other nodes
* !^X-Loop:.*somenode.com
! cypherpunks at somenode.com
* !^X-Loop:.*othernode.com
! cypherpunks at othernode.com
 /etc/procmailrcs/procmailrc_cpunks----
This is a nice thought, but it has two pretty major issues.
First, one of the reasons to have many nodes is so that nodes can apply
their own filtering policies to the traffic. But naively operating
the setup you describe would apply that filtering policy to mail
going from that node to other nodes, which is bad---the "backbone"
traffic should be unfiltered. It's possible to get around this issue,
but (e.g.) vanilla mailman can't do it.
Second, in the setup you describe, posting to the list instantly
reveals to everyone which node you're subscribed to, which is
information I was trying to keep hidden in the design I proposed.
If it's OK to reveal to other node operators which list a poster is
subscribed to, a simple solution is having the nodes share blinded
(e.g., hashed and salted) subscriber lists with one another (note
that this hides subscription information from everyone other than
node operators).
In my estimation, this is not a good idea. The reason is that adding
nodes to the network takes work from existing node owners. If the
incentive structure is such that it's almost no work to set up a new
node, then people will be incentivized to start nodes ("hey, that
sounds fun"), but not to keep them running ("ugh, too much work").
This will result in a bunch of node churn, which is bad.
Plus, what sane person would run a Docker image put together by a
bunch of strangers from Cypherpunks?
Finally, lowering the bar for people to run nodes sounds like a good
idea until you're subscribed to a node whose operator is ignorant or
malicious. Node operators are in a semi-trusted position. Having a
barrier to entry is probably a good thing.

@_date: 2016-09-01 11:06:08
@_author: Riad S. Wahby 
@_subject: moving on (multiple future forks) 
Yes. Really, procmail is all you need. If the local node is
mynodename.com, then make the posting address (cypherpunks go to
the procmailrc below and an internal address (_cypherpunks go to
the local mailman instance. So your /etc/aliases might have lines like:
    cypherpunks: |procmail -m /etc/procmailrcs/procmailrc_cpunks
    _cypherpunks: |mailman post cypherpunks
Note that you will have to tell mailman to accept messages addressed
to cypherpunks at somenode.com and cypherpunks at othernode.com in addition
to cypherpunks at mynodename.com.
As I said in my previous message, the harder part is sender whitelisting.
More on that below.
One more note: the scripts I used during the CDR days are available from
    See also
     /etc/procmailrcs/procmailrc_cpunks----
# This script is very similar to how the "backbone" operated in the
# original CDR, updated with the assumption that the nodes run mailman.
# NOTE that I have not tested this!!! :)
# nuke messages from MAILER-DAEMON or the local list instance
* (^From:.*MAILER-DAEMON
# keep a cache of message-IDs so that each message is only processed once
:0 Wh: msgid.lock
# maybe add a rule here to delete administrivia
# check whether this message is "backbone" traffic that we've already seen
* !^X-Loop:.*mynodename.com
! _cypherpunks at localhost
# now add an X-Loop header
# now bounce to other nodes
* !^X-Loop:.*somenode.com
! cypherpunks at somenode.com
* !^X-Loop:.*othernode.com
! cypherpunks at othernode.com
 /etc/procmailrcs/procmailrc_cpunks----
This is a nice thought, but it has two pretty major issues.
First, one of the reasons to have many nodes is so that nodes can apply
their own filtering policies to the traffic. But naively operating
the setup you describe would apply that filtering policy to mail
going from that node to other nodes, which is bad---the "backbone"
traffic should be unfiltered. It's possible to get around this issue,
but (e.g.) vanilla mailman can't do it.
Second, in the setup you describe, posting to the list instantly
reveals to everyone which node you're subscribed to, which is
information I was trying to keep hidden in the design I proposed.
If it's OK to reveal to other node operators which list a poster is
subscribed to, a simple solution is having the nodes share blinded
(e.g., hashed and salted) subscriber lists with one another (note
that this hides subscription information from everyone other than
node operators).
In my estimation, this is not a good idea. The reason is that adding
nodes to the network takes work from existing node owners. If the
incentive structure is such that it's almost no work to set up a new
node, then people will be incentivized to start nodes ("hey, that
sounds fun"), but not to keep them running ("ugh, too much work").
This will result in a bunch of node churn, which is bad.
Plus, what sane person would run a Docker image put together by a
bunch of strangers from Cypherpunks?
Finally, lowering the bar for people to run nodes sounds like a good
idea until you're subscribed to a node whose operator is ignorant or
malicious. Node operators are in a semi-trusted position. Having a
barrier to entry is probably a good thing.

@_date: 2016-09-01 23:21:18
@_author: Riad S. Wahby 
@_subject: Fwd: [Cryptography] "Flip Feng Shui: Hammering a Needle in the 
The answer is "it depends."
Machines with ECC RAM make successful rowhammer attacks considerably
harder, and meanwhile most cloud providers use ECC (e.g., Amazon uses
ECC on all machines according to their FAQ). In fact, the Flip Feng
Shui paper obliquely acknowledges that ECC helps to prevent the attack,
but doesn't quantify beyond "we have observed that Rowhammer can
occasionally induce multiple flips in a single 64-bit word" (\S 6.1.1).
For a better idea of how much harder it makes things, let's have a
look at another paper from USENIX Security this year,
    There's a bit of decoding to do here: all of the evaluation in
this paper uses machines that *don't* have ECC. Fortunately, we can
extrapolate from figure 13(c). Remember that with ECC, one needs to
flip 3 bits in a word to undetectably change the state of RAM: ECC
will silently fix 1-bit errors and produce a machine check exception
on a 2-bit error. How much harder is it to flip 1 bit than to flip
3? According to Fig. 13(c), it's ~30x harder to flip 2 bits than 1,
and another ~30x harder to flip 3 bits than 2.
As an aside: note that the attack the Xiao paper describes only works
against Xen guests that *don't* use hardware-assisted page tables
(EPT for Intel, NPT for AMD). If you're using hardware-assisted
virtualization (e.g., most Amazon "HVM" instances), this particular
attack won't work; others might, of course.
So if you're paranoid about rowhammer in a cloud setting, one strategy
is to monitor the MCE log and shut down any instance that's getting
a lot of uncorrectable ECC errors, as this may indicate an active
rowhammer attack. But my guess is that if someone is trying to pwn
you with a cross-VM attack, they're going to use something like
cache timing: it's harder to detect and probably easier to pull off,
assuming your cloud box has ECC RAM.
But as always, new discoveries might change the whole game.

@_date: 2016-09-02 08:31:32
@_author: Riad S. Wahby 
@_subject: Fwd: [Cryptography] "Flip Feng Shui: Hammering a Needle in the 
RAM sharing is necessary for the Razavi et al. attack. The Xen attack
is from Xiao et al.

@_date: 2016-09-03 17:29:07
@_author: Riad S. Wahby 
@_subject: 4096 bit SSL keys 
Multiplying two n-bit numbers naively costs O(n^2) operations (one
can do better with Karatsuba and related tricks), and exponentiation
costs O(n) multiplications (so O(n^3) in total). So assuming the device
is using something like Montgomery multiplication you'd expect about
8x increased load. 30x sounds like there *could* be some other issue
with the implementation, but a significant slowdown is not unexpected.
Depends who you ask.
    - NSA Suite B recommends at least 3072 bits.
- BSI says 2048 bits for now, but 3072 bits for 2017 and beyond.
- ANSSI and NIST both say 2048 bits should be fine through 2030.
All of the above recommendations seem to assume the adversary is
classical rather than quantum.
Shor's algorithm runs in time O(n^2) and requires O(n) qubits to
factor an n-bit number. The first doesn't offer much help: you're
only increasing the time by 4x going from 2048 to 4096 bits. I'm not
qualified to comment on how much the second helps because it's not
at all clear to me how the expense/difficulty of building a quantum
computer scales with the number of qubits.
But if you're worried about defending against general-purpose quantum
computers, there are other weak points you should be shoring up (no pun
intended): 256-bit symmetric ciphers, preferably with 256-bit blocks
(so Rijndael-256 rather than AES-256); and ephemeral key exchanges
that don't rely on Diffie-Hellman (Google is deploying RLWE and LWE
schemes in the next coupld years; supersingular isogeny D-H also
looks promising, but there's a recent attack that suggests caution).
In sum: it's a strange and scary new world once general-purpose quantum
computers arrive. In the next few years we're going to see the rollout
of new post-quantum ciphersuites. For now, maybe we should learn to
stop worrying and love the qubit :)

@_date: 2016-09-04 21:10:58
@_author: Riad S. Wahby 
@_subject: New list confirmation (Re: cpunks list relocation imminent (was: 
I'm guessing the big change since we moved the list is TLS.
SPF is already in place.
There's a DKIM pubkey with the selector "email" to which Greg's server
(presumably) has the secret. But it is somewhat unusual, as far as
I know, for listservs to add their own DKIM signatures when passing
mail through; certainly mine never did. Usually the idea is that you
check the sender's DKIM, and the listserv should just avoid munging
headers so that the signatures can still be checked by the recipient.
I'd be surprised if DMARC changes much since I never had it set up
either, but of course I could be wrong.
