
@_date: 2013-11-04 20:16:29
@_author: Theodore Ts'o 
@_subject: [Cryptography] randomness +- entropy 
One of the reasons why we don't attempt to extract "true random bits"
and save them across a reboot is that even we had such bits that were
secure even if the underlying crypto primitives were compromised to a
fare-thee-well, once you write them to the file on the hard drive and
the OS gets shut down, there's no guarantee that an adversary might
not be able to read the bits while the OS is shut down.  Even if you
don't do something truly stupid (such as leaving your laptop
unattended in a hotel room while visiting China), the risk of having
your "true random bits" stolen is probably higher than the
cryptographic primitives getting compromised.
That's probably one of the reasons why people tend to not necessarily
worry about the difference between a CSRNG and a TRNG in practice.
For example, these are the people who believe that we should just
replace Linux's /dev/random with a Fortuna RNG which doesn't even
pretend to try to track entropy estimates, and which fundamentally
assumes that the underlying crypto algorithms are secure, or at least,
not the weakest link to worry about.  (Again, realistically, the
chances that your OS kernel has some 0-day vulnerability that the
NSA's Tailored Access Operations folks have purchased from some black
hat is probably a bigger risk than there being a cryptographic
weakness in AES or SHA that is exploitable given the how we are using
the encryption or crypto hash in Yarrow, Fortuna or Linux's
I still think it's worth it to have a /dev/random where we attempt to
make an estimate of the entropy that we've collected and then later
dispensed.  But I recognize that from a engineering perspective, the
distinction is not going to be that important for many people who are
interested in practical security issues.
The cryptography mailing list

@_date: 2013-11-04 20:16:29
@_author: Theodore Ts'o 
@_subject: [Cryptography] randomness +- entropy 
One of the reasons why we don't attempt to extract "true random bits"
and save them across a reboot is that even we had such bits that were
secure even if the underlying crypto primitives were compromised to a
fare-thee-well, once you write them to the file on the hard drive and
the OS gets shut down, there's no guarantee that an adversary might
not be able to read the bits while the OS is shut down.  Even if you
don't do something truly stupid (such as leaving your laptop
unattended in a hotel room while visiting China), the risk of having
your "true random bits" stolen is probably higher than the
cryptographic primitives getting compromised.
That's probably one of the reasons why people tend to not necessarily
worry about the difference between a CSRNG and a TRNG in practice.
For example, these are the people who believe that we should just
replace Linux's /dev/random with a Fortuna RNG which doesn't even
pretend to try to track entropy estimates, and which fundamentally
assumes that the underlying crypto algorithms are secure, or at least,
not the weakest link to worry about.  (Again, realistically, the
chances that your OS kernel has some 0-day vulnerability that the
NSA's Tailored Access Operations folks have purchased from some black
hat is probably a bigger risk than there being a cryptographic
weakness in AES or SHA that is exploitable given the how we are using
the encryption or crypto hash in Yarrow, Fortuna or Linux's
I still think it's worth it to have a /dev/random where we attempt to
make an estimate of the entropy that we've collected and then later
dispensed.  But I recognize that from a engineering perspective, the
distinction is not going to be that important for many people who are
interested in practical security issues.
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-11-04 20:16:29
@_author: Theodore Ts'o 
@_subject: [Cryptography] randomness +- entropy 
One of the reasons why we don't attempt to extract "true random bits"
and save them across a reboot is that even we had such bits that were
secure even if the underlying crypto primitives were compromised to a
fare-thee-well, once you write them to the file on the hard drive and
the OS gets shut down, there's no guarantee that an adversary might
not be able to read the bits while the OS is shut down.  Even if you
don't do something truly stupid (such as leaving your laptop
unattended in a hotel room while visiting China), the risk of having
your "true random bits" stolen is probably higher than the
cryptographic primitives getting compromised.
That's probably one of the reasons why people tend to not necessarily
worry about the difference between a CSRNG and a TRNG in practice.
For example, these are the people who believe that we should just
replace Linux's /dev/random with a Fortuna RNG which doesn't even
pretend to try to track entropy estimates, and which fundamentally
assumes that the underlying crypto algorithms are secure, or at least,
not the weakest link to worry about.  (Again, realistically, the
chances that your OS kernel has some 0-day vulnerability that the
NSA's Tailored Access Operations folks have purchased from some black
hat is probably a bigger risk than there being a cryptographic
weakness in AES or SHA that is exploitable given the how we are using
the encryption or crypto hash in Yarrow, Fortuna or Linux's
I still think it's worth it to have a /dev/random where we attempt to
make an estimate of the entropy that we've collected and then later
dispensed.  But I recognize that from a engineering perspective, the
distinction is not going to be that important for many people who are
interested in practical security issues.
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-19 10:33:34
@_author: Theodore Ts'o 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
At the risk of repeating myself, we made a lot of changes to the
P's and Q's paper (patches went into mainline the first week in July,
and got propagated to older kernels via the stable kernel trees about
2 weeks later; the paper was published at Usenix Security in August.)
One of them was to do precisely this --- /dev/urandom now mixes in
salting information (ethernet MAC addresses, etc, via the new
interface add_device_randomness).  Zero entropy is indeed assessed,
and the main goal is to avoid the trivially easy case of shared primes
in the case where we fail to gather enough entropy.
The other change we made was to gather entropy on every single
interrupt, instead of only on those device drivers where the device
driver authors gave us permission to collect entropy.  That was a
mistake, because device driver maintainers care about performance and
CPU efficiency at all costs, and they don't particularly care about
entropy collection.  So we made entropy collection fast, and
As I've already said, I'm open to adding code that blocks /dev/urandom
until "enough" entropy has been collected.  But that's an
interface-visible change, and it could break things.  So there is due
diligence that will need to be done first, because the reality is if
it breaks things, people will just comment it out, and it will be
harder to propagate the change in the future.  In the real world, the
product manager is often as much a security engineer's adversary as
Boris and Natasha.  :-(
The cryptography mailing list

@_date: 2013-10-27 04:15:36
@_author: Theodore Ts'o 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Peter Saint-Andre Yes, absolutely.  For example, if you assume that the attacker has
network taps at Fort Meade and in a phone closets of companies like
AT&T, they are very likely not going to be able to watch your LAN
traffic.  OTOH, if they have physical access to your LAN such that
they can drop an agent close to your computer that can monitor all of
the packets hitting your computer, we have to ask how are they doing
this?  If they can someone break into your local ethernet switch
remotely, then you might be in a world of hurt (although usually
switches generally don't have enough of general purpose CPU that this
is likely).
If you posit a "black bag" job where they physically break into your
house, and replace your ethernet switch, then they could presumably
place a keyboard bug on your keyboard, or otherwise physically tamper
with your computer, install audio/video surveillance equipment in an
HVAC duct, etc. --- and then you're either doing something really
black hatish, or I have a tin foil hat to sell to you, or possibly
both.  :-)
My challenge as someone who is designing things like a general purpose
about the threat environment might make sense in a large set of
hypothetical scenarios, and which do not.  I can imagine scenarios
where the adversary is on a public network --- say, at a University
dorm network --- who might be able to watch interpacket network
arrival times, but who probably can't make a lot of assumptions about
HDD completion drive times --- and the user might want to generate a
securely long-term public key for their ssh host key or for GPG.
I'm less willing to accept as a valid threat model one where the
adversary has near-total control over _all_ entropy sources, *and* can
divine the state of the prng, but has no other access to the system so
they can't break root in other ways, *and* where if you can't prove
that you can make the prng secure again, it's somehow horrible and
your rng is not robust (and that the authors of said paper should
deserve lots of citations so they can get a suitably high impact score
on their way to achieving tenure :-).
But maybe there are scenarios where such a threat environment is
actually realistic.  I'm certainly willing to hear someone try to give
me an example of such a threat environment; it would probably be quite
The cryptography mailing list

@_date: 2013-10-28 18:04:01
@_author: Theodore Ts'o 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
And this is *already* in Linux's /dev/random code since July 2012.
(There is another problem caused by proprietary binary drivers from
!@ proprietary chips from a company whose name shall remain
starting with the letter Q, forcing some home routers to still be
using ancient, years-old 2.6 kernels, but that's not a problem under
my control.  Said 2.6 kernels probably have huge numbers of zero-day
flaws, some of which might allow a remote adversary to be able to
execute a buffer overflow attack in kernel space, making flaws in the
random number generator somewhat irrelevant...)
There is no "solve".  In all of these cases, it's going to be very
dependent on the hardware involved.  Many home routers might only have
two or three devices, so even if you get four bits per device, that's
only going to be 12 bits of extra entropy.  In combination with the
entropy that we get from sampling interrupts, and if the device holds
off on generation of public/private keypairs until they are actually
needed, hopefully it will be enough.  In other cases, if there are
almost no init scripts configured, and SSH keys generated as the very
thing after a cold power up, even adding device attach times might not
be sufficient to defeat an adversary who is doing deep analysis about
your particular home router's hardware and software setup.
We are already adding the CPU time elapsed (userspace plus kernel
time) for each process when it exits.  The theory behind this is that
we have this information anyway, and process exits are a place where
adding a call to add_device_randomness() isn't going to hurt system
performance.  We don't credit the entropy counter with any additional
randomness, but the theory is that it can't hurt, and it might help.
It's hopeful that for a system that is running shell scripts as part
of boot, there will be at least some entropy added by sampling these
values, even if it is not a huge amount.
In theory this could be done for other system timings, but we need to
chose things that minimize overhead imposed on the system.       	     	  	   	    	       - Ted
The cryptography mailing list

@_date: 2013-10-19 10:33:34
@_author: Theodore Ts'o 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
At the risk of repeating myself, we made a lot of changes to the
P's and Q's paper (patches went into mainline the first week in July,
and got propagated to older kernels via the stable kernel trees about
2 weeks later; the paper was published at Usenix Security in August.)
One of them was to do precisely this --- /dev/urandom now mixes in
salting information (ethernet MAC addresses, etc, via the new
interface add_device_randomness).  Zero entropy is indeed assessed,
and the main goal is to avoid the trivially easy case of shared primes
in the case where we fail to gather enough entropy.
The other change we made was to gather entropy on every single
interrupt, instead of only on those device drivers where the device
driver authors gave us permission to collect entropy.  That was a
mistake, because device driver maintainers care about performance and
CPU efficiency at all costs, and they don't particularly care about
entropy collection.  So we made entropy collection fast, and
As I've already said, I'm open to adding code that blocks /dev/urandom
until "enough" entropy has been collected.  But that's an
interface-visible change, and it could break things.  So there is due
diligence that will need to be done first, because the reality is if
it breaks things, people will just comment it out, and it will be
harder to propagate the change in the future.  In the real world, the
product manager is often as much a security engineer's adversary as
Boris and Natasha.  :-(
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-27 04:15:36
@_author: Theodore Ts'o 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Peter Saint-Andre Yes, absolutely.  For example, if you assume that the attacker has
network taps at Fort Meade and in a phone closets of companies like
AT&T, they are very likely not going to be able to watch your LAN
traffic.  OTOH, if they have physical access to your LAN such that
they can drop an agent close to your computer that can monitor all of
the packets hitting your computer, we have to ask how are they doing
this?  If they can someone break into your local ethernet switch
remotely, then you might be in a world of hurt (although usually
switches generally don't have enough of general purpose CPU that this
is likely).
If you posit a "black bag" job where they physically break into your
house, and replace your ethernet switch, then they could presumably
place a keyboard bug on your keyboard, or otherwise physically tamper
with your computer, install audio/video surveillance equipment in an
HVAC duct, etc. --- and then you're either doing something really
black hatish, or I have a tin foil hat to sell to you, or possibly
both.  :-)
My challenge as someone who is designing things like a general purpose
about the threat environment might make sense in a large set of
hypothetical scenarios, and which do not.  I can imagine scenarios
where the adversary is on a public network --- say, at a University
dorm network --- who might be able to watch interpacket network
arrival times, but who probably can't make a lot of assumptions about
HDD completion drive times --- and the user might want to generate a
securely long-term public key for their ssh host key or for GPG.
I'm less willing to accept as a valid threat model one where the
adversary has near-total control over _all_ entropy sources, *and* can
divine the state of the prng, but has no other access to the system so
they can't break root in other ways, *and* where if you can't prove
that you can make the prng secure again, it's somehow horrible and
your rng is not robust (and that the authors of said paper should
deserve lots of citations so they can get a suitably high impact score
on their way to achieving tenure :-).
But maybe there are scenarios where such a threat environment is
actually realistic.  I'm certainly willing to hear someone try to give
me an example of such a threat environment; it would probably be quite
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-28 18:04:01
@_author: Theodore Ts'o 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
And this is *already* in Linux's /dev/random code since July 2012.
(There is another problem caused by proprietary binary drivers from
!@ proprietary chips from a company whose name shall remain
starting with the letter Q, forcing some home routers to still be
using ancient, years-old 2.6 kernels, but that's not a problem under
my control.  Said 2.6 kernels probably have huge numbers of zero-day
flaws, some of which might allow a remote adversary to be able to
execute a buffer overflow attack in kernel space, making flaws in the
random number generator somewhat irrelevant...)
There is no "solve".  In all of these cases, it's going to be very
dependent on the hardware involved.  Many home routers might only have
two or three devices, so even if you get four bits per device, that's
only going to be 12 bits of extra entropy.  In combination with the
entropy that we get from sampling interrupts, and if the device holds
off on generation of public/private keypairs until they are actually
needed, hopefully it will be enough.  In other cases, if there are
almost no init scripts configured, and SSH keys generated as the very
thing after a cold power up, even adding device attach times might not
be sufficient to defeat an adversary who is doing deep analysis about
your particular home router's hardware and software setup.
We are already adding the CPU time elapsed (userspace plus kernel
time) for each process when it exits.  The theory behind this is that
we have this information anyway, and process exits are a place where
adding a call to add_device_randomness() isn't going to hurt system
performance.  We don't credit the entropy counter with any additional
randomness, but the theory is that it can't hurt, and it might help.
It's hopeful that for a system that is running shell scripts as part
of boot, there will be at least some entropy added by sampling these
values, even if it is not a huge amount.
In theory this could be done for other system timings, but we need to
chose things that minimize overhead imposed on the system.       	     	  	   	    	       - Ted
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-19 10:33:34
@_author: Theodore Ts'o 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
At the risk of repeating myself, we made a lot of changes to the
P's and Q's paper (patches went into mainline the first week in July,
and got propagated to older kernels via the stable kernel trees about
2 weeks later; the paper was published at Usenix Security in August.)
One of them was to do precisely this --- /dev/urandom now mixes in
salting information (ethernet MAC addresses, etc, via the new
interface add_device_randomness).  Zero entropy is indeed assessed,
and the main goal is to avoid the trivially easy case of shared primes
in the case where we fail to gather enough entropy.
The other change we made was to gather entropy on every single
interrupt, instead of only on those device drivers where the device
driver authors gave us permission to collect entropy.  That was a
mistake, because device driver maintainers care about performance and
CPU efficiency at all costs, and they don't particularly care about
entropy collection.  So we made entropy collection fast, and
As I've already said, I'm open to adding code that blocks /dev/urandom
until "enough" entropy has been collected.  But that's an
interface-visible change, and it could break things.  So there is due
diligence that will need to be done first, because the reality is if
it breaks things, people will just comment it out, and it will be
harder to propagate the change in the future.  In the real world, the
product manager is often as much a security engineer's adversary as
Boris and Natasha.  :-(
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-27 04:15:36
@_author: Theodore Ts'o 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Yes, absolutely.  For example, if you assume that the attacker has
network taps at Fort Meade and in a phone closets of companies like
AT&T, they are very likely not going to be able to watch your LAN
traffic.  OTOH, if they have physical access to your LAN such that
they can drop an agent close to your computer that can monitor all of
the packets hitting your computer, we have to ask how are they doing
this?  If they can someone break into your local ethernet switch
remotely, then you might be in a world of hurt (although usually
switches generally don't have enough of general purpose CPU that this
is likely).
If you posit a "black bag" job where they physically break into your
house, and replace your ethernet switch, then they could presumably
place a keyboard bug on your keyboard, or otherwise physically tamper
with your computer, install audio/video surveillance equipment in an
HVAC duct, etc. --- and then you're either doing something really
black hatish, or I have a tin foil hat to sell to you, or possibly
both.  :-)
My challenge as someone who is designing things like a general purpose
about the threat environment might make sense in a large set of
hypothetical scenarios, and which do not.  I can imagine scenarios
where the adversary is on a public network --- say, at a University
dorm network --- who might be able to watch interpacket network
arrival times, but who probably can't make a lot of assumptions about
HDD completion drive times --- and the user might want to generate a
securely long-term public key for their ssh host key or for GPG.
I'm less willing to accept as a valid threat model one where the
adversary has near-total control over _all_ entropy sources, *and* can
divine the state of the prng, but has no other access to the system so
they can't break root in other ways, *and* where if you can't prove
that you can make the prng secure again, it's somehow horrible and
your rng is not robust (and that the authors of said paper should
deserve lots of citations so they can get a suitably high impact score
on their way to achieving tenure :-).
But maybe there are scenarios where such a threat environment is
actually realistic.  I'm certainly willing to hear someone try to give
me an example of such a threat environment; it would probably be quite
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-28 18:04:01
@_author: Theodore Ts'o 
@_subject: [Cryptography] [RNG] /dev/random initialisation 
And this is *already* in Linux's /dev/random code since July 2012.
(There is another problem caused by proprietary binary drivers from
!@ proprietary chips from a company whose name shall remain
starting with the letter Q, forcing some home routers to still be
using ancient, years-old 2.6 kernels, but that's not a problem under
my control.  Said 2.6 kernels probably have huge numbers of zero-day
flaws, some of which might allow a remote adversary to be able to
execute a buffer overflow attack in kernel space, making flaws in the
random number generator somewhat irrelevant...)
There is no "solve".  In all of these cases, it's going to be very
dependent on the hardware involved.  Many home routers might only have
two or three devices, so even if you get four bits per device, that's
only going to be 12 bits of extra entropy.  In combination with the
entropy that we get from sampling interrupts, and if the device holds
off on generation of public/private keypairs until they are actually
needed, hopefully it will be enough.  In other cases, if there are
almost no init scripts configured, and SSH keys generated as the very
thing after a cold power up, even adding device attach times might not
be sufficient to defeat an adversary who is doing deep analysis about
your particular home router's hardware and software setup.
We are already adding the CPU time elapsed (userspace plus kernel
time) for each process when it exits.  The theory behind this is that
we have this information anyway, and process exits are a place where
adding a call to add_device_randomness() isn't going to hurt system
performance.  We don't credit the entropy counter with any additional
randomness, but the theory is that it can't hurt, and it might help.
It's hopeful that for a system that is running shell scripts as part
of boot, there will be at least some entropy added by sampling these
values, even if it is not a huge amount.
In theory this could be done for other system timings, but we need to
chose things that minimize overhead imposed on the system.       	     	  	   	    	       - Ted
The cryptography mailing list
cryptography at metzdowd.com
