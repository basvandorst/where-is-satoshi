
@_date: 2013-03-05 20:26:37
@_author: Yosem Companys 
@_subject: [liberationtech] CfP: 4S, 
Call for Papers (w/ apologies for cross-listing)
Surveillance and the Mediation of Big Data
4S session(s) organized by Torin Monahan and Anders Albrechtslund
4S Annual Meeting (
San Diego, CA
October 9 - 12, 2013
The bbig datab paradigm signals an intensification and distribution of
algorithmic surveillance across multiple organizational and
geographical scales. More than an exponential advancement in storage
and processing capacity, big data currently operates as a fluid
metaphor for the potential of data analytics to intelligently predict
and respond to the needs of individuals and institutions. Clearly STS
inquiry could fruitfully deconstruct the technological deterministic
slant of discourses surrounding big data so that attention could be
drawn to the values being inscribed in algorithms, the profound
materiality of cloud computing, the control dimensions of pervasive
software, and the active cultivation of new subjectivities as people
come to understand themselves through their data doubles. Surveillance
is key to these processes, as the capture and processing of data is
frequently oriented toward some form of intervention or control.
Rather than viewing surveillance through big data as completely
automated or neutral processes, this panel seeks to investigate the
many forms of mediation and politics inherent in big-data
Possible areas of inquiry might include:
B7      Data fusion, profiling, and prediction by security organizations.
B7      The crafting of new subjectivities as individuals embrace
bquantified selfb movements.
B7      The social and political effects of bfilter bubblesb erected by
various search platforms.
B7      Gamification of interaction with customers and clients as
public and private organizations seek to capitalize on (and control)
user involvement.
B7      Activist and civil-society harnessing of data repositories and
sensing devices to achieve progressive outcomes.
B7      The optimization of urban infrastructures through bsmartb
information technologies.
B7      Health technologies used for documentation, analyses,
predictions and recommendations.
Please email titles, abstracts, and institutional affiliations to
Torin Monahan  and Anders Albrechtslund
 by March 15, 2013.
Torin Monahan, Ph.D.
Associate Editor, Surveillance & Society
Associate Professor
Dept. of Communication Studies
The University of North Carolina at Chapel Hill
NEW BOOK: SuperVision: An Introduction to the Surveillance Society
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-08 12:06:28
@_author: Yosem Companys 
@_subject: [liberationtech] Mechanical Turk is not anonymous 
This may be of interest to those in community using Amazon's Mechanical
Turk platform for research, as well as those more generally interested
in how online data can be linked in ways that can be surprising to
people in practice and compromise their privacy in a manner they didn't
Several collaborators and I have just announced discovery of a
vulnerability on Amazon's Mechanical Turk platform, with potential
implications for IRB governance of human subjects research using AMT at
US universities. In particular, this vulnerability can be exploited to
obtain personally identifying information (PII) and other private
information of some workers, who may have shared this information online
in a way they did not recognize could be linked to their WorkerIDs.
This may impact IRB oversight of research conducted at UT with AMT, as
well as what research is classified as human research and subject to IRB
governance.  I am just starting to follow up on this now with our IRB
coordinator here at UT Austin.
The announcement of our finding is below:
Blog post: Paper: We are now trying to get the word out to be AMT workers, as well as
researchers whose might be impacted or who may have posted WorkerIDs
online which could be compromised via this vulnerability. We would
appreciate your help with this.
We are also specifically advocating *against* online posting of
WorkerIDs due to the risk of workers not having realized that
information they have shared could be linked with their worker accounts.
Regardless of the vulnerability, we have also found explicit requests
from workers to not post such uniquely identifying information.
Too many emails? Unsubscribe, change to digest, or change password by emailing moderator at companys at stanford.edu or changing your settings at

@_date: 2013-03-15 12:09:28
@_author: Yosem Companys 
@_subject: [liberationtech] Stanford Magazine - Can I Get Some Privacy? - 
How much do Internet companies know about us, and what do they plan to do with
the information? If only we knew.
By Brian Eule, Stanford Magazine
ASSUMING YOU POSSESS a cell phone and a computer and a credit card, the
following scenario, or something like it, might sound familiar.
Your morning begins with coffee and a bagel and the morning paper, perhaps
read on a laptop. You click on stories about Egyptian unrest, the firearms
industry and Downton Abbey. Two other websites are open on your desktop. One
of them shows your Facebook account. You notice that you've been "tagged" in a
photo from last week's poker game, in a pose that suggests one too many beers.
Meanwhile, a friend has sent you a link to an article in the Onion that
zestfully parodies a well-known senator. You "like" it.
You head out for your daily commute. At the toll booth, a Fastrak device
validates the code on your car and records the date and time of your arrival.
You stop for gas. You swipe your debit card. The pump asks for your ZIP code
and you type it in. As the 20-gallon tank fills, you pull out your smartphone
and do a quick search for a weekend flight to Chicago. Along with the flight
schedules and airfares, an advertisement appears about a local concert at the
same venue where you attended a performance last month.
In the first two hours of your day, computers have recorded that you are a
likely watcher of PBS, you drink alcohol and you have a penchant for
irreverent humor. They know you drive a large vehicle and probably have family
in the Midwest. They know when you go to work and the route you take. It's 8
a.m. and you've already left a sizable virtual fingerprint.
Now add the dozens of other electronic transactions you make in a given
daybevery website you visit, every item you purchase online, all the
searches you do, all the posts you make on social media sitesbplus those of
all your friends. Multiply that by hundreds of days of Internet activity.
Throw in motor vehicle records, mortgage documents, credit scores, medical
diagnoses. What does your profile look like now?
Data about all of us lives online, in "clouds," on our web browsers and in
others' databases. Cell phones show our physical location and track the places
we have been. Websites display the address and price of home purchases, along
with the buyer and seller. Advertising agencies know the web pages we have
visited and the text we have entered online. Increasingly, and with increasing
sophistication, companies are collecting, analyzing and selling data about
tens of millions of people. And most of those people have no idea when or how
it's happening.
"I don't think that people understand all the information that's out there
about them," says Jennifer Granick, director of civil liberties at Stanford
Law School's Center for Internet and Society. "People might not think that you
can put it all together, but they're wrong. It's increasingly easy to figure
out who people are. There is a treasure trove of information out there that is
The interdisciplinary CIS is helping to expose the massive asymmetry between
the average consumer's understanding and practices that might threaten their
privacy. Its scholars, along with privacy advocates in the nonprofit sector,
are pushing for more transparency and stricter industry standards in how data
is collected and used.
Concern about privacy intrusions often originates from an innocuous-sounding
source: cookies. So named because of the "crumbs" of information they collect,
cookies are codes imbedded in a computer hard drive that track web activity.
They are legal and in many ways beneficial. For example, cookies "remember"
passwords so repeat users of a site don't have to type it in every time they
return. They save user preferences and enable basic Internet conventions like
a shopping cart that makes online buying easier and less time-consuming. But a
third party, unbeknownst to the user, also can set cookies that follow that
user from site to site, gathering information about him or her. The
proliferation of this practice has spawned a new business category: data
brokers. These companies harvest public records along with web activity of all
kinds, then mash it up with algorithms designed to help clients target
potential customers with advertisements. Although individual names aren't
attached to this data, scholars say there is sufficient information to tease
out a person's identity.
"Web browsing history is inextricably linked to personal information," wrote
Jonathan Mayer, a Law School student and a PhD student in computer science,
and Stanford computer science professor John C. Mitchell, in a paper last year
for the Institute of Electrical and Electronics Engineers Symposium on
Security and Privacy. "The pages a user visits can reveal her location,
interests, purchases, employment status, sexual orientation, financial
challenges, medical conditions, and more. Examining individual page loads is
often adequate to draw many conclusions about a user; analyzing patterns of
activity allows yet more inferences."
AT AN EXTREME, piecing together information that exists about each of us can
be used for identity theft. But that's rare in comparison to more typical
concerns regarding the lack of control over who sees what personal
information, how they use it and what decisions they base on it. Aleecia M.
McDonald, director of privacy at the CIS, notes that banks might charge a
higher mortgage rate for a customer whose friends on Facebook had negative
credit events. Or, web merchants might adjust the price of products based on a
customer's ZIP code. Much of the concern, McDonald notes, resides in the
uncertainty over how all of the information will eventually be employed.
It's not just the things they disclose that people find troubling; "it's also
this data leakage about what they do online and what they're interested in,
their intellectual history and then also their friends," McDonald says. "They
don't know where the data is going, they don't know how it's used, and they
don't know what happens 10, 20, 40, 50 years from now."
Inferences based on what a user does online and who their friends are can be
misleading. Car insurance companies already vary premiums based on
demographics, but what if a user's Internet searches also informed a risk
assessment? Taken out of context, most of us have conducted searches that
might look suspicious if revealed in raw form. Employers are allowed to ask a
job applicant to log in and show them their Facebook page during an interview.
What if they also could see your search history? Might a college reject an
applicant based on additional information that now lives online?
Earlier this year, Facebook announced a feature it called "graph search" which
allowed users to search for others who have "liked" various topics or checked
in at specific locations. Privacy advocates howled. Here was information
people might have voluntarily shared, but did not expect to be catalogued.
Information once known only to close friends might now more easily be found by
strangersband paired with other information. The Electronic Frontier
Foundation, a nonprofit that champions consumers' digital rights, used the
example of a graph-search-enabled query for "People who work at Apple, Inc.
who like Samsung Mobile," information that, if shared, might put those
employees in an awkward position. For its part, Facebook is encouraging all
users to revisit their privacy settings, which locks down some of what others
could find via graph search.
Google logs massive amounts of information about its users and, "regularly
receives requests from governments and courts around the world to hand over
user data," according to the company's transparency reports. In the second
half of 2012, Google received requests for information on more than 33,000
users' accounts and complied with 66 percent of those.
An investigation by the Wall Street Journal in 2010 found that, "the nation's
50 top websites on average installed 64 pieces of tracking technology onto the
computers of visitors, usually with no warning." Twelve of them, it noted,
installed more than 100.
Privacy concerns may vary by age. McDonald speculates that younger generations
might be most vigilant about protecting their privacy from their parents. The
middle generation might be most concerned with what employers or health care
providers might learn about them. Regardless of age, much of the issue centers
around control, or lack of it.
"The question, on some level, is 'Whose data is it?' " McDonald says.
And the problem isn't confined to for-profit companies. Last October, Mayer
noticed an article in the New York Times about the use of third-party trackers
by the Obama and Romney campaigns. Both campaigns claimed they had safeguards
in place to protect users' anonymity. Mayer didn't buy it. "This seemed pretty
implausible to me," he says. "It was frustrating, at this level of politics,
that they were making this claim."
So he fired up an open source platform he had created, called FourthParty,
that measures dynamic web contentbsites whose offerings vary based on
different information provided by the user or the programband monitors
interactions with web applications. Mayer had to give himself a screen name,
so he went with "Leland Stanford." Then he entered some information and tried
to see what ended up in the page codes that got passed along.
Within a day, Mayer had confirmed his hunch. On both campaign sites, personal
informationbin some instances a user's name, in others an address or ZIP
codebwas included in the page web address that was given to the third-party
Mayer didn't think it was an intentional privacy breach, but he felt the
parties should have known better than to claim they could keep the data
Facebook presents a particular dilemma. The site is extraordinarily popular in
part because it fosters connections by inviting people to share information.
But its reach and aggressiveness in collecting user data are troubling, says
Mayer. His research indicates roughly half of web browsers are logged into
Facebook while users are visiting other pages. Each time those users visit a
page that also has a Facebook icon, the information is sent back to Facebook.
Even if the user doesn't click on that icon.
In the absence of strong controls, what are consumers to do to protect
themselves? One strategy: Pay for privacy. Start-ups such as Reputation.com
will scrub personal information from online databases for a fee. But while
some people are willing to pay, critics say consumers need better options.
"Having to pay a fee in order to engage in a retrospective effort to claw back
personal information doesn't seem to us the right way to go about this," David
Vladeck, then director of the Bureau of Consumer Protection at the Federal
Trade Commission, said at a congressional hearing in 2010.
Deleting cookies from one's computer is only a half measure. There are still
other fingerprints left behind, Mayer says. Which version of which web browser
they use, which Windows updates they have, which plugins they installed, the
order of the updates they downloaded, and so on, all create a unique trail of
sites visited. "Consumers by and large have no idea what's going on," he
Scholars at CIS are actively working to strengthen individuals' remedies. Each
Wednesday, members of an international World Wide Web working group on
tracking protection dial in to a conference call. Their mission is to "improve
user privacy and user control by defining mechanisms for expressing user
preferences around Web tracking and for blocking or allowing Web tracking
elements." Representatives from academia and industry, including people from
Microsoft, Apple, Facebook, Google and Mozilla, try to agree on a set of
recommendations for the field. McDonald and Mayer both participate.
Much of the discussion stems from a relatively simple idea that Mayer and
Arvind Narayanan, a former postdoc at Stanford, now an affiliate scholar at
the CIS and professor at Princeton, helped demonstrate.
Around 2007, in response to increased tracking on the web, privacy advocates
explored a Do Not Track program that would provide website users a means of
blocking trackers. It would work much like the Do Not Call registry adopted to
protect consumers from intrusive telephone marketers. It seemed more sensible
to work from the user end, rather than having each company offer an opt-out,
but many in the industry thought it was impossible to do.
Mayer and Narayanan began writing on the subject, describing on a blog how it
would work: A header in an HTTP field, the building block of the web, would
signal the computer not to collect information, thus enabling users to opt out
of tracking of all kinds. They tried to show companies ways they could respond
to protect their businesses. It is "a simple technology that is completely
compatible with the existing web," they wrote. "We believe regulation is
necessary to verify and enforce compliance with a user's choice to opt out of
tracking." In a "Do Not Track Cookbook," which they posted online, Mayer and
Narayanan proposed limiting identifiers to each website to prevent tracking
from one place to another.
A 2010 FTC report recommended implementing a Do Not Track mechanism; several
web browsers have adopted its use, but compliance is voluntary and its
effectiveness has been limited.
UNLIKE SOME COUNTRIES that have codified a comprehensive right to privacy,
Jennifer Granick notes, the United States has no universal privacy law.
Instead, it relies on a patchwork of regulations and the Fourth Amendment,
which states: "The right of the people to be secure in their persons, houses,
papers, and effects, against unreasonable searches and seizures, shall not be
violated, and no Warrants shall issue, but upon probable cause, supported by
Oath or affirmation, and particularly describing the place to be searched, and
the persons or things to be seized."
But the Fourth Amendment applies only to intrusions from the government. And
most federal privacy statutes apply only to specific sectors, such as health
care, education or communications and therefore fail to adequately protect
personal data on the Internet. The oddest origin of such a statute relates to
video rental records and stems from the days of Robert Bork's Supreme Court
confirmation hearings.
In 1987, Michael Dolan, then a reporter for the Washington City Paper, an
alternative weekly in Washington, D.C., walked into a local video store he
knew Bork and his wife frequented and requested a list of the couple's video
rentals. The subsequent article he wrote, describing Bork based on 146 videos
he had presumably watched, did little to define the man, other than revealing
a yen for Alfred Hitchcock and Cary Grant. But it caused a stir among the
nation's legislators, who were suddenly concerned about their own privacy.
Within a year, Congress passed the Video Privacy Protection Act to prohibit
"wrongful disclosure of video tape rental or sale records" without a
customer's consent. The Act recently returned to the floor of Congress, with
an amendment that makes it easier for companies like Netflix to have consumers
share their online video viewing as a means of delivering suggestions that fit
their tastes.
The law in general is still catching up to the technology. In early February,
the California Supreme Court ruled that Apple could legally require some
personal information as a means of validating users and preventing fraud.
However, the majority opinion suggested that new laws might be necessary to
adequately protect consumer privacy.
Narayanan tries to make a clear distinction between privacy research and
privacy advocacy. He believes in an individual's choice, and thus transparency
and consumer awareness are important. He also is quick to point out that
technology advancements can improve privacy options. At the start of the
privacy class he teaches each year, he shares an example.
The novel Fifty Shades of Grey might have been stigmatized by its graphic
sexual content, Narayanan tells his students, but because it first was
released as an e-book, people were able to read it on tablets or e-readers
without other people knowing. Then, when the book became popular enough that
there was no stigma attached, it was published in print.
"The narrative of technology killing privacy is, at best, dramatically
overstated," Narayanan says. "For every example of technology hurting privacy,
there's one of technology helping privacy." Another example: Self-checkout
kiosks used in some large retailers and grocery stores that allow shoppers to
make purchases without a store clerk knowing what they've bought.
These examples present an interesting paradox: While reading Fifty Shades of
Grey on a Kindle feels more private, there is still an electronic record of
the purchase. Compare that to buying it at a bookstore, with cash. A clerk
might know you like steamy novels but that's where the "record" of your
purchase ends. As technology is adopted more widely, old ways are made
obsolete or, in some cases, disappear altogether. But that limits our ability
to avoid the technology, and the attendant privacy concerns, if we chose to do
Solving the privacy conundrum would be easier if the solution didn't also
encroach on the ability of companies to prosper, and to deliver new and
interesting methods of entertainment, social engagement and commerce that
consumers happily embrace. The same technological developments that raise
privacy questions also add convenience to many ordinary tasks. They enable
instantaneous communication. Social media sites work because of the
participation of all of our friends, sharing photos and updates that we enjoy
receiving. What's the answer?
Control and transparency were major themes of a 2012 government report titled
"A Consumer Privacy Bill of Rights" that aimed to establish "a baseline of
clear protections for consumers and greater certainty for companies." The
report stated that "Consumers have a right to exercise control over what
personal data companies collect from them and how they use it" as well as a
right "to easily understandable and accessible information about privacy and
security practices."
The report recognized and attempted to account for the benefits of data
collection and to find ways of protecting privacy without thwarting
innovation. But it warned that if companies don't adopt measures themselves,
further regulatory scrutiny is likely. Those warnings are coming true. Last
July Congress began an inquiry into data mining practices. In October, a
similar probe was launched into nine data brokers.
The Electronic Frontier Foundation expects several pieces of legislation to go
before Congress over the next year, including amendments to existing bills
that would mandate a warrant for obtaining private electronic communications
such as old emails. Minnesota Sen. Al Franken recently introduced The Location
Protection Privacy Act of 2012 that would potentially prevent smartphone apps
from tracking a cell phone's location and sending it to a third party without
consent. Another major player is the Electronic Privacy Information Center,
whose president and executive director Marc Rotenberg, JD '87, has testified
before Congress on many issues related to consumer privacy.
"I think the next couple of years will be formative for the next decade
after," CIS's McDonald says. But forecasts about how business interests and
privacy concerns ultimately will be reconciled are cloudy at best. And the
proverbial slippery slope is getting more treacherous all the time.
"I would expect that targeting advertising is just the beginning of what could
be done with this data," McDonald says. She worries "that we will look back
later on and go, 'remember when it was so simple? It was only advertising.'"
Brian Eule, '01, is a frequent contributor to Stanford.
Too many emails? Unsubscribe, change to digest, or change password by emailing
moderator at companys at stanford.edu or changing your settings at
Eugen* Leitl leitl ICBM: 48.07100, 11.36820  8B29F6BE: 099D 78BA 2FD3 B014 B08A  7779 75B0 2443 8B29 F6BE

@_date: 2013-11-06 09:31:24
@_author: Yosem Companys 
@_subject: [liberationtech] How Much Surveillance Can Democracy Withstand? 
How Much Surveillance Can Democracy Withstand?
by Richard Stallman
A version of this article was first published in Wired in October 2013.
The current level of general surveillance in society is incompatible
with human rights. To recover our freedom and restore democracy, we
must reduce surveillance to the point where it is possible for
whistleblowers of all kinds to talk with journalists without being
spotted. To do this reliably, we must reduce the surveillance capacity
of the systems we use.
Using free/libre software, as I've advocated for 30 years, is the
first step in taking control of our digital lives. We can't trust
nonfree software; the NSA uses and even createssecurity weaknesses in
nonfree software to invade our own computers and routers. Free
software gives us control of our own computers, but that won't protect
our privacy once we set foot on the Internet.
Bipartisan legislation to “curtail the domestic surveillance powers”
in the U.S. is being drawn up, but it relies on limiting the
government's use of our virtual dossiers. That won't suffice to
protect whistleblowers if “catching the whistleblower” is grounds for
access sufficient to identify him or her. We need to go further.
Thanks to Edward Snowden's disclosures, we know that the current level
of general surveillance in society is incompatible with human rights.
The repeated harassment and prosecution of dissidents, sources, and
journalists provides confirmation. We need to reduce the level of
general surveillance, but how far? Where exactly is the maximum
tolerable level of surveillance, beyond which it becomes oppressive?
That happens when surveillance interferes with the functioning of
democracy: when whistleblowers (such as Snowden) are likely to be
The Upper Limit on Surveillance in a Democracy
If whistleblowers don't dare reveal crimes and lies, we lose the last
shred of effective control over our government and institutions.
That's why surveillance that enables the state to find out who has
talked with a reporter is too much surveillance—too much for democracy
to endure.
An unnamed U.S. government official ominously told journalists in 2011
that the U.S. would not subpoena reporters because “We know who you're
talking to.” Sometimesjournalists' phone call records are subpoenaed
to find this out, but Snowden has shown us that in effect they
subpoena all the phone call records of everyone in the U.S., all the
Opposition and dissident activities need to keep secrets from states
that are willing to play dirty tricks on them. The ACLU has
demonstrated the U.S. government's systematic practice of infiltrating
peaceful dissident groups on the pretext that there might be
terrorists among them. The point at which surveillance is too much is
the point at which the state can find who spoke to a known journalist
or a known dissident.
Information, Once Collected, Will Be Misused
When people recognize that the level of general surveillance is too
high, the first response is to propose limits on access to the
accumulated data. That sounds nice, but it won't fix the problem, not
even slightly, even supposing that the government obeys the rules.
(The NSA has misled the FISA court, which said it was unable to
effectively hold the NSA accountable.) Suspicion of a crime will be
grounds for access, so once a whistleblower is accused of “espionage,”
finding the “spy” will provide an excuse to access the accumulated
The state's surveillance staff will misuse the data for personal
reasons too. Some NSA agents used U.S. surveillance systems to track
their lovers—past, present, or wished-for—in a practice called
“LOVEINT.” The NSA says it has caught and punished this a few times;
we don't know how many other times it wasn't caught. But these events
shouldn't surprise us, because police have long used their access to
driver's license records to track down someone attractive, a practice
known as “running a plate for a date.”
Surveillance data will always be used for other purposes, even if this
is prohibited. Once the data has been accumulated and the state has
the possibility of access to it, it canmisuse that data in dreadful
Total surveillance plus vague law provides an opening for a massive
fishing expedition against any desired target. To make journalism and
democracy safe, we must limit the accumulation of data that is easily
accessible to the state.
Robust Protection for Privacy Must Be Technical
The Electronic Frontier Foundation and other organizations propose a
set of legal principles designed to prevent the abuses of massive
surveillance. These principles include, crucially, explicit legal
protection for whistleblowers; as a consequence, they would be
adequate for protecting democratic freedoms—if adopted completely and
enforced without exception forever.
However, such legal protections are precarious: as recent history
shows, they can be repealed (as in the FISA Amendments Act),
suspended, or ignored.
Meanwhile, demagogues will cite the usual excuses as grounds for total
surveillance; any terrorist attack, even one that kills just a handful
of people, will give them an opportunity.
If limits on access to the data are set aside, it will be as if they
had never existed: years worth of dossiers would suddenly become
available for misuse by the state and its agents and, if collected by
companies, for their private misuse as well. If, however, we stop the
collection of dossiers on everyone, those dossiers won't exist, and
there will be no way to compile them retroactively. A new illiberal
regime would have to implement surveillance afresh, and it would only
collect data starting at that date. As for suspending or momentarily
ignoring this law, the idea would hardly make sense.
We Must Design Every System for Privacy
If we don't want a total surveillance society, we must consider
surveillance a kind of social pollution, and limit the surveillance
impact of each new digital system just as we limit the environmental
impact of physical construction.
For example: “Smart” meters for electricity are touted for sending the
power company moment-by-moment data about each customer's electric
usage, including how usage compares with users in general. This is
implemented based on general surveillance, but does not require any
surveillance. It would be easy for the power company to calculate the
average usage in a residential neighborhood by dividing the total
usage by the number of subscribers, and send that to the meters. Each
customer's meter could compare her usage, over any desired period of
time, with the average usage pattern for that period. The same
benefit, with no surveillance!
We need to design such privacy into all our digital systems.
Remedy for Collecting Data: Leaving It Dispersed
One way to make monitoring safe for privacy is to keep the data
dispersed and inconvenient to access. Old-fashioned security cameras
were no threat to privacy. The recording was stored on the premises,
and kept for a few weeks at most. Because of the inconvenience of
accessing these recordings, it was never done massively; they were
accessed only in the places where someone reported a crime. It would
not be feasible to physically collect millions of tapes every day and
watch them or copy them.
Nowadays, security cameras have become surveillance cameras: they are
connected to the Internet so recordings can be collected in a data
center and saved forever. This is already dangerous, but it is going
to get worse. Advances in face recognition may bring the day when
suspected journalists can be tracked on the street all the time to see
who they talk with.
Internet-connected cameras often have lousy digital security
themselves, so anyone could watch what the camera sees. To restore
privacy, we should ban the use of Internet-connected cameras aimed
where and when the public is admitted, except when carried by people.
Everyone must be free to post photos and video recordings
occasionally, but the systematic accumulation of such data on the
Internet must be limited.
Remedy for Internet Commerce Surveillance
Most data collection comes from people's own digital activities.
Usually the data is collected first by companies. But when it comes to
the threat to privacy and democracy, it makes no difference whether
surveillance is done directly by the state or farmed out to a
business, because the data that the companies collect is
systematically available to the state.
The NSA, through PRISM, has gotten into the databases of many large
Internet corporations. AT&T has saved all its phone call records since
1987 and makes them available to the DEA to search on request.
Strictly speaking, the U.S. government does not possess that data, but
in practical terms it may as well possess it.
The goal of making journalism and democracy safe therefore requires
that we reduce the data collected about people by any organization,
not just by the state. We must redesign digital systems so that they
do not accumulate data about their users. If they need digital data
about our transactions, they should not be allowed to keep them more
than a short time beyond what is inherently necessary for their
dealings with us.
One of the motives for the current level of surveillance of the
Internet is that sites are financed through advertising based on
tracking users' activities and propensities. This converts a mere
annoyance—advertising that we can learn to ignore—into a surveillance
system that harms us whether we know it or not. Purchases over the
Internet also track their users. And we are all aware that “privacy
policies” are more excuses to violate privacy than commitments to
uphold it.
We could correct both problems by adopting a system of anonymous
payments—anonymous for the payer, that is. (We don't want the payee to
dodge taxes.) Bitcoin is not anonymous, but technology for digital
cash was first developed 25 years ago; we need only suitable business
arrangements, and for the state not to obstruct them.
A further threat from sites' collection of personal data is that
security breakers might get in, take it, and misuse it. This includes
customers' credit card details. An anonymous payment system would end
this danger: a security hole in the site can't hurt you if the site
knows nothing about you.
Remedy for Travel Surveillance
We must convert digital toll collection to anonymous payment (using
digital cash, for instance). License-plate recognition systems
recognize all license plates, and the data can be kept indefinitely;
they should be required by law to notice and record only those license
numbers that are on a list of cars sought by court orders. A less
secure alternative would record all cars locally but only for a few
days, and not make the full data available over the Internet; access
to the data should be limited to searching for a list of court-ordered
The U.S. “no-fly” list must be abolished because it is punishment without trial.
It is acceptable to have a list of people whose person and luggage
will be searched with extra care, and anonymous passengers on domestic
flights could be treated as if they were on this list. It is also
acceptable to bar non-citizens, if they are not permitted to enter the
country at all, from boarding flights to the country. This ought to be
enough for all legitimate purposes.
Many mass transit systems use some kind of smart cards or RFIDs for
payment. These systems accumulate personal data: if you once make the
mistake of paying with anything but cash, they associate the card
permanently with your name. Furthermore, they record all travel
associated with each card. Together they amount to massive
surveillance. This data collection must be reduced.
Navigation services do surveillance: the user's computer tells the map
service the user's location and where the user wants to go; then the
server determines the route and sends it back to the user's computer,
which displays it. Nowadays, the server probably records the user's
locations, since there is nothing to prevent it. This surveillance is
not inherently necessary, and redesign could avoid it: free/libre
software in the user's computer could download map data for the
pertinent regions (if not downloaded previously), compute the route,
and display it, without ever telling anyone where the user is or wants
to go.
Systems for borrowing bicycles, etc., can be designed so that the
borrower's identity is known only inside the station where the item
was borrowed. Borrowing would inform all stations that the item is
“out,” so when the user returns it at any station (in general, a
different one), that station will know where and when that item was
borrowed. It will inform the other station that the item is no longer
“out.” It will also calculate the user's bill, and send it (after
waiting some random number of minutes) to headquarters along a ring of
stations, so that headquarters would not find out which station the
bill came from. Once this is done, the return station would forget all
about the transaction. If an item remains “out” for too long, the
station where it was borrowed can inform headquarters; in that case,
it could send the borrower's identity immediately.
Remedy for Communications Dossiers
Internet service providers and telephone companies keep extensive data
on their users' contacts (browsing, phone calls, etc). With mobile
phones, they also record the user's physical location. They keep these
dossiers for a long time: over 30 years, in the case of AT&T. Soon
they will even record the user's body activities. It appears that the
NSA collects cell phone location data in bulk.
Unmonitored communication is impossible where systems create such
dossiers. So it should be illegal to create or keep them. ISPs and
phone companies must not be allowed to keep this information for very
long, in the absence of a court order to surveil a certain party.
This solution is not entirely satisfactory, because it won't
physically stop the government from collecting all the information
immediately as it is generated—which is what theU.S. does with some or
all phone companies. We would have to rely on prohibiting that by law.
However, that would be better than the current situation, where the
relevant law (the PATRIOT Act) does not clearly prohibit the practice.
In addition, if the government did resume this sort of surveillance,
it would not get data about everyone's phone calls made prior to that
But Some Surveillance Is Necessary
For the state to find criminals, it needs to be able to investigate
specific crimes, or specific suspected planned crimes, under a court
order. With the Internet, the power to tap phone conversations would
naturally extend to the power to tap Internet connections. This power
is easy to abuse for political reasons, but it is also necessary.
Fortunately, this won't make it possible to find whistleblowers after
the fact.
Individuals with special state-granted power, such as police, forfeit
their right to privacy and must be monitored. (In fact, police have
their own jargon term for perjury, “testilying,” since they do it so
frequently, particularly about protesters and photographers.) One city
in California that required police to wear video cameras all the time
found their use of force fell by 60%. The ACLU is in favor of this.
Corporations are not people, and not entitled to human rights. It is
legitimate to require businesses to publish the details of processes
that might cause chemical, biological, nuclear, fiscal, computational
(e.g., DRM) or political (e.g., lobbying) hazards to society, to
whatever level is needed for public well-being. The danger of these
operations (consider the BP oil spill, the Fukushima meltdowns, and
the 2008 fiscal crisis) dwarfs that of terrorism.
However, journalism must be protected from surveillance even when it
is carried out as part of a business.
Digital technology has brought about a tremendous increase in the
level of surveillance of our movements, actions, and communications.
It is far more than we experienced in the 1990s, and far more than
people behind the Iron Curtain experienced in the 1980s, and would
still be far more even with additional legal limits on state use of
the accumulated data.
Unless we believe that our free countries previously suffered from a
grave surveillance deficit, and ought to be surveilled more than the
Soviet Union and East Germany were, we must reverse this increase.
That requires stopping the accumulation of big data about people.
Copyright 2013 Richard Stallman
Licensed under the Creative Commons Attribution-NoDerivs 3.0 United
States License

@_date: 2013-11-06 09:31:24
@_author: Yosem Companys 
@_subject: [liberationtech] How Much Surveillance Can Democracy Withstand? 
How Much Surveillance Can Democracy Withstand?
by Richard Stallman
A version of this article was first published in Wired in October 2013.
The current level of general surveillance in society is incompatible
with human rights. To recover our freedom and restore democracy, we
must reduce surveillance to the point where it is possible for
whistleblowers of all kinds to talk with journalists without being
spotted. To do this reliably, we must reduce the surveillance capacity
of the systems we use.
Using free/libre software, as I've advocated for 30 years, is the
first step in taking control of our digital lives. We can't trust
nonfree software; the NSA uses and even createssecurity weaknesses in
nonfree software to invade our own computers and routers. Free
software gives us control of our own computers, but that won't protect
our privacy once we set foot on the Internet.
Bipartisan legislation to “curtail the domestic surveillance powers”
in the U.S. is being drawn up, but it relies on limiting the
government's use of our virtual dossiers. That won't suffice to
protect whistleblowers if “catching the whistleblower” is grounds for
access sufficient to identify him or her. We need to go further.
Thanks to Edward Snowden's disclosures, we know that the current level
of general surveillance in society is incompatible with human rights.
The repeated harassment and prosecution of dissidents, sources, and
journalists provides confirmation. We need to reduce the level of
general surveillance, but how far? Where exactly is the maximum
tolerable level of surveillance, beyond which it becomes oppressive?
That happens when surveillance interferes with the functioning of
democracy: when whistleblowers (such as Snowden) are likely to be
The Upper Limit on Surveillance in a Democracy
If whistleblowers don't dare reveal crimes and lies, we lose the last
shred of effective control over our government and institutions.
That's why surveillance that enables the state to find out who has
talked with a reporter is too much surveillance—too much for democracy
to endure.
An unnamed U.S. government official ominously told journalists in 2011
that the U.S. would not subpoena reporters because “We know who you're
talking to.” Sometimesjournalists' phone call records are subpoenaed
to find this out, but Snowden has shown us that in effect they
subpoena all the phone call records of everyone in the U.S., all the
Opposition and dissident activities need to keep secrets from states
that are willing to play dirty tricks on them. The ACLU has
demonstrated the U.S. government's systematic practice of infiltrating
peaceful dissident groups on the pretext that there might be
terrorists among them. The point at which surveillance is too much is
the point at which the state can find who spoke to a known journalist
or a known dissident.
Information, Once Collected, Will Be Misused
When people recognize that the level of general surveillance is too
high, the first response is to propose limits on access to the
accumulated data. That sounds nice, but it won't fix the problem, not
even slightly, even supposing that the government obeys the rules.
(The NSA has misled the FISA court, which said it was unable to
effectively hold the NSA accountable.) Suspicion of a crime will be
grounds for access, so once a whistleblower is accused of “espionage,”
finding the “spy” will provide an excuse to access the accumulated
The state's surveillance staff will misuse the data for personal
reasons too. Some NSA agents used U.S. surveillance systems to track
their lovers—past, present, or wished-for—in a practice called
“LOVEINT.” The NSA says it has caught and punished this a few times;
we don't know how many other times it wasn't caught. But these events
shouldn't surprise us, because police have long used their access to
driver's license records to track down someone attractive, a practice
known as “running a plate for a date.”
Surveillance data will always be used for other purposes, even if this
is prohibited. Once the data has been accumulated and the state has
the possibility of access to it, it canmisuse that data in dreadful
Total surveillance plus vague law provides an opening for a massive
fishing expedition against any desired target. To make journalism and
democracy safe, we must limit the accumulation of data that is easily
accessible to the state.
Robust Protection for Privacy Must Be Technical
The Electronic Frontier Foundation and other organizations propose a
set of legal principles designed to prevent the abuses of massive
surveillance. These principles include, crucially, explicit legal
protection for whistleblowers; as a consequence, they would be
adequate for protecting democratic freedoms—if adopted completely and
enforced without exception forever.
However, such legal protections are precarious: as recent history
shows, they can be repealed (as in the FISA Amendments Act),
suspended, or ignored.
Meanwhile, demagogues will cite the usual excuses as grounds for total
surveillance; any terrorist attack, even one that kills just a handful
of people, will give them an opportunity.
If limits on access to the data are set aside, it will be as if they
had never existed: years worth of dossiers would suddenly become
available for misuse by the state and its agents and, if collected by
companies, for their private misuse as well. If, however, we stop the
collection of dossiers on everyone, those dossiers won't exist, and
there will be no way to compile them retroactively. A new illiberal
regime would have to implement surveillance afresh, and it would only
collect data starting at that date. As for suspending or momentarily
ignoring this law, the idea would hardly make sense.
We Must Design Every System for Privacy
If we don't want a total surveillance society, we must consider
surveillance a kind of social pollution, and limit the surveillance
impact of each new digital system just as we limit the environmental
impact of physical construction.
For example: “Smart” meters for electricity are touted for sending the
power company moment-by-moment data about each customer's electric
usage, including how usage compares with users in general. This is
implemented based on general surveillance, but does not require any
surveillance. It would be easy for the power company to calculate the
average usage in a residential neighborhood by dividing the total
usage by the number of subscribers, and send that to the meters. Each
customer's meter could compare her usage, over any desired period of
time, with the average usage pattern for that period. The same
benefit, with no surveillance!
We need to design such privacy into all our digital systems.
Remedy for Collecting Data: Leaving It Dispersed
One way to make monitoring safe for privacy is to keep the data
dispersed and inconvenient to access. Old-fashioned security cameras
were no threat to privacy. The recording was stored on the premises,
and kept for a few weeks at most. Because of the inconvenience of
accessing these recordings, it was never done massively; they were
accessed only in the places where someone reported a crime. It would
not be feasible to physically collect millions of tapes every day and
watch them or copy them.
Nowadays, security cameras have become surveillance cameras: they are
connected to the Internet so recordings can be collected in a data
center and saved forever. This is already dangerous, but it is going
to get worse. Advances in face recognition may bring the day when
suspected journalists can be tracked on the street all the time to see
who they talk with.
Internet-connected cameras often have lousy digital security
themselves, so anyone could watch what the camera sees. To restore
privacy, we should ban the use of Internet-connected cameras aimed
where and when the public is admitted, except when carried by people.
Everyone must be free to post photos and video recordings
occasionally, but the systematic accumulation of such data on the
Internet must be limited.
Remedy for Internet Commerce Surveillance
Most data collection comes from people's own digital activities.
Usually the data is collected first by companies. But when it comes to
the threat to privacy and democracy, it makes no difference whether
surveillance is done directly by the state or farmed out to a
business, because the data that the companies collect is
systematically available to the state.
The NSA, through PRISM, has gotten into the databases of many large
Internet corporations. AT&T has saved all its phone call records since
1987 and makes them available to the DEA to search on request.
Strictly speaking, the U.S. government does not possess that data, but
in practical terms it may as well possess it.
The goal of making journalism and democracy safe therefore requires
that we reduce the data collected about people by any organization,
not just by the state. We must redesign digital systems so that they
do not accumulate data about their users. If they need digital data
about our transactions, they should not be allowed to keep them more
than a short time beyond what is inherently necessary for their
dealings with us.
One of the motives for the current level of surveillance of the
Internet is that sites are financed through advertising based on
tracking users' activities and propensities. This converts a mere
annoyance—advertising that we can learn to ignore—into a surveillance
system that harms us whether we know it or not. Purchases over the
Internet also track their users. And we are all aware that “privacy
policies” are more excuses to violate privacy than commitments to
uphold it.
We could correct both problems by adopting a system of anonymous
payments—anonymous for the payer, that is. (We don't want the payee to
dodge taxes.) Bitcoin is not anonymous, but technology for digital
cash was first developed 25 years ago; we need only suitable business
arrangements, and for the state not to obstruct them.
A further threat from sites' collection of personal data is that
security breakers might get in, take it, and misuse it. This includes
customers' credit card details. An anonymous payment system would end
this danger: a security hole in the site can't hurt you if the site
knows nothing about you.
Remedy for Travel Surveillance
We must convert digital toll collection to anonymous payment (using
digital cash, for instance). License-plate recognition systems
recognize all license plates, and the data can be kept indefinitely;
they should be required by law to notice and record only those license
numbers that are on a list of cars sought by court orders. A less
secure alternative would record all cars locally but only for a few
days, and not make the full data available over the Internet; access
to the data should be limited to searching for a list of court-ordered
The U.S. “no-fly” list must be abolished because it is punishment without trial.
It is acceptable to have a list of people whose person and luggage
will be searched with extra care, and anonymous passengers on domestic
flights could be treated as if they were on this list. It is also
acceptable to bar non-citizens, if they are not permitted to enter the
country at all, from boarding flights to the country. This ought to be
enough for all legitimate purposes.
Many mass transit systems use some kind of smart cards or RFIDs for
payment. These systems accumulate personal data: if you once make the
mistake of paying with anything but cash, they associate the card
permanently with your name. Furthermore, they record all travel
associated with each card. Together they amount to massive
surveillance. This data collection must be reduced.
Navigation services do surveillance: the user's computer tells the map
service the user's location and where the user wants to go; then the
server determines the route and sends it back to the user's computer,
which displays it. Nowadays, the server probably records the user's
locations, since there is nothing to prevent it. This surveillance is
not inherently necessary, and redesign could avoid it: free/libre
software in the user's computer could download map data for the
pertinent regions (if not downloaded previously), compute the route,
and display it, without ever telling anyone where the user is or wants
to go.
Systems for borrowing bicycles, etc., can be designed so that the
borrower's identity is known only inside the station where the item
was borrowed. Borrowing would inform all stations that the item is
“out,” so when the user returns it at any station (in general, a
different one), that station will know where and when that item was
borrowed. It will inform the other station that the item is no longer
“out.” It will also calculate the user's bill, and send it (after
waiting some random number of minutes) to headquarters along a ring of
stations, so that headquarters would not find out which station the
bill came from. Once this is done, the return station would forget all
about the transaction. If an item remains “out” for too long, the
station where it was borrowed can inform headquarters; in that case,
it could send the borrower's identity immediately.
Remedy for Communications Dossiers
Internet service providers and telephone companies keep extensive data
on their users' contacts (browsing, phone calls, etc). With mobile
phones, they also record the user's physical location. They keep these
dossiers for a long time: over 30 years, in the case of AT&T. Soon
they will even record the user's body activities. It appears that the
NSA collects cell phone location data in bulk.
Unmonitored communication is impossible where systems create such
dossiers. So it should be illegal to create or keep them. ISPs and
phone companies must not be allowed to keep this information for very
long, in the absence of a court order to surveil a certain party.
This solution is not entirely satisfactory, because it won't
physically stop the government from collecting all the information
immediately as it is generated—which is what theU.S. does with some or
all phone companies. We would have to rely on prohibiting that by law.
However, that would be better than the current situation, where the
relevant law (the PATRIOT Act) does not clearly prohibit the practice.
In addition, if the government did resume this sort of surveillance,
it would not get data about everyone's phone calls made prior to that
But Some Surveillance Is Necessary
For the state to find criminals, it needs to be able to investigate
specific crimes, or specific suspected planned crimes, under a court
order. With the Internet, the power to tap phone conversations would
naturally extend to the power to tap Internet connections. This power
is easy to abuse for political reasons, but it is also necessary.
Fortunately, this won't make it possible to find whistleblowers after
the fact.
Individuals with special state-granted power, such as police, forfeit
their right to privacy and must be monitored. (In fact, police have
their own jargon term for perjury, “testilying,” since they do it so
frequently, particularly about protesters and photographers.) One city
in California that required police to wear video cameras all the time
found their use of force fell by 60%. The ACLU is in favor of this.
Corporations are not people, and not entitled to human rights. It is
legitimate to require businesses to publish the details of processes
that might cause chemical, biological, nuclear, fiscal, computational
(e.g., DRM) or political (e.g., lobbying) hazards to society, to
whatever level is needed for public well-being. The danger of these
operations (consider the BP oil spill, the Fukushima meltdowns, and
the 2008 fiscal crisis) dwarfs that of terrorism.
However, journalism must be protected from surveillance even when it
is carried out as part of a business.
Digital technology has brought about a tremendous increase in the
level of surveillance of our movements, actions, and communications.
It is far more than we experienced in the 1990s, and far more than
people behind the Iron Curtain experienced in the 1980s, and would
still be far more even with additional legal limits on state use of
the accumulated data.
Unless we believe that our free countries previously suffered from a
grave surveillance deficit, and ought to be surveilled more than the
Soviet Union and East Germany were, we must reverse this increase.
That requires stopping the accumulation of big data about people.
Copyright 2013 Richard Stallman
Licensed under the Creative Commons Attribution-NoDerivs 3.0 United
States License

@_date: 2013-11-06 09:31:24
@_author: Yosem Companys 
@_subject: [liberationtech] How Much Surveillance Can Democracy Withstand? 
How Much Surveillance Can Democracy Withstand?
by Richard Stallman
A version of this article was first published in Wired in October 2013.
The current level of general surveillance in society is incompatible
with human rights. To recover our freedom and restore democracy, we
must reduce surveillance to the point where it is possible for
whistleblowers of all kinds to talk with journalists without being
spotted. To do this reliably, we must reduce the surveillance capacity
of the systems we use.
Using free/libre software, as I've advocated for 30 years, is the
first step in taking control of our digital lives. We can't trust
nonfree software; the NSA uses and even createssecurity weaknesses in
nonfree software to invade our own computers and routers. Free
software gives us control of our own computers, but that won't protect
our privacy once we set foot on the Internet.
Bipartisan legislation to “curtail the domestic surveillance powers”
in the U.S. is being drawn up, but it relies on limiting the
government's use of our virtual dossiers. That won't suffice to
protect whistleblowers if “catching the whistleblower” is grounds for
access sufficient to identify him or her. We need to go further.
Thanks to Edward Snowden's disclosures, we know that the current level
of general surveillance in society is incompatible with human rights.
The repeated harassment and prosecution of dissidents, sources, and
journalists provides confirmation. We need to reduce the level of
general surveillance, but how far? Where exactly is the maximum
tolerable level of surveillance, beyond which it becomes oppressive?
That happens when surveillance interferes with the functioning of
democracy: when whistleblowers (such as Snowden) are likely to be
The Upper Limit on Surveillance in a Democracy
If whistleblowers don't dare reveal crimes and lies, we lose the last
shred of effective control over our government and institutions.
That's why surveillance that enables the state to find out who has
talked with a reporter is too much surveillance—too much for democracy
to endure.
An unnamed U.S. government official ominously told journalists in 2011
that the U.S. would not subpoena reporters because “We know who you're
talking to.” Sometimesjournalists' phone call records are subpoenaed
to find this out, but Snowden has shown us that in effect they
subpoena all the phone call records of everyone in the U.S., all the
Opposition and dissident activities need to keep secrets from states
that are willing to play dirty tricks on them. The ACLU has
demonstrated the U.S. government's systematic practice of infiltrating
peaceful dissident groups on the pretext that there might be
terrorists among them. The point at which surveillance is too much is
the point at which the state can find who spoke to a known journalist
or a known dissident.
Information, Once Collected, Will Be Misused
When people recognize that the level of general surveillance is too
high, the first response is to propose limits on access to the
accumulated data. That sounds nice, but it won't fix the problem, not
even slightly, even supposing that the government obeys the rules.
(The NSA has misled the FISA court, which said it was unable to
effectively hold the NSA accountable.) Suspicion of a crime will be
grounds for access, so once a whistleblower is accused of “espionage,”
finding the “spy” will provide an excuse to access the accumulated
The state's surveillance staff will misuse the data for personal
reasons too. Some NSA agents used U.S. surveillance systems to track
their lovers—past, present, or wished-for—in a practice called
“LOVEINT.” The NSA says it has caught and punished this a few times;
we don't know how many other times it wasn't caught. But these events
shouldn't surprise us, because police have long used their access to
driver's license records to track down someone attractive, a practice
known as “running a plate for a date.”
Surveillance data will always be used for other purposes, even if this
is prohibited. Once the data has been accumulated and the state has
the possibility of access to it, it canmisuse that data in dreadful
Total surveillance plus vague law provides an opening for a massive
fishing expedition against any desired target. To make journalism and
democracy safe, we must limit the accumulation of data that is easily
accessible to the state.
Robust Protection for Privacy Must Be Technical
The Electronic Frontier Foundation and other organizations propose a
set of legal principles designed to prevent the abuses of massive
surveillance. These principles include, crucially, explicit legal
protection for whistleblowers; as a consequence, they would be
adequate for protecting democratic freedoms—if adopted completely and
enforced without exception forever.
However, such legal protections are precarious: as recent history
shows, they can be repealed (as in the FISA Amendments Act),
suspended, or ignored.
Meanwhile, demagogues will cite the usual excuses as grounds for total
surveillance; any terrorist attack, even one that kills just a handful
of people, will give them an opportunity.
If limits on access to the data are set aside, it will be as if they
had never existed: years worth of dossiers would suddenly become
available for misuse by the state and its agents and, if collected by
companies, for their private misuse as well. If, however, we stop the
collection of dossiers on everyone, those dossiers won't exist, and
there will be no way to compile them retroactively. A new illiberal
regime would have to implement surveillance afresh, and it would only
collect data starting at that date. As for suspending or momentarily
ignoring this law, the idea would hardly make sense.
We Must Design Every System for Privacy
If we don't want a total surveillance society, we must consider
surveillance a kind of social pollution, and limit the surveillance
impact of each new digital system just as we limit the environmental
impact of physical construction.
For example: “Smart” meters for electricity are touted for sending the
power company moment-by-moment data about each customer's electric
usage, including how usage compares with users in general. This is
implemented based on general surveillance, but does not require any
surveillance. It would be easy for the power company to calculate the
average usage in a residential neighborhood by dividing the total
usage by the number of subscribers, and send that to the meters. Each
customer's meter could compare her usage, over any desired period of
time, with the average usage pattern for that period. The same
benefit, with no surveillance!
We need to design such privacy into all our digital systems.
Remedy for Collecting Data: Leaving It Dispersed
One way to make monitoring safe for privacy is to keep the data
dispersed and inconvenient to access. Old-fashioned security cameras
were no threat to privacy. The recording was stored on the premises,
and kept for a few weeks at most. Because of the inconvenience of
accessing these recordings, it was never done massively; they were
accessed only in the places where someone reported a crime. It would
not be feasible to physically collect millions of tapes every day and
watch them or copy them.
Nowadays, security cameras have become surveillance cameras: they are
connected to the Internet so recordings can be collected in a data
center and saved forever. This is already dangerous, but it is going
to get worse. Advances in face recognition may bring the day when
suspected journalists can be tracked on the street all the time to see
who they talk with.
Internet-connected cameras often have lousy digital security
themselves, so anyone could watch what the camera sees. To restore
privacy, we should ban the use of Internet-connected cameras aimed
where and when the public is admitted, except when carried by people.
Everyone must be free to post photos and video recordings
occasionally, but the systematic accumulation of such data on the
Internet must be limited.
Remedy for Internet Commerce Surveillance
Most data collection comes from people's own digital activities.
Usually the data is collected first by companies. But when it comes to
the threat to privacy and democracy, it makes no difference whether
surveillance is done directly by the state or farmed out to a
business, because the data that the companies collect is
systematically available to the state.
The NSA, through PRISM, has gotten into the databases of many large
Internet corporations. AT&T has saved all its phone call records since
1987 and makes them available to the DEA to search on request.
Strictly speaking, the U.S. government does not possess that data, but
in practical terms it may as well possess it.
The goal of making journalism and democracy safe therefore requires
that we reduce the data collected about people by any organization,
not just by the state. We must redesign digital systems so that they
do not accumulate data about their users. If they need digital data
about our transactions, they should not be allowed to keep them more
than a short time beyond what is inherently necessary for their
dealings with us.
One of the motives for the current level of surveillance of the
Internet is that sites are financed through advertising based on
tracking users' activities and propensities. This converts a mere
annoyance—advertising that we can learn to ignore—into a surveillance
system that harms us whether we know it or not. Purchases over the
Internet also track their users. And we are all aware that “privacy
policies” are more excuses to violate privacy than commitments to
uphold it.
We could correct both problems by adopting a system of anonymous
payments—anonymous for the payer, that is. (We don't want the payee to
dodge taxes.) Bitcoin is not anonymous, but technology for digital
cash was first developed 25 years ago; we need only suitable business
arrangements, and for the state not to obstruct them.
A further threat from sites' collection of personal data is that
security breakers might get in, take it, and misuse it. This includes
customers' credit card details. An anonymous payment system would end
this danger: a security hole in the site can't hurt you if the site
knows nothing about you.
Remedy for Travel Surveillance
We must convert digital toll collection to anonymous payment (using
digital cash, for instance). License-plate recognition systems
recognize all license plates, and the data can be kept indefinitely;
they should be required by law to notice and record only those license
numbers that are on a list of cars sought by court orders. A less
secure alternative would record all cars locally but only for a few
days, and not make the full data available over the Internet; access
to the data should be limited to searching for a list of court-ordered
The U.S. “no-fly” list must be abolished because it is punishment without trial.
It is acceptable to have a list of people whose person and luggage
will be searched with extra care, and anonymous passengers on domestic
flights could be treated as if they were on this list. It is also
acceptable to bar non-citizens, if they are not permitted to enter the
country at all, from boarding flights to the country. This ought to be
enough for all legitimate purposes.
Many mass transit systems use some kind of smart cards or RFIDs for
payment. These systems accumulate personal data: if you once make the
mistake of paying with anything but cash, they associate the card
permanently with your name. Furthermore, they record all travel
associated with each card. Together they amount to massive
surveillance. This data collection must be reduced.
Navigation services do surveillance: the user's computer tells the map
service the user's location and where the user wants to go; then the
server determines the route and sends it back to the user's computer,
which displays it. Nowadays, the server probably records the user's
locations, since there is nothing to prevent it. This surveillance is
not inherently necessary, and redesign could avoid it: free/libre
software in the user's computer could download map data for the
pertinent regions (if not downloaded previously), compute the route,
and display it, without ever telling anyone where the user is or wants
to go.
Systems for borrowing bicycles, etc., can be designed so that the
borrower's identity is known only inside the station where the item
was borrowed. Borrowing would inform all stations that the item is
“out,” so when the user returns it at any station (in general, a
different one), that station will know where and when that item was
borrowed. It will inform the other station that the item is no longer
“out.” It will also calculate the user's bill, and send it (after
waiting some random number of minutes) to headquarters along a ring of
stations, so that headquarters would not find out which station the
bill came from. Once this is done, the return station would forget all
about the transaction. If an item remains “out” for too long, the
station where it was borrowed can inform headquarters; in that case,
it could send the borrower's identity immediately.
Remedy for Communications Dossiers
Internet service providers and telephone companies keep extensive data
on their users' contacts (browsing, phone calls, etc). With mobile
phones, they also record the user's physical location. They keep these
dossiers for a long time: over 30 years, in the case of AT&T. Soon
they will even record the user's body activities. It appears that the
NSA collects cell phone location data in bulk.
Unmonitored communication is impossible where systems create such
dossiers. So it should be illegal to create or keep them. ISPs and
phone companies must not be allowed to keep this information for very
long, in the absence of a court order to surveil a certain party.
This solution is not entirely satisfactory, because it won't
physically stop the government from collecting all the information
immediately as it is generated—which is what theU.S. does with some or
all phone companies. We would have to rely on prohibiting that by law.
However, that would be better than the current situation, where the
relevant law (the PATRIOT Act) does not clearly prohibit the practice.
In addition, if the government did resume this sort of surveillance,
it would not get data about everyone's phone calls made prior to that
But Some Surveillance Is Necessary
For the state to find criminals, it needs to be able to investigate
specific crimes, or specific suspected planned crimes, under a court
order. With the Internet, the power to tap phone conversations would
naturally extend to the power to tap Internet connections. This power
is easy to abuse for political reasons, but it is also necessary.
Fortunately, this won't make it possible to find whistleblowers after
the fact.
Individuals with special state-granted power, such as police, forfeit
their right to privacy and must be monitored. (In fact, police have
their own jargon term for perjury, “testilying,” since they do it so
frequently, particularly about protesters and photographers.) One city
in California that required police to wear video cameras all the time
found their use of force fell by 60%. The ACLU is in favor of this.
Corporations are not people, and not entitled to human rights. It is
legitimate to require businesses to publish the details of processes
that might cause chemical, biological, nuclear, fiscal, computational
(e.g., DRM) or political (e.g., lobbying) hazards to society, to
whatever level is needed for public well-being. The danger of these
operations (consider the BP oil spill, the Fukushima meltdowns, and
the 2008 fiscal crisis) dwarfs that of terrorism.
However, journalism must be protected from surveillance even when it
is carried out as part of a business.
Digital technology has brought about a tremendous increase in the
level of surveillance of our movements, actions, and communications.
It is far more than we experienced in the 1990s, and far more than
people behind the Iron Curtain experienced in the 1980s, and would
still be far more even with additional legal limits on state use of
the accumulated data.
Unless we believe that our free countries previously suffered from a
grave surveillance deficit, and ought to be surveilled more than the
Soviet Union and East Germany were, we must reverse this increase.
That requires stopping the accumulation of big data about people.
Copyright 2013 Richard Stallman
Licensed under the Creative Commons Attribution-NoDerivs 3.0 United
States License

@_date: 2013-10-21 10:25:48
@_author: Yosem Companys 
@_subject: [liberationtech] Google Unveils Tools to Access Web From Repressive 
Google Ideas, the New York City-based “think/do tank” run by the
Internet search giant, is launching several new technologies designed
to highlight hacker attacks around the world and help people in
repressive regimes access the Internet. The new products, which are
being announced Monday at the Google Ideas Summit in New York City,
represent the most substantial offerings delivered by the
three-year-old Google policy unit and could be a major boon to
activists and reformers in the world’s most closed and repressive
“There are billions of people around the world living in environments
that severely restrict their free expression,” Jared Cohen, Director
of Google Ideas, told TIME in an interview on Sunday. “We want to
empower them to have access to the same Internet that the rest of us
experience. We talk about how we have a responsibility to our users.
That also includes people in Iran, North Korea, Cuba, and Syria, where
the challenges are so serious.”
Cohen, a 31-year-old geopolitical expert, earned undergraduate and
graduate degrees from Stanford and Oxford and later worked as a U.S.
State Department advisor to Condoleezza Rice and Hillary Clinton
before being asked by Google executive chairman Eric Schmidt to launch
Google Ideas in 2010. Cohen, who co-authored The New Digital Age with
Schmidt in April, said that he was attracted to Google by the
“activist spirit” of many of the company’s employees.
“This is a company of activists and white-hat hackers,” Cohen says.
“When you work at Google and tell these engineers that their skill-set
is relevant to somebody in Iran who doesn’t have access to information
in their country or the rest of the world, it really inspires them to
want to do something about it. There is a genuine altruism that exists
at this company, and that’s why I’m here and not anywhere else.”
The most ambitious product launch is uProxy, a new Web browser
extension that uses peer-to-peer technology to let people around the
world provide each other with a trusted Internet connection. This
product is designed to protect the Internet connection of users in,
say, Iran, from state surveillance or filtering. Google Ideas is
providing funding and technical assistance for uProxy, which was
developed by researchers at the University of Washington and Brave New
“If you look at existing proxy tools today, as soon as they’re
effective for dissidents, the government finds out about them and
either blocks them or infiltrates them,” says Cohen. “Every dissident
we know in every repressive society has friends outside the country
whom they know and trust. What if those trusted friends could unblock
the access in those repressive societies by sharing their own access?
That was the problem we tried to solve.”
UProxy allows users in the U.S. to give their trusted friends in
Iran—people they might already be emailing or chatting with—access to
the open U.S. Internet. “The user in Iran can get unfiltered access to
the Internet that’s completely uncensored and will look just like it
does in the U.S.,” says Cohen. “It’s completely encrypted and there’s
no way for the government to detect what’s happening because it just
looks like voice traffic or chat traffic. We wanted to build a proxy
service that builds on top of trusted relationships that already
Google Ideas is also launching Project Shield, which is an initiative
designed to help human rights activists, non-governmental
organizations (NGOs), election monitoring groups, and news
organizations better protect their websites from “distributed denial
of service” (DDoS) attacks. Several high-profile news organizations,
including The New York Times, have recently been targeted by hackers
who used DDoS attacks to temporarily shut down websites. ”Google is
very good at protecting itself from DDoS attacks,” says Cohen. “But
NGOs, independent media outlets, human rights organizations, and
election-monitoring organizations don’t have the capacity to protect
themselves in the way that we do.”
“We believe in human rights, we believe in free expression, we believe
in election-monitoring, and we believe in independent media.” Cohen
says the goal is to leverage Google’s technology to aid these efforts.
Project Shield is currently under development—consistent with Google’s
“launch and iterate” product philosophy—and the company is inviting
web-masters working in these areas to apply to join its next round of
“trusted” testers. For now, the product is free, Cohen says.
The third Google Ideas product launch is the Digital Attack Map, which
is a live data visualization, built in conjunction with network
security firm Arbor Networks, that displays DDoS attacks worldwide in
real-time. This online tool shows real-time anonymous traffic data
related to DDoS attacks, and also lets users explore historical trends
and see related news reports, via Google News, of website outages as
they are happening.
“What we’ve done for the first time is take all of the DDoS attacks
worldwide and show what the state of DDoS activity looks like in
real-time, much like you’d check the weather,” says Cohen. “If you
think about all of the organizations around the world that use a
website as their modern-day office—NGOs, businesses, governments—it’s
not OK to have this many digital office raids shutting them down.”
Cohen says DDoS attacks are the online equivalent of masked gunmen
storming a newsroom and taking a station off the air by force.
(MORE: The Internet Doesn’t Hurt People — People Do: ‘The New Digital Age’)
Google Ideas is introducing the new products during a conference in
New York City called “Conflict in a Connected World,” which the tech
giant is sponsoring in conjunction with the Council on Foreign
Relations and the Gen Next Foundation. Computer security experts,
entrepreneurs, dissidents and journalists from around the world have
gathered in lower Manhattan to discuss how technology can be both a
liberating force—and a tool for state repression.
Given Google’s size and influence in the tech world, it’s only natural
that some observers might take a cynical view of the company’s
Internet freedom efforts. After all, Google is neither a non-profit
group (although it has a philanthropic arm called Google.org) nor a
charitable organization. Google is a capitalist juggernaut with a $337
billion market capitalization, $56.5 billion in cash, and a stock
price that now exceeds $1000 per share. Put simply, as more people
around the world use the Internet, Google is poised to benefit
financially. Last quarter, Google said that revenue from outside the
U.S. totaled $7.67 billion, representing 56% of the company’s total
business, a figure that will only grow as more people around the world
get online.
In the interview with TIME, Cohen addressed such doubts. “If you think
about some of the environments we’re talking about, like North Korea,
Iran, Syria, Cuba, and Sudan, all of these countries have sanctions on
them,” says Cohen. “So there’s no business interest in these
countries. The interest we have is in giving users in every
environment the same level of security and unfiltered access that you
or I have here in the United States. We care about free expression,
and this is an example of us putting our product where our mouth is.”
Read more:

@_date: 2013-10-21 10:25:48
@_author: Yosem Companys 
@_subject: [liberationtech] Google Unveils Tools to Access Web From Repressive 
Google Ideas, the New York City-based “think/do tank” run by the
Internet search giant, is launching several new technologies designed
to highlight hacker attacks around the world and help people in
repressive regimes access the Internet. The new products, which are
being announced Monday at the Google Ideas Summit in New York City,
represent the most substantial offerings delivered by the
three-year-old Google policy unit and could be a major boon to
activists and reformers in the world’s most closed and repressive
“There are billions of people around the world living in environments
that severely restrict their free expression,” Jared Cohen, Director
of Google Ideas, told TIME in an interview on Sunday. “We want to
empower them to have access to the same Internet that the rest of us
experience. We talk about how we have a responsibility to our users.
That also includes people in Iran, North Korea, Cuba, and Syria, where
the challenges are so serious.”
Cohen, a 31-year-old geopolitical expert, earned undergraduate and
graduate degrees from Stanford and Oxford and later worked as a U.S.
State Department advisor to Condoleezza Rice and Hillary Clinton
before being asked by Google executive chairman Eric Schmidt to launch
Google Ideas in 2010. Cohen, who co-authored The New Digital Age with
Schmidt in April, said that he was attracted to Google by the
“activist spirit” of many of the company’s employees.
“This is a company of activists and white-hat hackers,” Cohen says.
“When you work at Google and tell these engineers that their skill-set
is relevant to somebody in Iran who doesn’t have access to information
in their country or the rest of the world, it really inspires them to
want to do something about it. There is a genuine altruism that exists
at this company, and that’s why I’m here and not anywhere else.”
The most ambitious product launch is uProxy, a new Web browser
extension that uses peer-to-peer technology to let people around the
world provide each other with a trusted Internet connection. This
product is designed to protect the Internet connection of users in,
say, Iran, from state surveillance or filtering. Google Ideas is
providing funding and technical assistance for uProxy, which was
developed by researchers at the University of Washington and Brave New
“If you look at existing proxy tools today, as soon as they’re
effective for dissidents, the government finds out about them and
either blocks them or infiltrates them,” says Cohen. “Every dissident
we know in every repressive society has friends outside the country
whom they know and trust. What if those trusted friends could unblock
the access in those repressive societies by sharing their own access?
That was the problem we tried to solve.”
UProxy allows users in the U.S. to give their trusted friends in
Iran—people they might already be emailing or chatting with—access to
the open U.S. Internet. “The user in Iran can get unfiltered access to
the Internet that’s completely uncensored and will look just like it
does in the U.S.,” says Cohen. “It’s completely encrypted and there’s
no way for the government to detect what’s happening because it just
looks like voice traffic or chat traffic. We wanted to build a proxy
service that builds on top of trusted relationships that already
Google Ideas is also launching Project Shield, which is an initiative
designed to help human rights activists, non-governmental
organizations (NGOs), election monitoring groups, and news
organizations better protect their websites from “distributed denial
of service” (DDoS) attacks. Several high-profile news organizations,
including The New York Times, have recently been targeted by hackers
who used DDoS attacks to temporarily shut down websites. ”Google is
very good at protecting itself from DDoS attacks,” says Cohen. “But
NGOs, independent media outlets, human rights organizations, and
election-monitoring organizations don’t have the capacity to protect
themselves in the way that we do.”
“We believe in human rights, we believe in free expression, we believe
in election-monitoring, and we believe in independent media.” Cohen
says the goal is to leverage Google’s technology to aid these efforts.
Project Shield is currently under development—consistent with Google’s
“launch and iterate” product philosophy—and the company is inviting
web-masters working in these areas to apply to join its next round of
“trusted” testers. For now, the product is free, Cohen says.
The third Google Ideas product launch is the Digital Attack Map, which
is a live data visualization, built in conjunction with network
security firm Arbor Networks, that displays DDoS attacks worldwide in
real-time. This online tool shows real-time anonymous traffic data
related to DDoS attacks, and also lets users explore historical trends
and see related news reports, via Google News, of website outages as
they are happening.
“What we’ve done for the first time is take all of the DDoS attacks
worldwide and show what the state of DDoS activity looks like in
real-time, much like you’d check the weather,” says Cohen. “If you
think about all of the organizations around the world that use a
website as their modern-day office—NGOs, businesses, governments—it’s
not OK to have this many digital office raids shutting them down.”
Cohen says DDoS attacks are the online equivalent of masked gunmen
storming a newsroom and taking a station off the air by force.
(MORE: The Internet Doesn’t Hurt People — People Do: ‘The New Digital Age’)
Google Ideas is introducing the new products during a conference in
New York City called “Conflict in a Connected World,” which the tech
giant is sponsoring in conjunction with the Council on Foreign
Relations and the Gen Next Foundation. Computer security experts,
entrepreneurs, dissidents and journalists from around the world have
gathered in lower Manhattan to discuss how technology can be both a
liberating force—and a tool for state repression.
Given Google’s size and influence in the tech world, it’s only natural
that some observers might take a cynical view of the company’s
Internet freedom efforts. After all, Google is neither a non-profit
group (although it has a philanthropic arm called Google.org) nor a
charitable organization. Google is a capitalist juggernaut with a $337
billion market capitalization, $56.5 billion in cash, and a stock
price that now exceeds $1000 per share. Put simply, as more people
around the world use the Internet, Google is poised to benefit
financially. Last quarter, Google said that revenue from outside the
U.S. totaled $7.67 billion, representing 56% of the company’s total
business, a figure that will only grow as more people around the world
get online.
In the interview with TIME, Cohen addressed such doubts. “If you think
about some of the environments we’re talking about, like North Korea,
Iran, Syria, Cuba, and Sudan, all of these countries have sanctions on
them,” says Cohen. “So there’s no business interest in these
countries. The interest we have is in giving users in every
environment the same level of security and unfiltered access that you
or I have here in the United States. We care about free expression,
and this is an example of us putting our product where our mouth is.”
Read more:

@_date: 2013-10-21 10:25:48
@_author: Yosem Companys 
@_subject: [liberationtech] Google Unveils Tools to Access Web From Repressive 
Google Ideas, the New York City-based “think/do tank” run by the
Internet search giant, is launching several new technologies designed
to highlight hacker attacks around the world and help people in
repressive regimes access the Internet. The new products, which are
being announced Monday at the Google Ideas Summit in New York City,
represent the most substantial offerings delivered by the
three-year-old Google policy unit and could be a major boon to
activists and reformers in the world’s most closed and repressive
“There are billions of people around the world living in environments
that severely restrict their free expression,” Jared Cohen, Director
of Google Ideas, told TIME in an interview on Sunday. “We want to
empower them to have access to the same Internet that the rest of us
experience. We talk about how we have a responsibility to our users.
That also includes people in Iran, North Korea, Cuba, and Syria, where
the challenges are so serious.”
Cohen, a 31-year-old geopolitical expert, earned undergraduate and
graduate degrees from Stanford and Oxford and later worked as a U.S.
State Department advisor to Condoleezza Rice and Hillary Clinton
before being asked by Google executive chairman Eric Schmidt to launch
Google Ideas in 2010. Cohen, who co-authored The New Digital Age with
Schmidt in April, said that he was attracted to Google by the
“activist spirit” of many of the company’s employees.
“This is a company of activists and white-hat hackers,” Cohen says.
“When you work at Google and tell these engineers that their skill-set
is relevant to somebody in Iran who doesn’t have access to information
in their country or the rest of the world, it really inspires them to
want to do something about it. There is a genuine altruism that exists
at this company, and that’s why I’m here and not anywhere else.”
The most ambitious product launch is uProxy, a new Web browser
extension that uses peer-to-peer technology to let people around the
world provide each other with a trusted Internet connection. This
product is designed to protect the Internet connection of users in,
say, Iran, from state surveillance or filtering. Google Ideas is
providing funding and technical assistance for uProxy, which was
developed by researchers at the University of Washington and Brave New
“If you look at existing proxy tools today, as soon as they’re
effective for dissidents, the government finds out about them and
either blocks them or infiltrates them,” says Cohen. “Every dissident
we know in every repressive society has friends outside the country
whom they know and trust. What if those trusted friends could unblock
the access in those repressive societies by sharing their own access?
That was the problem we tried to solve.”
UProxy allows users in the U.S. to give their trusted friends in
Iran—people they might already be emailing or chatting with—access to
the open U.S. Internet. “The user in Iran can get unfiltered access to
the Internet that’s completely uncensored and will look just like it
does in the U.S.,” says Cohen. “It’s completely encrypted and there’s
no way for the government to detect what’s happening because it just
looks like voice traffic or chat traffic. We wanted to build a proxy
service that builds on top of trusted relationships that already
Google Ideas is also launching Project Shield, which is an initiative
designed to help human rights activists, non-governmental
organizations (NGOs), election monitoring groups, and news
organizations better protect their websites from “distributed denial
of service” (DDoS) attacks. Several high-profile news organizations,
including The New York Times, have recently been targeted by hackers
who used DDoS attacks to temporarily shut down websites. ”Google is
very good at protecting itself from DDoS attacks,” says Cohen. “But
NGOs, independent media outlets, human rights organizations, and
election-monitoring organizations don’t have the capacity to protect
themselves in the way that we do.”
“We believe in human rights, we believe in free expression, we believe
in election-monitoring, and we believe in independent media.” Cohen
says the goal is to leverage Google’s technology to aid these efforts.
Project Shield is currently under development—consistent with Google’s
“launch and iterate” product philosophy—and the company is inviting
web-masters working in these areas to apply to join its next round of
“trusted” testers. For now, the product is free, Cohen says.
The third Google Ideas product launch is the Digital Attack Map, which
is a live data visualization, built in conjunction with network
security firm Arbor Networks, that displays DDoS attacks worldwide in
real-time. This online tool shows real-time anonymous traffic data
related to DDoS attacks, and also lets users explore historical trends
and see related news reports, via Google News, of website outages as
they are happening.
“What we’ve done for the first time is take all of the DDoS attacks
worldwide and show what the state of DDoS activity looks like in
real-time, much like you’d check the weather,” says Cohen. “If you
think about all of the organizations around the world that use a
website as their modern-day office—NGOs, businesses, governments—it’s
not OK to have this many digital office raids shutting them down.”
Cohen says DDoS attacks are the online equivalent of masked gunmen
storming a newsroom and taking a station off the air by force.
(MORE: The Internet Doesn’t Hurt People — People Do: ‘The New Digital Age’)
Google Ideas is introducing the new products during a conference in
New York City called “Conflict in a Connected World,” which the tech
giant is sponsoring in conjunction with the Council on Foreign
Relations and the Gen Next Foundation. Computer security experts,
entrepreneurs, dissidents and journalists from around the world have
gathered in lower Manhattan to discuss how technology can be both a
liberating force—and a tool for state repression.
Given Google’s size and influence in the tech world, it’s only natural
that some observers might take a cynical view of the company’s
Internet freedom efforts. After all, Google is neither a non-profit
group (although it has a philanthropic arm called Google.org) nor a
charitable organization. Google is a capitalist juggernaut with a $337
billion market capitalization, $56.5 billion in cash, and a stock
price that now exceeds $1000 per share. Put simply, as more people
around the world use the Internet, Google is poised to benefit
financially. Last quarter, Google said that revenue from outside the
U.S. totaled $7.67 billion, representing 56% of the company’s total
business, a figure that will only grow as more people around the world
get online.
In the interview with TIME, Cohen addressed such doubts. “If you think
about some of the environments we’re talking about, like North Korea,
Iran, Syria, Cuba, and Sudan, all of these countries have sanctions on
them,” says Cohen. “So there’s no business interest in these
countries. The interest we have is in giving users in every
environment the same level of security and unfiltered access that you
or I have here in the United States. We care about free expression,
and this is an example of us putting our product where our mouth is.”
Read more:

@_date: 2013-09-05 08:53:43
@_author: Yosem Companys 
@_subject: PayPal freezes MailPile's account 
Yes, but they could have used WePay, Stripe, or some other alternative.
 Remember Diaspora?  $80K in donations frozen by PayPal.  Once you get your
account unfrozen, as Diaspora learned, your momentum stops.  So it's
doubtful that they'll make over $45K now, without another appeal.

@_date: 2013-09-05 08:53:43
@_author: Yosem Companys 
@_subject: PayPal freezes MailPile's account 
Yes, but they could have used WePay, Stripe, or some other alternative.
 Remember Diaspora?  $80K in donations frozen by PayPal.  Once you get your
account unfrozen, as Diaspora learned, your momentum stops.  So it's
doubtful that they'll make over $45K now, without another appeal.

@_date: 2013-09-05 08:53:43
@_author: Yosem Companys 
@_subject: PayPal freezes MailPile's account 
Yes, but they could have used WePay, Stripe, or some other alternative.
 Remember Diaspora?  $80K in donations frozen by PayPal.  Once you get your
account unfrozen, as Diaspora learned, your momentum stops.  So it's
doubtful that they'll make over $45K now, without another appeal.
