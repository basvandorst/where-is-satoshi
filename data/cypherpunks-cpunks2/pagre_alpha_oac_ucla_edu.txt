
@_date: 2019-12-10 19:45:29
@_author: Phil Agre 
@_subject: [RRE]Your Face Is Not a Bar Code 
This message was forwarded through the Red Rock Eater News Service (RRE).
You are welcome to send the message along to others but please do not use
the "redirect" option.  For information about RRE, including instructions
for (un)subscribing, see    Your Face Is Not a Bar Code:
   Arguments Against Automatic Face Recognition in Public Places
   Phil Agre
      Version of 7 September 2001.
   2600 words.
   Copyright 2001 by Phil Agre.  You are welcome to forward this
   article in electronic form to anyone for any noncommercial reason.
   Please do not post it on any Web sites; instead, link to it here:
   Given a digital image of a person's face, face recognition software
matches it against a database of other images.  If any of the stored
images matches closely enough, the system reports the sighting to its
owner.  Research on automatic face recognition has been around for
decades, but accelerated in the 1990s.  Now it is becoming practical,
and face recognition systems are being deployed on a large scale.
Some applications of automatic face recognition systems are relatively
unobjectionable.  Many facilities have good reasons to authenticate
everyone who walks in the door, for example to regulate access to
weapons, money, criminal evidence, nuclear materials, or biohazards.
When a citizen has been arrested for probable cause, it is reasonable
for the police to use automatic face recognition to match a mug
shot of the individual against a database of mug shots of people who
have been arrested previously.  These uses of the technology should
be publicly justified, and audits should ensure that the technology
is being used only for proper purposes.
Face recognition systems in public places, however, are a matter for
serious concern.  The issue recently came to broad public attention
when it emerged that fans attending the Super Bowl had unknowingly
been matched against a database of alleged criminals, and when the
city of Tampa deployed a face-recognition system in the nightlife
district of Ybor City.  But current and proposed uses of face
recognition are much more widespread, as the resources at the end
of this article demonstrate in detail.  The time to consider the
acceptability of face recognition in public places is now, before
the practice becomes entrenched and people start getting hurt.
Nor is the problem limited to the scattered cases that have been
reported thus far.  As the underlying information and communication
technologies (digital cameras, image databases, processing power,
and data communications) become radically cheaper over the next two
decades, face recognition will become dramatically cheaper as well,
even without assuming major advances in technologies such as image
processing that are specific to recognizing faces.  Legal constraints
on the practice in the United States are minimal.  (In Europe the
data protection laws will apply, providing at least some basic rights
of notice and correction.)  Databases of identified facial images
already exist in large numbers (driver's license and employee ID
records, for example), and new facial-image databases will not be
hard to construct, with or without the knowledge or consent of the
people whose faces are captured.  (The images need to be captured
under controlled conditions, but most citizens enter controlled,
video-monitored spaces such as shops and offices on a regular basis.)
It is nearly certain, therefore, that automatic face recognition will
grow explosively and become pervasive unless action is taken now.
I believe that automatic face recognition in public places, including
commercial spaces such as shopping malls that are open to the public,
should be outlawed.  The dangers outweigh the benefits.  The necessary
laws will not be passed, however, without overwhelming pressure of
public opinion and organizing.  To that end, this article presents
the arguments against automatic face recognition in public places,
followed by responses to the most common arguments in favor.
Arguments against automatic face recognition in public places
  * The potential for abuse is astronomical.  Pervasive automatic
face recognition could be used to track individuals wherever they go.
Systems operated by different organizations could easily be networked
to cooperate in tracking an individual from place to place, whether
they know the person's identity or not, and they can share whatever
identities they do know.  This tracking information could be used
for many purposes.  At one end of the spectrum, the information could
be leaked to criminals who want to understand a prospective victim's
travel patterns.  Information routinely leaks from databases of all
sorts, and there is no reason to believe that tracking databases will
be any different.  But even more insidiously, tracking information can
be used to exert social control.  Individuals will be less likely to
contemplate public activities that offend powerful interests if they
know that their identity will be captured and relayed to anyone that
wants to know.
  * The information from face recognition systems is easily combined
with information from other technologies.  Industry often refers to
face recognition as "facial recognition" because they regard faces as
one modality of identification among many.  Among the many "biometric"
identification technologies, face recognition requires the least
cooperation from the individual.  Automatic fingerprint reading, by
contrast, requires an individual to press a finger against a machine.
(It will eventually be possible to identify people by the DNA-bearing
cells that they leave behind, but that technology is a long way
from becoming ubiquitous.)  Organizations that have good reasons to
identify individuals should employ whatever technology has the least
inherent potential for abuse, yet very few identification technologies
have more potential for abuse than face recognition.  Information
from face recognition systems is also easily combined with so-called
location technologies such as E-911 location tracking in cell phones,
thus further adding to the danger of abuse.
  * The technology is hardly foolproof.  Among the potential downsides
are false positives, for example that so-and-so was "seen" on a
street frequented by drug dealers.  Such a report will create "facts"
that the individual must explain away.  Yet the conditions for image
capture and recognition in most public places are far from ideal.
Shadows, occlusions, reflections, and multiple uncontrolled light
sources all increase the risk of false positives.  As the database
of facial images grows bigger, the chances of a false match to one of
those images grows proportionally larger.
  * Many social institutions depend on the difficulty of putting names
to faces without human intervention.  If people could be identified
just from looking in a shop window or eating in a restaurant, it
would be a tremendous change in our society's conception of the
human person.  People would find strangers addressing them by name.
Prospective customers walking into a shop could find that their
credit reports and other relevant information had already been pulled
up and displayed for the sales staff before they even inquire about
the goods.  Even aside from the privacy invasion that this represents,
premature disclosure of this sort of information could affect the
customer's bargaining position.
  * The public is poorly informed about the capabilities of the cameras
that are already ubiquitous in many countries.  They usually do not
realize, for example, what can be done with the infrared component
of the captured images.  Even the phrase "face recognition" does
not convey how easily the system can extract facial expressions.
It is not just "identity" that can be captured, then, but data that
reaches into the person's psyche.  Even if the public is adequately
informed about the capabilities of this year's cameras, software and
data sharing can be improved almost invisibly next year.
  * It is very hard to provide effective notice of the presence and
capabilities of cameras in most public places, much less obtain
meaningful consent.  Travel through many public places, for example
government offices and centralized transportation facilities,
is hardly a matter of choice for any individual wishing to live
in the modern world.  Even in the private sector, many retail
industries (groceries, for example) are highly concentrated, so that
consumers have little choice but to submit to the dominant company's
surveillance practices.
  * If face recognition technologies are pioneered in countries where
civil liberties are relatively strong, it becomes more likely that
they will also be deployed in countries where civil liberties hardly
exist.  In twenty years, at current rates of progress, it will be
feasible for the Chinese government to use face recognition to track
the public movements of everyone in the country.
Responses to arguments in favor of automatic face recognition in
public places
  * "All of the people in our database are wanted criminals.  We don't
store any of the images that our cameras capture, except when they
match an image in the database.  So the only people who have any cause
for complaint are criminals."
The problems with this argument are numerous:
(1) We have to trust your word that the only people whose images are
stored in the database are wanted criminals, and we have to trust
your word that you throw away all of the images that fail to match
the database.
(2) You don't really know yourself whether all of the people in the
database are criminals.  Quality control on those databases is far
from perfect, as the database of "felons" that was used to purge some
Florida counties' electoral rolls in 2000 demonstrated.
(3) Even if the only people in the database today are criminals, the
forces pushing us down a slippery slope of every-expanding databases
are nearly overwhelming.  Once the system is established and working,
why not add people with criminal records who have served their time?
Then we could add alleged troublemakers who have been ejected from
businesses in the past but have never been convicted of crimes, people
who have been convicted of minor offenses such as shoplifting, people
with court orders to stay away from certain places, missing persons,
children whose parents are worried about them, elders whose children
are worried about them, employees of the business where the system is
operating, and other individuals who have signed contracts agreeing to
be tracked.  And once those people are added, it is then a short step
to add many other categories of people as well.
  * "Public is public.  If someone happens to notice you walking in
the park, you have no grounds for complaint if they decide to tell
someone else where you were.  That's all we're doing.  You don't have
any reasonable expectation of privacy in a public place, and I have a
free-speech right to communicate factual information about where you
A human being who spots me in the park has the accountability that
someone can spot them as well.  Cameras are much more anonymous and
easy to hide.  More important is the question of scale.  Most people
understand the moral difference between a single chance observation
in a park and an investigator who follows you everywhere you go.  The
information collected in the second case is obviously more dangerous.
What is more, custom and law have always recognized many kinds of
privacy in public.  For example, the press cannot publish pictures of
most people in personally sensitive situations that have no legitimate
news value.  It is considered impolite to listen in on conversations
in public.  Pervasive face recognition clearly lies at the morally
most problematic end of this spectrum.  The chance of being spotted
is different from the certainty of being tracked.
The phrase "reasonable expectation of privacy" comes from a US Supreme
Court decision.  The phrase has been widely criticized as useless,
since reason that reasonable expectations of privacy in a situation
can disappear as soon as someone starts routinely invading privacy
in that situation.  The problem is an often-exploited ambiguity in
the word "expectation", which can mean either a prediction (with no
logical implication that the world morally *ought* to hold conform
to it) or a norm (with no logical implication that the world actually
*will* conform to it).  In arguing in favor of a ban on automatic face
recognition in public places, one is not arguing for a blanket "right
of privacy in public", which would be unreasonable and impractical.
Rather, one is arguing for a right against technologically mediated
privacy invasions of certain types.  Technological mediation is key
because of its continuous operation, standardized results, lack of
other legitimate purposes, and rapidly dropping costs.
The argument about free speech rights is spurious because the proposed
ban is not on the transfer of information, but on the creation of
certain kinds of electronic records.  You still have the right to
communicate the same information if you acquire it in other ways.
  * "Automatic face recognition stops crime.  Police say they want it.
And if it prevents one child from being killed then I support it."
A free society is a society in which there are limits on what the
police can do.  If we want to remain a free society then we need
to make a decision.  Once a new surveillance technology is installed,
it is nearly impossible to stop the slippery slope toward ever broader
law enforcement use of it.  The case of automatic toll collection
makes this clear.  Absent clear legal protections, then, we should
assume from the beginning that any technology that captures personal
information will be used for law enforcement purposes, and not only in
cases where lives are immediately at stake.  The potential for abuse
should then be figured into our decision about whether the technology
should be deployed at all.  That said, it is hardly proven that face
recognition stops crime, when face recognition is being added to a
world that already contains many other crime-fighting technologies.
The range of crime detection technologies available to the police
has grown immensely in recent years, and even if one encountered a
case where a crime was solved using a given technology it by no means
follows that the crime would not have been solved equally well using
some other technology.
  * "Privacy prevents the marketplace from functioning efficiently.
When a company knows more about you, it can tailor its offerings
more specifically to your needs.  Of course if you ask people whether
scary face recognition systems should be banned then they'll say yes.
But you're asking the wrong question.  The right question is whether
people are willing to give up information in exchange for something
of value, and most people are."
This is a non sequitur.  Few proposals for privacy protection prevent
people from voluntarily handing information about themselves to
companies with which they wish to do business.  The problem arises
when information is transferred without the individual's knowledge,
and in ways that might well cause upset or harm if they became known.
What distinguishes automatic face recognition from many other equally
good identification technologies is that it can be used without the
individual's permission (and therefore without the individual having
agreed to any exchange).  That is why it should be banned.
  * "A preoccupation with privacy is corrosive.  Democracy requires
people to have public personae, and excessive secrecy is unhealthy."
Privacy does not equal secrecy.  Privacy means that an individual has
reasonable control over what information is made public, and what is
not.  Any decent social order requires that individuals be entrusted
with this judgement.  Even if particular individuals choose to become
secretive in a pathological way, forcing them to change will not help
the situation and is intrinsincally wrong anyway.  As to the value of
public personae, we should encourage the development of technologies
that give people the option to appear publicly where and how they want.
  * "What do you have to hide?"
This line is used against nearly every attempt to protect personal
privacy, and the response in each case is the same.  People have lots
of valid reasons, personal safety for example, to prevent particular
others from knowing particular information about them.  Democracy only
works if groups can organize and develop their political strategies
in seclusion from the government, and from any established interests
they might be opposing.  This includes, for example, the identities of
people who might travel through public places to gather for a private
political meeting.  In its normal use, the question "What do you have
to hide?" stigmatizes all personal autonomy as anti-social.  As such
it is an authoritarian demand, and has no place in a free society.
For more responses to bad arguments against privacy, see:
News articles with background on face recognition.
Facial-Recognition System Gets Millions in Federal Funds
Facial ID Systems Raising Concerns About Privacy
Facial-Recognition Tech Has People Pegged
Face Scanners Turn Lens on Selves
Face-Recognition Systems Offer New Tools, but Mixed Results
How Facial Recognition Software Finds Faces
Law Enforcement Agencies Working on 3D Face Recognition Technology
Face-Recognition Technology Raises Fears of Big Brother
Seeking Clues to Recognition ... in Your Face
Smile, You're On Scan Camera
Other sites with background information on face recognition technology
and its potential for privacy invasion.
Electronic Privacy Information Center Face Recognition Page
Coalition Declares December 24, 2001 to Be "World Subjectrights Day"
Facial Recognition Vendor Test 2000
Selected Facial Scan Projects
US government site for biometric technology (including face recognition)
Facing the Truth: A New Tool to Analyze Our Expressions
Biometrics: Face Recognition Technology
Automatic Face and Gesture Recognition, Washington, 20-21 May 2002
the two dominant face recognition companies
other companies
Web pages about technical research projects on face recognition.
directory of face recognition research
Face Recognition and Detection
DoD Counterdrug Program Face Recognition Technology Program
Wearable Face Recognition and Detection
Identification of Faces From Video
Evaluation of Face Recognition Algorithms
slides from an MIT course on human and artificial face recognition
Gesture Recognition Home Page (related technology)
Articles about face-recognition controversies in various places,
roughly in reverse chronological order.
Borders stores
first Borders says it "suspended any plans to implement" face recognition ...
... then it denies that it ever had any such intention
Borders is planning to use face recognition to identify shop-lifters
Smart Cameras at Casinos Spark a Debate on Privacy
Privacy Commissioner Reassures Public That Casinos Are Not Scanning All Patrons
OPP uses secret cameras in casinos
("police are secretly scanning the faces of customers at all Ontario casinos")
Global Cash Access Signs New Contracts With 20 Gaming Properties
(face-recognizing ATM machines in casinos)
Smile! You're on Casino Camera
Virginia Beach, Virginia
Technology Helps Authorities Keep a Constant Eye on Public
Beach May Scan Oceanfront Faces
Huntington Beach, California
Imagis and ORION Chosen to Install Biometrics by Huntington Beach Police
Jacksonville, Florida
Police Snooper Camera Fight Still Alive
Florida City Moves to Ban Face-Recognition System
Pinellas County, Florida
Face Recognition System Will Be Used by Florida Sheriff's Office
Think Tank Urges Face-Scanning of the Masses
face recognition technology in the UK
Newham Council Launches "Face Recognition" in the UK
Joyrider, 14, Is First Tagging Guinea Pig
Colorado Governor Doesn't Want Face Recognition Technology Abused
 Colorado Won't Use Facial Recognition Technology on Licenses
 Colorado To Use Face Recognition Photos To Stop ID Theft
Colorado to "Map" Faces of Drivers
Minnesota Adopts Visionics' FaceIt for Integrated Mug Shot Database System
Super Bowl
Face Scans Match Few Suspects
ACLU Protests High-Tech Super Bowl Surveillance
Super Bowl Surveillance: Facing Up to Biometrics
Feds Use Biometrics Against Super Bowl Fans
Cameras Scanned Fans for Criminals
Tampa, Florida
Facial Frisking in Tampa
complete directory of Tampa news articles through early August from the ACLU
"Big Brother" Cameras on Watch for Criminals
"They made me feel like a criminal"
Tampa Face-Recognition Vote Rattles Privacy Group
Civil Rights or Just Sour Grapes?
Tampa City Council meeting which voted to keep the face recognition cameras
 Click. BEEP! Face Captured
Tampa Gets Ready For Its Closeup
Masked Protesters Fight Face Scans
Tampa Puts Face-Recognition System on Public Street
Congressional Leader Calls for Action on Ybor City Surveillance
(Ybor City is a busy nightlife neighborhood of Tampa)
ACLU Probes Police Use of Facial-Recognition Cameras in Florida City
Tampa Scans the Faces in Its Crowds for Criminals
public radio report about the controversy
Ybor Police Cameras Go Spy-Tech
Subscribe to Freematt's Alerts: Pro-Individual Rights Issues
Send a blank message to: freematt at coil.com with the words subscribe FA
on the subject line. List is private and moderated (7-30 messages per week)
Matthew Gaylor, (614) 313-5722  ICQ: 106212065   Archived at
