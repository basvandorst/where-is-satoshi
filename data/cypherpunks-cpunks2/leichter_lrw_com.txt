
@_date: 2013-11-05 07:18:58
@_author: Jerry Leichter 
@_subject: [Cryptography] randomness +- entropy 
Well, yes, and in its technical definitions - either in thermodynamics where it arose or information theory where it was imported because of a similarity in formalisms - it plays virtually no role in cryptographic discussion.  In cryptography, especially when discussing random number generators, the word has a loosy-goosy meaning that's somehow tied to lack of predictability - but in an unspecified way.  When people make it a regular habit to "guess" the entropy of various processes and then go on to build systems based on guesses, you know the word has lost any formal meaning it ever had.
While the distinctions you draw are valid and important, I'm afraid "entropy" no longer has the capability to distinguish them.
I don't know what this means.
I don't know what *this* means either.  I drew a distinction in an earlier post - a distinction you can find in many papers on cryptographic primitives - between random values (unpredictable to the attackers being considered) and nonces (never repeated in a given cryptographic context, but there are no assumptions about unpredictability).  Where a random n-bit value is specified, I can think of no paper that does not assume what we call "n bits of entropy" - though a better way to say it is "a value chosen uniformly at random from the set of n-bit strings".  Sometimes the value is supposed to be chosen uniformly at random from some other set - e.g., from Z/p, i.e., between 0 and p-1.  Trying to state this in terms of entropy is a losing game - and in fact it isn't actually trivial, given a random *bit* source, to produce such a distribution.  People have gotten it wrong in the past.  (The obvious technique of choosing a k with 2^k > p, choosing a "random" k-bit value, and the
 n reducing it mod p, if described in terms of "entropy", looks fine - I have k bits of entropy, which is more than enough to cover the choice I need to make.  But the output is biased.)
"Unicity distance" is a nice but different concept - and one with little bearing on cryptography today.  (If I draw a cipher E at random from some a collection of functions - e.g., by choosing a key - then the unicity distance is the unicity distance is just the number of pairs (x, E(x)) that specify E uniquely within the set.  I suppose you can stretch this to talk about how many samples from the "random" generator are needed to specify *it* uniquely - i.e., be able to determine all past and future states - but I've seen the term used that way.)  A broader - hence more useful - classical term (which may have been introduced by Shannon) is "equivocation".  I don't recall the formal definition, but it attempts to capture the uncertainty an attacker has about the next plaintext, given all the information he already has.  If I know a message was encrypted using a one-time pad, my uncertainty about the first character is not absolute - it's much more likely to be "t" than "z".  T
 o provide information-theoretic security, a one-time-pad must contain "enough randomness" to keep my a priori and a postiori equivocation equal.  This *is* something that can be given in terms of the entropies of the message and one-time-pad sources, but the deracinated notion of "entropy" one sees in most discussions is way too weak to say anything useful here.)
A BBS generator is "indistinguishable" from a true random number generator.  What's missing from that statement - and from the distinction you're drawing above - is a specification of the attack model.
The BBS generator has inherent limitations that are given in its proof of correctness:  The attacker has polynomially bounded resources (in fact, "attacker" literally means a polynomially-bounded probabilistic TM), which in turn implies that it only has access to a polynomially-bounded number of outputs.  These are generally fine.  The proof doesn't bother to state (though it's implicit) the obvious:  That the attacker doesn't have access to the internal state of the generator.  This isn't an "entropy" assumption - the internal state must, to the attacker, appear to have been chosen uniformly at random from all possible internal states, and is not available to the attacker.  If you want to use "entropy-talk", all the entropy in a BBS generator is there, at the start, in the choice of the initial state.  And yet there's a profound difference between the output of a BBS generator and the output of, say, a linear congruential PRNG starting with exactly the same state.  One is pr
 edictable given a few successive samples; the other is secure given any polynomially-bounded number of them.  "Entropy" simply cannot capture this distinction.  And it's in fact exactly the distinction - in the transition from Shannon's classic notions of information-based security to modern computability-based ones - that make it possible to say anything useful at all about encryption algorithms other than one-time-pads.
While we have no proofs like those for BBS for PRNG's built on practical cryptographic primitives, we generally assume that they have similar properties.  (More correctly, we can prove some properties given assumptions about others.  But those are the same assumptions we make about the actual encryption and hashing and signature algorithms we use.  If they fail, the whole system falls down regardless of the source of "random" values.)
To summarize:  The distinction between cryptographic PRNG's and "true" RNG's has to do with the attack model.  The attacker considered in the former is polynomially bounded (OK) and doesn't receive as input some special piece that we label "internal state" (this one can be violated).  The attacker against a "true" RNG is ... what?  Formalizing that is equivalent to formalizing randomness - which no one has managed to do.  (In fact, modern developments of probability theory don't even try - random distributions are simply among the axioms.  Even more, if you believe John Conway, the "Free Will" Theorem he and he and Simon Kochen proved show that "quantum unpredictability" is *stronger* than randomness!)  In practical cryptography, this translates into "whatever I can imagine".  In my other thread on plausible attacks, I tried to focus on limiting the attacker to, well, plausible operations in a particular real-world setting.  If you *don't* do that, you can make no progress at
  all.  A hardware generator - even Turbid - is vulnerable if I include as plausible an attacker who's infiltrated every supplier of electronic components in the world and has slipped a small transmitter into everything built, including every diode, resistor - hell, maybe every piece of wire!
I have no problem with designing strong, practical random number generators.  I'd love to see them deployed more widely.  But clever designs of low-level primitives, as important as they are, are not a substitute for *system* designs; in fact, they can blind us to the necessary system properties.  If a cryptographic primitive needs some unpredictable input, we need to go further and ask (a) how much? (b) unpredictable under what attack model?  Only then can we begin to answer the *system* design question of "what's a suitable generator for such inputs?"  If we can, for a reasonable cost (measured in any appropriate way), get our hands on a generator whose attack model assumes way more attacker resources than attacks on multiple uses of those values - great, let's make use of it.
Too much discussion of "random number generators" is the equivalent of "I'm not sure AES is strong enough, so I'll do a ROT-13 encoding first - it can't hurt".  And it can't - until you run into Tony Hoare's comment to the effect that "You can make a system so simple that you can see at a glance that it's correct, or so complex that you can't see at a glance that it's *not* correct."
                                                        -- Jerry
The cryptography mailing list

@_date: 2013-11-05 07:18:58
@_author: Jerry Leichter 
@_subject: [Cryptography] randomness +- entropy 
Well, yes, and in its technical definitions - either in thermodynamics where it arose or information theory where it was imported because of a similarity in formalisms - it plays virtually no role in cryptographic discussion.  In cryptography, especially when discussing random number generators, the word has a loosy-goosy meaning that's somehow tied to lack of predictability - but in an unspecified way.  When people make it a regular habit to "guess" the entropy of various processes and then go on to build systems based on guesses, you know the word has lost any formal meaning it ever had.
While the distinctions you draw are valid and important, I'm afraid "entropy" no longer has the capability to distinguish them.
I don't know what this means.
I don't know what *this* means either.  I drew a distinction in an earlier post - a distinction you can find in many papers on cryptographic primitives - between random values (unpredictable to the attackers being considered) and nonces (never repeated in a given cryptographic context, but there are no assumptions about unpredictability).  Where a random n-bit value is specified, I can think of no paper that does not assume what we call "n bits of entropy" - though a better way to say it is "a value chosen uniformly at random from the set of n-bit strings".  Sometimes the value is supposed to be chosen uniformly at random from some other set - e.g., from Z/p, i.e., between 0 and p-1.  Trying to state this in terms of entropy is a losing game - and in fact it isn't actually trivial, given a random *bit* source, to produce such a distribution.  People have gotten it wrong in the past.  (The obvious technique of choosing a k with 2^k > p, choosing a "random" k-bit value, and the
 n reducing it mod p, if described in terms of "entropy", looks fine - I have k bits of entropy, which is more than enough to cover the choice I need to make.  But the output is biased.)
"Unicity distance" is a nice but different concept - and one with little bearing on cryptography today.  (If I draw a cipher E at random from some a collection of functions - e.g., by choosing a key - then the unicity distance is the unicity distance is just the number of pairs (x, E(x)) that specify E uniquely within the set.  I suppose you can stretch this to talk about how many samples from the "random" generator are needed to specify *it* uniquely - i.e., be able to determine all past and future states - but I've seen the term used that way.)  A broader - hence more useful - classical term (which may have been introduced by Shannon) is "equivocation".  I don't recall the formal definition, but it attempts to capture the uncertainty an attacker has about the next plaintext, given all the information he already has.  If I know a message was encrypted using a one-time pad, my uncertainty about the first character is not absolute - it's much more likely to be "t" than "z".  T
 o provide information-theoretic security, a one-time-pad must contain "enough randomness" to keep my a priori and a postiori equivocation equal.  This *is* something that can be given in terms of the entropies of the message and one-time-pad sources, but the deracinated notion of "entropy" one sees in most discussions is way too weak to say anything useful here.)
A BBS generator is "indistinguishable" from a true random number generator.  What's missing from that statement - and from the distinction you're drawing above - is a specification of the attack model.
The BBS generator has inherent limitations that are given in its proof of correctness:  The attacker has polynomially bounded resources (in fact, "attacker" literally means a polynomially-bounded probabilistic TM), which in turn implies that it only has access to a polynomially-bounded number of outputs.  These are generally fine.  The proof doesn't bother to state (though it's implicit) the obvious:  That the attacker doesn't have access to the internal state of the generator.  This isn't an "entropy" assumption - the internal state must, to the attacker, appear to have been chosen uniformly at random from all possible internal states, and is not available to the attacker.  If you want to use "entropy-talk", all the entropy in a BBS generator is there, at the start, in the choice of the initial state.  And yet there's a profound difference between the output of a BBS generator and the output of, say, a linear congruential PRNG starting with exactly the same state.  One is pr
 edictable given a few successive samples; the other is secure given any polynomially-bounded number of them.  "Entropy" simply cannot capture this distinction.  And it's in fact exactly the distinction - in the transition from Shannon's classic notions of information-based security to modern computability-based ones - that make it possible to say anything useful at all about encryption algorithms other than one-time-pads.
While we have no proofs like those for BBS for PRNG's built on practical cryptographic primitives, we generally assume that they have similar properties.  (More correctly, we can prove some properties given assumptions about others.  But those are the same assumptions we make about the actual encryption and hashing and signature algorithms we use.  If they fail, the whole system falls down regardless of the source of "random" values.)
To summarize:  The distinction between cryptographic PRNG's and "true" RNG's has to do with the attack model.  The attacker considered in the former is polynomially bounded (OK) and doesn't receive as input some special piece that we label "internal state" (this one can be violated).  The attacker against a "true" RNG is ... what?  Formalizing that is equivalent to formalizing randomness - which no one has managed to do.  (In fact, modern developments of probability theory don't even try - random distributions are simply among the axioms.  Even more, if you believe John Conway, the "Free Will" Theorem he and he and Simon Kochen proved show that "quantum unpredictability" is *stronger* than randomness!)  In practical cryptography, this translates into "whatever I can imagine".  In my other thread on plausible attacks, I tried to focus on limiting the attacker to, well, plausible operations in a particular real-world setting.  If you *don't* do that, you can make no progress at
  all.  A hardware generator - even Turbid - is vulnerable if I include as plausible an attacker who's infiltrated every supplier of electronic components in the world and has slipped a small transmitter into everything built, including every diode, resistor - hell, maybe every piece of wire!
I have no problem with designing strong, practical random number generators.  I'd love to see them deployed more widely.  But clever designs of low-level primitives, as important as they are, are not a substitute for *system* designs; in fact, they can blind us to the necessary system properties.  If a cryptographic primitive needs some unpredictable input, we need to go further and ask (a) how much? (b) unpredictable under what attack model?  Only then can we begin to answer the *system* design question of "what's a suitable generator for such inputs?"  If we can, for a reasonable cost (measured in any appropriate way), get our hands on a generator whose attack model assumes way more attacker resources than attacks on multiple uses of those values - great, let's make use of it.
Too much discussion of "random number generators" is the equivalent of "I'm not sure AES is strong enough, so I'll do a ROT-13 encoding first - it can't hurt".  And it can't - until you run into Tony Hoare's comment to the effect that "You can make a system so simple that you can see at a glance that it's correct, or so complex that you can't see at a glance that it's *not* correct."
                                                        -- Jerry
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-11-05 07:18:58
@_author: Jerry Leichter 
@_subject: [Cryptography] randomness +- entropy 
Well, yes, and in its technical definitions - either in thermodynamics where it arose or information theory where it was imported because of a similarity in formalisms - it plays virtually no role in cryptographic discussion.  In cryptography, especially when discussing random number generators, the word has a loosy-goosy meaning that's somehow tied to lack of predictability - but in an unspecified way.  When people make it a regular habit to "guess" the entropy of various processes and then go on to build systems based on guesses, you know the word has lost any formal meaning it ever had.
While the distinctions you draw are valid and important, I'm afraid "entropy" no longer has the capability to distinguish them.
I don't know what this means.
I don't know what *this* means either.  I drew a distinction in an earlier post - a distinction you can find in many papers on cryptographic primitives - between random values (unpredictable to the attackers being considered) and nonces (never repeated in a given cryptographic context, but there are no assumptions about unpredictability).  Where a random n-bit value is specified, I can think of no paper that does not assume what we call "n bits of entropy" - though a better way to say it is "a value chosen uniformly at random from the set of n-bit strings".  Sometimes the value is supposed to be chosen uniformly at random from some other set - e.g., from Z/p, i.e., between 0 and p-1.  Trying to state this in terms of entropy is a losing game - and in fact it isn't actually trivial, given a random *bit* source, to produce such a distribution.  People have gotten it wrong in the past.  (The obvious technique of choosing a k with 2^k > p, choosing a "random" k-bit value, and the
 n reducing it mod p, if described in terms of "entropy", looks fine - I have k bits of entropy, which is more than enough to cover the choice I need to make.  But the output is biased.)
"Unicity distance" is a nice but different concept - and one with little bearing on cryptography today.  (If I draw a cipher E at random from some a collection of functions - e.g., by choosing a key - then the unicity distance is the unicity distance is just the number of pairs (x, E(x)) that specify E uniquely within the set.  I suppose you can stretch this to talk about how many samples from the "random" generator are needed to specify *it* uniquely - i.e., be able to determine all past and future states - but I've seen the term used that way.)  A broader - hence more useful - classical term (which may have been introduced by Shannon) is "equivocation".  I don't recall the formal definition, but it attempts to capture the uncertainty an attacker has about the next plaintext, given all the information he already has.  If I know a message was encrypted using a one-time pad, my uncertainty about the first character is not absolute - it's much more likely to be "t" than "z".  T
 o provide information-theoretic security, a one-time-pad must contain "enough randomness" to keep my a priori and a postiori equivocation equal.  This *is* something that can be given in terms of the entropies of the message and one-time-pad sources, but the deracinated notion of "entropy" one sees in most discussions is way too weak to say anything useful here.)
A BBS generator is "indistinguishable" from a true random number generator.  What's missing from that statement - and from the distinction you're drawing above - is a specification of the attack model.
The BBS generator has inherent limitations that are given in its proof of correctness:  The attacker has polynomially bounded resources (in fact, "attacker" literally means a polynomially-bounded probabilistic TM), which in turn implies that it only has access to a polynomially-bounded number of outputs.  These are generally fine.  The proof doesn't bother to state (though it's implicit) the obvious:  That the attacker doesn't have access to the internal state of the generator.  This isn't an "entropy" assumption - the internal state must, to the attacker, appear to have been chosen uniformly at random from all possible internal states, and is not available to the attacker.  If you want to use "entropy-talk", all the entropy in a BBS generator is there, at the start, in the choice of the initial state.  And yet there's a profound difference between the output of a BBS generator and the output of, say, a linear congruential PRNG starting with exactly the same state.  One is pr
 edictable given a few successive samples; the other is secure given any polynomially-bounded number of them.  "Entropy" simply cannot capture this distinction.  And it's in fact exactly the distinction - in the transition from Shannon's classic notions of information-based security to modern computability-based ones - that make it possible to say anything useful at all about encryption algorithms other than one-time-pads.
While we have no proofs like those for BBS for PRNG's built on practical cryptographic primitives, we generally assume that they have similar properties.  (More correctly, we can prove some properties given assumptions about others.  But those are the same assumptions we make about the actual encryption and hashing and signature algorithms we use.  If they fail, the whole system falls down regardless of the source of "random" values.)
To summarize:  The distinction between cryptographic PRNG's and "true" RNG's has to do with the attack model.  The attacker considered in the former is polynomially bounded (OK) and doesn't receive as input some special piece that we label "internal state" (this one can be violated).  The attacker against a "true" RNG is ... what?  Formalizing that is equivalent to formalizing randomness - which no one has managed to do.  (In fact, modern developments of probability theory don't even try - random distributions are simply among the axioms.  Even more, if you believe John Conway, the "Free Will" Theorem he and he and Simon Kochen proved show that "quantum unpredictability" is *stronger* than randomness!)  In practical cryptography, this translates into "whatever I can imagine".  In my other thread on plausible attacks, I tried to focus on limiting the attacker to, well, plausible operations in a particular real-world setting.  If you *don't* do that, you can make no progress at
  all.  A hardware generator - even Turbid - is vulnerable if I include as plausible an attacker who's infiltrated every supplier of electronic components in the world and has slipped a small transmitter into everything built, including every diode, resistor - hell, maybe every piece of wire!
I have no problem with designing strong, practical random number generators.  I'd love to see them deployed more widely.  But clever designs of low-level primitives, as important as they are, are not a substitute for *system* designs; in fact, they can blind us to the necessary system properties.  If a cryptographic primitive needs some unpredictable input, we need to go further and ask (a) how much? (b) unpredictable under what attack model?  Only then can we begin to answer the *system* design question of "what's a suitable generator for such inputs?"  If we can, for a reasonable cost (measured in any appropriate way), get our hands on a generator whose attack model assumes way more attacker resources than attacks on multiple uses of those values - great, let's make use of it.
Too much discussion of "random number generators" is the equivalent of "I'm not sure AES is strong enough, so I'll do a ROT-13 encoding first - it can't hurt".  And it can't - until you run into Tony Hoare's comment to the effect that "You can make a system so simple that you can see at a glance that it's correct, or so complex that you can't see at a glance that it's *not* correct."
                                                        -- Jerry
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-20 10:22:16
@_author: Jerry Leichter 
@_subject: [Cryptography] Mail Lists In the Post-Snowden Era 
Perry re-started this mailing list in response to the Snowden revelations about the NSA's attacks on Internet cryptography.  He raised the questions of whether we could make a Prism-proof Internet.
That's a big problem, and we've been debating small pieces of it ever since.  I'd like to suggest a smaller problem, just as a kind of rallying point.
This list has certainly attracted NSA interest.  Whether by subject, by keyword matching, or because so many of the participants here are clearly "adversaries" of those in the NSA responsible for gaining access to all that crunchy good stuff out there, there's no way anyone here could avoid scrutiny.
So ... imagine we don't like that.  How could this list be constituted in a "secure" way?  The quotes are on "secure" because even the definition of the word isn't clear.  Realistically, there's no way to avoid an NSA "plant" joining an open group, so perhaps there's little point in encrypting the messages.  Anonymous/pseudonymous posting?  Signed messages?  (A few members post them; hardly any of us do.)  Does that just make messages even more traceable/linkable?
We think we know what it means to have secure 1-1 email.  Adding a couple of additional participants seems as if it leaves the nature of the problem unchanged, but in fact you very quickly get into trust issues:  In a 1-1 conversation, I can decide whether to trust my correspondent.  In any multi-party conversation, it's likely that at least one of the participants doesn't know *all* the others, so must make an indirect trust decision:  I trust him because the others here seem to trust him.  For a mailing list, this problem explodes - while in addition there are all kinds of issue with how exactly to set up key exchanges.  A moderated group like this could be looked at as a star configuration:  In a way, each participant really only communicates with the moderator.  But that seems to miss the point - despite the moderation, this group *feels* like a free-flowing conversation among a group of people.
So what would a reasonable security model for the Cryptography list look like?  Is it inherently just an open discussion?  Or could we come up with something else?  If we can do more, what kind of software would be needed to make it as free-flowing and easy to participate in and manage as the current list?
                                                        -- Jerry
The cryptography mailing list

@_date: 2013-10-23 06:14:53
@_author: Jerry Leichter 
@_subject: [Cryptography] programable computers inside our computers (was: 
Actually, there is a difference:  Palladium had remote attestation built in - it was a selling point.  People concentrated on that as the "bad" part, thought the rest could actually be useful.  The reference designs let you do whatever you wanted with your own device - you have full access to the trusted elements, could sign your own boot loader if you wanted.  Of course, someone providing DRM'ed material could refuse to talk to your system if it didn't attest to running "acceptable" code.
The new technologies don't build remote attestation in, so avoid the whole debate.  And the base technologies are neutral on the issue of whether you can write your own trusted code.  It's the specific implementations that block you from changing the keys, the bootloader, any of the code running in the secure element, etc.
The net effect is similar.  Nothing keeps a system builder from including remote attestation, but because of the nature of the devices, who is doing the controlling (the cell service providers), and the much higher level of integration of the components (making it harder to pull pieces out of the controlled environment) it really doesn't much matter:  If you're successfully talking to the cell network at all, they assume you have "approved" hardware. (Should people start building their own cell hardware from the ground up - certainly possible if you don't care about how practical the device is as a *cell phone*, but extremely difficult if you want something practical - they could always add remote attestation, or some simplified variant that's good enough for the cell provider's purposes, later.)
Palladium was subject to political attack because it was open about what it could do for DRM suppliers.  The new technologies are harder to attack this way because the responsibility is diffused, and the good and the bad are very thoroughly mixed together.  The availability of secure modes in the hardware can be explained as necessary to allow for safe operation in an unsafe world, and in and of themselves harmless - just a safer extension of user space/kernel space isolation.  The system builders build things to keep the systems safe from malware, a known and growing problem.  The network providers want to protect their networks.  Everyone sees the need for heavy protection - including from the device owner - of internal "wallets".
                                                        -- Jerry
The cryptography mailing list

@_date: 2013-10-20 10:22:16
@_author: Jerry Leichter 
@_subject: [Cryptography] Mail Lists In the Post-Snowden Era 
Perry re-started this mailing list in response to the Snowden revelations about the NSA's attacks on Internet cryptography.  He raised the questions of whether we could make a Prism-proof Internet.
That's a big problem, and we've been debating small pieces of it ever since.  I'd like to suggest a smaller problem, just as a kind of rallying point.
This list has certainly attracted NSA interest.  Whether by subject, by keyword matching, or because so many of the participants here are clearly "adversaries" of those in the NSA responsible for gaining access to all that crunchy good stuff out there, there's no way anyone here could avoid scrutiny.
So ... imagine we don't like that.  How could this list be constituted in a "secure" way?  The quotes are on "secure" because even the definition of the word isn't clear.  Realistically, there's no way to avoid an NSA "plant" joining an open group, so perhaps there's little point in encrypting the messages.  Anonymous/pseudonymous posting?  Signed messages?  (A few members post them; hardly any of us do.)  Does that just make messages even more traceable/linkable?
We think we know what it means to have secure 1-1 email.  Adding a couple of additional participants seems as if it leaves the nature of the problem unchanged, but in fact you very quickly get into trust issues:  In a 1-1 conversation, I can decide whether to trust my correspondent.  In any multi-party conversation, it's likely that at least one of the participants doesn't know *all* the others, so must make an indirect trust decision:  I trust him because the others here seem to trust him.  For a mailing list, this problem explodes - while in addition there are all kinds of issue with how exactly to set up key exchanges.  A moderated group like this could be looked at as a star configuration:  In a way, each participant really only communicates with the moderator.  But that seems to miss the point - despite the moderation, this group *feels* like a free-flowing conversation among a group of people.
So what would a reasonable security model for the Cryptography list look like?  Is it inherently just an open discussion?  Or could we come up with something else?  If we can do more, what kind of software would be needed to make it as free-flowing and easy to participate in and manage as the current list?
                                                        -- Jerry
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-23 06:14:53
@_author: Jerry Leichter 
@_subject: [Cryptography] programable computers inside our computers (was: 
Actually, there is a difference:  Palladium had remote attestation built in - it was a selling point.  People concentrated on that as the "bad" part, thought the rest could actually be useful.  The reference designs let you do whatever you wanted with your own device - you have full access to the trusted elements, could sign your own boot loader if you wanted.  Of course, someone providing DRM'ed material could refuse to talk to your system if it didn't attest to running "acceptable" code.
The new technologies don't build remote attestation in, so avoid the whole debate.  And the base technologies are neutral on the issue of whether you can write your own trusted code.  It's the specific implementations that block you from changing the keys, the bootloader, any of the code running in the secure element, etc.
The net effect is similar.  Nothing keeps a system builder from including remote attestation, but because of the nature of the devices, who is doing the controlling (the cell service providers), and the much higher level of integration of the components (making it harder to pull pieces out of the controlled environment) it really doesn't much matter:  If you're successfully talking to the cell network at all, they assume you have "approved" hardware. (Should people start building their own cell hardware from the ground up - certainly possible if you don't care about how practical the device is as a *cell phone*, but extremely difficult if you want something practical - they could always add remote attestation, or some simplified variant that's good enough for the cell provider's purposes, later.)
Palladium was subject to political attack because it was open about what it could do for DRM suppliers.  The new technologies are harder to attack this way because the responsibility is diffused, and the good and the bad are very thoroughly mixed together.  The availability of secure modes in the hardware can be explained as necessary to allow for safe operation in an unsafe world, and in and of themselves harmless - just a safer extension of user space/kernel space isolation.  The system builders build things to keep the systems safe from malware, a known and growing problem.  The network providers want to protect their networks.  Everyone sees the need for heavy protection - including from the device owner - of internal "wallets".
                                                        -- Jerry
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-20 10:22:16
@_author: Jerry Leichter 
@_subject: [Cryptography] Mail Lists In the Post-Snowden Era 
Perry re-started this mailing list in response to the Snowden revelations about the NSA's attacks on Internet cryptography.  He raised the questions of whether we could make a Prism-proof Internet.
That's a big problem, and we've been debating small pieces of it ever since.  I'd like to suggest a smaller problem, just as a kind of rallying point.
This list has certainly attracted NSA interest.  Whether by subject, by keyword matching, or because so many of the participants here are clearly "adversaries" of those in the NSA responsible for gaining access to all that crunchy good stuff out there, there's no way anyone here could avoid scrutiny.
So ... imagine we don't like that.  How could this list be constituted in a "secure" way?  The quotes are on "secure" because even the definition of the word isn't clear.  Realistically, there's no way to avoid an NSA "plant" joining an open group, so perhaps there's little point in encrypting the messages.  Anonymous/pseudonymous posting?  Signed messages?  (A few members post them; hardly any of us do.)  Does that just make messages even more traceable/linkable?
We think we know what it means to have secure 1-1 email.  Adding a couple of additional participants seems as if it leaves the nature of the problem unchanged, but in fact you very quickly get into trust issues:  In a 1-1 conversation, I can decide whether to trust my correspondent.  In any multi-party conversation, it's likely that at least one of the participants doesn't know *all* the others, so must make an indirect trust decision:  I trust him because the others here seem to trust him.  For a mailing list, this problem explodes - while in addition there are all kinds of issue with how exactly to set up key exchanges.  A moderated group like this could be looked at as a star configuration:  In a way, each participant really only communicates with the moderator.  But that seems to miss the point - despite the moderation, this group *feels* like a free-flowing conversation among a group of people.
So what would a reasonable security model for the Cryptography list look like?  Is it inherently just an open discussion?  Or could we come up with something else?  If we can do more, what kind of software would be needed to make it as free-flowing and easy to participate in and manage as the current list?
                                                        -- Jerry
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-23 06:14:53
@_author: Jerry Leichter 
@_subject: [Cryptography] programable computers inside our computers (was: 
Actually, there is a difference:  Palladium had remote attestation built in - it was a selling point.  People concentrated on that as the "bad" part, thought the rest could actually be useful.  The reference designs let you do whatever you wanted with your own device - you have full access to the trusted elements, could sign your own boot loader if you wanted.  Of course, someone providing DRM'ed material could refuse to talk to your system if it didn't attest to running "acceptable" code.
The new technologies don't build remote attestation in, so avoid the whole debate.  And the base technologies are neutral on the issue of whether you can write your own trusted code.  It's the specific implementations that block you from changing the keys, the bootloader, any of the code running in the secure element, etc.
The net effect is similar.  Nothing keeps a system builder from including remote attestation, but because of the nature of the devices, who is doing the controlling (the cell service providers), and the much higher level of integration of the components (making it harder to pull pieces out of the controlled environment) it really doesn't much matter:  If you're successfully talking to the cell network at all, they assume you have "approved" hardware. (Should people start building their own cell hardware from the ground up - certainly possible if you don't care about how practical the device is as a *cell phone*, but extremely difficult if you want something practical - they could always add remote attestation, or some simplified variant that's good enough for the cell provider's purposes, later.)
Palladium was subject to political attack because it was open about what it could do for DRM suppliers.  The new technologies are harder to attack this way because the responsibility is diffused, and the good and the bad are very thoroughly mixed together.  The availability of secure modes in the hardware can be explained as necessary to allow for safe operation in an unsafe world, and in and of themselves harmless - just a safer extension of user space/kernel space isolation.  The system builders build things to keep the systems safe from malware, a known and growing problem.  The network providers want to protect their networks.  Everyone sees the need for heavy protection - including from the device owner - of internal "wallets".
                                                        -- Jerry
The cryptography mailing list
cryptography at metzdowd.com
