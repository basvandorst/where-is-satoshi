
@_date: 2013-10-21 14:28:22
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Also, the universe is of limited size and life expectancy: the "resources and time" bit really matters once the numbers get big.
In isolation of a larger analysis (of the threat and the definition of the system boundaries being defended) there are still useful things to say. Such as ROT-13 is extremely weak, DES medium weak, AES-256 likely very much stronger, OTP completely strong.
But the system boundaries matter. I don't hold AES-256 responsible for protecting the secrecy of the key, though that matters in a larger system (try memorizing and accurately entering 256-bits, it ain't easy).  Similarly, I don't hold OTP responsible for key generation nor key distribution, though those do become extremely important when designing the larger system.
One has to look at the larger system if one wants to draw conclusions about the security of the larger system (and so on for the system larger than that, and the one larger than that).  But components can still be examined, at each level, weaknesses found, improvements made.
In the case of and RNG (as with much of crypto), failures can be silent.  It makes sense to build into an RNG the ability to refuse to work absent any seed (or entropy, as the case may be).  It makes sense to make this facility have parameters that can be tuned by those using it when carefully building a larger system.  It further makes sense to choose defaults that give those larger designers as much help as possible, hurt as little as possible, and try to reduce the "fail silently" property to fewer cases and lesser severity.
If the RNG also mixes in locally unique information that isn't particularly secret (MAC addresses, time, etc.), as long as it doesn't hurt, I conclude it doesn't hurt and it is worth doing. Even if you don't know what the larger system is, it helps.  A little like a crypto angorithm having more rounds, it usually helps.
The refusal to look at the component without first being served your cookies and milk is pedandic silliness.  Like refusing to reduce the failure rate of your bolts, nor examine their strength, because it is the fault of the bridge builder for not doing the entire analysis and using enough bolts.  Yes, the bridge builder should do his/er job.  But it is still worth talking about bridges independent of any specific structure.  It is still worth studying bolts independent of specific Similarly, reducing the silent failure modes of RNGs, and making residual failures less fatal, is worthwhile.
The cryptography mailing list

@_date: 2013-10-24 12:04:10
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
A warning here: when mixing in different sources, you want to make sure they are different or it might make matters worse.
In recent versions of Linux's urandom the Intel CPU random HW is NOT independent of urandom output; CPU HW random bits are XOR-ed in just before they are output.
If you mix them Intel random bits again you are making a complex system that is hard to analyze, and so not necessarily an improvement.  Using some different and independent HW source?  Cool.
The cryptography mailing list

@_date: 2013-10-28 14:42:34
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Peter Saint-Andre , Russ Nelson Knowing "packet timing" isn't good enough.  It is the interrupt timing that matters, and even that isn't good enough, at least not in the case of a fast CPU with a GHz+ system clock: you have to know the value of a fast counter at the moment that it is sampled as part of servicing the The clock the attacker needs to know doesn't even exist outside the chip in question.  An attacker needs to infer very precise phase angles here, or a bit or more of entropy will slip through on that interrupt.
And you expect to measure this via malware running on a cheap printer plugged into feet of ethernet cable plus an ethernet switch plus more cabling between it and the computer that gets the interrupt?  The malware might make an estimation of interrupt timing, but it can't get down to the last LSB of that clock at the moment when the CPU gets around to reading it.
We are talking not just an off-chip measurement of a signal that doesn't exist off-chip, we are talking about doing it from outside the box, when the box isn't trying to cooperate.
Making timing measurments precisely is hard to do in the best possible and most carefully engineered circumstances.
The cryptography mailing list

@_date: 2013-10-21 14:28:22
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Also, the universe is of limited size and life expectancy: the "resources and time" bit really matters once the numbers get big.
In isolation of a larger analysis (of the threat and the definition of the system boundaries being defended) there are still useful things to say. Such as ROT-13 is extremely weak, DES medium weak, AES-256 likely very much stronger, OTP completely strong.
But the system boundaries matter. I don't hold AES-256 responsible for protecting the secrecy of the key, though that matters in a larger system (try memorizing and accurately entering 256-bits, it ain't easy).  Similarly, I don't hold OTP responsible for key generation nor key distribution, though those do become extremely important when designing the larger system.
One has to look at the larger system if one wants to draw conclusions about the security of the larger system (and so on for the system larger than that, and the one larger than that).  But components can still be examined, at each level, weaknesses found, improvements made.
In the case of and RNG (as with much of crypto), failures can be silent.  It makes sense to build into an RNG the ability to refuse to work absent any seed (or entropy, as the case may be).  It makes sense to make this facility have parameters that can be tuned by those using it when carefully building a larger system.  It further makes sense to choose defaults that give those larger designers as much help as possible, hurt as little as possible, and try to reduce the "fail silently" property to fewer cases and lesser severity.
If the RNG also mixes in locally unique information that isn't particularly secret (MAC addresses, time, etc.), as long as it doesn't hurt, I conclude it doesn't hurt and it is worth doing. Even if you don't know what the larger system is, it helps.  A little like a crypto angorithm having more rounds, it usually helps.
The refusal to look at the component without first being served your cookies and milk is pedandic silliness.  Like refusing to reduce the failure rate of your bolts, nor examine their strength, because it is the fault of the bridge builder for not doing the entire analysis and using enough bolts.  Yes, the bridge builder should do his/er job.  But it is still worth talking about bridges independent of any specific structure.  It is still worth studying bolts independent of specific Similarly, reducing the silent failure modes of RNGs, and making residual failures less fatal, is worthwhile.
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-24 12:04:10
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
A warning here: when mixing in different sources, you want to make sure they are different or it might make matters worse.
In recent versions of Linux's urandom the Intel CPU random HW is NOT independent of urandom output; CPU HW random bits are XOR-ed in just before they are output.
If you mix them Intel random bits again you are making a complex system that is hard to analyze, and so not necessarily an improvement.  Using some different and independent HW source?  Cool.
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-28 14:42:34
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Peter Saint-Andre , Russ Nelson Knowing "packet timing" isn't good enough.  It is the interrupt timing that matters, and even that isn't good enough, at least not in the case of a fast CPU with a GHz+ system clock: you have to know the value of a fast counter at the moment that it is sampled as part of servicing the The clock the attacker needs to know doesn't even exist outside the chip in question.  An attacker needs to infer very precise phase angles here, or a bit or more of entropy will slip through on that interrupt.
And you expect to measure this via malware running on a cheap printer plugged into feet of ethernet cable plus an ethernet switch plus more cabling between it and the computer that gets the interrupt?  The malware might make an estimation of interrupt timing, but it can't get down to the last LSB of that clock at the moment when the CPU gets around to reading it.
We are talking not just an off-chip measurement of a signal that doesn't exist off-chip, we are talking about doing it from outside the box, when the box isn't trying to cooperate.
Making timing measurments precisely is hard to do in the best possible and most carefully engineered circumstances.
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-21 14:28:22
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Also, the universe is of limited size and life expectancy: the "resources and time" bit really matters once the numbers get big.
In isolation of a larger analysis (of the threat and the definition of the system boundaries being defended) there are still useful things to say. Such as ROT-13 is extremely weak, DES medium weak, AES-256 likely very much stronger, OTP completely strong.
But the system boundaries matter. I don't hold AES-256 responsible for protecting the secrecy of the key, though that matters in a larger system (try memorizing and accurately entering 256-bits, it ain't easy).  Similarly, I don't hold OTP responsible for key generation nor key distribution, though those do become extremely important when designing the larger system.
One has to look at the larger system if one wants to draw conclusions about the security of the larger system (and so on for the system larger than that, and the one larger than that).  But components can still be examined, at each level, weaknesses found, improvements made.
In the case of and RNG (as with much of crypto), failures can be silent.  It makes sense to build into an RNG the ability to refuse to work absent any seed (or entropy, as the case may be).  It makes sense to make this facility have parameters that can be tuned by those using it when carefully building a larger system.  It further makes sense to choose defaults that give those larger designers as much help as possible, hurt as little as possible, and try to reduce the "fail silently" property to fewer cases and lesser severity.
If the RNG also mixes in locally unique information that isn't particularly secret (MAC addresses, time, etc.), as long as it doesn't hurt, I conclude it doesn't hurt and it is worth doing. Even if you don't know what the larger system is, it helps.  A little like a crypto angorithm having more rounds, it usually helps.
The refusal to look at the component without first being served your cookies and milk is pedandic silliness.  Like refusing to reduce the failure rate of your bolts, nor examine their strength, because it is the fault of the bridge builder for not doing the entire analysis and using enough bolts.  Yes, the bridge builder should do his/er job.  But it is still worth talking about bridges independent of any specific structure.  It is still worth studying bolts independent of specific Similarly, reducing the silent failure modes of RNGs, and making residual failures less fatal, is worthwhile.
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-24 12:04:10
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
A warning here: when mixing in different sources, you want to make sure they are different or it might make matters worse.
In recent versions of Linux's urandom the Intel CPU random HW is NOT independent of urandom output; CPU HW random bits are XOR-ed in just before they are output.
If you mix them Intel random bits again you are making a complex system that is hard to analyze, and so not necessarily an improvement.  Using some different and independent HW source?  Cool.
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-28 14:42:34
@_author: Kent Borg 
@_subject: [Cryptography] [RNG] on RNGs, VM state, rollback, etc. 
Knowing "packet timing" isn't good enough.  It is the interrupt timing that matters, and even that isn't good enough, at least not in the case of a fast CPU with a GHz+ system clock: you have to know the value of a fast counter at the moment that it is sampled as part of servicing the The clock the attacker needs to know doesn't even exist outside the chip in question.  An attacker needs to infer very precise phase angles here, or a bit or more of entropy will slip through on that interrupt.
And you expect to measure this via malware running on a cheap printer plugged into feet of ethernet cable plus an ethernet switch plus more cabling between it and the computer that gets the interrupt?  The malware might make an estimation of interrupt timing, but it can't get down to the last LSB of that clock at the moment when the CPU gets around to reading it.
We are talking not just an off-chip measurement of a signal that doesn't exist off-chip, we are talking about doing it from outside the box, when the box isn't trying to cooperate.
Making timing measurments precisely is hard to do in the best possible and most carefully engineered circumstances.
The cryptography mailing list
cryptography at metzdowd.com
