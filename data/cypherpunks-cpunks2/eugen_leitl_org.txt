
@_date: 2013-03-07 12:52:16
@_author: Eugen Leitl 
@_subject: General David Petraeus and 'dirty wars' veteran behind commando 
Revealed: Pentagon's link to Iraqi torture centres
Exclusive: General David Petraeus and 'dirty wars' veteran behind commando
units implicated in detainee abuse
Mona Mahmood, Maggie O'Kane, Chavala Madlena and Teresa Smith
The Guardian, Wednesday 6 March 2013 20.04 GMT
Link to video: James Steele: America's mystery man in Iraq
The Pentagon sent a US veteran of the "dirty wars" in Central America to
oversee sectarian police commando units in Iraq that set up secret detention
and torture centres to get information from insurgents. These units conducted
some of the worst acts of torture during the US occupation and accelerated
the country's descent into full-scale civil war.
Colonel James Steele was a 58-year-old retired special forces veteran when he
was nominated by Donald Rumsfeld to help organise the paramilitaries in an
attempt to quell a Sunni insurgency, an investigation by the Guardian and BBC
Arabic shows.
After the Pentagon lifted a ban on Shia militias joining the security forces,
the special police commando (SPC) membership was increasingly drawn from
violent Shia groups such as the Badr brigades.
A second special adviser, retired Colonel James H Coffman, worked alongside
Steele in detention centres that were set up with millions of dollars of US
Coffman reported directly to General David Petraeus, sent to Iraq in June
2004 to organise and train the new Iraqi security forces. Steele, who was in
Iraq from 2003 to 2005, and returned to the country in 2006, reported
directly to Rumsfeld.
The allegations, made by US and Iraqi witnesses in the Guardian/BBC
documentary, implicate US advisers for the first time in the human rights
abuses committed by the commandos. It is also the first time that Petraeus b
who last November was forced to resign as director of the CIA after a sex
scandal b has been linked through an adviser to this abuse.
Coffman reported to Petraeus and described himself in an interview with the
US military newspaper Stars and Stripes as Petraeus's "eyes and ears out on
the ground" in Iraq.
"They worked hand in hand," said General Muntadher al-Samari, who worked with
Steele and Coffman for a year while the commandos were being set up. "I never
saw them apart in the 40 or 50 times I saw them inside the detention centres.
They knew everything that was going on there ... the torture, the most
horrible kinds of torture."
Additional Guardian reporting has confirmed more details of how the
interrogation system worked. "Every single detention centre would have its
own interrogation committee," claimed Samari, talking for the first time in
detail about the US role in the interrogation units.
"Each one was made up of an intelligence officer and eight interrogators.
This committee will use all means of torture to make the detainee confess
like using electricity or hanging him upside down, pulling out their nails,
and beating them on sensitive parts."
There is no evidence that Steele or Coffman tortured prisoners themselves,
only that they were sometimes present in the detention centres where torture
took place and were involved in the processing of thousands of detainees.
The Guardian/BBC Arabic investigation was sparked by the release of
classified US military logs on WikiLeaks that detailed hundreds of incidents
where US soldiers came across tortured detainees in a network of detention
centres run by the police commandos across Iraq. Private Bradley Manning, 25,
is facing a prison sentence of up to 20 years after he pleaded guilty to
leaking the documents.
Samari claimed that torture was routine in the SPC-controlled detention
centres. "I remember a 14-year-old who was tied to one of the library's
columns. And he was tied up, with his legs above his head. Tied up. His whole
body was blue because of the impact of the cables with which he had been
Gilles Peress, a photographer, came across Steele when he was on assignment
for the New York Times, visiting one of the commando centres in the same
library, in Samarra. "We were in a room in the library interviewing Steele
and I'm looking around I see blood everywhere."
The reporter Peter Maass was also there, working on the story with Peress.
"And while this interview was going on with a Saudi jihadi with Jim Steele
also in the room, there were these terrible screams, somebody shouting:
'Allah, Allah, Allah!' But it wasn't kind of religious ecstasy or something
like that, these were screams of pain and terror."
The pattern in Iraq provides an eerie parallel to the well-documented human
rights abuses committed by US-advised and funded paramilitary squads in
Central America in the 1980s. Steele was head of a US team of special
military advisers that trained units of El Salvador's security forces in
counterinsurgency. Petraeus visited El Salvador in 1986 while Steele was
there and became a major advocate of counterinsurgency methods.
Steele has not responded to any questions from the Guardian and BBC Arabic
about his role in El Salvador or Iraq. He has in the past denied any
involvement in torture and said publicly he is "opposed to human rights
abuses." Coffman declined to comment.
An official speaking for Petraeus said: "During the course of his years in
Iraq, General Petraeus did learn of allegations of Iraqi forces torturing
detainees. In each incident, he shared information immediately with the US
military chain of command, the US ambassador in Baghdad ... and the relevant
Iraqi leaders."
The Guardian has learned that the SPC units' involvement with torture entered
the popular consciousness in Iraq when some of their victims were paraded in
front of a TV audience on a programme called "Terrorism In The Hands of
SPC detention centres bought video cameras, funded by the US military, which
they used to film detainees for the show. When the show began to outrage the
Iraqi public, Samari remembers being in the home of General Adnan Thabit b
head of the special commandos b when a call came from Petraeus's office
demanding that they stop showing tortured men on TV.
"General Petraeus's special translator, Sadi Othman, rang up to pass on a
message from General Petraeus telling us not to show the prisoners on TV
after they had been tortured," said Samari. "Then 20 minutes later we got a
call from the Iraqi ministry of interior telling us the same thing, that
General Petraeus didn't want the torture victims shown on TV."
Othman, who now lives in New York, confirmed that he made the phone call on
behalf of Petraeus to the head of the SPC to ask him to stop showing the
tortured prisoners. "But General Petraeus does not agree with torture," he
added. "To suggest he does support torture is horseshit."
Thabit is dismissive of the idea that the Americans he dealt with were
unaware of what the commandos were doing. "Until I left, the Americans knew
about everything I did; they knew what was going on in the interrogations and
they knew the detainees. Even some of the intelligence about the detainees
came to us from them b they are lying."
Just before Petraeus and Steele left Iraq in September 2005, Jabr al-Solagh
was appointed as the new minister of the interior. Under Solagh, who was
closely associated with the violent Badr Brigades militia, allegations of
torture and brutality by the commandos soared. It was also widely believed
that the units had evolved into death squads.
The Guardian has learned that high-ranking Iraqis who worked with the US
after the invasion warned Petraeus of the consequences of appointing Solagh
but their pleas were ignored.
The long-term impact of funding and arming this paramilitary force was to
unleash a deadly sectarian militia that terrorised the Sunni community and
helped germinate a civil war that claimed tens of thousands of lives. At the
height of that sectarian conflict, 3,000 bodies a month were strewn on the
streets of Iraq.
CV: James Steele
Jim Steele's first experience of war was in Vietnam, where from 1965 to 1975
US combat units were deployed against the communist North Vietnamese
government and Viet Cong. 58,000 Americans were killed, dealing a blow to the
nation's self-esteem and leading to a change in military thinking for
subsequent conflicts.
El Salvador
A 1979 military coup plunged the smallest country in Central America into
civil war and drew in US training and funding on the side of the rightwing
government. From 1984 to 1986 Steele b a "counterinsurgency specialist" b was
head of the US MilGroup of US special forces advisers to frontline battalions
of the Salvadorean military, which developed a fearsome international
reputation for its death-squad activities. Prof Terry Karl, an expert at
Stanford University on El Salvador's civil war, said that Steele's main aim
was to shift the fight from so-called total war, which then meant the
indiscriminate murder of thousands of civilians, to a more "discriminate"
approach. One of his tasks was to put more emphasis on "human intelligence"
and interrogation.
He became involved in the Iran-Contra affair, which saw the proceeds from
covert arms sales by senior US officials to Iran used to fund the Contras,
rightwing guerrillas fighting Daniel Ortega's leftwing Sandinista government
in Nicaragua. Steele ran operations at El Salvador's Ilopango airport, from
where Lieutenant Colonel Oliver North illegally ran weapons and supplies to
the Contras.
Soon after the 2003 US-led invasion of Iraq, now retired Colonel James Steele
was in Baghdad as one of the White House's most important agents, sending
back reports to Donald Rumsfeld and acting as the US defence secretary's
personal envoy to Iraq's Special Police Commandos, whose
intelligence-gathering activities he oversaw. Drawn mostly from violent Shia
militia, the commandos developed a reputation for torture and later for their
death-squad activities directed against the Sunni community.

@_date: 2013-03-18 11:09:47
@_author: Eugen Leitl 
@_subject: The Internet is a surveillance state 
The Internet is a surveillance state
By Bruce Schneier, Special to CNN
March 16, 2013 -- Updated 1804 GMT (0204 HKT)
STORY HIGHLIGHTS
    Bruce Schneier: Whether we like it or not, we're being tracked all the
time on the Internet
    Schneier: Our surveillance state is efficient beyond the wildest dreams
of George Orwell
    He says governments and corporations are working together to keep things
that way
    Schneier: Slap-on-the-wrist fines notwithstanding, no one is agitating
for better privacy laws
Editor's note: Bruce Schneier is a security technologist and author of "Liars
and Outliers: Enabling the Trust Society Needs to Survive."
(CNN) -- I'm going to start with three data points.
One: Some of the Chinese military hackers who were implicated in a broad set
of attacks against the U.S. government and corporations were identified
because they accessed Facebook from the same network infrastructure they used
to carry out their attacks.
Two: Hector Monsegur, one of the leaders of the LulzSac hacker movement, was
identified and arrested last year by the FBI. Although he practiced good
computer security and used an anonymous relay service to protect his
identity, he slipped up.
Bruce Schneier
And three: Paula Broadwell,who had an affair with CIA director David
Petraeus, similarly took extensive precautions to hide her identity. She
never logged in to her anonymous e-mail service from her home network.
Instead, she used hotel and other public networks when she e-mailed him. The
FBI correlated hotel registration data from several different hotels -- and
hers was the common name.
The Internet is a surveillance state. Whether we admit it to ourselves or
not, and whether we like it or not, we're being tracked all the time. Google
tracks us, both on its pages and on other pages it has access to. Facebook
does the same; it even tracks non-Facebook users. Apple tracks us on our
iPhones and iPads. One reporter used a tool called Collusion to track who was
tracking him; 105 companies tracked his Internet use during one 36-hour
Increasingly, what we do on the Internet is being combined with other data
about us. Unmasking Broadwell's identity involved correlating her Internet
activity with her hotel stays. Everything we do now involves computers, and
computers produce data as a natural by-product. Everything is now being saved
and correlated, and many big-data companies make money by building up
intimate profiles of our lives from a variety of sources.
News: Cyberthreats getting worse, House intelligence officials warn
Facebook, for example, correlates your online behavior with your purchasing
habits offline. And there's more. There's location data from your cell phone,
there's a record of your movements from closed-circuit TVs.
This is ubiquitous surveillance: All of us being watched, all the time, and
that data being stored forever. This is what a surveillance state looks like,
and it's efficient beyond the wildest dreams of George Orwell.
Sure, we can take measures to prevent this. We can limit what we search on
Google from our iPhones, and instead use computer web browsers that allow us
to delete cookies. We can use an alias on Facebook. We can turn our cell
phones off and spend cash. But increasingly, none of it matters.
There are simply too many ways to be tracked. The Internet, e-mail, cell
phones, web browsers, social networking sites, search engines: these have
become necessities, and it's fanciful to expect people to simply refuse to
use them just because they don't like the spying, especially since the full
extent of such spying is deliberately hidden from us and there are few
alternatives being marketed by companies that don't spy.
This isn't something the free market can fix. We consumers have no choice in
the matter. All the major companies that provide us with Internet services
are interested in tracking us. Visit a website and it will almost certainly
know who you are; there are lots of ways to be tracked without cookies.
Cellphone companies routinely undo the web's privacy protection. One
experiment at Carnegie Mellon took real-time videos of students on campus and
was able to identify one-third of them by comparing their photos with
publicly available tagged Facebook photos.
Maintaining privacy on the Internet is nearly impossible. If you forget even
once to enable your protections, or click on the wrong link, or type the
wrong thing, and you've permanently attached your name to whatever anonymous
service you're using. Monsegur slipped up once, and the FBI got him. If the
director of the CIA can't maintain his privacy on the Internet, we've got no
In today's world, governments and corporations are working together to keep
things that way. Governments are happy to use the data corporations collect

@_date: 2013-03-20 14:07:00
@_author: Eugen Leitl 
@_subject: Researcher sets up illegal 420,000 node botnet for IPv4 
Researcher sets up illegal 420,000 node botnet for IPv4 internet map
Potentially risks thousands of years in jail
By Iain Thomson in San Francisco b" Get more from this author
Posted in Security, 19th March 2013 23:14 GMT
An anonymous researcher has taken an unorthodox approach to achieve the dream
of mapping out the entire remaining IPv4 internet, and has broken enough laws
around the world to make them liable for many thousands of years behind bars
in doing so, if current sentencing policy prevails.
Getting the sheer numbers of IPv4 addresses involved would take a huge amount
of scanners to make billions of pings. While noodling around with an Nmap
scripting engine the researcher noticed a lot of virtually unsecured IPv4
devices b only requiring the admin/admin, root/root login, or either admin or
root with the password field blank. What if these could be used as a
temporary botnet to perform?
"I did not want to ask myself for the rest of my life how much fun it could
have been or if the infrastructure I imagined in my head would have worked as
expected," the report "Internet Census 2012" states.
"I saw the chance to really work on an Internet scale, command hundred
thousands of devices with a click of my mouse, portscan and map the whole
Internet in a way nobody had done before, basically have fun with computers
and the Internet in a way very few people ever will."
The report states a 46 and 60 kb binary was written in C with two parts; a
telnet scanner to try the login connection and propagate and then control
code to assign scan ranges and feed the results back. A reboot of the
infected system would wipe the binary completely and the code didn't scan
traffic running though the device or any intranet-connected systems.
The code was set to run as lowest possible priority in the infected device to
avoid interference and included a watchdog to make sure normal operations of
the host weren't overloaded. It also carried a readme file with a description
of the project and an email address for the owner, or law enforcement, to get
in touch if it was discovered.
After releasing the code overnight the report's writer found 420,000 suitable
botnet endpoints, accounting for around a quarter of the total number of
suitable IPv4 systems with enough CPU and RAM and which ran Linux. The botnet
was able to spread quickly and efficiently just using the four login
combinations and was soon reporting back in healthy numbers.
The Carna IPv4 botnet
"While everybody is talking about high-class exploits and cyberwar, four
simple stupid default telnet passwords can give you access to hundreds of
thousands of consumer as well as tens of thousands of industrial devices all
over the world," the unnamed researcher stated in the report.
Mark Bower, veep of product management at Voltage Security, told El Reg:
"This is a great study which underlines the fact that once again exploitable
weak links are abundant and ripe for compromise, even on embedded or
industrial systems. While the researchers merely reported on security gaps,
any attacker could quickly access these systems - maybe leading to downstream
compromise of something much more valuable."
The home spy
The vast majority of infected systems were consumer routers or set-top boxes
but they also found Cisco and Juniper hardware, x86 equipment with crypto
accelerator cards, industrial control systems, and physical door security
"A lot of devices and services we have seen during our research should never
be connected to the public Internet at all. As a rule of thumb, if you
believe that 'nobody would connect that to the Internet, really nobody',
there are at least 1000 people who did," the report states.
"Whenever you think 'that shouldn't be on the Internet but will probably be
found a few times' it's there a few hundred thousand times. Like half a
million printers, or a Million Webcams, or devices that have root as a root
The resultant botnet was used to build the botnet the report dubs Carna,
named after the Roman goddess of physical health or door hinges, depending on
which historical source you believe. But it soon found it was getting
competition from a malicious botnet dubbed Aidra and the researcher adapted
the binary to block this competitor where possible, but estimates it still
has around 30,000 endpoints.
In all the project took nearly six months and the full scan was concluded by
October last year. The report estimates that the remaining number of active
IPv4 addresses is around 1.3 billion, out a total of around 4.3 billion. The
complete scan data, all 9TB or it, is available for download, but not the
botnet which created it.
"The actual research itself is noteworthy in that it is the most
comprehensive Internet-wide scan. I'd like to see more projects of this kind,
conducted legally, and sharing information about the real state of play on
the internet," said Mark Schloesser, security researcher at Rapid7 in an
emailed statement.
"While the Internet Census 2012 provides interesting data, the way it was
collated is highly illegal in most countries. Using insecure configurations
and default passwords to gain access to remote devices and run code on them
is unethical, and taking precautions to not interfere with any normal
operation of the devices being used doesn't make it OK,"
He has a point. Monday's sentence of three years and five months in prison
for Andrew Auernheimer, a member of the grey-hat hacking collective Goatse
Security, after he used a server vulnerability to expose iPad user accounts
is causing great concern to some in the security research industry.
The two situations arenbt exactly the same, but a strict interpretation of
the law in both the US and elsewhere would make the Carna botnet used highly
illegal and each node could be worth its own charge to an over-zealous
prosecutor. No wonder the researcher in question wishes to remain anonymous.

@_date: 2013-03-25 21:48:15
@_author: Eugen Leitl 
@_subject: Material Support to Al-Qaeda 
Their equivalent would be a 20 kT nuclear device in a Manhattan
penthouse. If Theodore B. Taylor would be alive today, I think he
would agree that today a thermonuclear device is no longer out
of reach for small groups.

@_date: 2013-03-25 22:24:15
@_author: Eugen Leitl 
@_subject: Material Support to Al-Qaeda 
If a drone holocausts your wedding party, surely this is terrorism?
And surely there's only one way to avenge it, via the family honor
killing code?
Just invert the viewpoints, and it all becomes quite clear.
Intent and ability to execute as well as funds are independently
distributed traits, orelse it would have happened already.

@_date: 2013-03-26 13:29:45
@_author: Eugen Leitl 
@_subject: Bitmessage is a P2P communications protocol used to send 
Bitmessage is a P2P communications protocol used to send encrypted messages
to another person or to many subscribers. It is decentralized and trustless,
meaning that you need-not inherently trust any entities like root certificate
authorities. It uses strong authentication which means that the sender of a
message cannot be spoofed, and it aims to hide "non-content" data, like the
sender and receiver of messages, from passive eavesdroppers like those
running warrantless wiretapping programs. If Bitmessage is completely new to
you, you may wish to start by reading the whitepaper.
An open source client is available for free under the very liberal MIT
license. For screenshots and a description of the client, see this
CryptoJunky article: "Setting Up And Using Bitmessage".
 Download for Windows
If you are looking for someone to message, visit the forum or send me a
greeting. Here is my address: BM-BcJFNZDyzQKXCVJZtBJGqoon2f7GKo6s
Source code
You may view the Python source code on Github. Bitmessage requires PyQt and
OpenSSL. Step-by-step instructions on how to run the source code on Windows
or Linux is available here.
Bitmessage should run on any OS though it is only lightly tested on OSX. The
start-on-boot and minimize-to-tray features are only implemented for Windows
thus far.
Security audit needed
Bitmessage is in need of an independent audit to verify its security. If you
are a researcher capable of reviewing the source code, please email the lead
developer or send a bitmessage to the address above. You will be helping to
create a great privacy option for people everywhere!
Visit or subscribe to the Bitmessage subreddit.
A community-based forum for questions, feedback, and discussion is also
available at Bitmessage.org/forum.

@_date: 2013-03-27 13:57:20
@_author: Eugen Leitl 
@_subject: Unique in the Crowd: The privacy bounds of human mobility 
(full text available on site)
Unique in the Crowd: The privacy bounds of human mobility
Yves-Alexandre de Montjoye,	 Cisar A. Hidalgo,	 Michel Verleysen
& Vincent D. Blondel
Scientific Reports 3, Article number: 1376 doi:10.1038/srep01376
Received 01 October 2012 Accepted 04 February 2013 Published 25 March 2013
We study fifteen months of human mobility data for one and a half million
individuals and find that human mobility traces are highly unique. In fact,
in a dataset where the location of an individual is specified hourly, and
with a spatial resolution equal to that given by the carrier's antennas, four
spatio-temporal points are enough to uniquely identify 95% of the
individuals. We coarsen the data spatially and temporally to find a formula
for the uniqueness of human mobility traces given their resolution and the
available outside information. This formula shows that the uniqueness of
mobility traces decays approximately as the 1/10 power of their resolution.
Hence, even coarse datasets provide little anonymity. These findings
represent fundamental constraints to an individual's privacy and have
important implications for the design of frameworks and institutions
dedicated to protect the privacy of individuals.
Subject terms:
Applied mathematicsComputational scienceStatisticsApplied physics

@_date: 2013-03-27 14:00:00
@_author: Eugen Leitl 
@_subject: FBI Pursuing Real-Time Gmail =?utf-8?Q?Spy?=  
FBI Pursuing Real-Time Gmail Spying Powers as bTop Priorityb for 2013
By Ryan Gallagher | Posted Tuesday, March 26, 2013, at 4:58 PM
For now, law enforcement has trouble monitoring Gmail communications in real
Image courtesy Google
Despite the pervasiveness of law enforcement surveillance of digital
communication, the FBI still has a difficult time monitoring Gmail, Google
Voice, and Dropbox in real time. But that may change soon, because the bureau
says it has made gaining more powers to wiretap all forms of Internet
conversation and cloud storage a btop priorityb this year.
Last week, during a talk for the American Bar Association in Washington,
D.C., FBI general counsel Andrew Weissmann discussed some of the pressing
surveillance and national security issues facing the bureau. He gave a few
updates on the FBIbs efforts to address what it calls the bgoing darkb
problembhow the rise in popularity of email and social networks has stifled
its ability to monitor communications as they are being transmitted. Itbs no
secret that under the Electronic Communications Privacy Act, the feds can
easily obtain archive copies of emails. When it comes to spying on emails or
Gchat in real time, however, itbs a different story.
Thatbs because a 1994 surveillance law called the Communications Assistance
for Law Enforcement Act only allows the government to force Internet
providers and phone companies to install surveillance equipment within their
networks. But it doesnbt cover email, cloud services, or online chat
providers like Skype. Weissmann said that the FBI wants the power to mandate
real-time surveillance of everything from Dropbox and online games (bthe chat
feature in Scrabbleb) to Gmail and Google Voice. bThose communications are
being used for criminal conversations,b he said.
While it is true that CALEA can only be used to compel Internet and phone
providers to build in surveillance capabilities into their networks, the feds
do have some existing powers to request surveillance of other services.
Authorities can use a bTitle IIIb order under the bWiretap Actb to ask email
and online chat providers furnish the government with btechnical assistance
necessary to accomplish the interception.b However, the FBI claims this is
not sufficient because mandating that providers help with btechnical
assistanceb is not the same thing as forcing them to beffectuateb a wiretap.
In 2011, then-FBI general counsel Valerie CapronibWeissmannbs
predecessorbstated that Title III orders did not provide the bureau with an
"effective lever" to "encourage providers" to set up live surveillance
quickly and efficiently. In other words, the FBI believes it doesnbt have
enough power under current legislation to strong-arm companies into providing
real-time wiretaps of communications.
Because Gmail is sent between a userbs computer and Googlebs servers using
SSL encryption, for instance, the FBI canbt intercept it as it is flowing
across networks and relies on the company to provide it with access. Google
spokesman Chris Gaither hinted that it is already possible for the company to
set up live surveillance under some circumstances. bCALEA doesn't apply to
Gmail but an order under the Wiretap Act may,b Gaither told me in an email.
bAt some point we may expand our transparency report to cover this topic in
more depth, but until then I'm not able to provide additional information.b
Either way, the FBI is not happy with the current arrangement and is on a
crusade for more surveillance authority. According to Weissmann, the bureau
is working with bmembers of intelligence communityb to craft a proposal for
new Internet spy powers as ba top priority this year.b Citing security
concerns, he declined to reveal any specifics. bIt's a very hard thing to
talk about publicly,b he said, though acknowledged that bit's something that
there should be a public debate about.b

@_date: 2013-03-27 14:36:11
@_author: Eugen Leitl 
@_subject: Neuroimaging 'biomarker' linked to rearrest after 
Brain scans predict which criminals are more likely to reoffend
Neuroimaging 'biomarker' linked to rearrest after incarceration.
Regina Nuzzo
25 March 2013
Activity in a particular region of the cortex could tell whether a convict is
likely to get in trouble again.  DOUG MENUEZ/GETTY
In a twist that evokes the dystopian science fiction of writer Philip K.
Dick, neuroscientists have found a way to predict whether convicted felons
are likely to commit crimes again from looking at their brain scans. Convicts
showing low activity in a brain region associated with decision-making and
action are more likely to be arrested again, and sooner.
Kent Kiehl, a neuroscientist at the non-profit Mind Research Network in
Albuquerque, New Mexico, and his collaborators studied a group of 96 male
prisoners just before their release. The researchers used functional magnetic
resonance imaging (fMRI) to scan the prisonersb brains during computer tasks
in which subjects had to make quick decisions and inhibit impulsive
The scans focused on activity in a section of the anterior cingulate cortex
(ACC), a small region in the front of the brain involved in motor control and
executive functioning. The researchers then followed the ex-convicts for four
years to see how they fared.
Among the subjects of the study, men who had lower ACC activity during the
quick-decision tasks were more likely to be arrested again after getting out
of prison, even after the researchers accounted for other risk factors such
as age, drug and alcohol abuse and psychopathic traits. Men who were in the
lower half of the ACC activity ranking had a 2.6-fold higher rate of rearrest
for all crimes and a 4.3-fold higher rate for nonviolent crimes. The results
are published today in the Proceedings of the National Academy of Sciences1.
There is growing interest in using neuroimaging to predict specific
behaviour, says Tor Wager, a neuroscientist at the University of Colorado in
Boulder. He says that studies such as this one, which tie brain imaging to
concrete clinical outcomes, bprovide a new and so far very promising wayb to
find patterns of brain activity that have broader implications for society.
But the authors themselves stress that much more work is needed to prove that
the technique is reliable and consistent, and that it is likely to flag only
the truly high-risk felons and leave the low-risk ones alone. bThis isn't
ready for prime time,b says Kiehl.
Wager adds that the part of the ACC examined in this study bis one of the
most frequently activated areas in the human brain across all kinds of tasks
and psychological statesb. Low ACC activity could have a variety of causes b
impulsivity, caffeine use, vascular health, low motivation or better neural
efficiency b and not all of these are necessarily related to criminal
Crime prediction was the subject of Dick's 1956 short story bThe Minority
Reportb (adapted for the silver screen by Steven Spielberg in 2002), which
highlighted the thorny ethics of arresting people for crimes they had yet to
Brain scans are of course a far cry from the clairvoyants featured in that
science-fiction story. But even if the science turns out to be reliable, the
legal and social implications remain to be explored, the authors warn.
Perhaps the most appropriate use for neurobiological markers would be for
helping to make low-stakes decisions, such as which rehabilitation treatment
to assign a prisoner, rather than high-stakes ones such as sentencing or
releasing on parole.
bA treatment of [these clinical neuroimaging studies] that is either too
glibly enthusiastic or over-critical,b Wager says, bwill be damaging for this
emerging science in the long run.b
Nature doi:10.1038/nature.2013.12672
Aharoni, E. et al. Proc. Natl Acad. Sci. USA
 (2013).
Yarkoni, T., Poldrack, R. A., Nichols, T. E., Van Essen, D. C. & Wager, T. D.
Nature Methods 8, 665b670 (2011).

@_date: 2013-03-27 15:26:46
@_author: Eugen Leitl 
@_subject: Wikileaks Was Just a Preview: We're Headed for an Even Bigger  
Wikileaks Was Just a Preview: We're Headed for an Even Bigger Showdown Over
POSTED: March 22, 10:53 AM ET
U.S. Army Private Bradley Manning
Alex Wong/Getty Images
I went yesterday to a screening of We Steal Secrets, Oscar-winning director
Alex Gibney's brilliant new documentary about Wikileaks. The movie is
beautiful and profound, an incredible story that's about many things all at
once, including the incredible Shakespearean narrative that is the life of
Julian Assange, a free-information radical who has become an uncompromising
guarder of secrets.
I'll do a full review in a few months, when We Steal Secrets comes out, but I
bring it up now because the whole issue of secrets and how we keep them is
increasingly in the news, to the point where I think we're headed for a major
confrontation between the government and the public over the issue, one
bigger in scale than even the Wikileaks episode.
We've seen the battle lines forming for years now. It's increasingly clear
that governments, major corporations, banks, universities and other such
bodies view the defense of their secrets as a desperate matter of
institutional survival, so much so that the state has gone to extraordinary
lengths to punish and/or threaten to punish anyone who so much as tiptoes
across the informational line.
This is true not only in the case of Wikileaks b and especially the real
subject of Gibney's film, Private Bradley Manning, who in an incredible act
of institutional vengeance is being charged with aiding the enemy (among
other crimes) and could, theoretically, receive a death sentence.
Did the Mainstream Media Fail Bradley Manning?
There's also the horrific case of Aaron Swartz, a genius who helped create
the technology behind Reddit at the age of 14, who earlier this year hanged
himself after the government threatened him with 35 years in jail for
downloading a bunch of academic documents from an MIT server. Then there's
the case of Sergey Aleynikov, the Russian computer programmer who allegedly
stole the High-Frequency Trading program belonging to Goldman, Sachs
(Aleynikov worked at Goldman), a program which prosecutors in open court
admitted could, "in the wrong hands," be used to "manipulate markets."
Aleynikov spent a year in jail awaiting trial, was convicted, had his
sentence overturned, was freed, and has since been re-arrested by a
government seemingly determined to make an example out of him.
The Brilliant Life and Tragic Death of Aaron Swartz
And most recently, there's the Matthew Keys case, in which a Reuters social
media editor was charged by the government with conspiring with the hacker
group Anonymous to alter a Los Angeles Times headline in December 2010. The
change in the headline? It ended up reading, "Pressure Builds in House to
Elect CHIPPY 1337," Chippy being the name of another hacker group accused of
defacing a video game publisher's website.
Keys is charged with crimes that carry up to 25 years in prison, although the
likelihood is that he'd face far less than that if convicted. Still, it seems
like an insane amount of pressure to apply, given the other types of crimes
(of, say, the HSBC variety) where stiff sentences haven't even been
threatened, much less imposed.
A common thread runs through all of these cases. On the one hand, the
motivations for these information-stealers seem extremely diverse: You have
people who appear to be primarily motivated by traditional whistleblower
concerns (Manning, who never sought money and was obviously initially moved
by the moral horror aroused by the material he was seeing, falls into that
category for me), you have the merely mischievous (the Keys case seems to
fall in this area), there are those who either claim to be or actually are
free-information ideologues (Assange and Swartz seem more in this realm), and
then there are other cases where the motive might have been money (Aleynikov,
who was allegedly leaving Goldman to join a rival trading startup, might be
among those).
But in all of these cases, the government pursued maximum punishments and
generally took zero-tolerance approaches to plea negotiations. These
prosecutions reflected an obvious institutional terror of letting the public
see the sausage-factory locked behind the closed doors not only of the state,
but of banks and universities and other such institutional pillars of
society. As Gibney pointed out in his movie, this is a Wizard of Oz moment,
where we are being warned not to look behind the curtain.
What will we find out? We already know that our armies mass-murder women and
children in places like Iraq and Afghanistan, that our soldiers joke about
smoldering bodies from the safety of gunships, that some of our closest
diplomatic allies starve and repress their own citizens, and we may even have
gotten a glimpse or two of a banking system that uses computerized insider
trading programs to steal from everyone who has an IRA or a mutual fund or
any stock at all by manipulating markets like the NYSE.
These fervent, desperate prosecutions suggest that there's more awfulness
under there, things that are worse, and there is a determination to not let
us see what those things are. Most recently, we've seen that determination in
the furor over Barack Obama's drone assassination program and the so-called
"kill list" that is associated with it.
Weeks ago, Kentucky Senator Rand Paul b whom I've previously railed against
as one of the biggest self-aggrandizing jackasses in politics b pulled a
widely-derided but, I think, absolutely righteous Frank Capra act on the
Senate floor, executing a one-man filibuster of Obama's CIA nominee, John
Paul had been mortified when he received a letter from Eric Holder refusing
to rule out drone strikes on American soil in "extraordinary" circumstances
like a 9/11 or a Pearl Harbor. Paul refused to yield until he extracted a
guarantee that no American could be assassinated by a drone on American soil
without first being charged with a crime.
He got his guarantee, but the way the thing is written doesn't fill one with
anything like confidence. Eric Holder's letter to Paul reads like the legal
disclaimer on a pack of unfiltered cigarettes:
Dear Senator Paul,
It has come to my attention that you have now asked an additional question:
"Does the president have the additional authority to use a weaponized drone
to kill an American not engaged in combat on American soil?" The answer is
Eric Holder
You could drive a convoy of tanker trucks through the loopholes in that
letter. Not to worry, though, this past week, word has come out via Congress
b the White House won't tell us anything b that no Americans are on its
infamous kill list. The National Journal's report on this story offered a
similarly comical sort of non-reassurance:
The White House has wrapped its kill list in secrecy and already the United
States has killed four Americans in drone strikes. Only one of them, senior
al-Qaida operative Anwar al-Awlaki, was the intended target, according to
U.S. officials. The others b including Awlaki's teenage son b were collateral
damage, killed because they were too near a person being targeted.
But no more Americans are in line for such killings b at least not yet.
"There is no list where Americans are on the list," House Intelligence
Chairman Mike Rogers told National Journal. Still, he suggested, that could
"There is no list where Americans are on the list" b even the language used
here sounds like a cheap Orwell knockoff (although, to be fair, so does V for
Vendetta, which has unfortunately provided the model for the modern protest
aesthetic). It's not an accident that so much of this story is starting to
sound like farce. The idea that we have to beg and plead and pull Capra-esque
stunts in the Senate just to find out whether or not our government has
"asserted the legal authority" (this preposterous phrase is beginning to leak
into news coverage with alarming regularity) to kill U.S. citizens on U.S.
soil without trial would be laughable, were it not for the obvious fact that
such lines are in danger of really being crossed, if they haven't been
crossed already.
This morning, an Emory University law professor named Mary Dudziak wrote an
op-ed in the Times in which she pointed out several disturbing aspects to the
drone-attack policy. It's bad enough, she writes, that the Obama
administration is considering moving the program from the CIA to the Defense
Department. (Which, Dudziak notes, "would do nothing to confer legitimacy to
the drone strikes. The legitimacy problem comes from the secrecy itself b not
which entity secretly does the killing.") It's even worse that the
administration is citing Nixon's infamous bombing of Cambodia as part of its
legal precedent.
But beyond that, Obama's lawyers used bad information in their white paper:
On Page 4 of the unclassified 16-page "white paper," Justice Department
lawyers tried to refute the argument that international law does not support
extending armed conflict outside a battlefield. They cited as historical
authority a speech given May 28, 1970, by John R. Stevenson, then the top
lawyer for the State Department, following the United States' invasion of
Since 1965, "the territory of Cambodia has been used by North Vietnam as a
base of military operations," he told the New York City Bar Association. "It
long ago reached a level that would have justified us in taking appropriate
measures of self-defense on the territory of Cambodia. However, except for
scattered instances of returning fire across the border, we refrained until
April from taking such action in Cambodia."
But, Dudziak notes, there is a catch:
In fact, Nixon had begun his secret bombing of Cambodia more than a year
earlier. (It is not clear whether Mr. Stevenson knew this.) So the Obama
administration's lawyers have cited a statement that was patently false.
Now, this "white paper" of Obama's is already of dubious legality at best.
The idea that the President can simply write a paper expanding presidential
power into extralegal assassination without asking the explicit permission
of, well, somebody, anyway, is absurd from the start. Now you add to that the
complication of the paper being based in part on some half-assed,
hastily-cobbled-together, factually lacking precedent, and the Obama
drone-attack rationale becomes like all rationales of blunt-force, repressive
power ever written b plainly ridiculous, the stuff of bad comedy, like the
Russian military superpower invading tiny South Ossetia cloaked in hysterical
claims of self-defense.
Why Rand Paul's Filibuster Matters
The Wikileaks episode was just an early preview of the inevitable
confrontation between the citizens of the industrialized world and the giant,
increasingly secretive bureaucracies that support them. As some of Gibney's
interview subjects point out in his movie, the experts in this field, the
people who worked on information security in the Pentagon and the CIA, have
known for a long time that the day would come when all of our digitized
secrets would spill out somewhere.  But the secret-keepers got lucky with Wikileaks. They successfully turned the
story into one about Julian Assange and his personal failings, and headed off
the confrontation with the major news organizations that were, for a time,
his allies.
But that was just a temporary reprieve. The secrets are out there and
everyone from hackers to journalists to U.S. senators are digging in search
of them. Sooner or later, there's going to be a pitched battle, one where the
state won't be able to peel off one lone Julian Assange or Bradley Manning
and batter him into nothingness. Next time around, it'll be a Pentagon
Papers-style constitutional crisis, where the public's legitimate right to
know will be pitted head-to-head with presidents, generals and CEOs.
My suspicion is that this story will turn out to be less of a simplistic
narrative about Orwellian repression than a mortifying journey of
self-discovery. There are all sorts of things we both know and don't know
about the processes that keep our society running. We know children in Asia
are being beaten to keep our sneakers and furniture cheap, we know our access
to oil and other raw materials is being secured only by the cooperation of
corrupt and vicious dictators, and we've also known for a while now that the
anti-terror program they say we need to keep our airports and reservoirs safe
involves mass campaigns of extralegal detention and assassination.
We haven't had to openly ratify any of these policies because the
secret-keepers have done us the favor of making these awful moral choices for
But the stink is rising to the surface. It's all coming out. And when it
isn't Julian Assange the next time but The New York Times, Der Spiegel and
The Guardian standing in the line of fire, the state will probably lose, just
as it lost in the Pentagon Papers case, because those organizations will be
careful to only publish materials clearly in the public interest b there's no
conceivable legal justification for keeping us from knowing the policies of
our own country (although stranger things have happened).
When that happens, we'll be left standing face-to-face with the reality of
how our state functions. Do we want to do that? We still haven't taken a very
close look at even the Bradley Manning material, and my guess is because we
just don't want to. There were thousands of outrages in those files, any one
of which would have a caused a My-Lai-style uproar decades ago.
Did you hear the one about how American troops murdered four women and five
children in Iraq in 2006, including a woman over 70 and an infant under five
months old, with all the kids under five? All of them were handcuffed and
shot in the head. We later called in an airstrike to cover it up, apparently.
But it barely registered a blip on the American consciousness.
What if it we're forced to look at all of this for real next time, and what
if it turns out we can't accept it? What if murder and corruption is what's
holding it all together? I personally don't believe that's true b I believe
it all needs to come out and we need to rethink everything together, and we
can find a less totally evil way of living b but this is going to be the
implicit argument from the secret-keeping side when this inevitable
confrontation comes. They will say to us, in essence, "It's the only way. And
you don't want to know." And a lot of us won't.
It's fascinating, profound stuff. We don't want to know, but increasingly it
seems we can't not know, either. Sooner or later, something is going to have
to give.
Read more:
 Follow us:  on Twitter | RollingStone on Facebook

@_date: 2013-03-30 10:15:46
@_author: Eugen Leitl 
@_subject: [info] [liberationtech] What's wrong with the kids these 
It really seems that mutt in a screen jail with a few extensions
is a kind of design optimum.

@_date: 2013-05-03 13:52:23
@_author: Eugen Leitl 
@_subject: Meet Drone Shield, an ambitious idea for a $70 drone detection 
Meet Drone Shield, an ambitious idea for a $70 drone detection system
Aerospace engineer wants to scan for audio signatures of flying robots.
by Cyrus Farivar - May 2 2013, 1:30am WEDT
Drone Shield
On Tuesday, an ambitious aerospace engineer from Washington, DC began seeking
donations on Indiegogo to create an bopen-source drone detection system.b
The Drone Shield would combine a Raspberry Pi, a signal processor, a
microphone, and analysis software to scan for specific audio signatures and
compare them against what known drones sound like (because obviously a
Predator drone is going to sound very different from a small quadcopter.)
Once a match is found, the Drone Shield then sends an e-mail or SMS to its
owner. As of this writing, the campaign is only closing in on one-tenth of
its goal with $301 out $3,500 raised.
John Franklin, the projectbs organizer, believes it would cost around $60 to
$70 to make one, but hebs hoping to raise funds from other privacy-minded
citizens like himself. He notes the idea here is to counter the rising use of
drones not only in foreign theaters of war, but also in domestic skies.
"I'm a problem solver and I'm trying to gauge if this is a problem that
people are interested in solving,b he told Ars. bThe idea here is that it
becomes an open-source thing and people could contribute their own
signatures.b
Franklin estimated it probably would take babout $100 and two monthsb to
figure out if the idea would work. There are other anti-drone tactics and
devices out there, but none quite as cheap as this onebassuming it functions
as advertised. Not all experts are convinced.
"It would be theoretically feasible," said Chris Kyriakakis, a professor of
electrical engineering at the University of Southern California with
expertise in acoustic signal processing. "A lot of problems to solve,
however, to make that happen. [It's] not clear if a single mic would
sufficebmost likely [you] would need a mic array. Noise mitigation would be
another huge problem. Yes, there are dozens of feature extraction approaches
that would work theoretically, but none that I have seen be effective in the
presence of additive or convolutive noise."
Franklin acknowledged that the device wonbt be 100 percent perfect. He also
told Ars that the system would be based on existing publicly available
documents, such as this 1997-era research paper from the Army Research
Laboratory entitled: "Acoustic Feature Extraction for a Neural Network
Classifier" (PDF). But again, his goal is an open-sourced device that an
audience can build upon and improve. If the interest is there, hopefully the
implementation will be too.
bThis project is yet another indicator of the fact that there is very strong
and widespread sentiment on the ground about dronesband itbs one of
tremendous skepticism,b wrote Linda Lye, an attorney with the American Civil
Liberties Union of Northern California, in an e-mail to Ars.

@_date: 2013-11-01 19:19:22
@_author: Eugen Leitl 
@_subject: INDECT: Intelligent Information System Supporting Observation, 
Liberation Technologies  Project: INDECT
Title: Intelligent Information System Supporting Observation, Searching and Detection for Security of Citizens in Urban Environment	
Call: FP7-SEC-2007-1	
Grant agreement number: 218086	
Start date: 01/01/2009	
End date: 31/12/2013	
Special clause 39: no	
Scientific area: Security	
Programme: SP1-Cooperation	
Detailed project information (CORDIS)
Use of the bio-inspired algorithms to find global minimum in force directed layout algorithms
DoS attacks targeting SIP server and improvements of robustness
Impact of network Jitter on effective equipment impairment factor
Video files recording and playback with VoiceXML
Objective assessment of IP video calls with Asterisk
Delay model of RTP flows in accordance with M/D/1 and M/D/2 Kendall's notation
Monitoring the quality of speech in the communication system BESIP
Remote control of asterisk via web services
E-model modification for case of cascade codecs arrangement
Methodology of the direct measurement of the switching latency
Performance analysis of virtualized real-time applications
SIP end to end performance metrics
Improvement of network efficiency on the grounds of change communication protocol
Software designed 64-QAM demodulator of OFDM signal implemented into FPGA elements
Fundamental frequency extraction method using central clipping and its importance for the classification of emotional state
The interactions of SOAP-based web services for recording and replaying video files
Malicious traffic monitoring and its evaluation in VoIP infrastructure
Automated speech quality monitoring tool based on perceptual evaluation
Approach to stress tests in SIP environment based on marginal analysis
Applied multiprotocol routing in IP telephony
Advanced concept of voice communication server on embedded platform
SIP registration stress test
Delay variation model for RTP flows in network with priority queueing
E-model improvement for speech quality evaluation including codecs tandeming
Jitter buffer loss estimate for effective equipment impairment factor
Overview of the security components of INDECT project
VoIP based system for the message distribution
Security infrastructures: towards the INDECT system security
Mathematical model of subscriber extension line
Performance evaluation of INACT - INDECT advanced image cataloguing tool
Influence of atmospheric parameters on speech quality in GSM/UMTS
Danger alert communication system
Development of a speech quality monitoring tool based on ITU-T P.862
IP telephony based danger alert communication system and its implementation
Multimedia services in Asterisk based on VoiceXML
Impact of emotions on fundamental speech signal frequency
Speech quality monitoring in czech national research network
Delay variation model with RTP flows behavior in accordance with M/D/1 Kendall's notation
SIP threats detection system
Interactive VoiceXML module into SIP-based warning distribution system
Web-based IP telephony penetration system evaluating level of protection from attacks and threats
Non-intrusive speech quality assessment in simplified e-model
Replication-Based Information Sharing in Multi-Agent System for Monitoring the Internet
Feature selection for acoustic events detection
M-JPEG Robust Video Watermarking Based on DPCM and Transform Coding
Traffic Danger Ontology for Citizen Safety Web System
How to Build an Objective Model for Packet Loss Effect on High Definition Content Based on SSIM and Subjective Experiments
Web-Based Knowledge Acquisition and Management System Supporting Collaboration for Improving Safety in Urban Environment
A New Method for Automatic Generation of Animated Motion
A no reference metric for the quality assessment of videos affected by exposure distortion
On Occlusion-Handling for People Detection Fusion in Multi-camera Networks
Agent-based Modelling of Social Organisations
Content protection in grayscale and color images based on robust digital watermarking
Anchor-Free Localization Algorithm with Low-Complexity Method for Node Distance Estimation Enhancement Using ToA
Analysis of privacy vulnerabilities in single sign-on mechanisms for multimedia websites
Scenario-Driven System for Open Source Intelligence
Correction Trees as an Alternative to Turbo Codes and Low Density Parity Check Codes
Prototypes of a Web System for Citizen Provided Information, Automatic Knowledge Extraction, Knowledge Management and GIS Integration
Recent advances in multimedia networking
INDECT Security Architecture
LDA for Face Profile Detection
Audio-Visual Surveillance System for Application in Bank Operating Room
Software Implementation of New Symmetric Block Cipher
Malicious traffic monitoring and its evaluation in VoIP infrastructure
Approach to stress tests in SIP environment based on marginal analysis
Graph-Based Relation Mining
Detection and Localization of Selected Acoustic Events in 3D Acoustic Field for Smart Surveillance Applications
Distributed Framework for Visual Event Detection in Parking Lot Area
Object Detection and Measurement Using Stereo Images
Semantic Structure Matching Recommendation Algorithm
Acoustic Events Detection Using MFCC and MPEG-7 Descriptors
Quality Assessment for a Licence Plate Recognition Task Based on a Video Streamed in Limited Networking Conditions
Automatic quality control of digital image content reconstruction schemes
Broadcast news audio classification using SVM binary trees
Analysis of Particular Iris Recognition Stages
Determining image quality requirements for recognition tasks in generalized public safety video applications: Definitions, testing, standardization, and current trends
INSTREET - Application for Urban Photograph Localization
Quantum cryptography - The analysis of security requirements
Implementation of the New Integration Model of Security and QoS for MANET to the OPNET
A new approach to high-capacity annotation watermarking based on digital fountain codes
A Novel JPEG Steganography Method Based on Modulus Function with Histogram Analysis
Hierarchical Multi-Agent System for Heterogeneous Data Integration
INCR  INDECT Multimedia Crawler
Performance of Basic Spectral Descriptors and MRMR Algorithm to the Detection of Acoustic Events
Towards Hardware Implementation of INDECT Block Cipher
Multi-camera Vehicle Tracking Using Local Image Features and Neural Networks
Video Watermarking Based on DPCM and Transformcoding Using Permutation Spectrum and QIM
Camera Angle Invariant Shape Recognition in Surveillance Systems
A Statistical Blind Image Steganalysis Based on Image Multi-classification
Integrating Applications Developed for Heterogeneous Platforms: Building an Environment for Criminal Analysts
A new symmetric block cipher based on key-dependent S-boxes
INACT  INDECT Advanced Image Cataloguing Tool
QoE as a Function of Frame Rate and Resolution Changes
Monitoring the quality of speech in the communication system BESIP
Brightness Correction and Stereovision Impression Based Methods of Perceived Quality Improvement of CCTV Video Sequences
Performance Measurements of Real Time Video Transmission from Car Patrol
Multiple Sound Sources Localization in Real Time Using Acoustic Vector Sensor
Vehicle Classification Based on Soft Computing Algorithms
Quality Assessment in Video Surveillance
Performance Evaluation of the Parallel Codebook Algorithm for Background Subtraction in Video Stream
A High-Capacity Annotation Watermarking Scheme
Fast Face Localisation Using AdaBoost Algorithm and Identification with Matrix Decomposition Methods
Detection of Moving Objects in Images Combined from Video and Thermal Cameras
A novel approach to adaptive image authentication
Recent Progress in Development of Language Model for Slovak LVCSR
Automated qualitative assessment of multi-modal distortions in digital images based on GLZ
Assessing Task-Based Video Quality  A Journey from Subjective Psycho-Physical Experiments to Objective Quality Models
Extensible Web Crawler  Towards Multimedia Material Analysis
Efficient Method for Content Reconstruction With Self-Embedding
Face Detection using Color based Skin Localization and Facial Features Extraction
Security Infrastructures: Towards the INDECT System Security
Verification of the Parameterization Methods in the Context of Automatic Recognition of Sounds Related to Danger
Resolving Conflicts in Object Tracking in Video Stream Employing Key Point Matching
One Approach of Using Key-Dependent S-BOXes in AES
Quantum Cryptography Protocol Simulator
A novel method of image steganography in DWT domain
A scheme for censorship of sensitive image content with high-quality reconstruction ability
Detecting Predatory Behaviour from Online Textual Chats
Classification of video sequences into specified Generalized Use Classes of target size and lighting level
SIP Registration Burst Load Test
Comparison of Different Feature Types for Acoustic Event Detection System
Multicriteria Metadata Mechanisms for Fast and Reliable Searching of People Using Databases with Unreliable Records
Evolutionary Tuning of Compound Image Analysis Systems for Effective License Plate Recognition
Redefining ITU-T P.912 Recommendation Requirements for Subjects of Quality Assessments in Recognition Tasks
Analysis of Malware Network Activity

@_date: 2013-11-06 09:56:15
@_author: Eugen Leitl 
@_subject: fuck these guys 
Mike Hearn Shared publicly  -  Yesterday 10:30 AM The packet capture shown in these new NSA slides shows internal database
replication traffic for the anti-hacking system I worked on for over two
years. Specifically, it shows a database recording a user login as part of
this system: Recently  +Brandon Downey , a colleague of mine on the Google security team,
said (after the usual disclaimers about being personal opinions and not
speaking for the firm which I repeat here) - "fuck these guys":  I now join him in issuing a giant Fuck You to the people who made these
slides. I am not American, I am a Brit, but it's no different - GCHQ turns
out to be even worse than the NSA. We designed this system to keep criminals out . There's no ambiguity here.
The warrant system with skeptical judges, paths for appeal, and rules of
evidence was built from centuries of hard won experience. When it works, it
represents as good a balance as we've got between the need to restrain the
state and the need to keep crime in check. Bypassing that system is illegal
for a good reason . Unfortunately we live in a world where all too often, laws are for the little
people. Nobody at GCHQ or the NSA will ever stand before a judge and answer
for this industrial-scale subversion of the judicial process. In the absence
of working law enforcement,  we therefore do what internet engineers have
always done - build more secure software. The traffic shown in the slides
below is now all encrypted and the work the NSA/GCHQ staff did on
understanding it, ruined. Thank you Edward Snowden. For me personally, this is the most interesting
revelation all summer.
How we know the NSA had access to internal Google and Yahoo cloud data
732502Nico Lumma's profile photoIan Batterbee's profile photoAmber Yust's
profile photoKonrad Rudolph's profile photo 39 comments
Jeff WeissYesterday 2:46 PM+19 20 19
Until this article no one had mentioned that the intercepted traffic was on
leased fiber, not on the public internet.  That makes the cleartext
transmission seem like a less glaring error, I suppose I can see how it
wouldn't seem necessary.   In fact, anyone claiming in was necessary probably
would have been seen as paranoid until now. Still, encrypting data sent over the wire is not difficult.  Considering the
value of the data in question, and the number of parties who could access it
(at least two - the fiber owners and the government), it seems like a
worthwhile investment.   Lesson learned, I suppose.
Mike HearnYesterday 3:42 PM+42 3 2
I think the fact that Google uses private fiber has been well known for quite
a while actually. Just search for [google dark fiber] and you will find many
news stories discussing that, and it was mentioned off-hand in previous
stories as well (I think). Yes, that's pretty much it. Encryption was being worked on prior to Snowden
but it didn't seem like a high priority because there was no evidence it
would achieve anything useful, and it cost a lot of resources. Once it became
clear how badly compromised the fiber paths were, there was a crash effort to
encrypt everything. Re: "not difficult". I disagree. Doing end to end on the scale of Google is a
lot harder than it looks. Ignoring CPU capacity constraints, the entire thing
requires a large and complex key distribution and management infrastructure
(fortunately already present). Also lots of different protocols flow over our
wires, each one of which has to be handled.
Jeff WeissYesterday 4:15 PM+9 10 9
At Google's scale, everything is difficult.  I meant "not difficult" relative
to all the other feats they've pulled off. I can't say I blame them, really.  They haven't historically come across as
careless with their users' data - just the opposite in fact. If only the NSA manages to steal Google users' personal info, they're doing
relatively well.  There's always room for improvement.
Mike HearnYesterday 4:16 PM+18 9 8
Right, sure. Compared to some other initiatives encrypting cross-dc links
wasn't a moonshot. Self driving cars definitely rate as harder :)
John A. TamplinYesterday 4:29 PM+18 9 8
I don't know in Google's case, but when I was at an ISP before, dark fiber
meant we owned the fiber in the ground and were responsible for terminating
it with our repeaters/routers/etc.  So, to tap it would require either
compromising the equipment we owned or someone physically digging up the
fiber, inserting a tap, and putting it back.  You could conceivably detect
such a tap with TDR, but especially if this happened under the cover of a
cable cut you might just assume the tap was an imperfect splice to repair the
cut.  So, I don't think it was unreasonable to assume that dark fiber was
"safe". When I came to Square, it seemed over the top that even connections between
services in the same datacenter were secured with mutual auth SSL -- it
doesn't seem so excessive now.
Jeffrey YunesYesterday 5:49 PM+14 5 4
I don't think this is a "big people vs. little people" thing. I'm little,
Google's big, and we're both on the same side of this. Rather, this is a
"government vs everyone else" thing.
Andree ChristaldiYesterday 6:05 PM+4 5 4
Shocking, disgusting stuff. As you said, laws only matter to common folk, not
the state. Good work Mike. Laurent GaffiYesterday 7:25 PM+1 2 1
Well said Mike, well said.
Trevor LoucksYesterday 7:57 PM+1 2 1
possible for Google,within the next few years, to do end to end encryption
for all its services, but not manage or store the keys? I would prefer if
everything was encrypted and decrypted locally and I stored the key how I saw
fit.  Using LastPass, hard copy paper, truecrypt container, or some other
mechanism. I realize this would completely obliterate any type of possible password
recovery. But man, a system like that would allow me to feel so much better
when using Gmail or Google Drive. I guess it would have to be offered as an option, because I don't doubt most
Google users would opt for easy usability instead of higher security. In the meantime I feel compelled to transfer my backups to places which offer
end to end encryption with keys that aren't stored by the service provider.
Jason BraddyYesterday 8:15 PM+6 7 6
+John A. Tamplin  It's possible to tap an optical cable without breaking it,
by bending it far enough that some of the light leaks out through a gap in
the jacket. This can be detected by looking for unexpected drops in the light
level via DOM, etc., and I believe that critical defense/intelligence network
paths do this already.
Jeff WeissYesterday 8:15 PM+1 2 1
+Trevor Loucks that would dramatically change Google's business model, since
they generally offer free services in exchange for collecting people's data. Most of the offerings where privacy is a concern, the best private service
wouldn't be a service at all.  It would just be software you run yourself.
Or maybe it would run on some cloud service, but the important point is that
the provider doesn't see your data or care about it, they just lease you some
computing capacity.
John A. TamplinYesterday 8:27 PM+1 2 1
+Trevor Loucks  In many cases that would mean the service couldn't operate -
for example, GMail couldn't communicate with other SMTP servers if Google
never had the decrypted message on its servers.  If you have a doc for
collaborative editing, how do multiple people get the same key?  You
certainly wouldn't have the ease of saying "share this document with the
following" and it just work. Besides that, decrypting in the web browser using JS is slow and prone to
other vulnerabilities.  It currently isn't practical for web-based services
to operate as you suggest.
John MardlinYesterday 8:30 PM
+Mike Hearn  Was this work  started before the most recent revelations made
it clear that this was mission critical?   I'm sure that implementing encryption on your scale is a massive challenge,
it seems counter intuitive that it could be finalized so quickly after these
revelations, regardless of whether or not the work had been begun already. Follow on: do you ever wish Edward Snowden would just give you everything you
needed to know right away so this could be stopped sooner? Would you try to
reach out and encourage that moving forward? Thanks for taking the time to be transparent and clarify to your users, while
you're undoubtedly insanely busy.
Ian BatterbeeYesterday 8:40 PM
+John A. Tamplin   Also worked at an ISP, for us, dark fibre was simply
something where bits you shoved in one end came out the other untouched. The
dark part referred more to the fact that the packet wouldn't congest with
other people's traffic on the way, and would typically be a leased service on
someone else's CWDM or DWDM network, though it could also be simple patching
with no equipment in the way.
Stephan BealYesterday 8:51 PM
Okay, now admit it: how many of you had to google "Sisyphus" at the end of
the article? ;) (i did!)
Nicolas FischerYesterday 9:51 PM+4 5 4
These assholes think they're above the law. Fuck them! Let's use bitcoin to defund them.
Amber YustYesterday 9:57 PM+3 4 3
+John Mardlin  Yes, the project was started well before Snowden. The pace
just got ramped up immensely in the past year or so.
Jeff WeaverYesterday 10:57 PM+3 4 3
quite a post for bonfire day Guy would be proud :-)
Mike HearnYesterday 11:39 PM+13 4 3
Nobody knows how to build services like the ones Google provides but where
the service provider is blind to the traffic. It's not as simple as "Google
makes money off ads so they don't want to change things". Ad-funded services are actually a good thing from a privacy perspective! A
lot of people and media commentators don't realise this. The alternative to
advertising is direct payment by end users for a service. Unfortunately,
there are no ways to pay someone for something online anonymously. The
closest is Bitcoin but it's still very young and immature, most people can't
use it. So if the dominant paradigm for Google services was that you paid for
them, you'd pay for them with a credit card and then anonymous accounts would
be impossible, we'd always know exactly who you were. Even if we couldn't
read the message traffic, we would still know immediately and automatically
that Edward Snowden of BAH Hawaii had sent a message to Glenn Greenwald of
the Guardian, which is obviously of great interest to the NSA. You don't need
to be a genius to guess what a message from a high-clearance member of NSA
staff to a journalist might say. All you need to know is that they're
communicating at all. Currently though, anyone can sign up for a webmail account and provide any
bogus name they like (and people do). Neither the webmail provider nor the
advertisers know who a user really is, nor do they care. That's a pretty
decent situation to be in. Anyway, although I'd love it to be different, there aren't any viable
alternatives to the way cloud services operate today. These things either get
fixed legislatively, or they don't. Cryptographers are inventing lots of
really amazing technology that might one day make a truly private p2p cloud
possible, but those techniques are probably decades away from being
competitive (if they ever are).
Jeroen van Gelderen1:03 AM+3 4 3
+Mike Hearn  "These things either get fixed legislatively, or they don't." Then they won't. The TLAs will ignore the laws and lie about it until caught.
Then do it again.
Lauren Weinstein2:13 AM+12 3 2
I've had quite  a few people ask why I haven't seemed to be more upset
publicly about all the recent NSA and other surveillance disclosures. It's
real simple -- there has been nothing disclosed that I (and many others)
haven't assumed was going on at the hand of every capable surveillance org
around the world for decades, one way or another. This sort of behavior goes
back to the dawn of written communications -- tech has just made it easier in
some ways (by concentrating flows and making storage so cheap) and harder in
other ways (by providing means for robust encryption, when it's used). And recent history (that is, some decades) speaks clearly to the following.
No matter what the politicians tell you, not matter what any countries'
agencies say, there will be no substantive long-term change in these
practices. Opportunistic gathering of all data they can get their hands on
will continue, especially if it can be declared to be foreign or
international in nature and so not subject to purely domestic restrictions
(when those exist).
At the best, we can hope for a bit more oversight (at least in the short
term) and push hard for more transparency so that companies like Google can
explain to the public what really happens in terms of data demands from
government, and not be faced with when did you stop beating your wife? no-win
situations where hyperbolic, false accusations can't even be legally refuted. Above all from a practical standpoint, it has to be encrypt, encrypt, encrypt

@_date: 2013-11-06 10:40:17
@_author: Eugen Leitl 
@_subject: Open phones for privacy/anonymity applications, Guardian 
IIRC the only way to run a FLOSS GSM stack is by way of SDR (not exactly
pocket-sized), unless you can reverse-engineer the baseband firmware blob.
The most interesting news in SDR lately has been

@_date: 2013-11-13 09:54:09
@_author: Eugen Leitl 
@_subject: The second operating system hiding in every mobile phone 
The second operating system hiding in every mobile phone
posted by Thom Holwerda	 on Tue 12th Nov 2013 23:06 UTC
I've always known this, and I'm sure most of you do too, but we never really
talk about it. Every smartphone or other device with mobile communications
capability (e.g. 3G or LTE) actually runs not one, but two operating systems.
Aside from the operating system that we as end-users see (Android, iOS,
PalmOS), it also runs a small operating system that manages everything
related to radio. Since this functionality is highly timing-dependent, a
real-time operating system is required.
This operating system is stored in firmware, and runs on the baseband
processor. As far as I know, this baseband RTOS is always entirely
proprietary. For instance, the RTOS inside Qualcomm baseband processors (in
this specific case, the MSM6280) is called AMSS, built upon their own
proprietary REX kernel, and is made up of 69 concurrent tasks, handling
everything from USB to GPS. It runs on an ARMv5 processor.
The problem here is clear: these baseband processors and the proprietary,
closed software they run are poorly understood, as there's no proper peer
review. This is actually kind of weird, considering just how important these
little bits of software are to the functioning of a modern communication
device. You may think these baseband RTOS' are safe and secure, but that's
not exactly the case. You may have the most secure mobile operating system in
the world, but you're still running a second operating system that is poorly
understood, poorly documented, proprietary, and all you have to go on are
Qualcomm's Infineon's, and others' blue eyes.
The insecurity of baseband software is not by error; it's by design. The
standards that govern how these baseband processors and radios work were
designed in the '80s, ending up with a complicated codebase written in the
'90s - complete with a '90s attitude towards security. For instance, there is
barely any exploit mitigation, so exploits are free to run amok. What makes
it even worse, is that every baseband processor inherently trusts whatever
data it receives from a base station (e.g. in a cell tower). Nothing is
checked, everything is automatically trusted. Lastly, the baseband processor
is usually the master processor, whereas the application processor (which
runs the mobile operating system) is the slave.
So, we have a complete operating system, running on an ARM processor, without
any exploit mitigation (or only very little of it), which automatically
trusts every instruction, piece of code, or data it receives from the base
station you're connected to. What could possibly go wrong?
With this in mind, security researcher Ralf-Philipp Weinmann of the
University of Luxembourg set out to reverse engineer the baseband processor
software of both Qualcomm and Infineon, and he easily spotted loads and loads
of bugs, scattered all over the place, each and every one of which could lead
to exploits - crashing the device, and even allowing the attacker to remotely
execute code. Remember: all over the air. One of the exploits he found
required nothing more but a 73 byte message to get remote code execution.
Over the air.
You can do some crazy things with these exploits. For instance, you can turn
on auto-answer, using the Hayes command set. This is a command language for
modems designed in 1981, and it still works on modern baseband processors
found in smartphones today (!). The auto-answer can be made silent and
invisible, too.
While we can sort-of assume that the base stations in cell towers operated by
large carriers are "safe", the fact of the matter is that base stations are
becoming a lot cheaper, and are being sold on eBay - and there are even open
source base station software packages. Such base stations can be used to
target phones. Put a compromised base station in a crowded area - or even a
financial district or some other sensitive area - and you can remotely turn
on microphones, cameras, place rootkits, place calls/send SMS messages to
expensive numbers, and so on. Yes, you can even brick phones permanently.
This is a pretty serious issue, but one that you rarely hear about. This is
such low-level, complex software that I would guess very few people in the
world actually understand everything that's going on here.
That complexity is exactly one of the reasons why it's not easy to write your
own baseband implementation. The list of standards that describe just GSM is
unimaginably long - and that's only GSM. Now you need to add UMTS, HSDPA, and
so on, and so forth. And, of course, everything is covered by a ridiculously
complex set of patents. To top it all off, communication authorities require
baseband software to be certified.
Add all this up, and it's easy to see why every cellphone manufacturer just
opts for an off-the-shelf baseband processor and associated software. This
does mean that each and every feature and smartphone has a piece of software
that always runs (when the device is on), but that is essentially a black
box. Whenever someone does dive into baseband software, many bugs and issues
are found, which raises the question just how long this rather dubious
situation can continue.
It's kind of a sobering thought that mobile communications, the cornerstone
of the modern world in both developed and developing regions, pivots around
software that is of dubious quality, poorly understood, entirely proprietary,
and wholly insecure by design.

@_date: 2013-11-18 11:26:02
@_author: Eugen Leitl 
@_subject: RetroShare 
You can run RS over Tor. In fact, IIRC RS is in Whonix.
RS could have profited from a less is more approach. E.g. running NNTP
could have allowed you to use standard clients. In general I'd much
prefer to connect with known (SMTP, IMAP) protocols to localhost rather
than poking an unstable, monolithic blob with usability from hell.

@_date: 2013-11-21 12:29:58
@_author: Eugen Leitl 
@_subject: Exclusive: Inside America's Plan to Kill Online Privacy Rights 
cypherpunks
 Liberation Technologies ,
 doctrinezero
Exclusive: Inside America's Plan to Kill Online Privacy Rights Everywhere
Posted By Colum Lynch   Wednesday, November 20, 2013 - 6:10 PM     Share
The United States and its key intelligence allies are quietly working behind
the scenes to kneecap a mounting movement in the United Nations to promote a
universal human right to online privacy, according to diplomatic sources and
an internal American government document obtained by The Cable.
The diplomatic battle is playing out in an obscure U.N. General Assembly
committee that is considering a proposal by Brazil and Germany to place
constraints on unchecked internet surveillance by the National Security
Agency and other foreign intelligence services. American representatives have
made it clear that they won't tolerate such checks on their global
surveillance network. The stakes are high, particularly in Washington --
which is seeking to contain an international backlash against NSA spying --
and in Brasilia, where Brazilian President Dilma Roussef is personally
involved in monitoring the U.N. negotiations.
The Brazilian and German initiative seeks to apply the right to privacy,
which is enshrined in the International Covenant on Civil and Political
Rights (ICCPR), to online communications. Their proposal, first revealed by
The Cable, affirms a "right to privacy that is not to be subjected to
arbitrary or unlawful interference with their privacy, family, home, or
correspondence." It notes that while public safety may "justify the gathering
and protection of certain sensitive information," nations "must ensure full
compliance" with international human rights laws. A final version the text is
scheduled to be presented to U.N. members on Wednesday evening and the
resolution is expected to be adopted next week.
A draft of the resolution, which was obtained by The Cable, calls on states
to "to respect and protect the right to privacy," asserting that the "same
rights that people have offline must also be protected online, including the
right to privacy." It also requests the U.N. high commissioner for human
rights, Navi Pillay, present the U.N. General Assembly next year with a
report on the protection and promotion of the right to privacy, a provision
that will ensure the issue remains on the front burner.
Publicly, U.S. representatives say they're open to an affirmation of privacy
rights. "The United States takes very seriously our international legal
obligations, including those under the International Covenant on Civil and
Political Rights," Kurtis Cooper, a spokesman for the U.S. mission to the
United Nations, said in an email. "We have been actively and constructively
negotiating to ensure that the resolution promotes human rights and is
consistent with those obligations."
But privately, American diplomats are pushing hard to kill a provision of the
Brazilian and German draft which states that "extraterritorial surveillance"
and mass interception of communications, personal information, and metadata
may constitute a violation of human rights. The United States and its allies,
according to diplomats, outside observers, and documents, contend that the
Covenant on Civil and Political Rights does not apply to foreign espionage.
In recent days, the United States circulated to its allies a confidential
paper highlighting American objectives in the negotiations, "Right to Privacy
in the Digital Age -- U.S. Redlines." It calls for changing the Brazilian and
German text so "that references to privacy rights are referring explicitly to
States' obligations under ICCPR and remove suggestion that such obligations
apply extraterritorially." In other words: America wants to make sure it
preserves the right to spy overseas.
The U.S. paper also calls on governments to promote amendments that would
weaken Brazil's and Germany's contention that some "highly intrusive" acts of
online espionage may constitute a violation of freedom of expression.
Instead, the United States wants to limit the focus to illegal surveillance

@_date: 2013-11-22 16:17:52
@_author: Eugen Leitl 
@_subject: Users ID'ed through typing, mouse movements 
Users ID'ed through typing, mouse movements
By Darren Pauli on Nov 22, 2013 2:16 PM
Continuous authentication app created from DARPA research.
Researchers have built a continuous authentication platform that can
accurately identify users based on their typing patterns.
A series of 90 minute typing tests carried out on 2000 people at Iowa State
University found users could be identified with a half percent margin of
error based on the way they hit keys.
The work has been spun into an application that could continuously
authenticate users and lock accounts if another person jumped on the computer
resulting in irregularities being detected. (pdf)
Uniquely syncopated mouse and keyboard patterns made it possible to identify
users, Iowa State University associate professor Morris Chang said.
These pauses between words, searches for unusual characters and spellings of
unfamiliar words, all have to do with our past experiences, our learning
experiences, Chang said. And so we call them cognitive fingerprints which
manifest themselves in typing rhythms.
The system can see if the same person or an imposter is coming in to hijack
the computer."
The year-long research run together with electrical engineering students
Terry Fang, Kuan-Hsing Ho and Danny Shih received a half a million dollar
grant from the US Defense Advanced Research Projects Agency which sought to
discover if continuous authentication was possible.
It was now being extended to capture mouse movements and touch inputs from
mobile devices with an additional $1.76 million dollars from the agency over
two years.
Copyright  SC Magazine, Australia

@_date: 2013-11-26 08:09:50
@_author: Eugen Leitl 
@_subject: bitcoin as a global medium of exchange (was Re: Interesting take 
There are scaling issues in Bitcoin which can be addressed in
a successor that is not a mere copycat with no added value.
Some of the issues might be even fixed as time passes, and
there's sufficient incentive.

@_date: 2013-11-26 13:05:46
@_author: Eugen Leitl 
@_subject: bitcoin as a global medium of exchange (was Re: Interesting take 
Moore's law has unfortunately recently ran into financial scaling limits,
which are slowing doubling times (estimate from 18 months to three years
at the moment) with physical scaling limits close to follow (somewhen
shortly below 5 nm).
Of course current ASICs are far removed from cutting edge. Another
issue is blockchain storage (NOR flash is also pretty finished, HDD
area density has stalled recently, but might resume scaling, at least
for a while) and availability of network bandwidth. You can buy 10 Gbit/s
close to the backbone, but it's beyond affordability for most people.

@_date: 2013-11-27 12:01:58
@_author: Eugen Leitl 
@_subject: bitcoin as a global medium of exchange (was Re: Interesting take 
Transactions are in a global ledger. You might not be able
to link warm bodies to a specific account directly, but indirectly (especially, if they engage in transactions,
or want to convert their currency). This is more difficult with banknotes, even if you have the serial numbers on record. Banknotes do not globally broadcast their current location.
This is the tradeoff of having a practical system. I personally
think that anonymous cash is orthogonal to the digital cash issue.
It can be done in a different system, or use an anonymization layer
like Tor, I2P or cjdns operates on top of TCP/IP.

@_date: 2013-11-01 19:19:22
@_author: Eugen Leitl 
@_subject: INDECT: Intelligent Information System Supporting Observation, 
Liberation Technologies  Project: INDECT
Title: Intelligent Information System Supporting Observation, Searching and Detection for Security of Citizens in Urban Environment	
Call: FP7-SEC-2007-1	
Grant agreement number: 218086	
Start date: 01/01/2009	
End date: 31/12/2013	
Special clause 39: no	
Scientific area: Security	
Programme: SP1-Cooperation	
Detailed project information (CORDIS)
Use of the bio-inspired algorithms to find global minimum in force directed layout algorithms
DoS attacks targeting SIP server and improvements of robustness
Impact of network Jitter on effective equipment impairment factor
Video files recording and playback with VoiceXML
Objective assessment of IP video calls with Asterisk
Delay model of RTP flows in accordance with M/D/1 and M/D/2 Kendall's notation
Monitoring the quality of speech in the communication system BESIP
Remote control of asterisk via web services
E-model modification for case of cascade codecs arrangement
Methodology of the direct measurement of the switching latency
Performance analysis of virtualized real-time applications
SIP end to end performance metrics
Improvement of network efficiency on the grounds of change communication protocol
Software designed 64-QAM demodulator of OFDM signal implemented into FPGA elements
Fundamental frequency extraction method using central clipping and its importance for the classification of emotional state
The interactions of SOAP-based web services for recording and replaying video files
Malicious traffic monitoring and its evaluation in VoIP infrastructure
Automated speech quality monitoring tool based on perceptual evaluation
Approach to stress tests in SIP environment based on marginal analysis
Applied multiprotocol routing in IP telephony
Advanced concept of voice communication server on embedded platform
SIP registration stress test
Delay variation model for RTP flows in network with priority queueing
E-model improvement for speech quality evaluation including codecs tandeming
Jitter buffer loss estimate for effective equipment impairment factor
Overview of the security components of INDECT project
VoIP based system for the message distribution
Security infrastructures: towards the INDECT system security
Mathematical model of subscriber extension line
Performance evaluation of INACT - INDECT advanced image cataloguing tool
Influence of atmospheric parameters on speech quality in GSM/UMTS
Danger alert communication system
Development of a speech quality monitoring tool based on ITU-T P.862
IP telephony based danger alert communication system and its implementation
Multimedia services in Asterisk based on VoiceXML
Impact of emotions on fundamental speech signal frequency
Speech quality monitoring in czech national research network
Delay variation model with RTP flows behavior in accordance with M/D/1 Kendall's notation
SIP threats detection system
Interactive VoiceXML module into SIP-based warning distribution system
Web-based IP telephony penetration system evaluating level of protection from attacks and threats
Non-intrusive speech quality assessment in simplified e-model
Replication-Based Information Sharing in Multi-Agent System for Monitoring the Internet
Feature selection for acoustic events detection
M-JPEG Robust Video Watermarking Based on DPCM and Transform Coding
Traffic Danger Ontology for Citizen Safety Web System
How to Build an Objective Model for Packet Loss Effect on High Definition Content Based on SSIM and Subjective Experiments
Web-Based Knowledge Acquisition and Management System Supporting Collaboration for Improving Safety in Urban Environment
A New Method for Automatic Generation of Animated Motion
A no reference metric for the quality assessment of videos affected by exposure distortion
On Occlusion-Handling for People Detection Fusion in Multi-camera Networks
Agent-based Modelling of Social Organisations
Content protection in grayscale and color images based on robust digital watermarking
Anchor-Free Localization Algorithm with Low-Complexity Method for Node Distance Estimation Enhancement Using ToA
Analysis of privacy vulnerabilities in single sign-on mechanisms for multimedia websites
Scenario-Driven System for Open Source Intelligence
Correction Trees as an Alternative to Turbo Codes and Low Density Parity Check Codes
Prototypes of a Web System for Citizen Provided Information, Automatic Knowledge Extraction, Knowledge Management and GIS Integration
Recent advances in multimedia networking
INDECT Security Architecture
LDA for Face Profile Detection
Audio-Visual Surveillance System for Application in Bank Operating Room
Software Implementation of New Symmetric Block Cipher
Malicious traffic monitoring and its evaluation in VoIP infrastructure
Approach to stress tests in SIP environment based on marginal analysis
Graph-Based Relation Mining
Detection and Localization of Selected Acoustic Events in 3D Acoustic Field for Smart Surveillance Applications
Distributed Framework for Visual Event Detection in Parking Lot Area
Object Detection and Measurement Using Stereo Images
Semantic Structure Matching Recommendation Algorithm
Acoustic Events Detection Using MFCC and MPEG-7 Descriptors
Quality Assessment for a Licence Plate Recognition Task Based on a Video Streamed in Limited Networking Conditions
Automatic quality control of digital image content reconstruction schemes
Broadcast news audio classification using SVM binary trees
Analysis of Particular Iris Recognition Stages
Determining image quality requirements for recognition tasks in generalized public safety video applications: Definitions, testing, standardization, and current trends
INSTREET - Application for Urban Photograph Localization
Quantum cryptography - The analysis of security requirements
Implementation of the New Integration Model of Security and QoS for MANET to the OPNET
A new approach to high-capacity annotation watermarking based on digital fountain codes
A Novel JPEG Steganography Method Based on Modulus Function with Histogram Analysis
Hierarchical Multi-Agent System for Heterogeneous Data Integration
INCR  INDECT Multimedia Crawler
Performance of Basic Spectral Descriptors and MRMR Algorithm to the Detection of Acoustic Events
Towards Hardware Implementation of INDECT Block Cipher
Multi-camera Vehicle Tracking Using Local Image Features and Neural Networks
Video Watermarking Based on DPCM and Transformcoding Using Permutation Spectrum and QIM
Camera Angle Invariant Shape Recognition in Surveillance Systems
A Statistical Blind Image Steganalysis Based on Image Multi-classification
Integrating Applications Developed for Heterogeneous Platforms: Building an Environment for Criminal Analysts
A new symmetric block cipher based on key-dependent S-boxes
INACT  INDECT Advanced Image Cataloguing Tool
QoE as a Function of Frame Rate and Resolution Changes
Monitoring the quality of speech in the communication system BESIP
Brightness Correction and Stereovision Impression Based Methods of Perceived Quality Improvement of CCTV Video Sequences
Performance Measurements of Real Time Video Transmission from Car Patrol
Multiple Sound Sources Localization in Real Time Using Acoustic Vector Sensor
Vehicle Classification Based on Soft Computing Algorithms
Quality Assessment in Video Surveillance
Performance Evaluation of the Parallel Codebook Algorithm for Background Subtraction in Video Stream
A High-Capacity Annotation Watermarking Scheme
Fast Face Localisation Using AdaBoost Algorithm and Identification with Matrix Decomposition Methods
Detection of Moving Objects in Images Combined from Video and Thermal Cameras
A novel approach to adaptive image authentication
Recent Progress in Development of Language Model for Slovak LVCSR
Automated qualitative assessment of multi-modal distortions in digital images based on GLZ
Assessing Task-Based Video Quality  A Journey from Subjective Psycho-Physical Experiments to Objective Quality Models
Extensible Web Crawler  Towards Multimedia Material Analysis
Efficient Method for Content Reconstruction With Self-Embedding
Face Detection using Color based Skin Localization and Facial Features Extraction
Security Infrastructures: Towards the INDECT System Security
Verification of the Parameterization Methods in the Context of Automatic Recognition of Sounds Related to Danger
Resolving Conflicts in Object Tracking in Video Stream Employing Key Point Matching
One Approach of Using Key-Dependent S-BOXes in AES
Quantum Cryptography Protocol Simulator
A novel method of image steganography in DWT domain
A scheme for censorship of sensitive image content with high-quality reconstruction ability
Detecting Predatory Behaviour from Online Textual Chats
Classification of video sequences into specified Generalized Use Classes of target size and lighting level
SIP Registration Burst Load Test
Comparison of Different Feature Types for Acoustic Event Detection System
Multicriteria Metadata Mechanisms for Fast and Reliable Searching of People Using Databases with Unreliable Records
Evolutionary Tuning of Compound Image Analysis Systems for Effective License Plate Recognition
Redefining ITU-T P.912 Recommendation Requirements for Subjects of Quality Assessments in Recognition Tasks
Analysis of Malware Network Activity

@_date: 2013-11-06 09:56:15
@_author: Eugen Leitl 
@_subject: fuck these guys 
Mike Hearn Shared publicly  -  Yesterday 10:30 AM The packet capture shown in these new NSA slides shows internal database
replication traffic for the anti-hacking system I worked on for over two
years. Specifically, it shows a database recording a user login as part of
this system: Recently  +Brandon Downey , a colleague of mine on the Google security team,
said (after the usual disclaimers about being personal opinions and not
speaking for the firm which I repeat here) - "fuck these guys":  I now join him in issuing a giant Fuck You to the people who made these
slides. I am not American, I am a Brit, but it's no different - GCHQ turns
out to be even worse than the NSA. We designed this system to keep criminals out . There's no ambiguity here.
The warrant system with skeptical judges, paths for appeal, and rules of
evidence was built from centuries of hard won experience. When it works, it
represents as good a balance as we've got between the need to restrain the
state and the need to keep crime in check. Bypassing that system is illegal
for a good reason . Unfortunately we live in a world where all too often, laws are for the little
people. Nobody at GCHQ or the NSA will ever stand before a judge and answer
for this industrial-scale subversion of the judicial process. In the absence
of working law enforcement,  we therefore do what internet engineers have
always done - build more secure software. The traffic shown in the slides
below is now all encrypted and the work the NSA/GCHQ staff did on
understanding it, ruined. Thank you Edward Snowden. For me personally, this is the most interesting
revelation all summer.
How we know the NSA had access to internal Google and Yahoo cloud data
732502Nico Lumma's profile photoIan Batterbee's profile photoAmber Yust's
profile photoKonrad Rudolph's profile photo 39 comments
Jeff WeissYesterday 2:46 PM+19 20 19
Until this article no one had mentioned that the intercepted traffic was on
leased fiber, not on the public internet.  That makes the cleartext
transmission seem like a less glaring error, I suppose I can see how it
wouldn't seem necessary.   In fact, anyone claiming in was necessary probably
would have been seen as paranoid until now. Still, encrypting data sent over the wire is not difficult.  Considering the
value of the data in question, and the number of parties who could access it
(at least two - the fiber owners and the government), it seems like a
worthwhile investment.   Lesson learned, I suppose.
Mike HearnYesterday 3:42 PM+42 3 2
I think the fact that Google uses private fiber has been well known for quite
a while actually. Just search for [google dark fiber] and you will find many
news stories discussing that, and it was mentioned off-hand in previous
stories as well (I think). Yes, that's pretty much it. Encryption was being worked on prior to Snowden
but it didn't seem like a high priority because there was no evidence it
would achieve anything useful, and it cost a lot of resources. Once it became
clear how badly compromised the fiber paths were, there was a crash effort to
encrypt everything. Re: "not difficult". I disagree. Doing end to end on the scale of Google is a
lot harder than it looks. Ignoring CPU capacity constraints, the entire thing
requires a large and complex key distribution and management infrastructure
(fortunately already present). Also lots of different protocols flow over our
wires, each one of which has to be handled.
Jeff WeissYesterday 4:15 PM+9 10 9
At Google's scale, everything is difficult.  I meant "not difficult" relative
to all the other feats they've pulled off. I can't say I blame them, really.  They haven't historically come across as
careless with their users' data - just the opposite in fact. If only the NSA manages to steal Google users' personal info, they're doing
relatively well.  There's always room for improvement.
Mike HearnYesterday 4:16 PM+18 9 8
Right, sure. Compared to some other initiatives encrypting cross-dc links
wasn't a moonshot. Self driving cars definitely rate as harder :)
John A. TamplinYesterday 4:29 PM+18 9 8
I don't know in Google's case, but when I was at an ISP before, dark fiber
meant we owned the fiber in the ground and were responsible for terminating
it with our repeaters/routers/etc.  So, to tap it would require either
compromising the equipment we owned or someone physically digging up the
fiber, inserting a tap, and putting it back.  You could conceivably detect
such a tap with TDR, but especially if this happened under the cover of a
cable cut you might just assume the tap was an imperfect splice to repair the
cut.  So, I don't think it was unreasonable to assume that dark fiber was
"safe". When I came to Square, it seemed over the top that even connections between
services in the same datacenter were secured with mutual auth SSL -- it
doesn't seem so excessive now.
Jeffrey YunesYesterday 5:49 PM+14 5 4
I don't think this is a "big people vs. little people" thing. I'm little,
Google's big, and we're both on the same side of this. Rather, this is a
"government vs everyone else" thing.
Andree ChristaldiYesterday 6:05 PM+4 5 4
Shocking, disgusting stuff. As you said, laws only matter to common folk, not
the state. Good work Mike. Laurent GaffiYesterday 7:25 PM+1 2 1
Well said Mike, well said.
Trevor LoucksYesterday 7:57 PM+1 2 1
possible for Google,within the next few years, to do end to end encryption
for all its services, but not manage or store the keys? I would prefer if
everything was encrypted and decrypted locally and I stored the key how I saw
fit.  Using LastPass, hard copy paper, truecrypt container, or some other
mechanism. I realize this would completely obliterate any type of possible password
recovery. But man, a system like that would allow me to feel so much better
when using Gmail or Google Drive. I guess it would have to be offered as an option, because I don't doubt most
Google users would opt for easy usability instead of higher security. In the meantime I feel compelled to transfer my backups to places which offer
end to end encryption with keys that aren't stored by the service provider.
Jason BraddyYesterday 8:15 PM+6 7 6
+John A. Tamplin  It's possible to tap an optical cable without breaking it,
by bending it far enough that some of the light leaks out through a gap in
the jacket. This can be detected by looking for unexpected drops in the light
level via DOM, etc., and I believe that critical defense/intelligence network
paths do this already.
Jeff WeissYesterday 8:15 PM+1 2 1
+Trevor Loucks that would dramatically change Google's business model, since
they generally offer free services in exchange for collecting people's data. Most of the offerings where privacy is a concern, the best private service
wouldn't be a service at all.  It would just be software you run yourself.
Or maybe it would run on some cloud service, but the important point is that
the provider doesn't see your data or care about it, they just lease you some
computing capacity.
John A. TamplinYesterday 8:27 PM+1 2 1
+Trevor Loucks  In many cases that would mean the service couldn't operate -
for example, GMail couldn't communicate with other SMTP servers if Google
never had the decrypted message on its servers.  If you have a doc for
collaborative editing, how do multiple people get the same key?  You
certainly wouldn't have the ease of saying "share this document with the
following" and it just work. Besides that, decrypting in the web browser using JS is slow and prone to
other vulnerabilities.  It currently isn't practical for web-based services
to operate as you suggest.
John MardlinYesterday 8:30 PM
+Mike Hearn  Was this work  started before the most recent revelations made
it clear that this was mission critical?   I'm sure that implementing encryption on your scale is a massive challenge,
it seems counter intuitive that it could be finalized so quickly after these
revelations, regardless of whether or not the work had been begun already. Follow on: do you ever wish Edward Snowden would just give you everything you
needed to know right away so this could be stopped sooner? Would you try to
reach out and encourage that moving forward? Thanks for taking the time to be transparent and clarify to your users, while
you're undoubtedly insanely busy.
Ian BatterbeeYesterday 8:40 PM
+John A. Tamplin   Also worked at an ISP, for us, dark fibre was simply
something where bits you shoved in one end came out the other untouched. The
dark part referred more to the fact that the packet wouldn't congest with
other people's traffic on the way, and would typically be a leased service on
someone else's CWDM or DWDM network, though it could also be simple patching
with no equipment in the way.
Stephan BealYesterday 8:51 PM
Okay, now admit it: how many of you had to google "Sisyphus" at the end of
the article? ;) (i did!)
Nicolas FischerYesterday 9:51 PM+4 5 4
These assholes think they're above the law. Fuck them! Let's use bitcoin to defund them.
Amber YustYesterday 9:57 PM+3 4 3
+John Mardlin  Yes, the project was started well before Snowden. The pace
just got ramped up immensely in the past year or so.
Jeff WeaverYesterday 10:57 PM+3 4 3
quite a post for bonfire day Guy would be proud :-)
Mike HearnYesterday 11:39 PM+13 4 3
Nobody knows how to build services like the ones Google provides but where
the service provider is blind to the traffic. It's not as simple as "Google
makes money off ads so they don't want to change things". Ad-funded services are actually a good thing from a privacy perspective! A
lot of people and media commentators don't realise this. The alternative to
advertising is direct payment by end users for a service. Unfortunately,
there are no ways to pay someone for something online anonymously. The
closest is Bitcoin but it's still very young and immature, most people can't
use it. So if the dominant paradigm for Google services was that you paid for
them, you'd pay for them with a credit card and then anonymous accounts would
be impossible, we'd always know exactly who you were. Even if we couldn't
read the message traffic, we would still know immediately and automatically
that Edward Snowden of BAH Hawaii had sent a message to Glenn Greenwald of
the Guardian, which is obviously of great interest to the NSA. You don't need
to be a genius to guess what a message from a high-clearance member of NSA
staff to a journalist might say. All you need to know is that they're
communicating at all. Currently though, anyone can sign up for a webmail account and provide any
bogus name they like (and people do). Neither the webmail provider nor the
advertisers know who a user really is, nor do they care. That's a pretty
decent situation to be in. Anyway, although I'd love it to be different, there aren't any viable
alternatives to the way cloud services operate today. These things either get
fixed legislatively, or they don't. Cryptographers are inventing lots of
really amazing technology that might one day make a truly private p2p cloud
possible, but those techniques are probably decades away from being
competitive (if they ever are).
Jeroen van Gelderen1:03 AM+3 4 3
+Mike Hearn  "These things either get fixed legislatively, or they don't." Then they won't. The TLAs will ignore the laws and lie about it until caught.
Then do it again.
Lauren Weinstein2:13 AM+12 3 2
I've had quite  a few people ask why I haven't seemed to be more upset
publicly about all the recent NSA and other surveillance disclosures. It's
real simple -- there has been nothing disclosed that I (and many others)
haven't assumed was going on at the hand of every capable surveillance org
around the world for decades, one way or another. This sort of behavior goes
back to the dawn of written communications -- tech has just made it easier in
some ways (by concentrating flows and making storage so cheap) and harder in
other ways (by providing means for robust encryption, when it's used). And recent history (that is, some decades) speaks clearly to the following.
No matter what the politicians tell you, not matter what any countries'
agencies say, there will be no substantive long-term change in these
practices. Opportunistic gathering of all data they can get their hands on
will continue, especially if it can be declared to be foreign or
international in nature and so not subject to purely domestic restrictions
(when those exist).
At the best, we can hope for a bit more oversight (at least in the short
term) and push hard for more transparency so that companies like Google can
explain to the public what really happens in terms of data demands from
government, and not be faced with when did you stop beating your wife? no-win
situations where hyperbolic, false accusations can't even be legally refuted. Above all from a practical standpoint, it has to be encrypt, encrypt, encrypt

@_date: 2013-11-06 10:40:17
@_author: Eugen Leitl 
@_subject: Open phones for privacy/anonymity applications, Guardian 
IIRC the only way to run a FLOSS GSM stack is by way of SDR (not exactly
pocket-sized), unless you can reverse-engineer the baseband firmware blob.
The most interesting news in SDR lately has been

@_date: 2013-11-13 09:54:09
@_author: Eugen Leitl 
@_subject: The second operating system hiding in every mobile phone 
The second operating system hiding in every mobile phone
posted by Thom Holwerda	 on Tue 12th Nov 2013 23:06 UTC
I've always known this, and I'm sure most of you do too, but we never really
talk about it. Every smartphone or other device with mobile communications
capability (e.g. 3G or LTE) actually runs not one, but two operating systems.
Aside from the operating system that we as end-users see (Android, iOS,
PalmOS), it also runs a small operating system that manages everything
related to radio. Since this functionality is highly timing-dependent, a
real-time operating system is required.
This operating system is stored in firmware, and runs on the baseband
processor. As far as I know, this baseband RTOS is always entirely
proprietary. For instance, the RTOS inside Qualcomm baseband processors (in
this specific case, the MSM6280) is called AMSS, built upon their own
proprietary REX kernel, and is made up of 69 concurrent tasks, handling
everything from USB to GPS. It runs on an ARMv5 processor.
The problem here is clear: these baseband processors and the proprietary,
closed software they run are poorly understood, as there's no proper peer
review. This is actually kind of weird, considering just how important these
little bits of software are to the functioning of a modern communication
device. You may think these baseband RTOS' are safe and secure, but that's
not exactly the case. You may have the most secure mobile operating system in
the world, but you're still running a second operating system that is poorly
understood, poorly documented, proprietary, and all you have to go on are
Qualcomm's Infineon's, and others' blue eyes.
The insecurity of baseband software is not by error; it's by design. The
standards that govern how these baseband processors and radios work were
designed in the '80s, ending up with a complicated codebase written in the
'90s - complete with a '90s attitude towards security. For instance, there is
barely any exploit mitigation, so exploits are free to run amok. What makes
it even worse, is that every baseband processor inherently trusts whatever
data it receives from a base station (e.g. in a cell tower). Nothing is
checked, everything is automatically trusted. Lastly, the baseband processor
is usually the master processor, whereas the application processor (which
runs the mobile operating system) is the slave.
So, we have a complete operating system, running on an ARM processor, without
any exploit mitigation (or only very little of it), which automatically
trusts every instruction, piece of code, or data it receives from the base
station you're connected to. What could possibly go wrong?
With this in mind, security researcher Ralf-Philipp Weinmann of the
University of Luxembourg set out to reverse engineer the baseband processor
software of both Qualcomm and Infineon, and he easily spotted loads and loads
of bugs, scattered all over the place, each and every one of which could lead
to exploits - crashing the device, and even allowing the attacker to remotely
execute code. Remember: all over the air. One of the exploits he found
required nothing more but a 73 byte message to get remote code execution.
Over the air.
You can do some crazy things with these exploits. For instance, you can turn
on auto-answer, using the Hayes command set. This is a command language for
modems designed in 1981, and it still works on modern baseband processors
found in smartphones today (!). The auto-answer can be made silent and
invisible, too.
While we can sort-of assume that the base stations in cell towers operated by
large carriers are "safe", the fact of the matter is that base stations are
becoming a lot cheaper, and are being sold on eBay - and there are even open
source base station software packages. Such base stations can be used to
target phones. Put a compromised base station in a crowded area - or even a
financial district or some other sensitive area - and you can remotely turn
on microphones, cameras, place rootkits, place calls/send SMS messages to
expensive numbers, and so on. Yes, you can even brick phones permanently.
This is a pretty serious issue, but one that you rarely hear about. This is
such low-level, complex software that I would guess very few people in the
world actually understand everything that's going on here.
That complexity is exactly one of the reasons why it's not easy to write your
own baseband implementation. The list of standards that describe just GSM is
unimaginably long - and that's only GSM. Now you need to add UMTS, HSDPA, and
so on, and so forth. And, of course, everything is covered by a ridiculously
complex set of patents. To top it all off, communication authorities require
baseband software to be certified.
Add all this up, and it's easy to see why every cellphone manufacturer just
opts for an off-the-shelf baseband processor and associated software. This
does mean that each and every feature and smartphone has a piece of software
that always runs (when the device is on), but that is essentially a black
box. Whenever someone does dive into baseband software, many bugs and issues
are found, which raises the question just how long this rather dubious
situation can continue.
It's kind of a sobering thought that mobile communications, the cornerstone
of the modern world in both developed and developing regions, pivots around
software that is of dubious quality, poorly understood, entirely proprietary,
and wholly insecure by design.

@_date: 2013-11-18 11:26:02
@_author: Eugen Leitl 
@_subject: RetroShare 
You can run RS over Tor. In fact, IIRC RS is in Whonix.
RS could have profited from a less is more approach. E.g. running NNTP
could have allowed you to use standard clients. In general I'd much
prefer to connect with known (SMTP, IMAP) protocols to localhost rather
than poking an unstable, monolithic blob with usability from hell.

@_date: 2013-11-21 12:29:58
@_author: Eugen Leitl 
@_subject: Exclusive: Inside America's Plan to Kill Online Privacy Rights 
cypherpunks
 Liberation Technologies ,
 doctrinezero
Exclusive: Inside America's Plan to Kill Online Privacy Rights Everywhere
Posted By Colum Lynch   Wednesday, November 20, 2013 - 6:10 PM     Share
The United States and its key intelligence allies are quietly working behind
the scenes to kneecap a mounting movement in the United Nations to promote a
universal human right to online privacy, according to diplomatic sources and
an internal American government document obtained by The Cable.
The diplomatic battle is playing out in an obscure U.N. General Assembly
committee that is considering a proposal by Brazil and Germany to place
constraints on unchecked internet surveillance by the National Security
Agency and other foreign intelligence services. American representatives have
made it clear that they won't tolerate such checks on their global
surveillance network. The stakes are high, particularly in Washington --
which is seeking to contain an international backlash against NSA spying --
and in Brasilia, where Brazilian President Dilma Roussef is personally
involved in monitoring the U.N. negotiations.
The Brazilian and German initiative seeks to apply the right to privacy,
which is enshrined in the International Covenant on Civil and Political
Rights (ICCPR), to online communications. Their proposal, first revealed by
The Cable, affirms a "right to privacy that is not to be subjected to
arbitrary or unlawful interference with their privacy, family, home, or
correspondence." It notes that while public safety may "justify the gathering
and protection of certain sensitive information," nations "must ensure full
compliance" with international human rights laws. A final version the text is
scheduled to be presented to U.N. members on Wednesday evening and the
resolution is expected to be adopted next week.
A draft of the resolution, which was obtained by The Cable, calls on states
to "to respect and protect the right to privacy," asserting that the "same
rights that people have offline must also be protected online, including the
right to privacy." It also requests the U.N. high commissioner for human
rights, Navi Pillay, present the U.N. General Assembly next year with a
report on the protection and promotion of the right to privacy, a provision
that will ensure the issue remains on the front burner.
Publicly, U.S. representatives say they're open to an affirmation of privacy
rights. "The United States takes very seriously our international legal
obligations, including those under the International Covenant on Civil and
Political Rights," Kurtis Cooper, a spokesman for the U.S. mission to the
United Nations, said in an email. "We have been actively and constructively
negotiating to ensure that the resolution promotes human rights and is
consistent with those obligations."
But privately, American diplomats are pushing hard to kill a provision of the
Brazilian and German draft which states that "extraterritorial surveillance"
and mass interception of communications, personal information, and metadata
may constitute a violation of human rights. The United States and its allies,
according to diplomats, outside observers, and documents, contend that the
Covenant on Civil and Political Rights does not apply to foreign espionage.
In recent days, the United States circulated to its allies a confidential
paper highlighting American objectives in the negotiations, "Right to Privacy
in the Digital Age -- U.S. Redlines." It calls for changing the Brazilian and
German text so "that references to privacy rights are referring explicitly to
States' obligations under ICCPR and remove suggestion that such obligations
apply extraterritorially." In other words: America wants to make sure it
preserves the right to spy overseas.
The U.S. paper also calls on governments to promote amendments that would
weaken Brazil's and Germany's contention that some "highly intrusive" acts of
online espionage may constitute a violation of freedom of expression.
Instead, the United States wants to limit the focus to illegal surveillance

@_date: 2013-11-22 16:17:52
@_author: Eugen Leitl 
@_subject: Users ID'ed through typing, mouse movements 
Users ID'ed through typing, mouse movements
By Darren Pauli on Nov 22, 2013 2:16 PM
Continuous authentication app created from DARPA research.
Researchers have built a continuous authentication platform that can
accurately identify users based on their typing patterns.
A series of 90 minute typing tests carried out on 2000 people at Iowa State
University found users could be identified with a half percent margin of
error based on the way they hit keys.
The work has been spun into an application that could continuously
authenticate users and lock accounts if another person jumped on the computer
resulting in irregularities being detected. (pdf)
Uniquely syncopated mouse and keyboard patterns made it possible to identify
users, Iowa State University associate professor Morris Chang said.
These pauses between words, searches for unusual characters and spellings of
unfamiliar words, all have to do with our past experiences, our learning
experiences, Chang said. And so we call them cognitive fingerprints which
manifest themselves in typing rhythms.
The system can see if the same person or an imposter is coming in to hijack
the computer."
The year-long research run together with electrical engineering students
Terry Fang, Kuan-Hsing Ho and Danny Shih received a half a million dollar
grant from the US Defense Advanced Research Projects Agency which sought to
discover if continuous authentication was possible.
It was now being extended to capture mouse movements and touch inputs from
mobile devices with an additional $1.76 million dollars from the agency over
two years.
Copyright  SC Magazine, Australia

@_date: 2013-11-26 08:09:50
@_author: Eugen Leitl 
@_subject: bitcoin as a global medium of exchange (was Re: Interesting take 
There are scaling issues in Bitcoin which can be addressed in
a successor that is not a mere copycat with no added value.
Some of the issues might be even fixed as time passes, and
there's sufficient incentive.

@_date: 2013-11-26 13:05:46
@_author: Eugen Leitl 
@_subject: bitcoin as a global medium of exchange (was Re: Interesting take 
Moore's law has unfortunately recently ran into financial scaling limits,
which are slowing doubling times (estimate from 18 months to three years
at the moment) with physical scaling limits close to follow (somewhen
shortly below 5 nm).
Of course current ASICs are far removed from cutting edge. Another
issue is blockchain storage (NOR flash is also pretty finished, HDD
area density has stalled recently, but might resume scaling, at least
for a while) and availability of network bandwidth. You can buy 10 Gbit/s
close to the backbone, but it's beyond affordability for most people.

@_date: 2013-11-27 12:01:58
@_author: Eugen Leitl 
@_subject: bitcoin as a global medium of exchange (was Re: Interesting take 
Transactions are in a global ledger. You might not be able
to link warm bodies to a specific account directly, but indirectly (especially, if they engage in transactions,
or want to convert their currency). This is more difficult with banknotes, even if you have the serial numbers on record. Banknotes do not globally broadcast their current location.
This is the tradeoff of having a practical system. I personally
think that anonymous cash is orthogonal to the digital cash issue.
It can be done in a different system, or use an anonymization layer
like Tor, I2P or cjdns operates on top of TCP/IP.

@_date: 2013-11-01 19:19:22
@_author: Eugen Leitl 
@_subject: INDECT: Intelligent Information System Supporting Observation, 
Project: INDECT
Title: Intelligent Information System Supporting Observation, Searching and Detection for Security of Citizens in Urban Environment	
Call: FP7-SEC-2007-1	
Grant agreement number: 218086	
Start date: 01/01/2009	
End date: 31/12/2013	
Special clause 39: no	
Scientific area: Security	
Programme: SP1-Cooperation	
Detailed project information (CORDIS)
Use of the bio-inspired algorithms to find global minimum in force directed layout algorithms
DoS attacks targeting SIP server and improvements of robustness
Impact of network Jitter on effective equipment impairment factor
Video files recording and playback with VoiceXML
Objective assessment of IP video calls with Asterisk
Delay model of RTP flows in accordance with M/D/1 and M/D/2 Kendall's notation
Monitoring the quality of speech in the communication system BESIP
Remote control of asterisk via web services
E-model modification for case of cascade codecs arrangement
Methodology of the direct measurement of the switching latency
Performance analysis of virtualized real-time applications
SIP end to end performance metrics
Improvement of network efficiency on the grounds of change communication protocol
Software designed 64-QAM demodulator of OFDM signal implemented into FPGA elements
Fundamental frequency extraction method using central clipping and its importance for the classification of emotional state
The interactions of SOAP-based web services for recording and replaying video files
Malicious traffic monitoring and its evaluation in VoIP infrastructure
Automated speech quality monitoring tool based on perceptual evaluation
Approach to stress tests in SIP environment based on marginal analysis
Applied multiprotocol routing in IP telephony
Advanced concept of voice communication server on embedded platform
SIP registration stress test
Delay variation model for RTP flows in network with priority queueing
E-model improvement for speech quality evaluation including codecs tandeming
Jitter buffer loss estimate for effective equipment impairment factor
Overview of the security components of INDECT project
VoIP based system for the message distribution
Security infrastructures: towards the INDECT system security
Mathematical model of subscriber extension line
Performance evaluation of INACT - INDECT advanced image cataloguing tool
Influence of atmospheric parameters on speech quality in GSM/UMTS
Danger alert communication system
Development of a speech quality monitoring tool based on ITU-T P.862
IP telephony based danger alert communication system and its implementation
Multimedia services in Asterisk based on VoiceXML
Impact of emotions on fundamental speech signal frequency
Speech quality monitoring in czech national research network
Delay variation model with RTP flows behavior in accordance with M/D/1 Kendall's notation
SIP threats detection system
Interactive VoiceXML module into SIP-based warning distribution system
Web-based IP telephony penetration system evaluating level of protection from attacks and threats
Non-intrusive speech quality assessment in simplified e-model
Replication-Based Information Sharing in Multi-Agent System for Monitoring the Internet
Feature selection for acoustic events detection
M-JPEG Robust Video Watermarking Based on DPCM and Transform Coding
Traffic Danger Ontology for Citizen Safety Web System
How to Build an Objective Model for Packet Loss Effect on High Definition Content Based on SSIM and Subjective Experiments
Web-Based Knowledge Acquisition and Management System Supporting Collaboration for Improving Safety in Urban Environment
A New Method for Automatic Generation of Animated Motion
A no reference metric for the quality assessment of videos affected by exposure distortion
On Occlusion-Handling for People Detection Fusion in Multi-camera Networks
Agent-based Modelling of Social Organisations
Content protection in grayscale and color images based on robust digital watermarking
Anchor-Free Localization Algorithm with Low-Complexity Method for Node Distance Estimation Enhancement Using ToA
Analysis of privacy vulnerabilities in single sign-on mechanisms for multimedia websites
Scenario-Driven System for Open Source Intelligence
Correction Trees as an Alternative to Turbo Codes and Low Density Parity Check Codes
Prototypes of a Web System for Citizen Provided Information, Automatic Knowledge Extraction, Knowledge Management and GIS Integration
Recent advances in multimedia networking
INDECT Security Architecture
LDA for Face Profile Detection
Audio-Visual Surveillance System for Application in Bank Operating Room
Software Implementation of New Symmetric Block Cipher
Malicious traffic monitoring and its evaluation in VoIP infrastructure
Approach to stress tests in SIP environment based on marginal analysis
Graph-Based Relation Mining
Detection and Localization of Selected Acoustic Events in 3D Acoustic Field for Smart Surveillance Applications
Distributed Framework for Visual Event Detection in Parking Lot Area
Object Detection and Measurement Using Stereo Images
Semantic Structure Matching Recommendation Algorithm
Acoustic Events Detection Using MFCC and MPEG-7 Descriptors
Quality Assessment for a Licence Plate Recognition Task Based on a Video Streamed in Limited Networking Conditions
Automatic quality control of digital image content reconstruction schemes
Broadcast news audio classification using SVM binary trees
Analysis of Particular Iris Recognition Stages
Determining image quality requirements for recognition tasks in generalized public safety video applications: Definitions, testing, standardization, and current trends
INSTREET - Application for Urban Photograph Localization
Quantum cryptography - The analysis of security requirements
Implementation of the New Integration Model of Security and QoS for MANET to the OPNET
A new approach to high-capacity annotation watermarking based on digital fountain codes
A Novel JPEG Steganography Method Based on Modulus Function with Histogram Analysis
Hierarchical Multi-Agent System for Heterogeneous Data Integration
INCR  INDECT Multimedia Crawler
Performance of Basic Spectral Descriptors and MRMR Algorithm to the Detection of Acoustic Events
Towards Hardware Implementation of INDECT Block Cipher
Multi-camera Vehicle Tracking Using Local Image Features and Neural Networks
Video Watermarking Based on DPCM and Transformcoding Using Permutation Spectrum and QIM
Camera Angle Invariant Shape Recognition in Surveillance Systems
A Statistical Blind Image Steganalysis Based on Image Multi-classification
Integrating Applications Developed for Heterogeneous Platforms: Building an Environment for Criminal Analysts
A new symmetric block cipher based on key-dependent S-boxes
INACT  INDECT Advanced Image Cataloguing Tool
QoE as a Function of Frame Rate and Resolution Changes
Monitoring the quality of speech in the communication system BESIP
Brightness Correction and Stereovision Impression Based Methods of Perceived Quality Improvement of CCTV Video Sequences
Performance Measurements of Real Time Video Transmission from Car Patrol
Multiple Sound Sources Localization in Real Time Using Acoustic Vector Sensor
Vehicle Classification Based on Soft Computing Algorithms
Quality Assessment in Video Surveillance
Performance Evaluation of the Parallel Codebook Algorithm for Background Subtraction in Video Stream
A High-Capacity Annotation Watermarking Scheme
Fast Face Localisation Using AdaBoost Algorithm and Identification with Matrix Decomposition Methods
Detection of Moving Objects in Images Combined from Video and Thermal Cameras
A novel approach to adaptive image authentication
Recent Progress in Development of Language Model for Slovak LVCSR
Automated qualitative assessment of multi-modal distortions in digital images based on GLZ
Assessing Task-Based Video Quality  A Journey from Subjective Psycho-Physical Experiments to Objective Quality Models
Extensible Web Crawler  Towards Multimedia Material Analysis
Efficient Method for Content Reconstruction With Self-Embedding
Face Detection using Color based Skin Localization and Facial Features Extraction
Security Infrastructures: Towards the INDECT System Security
Verification of the Parameterization Methods in the Context of Automatic Recognition of Sounds Related to Danger
Resolving Conflicts in Object Tracking in Video Stream Employing Key Point Matching
One Approach of Using Key-Dependent S-BOXes in AES
Quantum Cryptography Protocol Simulator
A novel method of image steganography in DWT domain
A scheme for censorship of sensitive image content with high-quality reconstruction ability
Detecting Predatory Behaviour from Online Textual Chats
Classification of video sequences into specified Generalized Use Classes of target size and lighting level
SIP Registration Burst Load Test
Comparison of Different Feature Types for Acoustic Event Detection System
Multicriteria Metadata Mechanisms for Fast and Reliable Searching of People Using Databases with Unreliable Records
Evolutionary Tuning of Compound Image Analysis Systems for Effective License Plate Recognition
Redefining ITU-T P.912 Recommendation Requirements for Subjects of Quality Assessments in Recognition Tasks
Analysis of Malware Network Activity

@_date: 2013-11-06 09:56:15
@_author: Eugen Leitl 
@_subject: fuck these guys 
Mike Hearn Shared publicly  -  Yesterday 10:30 AM The packet capture shown in these new NSA slides shows internal database
replication traffic for the anti-hacking system I worked on for over two
years. Specifically, it shows a database recording a user login as part of
this system: Recently  +Brandon Downey , a colleague of mine on the Google security team,
said (after the usual disclaimers about being personal opinions and not
speaking for the firm which I repeat here) - "fuck these guys":  I now join him in issuing a giant Fuck You to the people who made these
slides. I am not American, I am a Brit, but it's no different - GCHQ turns
out to be even worse than the NSA. We designed this system to keep criminals out . There's no ambiguity here.
The warrant system with skeptical judges, paths for appeal, and rules of
evidence was built from centuries of hard won experience. When it works, it
represents as good a balance as we've got between the need to restrain the
state and the need to keep crime in check. Bypassing that system is illegal
for a good reason . Unfortunately we live in a world where all too often, laws are for the little
people. Nobody at GCHQ or the NSA will ever stand before a judge and answer
for this industrial-scale subversion of the judicial process. In the absence
of working law enforcement,  we therefore do what internet engineers have
always done - build more secure software. The traffic shown in the slides
below is now all encrypted and the work the NSA/GCHQ staff did on
understanding it, ruined. Thank you Edward Snowden. For me personally, this is the most interesting
revelation all summer.
How we know the NSA had access to internal Google and Yahoo cloud data
732502Nico Lumma's profile photoIan Batterbee's profile photoAmber Yust's
profile photoKonrad Rudolph's profile photo 39 comments
Jeff WeissYesterday 2:46 PM+19 20 19
Until this article no one had mentioned that the intercepted traffic was on
leased fiber, not on the public internet.  That makes the cleartext
transmission seem like a less glaring error, I suppose I can see how it
wouldn't seem necessary.   In fact, anyone claiming in was necessary probably
would have been seen as paranoid until now. Still, encrypting data sent over the wire is not difficult.  Considering the
value of the data in question, and the number of parties who could access it
(at least two - the fiber owners and the government), it seems like a
worthwhile investment.   Lesson learned, I suppose.
Mike HearnYesterday 3:42 PM+42 3 2
I think the fact that Google uses private fiber has been well known for quite
a while actually. Just search for [google dark fiber] and you will find many
news stories discussing that, and it was mentioned off-hand in previous
stories as well (I think). Yes, that's pretty much it. Encryption was being worked on prior to Snowden
but it didn't seem like a high priority because there was no evidence it
would achieve anything useful, and it cost a lot of resources. Once it became
clear how badly compromised the fiber paths were, there was a crash effort to
encrypt everything. Re: "not difficult". I disagree. Doing end to end on the scale of Google is a
lot harder than it looks. Ignoring CPU capacity constraints, the entire thing
requires a large and complex key distribution and management infrastructure
(fortunately already present). Also lots of different protocols flow over our
wires, each one of which has to be handled.
Jeff WeissYesterday 4:15 PM+9 10 9
At Google's scale, everything is difficult.  I meant "not difficult" relative
to all the other feats they've pulled off. I can't say I blame them, really.  They haven't historically come across as
careless with their users' data - just the opposite in fact. If only the NSA manages to steal Google users' personal info, they're doing
relatively well.  There's always room for improvement.
Mike HearnYesterday 4:16 PM+18 9 8
Right, sure. Compared to some other initiatives encrypting cross-dc links
wasn't a moonshot. Self driving cars definitely rate as harder :)
John A. TamplinYesterday 4:29 PM+18 9 8
I don't know in Google's case, but when I was at an ISP before, dark fiber
meant we owned the fiber in the ground and were responsible for terminating
it with our repeaters/routers/etc.  So, to tap it would require either
compromising the equipment we owned or someone physically digging up the
fiber, inserting a tap, and putting it back.  You could conceivably detect
such a tap with TDR, but especially if this happened under the cover of a
cable cut you might just assume the tap was an imperfect splice to repair the
cut.  So, I don't think it was unreasonable to assume that dark fiber was
"safe". When I came to Square, it seemed over the top that even connections between
services in the same datacenter were secured with mutual auth SSL -- it
doesn't seem so excessive now.
Jeffrey YunesYesterday 5:49 PM+14 5 4
I don't think this is a "big people vs. little people" thing. I'm little,
Google's big, and we're both on the same side of this. Rather, this is a
"government vs everyone else" thing.
Andree ChristaldiYesterday 6:05 PM+4 5 4
Shocking, disgusting stuff. As you said, laws only matter to common folk, not
the state. Good work Mike. Laurent GaffiYesterday 7:25 PM+1 2 1
Well said Mike, well said.
Trevor LoucksYesterday 7:57 PM+1 2 1
possible for Google,within the next few years, to do end to end encryption
for all its services, but not manage or store the keys? I would prefer if
everything was encrypted and decrypted locally and I stored the key how I saw
fit.  Using LastPass, hard copy paper, truecrypt container, or some other
mechanism. I realize this would completely obliterate any type of possible password
recovery. But man, a system like that would allow me to feel so much better
when using Gmail or Google Drive. I guess it would have to be offered as an option, because I don't doubt most
Google users would opt for easy usability instead of higher security. In the meantime I feel compelled to transfer my backups to places which offer
end to end encryption with keys that aren't stored by the service provider.
Jason BraddyYesterday 8:15 PM+6 7 6
+John A. Tamplin  It's possible to tap an optical cable without breaking it,
by bending it far enough that some of the light leaks out through a gap in
the jacket. This can be detected by looking for unexpected drops in the light
level via DOM, etc., and I believe that critical defense/intelligence network
paths do this already.
Jeff WeissYesterday 8:15 PM+1 2 1
+Trevor Loucks that would dramatically change Google's business model, since
they generally offer free services in exchange for collecting people's data. Most of the offerings where privacy is a concern, the best private service
wouldn't be a service at all.  It would just be software you run yourself.
Or maybe it would run on some cloud service, but the important point is that
the provider doesn't see your data or care about it, they just lease you some
computing capacity.
John A. TamplinYesterday 8:27 PM+1 2 1
+Trevor Loucks  In many cases that would mean the service couldn't operate -
for example, GMail couldn't communicate with other SMTP servers if Google
never had the decrypted message on its servers.  If you have a doc for
collaborative editing, how do multiple people get the same key?  You
certainly wouldn't have the ease of saying "share this document with the
following" and it just work. Besides that, decrypting in the web browser using JS is slow and prone to
other vulnerabilities.  It currently isn't practical for web-based services
to operate as you suggest.
John MardlinYesterday 8:30 PM
+Mike Hearn  Was this work  started before the most recent revelations made
it clear that this was mission critical?   I'm sure that implementing encryption on your scale is a massive challenge,
it seems counter intuitive that it could be finalized so quickly after these
revelations, regardless of whether or not the work had been begun already. Follow on: do you ever wish Edward Snowden would just give you everything you
needed to know right away so this could be stopped sooner? Would you try to
reach out and encourage that moving forward? Thanks for taking the time to be transparent and clarify to your users, while
you're undoubtedly insanely busy.
Ian BatterbeeYesterday 8:40 PM
+John A. Tamplin   Also worked at an ISP, for us, dark fibre was simply
something where bits you shoved in one end came out the other untouched. The
dark part referred more to the fact that the packet wouldn't congest with
other people's traffic on the way, and would typically be a leased service on
someone else's CWDM or DWDM network, though it could also be simple patching
with no equipment in the way.
Stephan BealYesterday 8:51 PM
Okay, now admit it: how many of you had to google "Sisyphus" at the end of
the article? ;) (i did!)
Nicolas FischerYesterday 9:51 PM+4 5 4
These assholes think they're above the law. Fuck them! Let's use bitcoin to defund them.
Amber YustYesterday 9:57 PM+3 4 3
+John Mardlin  Yes, the project was started well before Snowden. The pace
just got ramped up immensely in the past year or so.
Jeff WeaverYesterday 10:57 PM+3 4 3
quite a post for bonfire day Guy would be proud :-)
Mike HearnYesterday 11:39 PM+13 4 3
Nobody knows how to build services like the ones Google provides but where
the service provider is blind to the traffic. It's not as simple as "Google
makes money off ads so they don't want to change things". Ad-funded services are actually a good thing from a privacy perspective! A
lot of people and media commentators don't realise this. The alternative to
advertising is direct payment by end users for a service. Unfortunately,
there are no ways to pay someone for something online anonymously. The
closest is Bitcoin but it's still very young and immature, most people can't
use it. So if the dominant paradigm for Google services was that you paid for
them, you'd pay for them with a credit card and then anonymous accounts would
be impossible, we'd always know exactly who you were. Even if we couldn't
read the message traffic, we would still know immediately and automatically
that Edward Snowden of BAH Hawaii had sent a message to Glenn Greenwald of
the Guardian, which is obviously of great interest to the NSA. You don't need
to be a genius to guess what a message from a high-clearance member of NSA
staff to a journalist might say. All you need to know is that they're
communicating at all. Currently though, anyone can sign up for a webmail account and provide any
bogus name they like (and people do). Neither the webmail provider nor the
advertisers know who a user really is, nor do they care. That's a pretty
decent situation to be in. Anyway, although I'd love it to be different, there aren't any viable
alternatives to the way cloud services operate today. These things either get
fixed legislatively, or they don't. Cryptographers are inventing lots of
really amazing technology that might one day make a truly private p2p cloud
possible, but those techniques are probably decades away from being
competitive (if they ever are).
Jeroen van Gelderen1:03 AM+3 4 3
+Mike Hearn  "These things either get fixed legislatively, or they don't." Then they won't. The TLAs will ignore the laws and lie about it until caught.
Then do it again.
Lauren Weinstein2:13 AM+12 3 2
I've had quite  a few people ask why I haven't seemed to be more upset
publicly about all the recent NSA and other surveillance disclosures. It's
real simple -- there has been nothing disclosed that I (and many others)
haven't assumed was going on at the hand of every capable surveillance org
around the world for decades, one way or another. This sort of behavior goes
back to the dawn of written communications -- tech has just made it easier in
some ways (by concentrating flows and making storage so cheap) and harder in
other ways (by providing means for robust encryption, when it's used). And recent history (that is, some decades) speaks clearly to the following.
No matter what the politicians tell you, not matter what any countries'
agencies say, there will be no substantive long-term change in these
practices. Opportunistic gathering of all data they can get their hands on
will continue, especially if it can be declared to be foreign or
international in nature and so not subject to purely domestic restrictions
(when those exist).
At the best, we can hope for a bit more oversight (at least in the short
term) and push hard for more transparency so that companies like Google can
explain to the public what really happens in terms of data demands from
government, and not be faced with when did you stop beating your wife? no-win
situations where hyperbolic, false accusations can't even be legally refuted. Above all from a practical standpoint, it has to be encrypt, encrypt, encrypt

@_date: 2013-11-06 10:40:17
@_author: Eugen Leitl 
@_subject: Open phones for privacy/anonymity applications, Guardian 
IIRC the only way to run a FLOSS GSM stack is by way of SDR (not exactly
pocket-sized), unless you can reverse-engineer the baseband firmware blob.
The most interesting news in SDR lately has been

@_date: 2013-11-13 09:54:09
@_author: Eugen Leitl 
@_subject: The second operating system hiding in every mobile phone 
The second operating system hiding in every mobile phone
posted by Thom Holwerda	 on Tue 12th Nov 2013 23:06 UTC
I've always known this, and I'm sure most of you do too, but we never really
talk about it. Every smartphone or other device with mobile communications
capability (e.g. 3G or LTE) actually runs not one, but two operating systems.
Aside from the operating system that we as end-users see (Android, iOS,
PalmOS), it also runs a small operating system that manages everything
related to radio. Since this functionality is highly timing-dependent, a
real-time operating system is required.
This operating system is stored in firmware, and runs on the baseband
processor. As far as I know, this baseband RTOS is always entirely
proprietary. For instance, the RTOS inside Qualcomm baseband processors (in
this specific case, the MSM6280) is called AMSS, built upon their own
proprietary REX kernel, and is made up of 69 concurrent tasks, handling
everything from USB to GPS. It runs on an ARMv5 processor.
The problem here is clear: these baseband processors and the proprietary,
closed software they run are poorly understood, as there's no proper peer
review. This is actually kind of weird, considering just how important these
little bits of software are to the functioning of a modern communication
device. You may think these baseband RTOS' are safe and secure, but that's
not exactly the case. You may have the most secure mobile operating system in
the world, but you're still running a second operating system that is poorly
understood, poorly documented, proprietary, and all you have to go on are
Qualcomm's Infineon's, and others' blue eyes.
The insecurity of baseband software is not by error; it's by design. The
standards that govern how these baseband processors and radios work were
designed in the '80s, ending up with a complicated codebase written in the
'90s - complete with a '90s attitude towards security. For instance, there is
barely any exploit mitigation, so exploits are free to run amok. What makes
it even worse, is that every baseband processor inherently trusts whatever
data it receives from a base station (e.g. in a cell tower). Nothing is
checked, everything is automatically trusted. Lastly, the baseband processor
is usually the master processor, whereas the application processor (which
runs the mobile operating system) is the slave.
So, we have a complete operating system, running on an ARM processor, without
any exploit mitigation (or only very little of it), which automatically
trusts every instruction, piece of code, or data it receives from the base
station you're connected to. What could possibly go wrong?
With this in mind, security researcher Ralf-Philipp Weinmann of the
University of Luxembourg set out to reverse engineer the baseband processor
software of both Qualcomm and Infineon, and he easily spotted loads and loads
of bugs, scattered all over the place, each and every one of which could lead
to exploits - crashing the device, and even allowing the attacker to remotely
execute code. Remember: all over the air. One of the exploits he found
required nothing more but a 73 byte message to get remote code execution.
Over the air.
You can do some crazy things with these exploits. For instance, you can turn
on auto-answer, using the Hayes command set. This is a command language for
modems designed in 1981, and it still works on modern baseband processors
found in smartphones today (!). The auto-answer can be made silent and
invisible, too.
While we can sort-of assume that the base stations in cell towers operated by
large carriers are "safe", the fact of the matter is that base stations are
becoming a lot cheaper, and are being sold on eBay - and there are even open
source base station software packages. Such base stations can be used to
target phones. Put a compromised base station in a crowded area - or even a
financial district or some other sensitive area - and you can remotely turn
on microphones, cameras, place rootkits, place calls/send SMS messages to
expensive numbers, and so on. Yes, you can even brick phones permanently.
This is a pretty serious issue, but one that you rarely hear about. This is
such low-level, complex software that I would guess very few people in the
world actually understand everything that's going on here.
That complexity is exactly one of the reasons why it's not easy to write your
own baseband implementation. The list of standards that describe just GSM is
unimaginably long - and that's only GSM. Now you need to add UMTS, HSDPA, and
so on, and so forth. And, of course, everything is covered by a ridiculously
complex set of patents. To top it all off, communication authorities require
baseband software to be certified.
Add all this up, and it's easy to see why every cellphone manufacturer just
opts for an off-the-shelf baseband processor and associated software. This
does mean that each and every feature and smartphone has a piece of software
that always runs (when the device is on), but that is essentially a black
box. Whenever someone does dive into baseband software, many bugs and issues
are found, which raises the question just how long this rather dubious
situation can continue.
It's kind of a sobering thought that mobile communications, the cornerstone
of the modern world in both developed and developing regions, pivots around
software that is of dubious quality, poorly understood, entirely proprietary,
and wholly insecure by design.

@_date: 2013-11-18 11:26:02
@_author: Eugen Leitl 
@_subject: RetroShare 
You can run RS over Tor. In fact, IIRC RS is in Whonix.
RS could have profited from a less is more approach. E.g. running NNTP
could have allowed you to use standard clients. In general I'd much
prefer to connect with known (SMTP, IMAP) protocols to localhost rather
than poking an unstable, monolithic blob with usability from hell.

@_date: 2013-11-21 12:29:58
@_author: Eugen Leitl 
@_subject: Exclusive: Inside America's Plan to Kill Online Privacy Rights 
Exclusive: Inside America's Plan to Kill Online Privacy Rights Everywhere
Posted By Colum Lynch   Wednesday, November 20, 2013 - 6:10 PM     Share
The United States and its key intelligence allies are quietly working behind
the scenes to kneecap a mounting movement in the United Nations to promote a
universal human right to online privacy, according to diplomatic sources and
an internal American government document obtained by The Cable.
The diplomatic battle is playing out in an obscure U.N. General Assembly
committee that is considering a proposal by Brazil and Germany to place
constraints on unchecked internet surveillance by the National Security
Agency and other foreign intelligence services. American representatives have
made it clear that they won't tolerate such checks on their global
surveillance network. The stakes are high, particularly in Washington --
which is seeking to contain an international backlash against NSA spying --
and in Brasilia, where Brazilian President Dilma Roussef is personally
involved in monitoring the U.N. negotiations.
The Brazilian and German initiative seeks to apply the right to privacy,
which is enshrined in the International Covenant on Civil and Political
Rights (ICCPR), to online communications. Their proposal, first revealed by
The Cable, affirms a "right to privacy that is not to be subjected to
arbitrary or unlawful interference with their privacy, family, home, or
correspondence." It notes that while public safety may "justify the gathering
and protection of certain sensitive information," nations "must ensure full
compliance" with international human rights laws. A final version the text is
scheduled to be presented to U.N. members on Wednesday evening and the
resolution is expected to be adopted next week.
A draft of the resolution, which was obtained by The Cable, calls on states
to "to respect and protect the right to privacy," asserting that the "same
rights that people have offline must also be protected online, including the
right to privacy." It also requests the U.N. high commissioner for human
rights, Navi Pillay, present the U.N. General Assembly next year with a
report on the protection and promotion of the right to privacy, a provision
that will ensure the issue remains on the front burner.
Publicly, U.S. representatives say they're open to an affirmation of privacy
rights. "The United States takes very seriously our international legal
obligations, including those under the International Covenant on Civil and
Political Rights," Kurtis Cooper, a spokesman for the U.S. mission to the
United Nations, said in an email. "We have been actively and constructively
negotiating to ensure that the resolution promotes human rights and is
consistent with those obligations."
But privately, American diplomats are pushing hard to kill a provision of the
Brazilian and German draft which states that "extraterritorial surveillance"
and mass interception of communications, personal information, and metadata
may constitute a violation of human rights. The United States and its allies,
according to diplomats, outside observers, and documents, contend that the
Covenant on Civil and Political Rights does not apply to foreign espionage.
In recent days, the United States circulated to its allies a confidential
paper highlighting American objectives in the negotiations, "Right to Privacy
in the Digital Age -- U.S. Redlines." It calls for changing the Brazilian and
German text so "that references to privacy rights are referring explicitly to
States' obligations under ICCPR and remove suggestion that such obligations
apply extraterritorially." In other words: America wants to make sure it
preserves the right to spy overseas.
The U.S. paper also calls on governments to promote amendments that would
weaken Brazil's and Germany's contention that some "highly intrusive" acts of
online espionage may constitute a violation of freedom of expression.
Instead, the United States wants to limit the focus to illegal surveillance

@_date: 2013-11-22 16:17:52
@_author: Eugen Leitl 
@_subject: Users ID'ed through typing, mouse movements 
Users ID'ed through typing, mouse movements
By Darren Pauli on Nov 22, 2013 2:16 PM
Continuous authentication app created from DARPA research.
Researchers have built a continuous authentication platform that can
accurately identify users based on their typing patterns.
A series of 90 minute typing tests carried out on 2000 people at Iowa State
University found users could be identified with a half percent margin of
error based on the way they hit keys.
The work has been spun into an application that could continuously
authenticate users and lock accounts if another person jumped on the computer
resulting in irregularities being detected. (pdf)
Uniquely syncopated mouse and keyboard patterns made it possible to identify
users, Iowa State University associate professor Morris Chang said.
These pauses between words, searches for unusual characters and spellings of
unfamiliar words, all have to do with our past experiences, our learning
experiences, Chang said. And so we call them cognitive fingerprints which
manifest themselves in typing rhythms.
The system can see if the same person or an imposter is coming in to hijack
the computer."
The year-long research run together with electrical engineering students
Terry Fang, Kuan-Hsing Ho and Danny Shih received a half a million dollar
grant from the US Defense Advanced Research Projects Agency which sought to
discover if continuous authentication was possible.
It was now being extended to capture mouse movements and touch inputs from
mobile devices with an additional $1.76 million dollars from the agency over
two years.
Copyright  SC Magazine, Australia

@_date: 2013-11-26 08:09:50
@_author: Eugen Leitl 
@_subject: bitcoin as a global medium of exchange (was Re: Interesting take 
There are scaling issues in Bitcoin which can be addressed in
a successor that is not a mere copycat with no added value.
Some of the issues might be even fixed as time passes, and
there's sufficient incentive.

@_date: 2013-11-26 13:05:46
@_author: Eugen Leitl 
@_subject: bitcoin as a global medium of exchange (was Re: Interesting take 
Moore's law has unfortunately recently ran into financial scaling limits,
which are slowing doubling times (estimate from 18 months to three years
at the moment) with physical scaling limits close to follow (somewhen
shortly below 5 nm).
Of course current ASICs are far removed from cutting edge. Another
issue is blockchain storage (NOR flash is also pretty finished, HDD
area density has stalled recently, but might resume scaling, at least
for a while) and availability of network bandwidth. You can buy 10 Gbit/s
close to the backbone, but it's beyond affordability for most people.

@_date: 2013-11-27 12:01:58
@_author: Eugen Leitl 
@_subject: bitcoin as a global medium of exchange (was Re: Interesting take 
Transactions are in a global ledger. You might not be able
to link warm bodies to a specific account directly, but indirectly (especially, if they engage in transactions,
or want to convert their currency). This is more difficult with banknotes, even if you have the serial numbers on record. Banknotes do not globally broadcast their current location.
This is the tradeoff of having a practical system. I personally
think that anonymous cash is orthogonal to the digital cash issue.
It can be done in a different system, or use an anonymization layer
like Tor, I2P or cjdns operates on top of TCP/IP.

@_date: 2013-10-01 13:30:25
@_author: Eugen Leitl 
@_subject: Surveillance 
It's Six Eyes, as Sweden is also part of the big vacuum, due to
special geography.

@_date: 2013-10-01 13:32:46
@_author: Eugen Leitl 
@_subject: [tor-relays] Relay security, re: local network 
Hash: SHA1
That reminds me of a question I've been meaning to ask lately...
Has anyone tried running Tor on top of OSv (
As I understand it, OSv is an ultra-small OS which is Linux
API-compatible and designed for running a single app only atop a
virtualization stack.  For example, it should, in theory, be possible
to run the Tor daemon within a copy of OSv, that would be the only
application running inside of that VM, and it should be running like
greased lightning because it would be the only process running in that VM.
Granted, it is fairly new so I do not believe anyone has done any
serious security analysis of OSv, but it seems like it would be an
ideal candidate for a very high performance Tor node.

@_date: 2013-10-01 16:27:33
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] homomorphic coin value (validatable but 
Thanks for providing the impetus to write down the current state, the
efficient version of which I only figured out a few days ago :)
I have been researching this for a few months on and off, because it seems
like an interesting construct in its own right, a different aspect of
payment privacy (eg for auditable but commercial sensistive information) but
also that other than its direct use it may enable some features that we have
not thought of yet.
I moved it to bitcointalk:
Its efficient finally (after many dead ends): approximately 2x cost of
current in terms of coin size and coin verification cost, however it also
gives some perf advantages back in a different way - necessary changes to
schnorr (EC version of Schnorr based proofs) allow n of n multiparty sigs,
or k of n multiparty sigs for the verification cost and signature size of
one pair of ECS signatures, for n > 2 its a space and efficiency improvement
over current bitcoin.

@_date: 2013-10-01 16:58:00
@_author: Eugen Leitl 
@_subject: [cryptography] The Compromised Internet 
Hash: SHA1
If enough hams (or one sufficiently angry lone ham operator) decide
that this is a problem they'll organize a turkey hunt to triangulate
the operator(s) and politely ask them to stop before the feds get
called in.  The thinking behind this seems to be that the amateur
community has been graciously granted a small portion of the RF
spectrum to experiment with.  People (licensed hams or otherwise) who
do specifically prohibited things within the amateur bands (like
transmitting encrypted traffic or undocumented digital protocols
(which may be indistinguishable from encrypted traffic)) can get some
or all of the amateur band taken away.  A lot of time and effort are
spent every year by ham operators who don't want this, that, or the
other sliver of the amateur band reassigned away from amateur use, and
someone doing something dodgy within those spectra could have
disasterous consequences.
When Project Byzantium was adding amateur radio support for ISC
milestone  these regulations were noted and discussed at length
during initial reasearch.  We also spoke with the ARRL during
development, which expressed similar sentiments about crypto in the
amateur bands (and passing traffic from unlicensed network users over
the amateur band, incidentally).
That would probably fall under jamming, which is definitely against
ham ethics.
The hams I've spoken to seem to, but they also seem to fall into the
camp of "It's on the amateur bands, so if it's something I'd want to
encrypt I'm not going to talk about it while chewing the rag anyway."

@_date: 2013-10-07 10:02:01
@_author: Eugen Leitl 
@_subject: [tor-talk] Silk Road taken down by FBI 
We know that Freedom Hosting platform was compromised, and
dropped malware via a known vulnerability in the TBB.
We do not know how exactly TSR was taken down.
There are reasons to suspect that the official story
might be a parallel construct.
The rise in Tor traffic well predates the events, and seems
to be entirely attributable to C&C traffic of a botnet.

@_date: 2013-10-07 11:25:43
@_author: Eugen Leitl 
@_subject: [tor-talk] Silk Road taken down by FBI 
Let's say you run a piece of buggy PHP code as a hidden service, on a mass hoster allowing easy signups and installation
of own code, with no hard separation of service hosted, and possibly not even firewall the VM traffic, forcing it through Tor.
While it's possible they knew the physical host already,
there are certainly far easier ways to nail your ass, given
the above.
It would be interesting to post a hidden service with actionable
content as a honeypot with everything done right, to see what the parallel construct story would emerge. No, I'm not volunteering.

@_date: 2013-10-07 11:37:56
@_author: Eugen Leitl 
@_subject: Analysis of Silk =?utf-8?B?Um9hZOKAmQ==?= =?utf-8?Q?s?= Historical 
Analysis of Silk Roads Historical Impact on Bitcoin
Oct 3, 2013 Posted By Jonathan Stacke In Featured, News	 Tagged Bitcoin,
Price, Silk Road, Volume	 Comments 11
Silk Road, the online drug bazaar that has eluded authorities and been
ingrained in the bitcoin narrative for years, was shut down yesterday. Ross
Ulbricht was named in the court documents outlining Silk Roads activities,
as were a number of key data points that offer insights into the impact the
worlds most infamous retail website has had on bitcoin.
Ulbricht was caught as a result of human error and excessive risks related to
physical delivery of false identification being delivered to his home address
in San Francisco from Canada. After tracking the package, authorities found
their way to Ulbricht and were able to compile a significant case against him
(more details in the official complaint embedded below). Notably, it does not
appear he was tracked as the result of any underlying flaws with tor, used
for anonymous web browsing, or bitcoin, the only currency accepted on Silk
For years the cloaked narcotics website has found its way into
bitcoin-oriented conversations, but only now are the qualitative and
quantitative data points available to asses Silk Roads true impact on the
fledgling digital currency.
A History of Influence
Facts offered by federal prosecutors overlayed onto bitcoin trading data
tells a convincing story about the intertwined histories of bitcoin and Silk
Road. It appears that a significant portion of bitcoins early traction and
price gains can be traced directly to Silk Road, with that impact waning over
time, most dramatically in the past six months.
On December 30, 2010, bitcoin was traded at $0.30/BTC. The court documents
filed yesterday point to Silk Roads first known publicity occurring via
posts from Ulbricht on internet forums and an explanatory WordPress page
beginning on January 27, 2011. Bitcoin tripled in value, reaching parity with
USD, just two weeks later on February 8.
early 2011
Bitcoin then traded between between $0.65 and $0.80 for the next two months
until interest was reignited by coverage in major publications, including
TIME Magazine and The New York Times. In the weeks following the NYC piece,
bitcoin prices and volume exploded, drawing significant attention from the
media. Notably, Gawker broke a story about the Silk Road itself, pushing up
the last gain of one of bitcoins early bubbles.
As bitcoin reached a remarkable 100x year-to-date growth at $30/BTC on June
7, the relationship between Silk Road and bitcoin would see its first true
test. On June 8, 2011, Senators Charles Shumer and Joe Manchin wrote a letter
to Attorney General Eric Holder, urging him to investigate bitcoin for its
relationship to online narcotics purchases, as well as urge [Holder] to take
immediate action and shut down the Silk Road network. Bitcoin plunged 66% to
$10 over the next three days, trending downward to $2 by November 2011. It
would seem that in 2011, direct use of bitcoin on Silk Road or speculators on
its adoption comprised between 66% and 93% of the currencys value.
2011 bubble
Over the next few months as the calendar rolled over into 2012, once again
coverage from a number of important press outlets like TIME and Wired rallied
enthusiasm for bitcoin, pushing prices up to a stabilized $5 by February.
According to the complaint released yesterday, that is also around the time
Ulbricht began to add features to Silk Road, including the establishment of a
forum and stealth mode for top vendors.
In June of 2012, bitcoin began another rally. By this time, infrastructure in
the bitcoin world had begun to increase dramatically, including the first
bitcoin ASIC companies to begin advertising products and new exchanges being
formed. Gawker ran another story about Silk Road in July 2012, which appears
to have had positive impact on bitcoin prices, though not nearly to the
extent it did previously. The months following proved to be highly
transitional, with Bitcoin Foundation putting a public face on the new
industry and early 2013 seeing the European financial troubles that led to
the climb to $260 in April of this year and unprecedented global attention.
Just a few weeks later the markets would see another test of the relationship
between Bitcoin and Silk Road. Between April 24 and May 1, Silk Road suffered
a series of DDoS attacks that sent bitcoin prices sliding downwards. The
negative price action was timed perfectly with the attacks, indicating a
strong relationship. While the drop was significant at 35% initially before
leveling off around a 25% loss  it was notably lighter than the impact of
negative Silk Road news previously.
april 2013 ddos
Looking at the impact from the most recent news, we see a similar pattern
emerging. Despite being the definitive end of Silk Road, with its founder
detained and the logos of federal agencies plastered across the site, the
impact on bitcoin prices was relatively muted. On the initial news break
USD/BTC rates fell 20-35%, depending on the exchange, before settling around
10-15% lower than before the news shortly thereafter.
October 2013
Quantifiable Impact
Also contained within the filings were a number of aggregate statistics about
Silk Roads transactional volume that shed significant light on how much of
the bitcoin market was built around the companys narcotics trade.
Specifically, the complaint states that sites total revenue between February
2011 and July 2013 was 9.5 million bitcoin. Over that same period
approximately 225 million bitcoin were transacted over the block chain, of
which the 9.5 million in Silk Road sales accounted for just 4%.
Similarly, total exchange volume over the same period was roughly 75 million
bitcoin, making Silk Road approximately 12% of total volume. This, of course,
assumes all bitcoins used for purchases on the site were purchased on
exchanges rather than obtained from in person transactions, mining, earnings,
gifts or reused by sellers to purchase from others on the site.
Important to remember is that these figures are aggregate stats over two
years of revenue. Unless fiat-equivalent sales on Silk Road were growing
exponentially alongside bitcoin exchange rates over the past two years, this
also means the bitcoin volume listed in the filing is front loaded into the
periods when more bitcoins were required for the same fiat equivalent
purchasing power. This coincides with the market reactions that also
indicates a significantly reduced importance of Silk Road on the bitcoin
Looking Forward
The bitcoin markets as a whole seem well poised to move forward. An unknown
has been removed from the ecosystem, but a number of concerns remain.
While bitoin will likely recover, there are probably more than a few
concerned bitcoin users right now. The contents of the filing pertained
almost exclusively to the charges against Ulbricht, but give little insight
into what other information was obtained. Whether or not home addresses or
bitcoin addresses of Silk Road users were retained in some way is still
unclear and the extent to which such matters are prosecutable has yet to be
There is also a strong likelihood of copycat sites arising. While the recent
action may deter US citizens, Silk Road was known for its global reach,
meaning an aspiring entrepreneur could run a similar company from anywhere in
the world. The business model is proven and the technology still apparently
sound and repeatable. The downfall was related to human error, which was
clearly outlined in the filing, creating an advanced watchlist for the next
person to avoid. The barriers to entry are remarkably low and now paired with
a known surplus of both demand and supply in the marketplace.
While Silk Roads early impact on digital currency appears to have been quite
significant, any new participant at this stage will likely encounter the same
decreasing importance to the broader bitcoin ecosystem.

@_date: 2013-10-07 12:43:36
@_author: Eugen Leitl 
@_subject: Russia to monitor 'all communications' at Winter Olympics in Sochi 
Russia to monitor 'all communications' at Winter Olympics in Sochi
Exclusive: Investigation uncovers FSB surveillance system  branded 'Prism on
steroids'  to listen to all athletes and visitors
Shaun Walker in Moscow
The Guardian, Sunday 6 October 2013 15.31 BST
Sochi, venue for 2014 Winter Olympics
The Black Sea resort of Sochi has apparently been wired so that the FSB can
log all visitor communications. Photograph: Ignat Kozlov/AP
Athletes and spectators attending the Winter Olympics in Sochi in February
will face some of the most invasive and systematic spying and surveillance in
the history of the Games, documents shared with the Guardian show.
Russia's powerful FSB security service plans to ensure that no communication
by competitors or spectators goes unmonitored during the event, according to
a dossier compiled by a team of Russian investigative journalists looking
into preparations for the 2014 Games.
In a ceremony on Red Square on Sunday afternoon, the president, Vladimir
Putin, held the Olympic flame aloft and sent it on its epic journey around
the country, saying Russia and its people had always been imbued with the
qualities of "openness and friendship", making Sochi the perfect destination
for the Olympics.
But government procurement documents and tenders from Russian communication
companies indicate that newly installed telephone and internet spying
capabilities will give the FSB free rein to intercept any telephony or data
traffic and even track the use of sensitive words or phrases mentioned in
emails, webchats and on social media.
The journalists, Andrei Soldatov and Irina Borogan, who are experts on the
Russian security services, collated dozens of open source technical documents
published on the Zakupki government procurement agency website, as well as
public records of government oversight agencies. They found that major
amendments have been made to telephone and Wi-Fi networks in the Black Sea
resort to ensure extensive and all-permeating monitoring and filtering of all
traffic, using Sorm, Russia's system for intercepting phone and internet
Putin at a Sochi Olympic flame ceremony in Moscow on Sunday. Photograph: Ivan
The Sorm system is being modernised across Russia, but particular attention
has been paid to Sochi given the large number of foreign visitors expected
next year. Technical specifications set out by the Russian state telecoms
agency also show that a controversial technology known as deep packet
inspection, which allows intelligence agencies to filter users by particular
keywords, is being installed across Russia's networks, and is required to be
compatible with the Sorm system.
"For example you can use the keyword Navalny, and work out which people in a
particular region are using the word Navalny," says Soldatov, referring to
Alexei Navalny, Russia's best-known opposition politician. "Then, those
people can be tracked further."
Ron Deibert, a professor at the University of Toronto and director of Citizen
Lab, which co-operated with the Sochi research, describes the Sorm amendments
as "Prism on steroids", referring to the programme used by the NSA in the US
and revealed to the Guardian by the whistleblower Edward Snowden. "The scope
and scale of Russian surveillance are similar to the disclosures about the US
programme but there are subtle differences to the regulations," says Deibert.
"We know from Snowden's disclosures that many of the checks were weak or
sidestepped in the US, but in the Russian system permanent access for Sorm is
a requirement of building the infrastructure."
"Even as recently as the Beijing Olympics, the sophistication of surveillance
and tracking capabilities were nowhere near where they are today."
Gus Hosein, executive director of Privacy International, which also
co-operated with the research, said: "Since 2008, more people are travelling
with smartphones with far more data than back then, so there is more to spy
Wary of Sorm's capabilities, earlier this year a leaflet from the US state
department's bureau of diplomatic security warned anyone travelling to the
Games to be extremely cautious with communications.
"Business travellers should be particularly aware that trade secrets,
negotiating positions, and other sensitive information may be taken and
shared with competitors, counterparts, and/or Russian regulatory and legal
entities," the document reads. The advice contains an extraordinary list of
precautions for visitors who wish to ensure safe communications, such as
removing batteries from phones when not in use and only travelling with
"clean" devices.
Soldatov and Borogan have discovered that the FSB has been working since 2010
to upgrade the Sorm system to ensure it can cope with the extra traffic
during the Games. All telephone and ISP providers have to install Sorm boxes
in their technology by law, and once installed, the FSB can access data
without the provider ever knowing, meaning every phone call or internet
communication can be logged. Although the FSB technically requires a warrant
to intercept a communication, it is not obliged to show it to anyone.
Tellingly, the FSB has appointed one of its top counterintelligence chiefs,
Oleg Syromolotov, to be in charge at Sochi: security will thus be overseen by
someone who has spent his career chasing foreign spies rather than
Another target may well be gay rights, likely to be one of the biggest issues
of the Games. Putin has said that competitors who wear rainbow pins, for
example, will not be arrested under the country's controversial new law that
bans "homosexual propaganda". However, it is likely that any attempts to
stage any kind of rally or gathering to support gay rights will be ruthlessly
broken up by police, as has been the case on numerous occasions in Russian
cities in the past. Using DPI, Russian authorities will be able to identify,
tag and follow all visitors to the Olympics, both Russian and foreign, who
are discussing gay issues, and possibly planning to organise protests.
"Athletes may have particular political views, or they may be openly gay,"
says Deibert. "I think given recent developments in Russia, we have to be
worried about these issues."
At a rare FSB press conference this week, an official, Alexei Lavrishchev,
denied security and surveillance at the Games would be excessive, and said
that the London Olympics featured far more intrusive measures. "There, they
even put CCTV cameras in, excuse me for saying it, the toilets," said
Lavrishchev. "We are not taking this kind of measure."
The FSB did not respond to a request for comment from the Guardian, while a
spokesperson for the Sochi Olympics referred all requests to the security
services. But Russian authorities often express a belief that NGOs working on
human rights and other issues have subversive agendas dictated from abroad,
and the FSB apparently feels that with so many potentially dangerous
foreigners descending on the Black Sea resort for the Olympics, it has a duty
to keep an eye on them.
In the end, the goal is overarching, but simple, says Soldatov: "Russian
authorities want to make sure that every connection and every move made
online in Sochi during the Olympics will be absolutely transparent to the
secret services of the country."

@_date: 2013-10-07 13:18:17
@_author: Eugen Leitl 
@_subject: [tor-talk] Freenet and hidden services 
Hash: SHA512
I consider Tahoe-LAFS to be the (current) best solution for this. It
provides a distributed data store, which can be used for hosting (with
a Javascript "web server"). I know Tahoe works with Tor via SOCKS but
I don't personally know of any active networks. Tahoe has been used in
I2P as a distributed data store for a long time, and there are several
"deepsites" hosted in it. We are actively working to make Tahoe
integrate better with Tor/I2P.
Zooko recently posted a *much* better summary of this:

@_date: 2013-10-07 13:55:36
@_author: Eugen Leitl 
@_subject: <nettime> A CEO who resisted NSA spying is out of prison. 
A good point. I deal with that by
alternative_order text/plain text/html text/enrichened
auto_view text/html
which calls links via /etc/mailcap
text/plain; less '%s'; needsterminal
text/html; /usr/bin/sensible-browser '%s'; description=HTML Text; nametemplate=%s.html
How exploitable is /usr/bin/links?

@_date: 2013-10-07 16:50:38
@_author: Eugen Leitl 
@_subject: interesting commercial cjdns project: Enigmabox 
Just came across  which is a commercial
project using cjdns/Hyperboria for transport and offers end to end encrypted VoIP and operates http (and more?) exits.
The hardware seems to be PCEngines ALIX. It doesn't ship
with Tor, but Tor can be used with it. Don't see any open
source, but users are getting root access on the system.

@_date: 2013-10-07 17:16:29
@_author: Eugen Leitl 
@_subject: Bruce Schneier on the good, old air gap 
Want to Evade NSA Spying? Dont Connect to the Internet
BY BRUCE SCHNEIER 10.07.13 6:30 AM
Photo: Ariel Zambelich / WIRED; Illustration: Ross Patton / WIRED
Since I started working with Snowdens documents, I have been using a number
of tools to try to stay secure from the NSA. The advice I shared included
using Tor, preferring certain cryptography over others, and using
public-domain encryption wherever possible.
I also recommended using an air gap, which physically isolates a computer or
local network of computers from the internet. (The name comes from the
literal gap of air between the computer and the internet; the word predates
wireless networks.)
But this is more complicated than it sounds, and requires explanation.
Since we know that computers connected to the internet are vulnerable to
outside hacking, an air gap should protect against those attacks. There are a
lot of systems that use  or should use  air gaps: classified military
networks, nuclear power plant controls, medical equipment, avionics, and so
Osama Bin Laden used one. I hope human rights organizations in repressive
countries are doing the same.
Air gaps might be conceptually simple, but theyre hard to maintain in
practice. The truth is that nobody wants a computer that never receives files
from the internet and never sends files out into the internet. What they want
is a computer thats not directly connected to the internet, albeit with some
secure way of moving files on and off.
But every time a file moves back or forth, theres the potential for attack.
And air gaps have been breached. Stuxnet was a U.S. and Israeli
military-grade piece of malware that attacked the Natanz nuclear plant in
Iran. It successfully jumped the air gap and penetrated the Natanz network.
Another piece of malware named agent.btz, probably Chinese in origin,
successfully jumped the air gap protecting U.S. military networks.
These attacks work by exploiting security vulnerabilities in the removable
media used to transfer files on and off the air gapped computers.
Bruce Schneier is a security technologist and author. His latest book is
Liars and Outliers: Enabling the Trust Society Needs to Survive.
Since working with Snowdens NSA files, I have tried to maintain a single
air-gapped computer. It turned out to be harder than I expected, and I have
ten rules for anyone trying to do the same:
1. When you set up your computer, connect it to the internet as little as
possible. Its impossible to completely avoid connecting the computer to the
internet, but try to configure it all at once and as anonymously as possible.
I purchased my computer off-the-shelf in a big box store, then went to a
friends network and downloaded everything I needed in a single session. (The
ultra-paranoid way to do this is to buy two identical computers, configure
one using the above method, upload the results to a cloud-based anti-virus
checker, and transfer the results of that to the air gap machine using a
one-way process.)
2. Install the minimum software set you need to do your job, and disable all
operating system services that you wont need. The less software you install,
the less an attacker has available to exploit. I downloaded and installed
OpenOffice, a PDF reader, a text editor, TrueCrypt, and BleachBit. Thats
all. (No, I dont have any inside knowledge about TrueCrypt, and theres a
lot about it that makes me suspicious. But for Windows full-disk encryption
its that, Microsofts BitLocker, or Symantecs PGPDisk  and I am more
worried about large U.S. corporations being pressured by the NSA than I am
about TrueCrypt.)
3. Once you have your computer configured, never directly connect it to the
internet again. Consider physically disabling the wireless capability, so it
doesnt get turned on by accident.
4. If you need to install new software, download it anonymously from a random
network, put it on some removable media, and then manually transfer it to the
air gapped computer. This is by no means perfect, but its an attempt to make
it harder for the attacker to target your computer.
5. Turn off all auto-run features. This should be standard practice for all
the computers you own, but its especially important for an air-gapped
computer. Agent.btz used autorun to infect U.S. military computers.
6. Minimize the amount of executable code you move onto the air-gapped
computer. Text files are best. Microsoft Office files and PDFs are more
dangerous, since they might have embedded macros. Turn off all macro
capabilities you can on the air-gapped computer. Dont worry too much about
patching your system; in general, the risk of the executable code is worse
than the risk of not having your patches up to date. Youre not on the
internet, after all.
7. Only use trusted media to move files on and off air-gapped computers. A
USB stick you purchase from a store is safer than one given to you by someone
you dont know  or one you find in a parking lot.
8. For file transfer, a writable optical disk (CD or DVD) is safer than a USB
stick. Malware can silently write data to a USB stick, but it cant spin the
CD-R up to 1000 rpm without your noticing. This means that the malware can
only write to the disk when you write to the disk. You can also verify how
much data has been written to the CD by physically checking the back of it.
If youve only written one file, but it looks like three-quarters of the CD
was burned, you have a problem. Note: the first company to market a USB stick
with a light that indicates a write operation  not read or write; Ive got
one of those  wins a prize.
9. When moving files on and off your air-gapped computer, use the absolute
smallest storage device you can. And fill up the entire device with random
files. If an air-gapped computer is compromised, the malware is going to try
to sneak data off it using that media. While malware can easily hide stolen
files from you, it cant break the laws of physics. So if you use a tiny
transfer device, it can only steal a very small amount of data at a time. If
you use a large device, it can take that much more. Business-card-sized
mini-CDs can have capacity as low as 30 MB. I still see 1-GB USB sticks for
10. Consider encrypting everything you move on and off the air-gapped
computer. Sometimes youll be moving public files and it wont matter, but
sometimes you wont be, and it will. And if youre using optical media, those
disks will be impossible to erase. Strong encryption solves these problems.
And dont forget to encrypt the computer as well; whole-disk encryption is
the best.
One thing I didnt do, although its worth considering, is use a stateless
operating system like Tails. You can configure Tails with a persistent volume
to save your data, but no operating system changes are ever saved. Booting
Tails from a read-only DVD  you can keep your data on an encrypted USB stick
 is even more secure. Of course, this is not foolproof, but it greatly
reduces the potential avenues for attack.
Yes, all this is advice for the paranoid. And its probably impossible to
enforce for any network more complicated than a single computer with a single
user. But if youre thinking about setting up an air-gapped computer, you
already believe that some very powerful attackers are after you personally.
If youre going to use an air gap, use it properly.
Of course you can take things further. I have met people who have physically
removed the camera, microphone, and wireless capability altogether. But
thats too much paranoia for me right now.

@_date: 2013-10-07 23:55:49
@_author: Eugen Leitl 
@_subject: Bruce Schneier on the good, old air gap 
Liberation Technologies That advice is not exactly targeted towards Jane Doe. Some people don't have mobile phones. Others leave them at home,
or remove the power pack when it matters.
No. You just need to buy an offline machine, e.g. a used notebook. Separation by air gap was SOP in the intelligence community before virtualization allowed to separate trust compartments in one machine.
I trust air gap much more than hypervisors.
I don't understand the problem. Bruce gave good basic opsec advice,
what's the problem with following it up in practice but to tamper-proof
against evil maid attacks?

@_date: 2013-10-08 17:15:50
@_author: Eugen Leitl 
@_subject: Feds Arrest Alleged Top Silk Road Drug Seller 
Feds Arrest Alleged Top Silk Road Drug Seller
Federal authorities last week arrested a Washington state man accused of
being one of the most active and sought-after drug dealers on the online
black market known as the Silk Road. Meanwhile, new details about the
recent coordinated takedown of the Silk Road became public, as other former
buyers and sellers on the fraud bazaar pondered who might be next and whether
competing online drug markets will move in to fill the void.
NOD's feedback from Silk Road buyers, according to the government. A complaint unsealed Oct. 2 by the U.S. District Court for the Western
District of Washington at Seattle alleges that Steven Lloyd Sadler, 40, of
Bellevue, Wash., used the nickname NOD on the Silk Road, and was among the
top one percent of sellers on the Silk Road, selling high-quality cocaine,
heroin and methamphetamine in small, individual-use amounts to hundreds of
buyers around the world.
Investigators with the FBI and U.S. Post Office inspectors say they tracked
dozens of packages containing drugs allegedly shipped by Sadler and a woman
who was living with him at the time of his arrest. Authorities tied Sadler to
the Silk Road after intercepting a package of cocaine and heroin destined for
an Alaskan resident. That resident agreed to cooperate with authorities in
the hopes of reducing his own sentence, and said hed purchased the drugs
from NOD via the Silk Road.
Agents in Seattle sought and were granted permission to place GPS tracking
devices on Sadlers car and that of his roommate, Jenna White, also charged
in this case. Investigators allege that the tracking showed the two traveled
to at least 38 post offices in the Seattle area during the surveillance
Interestingly, the investigators used the feedback on NODs Silk Road seller
profile to get a sense of the volume of drugs he sold. Much like eBay
sellers, merchants on the Silk Road are evaluated by previous buyers, who are
encouraged to leave feedback about the quality of the sellers goods and
services. According to the government, NOD had 1,400 reviews for individual
sales/purchases of small amounts of drugs, including: 2,269.5 grams of
cocaine, 593 grams of heroin and 105 grams of meth. The complaint notes that
these amounts dont count sales going back more than five months prior to the
investigation, when NOD first created his Silk Road vendor account.
Cryptome has published a copy of the complaint (PDF) against Sadler. A copy
of Sadlers case docket is here. NODs reputation on the Silk Road also was
discussed for several months on this Reddit thread.
Many readers of last weeks story on the Silk Road takedown have been asking
what is known about the locations of the Silk Road servers that were copied
by the FBI. Its still unclear how agents gained access to those servers, but
a civil forfeiture complaint released by the Justice Department shows that
they were aware of five, geographically dispersed servers that were
supporting the Silk Road, either by directly hosting the site and/or hosting
the Bitcoin wallets that the Silk Road maintains for buyers and sellers.
Two of those servers were located in Iceland, one in Latvia, another in
Switzerland, and apparently one in the United States. See the map above.
As if the subset of Bitcoin users who frequented the Silk Road already didnt
have enough to worry about, there are indications that the individual(s)
responsible for creating a competing Tor-based drug market  SheepMarketplace
 may have made some missteps that could make it easier for authorities to
discover the true location of that fraud bazaar as well. Check out this
Reddit thread for more on that.
Also, there are some indications that a Silk Road 2.0 is in the works, at
least according to DailyGadgetry.com. If that doesnt work out, perhaps
would-be future Dread Pirate Robertses will turn to Bitwasp, a budding Github
project which aims to provide open source code for setting up standalone
markets using Bitcoin.
I think what youre going to see is that a lot of me-too communities spring
up and get squished pretty quickly, said Nicholas Weaver, a researcher at
the International Computer Science Institute (ICSI) and at University of
California San Diego. Part of the reason why the Silk Road was so useful was
that it was so popular, and a half dozen smaller markets could be far less
efficient than these larger markets. But personally, Im betting well soon
see a fair number of them.
Finally, it seems a large number of Bitcoin users have been spending tiny
fractions of their coinage to send messages to the FBIs Bitcoin address on
Blockchain. Some of the love letters to the FBI are amusing, such as, All
your Bitcoins are belong to us, while others sound a defiant tone, including
this one: One star is born as another fades away. Which one will come next?
is my favorite riddle. Said a girl puffing rings in a dot, dot, dash haze.
No worry, No hurry. They cant stop the signal.
Update, Oct. 8, 2013: The BBC is reporting that four men have been arrested
in the U.K. for alleged drug offenses on the Silk Road, and that more arrests
are expected in the coming weeks. The BBC quotes the U.K. National Crime
Agency as saying such sites would are a key priority.

@_date: 2013-10-09 11:37:07
@_author: Eugen Leitl 
@_subject: Attacking Tor: how the NSA targets users' online anonymity 
(Use VM jails with amnesiac distros like Tails for daily browsing, separate security compartments using CubeOS and related, use air gap with USB sneakernet (using *nix with no USB autorun) to encrypt/decrypt and maintain sensitive information in general).
Attacking Tor: how the NSA targets users' online anonymity
Secret servers and a privileged position on the internet's backbone used to
identify users and attack target computers
Bruce Schneier
theguardian.com, Friday 4 October 2013 15.50 BST
Tor is a well-designed and robust anonymity tool, and successfully attacking
it is difficult. Photograph: Magdalena Rehova/Alamy
The online anonymity network Tor is a high-priority target for the National
Security Agency. The work of attacking Tor is done by the NSA's application
vulnerabilities branch, which is part of the systems intelligence
directorate, or SID. The majority of NSA employees work in SID, which is
tasked with collecting data from communications systems around the world.
According to a top-secret NSA presentation provided by the whistleblower
Edward Snowden, one successful technique the NSA has developed involves
exploiting the Tor browser bundle, a collection of programs designed to make
it easy for people to install and use the software. The trick identified Tor
users on the internet and then executes an attack against their Firefox web
The NSA refers to these capabilities as CNE, or computer network
The first step of this process is finding Tor users. To accomplish this, the
NSA relies on its vast capability to monitor large parts of the internet.
This is done via the agency's partnership with US telecoms firms under
programs codenamed Stormbrew, Fairview, Oakstar and Blarney.
The NSA creates "fingerprints" that detect http requests from the Tor network
to particular servers. These fingerprints are loaded into NSA database
systems like XKeyscore, a bespoke collection and analysis tool which NSA
boasts allows its analysts to see "almost everything" a target does on the
Using powerful data analysis tools with codenames such as Turbulence, Turmoil
and Tumult, the NSA automatically sifts through the enormous amount of
internet traffic that it sees, looking for Tor connections.
Last month, Brazilian TV news show Fantastico showed screenshots of an NSA
tool that had the ability to identify Tor users by monitoring internet
The very feature that makes Tor a powerful anonymity service, and the fact
that all Tor users look alike on the internet, makes it easy to differentiate
Tor users from other web users. On the other hand, the anonymity provided by
Tor makes it impossible for the NSA to know who the user is, or whether or
not the user is in the US.
After identifying an individual Tor user on the internet, the NSA uses its
network of secret internet servers to redirect those users to another set of
secret internet servers, with the codename FoxAcid, to infect the user's
computer. FoxAcid is an NSA system designed to act as a matchmaker between
potential targets and attacks developed by the NSA, giving the agency
opportunity to launch prepared attacks against their systems.
Once the computer is successfully attacked, it secretly calls back to a
FoxAcid server, which then performs additional attacks on the target computer
to ensure that it remains compromised long-term, and continues to provide
eavesdropping information back to the NSA.
Exploiting the Tor browser bundle
Tor is a well-designed and robust anonymity tool, and successfully attacking
it is difficult. The NSA attacks we found individually target Tor users by
exploiting vulnerabilities in their Firefox browsers, and not the Tor
application directly.
This, too, is difficult. Tor users often turn off vulnerable services like
scripts and Flash when using Tor, making it difficult to target those
services. Even so, the NSA uses a series of native Firefox vulnerabilities to
attack users of the Tor browser bundle.
According to the training presentation provided by Snowden,
EgotisticalGiraffe exploits a type confusion vulnerability in E4X, which is
an XML extension for Javascript. This vulnerability exists in Firefox 11.0 
16.0.2, as well as Firefox 10.0 ESR  the Firefox version used until recently
in the Tor browser bundle. According to another document, the vulnerability
exploited by EgotisticalGiraffe was inadvertently fixed when Mozilla removed
the E4X library with the vulnerability, and when Tor added that Firefox
version into the Tor browser bundle, but NSA were confident that they would
be able to find a replacement Firefox exploit that worked against version
17.0 ESR.
The Quantum system
To trick targets into visiting a FoxAcid server, the NSA relies on its secret
partnerships with US telecoms companies. As part of the Turmoil system, the
NSA places secret servers, codenamed Quantum, at key places on the internet
backbone. This placement ensures that they can react faster than other
websites can. By exploiting that speed difference, these servers can
impersonate a visited website to the target before the legitimate website can
respond, thereby tricking the target's browser to visit a Foxacid server.
In the academic literature, these are called "man-in-the-middle" attacks, and
have been known to the commercial and academic security communities. More
specifically, they are examples of "man-on-the-side" attacks.
They are hard for any organization other than the NSA to reliably execute,
because they require the attacker to have a privileged position on the
internet backbone, and exploit a "race condition" between the NSA server and
the legitimate website. This top-secret NSA diagram, made public last month,
shows a Quantum server impersonating Google in this type of attack.
The NSA uses these fast Quantum servers to execute a packet injection attack,
which surreptitiously redirects the target to the FoxAcid server. An article
in the German magazine Spiegel, based on additional top secret Snowden
documents, mentions an NSA developed attack technology with the name of
QuantumInsert that performs redirection attacks. Another top-secret Tor
presentation provided by Snowden mentions QuantumCookie to force cookies onto
target browsers, and another Quantum program to "degrade/deny/disrupt Tor
This same technique is used by the Chinese government to block its citizens
from reading censored internet content, and has been hypothesized as a
probable NSA attack technique.
The FoxAcid system
According to various top-secret documents provided by Snowden, FoxAcid is the
NSA codename for what the NSA calls an "exploit orchestrator," an
internet-enabled system capable of attacking target computers in a variety of
different ways. It is a Windows 2003 computer configured with custom software
and a series of Perl scripts. These servers are run by the NSA's tailored
access operations, or TAO, group. TAO is another subgroup of the systems
intelligence directorate.
The servers are on the public internet. They have normal-looking domain
names, and can be visited by any browser from anywhere; ownership of those
domains cannot be traced back to the NSA.
However, if a browser tries to visit a FoxAcid server with a special URL,
called a FoxAcid tag, the server attempts to infect that browser, and then
the computer, in an effort to take control of it. The NSA can trick browsers
into using that URL using a variety of methods, including the race-condition
attack mentioned above and frame injection attacks.
FoxAcid tags are designed to look innocuous, so that anyone who sees them
would not be suspicious. An example of one such tag [LINK REMOVED] is given
in another top-secret training presentation provided by Snowden.
There is no currently registered domain name by that name; it is just an
example for internal NSA training purposes.
The training material states that merely trying to visit the homepage of a
real FoxAcid server will not result in any attack, and that a specialized URL
is required. This URL would be created by TAO for a specific NSA operation,
and unique to that operation and target. This allows the FoxAcid server to
know exactly who the target is when his computer contacts it.
According to Snowden, FoxAcid is a general CNE system, used for many types of
attacks other than the Tor attacks described here. It is designed to be
modular, with flexibility that allows TAO to swap and replace exploits if
they are discovered, and only run certain exploits against certain types of
The most valuable exploits are saved for the most important targets.
Low-value exploits are run against technically sophisticated targets where
the chance of detection is high. TAO maintains a library of exploits, each
based on a different vulnerability in a system. Different exploits are
authorized against different targets, depending on the value of the target,
the target's technical sophistication, the value of the exploit, and other
In the case of Tor users, FoxAcid might use EgotisticalGiraffe against their
Firefox browsers.
FoxAcid servers also have sophisticated capabilities to avoid detection and
to ensure successful infection of its targets. One of the top-secret
documents provided by Snowden demonstrates how FoxAcid can circumvent
commercial products that prevent malicious software from making changes to a
system that survive a reboot process.
According to a top-secret operational management procedures manual provided
by Snowden, once a target is successfully exploited it is infected with one
of several payloads. Two basic payloads mentioned in the manual, are designed
to collect configuration and location information from the target computer so
an analyst can determine how to further infect the computer.
These decisions are made in part by the technical sophistication of the
target and the security software installed on the target computer; called
Personal Security Products or PSP, in the manual.
FoxAcid payloads are updated regularly by TAO. For example, the manual refers
to version 8.2.1.1 of one of them.
FoxAcid servers also have sophisticated capabilities to avoid detection and
to ensure successful infection of its targets. The operations manual states
that a FoxAcid payload with the codename DireScallop can circumvent
commercial products that prevent malicious software from making changes to a
system that survive a reboot process.
The NSA also uses phishing attacks to induce users to click on FoxAcid tags.
TAO additionally uses FoxAcid to exploit callbacks  which is the general
term for a computer infected by some automatic means  calling back to the
NSA for more instructions and possibly to upload data from the target
According to a top-secret operational management procedures manual, FoxAcid
servers configured to receive callbacks are codenamed FrugalShot. After a
callback, the FoxAcid server may run more exploits to ensure that the target
computer remains compromised long term, as well as install "implants"
designed to exfiltrate data.
By 2008, the NSA was getting so much FoxAcid callback data that they needed
to build a special system to manage it all.

@_date: 2013-10-10 10:36:44
@_author: Eugen Leitl 
@_subject: NSA data centre power surges & unknowns... 
You obviously have to consider not just the known unknowns, but also
unknown unknowns. FWIW, I much doubt they can factor large numbers with QC (if you want to make sure, do a lit review on QC,
pull up the list of names, and see whether some of them suddenly
stopped publishing, or greatly reduced their publishing rate), but public key cryptosystems do have a slight smell about them lately.
We definitely need more diversity in cryptosystems, and should revert
to systems which are more well-understood, and focus on future systems
that are simple to analyze.

@_date: 2013-10-10 14:13:36
@_author: Eugen Leitl 
@_subject: Cryptographers condemn US =?utf-8?Q?Nation?= 
but mathematicians shrug.
 Liberation Technologies ,
 cypherpunks
Researchers split over NSA hacking
Cryptographers condemn US National Security Agencys tapping and tampering,
but mathematicians shrug.
Ann Finkbeiner 08 October 2013
The National Security Agency is the largest employer of mathematicians in the
United States.
PATRICK SEMANSKY/ASSOCIATED PRESS
The US National Security Agency (NSA) has upset a great many people this
year. Since June, newspapers have been using documents leaked by former
intelligence worker Edward Snowden to show how the secretive but powerful
agency has spied on the communications of US citizens and foreign
governments. Last month, the media reported that the NSA, which is based in
Fort Meade, Maryland, had undermined Internet security standards. The
revelations have sparked international outrage at the highest levels  even
the president of Brazil cancelled a visit to the United States because of the
Yet amid the uproar, NSA-supported mathematicians and computer scientists
have remained mostly quiet, to the growing frustration of others in similar
fields. Most have never met a funding source they do not like, says Phillip
Rogaway, a computer scientist at the University of California, Davis, who has
sworn not to accept NSA funding and is critical of other researchers
silence. And most of us have little sense of social responsibility.
Mathematicians and the NSA are certainly interdependent. The agency declares
that it is the United States largest maths employer, and Samuel Rankin,
director of the Washington DC office of the American Mathematical Society,
estimates that the agency hires 3040 mathematicians every year. The NSA
routinely holds job fairs on university campuses, and academic researchers
can work at the agency on sabbaticals. In 2013, the agencys mathematical
sciences programme offered more than US$3.3 million in research grants.
Furthermore, the NSA has designated more than 150 colleges and universities
as centres of excellence, which qualifies students and faculty members for
extra support. It can also fund research indirectly through other agencies,
and so the total amount of support may be much higher. A leaked budget
document says that the NSA spends more than $400 million a year on research
and technology  although only a fraction of this money might go to research
outside the agency itself.
I understand whats in the newspapers, but the NSA is funding serious
long-term fundamental research and Im happy theyre doing it. Many US
researchers, especially those towards the basic-research end of the spectrum,
are comfortable with the NSAs need for their expertise. Christopher Monroe,
a physicist at the University of Maryland in College Park, is among them. He
previously had an NSA grant for basic research on controlling cold atoms,
which can form the basis of the qubits of information in quantum computers.
He notes that he is free to publish in the open literature, and he has no
problems with the NSA research facilities in physical sciences,
telecommunications and languages that sit on his campus. Monroe is
sympathetic to the NSAs need to track the development of quantum computers
that could one day be used to crack codes beyond the ability of conventional
machines. I understand whats in the newspapers, he says, but the NSA is
funding serious long-term fundamental research and Im happy theyre doing
Dena Tsamitis, director of education, outreach and training at Carnegie
Mellon Universitys cybersecurity research centre in Pittsburgh,
Pennsylvania, also wants to maintain the relationship. She oversees visitors
and recruiters from the NSA but her centre gets no direct funding. She says
that her graduate students understand the NSAs public surveillance to be a
policy decision, not a technology decision. Our students are most interested
in the technology. And the NSA, she says  echoing many other researchers 
has very interesting technology problems.
The academics who are professionally uneasy with the NSA tend to lie on the
applied end of the spectrum: they work on computer security and cryptography
rather than pure mathematics and basic physics. Matthew Green, a
cryptographer at Johns Hopkins University in Baltimore, Maryland, says that
these researchers are unsettled in part because they are dependent on
protocols developed by the US National Institute of Standards and Technology
(NIST) to govern most encrypted web traffic. When it was revealed that the
NSA had inserted a back door into the NIST standards to allow snooping,
some of them felt betrayed. We certainly had no idea that they were
tampering with products or standards, says Green. He is one of 47
technologists who on 4 October sent a letter to the director of a group
created last month by US President Barack Obama to review NSA practices,
protesting because the group does not include any independent technologists.
Edward Felten, who studies computer security at Princeton University in New
Jersey, says that the NSAs breach of security standards means that
cryptographers will need to change what they call their threat model  the
set of assumptions about possible attacks to guard against. Now the attacks
might come from the home team. There was a sense of certain lines that NSA
wouldnt cross, says Felten, and now were not so sure about that.
Nature 502, 152 (10 October 2013) doi:10.1038/502152a

@_date: 2013-10-11 13:42:13
@_author: Eugen Leitl 
@_subject: who are the service operators here? 
I think we need more hidden services to make the darknet more attractive,
less exits. The open Internet has been dead for a while, time to accept it.
Running a non-exit relay from home is still worthwhile, since it raises the bar for physical access, and also increases the traffic background.
Decentral search is pretty important, we could really use lots of
YaCy nodes as hidden services -- indexing not just the hidden web, of
I wish there was a library of different privacy-based appliances in
virtual formats (.ovf) which are kept up to date for easy deployment
(even though running it on bare iron would be preferable). That would
seem to be a lot of work, though, and run into trust issues.

@_date: 2013-10-11 17:53:25
@_author: Eugen Leitl 
@_subject: who are the service operators here? 
Their official position IIRC is that they discourage VM use,
so they might not want to offer a virtual appliance.
While they're technically correct, there's value in virtual
network plumbing, so you can build up separated compartments, and
routers which force everything through Tor.
It would reduce the threshold of entry, even though there
are ways of detecting that you're running in a hypervisor
jail, and break out of it.

@_date: 2013-10-12 11:28:36
@_author: Eugen Leitl 
@_subject: who are the service operators here? 
Certainly nice growth, but realistically won't be sustained post-Snowden.
Most-used services on the Internet is search, and there's just one
useful search engine in onionland: 3g2upl4pq6kufc4m.onion and it's
not operated by multiple, independent, noncommercial parties.

@_date: 2013-10-14 15:36:14
@_author: Eugen Leitl 
@_subject: funding Tor development 
Guys, in order to minimize Tor Project's dependance on
federal funding and/or increase what they can do it
would be great to have some additional funding ~10 kUSD/month.
If anyone is aware of anyone who can provide funding at
that level or higher, please contact execdir

@_date: 2013-10-14 20:15:42
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
The worst is that the entire trainwreck has been so
predictable, right from the start.

@_date: 2013-10-15 09:50:12
@_author: Eugen Leitl 
@_subject: NSA collects millions of e-mail address books globally 
NSA collects millions of e-mail address books globally
Video: In June, President Obama said the NSAs email collecting program does
not apply to U.S. citizens.
By Barton Gellman and Ashkan Soltani, Tuesday, October 15, 12:53 AM E-mail
the writer
The National Security Agency is harvesting hundreds of millions of contact
lists from personal e-mail and instant messaging accounts around the world,
many of them belonging to Americans, according to senior intelligence
officials and top-secret documents provided by former NSA contractor Edward
The collection program, which has not been disclosed before, intercepts
e-mail address books and buddy lists from instant messaging services as
they move across global data links. Online services often transmit those
contacts when a user logs on, composes a message, or synchronizes a computer
or mobile device with information stored on remote servers.
Rather than targeting individual users, the NSA is gathering contact lists in
large numbers that amount to a sizable fraction of the worlds e-mail and
instant messaging accounts. Analysis of that data enables the agency to
search for hidden connections and to map relationships within a much smaller
universe of foreign intelligence targets.
During a single day last year, the NSAs Special Source Operations branch
collected 444,743 e-mail address books from Yahoo, 105,068 from Hotmail,
82,857 from Facebook, 33,697 from Gmail and 22,881 from unspecified other
providers, according to an internal NSA PowerPoint presentation. Those
figures, described as a typical daily intake in the document, correspond to a
rate of more than 250million a year.
Each day, the presentation said, the NSA collects contacts from an estimated
500,000 buddy lists on live-chat services as well as from the inbox displays
of Web-based e-mail accounts.
The collection depends on secret arrangements with foreign telecommunications
companies or allied intelligence services in control of facilities that
direct traffic along the Internets main data routes.
Although the collection takes place overseas, two senior U.S. intelligence
officials acknowledged that it sweeps in the contacts of many Americans. They
declined to offer an estimate but did not dispute that the number is likely
to be in the millions or tens of millions.
A spokesman for the Office of the Director of National Intelligence, which
oversees the NSA, said the agency is focused on discovering and developing
intelligence about valid foreign intelligence targets like terrorists, human
traffickers and drug smugglers. We are not interested in personal information
about ordinary Americans.
The spokesman, Shawn Turner, added that rules approved by the attorney
general require the NSA to minimize the acquisition, use and dissemination
of information that identifies a U.S. citizen or permanent resident.
The NSAs collection of nearly all U.S. call records, under a separate
program, has generated significant controversy since it was revealed in June.
The NSAs director, Gen. Keith B. Alexander, has defended bulk collection
as an essential counterterrorism and foreign intelligence tool, saying, You
need the haystack to find the needle.
Contact lists stored online provide the NSA with far richer sources of data
than call records alone. Address books commonly include not only names and
e-mail addresses, but also telephone numbers, street addresses, and business
and family information. Inbox listings of e-mail accounts stored in the
cloud sometimes contain content, such as the first few lines of a message.
Taken together, the data would enable the NSA, if permitted, to draw detailed
maps of a persons life, as told by personal, professional, political and
religious connections. The picture can also be misleading, creating false
associations with ex-spouses or people with whom an account holder has had
no contact in many years.
The NSA has not been authorized by Congress or the special intelligence court
that oversees foreign surveillance to collect contact lists in bulk, and
senior intelligence officials said it would be illegal to do so from
facilities in the United States. The agency avoids the restrictions in the
Foreign Intelligence Surveillance Act by intercepting contact lists from
access points all over the world, one official said, speaking on the
condition of anonymity to discuss the classified program. None of those are
on U.S. territory.
Because of the method employed, the agency is not legally required or
technically able to restrict its intake to contact lists belonging to
specified foreign intelligence targets, he said.
When information passes through the overseas collection apparatus, the
official added, the assumption is youre not a U.S. person.
In practice, data from Americans is collected in large volumes  in part
because they live and work overseas, but also because data crosses
international boundaries even when its American owners stay at home. Large
technology companies, including Google and Facebook, maintain data centers
around the world to balance loads on their servers and work around outages.
A senior U.S. intelligence official said the privacy of Americans is
protected, despite mass collection, because we have checks and balances
built into our tools.
NSA analysts, he said, may not search within the contacts database or
distribute information from it unless they can make the case that something
in there is a valid foreign intelligence target in and of itself.
In this program, the NSA is obliged to make that case only to itself or
others in the executive branch. With few exceptions, intelligence operations
overseas fall solely within the presidents legal purview. The Foreign
Intelligence Surveillance Act, enacted in 1978, imposes restrictions only on
electronic surveillance that targets Americans or takes place on U.S.
By contrast, the NSA draws on authority in the Patriot Act for its bulk
collection of domestic phone records, and it gathers online records from U.S.
Internet companies, in a program known as PRISM, under powers granted by
Congress in the FISA Amendments Act. Those operations are overseen by the
Foreign Intelligence Surveillance Court.
Sen. Dianne Feinstein, the California Democrat who chairs the Senate
Intelligence Committee, said in August that the committee has less
information about, and conducts less oversight of, intelligence gathering
that relies solely on presidential authority. She said she planned to ask for
more briefings on those programs.
In general, the committee is far less aware of operations conducted under
12333, said a senior committee staff member, referring to Executive Order
12333, which defines the basic powers and responsibilities of the
intelligence agencies. I believe the NSA would answer questions if we asked
them, and if we knew to ask them, but it would not routinely report these
things, and, in general, they would not fall within the focus of the
Because the agency captures contact lists on the fly as they cross major
Internet switches, rather than at rest on computer servers, the NSA has no
need to notify the U.S. companies that host the information or to ask for
help from them.
We have neither knowledge of nor participation in this mass collection of
web-mail addresses or chat lists by the government, said Google spokeswoman
Niki Fenwick.
At Microsoft, spokeswoman Nicole Miller said the company does not provide
any government with direct or unfettered access to our customers data,
adding that we would have significant concerns if these allegations about
government actions are true.
Facebook spokeswoman Jodi Seth said that we did not know and did not assist
in the NSAs interception of contact lists.
It is unclear why the NSA collects more than twice as many address books from
Yahoo than the other big services combined. One possibility is that Yahoo,
unlike other service providers, has left connections to its users unencrypted
by default.
Suzanne Philion, a Yahoo spokeswoman, said Monday in response to an inquiry
from The Washington Post that, beginning in January, Yahoo would begin
encrypting all its e-mail connections.
Google was the first to secure all its e-mail connections, turning on SSL
encryption globally in 2010. People with inside knowledge said the move was
intended in part to thwart large-scale collection of its users information
by the NSA and other intelligence agencies.
The volume of NSA contacts collection is so high that it has occasionally
threatened to overwhelm storage repositories, forcing the agency to halt its
intake with emergency detasking orders. Three NSA documents describe
short-term efforts to build an across-the-board technology throttle for
truly heinous data and longer-term efforts to filter out information that
the NSA does not need.
Spam has proven to be a significant problem for the NSA  clogging databases
with information that holds no foreign intelligence value. The majority of
all e-mails, one NSA document says, are SPAM from fake addresses and never
delivered to targets.
In fall 2011, according to an NSA presentation, the Yahoo account of an
Iranian target was hacked by an unknown actor, who used it to send spam.
The Iranian had a number of Yahoo groups in his/her contact list, some with
many hundreds or thousands of members.
The cascading effects of repeated spam messages, compounded by the automatic
addition of the Iranians contacts to other peoples address books, led to a
massive spike in the volume of traffic collected by the Australian
intelligence service on the NSAs behalf.
After nine days of data- bombing, the Iranians contact book and contact
books for several people within it were emergency detasked.
In a briefing from the NSAs Large Access Exploitation working group, that
example was used to illustrate the need to narrow the criteria for data
interception. It called for a shifting collection philosophy: Memorialize
what you need vs. Order one of everything off the menu and eat what you
Julie Tate contributed to this report. Soltani is an independent security
researcher and consultant.

@_date: 2013-10-15 11:08:29
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
The future that never was was built with Lisp machines and NeWS.
Twatr who?

@_date: 2013-10-15 14:23:46
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
Latest TBB3: Within our dataset of several million visitors, only one in 466 browsers have the same fingerprint as yours.
Currently, we estimate that your browser has a fingerprint that conveys 8.86 bits of identifying information.

@_date: 2013-10-15 14:27:04
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
As long as you're jailing your browser into an amnesiac
compartment and run TBB (latest 3 alpha is pretty good)
your risk is minimal.

@_date: 2013-10-15 14:37:44
@_author: Eugen Leitl 
@_subject: Bitcoin mining efficiency and Botnets 
Make something requiring huge LUTs, and in-memory access. That is not ASICable or FPGAble.
Doubling rate is now 3 years by end of this year instead
of 18 months, according to AMD. Moore is dead, long live Moore (in 3d volume integration
of molecular components, coming in a couple decades).

@_date: 2013-10-15 16:21:36
@_author: Eugen Leitl 
@_subject: Bitcoin mining efficiency and Botnets 
Never mentioned Bitcoin, and I would agree in principle.
Due to network effect and apparent good design Bitcoin may
last a lot longer than its detractors like to think, but it will fall, eventually. I disagree there's palpable progress in QC inasmuch practical
computing is concerned, at least in the open literature.
DNA computers basically don't work.
You're sampling conformation space of a linear molecule with
lots of viscous drag. There is very little infinity in that.

@_date: 2013-10-15 20:48:55
@_author: Eugen Leitl 
@_subject: Lessons from Silk Road: don't host your virtual illegal drug bazaar 
Lessons from Silk Road: don't host your virtual illegal drug bazaar in
By Adrianne Jeffries on October 14, 2013 11:47 am Email
When it comes to protecting your virtual black market from the Federal Bureau
of Investigation (FBI), some countries are better than others. As it turns
out, Iceland is probably not where you want to be. While the country may have
protected WikiLeaks from the Americans, it's not harboring the recently
busted illegal drug bazaar Silk Road. The Reykjavik Metropolitan Police have
confirmed that they handed over data on the Silk Road at the request of
American authorities.
It's unclear how much information Iceland turned over, but the FBI claims two
Silk Road servers were based there. Icelandic police say the site was
actually hosted there. Since Iceland does not have a formal Mutual Legal
Assistance Treaty (MLAT) with the US, it appears that the FBI negotiated a
special one-time agreement in order to get the data.
It still looks like the bulk of the information that broke open the case did
not come from Iceland, however. The complaint says "an image of the Silk Road
Web Server was made on or about July 23rd, 2013, and produced thereafter to
the FBI" as a result of a request made to a foreign country under a formal
"AN IMAGE OF THE SILK ROAD WEB SERVER WAS MADE ON OR ABOUT JULY 23RD, 2013."
That image, or bit-for-bit copy, of the Silk Road server gave authorities
access to private messages between the Silk Road's owner and other members of
the site. It was instrumental in seizing the site and arresting Ross
Ulbricht, the man police allege was behind the Silk Road.
Runa Sandvik, who works on the anonymizing network Tor, has been trying to
figure out which country handed over that server image. She initially ruled
out Iceland because it does not have an MLAT with the US. Various Silk Road
content was also hosted in the US, Latvia, and Malaysia. Latvia and Malaysia
are both MLAT signatories. If the request was indeed made under an MLAT, it
looks like the image either came from one of those countries or another that
has not been revealed yet by the FBI.
Another possibility is that the FBI's complaint erroneously claimed the
request was made under an MLAT, when the reality was less formal. Either way,
future virtual drug kingpins now know that Iceland is no safe haven.
Correction: An earlier version of this story said that Malaysia is not an
MLAT signatory; that is incorrect. Malaysia and the US signed an MLAT in

@_date: 2013-10-16 08:24:04
@_author: Eugen Leitl 
@_subject: Bitcoin mining efficiency and Botnets 
Difficulty is adaptive, so it will go down if hash rate goes down.
It's not a one-way ratchet.

@_date: 2013-10-16 09:43:10
@_author: Eugen Leitl 
@_subject: The NSA back door to NIST 
Thomas C. Hales (University of Pittsburgh)
(This article will be published in the Notices of the American Mathematical
Use once. Die once.  activist saying about insecure communication
This article gives a brief mathematical description of the NIST standard for
cryptographically secure pseudo-random number generation by elliptic curves,
the back door to the algorithm discovered by Ferguson and Shumow, and finally
the design of the back door based on the Diffie-Hellman key exchange
NIST (the National Institute for Standards and Technology) of the U.S.
Department of Commerce derives its mandate from the U.S. Constitution,
through the congressional power to fix the standard of weights and
measures. In brief, NIST establishes the basic standards of science and
commerce. Whatever NIST says about cryptography becomes implemented in
cryptographic applications throughout U.S. government agencies. Its influence
leads to the widespread use of its standards in industry and the broad
adoption of its standards internationally.
Through the Snowden disclosures, the NIST standard for pseudo-random number
generation has fallen into disrepute. Here I describe the back door to the
NIST standard for pseudo-random number generation in elementary and
mathematically precise terms. The NIST standard offers three methods for
pseudo-random number generation [NIST]. My remarks are limited to the third
of the three methods, which is based on elliptic curves.
Random number generators can either be truly random (obtaining their values
from randomness in the physical world such as a quantum mechanical process)
or pseudo-random (obtaining their values from a deterministic algorithm, yet
displaying a semblance of randomness). The significance of random number
generation within the theory of algorithms can be gauged by Knuths
multivolume book, The Art of Computer Programming. It devotes a massive 193
pages (half of volume two) to the subject! A subclass of pseudo-random number
generators are cryptographically secure, intended for use in cryptographic
applications such as key generation, one-way hash functions, signature
schemes, private key cryptosystems, and zero knowledge interactive proofs
Elliptic curves as pseudo-random number generators
The NIST standard gives a list of explicit mathematical data (E,p,n,f,P,Q) to
be used for pseudo-random number generation [NIST]. Here E is an elliptic
curve defined over a finite field \mathbb{F}_p of prime order p. The group
E(\mathbb{F}_p) has order n, which is prime for all of the curves that occur
in the NIST standard. The elements of the group E(\mathbb{F}_p) consist of
the set of points on an affine curve, together with a point at infinity which
serves as the identity element of the group. The affine curve is defined by
an equation y^2 = f(x) for some explicit cubic polynomial f in
\mathbb{F}_p[x]. Finally, P and Q are given points on the affine curve.
NIST gives a few sets of data and in each case the prime number p is large.
(The smallest is greater than 10^{77}.) No explanation is given of the
particular choices (E,p,n,f,P,Q). We are told to use these data and not to
question why. The standard stipulates that one of the following NIST
approved curves with associated points shall be used in applications
requiring certification under FIPS-140 [U.S. government computer security
When A is any point other than the identity in E(\mathbb{F}_p), we may
evaluate the coordinate function x at A, to obtain x(A)\in \mathbb{F}_p. By
further lifting \mathbb{F}_p to a set of representatives in \mathbb{Z}, we
obtain a function by composition x1 : E(\mathbb{F}_p)\setminus\{0\}~ \to~
\mathbb{F}_p~\to~ \mathbb{Z}. Write (n,A)\mapsto n * A for the
\mathbb{Z}-module action of \mathbb{Z} on E. (We write powers of the group
element A using multiplicative rather than exponential notation.)
The pseudo-random bit generator is initialized with a random integer seed s,
obtained by some different process such as a separate random number
generator. What is important for us is that the number s represents the
hidden internal state of the algorithm. The hidden state must be kept secret
for the pseudo-randomness to be effective. (Once the state is disclosed, a
pseudo-random sequence becomes predictable and useless for many cryptographic
The essence of the pseudo-random bit generator can be written in the
Objective Caml language as follows. In the syntax of this language, each
phrase (let x = a in ) defines the value of x to be a. The last line of the
block of code gives the output of the function.
let pseudo_random s =
 let r = x1 (s * P) in
 let s' = x1 (r * P) in
 let t = x1 (r * Q) in
 let b = extract_bits t in
  (s',b);
That is, we successively apply the integer s or r to the point P or the point
Q and take the x1 coordinate of the resulting point, then extract some bits
from the number t. The integer s becomes the new secret internal state to be
fed into the next iteration of the function. The output b is passed to the
consumer of pseudo-random bits. This output may become publicly known. The
function extract_bits operates by converting t to a list of bits, discarding
the 16 most significant bits (for reasons that do not matter to this
discussion), and giving the remaining bits as output. According to NIST
standards, by iterating this function, updating the internal state at each
iteration, a cryptographically secure stream b  of pseudo-random bits is
The back door
This algorithm is fatally flawed, as Ferguson and Shumow pointed out
[Shumow-Ferguson]. Since P and Q are non-identity elements of a cyclic group
of prime order, each is a multiple of the other. Write P = e * Q, for some
integer e. We show that once we have e in hand, it is a simple matter to
determine the secret internal state s of the pseudo-random bit generator by
observing the output b, and thus to compromise the entire system.
The function extract_bits discards 16 bits. Given the output b, we take the
2^{16} (a small number of) possible preimages t of b under extract_bits. For
each t, the coordinate x is known, and solving a quadratic, there are at most
two possibilities for the coordinate y of a point A on the elliptic curve
such that t = x1 (A). One such A is r * Q. For each A, we compute e * A. One
of the small number of possibilities for e * A is
e * (r * Q) = r * (e * Q) = r * P.     (1)
Finally s = x1 (r * P). In short, the internal state s can be be narrowed
down to a small number of possibilities by an examination of the
pseudo-random output bitstream. Shumow and Ferguson state that in
experiments, 32 bytes of output was sufficient to uniquely identify the
internal state of the PRNG [pseudo-random number generator].
The back door to the algorithm is the number e such that P = e * Q. To use
the back door, one must know of the value e. The NIST standard does not
disclose e (of course!), and extensive cryptographic experience suggests that
it is hard to compute e from the coordinates of P and Q (unless you happen to
own a quantum computer). This is the problem of discrete logarithms. But
starting with e, there is no difficulty in creating a pair P and Q. The back
door is universal: a single number e gives back door access to the internal
state of the algorithm of all users worldwide.
It is a matter of public fact that the NSA was tightly involved in the
writing of the standard. Indeed, NIST is required by law to consult with NSA
in creating its standard. According to the New York Times, classified NSA
memos appear to confirm that the fatal weakness, discovered by two Microsoft
cryptographers in 2007, was engineered by the agency [NYT]. The news article
goes on to say that eventually, NSA became the sole editor and then pushed
aggressively to make this the standard for the 163 member countries of the
International Organization for Standardization. Further historical and social
context appears in [Wired]. NSA had facile access to the crown jewel e and
motive to seize it. Draw your own conclusions.
1. This back door to this algorithm is extremely elementary from a
mathematical perspective. We wrote the essential algorithm in six lines of
computer code, even if more supporting code is needed to make it industrial
strength. The algorithm could be explained to undergraduate math majors, or
sufficiently advanced high-school students. The story also has the spy-agency
intrigue to make a good math club talk or a special lecture in an elementary
abstract algebra course. We essentially just need to understand that an
elliptic curve is an abelian group whose elements (other than the identity
element) are determined by two numbers x and y, that y is the root of a
quadratic when x is given, and that every non-identity element of a cyclic
group of prime order is a generator. Easy stuff.
2. Without prior knowledge of the back door, how difficult would it be to
rediscover the possible existence of a back door? An analysis of the argument
shows the required level of creativity is that of an undergraduate homework
problem. We must think to write the element P as a multiple of the generator
Q in a cyclic group of prime order. This a student learns in the first weeks
of undergraduate algebra.
The rest of the process of inverting the pseudo-random number generator is
determined by the definition of the function itself: simply take each step
defining the function and reverse the steps, asking for the preimage of the
function at each step of its definition, working from the output back to the
secret state s. Once the question of inverting the function is asked, it is
easy to do the group theory, even if it is computationally difficult to write
e explicitly.
One-way functions are a standard tool in the cryptographers bag. Every
professional who has been trained to analyze cryptographic algorithms knows
to ask the question of invertibility. It is unsettling that NIST and others
do not seem to have asked this basic question.
Diffie-Hellman key exchange
In what follows, let us assume that someone, whom we will call the Spy, has
access to the back door e. How is it possible for the Spy and the end user
(the User) of the NIST algorithm to come into possession of the same shared
secret (the internal state of the pseudo-random number generator), when all
communication between them is public? Information flows from the Spy to the
User through the published NIST standard, and from the User back to the Spy
through the public output of the pseudo-random generator. The back door must
have a remarkable cryptographic design to permit a secret to pass across
these public channels, yet prevent the secret from becoming known to a third
As we now explain, the design of the back door to NIST is based on a
well-known algorithm in cryptography called the Diffie-Hellman key exchange
[Diffie-Hellman]. This is an algorithm to share a secret between two parties,
when there is a possibility that the channel of communication is being
monitored. In the current context, the Spy has full knowledge of the
Diffie-Hellman key exchange for what it is. However, the User participates in
the exchange innocently and unwittingly, by blindly following the rules of
the NIST protocol.
The Diffie-Hellman key exchange requires a group, which we will take to be a
cyclic group E of order n (to preserve notation). The group E, its order n,
and a generator Q are made public. To share a secret, the first party (the
Spy), picks a random number e, which is kept secret, and publishes P = e * Q
to the world. The second party (the User) picks a random number r, which is
kept secret, and publishes r * Q. Then by Equation (1), the Spy who knows e
and r *Q, and the User who knows r and e * Q can both compute (r e) * Q = r *
P, which is the shared secret. (In our context, the shared secret determines
the internal state s of the pseudo-random number generator.) If E is a group
in which the public knowledge E, n, Q, P = e * Q, r * Q does not allow the
easy computation of (r e) * Q, then the shared secret is protected from
public disclosure by the difficulty of the computation. In this way, the only
two who learn the internal state of the pseudo-random number generator are
the Spy and the User.
What we have described here is not an imaginary scenario: NIST documents do
in fact publish the data E, n, Q, and P, needed to initiate the
Diffie-Hellman exchange. A user, when making public the output from the
pseudo-random number generator, does in fact complete the exchange.
Diffie-Hellman is Diffie-Hellman, whether it has been advertised as such or
To say that the Diffie-Hellman key exchange algorithm is well-known is a vast
understatement. This algorithm is a significant lesson in virtually every
first course in cryptography everywhere in the world. Building on Merkle, the
Diffie-Hellman paper, by starting the entire field of public key
cryptography, is one of the most influential papers in cryptography ever
What is the significance of all this? It is no secret that the NSA employs
some of the worlds keenest cryptographic minds. They all know
Diffie-Hellman. In my opinion, an algorithm that has been designed by NSA
with a clear mathematical structure giving them exclusive back door access is
no accident, particularly in light of the Snowden documents. This is a work
of experts.
[NIST] E. Barker and J. Kelsey, Recommendation for random number generation
using deterministic random bit generators. NIST Special Publication 800-90A
(2012), [Diffie-Hellman] W. Diffie and M. Hellman, New directions in cryptography.
IEEE Transactions on Information Theory 22 (1976), 644-654.
[Luby] M. Luby, Pseudorandomness and cryptographic applications, Princeton
University Press, 1996.
[NYT] N. Perloth, J. Larson, and S. Shane. N.S.A. able to foil basic
safeguards of privacy on web, September 5, 2013, New York Times,
[Shumow-Ferguson] D. Shumow and N. Ferguson, On the possibility of a back
door in the NIST SP800-90 dual EC PRNG,
 2007.
[Wired] K. Zetter, How a crypto `backdoor pitted the tech world against the
NSA, Wired (Sept 24, 2013),

@_date: 2013-10-16 10:26:43
@_author: Eugen Leitl 
@_subject: Curious use of cpunks list [Brian Carroll] 
The author is almost certainly schizophrenic, but he's
not disruptive, and occasionally amusing. I don't see
any reasons for action.

@_date: 2013-10-16 16:34:12
@_author: Eugen Leitl 
@_subject: The NSA's New Code Breakers 
(thank, John, worth reposting full-text)
The NSA's New Code Breakers
America's using front companies, break-in artists, and hacktivists to spy on
everyone -- and only North Korea seems able to resist.
BY MATTHEW M. AID | OCTOBER 15, 2013
There was a time when the code breakers of the National Security Agency
actually took the lead in solving enemy encryption systems. These days, not
so much. In today's NSA, it's hackers, break-in artists, corporate liaisons,
and shadow salesman using front companies who are at the forefront of this
effort. Even so-called "hacktivists" play an unwitting role in helping the
NSA gain access to computer networks -- both hostile and friendly.
Just about the only place that's somewhat immune to the NSA's new style of
code-breaking attacks? North Korea, because it's so disconnected from the
rest of the world's networks.
Former U.S. intelligence officials confirm that the more than 1,500
cryptanalysts, mathematicians, scientists, engineers, and computer
technicians who comprise NSA's elite cryptanalytic unit, the Office of
Cryptanalysis and Exploitation Services (S31), have had a remarkably large
number of code-breaking successes against foreign targets since the 9/11
attacks. But these wins were largely dependent on clandestine intelligence
activities for much of their success in penetrating foreign communications
networks and encryption systems, and not the more traditional cryptanalytic
attacks on encrypted messages that were the norm during the Cold War era.
Prior to 9/11, NSA's cryptanalysts used their huge stable of supercomputers
to break cipher systems using what is referred to as "brute force methods" --
using the super computers to run every cipher permutation until the message
or messages in question become readable. It was a long, tedious, and
extremely costly process (today NSA spends over $247 million a year to buy
and maintain its state-of-the-art supercomputer systems just for
cryptanalytic use). But it did work if there were inherent vulnerabilities or
structural weakness in the cipher being attacked, or if the system's users
did not practice proper communications security procedures, such as changing
the cipher keys and passwords frequently.
The NSA today has more supercomputers than ever and the agency still employs
a number of puzzle-solvers, linguists, and math geeks. But these classic
cryptanalysts have, in part, given way to a new breed.
You won't learn this in the files leaked by former NSA contractor Edward
Snowden -- at least not directly. According to individuals who have reviewed
the entire collection of 50,000 documents provided to the media by Snowden,
what is missing from the papers is any document which lays out in detail just
how successful the agency's code-breaking efforts have been. There are
numerous documents in the Snowden collection describing individual NSA
cryptologic programs, such as NSA's mostly unsuccessful multi-year effort to
crack the encryption protection used by the anonymizer service Tor. But no
reports describing the agency's cryptanalytic successes and failures have
been found in the Snowden collection to date.
Interviews with current and former intelligence officials conducted over the
past two months have revealed that since 9/11, NSA's computer scientists,
electronic engineers, software programmers, and collection specialists have
been remarkably inventive in finding new and innovative ways to circumvent
the protections supposedly offered by encryption systems by compromising them
through clandestine means. Among these clandestine means are CIA and FBI
"black bag jobs," as well as secret efforts by the U.S. intelligence
community to interdict the shipment of advanced encryption technology to
America's enemies around the world, inserting "back doors" into
commercially-available computer, communications and encryption technologies
which allow NSA to covertly access these systems without the users knowing
But the most sensitive of these clandestine techniques, and by far the most
productive to date, is to covertly hack into targeted computers and copy the
documents and message traffic stored on these machines before they are
encrypted, a process known within NSA as "Endpoint" operations.
Responsibility for conducting these Endpoint operations rests with the
computer hackers of NSA's cyberespionage unit, the Office of Tailored Access
Operations (TAO).
According to sources familiar with the organization's operations, TAO has
been enormously successful over the past 12 years in covertly inserting
highly sophisticated spyware into the hard drives of over 80,000 computer
systems around the world, although this number could be much higher. And
according to the sources, these implants are designed in such a way that they
cannot be detected by currently available commercial computer security
software. It has been suggested to me by a reliable source that "this is not
an accident," with the insinuation being that many of the biggest
commercially-available computer security software systems made in the United
States and overseas have been compromised by NSA, either covertly or with the
knowledge and consent of the companies that manufacture these systems.
Former agency personnel confirm that in innumerable instances these TAO
implants have allowed NSA's analysts to copy and read all of the unencrypted
documents stored on the targeted computer's hard drive, as well as copy every
document and email message produced and/or transmitted by the machine. But
more importantly, TAO has helped NSA's cryptanalysts solve several hundred
foreign government and commercial encryption systems because these spyware
implants, if properly inserted into the computer, can covertly alter its
security software as well as copy the encryption system's technical
parameters, especially the system's encryption algorithm and access
passwords, in a way that cannot be detected. These implants can compromise
the encryption systems used by not only the targeted computer, but also all
other computer systems that it communicates with using encryption technology.
According to confidential sources familiar with TAO's operations, many of
NSA's cryptanalytic "success stories" against high-priority targets such as
Russia and the People's Republic of China in recent years have been the
direct result of TAO's cyberespionage efforts. For example, sources confirm
that much of what the U.S. intelligence community knows about China's
computer hacking efforts against targets in the United States, Europe, and
Asia stems from TAO's intelligence collection efforts since 2005, when TAO
reportedly achieved a major technical breakthrough against a Chinese target.
But TAO doesn't just spy on America's rivals. In 2012, the group reportedly
compromised the encryption system used by an important G8 country to transmit
sensitive diplomatic communications via satellite to its embassies around the
world. The same is true with a number of countries in the Middle East and
South Asia, including Egypt, Syria, Iran, and Pakistan, although the details
of these successes are not yet known. And finally, sources report that TAO
has successfully compromised the privacy protection systems currently used on
a range of 4G cell phones and hand-held devices, thanks in large part to help
from a major American telecommunications company.
There are high-profile targets that have proven resistant to TAO's
cyberespionage efforts over the years, however. For example, TAO has
reportedly had virtually no success penetrating North Korean government
computer systems or networks because there are so few of them and they are
heavily protected from access to the outside world.
Over time, TAO has become increasingly accomplished at its mission, thanks in
part to the high-level cooperation that it secretly receives from the "big
three" American telecommunications companies (AT&T, Verizon, and Sprint),
most of the large U.S.-based internet service providers, and many of the top
computer security software manufacturers and consulting companies. According
to a February 2012 budget document (.pdf) published earlier this year by
ProPublica, these companies "Insert vulnerabilities into commercial
encryption systems, IT systems, networks, and endpoint communications devices
used by targets" on behalf of TAO.
TAO is also very active in the global computer security industry marketplace,
using the CIA, Defense Intelligence Agency, and State Department to help it
keep close tabs on the latest computer security devices and software systems
being developed around the world. And while details are lacking, informed
sources report that TAO has been active in covertly buying up commercially
available "hacker tools" or spyware software systems from individuals and
companies in the United States and overseas, particularly in Western Europe,
to help facilitate its ever-growing computer network exploitation efforts.
The extreme sensitivity of TAO's collection efforts has required the NSA to
take extraordinary steps to try to disguise its computer hacking activities.
For instance, current and former intelligence sources confirm that TAO
increasingly depends on clandestine techniques, such as commercial cover, to
hide its activities. TAO uses an array of commercial business entities, some
of them proprietary companies established specifically for this purpose, to
try to hide its global computer hacking activities from computer security
experts in a maze of interlocking computer servers and command-and-control
systems located in the United States and overseas that have no discernible
link to NSA or the U.S. government.
These sources also say that TAO gets a lot of help from politically-motivated
hackers, or "hacktivists," who unintentionally help NSA by providing ideas to
improve TAO's collection efforts. (Exactly which hacktivists have been
particularly helpful, these sources wouldn't say.) Working closely with NSA's
computer security experts at the NSA/CSS Threat Operations Center, TAO
personnel perform detailed forensic post-mortem studies of every major
successful computer penetration operation around the world. Some of these are
pulled off by criminal outfits, some by government-backed groups, others by
political actors. In each case, the agency's personnel looks for new
techniques or procedures that they can use to get inside computer systems
around the world.
There is no question that TAO's future looked incredibly bright before the
first newspaper articles began appearing in the British and American press in
June 2013 based on documents leaked by Snowden. Now, industry sources
familiar with TAO say that the organization's future prospects have dimmed
A number of foreign-based computer systems and IT networks that formerly were
major producers of intelligence information for TAO have over the past three
months changed security procedures and encryption systems, routed traffic to
more secure computer nodes or servers, erected new firewalls, or have gone
offline altogether. According to recent press reports, the Russian government
for a time reverted back to using manual typewriters rather than commit
sensitive information to their computer systems. And a number of European
countries and Brazil have begun shifting their most sensitive data and
communications traffic to secure networks that they hope will be resistant to
NSA's intrusive surveillance activities.
But this is, I am sure, just the tip of the iceberg. I have no doubt that the
damage to TAO's foreign intelligence collection capabilities and its ability
to facilitate the solution of foreign encryption systems by NSA's
cryptanalysts has been substantial. The big question that will determine
TAO's future prospects is whether the damage done so far proves to be

@_date: 2013-10-17 08:29:08
@_author: Eugen Leitl 
@_subject: Curious use of cpunks list [Brian Carroll] 
If we had good PRNGs everywhere, with lots of trustable physical entropy
stirred in then nobody would care about talking about these.
It would be boring, since a solved problem.
Now show me a cryptographic quality PRNG with a few MBytes of
internal state. Best, a whole robust family of them. See? That's
some quality trolling, right there.

@_date: 2013-10-17 09:49:09
@_author: Eugen Leitl 
@_subject: [tor-talk] Roger's status report, September/October 2013 
Reply-To: tor-talk
Six things I did in September/October 2013:
1) Released Tor 0.2.4.17-rc:
including writing the fix to prioritize NTor handshakes so Tor 0.2.4.x
remains usable despite the five million new bot users:
Released Tor 0.2.5.1-alpha:
2) Wrote many blog posts:
with a follow-up summary at
and also answered hundreds of blog comments / questions.
3) Talked to many many journalists to explain Tor and the Internet.
My most useful quotes went to Bruce Schneier:
and Brian Fung:
and Dan Goodin:
4) Helped the Tor Stack Exchange beta get off the ground:
I zipped up to 1000+ reputation from answering questions in the first
few days, but then I disappeared because I was distracted by other work.
Hopefully other people have filled in the gap.
5) Helped sort out the 2013 Q4 budget, and also get the new SponsorO
projects off the ground:
6) Attended the SponsorF "red team assessment" where they funded some
smart DPI developers to evaluate and try to break Obfsproxy and Flash
Proxy. So far so good -- one of the outcomes is that we should set up
a performance testbed for Flash Proxy to see if we can replicate their
"sometimes when I upload a bunch of stuff it takes a long time" behavior.
I plan to talk to Arlo, once I'm back online, about doing that.

@_date: 2013-10-17 10:29:45
@_author: Eugen Leitl 
@_subject: Cryptographer Adi Shamir Prevented from Attending NSA History 
cypherpunks
Cryptographer Adi Shamir Prevented from Attending NSA History Conference
Categories: Science, Secrecy
In this email message to colleagues, Israeli cryptographer Adi Shamir
recounts the difficulties he faced in getting a visa to attend the 2013
Cryptologic History Symposium sponsored by the National Security Agency. Adi
Shamir is the S in the RSA public-key algorithm and is one of the finest
cryptologists in the world today, according to historian David Kahn. The NSA
Symposium begins tomorrow. For the reasons described below, Dr. Shamir will
not be there.
The purpose of this email is to explain why I will not be able to attend the
forthcoming meeting of the History of Cryptology conference, even though I
submitted a paper which was formally accepted. As an active participant in
the exciting developments in academic cryptography in the last 35 years, I
thought that it would be a wonderful opportunity to meet all of you, but
unfortunately the US bureaucracy has made this impossible.
The story is too long to describe in detail, so I will only provide its main
highlights here. I planned to visit the US for several months, in order to
attend the Crypto 2013 conference, the History of Cryptology conference, and
to visit several universities and research institutes in between in order to
meet colleagues and give scientific lectures. To do all of these, I needed a
new J1 visa, and I filed the visa application at the beginning of June, two
and a half months before my planned departure to the Crypto conference in mid
August. I applied so early since it was really important for me to attend the
Crypto conference  I was one of the founders of this flagship annual
academic event (I actually gave the opening talk in the first session of the
first meeting of this conference in 1981) and I did my best to attend all its
meetings in the last 32 years.
To make a long story short, after applying some pressure and pulling a lot of
strings, I finally got the visa stamped in my passport on September 30-th,
exactly four months after filing my application, and way beyond the requested
start date of my visit. I was lucky in some sense, since on the next day the
US government went into shutdown, and I have no idea how this could have
affected my case. Needless to say, the long uncertainty had put all my travel
plans (flights, accomodations, lecture commitments, etc) into total disarray.
It turns out that I am not alone, and many foreign scientists are now facing
the same situation. Here is what the president of the Weizmann Institute of
Science (where I work in Israel) wrote in July 2013 to the US Ambassador in
Im allowing myself to write you again, on the same topic, and related to
the major difficulties the scientists of the Weizmann Institute of Science
are experiencing in order to get Visa to the US. In my humble opinion, we are
heading toward a disaster, and I have heard many people, among them our top
scientists, saying that they are not willing anymore to visit the US, and
collaborate with American scientists, because of the difficulties. It is
clear that scientists have been singled out, since I hear that other simple
citizen, do get their visa in a short time.
Even the president of the US National Academy of Science (of which I am a
member) tried to intervene, without results. He was very sympathetic, writing
to me at some stage:
Dear Professor Shamir
I have been hoping, day by day, that your visa had come through. It is very
disappointing to receive your latest report. We continue to try by seeking
extra attention from the U. S. Department of State, which has the sole
authority in these matters. As you know, the officers of the Department of
State in embassies around the world also have much authority. I am personally
very sympathetic and hopeful that your efforts and patience will still yield
results but also realize that this episode has been very trying. We hope to
hear of a last-minute success.
Yours sincerely, Ralph J. Cicerone
What does all of this have to do with the History of Cryptology conference?
In January 2013 I submitted a paper titled The Cryptology of John Nash From
a Modern Perspective to the conference, and a short time afterwards I was
told by the organizers that it was accepted. In July 2013 I told the
NSA-affiliated conference organizers that I was having some problems in
getting my visa, and gently asked whether they could do something about it.
Always eager to help, the NSA people leaped into action, and immediately sent
me a short email written with a lot of tact:
The trouble you are having is regrettableSorry you wont be able to come to
our conference. We have submitted our program and did not include you on it.
I must admit that in my 35 years of attending many conferences, it had never
happened to me that an accepted paper of mine was yanked out from the
official program in such a unilateral way. However, since I never try to go
to places where I do not feel wanted, I decided to inform MIT that a window
had become available in my busy schedule. They immediately invited me to
visit them on October 17 and 18, and to give a major lecture during my visit.
Naturally, I accepted their gracious invitation.
The final twist in this saga happened a few days ago, when out of the blue I
was suddenly reinvited by the conference organizers to attend the event and
to present my paper. However, this is too late now, since I am already fully
committed to my visit to MIT.
So what is the bottom line of this whole unhappy episode? Clearly, no one in
the US is trying to see the big picture, and the heavy handed visa
bureaucracy you have created seems to be collapsing under its own weight.
This is not a security issue  I have been to the US close to a hundred times
so far (including some multi-year visits), and had never overstayed my visas.
In addition, the number of terrorists among the members of the US National
Academy of Science is rather small. As a friend of the US I am deeply worried
that if you continue to delay visas in such a way, the only thing you will
achieve is to alienate many world-famous foreign scientists, forcing them to
increase their cooperation with European or Chinese scientists whose
countries roll the red carpet for such visits. Is this really in the US best
Best personal wishes, and apologies for not being able to meet you in person,
Adi Shamir

@_date: 2013-10-17 13:15:10
@_author: Eugen Leitl 
@_subject: Trekkie finally got fired -- it's a good start 
Keith Alexander, NSA Head, Stepping Down
Tyler Durden's pictureSubmitted by Tyler Durden on 10/16/2013 18:10 -0400
After eight years at the helm of "America's secret cyber army", NSA head
Keith Alexander, has decided to spend more time with his family and less time
with yours, and is stepping down. According to US officials, the director of
the NSA and his deputy are expected to depart in coming months, in a move
that almost certainly would not have happened without the involvement of
America's most infamous whitsleblower currently self-exiled in Russia, Edward
Snowden in a development which according to Reuters, "could give Obama a
chance to reshape the eavesdropping agency."
It is unclear what he would "reshape" it into: at last check the Stasi
headquarters in Berlin did not have quite the capacity to house the Cray
supercomputers needed to make sure that anyone and everyone caught selling
stocks gets a lifetime audit guarantee from the IRS.
We are confident, however, that with the surge in government-employed
architects coming back to "work" from their 17 days paid vacation, someone
will have an idea or two.
Army General Keith Alexander's eight-year tenure was rocked this year by
revelations contained in documents leaked by former NSA contractor Edward
Snowden about the agency's widespread scooping up of telephone, e-mail and
social media data.
Alexander has formalized plans to leave by next March or April, while his
civilian deputy, John "Chris" Inglis, is due to retire by year's end,
according to U.S. officials who spoke on condition of anonymity.
It also wasn't clear who would replace the man who once upon a time made his
office into a replica of the bridge of the Starship Enterprise, although
there certainly are candidates.
One leading candidate to replace Alexander is Vice Admiral Michael Rogers,
currently commander of the U.S. Navy's 10th Fleet and U.S. Fleet Cyber
Command, officials told Reuters. The 10th Fleet and Fleet Cyber Command both
have their headquarters at Fort Meade, Maryland, between Washington and
Baltimore. The NSA is also headquartered at Fort Meade.
There has been no final decision on selecting Rogers to succeed Alexander,
and other candidates may be considered, the officials said.  More
importantly, the question is whether with America's domestic epsionage and
email address book collection efforts exposed for the entire world to see,
courtesy of Edward Snowden, will Obama decide to engage in a strategic shift
in policy, or merely double down and install RFID chips into every newborn
While both men are leaving voluntarily, the dual vacancies give Obama an
opportunity both to install new leadership following Snowden's revelations
and to decide whether the NSA and Cyber Command should have separate leaders.
Cyber Command, which has grown significantly in recent years, has the
authority to engage in both defensive and offensive operations in cyberspace.
Many NSA veterans argue that having the same person lead the spy agency and
Cyber Command diminishes the emphasis on the NSA's work and its unique
Rogers has been the Navy's top cyber commander since September 2011. Prior to
that, he was director of intelligence for the U.S. Joint Chiefs of Staff and
for the U.S. Pacific Command.
Rogers is "a good leader, very insightful and well thought of within the
community," said a U.S. defense official who was not authorized to speak
publicly on the matter.
Rogers has worked hard to ensure that the Navy has sufficient sailors trained
to take on added cyber responsibilities for U.S. Cyber Command, the official
Sorry, we forgot to add "rhetorical" before question.

@_date: 2013-10-17 15:40:29
@_author: Eugen Leitl 
@_subject: NSA's key role in targeted killings 
Documents reveal NSAs extensive involvement in targeted killing program
Video: In June, President Obama said the NSAs programs help us prevent
terrorist attacks.
By Greg Miller, Julie Tate and Barton Gellman, Thursday, October 17, 2:07 AM
E-mail the writers
It was an innocuous e-mail, one of millions sent every day by spouses with
updates on the situation at home. But this one was of particular interest to
the National Security Agency and contained clues that put the senders
husband in the crosshairs of a CIA drone.
Days later, Hassan Ghul  an associate of Osama bin Laden who provided a
critical piece of intelligence that helped the CIA find the al-Qaeda leader 
was killed by a drone strike in Pakistans tribal belt.
The U.S. government has never publicly acknowledged killing Ghul. But
documents provided to The Washington Post by former NSA contractor Edward
Snowden confirm his demise in October 2012 and reveal the agencys extensive
involvement in the targeted killing program that has served as a centerpiece
of President Obamas counterterrorism strategy.
An al-Qaeda operative who had a knack for surfacing at dramatic moments in
the post-Sept. 11 story line, Ghul was an emissary to Iraq for the terrorist
group at the height of that war. He was captured in 2004 and helped expose
bin Ladens courier network before spending two years at a secret CIA prison.
Then, in 2006, the United States delivered him to his native Pakistan, where
he was released and returned to the al-Qaeda fold.
But beyond filling in gaps about Ghul, the documents provide the most
detailed account of the intricate collaboration between the CIA and the NSA
in the drone campaign.
The Post is withholding many details about those missions, at the request of
U.S. intelligence officials who cited potential damage to ongoing operations
and national security.
The NSA is focused on discovering and developing intelligence about valid
foreign intelligence targets, an NSA spokeswoman said in a statement
provided to The Post on Wednesday, adding that the agencys operations
protect the nation and its interests from threats such as terrorism and the
proliferation of weapons of mass destruction.
In the search for targets, the NSA has draped a surveillance blanket over
dozens of square miles of northwest Pakistan. In Ghuls case, the agency
deployed an arsenal of cyber-espionage tools, secretly seizing control of
laptops, siphoning audio files and other messages, and tracking radio
transmissions to determine where Ghul might bed down.
The e-mail from Ghuls wife about her current living conditions contained
enough detail to confirm the coordinates of that household, according to a
document summarizing the mission. This information enabled a capture/kill
operation against an individual believed to be Hassan Ghul on October 1, it
The file is part of a collection of records in the Snowden trove that make
clear that the drone campaign  often depicted as the CIAs exclusive domain
 relies heavily on the NSAs ability to vacuum up enormous quantities of
e-mail, phone calls and other fragments of signals intelligence, or SIGINT.
To handle the expanding workload, the NSA created a secret unit known as the
Counter-Terrorism Mission Aligned Cell, or CT MAC, to concentrate the
agencys vast resources on hard-to-find terrorism targets. The unit spent a
year tracking Ghul and his courier network, tunneling into an array of
systems and devices, before he was killed. Without those penetrations, the
document concluded, this opportunity would not have been possible.
At a time when the NSA is facing intense criticism for gathering data on
Americans, the drone files may bolster the agencys case that its resources
are focused on fighting terrorism and supporting U.S. operations overseas.
Ours is a noble cause, NSA Director Keith B. Alexander said during a public
event last month. Our job is to defend this nation and to protect our civil
liberties and privacy.
The documents do not explain how the Ghul e-mail was obtained or whether it
was intercepted using legal authorities that have emerged as a source of
controversy in recent months and enable the NSA to compel technology giants
including Microsoft and Google to turn over information about their users.
Nor is there a reference to another NSA program facing scrutiny after
Snowdens leaks, its metadata collection of numbers dialed by nearly every
person in the United States.
To the contrary, the records indicate that the agency depends heavily on
highly targeted network penetrations to gather information that wouldnt
otherwise be trapped in surveillance nets that it has set at key Internet
The new documents are self-congratulatory in tone, drafted to tout the NSAs
counterterrorism capabilities. One is titled CT MAC Hassan Gul Success. The
files make no mention of other agencies roles in a drone program that
escalated dramatically in 2009 and 2010 before tapering off in recent years.
Even so, former CIA officials said the files are an accurate reflection of
the NSAs contribution to finding targets in a campaign that has killed more
than 3,000 people, including thousands of alleged militants and hundreds of
civilians, in Pakistan, according to independent surveys. The officials said
the agency has assigned senior analysts to the CIAs Counterterrorism Center,
and deployed others to work alongside CIA counterparts at almost every major
U.S. embassy or military base overseas.
NSA threw the kitchen sink at the FATA, said a former U.S. intelligence
official with experience in Afghanistan and Pakistan, referring to the
Federally Administered Tribal Areas, the region in northwest Pakistan where
al-Qaedas leadership is based.
NSA employees rarely ventured beyond the security gates of the U.S. Embassy
in Islamabad, officials said. Surveillance operations that required placing a
device or sensor near an al-Qaeda compound were handled by the CIAs
Information Operations Center, which specializes in high-tech devices and
close-in surveillance work.
But if you wanted huge coverage of the FATA, NSA had 10 times the manpower,
20 times the budget and 100 times the brainpower, the former intelligence
official said, comparing the surveillance resources of the NSA to the smaller
capabilities of the agency's IOC. The two agencies are the largest in the
U.S. intelligence community, with budgets last year of $14.7 billion for the
CIA and $10.8 billion for the NSA. We provided the map, the former official
said, and they just filled in the pieces.
In broad terms, the NSA relies on increasingly sophisticated versions of
online attacks that are well-known among security experts. Many rely on
software implants developed by the agencys Tailored Access Operations
division with code-names such as UNITEDRAKE and VALIDATOR. In other cases,
the agency runs man-in-the-middle attacks in which it positions itself
unnoticed midstream between computers communicating with one another,
diverting files for real-time alerts and longer-term analysis in data
Through these and other tactics, the NSA is able to extract vast quantities
of digital information, including audio files, imagery and keystroke logs.
The operations amount to silent raids on suspected safe houses and often are
carried out by experts sitting behind desks thousands of miles from their
The reach of the NSAs Tailored Access Operations division extends far beyond
Pakistan. Other documents describe efforts to tunnel into systems used by
al-Qaeda affiliates in Yemen and Africa, each breach exposing other
An operation against a suspected facilitator for al-Qaedas branch in Yemen
led to a trove of files that could be used to help NSA map out the movement
of terrorists and aspiring extremists between Yemen, Syria, Turkey, Egypt,
Libya and Iran, according to the documents. This may enable NSA to better
flag the movement of these individuals to allied security services that can
put individuals on no-fly lists or monitor them once in country.
A single penetration yielded 90 encrypted al-Qaeda documents, 16 encryption
keys, 30 unencrypted messages as well as thousands of chat logs, according
to an inventory described in one of the Snowden documents.
The operations are so easy, in some cases, that the NSA is able to start
downloading data in less time than it takes the targeted machine to boot up.
Last year, a user account on a social media Web site provided an instant
portal to an al-Qaeda operatives hard drive. Within minutes, we
successfully exploited the target, the document said.
The hunt for Ghul followed a more elaborate path.
Ghul, who is listed in other documents as Mustafa Haji Muhammad Khan, had
surfaced on U.S. radar as early as 2003, when an al-Qaeda detainee disclosed
that Ghul escorted one of the intended hijackers to a Pakistani safe house a
year before the Sept. 11, 2001, attacks.
A trusted facilitator and courier, Ghul was dispatched to Iraq in 2003 to
deliver a message to Abu Musab al-Zarqawi, the al-Qaeda firebrand who angered
the networks leaders in Pakistan by launching attacks that often slaughtered
innocent Muslims.
When Ghul made another attempt to enter Iraq in 2004, he was detained by
Kurdish authorities in an operation directed by the CIA. Almost immediately,
Ghul provided a piece of intelligence that would prove more consequential
than he may have anticipated: He disclosed that bin Laden relied on a trusted
courier known as al-Kuwaiti.
The ripples from that revelation wouldnt subside for years. The CIA went on
to determine the true identity of al-Kuwaiti and followed him to a heavily
fortified compound in Abbottabad, Pakistan, where bin Laden was killed in
Because of the courier tip, Ghul became an unwitting figure in the
contentious debate over CIA interrogation measures. He was held at a CIA
black site in Eastern Europe, according to declassified Justice Department
memos, where he was slapped and subjected to stress positions and sleep
deprivation to break his will.
Defenders of the interrogation program have cited Ghuls courier disclosure
as evidence that the agencys interrogation program was crucial to getting
bin Laden. But others, including former CIA operatives directly involved in
Ghuls case, said that he identified the courier while he was being
interrogated by Kurdish authorities, who posed questions scripted by CIA
analysts in the background.
The debate resurfaced amid the release of the movie Zero Dark Thirty last
year, in which a detainees slip after a brutal interrogation sequence is
depicted as a breakthrough in the bin Laden hunt. Ghuls case also has been
explored in detail in a 6,000-page investigation of the CIA interrogation
program by the Senate Intelligence Committee that has yet to be released.
Sen. Dianne Feinstein (D-Calif.), the chairman of the panel, sought to settle
the Ghul debate in a statement last year that alluded to his role but didnt
mention him by name.
The CIA detainee who provided the most significant information about the
courier provided the information prior to being subjected to coercive
interrogation techniques, Feinstein said in the statement, which was signed
by Sen. Carl Levin (D-Mich.).
The George W. Bush administrations decision to close the secret CIA prisons
in 2006 set off a scramble to place prisoners whom the agency did not regard
as dangerous or valuable enough to transfer to Guantanamo Bay. Ghul was not
among the original 14 high-value CIA detainees sent to the U.S. installation
in Cuba. Instead, he was turned over to the CIAs counterpart in Pakistan,
with ostensible assurances that he would remain in custody.
A year later, Ghul was released. There was no public explanation from
Pakistani authorities. CIA officials have noted that Ghul had ties to
Lashkar-e-Taiba, a militant group supported by Pakistans intelligence
service. By 2007, he had returned to al-Qaedas stronghold in Waziristan.
In 2011, the Treasury Department named Ghul a target of U.S. counterterrorism
sanctions. Since his release, the department said, he had helped al-Qaeda
reestablish logistics networks, enabling al-Qaeda to move people and money in
and out of the country. The NSA document described Ghul as al-Qaedas chief
of military operations and detailed a broad surveillance effort to find him.
The most critical piece came with a discovery that provided a vector for
compounds used by Ghul, the document said. After months of investigation, and
surveillance by CIA drones, the e-mail from his wife erased any remaining
Even after Ghul was killed in Mir Ali, the NSAs role in the drone strike
wasnt done. Although the attack was aimed at an individual believed to be
the correct target, the outcome wasnt certain until later when, through
SIGINT, it was confirmed that Hassan Ghul was in fact killed.

@_date: 2013-10-17 22:45:05
@_author: Eugen Leitl 
@_subject: Curious RNG stalemate [was: use of cpunks] 
There's an ARM system in there: but in principle you can resurrect something like that, or
wait until the company sees fit to sell that product again.
You don't need radiation. 12 USD USB SDR can sample 1.5 Msamples/s
at 8 bit, and is as simple as it gets, and is amplifies effectively quantum
noise. I'm not sure how complex is, but you can certainly decap a representative sample from
each lot to validate it.
Seems like a decent business idea.

@_date: 2013-10-18 09:54:46
@_author: Eugen Leitl 
@_subject: Curious RNG stalemate [was: use of cpunks] 
Are they?
This is analog electronics 101. All you have is to sample
that at sufficient rate on the cheap. That used to be a problem, but
no longer is
We do not want a dinky little entropy drip. We want a
regular firehose. The USB RTL samples at 1.4 MSamples/s. Total part costs is probably 20 USD, in bulk.
Why is nobody selling a kit like that? Because worrying about
sufficient entropy in crypto settings is a terribly niche thing.
Now try for a decent clock. (Hint: time-nuts. And did you
know they use CSACs for IED trigger jamming?).

@_date: 2013-10-18 10:37:13
@_author: Eugen Leitl 
@_subject: Curious RNG stalemate [was: use of cpunks] 
I have a couple older VIA C3 with hardware RNG, bought long ago for just that purpose. What kind of motherboard is in there, do you know?
It is unauditable, just as any integrated RNG sources. Which
is not that big of problem, if you mix in enough external entropy
from a trusted source. The trusted source need to be sufficiently
simple to be validated by inspection. You can source RTL-SDRs
from many sources. All you need is to match impedance and output
power from your analog white noise circuit to goldilocks level.
In case anyone is interested,
But there is still no simple kit you could directly plug into your
coax socket. That is a threshold of entry too high for people
who can't tell which part of the soldering iron is the hot one.

@_date: 2013-10-18 11:02:42
@_author: Eugen Leitl 
@_subject: HTML List Abuse (was: "please ignore: this is only a test") 
Many people concerned with security use text-only MUAs,
as that works well over low-bandwidth mobile links and
gives less attack surface against compromises.
The less complexity, the less lines of codes and code
complexity and easier to debug. E.g. by not discarding
HTML-only (but giving preference to plain text in
multipart messages) I'm running risk for having this system
compromised, even if I render via a text browser
like links. That's ok, I consider this system sacrificial.
Rendering rich content in a GUI is courting disaster.
You will get nailed, and be it just malware from spam.
You can assume that people who care know this, so
text-only correlates with old hands and/or high clue.

@_date: 2013-10-18 16:55:46
@_author: Eugen Leitl 
@_subject: Police warning after drug traffickers' cyber-attack 
Eat your heart out, William Gibson.
Police warning after drug traffickers' cyber-attack
By Tom Bateman
Reporter, Today programme
Drug traffickers hacked into the computer controlling shipping containers at
the port of Antwerp
Earlier this year drug traffickers hacked into the computer controlling
shipping containers at the port of Antwerp
The head of Europe's crime fighting agency has warned of the growing risk of
organised crime groups using cyber-attacks to allow them to traffic drugs.
The director of Europol, Rob Wainwright, says the internet is being used to
facilitate the international drug trafficking business.
His comments follow a cyber-attack on the Belgian port of Antwerp.
Drug traffickers recruited hackers to breach IT systems that controlled the
movement and location of containers.
Police carried out a series of raids in Belgium and Holland earlier this
year, seizing computer-hacking equipment as well as large quantities of
cocaine and heroin, guns and a suitcase full of cash.
Fifteen people are currently awaiting trial in the two countries.
Mr Wainwright says the alleged plot demonstrates how the internet is being
used as a "freelance marketplace" in which drug trafficking groups recruit
hackers to help them carry out cyber-attacks "to order".
"[The case] is an example of how organised crime is becoming more
enterprising, especially online," he says.
A Europol official tells Tom Bateman how traffickers hacked into the IT
system at Antwerp port "We have effectively a service-orientated industry
where organised crime groups are paying for specialist hacking skills that
they can acquire online," he adds.
Vanishing containers
The attack on the port of Antwerp is thought to have taken place over a
two-year period from June 2011.
Prosecutors say a Dutch-based trafficking group hid cocaine and heroin among
legitimate cargoes, including timber and bananas shipped in containers from
South America.
The organised crime group allegedly used hackers based in Belgium to
infiltrate computer networks in at least two companies operating in the port
of Antwerp.
The breach allowed hackers to access secure data giving them the location and
security details of containers, meaning the traffickers could send in lorry
drivers to steal the cargo before the legitimate owner arrived.
Workers were first alerted to the plot when entire containers began to
disappear from the port without explanation.
"These criminal organisations always look for a new way to get drugs out of
the harbour," says Danny Decraene who heads the Antwerp organised crime unit
of the Belgian Federal Police.
Bag of cash seized by Belgian police
This suitcase, containing 1.3m euros, was seized by Belgian police during
raids on drug traffickers
"In this case they hired hackers [who were] very high level, intelligent
guys, doing a lot of software work," he adds.
He says the operation to hack the port companies took place in a number of
phases, starting with malicious software being emailed to staff, allowing the
organised crime group to access data remotely.
When the initial breach was discovered and a firewall installed to prevent
further attacks, hackers broke into the premises and fitted key-logging
devices onto computers.
This allowed them to gain wireless access to keystrokes typed by staff as
well as screen grabs from their monitors.
Assault rifle attack
Mr Decraene says the total quantity of drugs trafficked by the group is
unknown, but in a series of raids earlier this year police seized more than a
tonne of cocaine, with a street value of 130m, and a similar amount of
In January a lorry driver unconnected to the plot was shot at after he had
unwittingly driven a container allegedly filled with cocaine from the
terminal at Antwerp.
The attack took place in the province of Limburg, where suspects armed with
AK-47 assault rifles fired at the driver, who was unharmed.
Following the cyber-attack in Antwerp, a joint operation by Belgian and Dutch
police resulted in raids on more than 20 homes and businesses.
Officers seized six firearms including a machine gun and silencer,
bullet-proof vests, and 1.3m euros (1.1m) in cash inside a suitcase.
Mr Wainwright says the IT attack is consistent with a "new business model" of
organised crime activity and he says he expects this kind of cyber-security
breach to "become a more significant feature in future" of drug trafficking.
"What it means therefore is that the police need to change the way they
operate - they have to become much more tech savvy," he says.
"But also I think governments and parliaments need to help us to make sure
therefore that we have the right laws to fight back against this massive
exploitation of the internet," he adds.
Container companies operating out of the port of Antwerp say their IT
security has now been improved.

@_date: 2013-10-19 16:02:44
@_author: Eugen Leitl 
@_subject: HTML List Abuse (was: "please ignore: this is only a test") 
Moon Jones sees no added value as he subscribes to the very same
lists as me. (There is added value for less omniscient/omnipresent, though in order to see it you have to see it from my point of view, and it's not super-big -- I'm mostly a Layer 8 router).
I presume filtering for duplicates is easier if I do bounces,
so I'll do more of that in future.  The relevance is in the followup threads others generate.
I don't do helpdesks, sorry.

@_date: 2013-10-19 16:22:01
@_author: Eugen Leitl 
@_subject: HTML List Abuse (was: "please ignore: this is only a test") 
I'm highly sympathetic to your plight, and suggest the
following solution: install a procmail recipe to filter
out dupes with the same message ID (e.g. <5261AAC3.6050102 in case of the mail I'm replying to) and/or matching Resent-Message-ID: with leitl.org behind it.

@_date: 2013-10-19 18:18:01
@_author: Eugen Leitl 
@_subject: Cheney afraid of terrist h4x0rs 
Cheney had heart device partially disabled to prevent a terrorist from
sending a fatal shock
Olivia Harris, Pool, File/Associated Press -  In an interview with CBS 60
Minutes, former Vice President Dick Cheney says he once feared that
terrorists could use the electrical device that had been implanted near his
heart to kill him and had his doctor disable its wireless function.
By Associated Press, Saturday, October 19, 1:34 AM
WASHINGTON  Former Vice President Dick Cheney says he once feared that
terrorists could use the electrical device that had been implanted near his
heart to kill him and had his doctor disable its wireless function.
Cheney has a history of heart trouble, suffering the first of five heart
attacks at age 37. He underwent a heart transplant last year at age 71.
In an interview with CBS 60 Minutes, Cheney says doctors replaced an
implanted defibrillator near his heart in 2007. The device can detect
irregular heartbeats and control them with electrical jolts.
Cheney says that he and his doctor, cardiologist Jonathan Reiner, turned off
the devices wireless function in case a terrorist tried to send his heart a
fatal shock.
Years later, Cheney watched an episode of the Showtime series Homeland in
which such a scenario was part of the plot.
I found it credible, Cheney tells 60 Minutes in a segment to be aired
Sunday. I know from the experience we had, and the necessity for adjusting
my own device, that it was an accurate portrayal of what was possible.
Cheney and Reiner are promoting a book they co-authored, Heart: An American
Medical Odyssey.
In the 60 Minutes interview, Reiner says he worried that Cheney couldnt
stand the pressure that came on Sept. 11, 2001, the day terrorists attacked
the U.S. Medical tests seen that morning showed Cheney had elevated levels of
potassium in his blood, a condition called hyperkalemia, which could lead to
abnormal heart rhythms and cardiac arrest.
Reiner says he watched news coverage of the days events on television and
thought, Oh, great, the vice president is going to die tonight from

@_date: 2013-10-21 14:10:49
@_author: Eugen Leitl 
@_subject: The Most Lethal Weapon Americans Faced in Iraq 
(did you see the LEDs blink?)
October 18, 2013, 10:35 am Comment
The Most Lethal Weapon Americans Faced in Iraq
By JOHN ISMAY
In the first part of this series, At War explored the various conventional
weapons used by insurgents in Iraq, as evidenced by reports, called
storyboards, written by United States forces detailing the contents of
captured weapons caches. Often times these weapons had been considered
obsolete before 2003. But they were well known to Western intelligence
services and militaries.
Today, we look at weapons that the American military could not have
reasonably foreseen entering the fray, but that caused large numbers of
casualties. These are the improvised weapons that were made by hand, or in
small shops, and that, with one exception, were not made in industrial
Improvised Explosive Devices
At the time these storyboards were written, improvised explosive devices, or
I.E.D.s, caused approximately 80 percent of all coalition casualties.
 Page 1 of  27 
A network of insurgents financed, designed and manufactured these weapons.
Skilled bomb makers worked in clandestine shops, and leaders of I.E.D.
networks sent bomb emplacers to bury or hide their improvised bombs along
routes American patrols were expected to take.
Standard bomb-making equipment showed up again and again in the caches,
including: multimeters for checking the electrical continuity in circuits;
personal mobile radios for transmitting firing signals; switches to close
circuits; electric blasting caps; detonating cord for when multiple charges
were used.
Earlier firing systems often employed a variety of radio-controlled features.
Keyless entry fobs for automobiles, garage door openers, toy car controllers
 these all provided parts for initiating bombs, at least until coalition
electronic countermeasures made them almost completely ineffective. Other
common articles took their place.
Insurgents stripped timers from washing machines, or bought them by the
hundreds from commercial sources. Motion sensors meant to open grocery store
doors or to turn on security floodlights also found their way into bomb-maker
supply bins. These devices could trip a switch and initiate an explosion when
a soldier crossed their path.
The first bomb emplacers, many of them uneducated youth, sometimes blew
themselves up while connecting the basic components of their weapons: power
source, switch and explosive charge. They were supposed to connect these
parts with an open circuit, since connecting a closed circuit would send
current to an electric blasting cap. If that happened, it usually meant
instant death for the emplacer. To make bomb emplacement less
catastrophically failure-prone, bomb makers searched for devices that could
mechanically break the electric circuit. The washing machine timer was one
that worked. All the emplacer had to do was wind it up before connecting the
circuit and he would have a set amount of time to escape before the bomb was
armed. The use of these timers showed an adaptive enemy who learned from his
Explosively Formed Penetrators and Iranian C4
The single most lethal weapon American forces faced in Iraq was the
explosively formed penetrator, or E.F.P. Unlike other I.E.D. charges, E.F.P.
warheads required some skilled milling as well as heavy presses to produce.
Certain copper alloys were used as well, and analysis of their construction
was used to pinpoint the manufacturers.
What makes E.F.P.s so deadly is that they form slugs at detonation that
maintain their shape over distances of over 100 yards or more, traveling at
speeds of nearly a mile per second. This allowed insurgent forces to hide
these weapons far from the road, better camouflaging them and making them far
more deadly. In some I.E.D. factories, American forces found E.F.P.s
camouflaged to look like trash or rocks.
Much has been made of E.F.P.s generally being new Iranian weapons, but
that conflates two unrelated facts. First, E.F.P.s technology was invented
in the late 1930s by the oil industry to punch holes through the metal pipe
in wells and into the rock outside. These are called oil well perforators or
perforator guns. Any country engaged in oil field development has access to
E.F.P.s. Iran lists their domestically produced perforators for sale online.
Second, militaries applied this technology to anti-armor weapons as early as
World War II. (The United States military currently employs several weapons
incorporating E.F.P. warheads, to include the M2 SLAM, the TOW-2B, and the
M303 SOF Demolition Kit.)
But they became known as Iranian weapons because American intelligence
agencies reported that Iran passed E.F.P. technology to the Lebanese militia
Hezbollah, which in turn passed E.F.P. kits to proxy groups fighting in Iraq.
In the case of the Iraqi insurgent weapons, E.F.P.s arrived in kit form, and
were hand-packed with plastic explosives by bomb makers in Iraq just before
use. For their explosive charges, insurgents often turned to an Iranian copy
of an American staple: C4, packaged nearly identically to the original
1.25-lb M112 blocks. (Of note, the American M112 blocks changed their
markings slightly in 1996 once chemical tracers, called taggants, were added
in accordance with federal law; Iranian M112 block markings mimic the
pre-1996 markings.) According to an official with the Bureau of Alcohol,
Tobacco, Firearms and Explosives, manufacturing C4 is not difficult for any
nation capable of making industrial chemicals.
Homemade Explosives
Not long after the invasion, insurgents began mixing their own batches of
explosives and using them against their American adversaries. At first, these
mixtures were referred to simply as U.B.E.  unknown bulk explosive. Later,
the term HME, for homemade explosive, came into wide use.
As an agrarian society, Iraq had a nonstop demand for nitrated fertilizers 
urea and ammonium nitrate being the most common. Ground urea, mixed with
nitric acid, drained and dried, is a powerful explosive. Some caches held
bags of hexamethylenetetranitramine, which when mixed with nitric acids
produces a powerful explosive known as RDX. Still others combined ammonium
nitrate and diesel fuel oil to create the same explosive Timothy McVeigh used
to level the Alfred P. Murrah Federal Building in Oklahoma City in 1995.
Fertilizer plants, such as this one at Baiji, produced 500,000 tons of
fertilizer per year.
When homemade explosives first came into wide use in Iraq, American military
officers initially thought it was a sign that the insurgents were running out
of conventional or military-grade, munitions. That assumption had no basis
in fact. What it did signal was that the enemy had realized that bulk
explosives were more valuable and, in certain situations, more lethal.
Experience showed that a large enough charge could destroy any armor, or at
least wreak enough damage to cause casualties inside the targeted vehicle. In
Afghanistan, homemade explosives became such a problem for NATO forces that
President Hamid Karzais government banned ammonium nitrate in 2010.
End State
Although the last United States Army mission to destroy excess ordnance ended
in November 2011, violence in Iraq has continued well past the withdrawal of
the last American combat forces. According to the United Nations, nearly
1,000 Iraqi civilians were killed in September alone, amid levels of violence
last seen in 2008.
Between 2003 and 2010, the State Department spent more than $200 million on
destroying unexploded munitions in the country. Groups like Mines Advisory
Group continue their work in Iraq as well.
In July 2012, the State Departments own Web site gives an idea of the
challenges that lie ahead: In spite of progress, at least 719 square miles of
land is still contaminated by as many as 20 million land mines and millions
of pieces of unexploded ordnance. More than 1,600 municipalities are
affected, as are huge swathes of farmland, meaning clearing those explosives
will be an economic necessity. And as American forces discovered early in the
insurgency  and which Iraqis know all too well  every weapon and every
explosive that is not disposed of will eventually be put to destructive use
by some faction.
John Ismay is a former U.S. Navy Explosive Ordnance Disposal officer who
served in Iraq in 2007, and is now a member of Columbia Journalism Schools
class of 2014. Follow him on Twitter ( and on his blog

@_date: 2013-10-21 14:18:22
@_author: Eugen Leitl 
@_subject: The Secret History of =?utf-8?Q?Iraq?= =?utf-8?B?4oCZcw==?= 
(notice the date)
The Secret History of Iraqs Invisible War
BY NOAH SHACHTMAN 06.14.114:00 AM
In the early years of the Iraq war, the U.S. military developed a technology
so secret that soldiers would refuse to acknowledge its existence, and
reporters mentioning the gear were promptly escorted out of the country. That
equipment  a radio-frequency jammer  was upgraded several times, and
eventually robbed the Iraq insurgency of its most potent weapon, the
remote-controlled bomb. But the dark veil surrounding the jammers remained
largely intact, even after the Pentagon bought more than 50,000 units at a
cost of over $17 billion.
Recently, however, I received an unusual offer from ITT, the defense
contractor which made the vast majority of those 50,000 jammers. Company
executives were ready to discuss the jammer  its evolution, and its
capabilities. They were finally able to retell the largely-hidden battles for
the electromagnetic spectrum that raged, invisibly, as the insurgencies
carried on. They were prepared to bring me into the R&D facility where
company technicians were developing what could amount to the ultimate weapon
of this electromagnetic war: a tool that offers the promise of not only
jamming bombs, but finding them, interrupting GPS signals, eavesdropping on
enemy communications, and disrupting drones, too. The first of the these
machines begins field-testing next month.
On a fist-clenchingly cold winter morning, I took a train across the Hudson
River to the secret jammer lab.
Tucked behind a Target and an Olive Garden knock-off, the flat, anonymous
office building gives no hint of whats inside. Nor do the blank,
fluorescent-lit halls. But open a door off of one of those halls, and people
start screaming.
Screens off! barks a man with a fullbacks build. Turn off the test
equipment! On the ceiling, a yellow alarm light flashes and spins  the sign
that someone without a security clearance is in a classified facility.
Afghan militants began attacking U.S. troops with improvised explosive
devices in the first days after the October 2001 invasion. By early 02,
al-Qaida bomb-makers were cramming radio frequency receivers and simple
digital signal decoders into the bases of Japan InstaLite fluorescent lamps.
Then theyd connect the two-and-a-half inch wide lamp bases to firing
circuits, and to Soviet-era munitions. The result was a crude,
radio-controlled weapon dubbed the Spider by the Americans. With it, an
attacker could wait for his prey, set off the bomb at just the right moment 
and never have to worry about getting caught. When the explosion happened,
hed be hundreds of yards away.
Worse, U.S. forces had no way of blocking the Spiders triggering signal.
Military bomb squads carried around a few half-assed jammers. But they
couldnt be mounted on vehicles, and they were too weak to provide
protection beyond a few yards, Rick Atkinson notes in his exquisite history,
Left of Boom: The Struggle to Defeat Roadside Bombs.
If somebody sits a kilometer away with a radio and targets our guys, weve
got no ability to get him. Navy engineers hustled to build something a
little stronger, and a little more portable. By November of 2002, they had a
jammer called Acorn that was hard-wired to stop Spiders. It wasnt much. As a
so-called active jammer, the Acorn put out a relatively-indiscriminate
barrage signal that ate up power and generated all kinds of interference.
That kept its effective radiated power  the amount of signal hitting any one
bomb receiver  low. The signal was so weak, the jammer had to be left on and
screaming constantly. Otherwise, troops would be inside the bombs danger
radius before they ever had a chance to block it. Worse, it could only block
the specific receivers used in Spiders. If the bombers switched frequencies,
the countermeasure would be useless.
Meanwhile, the Army looked for ways to modify its Shortstop Electronic
Protection System, designed to shield troops from artillery and mortar fire.
This was a so-called reactive countermeasure. It monitored the airwaves,
listening for one of the radio signals used by the munitions proximity
fuses. Once the countermeasure heard that signal, Shortstop recorded it,
modified it, and then blasted it back at the munition. By confusing the
weapons with their own signals, Shortstop could fool the shells into
prematurely detonating.
The soldiers tweaked the Shortstop to scan for radio-controlled bombs
triggering frequencies, and to rely on a Humvees power supply. The wife of
one Fort Monmouth engineer collected miniature kitchen witches that inspired
a new name for the device: Warlock Green, Atkinson recounts.
Five Warlock Greens accompanied U.S. forces into Iraq in March, 2003. By
mid-summer, there were 100 jammers in the warzone. It wasnt nearly enough.
Iraqs militants had learned from their compatriots in Afghanistan, and were
setting off remotely-detonated explosives everywhere.
Just like the first turn of this improvised explosive device (IED) war, the
electronic countermeasures were having trouble keeping up with the bombs. It
took Warlock Green, ultimately manufactured by the EDO Corporation, a couple
of seconds to record, modify, and rebroadcast a triggering signal. An
insurgent bomber could set off an explosive in a few fractions of a second,
if he had a simple, low-powered trigger, like a garage door opener. The
jammer didnt have time to catch up.
The jammers could only cover a small slice of the radio frequency spectrum.
Whenever the insurgents should change triggers  from say, door openers to
key fobs  the jammer-makers would have to go back to the drawing board.
Warlock Greens could be reprogrammed, within limits. The Acorns couldnt; the
new threats rendered them useless.
Every time we put a countermeasure in the field  especially with Warlock 
they were able to outstrip it, says Paul Mueller, a long-time defense
executive, who supervised jammer-building operations at EDO  and at the ITT
Corporation. They were a step ahead of us.
Every time we used a countermeasure, they were able to outstrip it. But
with insurgents setting off 50 IEDs a week, even the step-behind jammers were
better than no jammers at all. By May 1, 2004  one year to the day since
President George W. Bush declared the end of major combat operations  the
improvised bombs had wounded more than 2,000 American troops in Iraq. The
IEDs killed 57 servicemembers in April alone, and injured another 691. IEDs
are my number-one threat in Iraq. I want a full-court press on IEDs, Gen.
John Abizaid, then the top military commander in the Middle East, wrote in a
June 2004 memo.
In the early fall of 2004, the Army signed a contract for 1,000 Warlocks. By
March, 2005, the Army upped that order to 8,000 jammers. It was a high-tech,
electromagnetic surge. And it was meant to send the militants sliding back
down the scale of sophistication. If somebody can sit a click [kilometer]
away with a radio and target our guys, weve got almost no ability to get
him, says a source familiar with the jammer buildup. But if hes doing the
Wile E. Coyote thing, and pushing down that plunger, at least weve got some
chance to shoot him before he gets it down.
All the big defense contractors  and lots of little ones  got into the
electronic countermeasure business. The Marines bought one model; the Army
another; Special Operations Forces, a third. The Army began buying Warlock
Reds  small, active jammers that blocked out the low-powered triggers that
Warlock Green couldnt stop in time. Warlock Blue was a wearable jammer, to
protect the infantryman on patrol. Each countermeasure had its shortcomings;
Warlock Blue, for instance, was a half-watt jammer at a time when some
engineers suspected that 50 watts might be too weak, Atkinson notes. But no
commander could afford to wait for a perfect, common bomb-stopper; too many
men were getting blown up. By May 1, 2005, the number of U.S. troops wounded
by the bombs had climbed to more than 7,700.
There were drawbacks to throwing all those countermeasures into the field at
once. Warlock Green would sometimes mistake Warlock Reds signal for an
enemys, and go after it. That would lock the jammers in a so-called deadly
embrace, cancelling one another out.
When the Warlocks were operational, they wreaked havoc with both the
remote-controlled robots that were supposed to handle bombs at a safe
distance and the radios soldiers used to warn each other about upcoming
threats. Warlock Red prevented communications from three of the Armys most
common radio systems, according to a classified report released by WikiLeaks.
The report recommended keeping radios and countermeasures in different
vehicles to prevent the electronic fratricide. Of course, that meant a
soldier with a jammer in his Humvee was cut off from the rest of his convoy.
For reporters, pointing out these drawbacks  in fact, pointing out anything
about the jammers  risked a swift military response. In Baghdad, a top
official with the Joint IED Task Force called me an al-Qaida ally for putting
together a Wired.com report on counter-IED technologies based on other
publicly-available information. A few months later, David Axe mentioned the
Warlocks in a post for Defensetech.org from Iraq. Shortly after the post went
live, Axe was detained, and was promptly thrown out of the country.
Even more secret were the flights of the jammers in the sky. The Navys EA-6
Prowlers could not only block triggering signals; they could remotely
detonate the bombs, as well. But they had to be very, very careful. U.S.
vehicles equipped with jammers had to get off of the roads, or risk the
deadliest embrace of all. Pilots had to make sure that civilians were nowhere
nearby, when they set the bombs off.
Despite the hiccups, the jammers were saving lives  including, I believe, my
In July of 2005, I found myself at a rubble-strewn intersection of two
highways, not far from Iraqs Abu Ghraib prison. The Explosive Ordnance
Disposal team I was traveling with called this place the Death X, because
of all the attacks nearby. The bomb squad was called out to the area because
of a suspicious package  a package that turned out to be nothing more than a
balled-up pair of pants. But on the way back from the incident, our Humvee
rolled over an artillery shell, buried in the highways middle lane and wired
to a radio. An improvised bomb.
The IED didnt go off, for reasons that werent completely clear. The Death X
bomber might have gotten cold feet. More likely, one of Warlocks in the
Humvee prevented him from detonating the weapon.
That same day, I took a Black Hawk ride to the town of Mahmudiya, just south
of Baghdad. At the outpost there, I met Staff Sgt. Johnnie Mason (pictured),
who showed off the cordless phone than nearly killed him. It was wired to a
series of artillery shells, and stuffed under a row of human corpses, rotting
by a canal in the 118 degree heat.
The dead bodies, they smelled like catfish bait.
When Mason  a lanky, 31 year-old Texan with big brown eyes and a goofy smile
 came across the bomb, he wanted to puke into his Kevlar protective suit.
The dead bodies, they smelled like catfish bait. But there was no time to
heave. Mason knew the weapon was live, and that he was outside his Warlocks
protective bubble. He figured he only had a moment or two to act before a
bomber remotely detonated his device. So Mason jumped behind a three-foot
berm, and crouched into a fetal position before the shock wave hit him. It
was too fast for me to think, Oh God, Im gonna die, Mason said. It was
just instant fear.
The bomb was less than twenty feet away when it went off. Dirt flew up.
Shards of bomb zipped through the air. The shockwave knocked Mason over. But
he was intact, somehow.
Masons partner, Pfc. Brian James, ran over. Are you alright? he yelled.
Where you at?
Im in Iraq, Brook! Mason shouted back. Brook was his wifes name.
Mason sat down for fifteen minutes, drank some water. And then he went right
back to the bodies. Before the explosion, he noticed a second shell, 20
meters away. So Mason took a couple pounds of C4 plastic explosive to
demolish the thing. I still had a job to do, he told me.
Five months later, on the 19th of December, Mason found himself on another
highway, responding to another suspicious package call. His team stumbled on
another IED, practically beneath their feet. Insurgents were routinely luring
bomb squads with one weapon in an attempt to kill them with the second. In
this case, the tactic worked.
Mason told everyone to clear out of the way while he tried to disarm the
device. Then the bomb went off.
Johnnie Mason was buried at Arlington Cemetery on January 10, 2006.
2006 rolled on. The insurgency in Iraq got worse. Much worse. The number of
troops wounded by bombs hit 15,000, and kept going. Explosively formed
projectiles  bombs that shot out jet of molten, armor-piercing metal  went
from a macabre curiosity to something like a staple of the insurgent arsenal.
There seemed to be no end to the carnage.
Militant bombmakers increasingly turned to long range cordless telephones and
cell phones for their triggers. That was a serious issue. The digital devices
were built to overcome dropped packets, reflected signals, and transmission
errors. Warlock Greens trick of fooling a trigger with its own, modified
signal didnt work. The gadgets were used to the hiccups.
The deadly embrace between the jammers began to loosen.
Behind the scenes, however, there were signs of improvement. The Navy sent to
Iraq hundreds of electronic warfare specialists, to bring the cacophony
produced by 14 kinds of jammers into some sort of harmony. Protocols were
established, to allow one device to send its signal and then go silent for a
few milliseconds, so another gadget could broadcast; that allowed Warlock Red
and Warlock Green to be packaged into a single, combination unit. The deadly
embrace between the jammers began to loosen. The Pentagons IED task force
became the Joint IED Defeat Organization, or JIEDDO, with a $3.6 billion
annual budget to tame the homemade bomb threat. Mongtomery Meigs, the retired
four-star general in charge of the organization, worked to unravel the
bureaucratic tangle that tied up bomb trigger analysis. The intelligence
specialists at the Combined Explosive Exploitation Cells got faster and
faster at analyzing which frequencies the insurgents were using. That, in
turn, allowed the jammers to be updated more quickly, so they could counter
emerging threats.
Most importantly, perhaps, a new generation of jammers entered the
battlefield, thanks to JIEDDOs billions. Some, like the Marines Chameleon
countermeasure, could cover a broad range of frequencies, from low-powered
triggers (like key fobs) to high-powered ones (like walkie-talkies). In
February of 06, the Corps announced they were buying 4,000 of the 125-pound,
Humvee-mounted systems.
Warlock Duke used a technique called set-on jamming to overcome the more
advanced digital triggers. Like Green, Duke would listen for a malicious
signal. But rather than confuse a receiver with a modified version of its own
signal, Duke had a series of built-in jamming responses, designed to fool
very specific devices. If Duke heard a particular FM walkie-talkie, Duke
would send out a specific FM spoof. It was actually a cruder technique than
Greens. And it relied on very detailed knowledge about exactly which threats
were in which area. But it worked. Tens of thousands were eventually fielded.
And slowly, slowly, the percentage of radio-controlled bombs as a whole began
to fall. Then they began to disappear altogether.
Electronic warfare defensive systems were instrumental in saving thousands
of Soldiers and Marines from being casualties in Iraq, emails retired Lt.
Gen. Michael Oates, who led the 10th Mountain Division during its tour in
Iraq at the time, and then became director of JIEDDO. The high use of remote
controlled detonation capability was a significant and effective threat
until the jammers were developed.
By the time I returned to Iraq, in the summer of 2007, IEDs had become relics
in broad swaths of the country. The insurgents had largely abandoned their
tool of choice.
It was not altogether good news.
North of Baghdad, insurgents took insulated copper threads, some not much
thicker than a hair, and buried them in the dust. Then they strung them out
for as long as a kilometer. At one end was an insurgent triggerman. At the
other, an explosively formed projectile. It was a crude approach to killing 
even more primitive than those first bombs planted in Afghanistan. But it was
lethally effective.
These command wire bombs had a fatal flaw, however. Insurgents had to stick
around to set them off. That made them vulnerable to American counter-attacks
and preemption. And that brought the number of bombs and bomb fatalities way
down. In December of 2007, only nine U.S. troops were killed by IEDs, and
another 166 were wounded. It was still an awful toll. But it was a tiny
fraction of the 69 slain and 473 injured in December of 2006.
All the gadgets built for Iraq were worthless against Afghanistans throwback
The casualty figures continued to fall as the military began to field a third
generation countermeasure  one that could stomp out a huge swath of radio
triggers with all sorts of jamming techniques. In April of 2007, the Pentagon
signed a deal with EDO for up to 10,000 of the so-called CVRJs. Shortly
thereafter, ITT bought EDO, and began to crank out the machines. The CVRJ
held up to 15 mission loads at once, quadrupled the number of simultaneous
channels it could jam on, and doubled the spectral coverage of pre-existing
systems. More importantly, the CVRJ could be reprogrammed on the fly: not
just the frequencies it covered, but the specific responses it used to
counter particular threats. For the first time ever, says Mueller, the
EDO-turned-ITT executive, we had a canvas to create a painting.
That enabled CVRJ to target the most advanced triggers  the ones which
relied on the latest mobile and long-range cordless phones. The new phones
hopped between frequencies and spread their signal across the spectrum to
overcome interference. That made them much harder to jam. But the phones have
a potential flaw. They relied on software protocols to establish connections
between transmitter and receiver. Those protocols could be spoofed, keeping
the connection from ever happening. That is, if you had a fully programmable
countermeasure, like CVRJ.
In the broadest sense, the strategy behind the U.S. jammer buildup had
succeeded. Thanks to the Americans bleeding edge technologies, the militants
had dropped back down the ladder of sophistication. They were now taking the
Wile E. Coyote approach  pushing down the plunger to detonate the bomb  and
suffering for it. That was the whole intent of the program: pushing the
enemy back to archaic means, says a source familiar with the effort. So
theyd actually have to face you and fight you.
In Afghanistan, however, the terrain favored the low tech. All the gadgets
the Americans had bought and built for Iraq proved largely worthless against
a new slew of throwback threats. The bombs were largely made of wood and
fertilizer, making them practically invisible to metal detectors. No command
wires were needed to set them off; just the pressure of an unlucky boot. The
placement of the bombs added to their effectiveness. The U.S. militarys new
hard-shelled, blast-deflecting vehicles were built for Iraqs well-paved
roads. So the insurgents put their explosives in the gullies and the mud
paths, where the trucks were useless. The bomb-handling robots couldnt
handle the rough terrain, either. And, during the summer, the weather was so
hot, EOD technicians didnt even bother wearing their protective suits.
As the fighting grew more intense  and the U.S.-led coalition poured more
troops into the Afghan campaign  the total number of bombs there crept up,
from 1,931 in 2006 to 3,276 in 2008. By July, 2010, that figure had reached
nearly 1,400 explosives found or detonated a month. Its stayed about that
high ever since.
The deaths and injuries caused by these bombs continued to mount, as well. In
July 2008, 25 American troops were wounded by Afghan IEDs. In July 2009, that
figure was 174. In July 2010, the number was 378 injured  about 15 times
higher than the casualty count from two years before.
JIEDDO shifted its focus to compensate. Jammers alone werent going to do
much against these no-tech weapons. The organization spent more on
surveillance and intelligence analysts, trying to find ways to crack apart
Afghanistans IED networks.
But even if those networks are shredded tomorrow, theres a sense in the
Pentagon that the improvised bomb has now become a permanent threat. Over the
last six months, theres been an average of 245 jury-rigged explosives found
or detonated  outside of Iraq and Afghanistan. The IED has gone global.
The lab where ITT engineers work on the fifth generation of bomb-stoppers
looks like a schoolroom  from the desks facing the front of the room to the
guy with the ponytail and circular glasses delivering the lecture. Behind the
guy  hes an engineer, not an English prof  are two screens. One shows a
CGI version of a jammers guts: the amplifiers, the transceivers, what have
you. The other screen shows a map of a military base, covered in red and
green. It shows how the countermeasure might perform with that configuration.
The Pentagon cant afford any more to crank out yet another stop-gap
countermeasure for yet another kind of bomb. So the military is instead
backing the development of a jammer that can be used anywhere, and for years
to come. The system is awkwardly known as Joint Counter Radio-Controlled
Improvised Explosive Device Electronic Warfare 3.3. An initial batch of 21 of
these JCREW machines are supposed to ship to the military in July for field
testing. If it passes those trials, among other hurdles, up to 20,000 of the
uber jammers could eventually be built.
Aircraft, vehicles, ships, and troops are all on the new jammers target
list.  But before it gets into troops hands, the countermeasure gets
simulated here. Lower the antenna from 15 feet to five makes more red
splotches appear on the map, indicating gaps in jammer coverage. Add a bigger
amplifier, and some of the red goes away.
ITT has bigger ambitions for its JCREW machine than simple bomb-blocking.
Step through a door, and theres a more traditional-looking electronics
workroom: cable-strewn benches, and machines stacked head-high. Guys with
soldering irons connect wires to boxey machines. The goal here isnt to see
how the countermeasures block signals. Its to see how they talk to one
another. Theres a JCREW jammer designed for vehicles, another for individual
troops, and a third to protect bases. All of the machines are meant to work
The JCREW 3.3s are supposed to be fully networkable, and able to communicate
over the militarys wireless battlefield networks. That should save them some
power and interference if youve got four jammers in a convoy, for instance,
one can silence a receiver while the other three quiet down. Or maybe that
jammer can spot the threat, record its signal and location, and transmit that
information back to headquarters. In that way, the new machine becomes more
than a single bomb-beater. The system might help track down the explosives,
and the guys who planted them. It could be configured to listen in on
communications  those cell phones are for more than triggering explosives,
after all. Hell, if the machines are passing data back and forth, they could
work as radios themselves, in theory.
With proper power management and frequency coordination, the new JCREW could
have a whole new range of potential targets, according to a company
briefing. Those include information systems and infrastructure, drones,
communications grids, sensors, position, navigation and timing capabilities
(thats shorthand for GPS signals), as well as aircraft, vehicles, ships,
troops. In other words: everything.
For now, these are just ideas, not orders. Its all on the roadmap,
potentially, Mueller says. How much we actually do remains to be seen.
But one thing is for sure: its a long way from stopping crude triggers,
stuffed into disposable lamps. Its a long way from frantically tweaking
electronics in the hope of somehow keeping thirty soldiers a day from being
blown up. Its a long way from the near decade-long fight against
remote-controlled bombs in which the enemy had the advantage of being the
first mover. This may be the chance to get ahead, before the next wave of
terror weapons hits.
Photos: USMC, Wikimedia, Noah Shachtman, ITT

@_date: 2013-10-21 14:34:48
@_author: Eugen Leitl 
@_subject: russian FSB requires all ISPs to give them access to metadata by 1 
Source: Not less than 12 hours logging of (all? or meta?) data,
with direct acess given to FSB (SORM, almost certainly
a VPN gateway to FSB like German SINA Box).

@_date: 2013-10-22 10:51:56
@_author: Eugen Leitl 
@_subject: Enigmabox releases source 
Just got word, Enigmabox has published source and
put up first documentation on Roll your own Enigmabox: Not too sure how to get a Debian 7 with minimum pain,
pfSense offers dd'able images. Voyage Linux or Debian for Alix?

@_date: 2013-10-22 11:55:52
@_author: Eugen Leitl 
@_subject: Undernet IPv6 Interop [was: Enigmabox/cjdns] 
Yes. If people are not familiar with cjdns, here's a good
intro I've asked about this a while back among a few IPv6 people, and it does not seem to be a problem. The keys/addresses are randomly generated and are all in FC00::/8. 120 bits is a lot of space. cjdns interoperates fine with dual-stack. The interesting
part is L2 routing over own infrastructure, and eventual
ASIC/FPGAfication of the router.

@_date: 2013-10-25 11:45:13
@_author: Eugen Leitl 
@_subject: Gentlemen do not read each other's mail... 
I see zero evidence that anyone is furious. It's pure political theater to appease those few percent of voting cattle that are privacy-minded. Notice everybody is carefully staying away from mandating simple
and the only measures which would work: strong end to end encryption,
with secrets held by end users, in tamper-proofed compartments.
Because this would seriously compromise their own surveillance
capability. And we certainly can't have that, oh noes.
People in power are used that the common laws are strictly for
the commons, so for those few clueless the outrage to be no
longer exempt might be even genuine.
So ruthlessly machiavellian, or clueless and entitled, pick
your poison.

@_date: 2013-10-28 08:20:42
@_author: Eugen Leitl 
@_subject: Another Snowden News Story. Another Lesson in Proper 
No. Trying to keep short-attention-span people engaged. It might not make a differences, but not even trying
would be foolish.

@_date: 2013-10-28 08:58:24
@_author: Eugen Leitl 
@_subject: Armed agents seize records of reporter, Washington Times prepares 
Armed agents seize records of reporter, Washington Times prepares legal
** FILE ** Associated Press** FILE ** Associated Press By Guy Taylor-The
Washington Times Friday, October 25, 2013
The Washington Times
Maryland state police and federal agents used a search warrant in an
unrelated criminal investigation to seize the private reporting files of an
award-winning former investigative journalist for The Washington Times who
had exposed problems in the Homeland Security Department's Federal Air
Marshal Service.
Reporter Audrey Hudson said the investigators, who included an agent for
Homeland's Coast Guard service, took her private notes and government
documents that she had obtained under the Freedom of Information Act during a
predawn raid of her family home on Aug. 6.
SEE ALSO: Judicial Watch sues IRS for stonewalling on tea party FOIA The
documents, some which chronicled her sources and her work at the Times about
problems inside the Homeland Security Department, were seized under a warrant
to search for unregistered firearms and a potato gun suspected of belonging
to her husband, Paul Flanagan, a Coast Guard employee. Mr. Flanagan has not
been charged with any wrongdoing since the raid.
The warrant, obtained by the Times, offered no specific permission to seize
reporting notes or files.
The Washington Times said Friday it is preparing legal action to fight what
it called an unwarranted intrusion on the First Amendment.
While we appreciate law enforcements right to investigate legitimate
concerns, there is no reason for agents to use an unrelated gun case to seize
the First Amendment protected materials of a reporter, Times Editor John
Solomon said. This violates the very premise of a free press, and it raises
additional concerns when one of the seizing agencies was a frequent target of
the reporters work.
Homelands conduct in seizing privileged reporters notes and Freedom of
Information Act documents raises serious Fourth Amendment issues, and our
lawyers are preparing an appropriate legal response, he said.
Maryland State Police declined comment, except to say that evidence and
information developed during this investigation is currently under review by
both the Anne Arundel County State's Attorney's Office and the United State's
Attorney's Office, and that a determination has yet to be made on any
PHOTOS: Families suspect SEAL Team 6 crash was inside job The U.S. Coast
Guard confirmed it seized and reviewed Ms. Hudsons documents but insisted it
did nothing wrong.
Capt. Tony Hahn, a spokesman at Coast Guard headquarters in Washington, said
the Coast Guard Investigative Service (CGIS) was involved in the case because
Mrs. Hudsons husband, Mr. Flanagan, is a Coast Guard employee.
During the search of the home, said Capt. Hahn, the CGIS agent discovered
government documents labeled FOUO  For Official Use Only and LES  Law
Enforcement Sensitive.
The files that contained these documents were cataloged on the search
warrant inventory and taken from the premises, he said. The documents were
reviewed with the source agency and determined to be obtained properly
through the Freedom of Information Act.
Ms. Hudson described a harrowing ordeal the morning her family home was
The agents, who had arrived a 4:30 a.m. in full body armor, collected several
small arms during the raid, although no charges have been filed against Mr.
Flanagan, 54, during the nearly three months since.
Mrs. Hudson, 50, says that while the authorities were raiding her house,
Coast Guard investigator Miguel Bosch  who formerly worked at the marshal
service  began asking questions about whether she was the same Audrey
Hudson who had written the air marshal stories for The Washington Times.
Mrs. Hudson says she responded that she was.
It was not until roughly a month later, Mrs. Hudson says, that she realized
the agents had quietly seized five files from her private office  including
handwritten and typed notes from interviews with numerous confidential
sources related to her exclusive reporting on the air marshals service.
The search warrant for the raid, issued to Maryland State Trooper Victor
Hodgin by a district court judge, made no reference to the documents. A copy
obtained by The Times indicates that the search was to be narrowly focused on
the pursuit of firearms and their accessories and/or parts, as well as
any communications that that might be found in Mrs. Hudson and Mrs.
Flanagans home related to the acquisition of firearms or accessories.
David W. Fischer, a private attorney contacted by the couple, says that the
raid is a potential violation of Mrs. Hudsons constitutional rights.
Obviously, the warrant is about a gun, nothing about reporters notes, he
said. It would be a blatant constitutional violation to take that stuff if
the search warrant didnt specifically say so.
This is a situation where they picked very specifically through her stuff
and took documents that the Coast Guard, or the Department of Homeland
Security, would be very interested in, he added.
The raid could constitute illegal search and seizure under the Fourth
Amendment  and the fact that the materials were related to her work as a
reporter could First Amendment freedom of the press protections.
Once the documents had been cleared, Homeland decided to return the
documents to Mr. Flanagan and Mrs. Hudson, Capt. Hahn said.
The Coast Guard, like the Federal Air Marshal Service is an agency within the
U.S. Department of Homeland Security.
A Reporters Word
What concerns Mrs. Hudson and The Times is the fact that private reporting
documents were seized during the search being conducted on totally unrelated
While Mr. Flanagan has a police record from the mid-1980s related to the
unlawful possession of firearms, including automatic weapons, Mrs. Hudson
fears her private documents may have been the real target of the search.
They tore my office apart more than any other room in my house, she said,
adding agents did not take other potentially non-TSA-related documents from
the office.
I had a box full of [Department of Defense] notes, she said. They didnt
touch those.
Some of the files included notes that she had used to expose how the Federal
Air Marshal Service had lied to Congress during the years after the Sept. 11,
2001, terrorist attacks about the number of airline flights that the service
was actually protecting against another terrorist attack.
A story written by Mrs. Hudson for The Times in March 2005, revealed how air
marshals were protecting less than 10 percent of domestic and international
flights during the month of December 2004, and that the number of flights
Homeland Security officials were providing to Congress was higher than the
actual number of marshals it employed.
Mrs. Hudson says that the experience of having a half-dozen armed officers
rifle through my personal belongings for the three-hour search was
But when the files were returned to me and I saw all the notes that had been
in their possession for a month, it was gut-wrenching, she said.
That her private files were seized, says Mrs. Hudson, is particularly
disturbing because of interactions that she and her husband had during the
search of their home, as well as months afterwards, with Coast Guard
investigator Miguel Bosch. According to his profile on the networking site
LinkedIn, Mr. Bosch worked at the Federal Air Marshal Service from April 2001
through November 2007.
It was Mr. Bosch, Mrs. Hudson says, who asked her during the Aug. 6 search if
she was the same Audrey Hudson who had written the air marshal stories. It
was also Mr. Bosch, she says, who phoned Mr. Flanagan a month later to say
that documents taken during the search had been cleared.
During the call, according Mrs. Hudson, Mr. Bosch said the files had been
taken to make sure that they contained only FOIA-able information and that
he had circulated them to the Transportation Security Administration, which
oversees the Federal Air Marshal Service, in order to verify that it was
legitimate for her to possess such information.
Essentially, the files that included the identities of numerous government
whistleblowers were turned over to the same government agency and officials
who they were exposing for wrongdoing, Mrs. Hudson said.
Reached on the telephone by a reporter for The Times, Mr. Bosch refused to
comment on whether or not journalist-related documents were seized during the
search of Mrs. Hudsons home.
I got to get on the phone with Coast Guard legal before I talk with you,
Mr. Bosch said. Its still an open investigation.
Asked specifically whether documents related to Mrs. Hudsons reporting
activities were taken during the search, he responded: There was a lot of
stuff taken.
Legitimate Case?
The U.S. Coast Guard maintains that it has done nothing wrong in the case and
that the investigation into Mrs. Hudsons husband is based on legitimate
suspicion that he was illegally in possession of firearms.
The warrant outlines how Mr. Flanagan was found guilty in 1985  when he was
25  of resisting arrest in Prince Georges County, Maryland.
The charge of carrying a concealed deadly weapon was dropped, but a year
later, the U.S. Marshal Service arrested Mr. Flanagan for possession of a
machine gun. The warrant also indicates that Mr. Flanagan was also arrested
in 1996 by police in Anne Arundel County, Maryland,for possessing a handgun
in his vehicle.
The warrant outlines how sometime this year Mr. Flanagan drew the interest of
the U.S. Bureau of Alcohol, Tobacco, Firearms and Explosives after allegedly
attempting to purchase possible machine gun parts from a Swedish national.
The warrant says the information was handed to the Coast Guards
investigative service  since Mr. Flanagan worked at the agency  which
conducted an interview during which Flanagan was evasive but stated he did
receive a potato gun but it was defective and it was thrown away.
The term potato gun is slang used during the illegal importation of
silencers, according to the warrant.
Mrs. Hudson says the potato gun claim is outrageous.
She says that her husband did in fact purchase a potato launcher from an
online company based in Sweden five years ago as a novelty item, but it was
discarded within as few weeks because it did not work.
She noted that the law enforcement agents who raided her home did not take a
golf ball launcher that also belonged to her husband as a novelty item.
They did, however, confiscate small arms belonging to Mrs. Hudson that she
had legally registered with the Maryland State Police as far back as 2005.
The search warrant allowed for the weapons to be confiscated, and Mrs. Hudson
says the agents told her that because her husband had pled guilty to a
resisting arrest charge nearly 30 years ago, she was not allowed to possess
the guns under state law. The guns she owned were for recreational shooting,
she says, as well as for security concerns resulting from many of her
I swear to God, were not smuggling machine gun parts from Sweden, said
Mrs. Hudson, adding that the potato launcher in question didnt even work.
Mrs. Hudson has been a reporter in Washington, D.C. for nearly 15 years, and
covered Homeland Security for the Times after the Sept. 11, 2001, terrorist
attacks through December 2009.
Her investigations have sparked numerous congressional investigations that
led to laws signed by former Presidents George W. Bush and Bill Clinton. She
has won numerous journalism awards for her investigations, including the
prestigious Sigma Delta Chi bronze medal for public service, the Society of
Professional Journalists Dateline Award in Investigative Reporting, and was
nominated twice by The Times for the Pulitzer Prize.
Protecting confidential sources is a part of my honor and hits me at my
ethical core, said Mrs. Hudson. To have someone steal my source information
and know it could impact peoples careers, is disgusting, a massive
overreach. This kind of conduct is intimidation clearly aimed at silencing a
vigorous press.
Read more:
 Follow us:  on Twitter

@_date: 2013-10-28 17:03:12
@_author: Eugen Leitl 
@_subject: The Battle for Power on the Internet 
forkit! , tt silklist
 cypherpunks
The Battle for Power on the Internet
Distributed citizen groups and nimble hackers once had the edge. Now
governments and corporations are catching up. Who will dominate in the
decades ahead?
BRUCE SCHNEIER OCT 24 2013, 7:07 AM ET
Vivek Prakash/Reuters
Were in the middle of an epic battle for power in cyberspace. On one side
are the traditional, organized, institutional powers such as governments and
large multinational corporations. On the other are the distributed and
nimble: grassroots movements, dissident groups, hackers, and criminals.
Initially, the Internet empowered the second side. It gave them a place to
coordinate and communicate efficiently, and made them seem unbeatable. But
now, the more traditional institutional powers are winning, and winning big.
How these two side fare in the long term, and the fate of the rest of us who
dont fall into either group, is an open questionand one vitally important
to the future of the Internet.
In the Internets early days, there was a lot of talk about its natural
lawshow it would upend traditional power blocks, empower the masses, and
spread freedom throughout the world. The international nature of the Internet
bypassed circumvented national laws. Anonymity was easy. Censorship was
impossible. Police were clueless about cybercrime. And bigger changes seemed
inevitable. Digital cash would undermine national sovereignty. Citizen
journalism would topple traditional media, corporate PR, and political
parties. Easy digital copying would destroy the traditional movie and music
industries. Web marketing would allow even the smallest companies to compete
against corporate giants. It really would be a new world order.
This was a utopian vision, but some of it did come to pass. Internet
marketing has transformed commerce. The entertainment industries have been
transformed by things like MySpace and YouTube, and are now more open to
outsiders. Mass media has changed dramatically, and some of the most
influential people in the media have come from the blogging world. There are
new ways to organize politically and run elections. Crowdfunding has made
tens of thousands of projects possible to finance, and crowdsourcing made
more types of projects possible. Facebook and Twitter really did help topple
But that is just one side of the Internets disruptive character. The
Internet has emboldened traditional power as well.
On the corporate side, power is consolidating, a result of two current trends
in computing. First, the rise of cloud computing means that we no longer have
control of our data. Our e-mail, photos, calendars, address books, messages,
and documents are on servers belonging to Google, Apple, Microsoft, Facebook,
and so on. And second, we are increasingly accessing our data using devices
that we have much less control over: iPhones, iPads, Android phones, Kindles,
ChromeBooks, and so on. Unlike traditional operating systems, those devices
are controlled much more tightly by the vendors, who limit what software can
run, what they can do, how theyre updated, and so on. Even Windows 8 and
Apples Mountain Lion operating system are heading in the direction of more
vendor control.
I have previously characterized this model of computing as feudal. Users
pledge their allegiance to more powerful companies who, in turn, promise to
protect them from both sysadmin duties and security threats. Its a metaphor
thats rich in history and in fiction, and a model thats increasingly
permeating computing today.
Medieval feudalism was a hierarchical political system, with obligations in
both directions. Lords offered protection, and vassals offered service. The
lord-peasant relationship was similar, with a much greater power
differential. It was a response to a dangerous world.
Feudal security consolidates power in the hands of the few. Internet
companies, like lords before them, act in their own self-interest. They use
their relationship with us to increase their profits, sometimes at our
expense. They act arbitrarily. They make mistakes. Theyre deliberatelyand
incidentallychanging social norms. Medieval feudalism gave the lords vast
powers over the landless peasants; were seeing the same thing on the
Its not all bad, of course. We, especially those of us who are not
technical, like the convenience, redundancy, portability, automation, and
shareability of vendor-managed devices. We like cloud backup. We like
automatic updates. We like not having to deal with security ourselves. We
like that Facebook just worksfrom any device, anywhere.
Government power is also increasing on the Internet. There is more government
surveillance than ever before. There is more government censorship than ever
before. There is more government propaganda, and an increasing number of
governments are controlling what their users can and cannot do on the
Internet. Totalitarian governments are embracing a growing cyber
sovereignty movement to further consolidate their power. And the cyberwar
arms race is on, pumping an enormous amount of money into cyber-weapons and
consolidated cyber-defenses, further increasing government power.
Technology magnifies power in general, but rates of adoption are different.
In many cases, the interests of corporate and government powers are aligning.
Both corporations and governments benefit from ubiquitous surveillance, and
the NSA is using Google, Facebook, Verizon, and others to get access to data
it couldnt otherwise. The entertainment industry is looking to governments
to enforce its antiquated business models. Commercial security equipment from
companies like BlueCoat and Sophos is being used by oppressive governments to
surveil and censor their citizens. The same facial recognition technology
that Disney uses in its theme parks can also identify protesters in China and
Occupy Wall Street activists in New York. Think of it as a public/private
surveillance partnership.
What happened? How, in those early Internet years, did we get the future so
The truth is that technology magnifies power in general, but rates of
adoption are different. The unorganized, the distributed, the marginal, the
dissidents, the powerless, the criminal: They can make use of new
technologies very quickly. And when those groups discovered the Internet,
suddenly they had power. But later, when the already-powerful big
institutions finally figured out how to harness the Internet, they had more
power to magnify. Thats the difference: The distributed were more nimble and
were faster to make use of their new power, while the institutional were
slower but were able to use their power more effectively.
So while the Syrian dissidents used Facebook to organize, the Syrian
government used Facebook to identify dissidents to arrest.
All isnt lost for distributed power, though. For institutional power, the
Internet is a change in degree, but for distributed power its a qualitative
one. The Internet gives decentralized groupsfor the first timethe ability
to coordinate. This can have incredible ramifications, as we saw in the
SOPA/PIPA debate, Gezi, Brazil, and the rising use of crowdfunding. It can
invert power dynamics, even in the presence of surveillance censorship and
use control. But aside from political coordination, the Internet allows for
social coordination as well to unite, for example, ethnic diasporas, gender
minorities, sufferers of rare diseases, and people with obscure interests.
This isnt static: Technological advances continue to provide advantage to
the nimble. I discussed this trend in my book Liars and Outliers. If you
think of security as an arms race between attackers and defenders, any
technological advance gives one side or the other a temporary advantage. But
most of the time, a new technology benefits the nimble first. They are not
hindered by bureaucracyand sometimes not by laws or ethics either. They can
evolve faster.
We saw it with the Internet. As soon as the Internet started being used for
commerce, a new breed of cybercriminal emerged, immediately able to take
advantage of the new technology. It took police a decade to catch up. And we
saw it on social media, as political dissidents made use of its
organizational powers before totalitarian regimes did.
Which type of power dominates in the coming decades?
Right now, it looks like traditional power.
This delay is what I call a security gap. Its greater when theres more
technology, and in times of rapid technological change. Basically, if there
are more innovations to exploit, there will be more damage resulting from
society's inability to keep up with exploiters of all of them. And since our
world is one in which theres more technology than ever before, and a faster
rate of technological change than ever before, we should expect to see a
greater security gap than ever before. In other words, there will be an
increasing time period during which nimble distributed powers can make use of
new technologies before slow institutional powers can make better use of
those technologies.
This is the battle: quick vs. strong. To return to medieval metaphors, you
can think of a nimble distributed powerwhether marginal, dissident, or
criminalas Robin Hood; and ponderous institutional powersboth government
and corporateas the feudal lords.
So who wins? Which type of power dominates in the coming decades?
Right now, it looks like traditional power. Ubiquitous surveillance means
that its easier for the government to identify dissidents than it is for the
dissidents to remain anonymous. Data monitoring means easier for the Great
Firewall of China to block data than it is for people to circumvent it. The
way we all use the Internet makes it much easier for the NSA to spy on
everyone than it is for anyone to maintain privacy. And even though it is
easy to circumvent digital copy protection, most users still cant do it.
The problem is that leveraging Internet power requires technical expertise.
Those with sufficient ability will be able to stay ahead of institutional
powers. Whether its setting up your own e-mail server, effectively using
encryption and anonymity tools, or breaking copy protection, there will
always be technologies that can evade institutional powers. This is why
cybercrime is still pervasive, even as police savvy increases; why
technically capable whistleblowers can do so much damage; and why
organizations like Anonymous are still a viable social and political force.
Assuming technology continues to advanceand theres no reason to believe it
wontthere will always be a security gap in which technically advanced Robin
Hoods can operate.
Most people, though, are stuck in the middle. These are people who have dont
have the technical ability to evade either the large governments and
corporations, avoid the criminal and hacker groups who prey on us, or join
any resistance or dissident movements. These are the people who accept
default configuration options, arbitrary terms of service, NSA-installed back
doors, and the occasional complete loss of their data. These are the people
who get increasingly isolated as government and corporate power align. In the
feudal world, these are the hapless peasants. And its even worse when the
feudal lordsor any powersfight each other. As anyone watching Game of
Thrones knows, peasants get trampled when powers fight: when Facebook,
Google, Apple, and Amazon fight it out in the market; when the U.S., EU,
China, and Russia fight it out in geopolitics; or when its the U.S. vs. the
terrorists or China vs. its dissidents.
The abuse will only get worse as technology continues to advance. In the
battle between institutional power and distributed power, more technology
means more damage. Weve already seen this: Cybercriminals can rob more
people more quickly than criminals who have to physically visit everyone they
rob. Digital pirates can make more copies of more things much more quickly
than their analog forebears. And well see it in the future: 3D printers mean
that the computer restriction debate will soon involves guns, not movies. Big
data will mean that more companies will be able to identify and track you
more easily. Its the same problem as the weapons of mass destruction fear:
terrorists with nuclear or biological weapons can do a lot more damage than
terrorists with conventional explosives. And by the same token, terrorists
with large-scale cyberweapons can potentially do more damage than terrorists
with those same bombs.
The more destabilizing the technologies, the greater the rhetoric of fear,
and the stronger institutional powers will get.  Its a numbers game. Very
broadly, because of the way humans behave as a species and as a society,
every society is going to have a certain amount of crime. And theres a
particular crime rate society is willing to tolerate. With historically
inefficient criminals, we were willing to live with some percentage of
criminals in our society. As technology makes each individual criminal more
powerful, the percentage we can tolerate decreases. Again, remember the
weapons of mass destruction debate: As the amount of damage each individual
terrorist can do increases, we need to do increasingly more to prevent even a
single terrorist from succeeding.
The more destabilizing the technologies, the greater the rhetoric of fear,
and the stronger institutional powers will get. This means increasingly
repressive security measures, even if the security gap means that such
measures become increasingly ineffective. And it will squeeze the peasants in
the middle even more.
Without the protection of his own feudal lord, the peasant was subject to
abuse both by criminals and other feudal lords. But both corporations and the
governmentand often the two in cahootsare using their power to their own
advantage, trampling on our rights in the process. And without the technical
savvy to become Robin Hoods ourselves, we have no recourse but to submit to
whatever the ruling institutional power wants.
So what happens as technology increases? Is a police state the only effective
way to control distributed power and keep our society safe? Or do the fringe
elements inevitably destroy society as technology increases their power?
Probably neither doomsday scenario will come to pass, but figuring out a
stable middle ground is hard. These questions are complicated, and dependent
on future technological advances that we cannot predict. But they are
primarily political questions, and any solutions will be political.
In the short term, we need more transparency and oversight. The more we know
of what institutional powers are doing, the more we can trust that they are
not abusing their authority. We have long known this to be true in
government, but we have increasingly ignored it in our fear of terrorism and
other modern threats. This is also true for corporate power. Unfortunately,
market dynamics will not necessarily force corporations to be transparent; we
need laws to do that. The same is true for decentralized power; transparency
is how well differentiate political dissidents from criminal organizations.
Oversight is also critically important, and is another long-understood
mechanism for checking power. This can be a combination of things: courts
that act as third-party advocates for the rule of law rather than
rubber-stamp organizations, legislatures that understand the technologies and
how they affect power balances, and vibrant public-sector press and watchdog
groups that analyze and debate the actions of those wielding power.
Transparency and oversight give us the confidence to trust institutional
powers to fight the bad side of distributed power, while still allowing the
good side to flourish. For if were going to entrust our security to
institutional powers, we need to know they will act in our interests and not
abuse that power. Otherwise, democracy fails.
In the longer term, we need to work to reduce power differences. The key to
all of this is access to data. On the Internet, data is power. To the extent
the powerless have access to it, they gain in power. To the extent that the
already powerful have access to it, they further consolidate their power. As
we look to reducing power imbalances, we have to look at data: data privacy
for individuals, mandatory disclosure laws for corporations, and open
government laws.
Medieval feudalism evolved into a more balanced relationship in which lords
had responsibilities as well as rights. Todays Internet feudalism is both
ad-hoc and one-sided. Those in power have a lot of rights, but increasingly
few responsibilities or limits. We need to rebalance this relationship. In
medieval Europe, the rise of the centralized state and the rule of law
provided the stability that feudalism lacked. The Magna Carta first forced
responsibilities on governments and put humans on the long road toward
government by the people and for the people. In addition to re-reigning in
government power, we need similar restrictions on corporate power: a new
Magna Carta focused on the institutions that abuse power in the 21st century.
Todays Internet is a fortuitous accident: a combination of an initial lack
of commercial interests, government benign neglect, military requirements for
survivability and resilience, and computer engineers building open systems
that worked simply and easily. Corporations have turned the Internet into an
enormous revenue generator, and theyre not going to back down easily.
Neither will governments, which have harnessed the Internet for political
Were at the beginning of some critical debates about the future of the
Internet: the proper role of law enforcement, the character of ubiquitous
surveillance, the collection and retention of our entire lifes history, how
automatic algorithms should judge us, government control over the Internet,
cyberwar rules of engagement, national sovereignty on the Internet,
limitations on the power of corporations over our data, the ramifications of
information consumerism, and so on.
Data is the pollution problem of the information age. All computer processes
produce it. It stays around. How we deal with ithow we reuse and recycle it,
who has access to it, how we dispose of it, and what laws regulate itis
central to how the information age functions. And I believe that just as we
look back at the early decades of the industrial age and wonder how society
could ignore pollution in their rush to build an industrial world, our
grandchildren will look back at us during these early decades of the
information age and judge us on how we dealt with the rebalancing of power
resulting from all this new data.
This wont be an easy period for us as we try to work these issues out.
Historically, no shift in power has ever been easy. Corporations have turned
our personal data into an enormous revenue generator, and theyre not going
to back down. Neither will governments, who have harnessed that same data for
their own purposes. But we have a duty to tackle this problem.
I cant tell you what the result will be. These are all complicated issues,
and require meaningful debate, international cooperation, and innovative
solutions. We need to decide on the proper balance between institutional and
decentralized power, and how to build tools that amplify what is good in each
while suppressing the bad.

@_date: 2013-10-29 11:32:44
@_author: Eugen Leitl 
@_subject: Cameron doesn't understand everybody's been playing nice so far 
David Cameron makes veiled threat to media over NSA and GCHQ leaks
Prime minister alludes to courts and D notices and singles out the Guardian
over coverage of Edward Snowden saga
Nicholas Watt, chief political correspondent The Guardian, Monday 28 October
2013 18.10 GMT
Cameron tours the Mini car plant in Oxford. The prime minister claims he
doesn't want to have to take legal action against the Guardian and other
newspapers over intelligence leaks but would rather talk to them. Photograph:
Ben Birchall/PA
David Cameron has called on the Guardian and other newspapers to show "social
responsibility" in the reporting of the leaked NSA files to avoid high court
injunctions or the use of D notices to prevent the publication of information
that could damage national security.
In a statement to MPs on Monday about last week's European summit in
Brussels, where he warned of the dangers of a "lah-di-dah, airy-fairy view"
about the dangers of leaks, the prime minister said his preference was to
talk to newspapers rather than resort to the courts. But he said it would be
difficult to avoid acting if newspapers declined to heed government advice.
The prime minister issued the warning after the Tory MP Julian Smith quoted a
report in Monday's edition of the Sun that said Britain's intelligence
agencies believed details from the NSA files leaked by the US whistleblower
Edward Snowden had hampered their work.
The Sun quoted a "top surveillance source" as saying that terrorists had
"gone quiet" after the publication of details about NSA and GCHQ operations.
Cameron told MPs: "We have a free press, it's very important the press feels
it is not pre-censored from what it writes and all the rest of it.
"The approach we have taken is to try to talk to the press and explain how
damaging some of these things can be and that is why the Guardian did
actually destroy some of the information and disks that they have. But
they've now gone on and printed further material which is damaging.
"I don't want to have to use injunctions or D notices or the other tougher
measures. I think it's much better to appeal to newspapers' sense of social
responsibility. But if they don't demonstrate some social responsibility it
would be very difficult for government to stand back and not to act."
The Guardian agreed to allow officials from GCHQ to oversee the destruction
of hard drives in July, after the government threatened to use an injunction
to block publication of information from the NSA files.
Alan Rusbridger, the editor-in-chief of the Guardian, said the destruction of
the hard drives allowed the Guardian to continue reporting on the NSA files
from its New York office.
The D-notice system is a voluntary code between government departments with
responsibility for national security and the media. A notice can be issued to
the media to prevent "inadvertent public disclosure of information that would
compromise UK military and intelligence operations and methods".
Cameron had earlier indicated that the oversight of Britain's intelligence
agencies may have to evolve in light of the revelations about the reach of
new technology. He told MPs: "We have parliamentary scrutiny of our
intelligence agencies through the intelligence and security committee and we
have strengthened that oversight.
"Our agencies operate under the law and their work is overseen by
intelligence commissioners. Of course as technology develops and as the
threats we face evolve so we need to make sure that the scrutiny and the
frameworks in place remain strong and effective."
Parliament's intelligence and security committee announced earlier this month
that it is to scutinise the extent of mass surveillance in response to the
concerns raised by the Snowden leaks.
The prime minister issued his warning to newspapers after Ed Miliband raised
concerns about the reports last week that the US has monitored the mobile
phone of the German chancellor Angela Merkel.
Miliband said: "I join the prime minister in his support for the work of our
intelligence services. It is vital, it keeps us safe and, by its very nature,
it goes unrecognised. I join the prime minister in applauding the men and
women who work for our intelligence agencies.
"We can all understand the deep concerns that recent reports have caused in
some European countries, especially Germany. As well as providing that
support for intelligence services it is right that every country ensures
proper oversight of those activities."
Julian Smith, who recently wrote to the Metropolitan police to assess whether
the Guardian has broken the law in publishing details from the NSA files,
asked the PM in the Commons: "Following the Sun's revelations this morning
about the impact of the Snowden leaks, is it not time that any newspaper that
may have crossed the line on national security comes forward and voluntarily
works with the government to mitigate further risks to our citizens?"

@_date: 2013-10-31 21:23:52
@_author: Eugen Leitl 
@_subject: Meet =?utf-8?B?4oCcYmFkQklPUyw=?= =?utf-8?B?4oCd?= the mysterious 
tt forkit!  Meet badBIOS, the mysterious Mac and PC malware that jumps airgaps
Like a super strain of bacteria, the rootkit plaguing Dragos Ruiu is
by Dan Goodin - Oct 31 2013, 3:07pm CET
BLACK HAT HACKING
Aurich Lawson / Thinkstock
Three years ago, security consultant Dragos Ruiu was in his lab when he
noticed something highly unusual: his MacBook Air, on which he had just
installed a fresh copy of OS X, spontaneously updated the firmware that helps
it boot. Stranger still, when Ruiu then tried to boot the machine off a CD
ROM, it refused. He also found that the machine could delete data and undo
configuration changes with no prompting. He didn't know it then, but that odd
firmware update would become a high-stakes malware mystery that would consume
most of his waking hours.
In the following months, Ruiu observed more odd phenomena that seemed
straight out of a science-fiction thriller. A computer running the Open BSD
operating system also began to modify its settings and delete its data
without explanation or prompting. His network transmitted data specific to
the Internet's next-generation IPv6 networking protocol, even from computers
that were supposed to have IPv6 completely disabled. Strangest of all was the
ability of infected machines to transmit small amounts of network data with
other infected machines even when their power cords and Ethernet cables were
unplugged and their Wi-Fi and Bluetooth cards were removed. Further
investigation soon showed that the list of affected operating systems also
included multiple variants of Windows and Linux.
"We were like, 'Okay, we're totally owned,'" Ruiu told Ars. "'We have to
erase all our systems and start from scratch,' which we did. It was a very
painful exercise. I've been suspicious of stuff around here ever since."
In the intervening three years, Ruiu said, the infections have persisted,
almost like a strain of bacteria that's able to survive extreme antibiotic
therapies. Within hours or weeks of wiping an infected computer clean, the
odd behavior would return. The most visible sign of contamination is a
machine's inability to boot off a CD, but other, more subtle behaviors can be
observed when using tools such as Process Monitor, which is designed for
troubleshooting and forensic investigations.
Another intriguing characteristic: in addition to jumping "airgaps" designed
to isolate infected or sensitive machines from all other networked computers,
the malware seems to have self-healing capabilities.
"We had an air-gapped computer that just had its [firmware] BIOS reflashed, a
fresh disk drive installed, and zero data on it, installed from a Windows
system CD," Ruiu said. "At one point, we were editing some of the components
and our registry editor got disabled. It was like: wait a minute, how can
that happen? How can the machine react and attack the software that we're
using to attack it? This is an air-gapped machine and all of the sudden the
search function in the registry editor stopped working when we were using it
to search for their keys."
Over the past two weeks, Ruiu has taken to Twitter, Facebook, and Google Plus
to document his investigative odyssey and share a theory that has captured
the attention of some of the world's foremost security experts. The malware,
Ruiu believes, is transmitted though USB drives to infect the lowest levels
of computer hardware. With the ability to target a computer's Basic
Input/Output System (BIOS), Unified Extensible Firmware Interface (UEFI), and
possibly other firmware standards, the malware can attack a wide variety of
platforms, escape common forms of detection, and survive most attempts to
eradicate it.
But the story gets stranger still. In posts here, here, and here, Ruiu
posited another theory that sounds like something from the screenplay of a
post-apocalyptic movie: "badBIOS," as Ruiu dubbed the malware, has the
ability to use high-frequency transmissions passed between computer speakers
and microphones to bridge airgaps.
Bigfoot in the age of the advanced persistent threat
At times as I've reported this story, its outline has struck me as the stuff
of urban legend, the advanced persistent threat equivalent of a Bigfoot
sighting. Indeed, Ruiu has conceded that while several fellow security
experts have assisted his investigation, none has peer reviewed his process
or the tentative findings that he's beginning to draw. (A compilation of
Ruiu's observations is here.)
Also unexplained is why Ruiu would be on the receiving end of such an
advanced and exotic attack. As a security professional, the organizer of the
internationally renowned CanSecWest and PacSec conferences, and the founder
of the Pwn2Own hacking competition, he is no doubt an attractive target to
state-sponsored spies and financially motivated hackers. But he's no more
attractive a target than hundreds or thousands of his peers, who have so far
not reported the kind of odd phenomena that has afflicted Ruiu's computers
and networks.
In contrast to the skepticism that's common in the security and hacking
cultures, Ruiu's peers have mostly responded with deep-seated concern and
even fascination to his dispatches about badBIOS.
"Everybody in security needs to follow  and watch his analysis of
 Alex Stamos, one of the more trusted and sober security
researchers, wrote in a tweet last week. Jeff Mossthe founder of the Defcon
and Blackhat security conferences who in 2009 began advising Department of
Homeland Security Secretary Janet Napolitano on matters of computer
securityretweeted the statement and added: "No joke it's really serious."
Plenty of others agree.
"Dragos is definitely one of the good reliable guys, and I have never ever
even remotely thought him dishonest," security researcher Arrigo Triulzi told
Ars. "Nothing of what he describes is science fiction taken individually, but
we have not seen it in the wild ever."
Been there, done that
Triulzi said he's seen plenty of firmware-targeting malware in the
laboratory. A client of his once infected the UEFI-based BIOS of his Mac
laptop as part of an experiment. Five years ago, Triulzi himself developed
proof-of-concept malware that stealthily infected the network interface
controllers that sit on a computer motherboard and provide the Ethernet jack
that connects the machine to a network. His research built off of work by
John Heasman that demonstrated how to plant hard-to-detect malware known as a
rootkit in a computer's peripheral component interconnect, the
Intel-developed connection that attaches hardware devices to a CPU.
It's also possible to use high-frequency sounds broadcast over speakers to
send network packets. Early networking standards used the technique, said
security expert Rob Graham. Ultrasonic-based networking is also the subject
of a great deal of research, including this project by scientists at MIT.
Of course, it's one thing for researchers in the lab to demonstrate viable
firmware-infecting rootkits and ultra high-frequency networking techniques.
But as Triulzi suggested, it's another thing entirely to seamlessly fuse the
two together and use the weapon in the real world against a seasoned security
consultant. What's more, use of a USB stick to infect an array of computer
platforms at the BIOS level rivals the payload delivery system found in the
state-sponsored Stuxnet worm unleashed to disrupt Iran's nuclear program. And
the reported ability of badBIOS to bridge airgaps also has parallels to
Flame, another state-sponsored piece of malware that used Bluetooth radio
signals to communicate with devices not connected to the Internet.
"Really, everything Dragos reports is something that's easily within the
capabilities of a lot of people," said Graham, who is CEO of penetration
testing firm Errata Security. "I could, if I spent a year, write a BIOS that
does everything Dragos said badBIOS is doing. To communicate over ultrahigh
frequency sound waves between computers is really, really easy."
Coincidentally, Italian newspapers this week reported that Russian spies
attempted to monitor attendees of last month's G20 economic summit by giving
them memory sticks and recharging cables programmed to intercept their
For most of the three years that Ruiu has been wrestling with badBIOS, its
infection mechanism remained a mystery. A month or two ago, after buying a
new computer, he noticed that it was almost immediately infected as soon as
he plugged one of his USB drives into it. He soon theorized that infected
computers have the ability to contaminate USB devices and vice versa.
"The suspicion right now is there's some kind of buffer overflow in the way
the BIOS is reading the drive itself, and they're reprogramming the flash
controller to overflow the BIOS and then adding a section to the BIOS table,"
he explained.
He still doesn't know if a USB stick was the initial infection trigger for
his MacBook Air three years ago, or if the USB devices were infected only
after they came into contact with his compromised machines, which he said now
number between one and two dozen. He said he has been able to identify a
variety of USB sticks that infect any computer they are plugged into. At next
month's PacSec conference, Ruiu said he plans to get access to expensive USB
analysis hardware that he hopes will provide new clues behind the infection
He said he suspects badBIOS is only the initial module of a multi-staged
payload that has the ability to infect the Windows, Mac OS X, BSD, and Linux
operating systems.
Dragos Ruiu
Julia Wolf
"It's going out over the network to get something or it's going out to the
USB key that it was infected from," he theorized. "That's also the conjecture
of why it's not booting CDs. It's trying to keep its claws, as it were, on
the machine. It doesn't want you to boot another OS it might not have code
for." To put it another way, he said, badBIOS "is the tip of the warhead, as
it were."
Things kept getting fixed
Ruiu said he arrived at the theory about badBIOS's high-frequency networking
capability after observing encrypted data packets being sent to and from an
infected laptop that had no obvious network connection withbut was in close
proximity toanother badBIOS-infected computer. The packets were transmitted
even when the laptop had its Wi-Fi and Bluetooth cards removed. Ruiu also
disconnected the machine's power cord so it ran only on battery to rule out
the possibility it was receiving signals over the electrical connection. Even
then, forensic tools showed the packets continued to flow over the airgapped
machine. Then, when Ruiu removed the internal speaker and microphone
connected to the airgapped machine, the packets suddenly stopped.
With the speakers and mic intact, Ruiu said, the isolated computer seemed to
be using the high-frequency connection to maintain the integrity of the
badBIOS infection as he worked to dismantle software components the malware
relied on.
"The airgapped machine is acting like it's connected to the Internet," he
said. "Most of the problems we were having is we were slightly disabling bits
of the components of the system. It would not let us disable some things.
Things kept getting fixed automatically as soon as we tried to break them. It
was weird."
It's too early to say with confidence that what Ruiu has been observing is a
USB-transmitted rootkit that can burrow into a computer's lowest levels and
use it as a jumping off point to infect a variety of operating systems with
malware that can't be detected. It's even harder to know for sure that
infected systems are using high-frequency sounds to communicate with isolated
machines. But after almost two weeks of online discussion, no one has been
able to rule out these troubling scenarios, either.
"It looks like the state of the art in intrusion stuff is a lot more advanced
than we assumed it was," Ruiu concluded in an interview. "The take-away from
this is a lot of our forensic procedures are weak when faced with challenges
like this. A lot of companies have to take a lot more care when they use
forensic data if they're faced with sophisticated attackers."

@_date: 2013-10-01 13:30:25
@_author: Eugen Leitl 
@_subject: Surveillance 
It's Six Eyes, as Sweden is also part of the big vacuum, due to
special geography.

@_date: 2013-10-01 13:32:46
@_author: Eugen Leitl 
@_subject: [tor-relays] Relay security, re: local network 
Hash: SHA1
That reminds me of a question I've been meaning to ask lately...
Has anyone tried running Tor on top of OSv (
As I understand it, OSv is an ultra-small OS which is Linux
API-compatible and designed for running a single app only atop a
virtualization stack.  For example, it should, in theory, be possible
to run the Tor daemon within a copy of OSv, that would be the only
application running inside of that VM, and it should be running like
greased lightning because it would be the only process running in that VM.
Granted, it is fairly new so I do not believe anyone has done any
serious security analysis of OSv, but it seems like it would be an
ideal candidate for a very high performance Tor node.

@_date: 2013-10-01 16:27:33
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] homomorphic coin value (validatable but 
Thanks for providing the impetus to write down the current state, the
efficient version of which I only figured out a few days ago :)
I have been researching this for a few months on and off, because it seems
like an interesting construct in its own right, a different aspect of
payment privacy (eg for auditable but commercial sensistive information) but
also that other than its direct use it may enable some features that we have
not thought of yet.
I moved it to bitcointalk:
Its efficient finally (after many dead ends): approximately 2x cost of
current in terms of coin size and coin verification cost, however it also
gives some perf advantages back in a different way - necessary changes to
schnorr (EC version of Schnorr based proofs) allow n of n multiparty sigs,
or k of n multiparty sigs for the verification cost and signature size of
one pair of ECS signatures, for n > 2 its a space and efficiency improvement
over current bitcoin.

@_date: 2013-10-01 16:58:00
@_author: Eugen Leitl 
@_subject: [cryptography] The Compromised Internet 
Hash: SHA1
If enough hams (or one sufficiently angry lone ham operator) decide
that this is a problem they'll organize a turkey hunt to triangulate
the operator(s) and politely ask them to stop before the feds get
called in.  The thinking behind this seems to be that the amateur
community has been graciously granted a small portion of the RF
spectrum to experiment with.  People (licensed hams or otherwise) who
do specifically prohibited things within the amateur bands (like
transmitting encrypted traffic or undocumented digital protocols
(which may be indistinguishable from encrypted traffic)) can get some
or all of the amateur band taken away.  A lot of time and effort are
spent every year by ham operators who don't want this, that, or the
other sliver of the amateur band reassigned away from amateur use, and
someone doing something dodgy within those spectra could have
disasterous consequences.
When Project Byzantium was adding amateur radio support for ISC
milestone  these regulations were noted and discussed at length
during initial reasearch.  We also spoke with the ARRL during
development, which expressed similar sentiments about crypto in the
amateur bands (and passing traffic from unlicensed network users over
the amateur band, incidentally).
That would probably fall under jamming, which is definitely against
ham ethics.
The hams I've spoken to seem to, but they also seem to fall into the
camp of "It's on the amateur bands, so if it's something I'd want to
encrypt I'm not going to talk about it while chewing the rag anyway."

@_date: 2013-10-07 10:02:01
@_author: Eugen Leitl 
@_subject: [tor-talk] Silk Road taken down by FBI 
We know that Freedom Hosting platform was compromised, and
dropped malware via a known vulnerability in the TBB.
We do not know how exactly TSR was taken down.
There are reasons to suspect that the official story
might be a parallel construct.
The rise in Tor traffic well predates the events, and seems
to be entirely attributable to C&C traffic of a botnet.

@_date: 2013-10-07 11:25:43
@_author: Eugen Leitl 
@_subject: [tor-talk] Silk Road taken down by FBI 
Let's say you run a piece of buggy PHP code as a hidden service, on a mass hoster allowing easy signups and installation
of own code, with no hard separation of service hosted, and possibly not even firewall the VM traffic, forcing it through Tor.
While it's possible they knew the physical host already,
there are certainly far easier ways to nail your ass, given
the above.
It would be interesting to post a hidden service with actionable
content as a honeypot with everything done right, to see what the parallel construct story would emerge. No, I'm not volunteering.

@_date: 2013-10-07 11:37:56
@_author: Eugen Leitl 
@_subject: Analysis of Silk =?utf-8?B?Um9hZOKAmQ==?= =?utf-8?Q?s?= Historical 
Analysis of Silk Roads Historical Impact on Bitcoin
Oct 3, 2013 Posted By Jonathan Stacke In Featured, News	 Tagged Bitcoin,
Price, Silk Road, Volume	 Comments 11
Silk Road, the online drug bazaar that has eluded authorities and been
ingrained in the bitcoin narrative for years, was shut down yesterday. Ross
Ulbricht was named in the court documents outlining Silk Roads activities,
as were a number of key data points that offer insights into the impact the
worlds most infamous retail website has had on bitcoin.
Ulbricht was caught as a result of human error and excessive risks related to
physical delivery of false identification being delivered to his home address
in San Francisco from Canada. After tracking the package, authorities found
their way to Ulbricht and were able to compile a significant case against him
(more details in the official complaint embedded below). Notably, it does not
appear he was tracked as the result of any underlying flaws with tor, used
for anonymous web browsing, or bitcoin, the only currency accepted on Silk
For years the cloaked narcotics website has found its way into
bitcoin-oriented conversations, but only now are the qualitative and
quantitative data points available to asses Silk Roads true impact on the
fledgling digital currency.
A History of Influence
Facts offered by federal prosecutors overlayed onto bitcoin trading data
tells a convincing story about the intertwined histories of bitcoin and Silk
Road. It appears that a significant portion of bitcoins early traction and
price gains can be traced directly to Silk Road, with that impact waning over
time, most dramatically in the past six months.
On December 30, 2010, bitcoin was traded at $0.30/BTC. The court documents
filed yesterday point to Silk Roads first known publicity occurring via
posts from Ulbricht on internet forums and an explanatory WordPress page
beginning on January 27, 2011. Bitcoin tripled in value, reaching parity with
USD, just two weeks later on February 8.
early 2011
Bitcoin then traded between between $0.65 and $0.80 for the next two months
until interest was reignited by coverage in major publications, including
TIME Magazine and The New York Times. In the weeks following the NYC piece,
bitcoin prices and volume exploded, drawing significant attention from the
media. Notably, Gawker broke a story about the Silk Road itself, pushing up
the last gain of one of bitcoins early bubbles.
As bitcoin reached a remarkable 100x year-to-date growth at $30/BTC on June
7, the relationship between Silk Road and bitcoin would see its first true
test. On June 8, 2011, Senators Charles Shumer and Joe Manchin wrote a letter
to Attorney General Eric Holder, urging him to investigate bitcoin for its
relationship to online narcotics purchases, as well as urge [Holder] to take
immediate action and shut down the Silk Road network. Bitcoin plunged 66% to
$10 over the next three days, trending downward to $2 by November 2011. It
would seem that in 2011, direct use of bitcoin on Silk Road or speculators on
its adoption comprised between 66% and 93% of the currencys value.
2011 bubble
Over the next few months as the calendar rolled over into 2012, once again
coverage from a number of important press outlets like TIME and Wired rallied
enthusiasm for bitcoin, pushing prices up to a stabilized $5 by February.
According to the complaint released yesterday, that is also around the time
Ulbricht began to add features to Silk Road, including the establishment of a
forum and stealth mode for top vendors.
In June of 2012, bitcoin began another rally. By this time, infrastructure in
the bitcoin world had begun to increase dramatically, including the first
bitcoin ASIC companies to begin advertising products and new exchanges being
formed. Gawker ran another story about Silk Road in July 2012, which appears
to have had positive impact on bitcoin prices, though not nearly to the
extent it did previously. The months following proved to be highly
transitional, with Bitcoin Foundation putting a public face on the new
industry and early 2013 seeing the European financial troubles that led to
the climb to $260 in April of this year and unprecedented global attention.
Just a few weeks later the markets would see another test of the relationship
between Bitcoin and Silk Road. Between April 24 and May 1, Silk Road suffered
a series of DDoS attacks that sent bitcoin prices sliding downwards. The
negative price action was timed perfectly with the attacks, indicating a
strong relationship. While the drop was significant at 35% initially before
leveling off around a 25% loss  it was notably lighter than the impact of
negative Silk Road news previously.
april 2013 ddos
Looking at the impact from the most recent news, we see a similar pattern
emerging. Despite being the definitive end of Silk Road, with its founder
detained and the logos of federal agencies plastered across the site, the
impact on bitcoin prices was relatively muted. On the initial news break
USD/BTC rates fell 20-35%, depending on the exchange, before settling around
10-15% lower than before the news shortly thereafter.
October 2013
Quantifiable Impact
Also contained within the filings were a number of aggregate statistics about
Silk Roads transactional volume that shed significant light on how much of
the bitcoin market was built around the companys narcotics trade.
Specifically, the complaint states that sites total revenue between February
2011 and July 2013 was 9.5 million bitcoin. Over that same period
approximately 225 million bitcoin were transacted over the block chain, of
which the 9.5 million in Silk Road sales accounted for just 4%.
Similarly, total exchange volume over the same period was roughly 75 million
bitcoin, making Silk Road approximately 12% of total volume. This, of course,
assumes all bitcoins used for purchases on the site were purchased on
exchanges rather than obtained from in person transactions, mining, earnings,
gifts or reused by sellers to purchase from others on the site.
Important to remember is that these figures are aggregate stats over two
years of revenue. Unless fiat-equivalent sales on Silk Road were growing
exponentially alongside bitcoin exchange rates over the past two years, this
also means the bitcoin volume listed in the filing is front loaded into the
periods when more bitcoins were required for the same fiat equivalent
purchasing power. This coincides with the market reactions that also
indicates a significantly reduced importance of Silk Road on the bitcoin
Looking Forward
The bitcoin markets as a whole seem well poised to move forward. An unknown
has been removed from the ecosystem, but a number of concerns remain.
While bitoin will likely recover, there are probably more than a few
concerned bitcoin users right now. The contents of the filing pertained
almost exclusively to the charges against Ulbricht, but give little insight
into what other information was obtained. Whether or not home addresses or
bitcoin addresses of Silk Road users were retained in some way is still
unclear and the extent to which such matters are prosecutable has yet to be
There is also a strong likelihood of copycat sites arising. While the recent
action may deter US citizens, Silk Road was known for its global reach,
meaning an aspiring entrepreneur could run a similar company from anywhere in
the world. The business model is proven and the technology still apparently
sound and repeatable. The downfall was related to human error, which was
clearly outlined in the filing, creating an advanced watchlist for the next
person to avoid. The barriers to entry are remarkably low and now paired with
a known surplus of both demand and supply in the marketplace.
While Silk Roads early impact on digital currency appears to have been quite
significant, any new participant at this stage will likely encounter the same
decreasing importance to the broader bitcoin ecosystem.

@_date: 2013-10-07 12:43:36
@_author: Eugen Leitl 
@_subject: Russia to monitor 'all communications' at Winter Olympics in Sochi 
Russia to monitor 'all communications' at Winter Olympics in Sochi
Exclusive: Investigation uncovers FSB surveillance system  branded 'Prism on
steroids'  to listen to all athletes and visitors
Shaun Walker in Moscow
The Guardian, Sunday 6 October 2013 15.31 BST
Sochi, venue for 2014 Winter Olympics
The Black Sea resort of Sochi has apparently been wired so that the FSB can
log all visitor communications. Photograph: Ignat Kozlov/AP
Athletes and spectators attending the Winter Olympics in Sochi in February
will face some of the most invasive and systematic spying and surveillance in
the history of the Games, documents shared with the Guardian show.
Russia's powerful FSB security service plans to ensure that no communication
by competitors or spectators goes unmonitored during the event, according to
a dossier compiled by a team of Russian investigative journalists looking
into preparations for the 2014 Games.
In a ceremony on Red Square on Sunday afternoon, the president, Vladimir
Putin, held the Olympic flame aloft and sent it on its epic journey around
the country, saying Russia and its people had always been imbued with the
qualities of "openness and friendship", making Sochi the perfect destination
for the Olympics.
But government procurement documents and tenders from Russian communication
companies indicate that newly installed telephone and internet spying
capabilities will give the FSB free rein to intercept any telephony or data
traffic and even track the use of sensitive words or phrases mentioned in
emails, webchats and on social media.
The journalists, Andrei Soldatov and Irina Borogan, who are experts on the
Russian security services, collated dozens of open source technical documents
published on the Zakupki government procurement agency website, as well as
public records of government oversight agencies. They found that major
amendments have been made to telephone and Wi-Fi networks in the Black Sea
resort to ensure extensive and all-permeating monitoring and filtering of all
traffic, using Sorm, Russia's system for intercepting phone and internet
Putin at a Sochi Olympic flame ceremony in Moscow on Sunday. Photograph: Ivan
The Sorm system is being modernised across Russia, but particular attention
has been paid to Sochi given the large number of foreign visitors expected
next year. Technical specifications set out by the Russian state telecoms
agency also show that a controversial technology known as deep packet
inspection, which allows intelligence agencies to filter users by particular
keywords, is being installed across Russia's networks, and is required to be
compatible with the Sorm system.
"For example you can use the keyword Navalny, and work out which people in a
particular region are using the word Navalny," says Soldatov, referring to
Alexei Navalny, Russia's best-known opposition politician. "Then, those
people can be tracked further."
Ron Deibert, a professor at the University of Toronto and director of Citizen
Lab, which co-operated with the Sochi research, describes the Sorm amendments
as "Prism on steroids", referring to the programme used by the NSA in the US
and revealed to the Guardian by the whistleblower Edward Snowden. "The scope
and scale of Russian surveillance are similar to the disclosures about the US
programme but there are subtle differences to the regulations," says Deibert.
"We know from Snowden's disclosures that many of the checks were weak or
sidestepped in the US, but in the Russian system permanent access for Sorm is
a requirement of building the infrastructure."
"Even as recently as the Beijing Olympics, the sophistication of surveillance
and tracking capabilities were nowhere near where they are today."
Gus Hosein, executive director of Privacy International, which also
co-operated with the research, said: "Since 2008, more people are travelling
with smartphones with far more data than back then, so there is more to spy
Wary of Sorm's capabilities, earlier this year a leaflet from the US state
department's bureau of diplomatic security warned anyone travelling to the
Games to be extremely cautious with communications.
"Business travellers should be particularly aware that trade secrets,
negotiating positions, and other sensitive information may be taken and
shared with competitors, counterparts, and/or Russian regulatory and legal
entities," the document reads. The advice contains an extraordinary list of
precautions for visitors who wish to ensure safe communications, such as
removing batteries from phones when not in use and only travelling with
"clean" devices.
Soldatov and Borogan have discovered that the FSB has been working since 2010
to upgrade the Sorm system to ensure it can cope with the extra traffic
during the Games. All telephone and ISP providers have to install Sorm boxes
in their technology by law, and once installed, the FSB can access data
without the provider ever knowing, meaning every phone call or internet
communication can be logged. Although the FSB technically requires a warrant
to intercept a communication, it is not obliged to show it to anyone.
Tellingly, the FSB has appointed one of its top counterintelligence chiefs,
Oleg Syromolotov, to be in charge at Sochi: security will thus be overseen by
someone who has spent his career chasing foreign spies rather than
Another target may well be gay rights, likely to be one of the biggest issues
of the Games. Putin has said that competitors who wear rainbow pins, for
example, will not be arrested under the country's controversial new law that
bans "homosexual propaganda". However, it is likely that any attempts to
stage any kind of rally or gathering to support gay rights will be ruthlessly
broken up by police, as has been the case on numerous occasions in Russian
cities in the past. Using DPI, Russian authorities will be able to identify,
tag and follow all visitors to the Olympics, both Russian and foreign, who
are discussing gay issues, and possibly planning to organise protests.
"Athletes may have particular political views, or they may be openly gay,"
says Deibert. "I think given recent developments in Russia, we have to be
worried about these issues."
At a rare FSB press conference this week, an official, Alexei Lavrishchev,
denied security and surveillance at the Games would be excessive, and said
that the London Olympics featured far more intrusive measures. "There, they
even put CCTV cameras in, excuse me for saying it, the toilets," said
Lavrishchev. "We are not taking this kind of measure."
The FSB did not respond to a request for comment from the Guardian, while a
spokesperson for the Sochi Olympics referred all requests to the security
services. But Russian authorities often express a belief that NGOs working on
human rights and other issues have subversive agendas dictated from abroad,
and the FSB apparently feels that with so many potentially dangerous
foreigners descending on the Black Sea resort for the Olympics, it has a duty
to keep an eye on them.
In the end, the goal is overarching, but simple, says Soldatov: "Russian
authorities want to make sure that every connection and every move made
online in Sochi during the Olympics will be absolutely transparent to the
secret services of the country."

@_date: 2013-10-07 13:18:17
@_author: Eugen Leitl 
@_subject: [tor-talk] Freenet and hidden services 
Hash: SHA512
I consider Tahoe-LAFS to be the (current) best solution for this. It
provides a distributed data store, which can be used for hosting (with
a Javascript "web server"). I know Tahoe works with Tor via SOCKS but
I don't personally know of any active networks. Tahoe has been used in
I2P as a distributed data store for a long time, and there are several
"deepsites" hosted in it. We are actively working to make Tahoe
integrate better with Tor/I2P.
Zooko recently posted a *much* better summary of this:

@_date: 2013-10-07 13:55:36
@_author: Eugen Leitl 
@_subject: <nettime> A CEO who resisted NSA spying is out of prison. 
A good point. I deal with that by
alternative_order text/plain text/html text/enrichened
auto_view text/html
which calls links via /etc/mailcap
text/plain; less '%s'; needsterminal
text/html; /usr/bin/sensible-browser '%s'; description=HTML Text; nametemplate=%s.html
How exploitable is /usr/bin/links?

@_date: 2013-10-07 16:50:38
@_author: Eugen Leitl 
@_subject: interesting commercial cjdns project: Enigmabox 
Just came across  which is a commercial
project using cjdns/Hyperboria for transport and offers end to end encrypted VoIP and operates http (and more?) exits.
The hardware seems to be PCEngines ALIX. It doesn't ship
with Tor, but Tor can be used with it. Don't see any open
source, but users are getting root access on the system.

@_date: 2013-10-07 17:16:29
@_author: Eugen Leitl 
@_subject: Bruce Schneier on the good, old air gap 
Want to Evade NSA Spying? Dont Connect to the Internet
BY BRUCE SCHNEIER 10.07.13 6:30 AM
Photo: Ariel Zambelich / WIRED; Illustration: Ross Patton / WIRED
Since I started working with Snowdens documents, I have been using a number
of tools to try to stay secure from the NSA. The advice I shared included
using Tor, preferring certain cryptography over others, and using
public-domain encryption wherever possible.
I also recommended using an air gap, which physically isolates a computer or
local network of computers from the internet. (The name comes from the
literal gap of air between the computer and the internet; the word predates
wireless networks.)
But this is more complicated than it sounds, and requires explanation.
Since we know that computers connected to the internet are vulnerable to
outside hacking, an air gap should protect against those attacks. There are a
lot of systems that use  or should use  air gaps: classified military
networks, nuclear power plant controls, medical equipment, avionics, and so
Osama Bin Laden used one. I hope human rights organizations in repressive
countries are doing the same.
Air gaps might be conceptually simple, but theyre hard to maintain in
practice. The truth is that nobody wants a computer that never receives files
from the internet and never sends files out into the internet. What they want
is a computer thats not directly connected to the internet, albeit with some
secure way of moving files on and off.
But every time a file moves back or forth, theres the potential for attack.
And air gaps have been breached. Stuxnet was a U.S. and Israeli
military-grade piece of malware that attacked the Natanz nuclear plant in
Iran. It successfully jumped the air gap and penetrated the Natanz network.
Another piece of malware named agent.btz, probably Chinese in origin,
successfully jumped the air gap protecting U.S. military networks.
These attacks work by exploiting security vulnerabilities in the removable
media used to transfer files on and off the air gapped computers.
Bruce Schneier is a security technologist and author. His latest book is
Liars and Outliers: Enabling the Trust Society Needs to Survive.
Since working with Snowdens NSA files, I have tried to maintain a single
air-gapped computer. It turned out to be harder than I expected, and I have
ten rules for anyone trying to do the same:
1. When you set up your computer, connect it to the internet as little as
possible. Its impossible to completely avoid connecting the computer to the
internet, but try to configure it all at once and as anonymously as possible.
I purchased my computer off-the-shelf in a big box store, then went to a
friends network and downloaded everything I needed in a single session. (The
ultra-paranoid way to do this is to buy two identical computers, configure
one using the above method, upload the results to a cloud-based anti-virus
checker, and transfer the results of that to the air gap machine using a
one-way process.)
2. Install the minimum software set you need to do your job, and disable all
operating system services that you wont need. The less software you install,
the less an attacker has available to exploit. I downloaded and installed
OpenOffice, a PDF reader, a text editor, TrueCrypt, and BleachBit. Thats
all. (No, I dont have any inside knowledge about TrueCrypt, and theres a
lot about it that makes me suspicious. But for Windows full-disk encryption
its that, Microsofts BitLocker, or Symantecs PGPDisk  and I am more
worried about large U.S. corporations being pressured by the NSA than I am
about TrueCrypt.)
3. Once you have your computer configured, never directly connect it to the
internet again. Consider physically disabling the wireless capability, so it
doesnt get turned on by accident.
4. If you need to install new software, download it anonymously from a random
network, put it on some removable media, and then manually transfer it to the
air gapped computer. This is by no means perfect, but its an attempt to make
it harder for the attacker to target your computer.
5. Turn off all auto-run features. This should be standard practice for all
the computers you own, but its especially important for an air-gapped
computer. Agent.btz used autorun to infect U.S. military computers.
6. Minimize the amount of executable code you move onto the air-gapped
computer. Text files are best. Microsoft Office files and PDFs are more
dangerous, since they might have embedded macros. Turn off all macro
capabilities you can on the air-gapped computer. Dont worry too much about
patching your system; in general, the risk of the executable code is worse
than the risk of not having your patches up to date. Youre not on the
internet, after all.
7. Only use trusted media to move files on and off air-gapped computers. A
USB stick you purchase from a store is safer than one given to you by someone
you dont know  or one you find in a parking lot.
8. For file transfer, a writable optical disk (CD or DVD) is safer than a USB
stick. Malware can silently write data to a USB stick, but it cant spin the
CD-R up to 1000 rpm without your noticing. This means that the malware can
only write to the disk when you write to the disk. You can also verify how
much data has been written to the CD by physically checking the back of it.
If youve only written one file, but it looks like three-quarters of the CD
was burned, you have a problem. Note: the first company to market a USB stick
with a light that indicates a write operation  not read or write; Ive got
one of those  wins a prize.
9. When moving files on and off your air-gapped computer, use the absolute
smallest storage device you can. And fill up the entire device with random
files. If an air-gapped computer is compromised, the malware is going to try
to sneak data off it using that media. While malware can easily hide stolen
files from you, it cant break the laws of physics. So if you use a tiny
transfer device, it can only steal a very small amount of data at a time. If
you use a large device, it can take that much more. Business-card-sized
mini-CDs can have capacity as low as 30 MB. I still see 1-GB USB sticks for
10. Consider encrypting everything you move on and off the air-gapped
computer. Sometimes youll be moving public files and it wont matter, but
sometimes you wont be, and it will. And if youre using optical media, those
disks will be impossible to erase. Strong encryption solves these problems.
And dont forget to encrypt the computer as well; whole-disk encryption is
the best.
One thing I didnt do, although its worth considering, is use a stateless
operating system like Tails. You can configure Tails with a persistent volume
to save your data, but no operating system changes are ever saved. Booting
Tails from a read-only DVD  you can keep your data on an encrypted USB stick
 is even more secure. Of course, this is not foolproof, but it greatly
reduces the potential avenues for attack.
Yes, all this is advice for the paranoid. And its probably impossible to
enforce for any network more complicated than a single computer with a single
user. But if youre thinking about setting up an air-gapped computer, you
already believe that some very powerful attackers are after you personally.
If youre going to use an air gap, use it properly.
Of course you can take things further. I have met people who have physically
removed the camera, microphone, and wireless capability altogether. But
thats too much paranoia for me right now.

@_date: 2013-10-07 23:55:49
@_author: Eugen Leitl 
@_subject: Bruce Schneier on the good, old air gap 
Liberation Technologies That advice is not exactly targeted towards Jane Doe. Some people don't have mobile phones. Others leave them at home,
or remove the power pack when it matters.
No. You just need to buy an offline machine, e.g. a used notebook. Separation by air gap was SOP in the intelligence community before virtualization allowed to separate trust compartments in one machine.
I trust air gap much more than hypervisors.
I don't understand the problem. Bruce gave good basic opsec advice,
what's the problem with following it up in practice but to tamper-proof
against evil maid attacks?

@_date: 2013-10-08 17:15:50
@_author: Eugen Leitl 
@_subject: Feds Arrest Alleged Top Silk Road Drug Seller 
Feds Arrest Alleged Top Silk Road Drug Seller
Federal authorities last week arrested a Washington state man accused of
being one of the most active and sought-after drug dealers on the online
black market known as the Silk Road. Meanwhile, new details about the
recent coordinated takedown of the Silk Road became public, as other former
buyers and sellers on the fraud bazaar pondered who might be next and whether
competing online drug markets will move in to fill the void.
NOD's feedback from Silk Road buyers, according to the government. A complaint unsealed Oct. 2 by the U.S. District Court for the Western
District of Washington at Seattle alleges that Steven Lloyd Sadler, 40, of
Bellevue, Wash., used the nickname NOD on the Silk Road, and was among the
top one percent of sellers on the Silk Road, selling high-quality cocaine,
heroin and methamphetamine in small, individual-use amounts to hundreds of
buyers around the world.
Investigators with the FBI and U.S. Post Office inspectors say they tracked
dozens of packages containing drugs allegedly shipped by Sadler and a woman
who was living with him at the time of his arrest. Authorities tied Sadler to
the Silk Road after intercepting a package of cocaine and heroin destined for
an Alaskan resident. That resident agreed to cooperate with authorities in
the hopes of reducing his own sentence, and said hed purchased the drugs
from NOD via the Silk Road.
Agents in Seattle sought and were granted permission to place GPS tracking
devices on Sadlers car and that of his roommate, Jenna White, also charged
in this case. Investigators allege that the tracking showed the two traveled
to at least 38 post offices in the Seattle area during the surveillance
Interestingly, the investigators used the feedback on NODs Silk Road seller
profile to get a sense of the volume of drugs he sold. Much like eBay
sellers, merchants on the Silk Road are evaluated by previous buyers, who are
encouraged to leave feedback about the quality of the sellers goods and
services. According to the government, NOD had 1,400 reviews for individual
sales/purchases of small amounts of drugs, including: 2,269.5 grams of
cocaine, 593 grams of heroin and 105 grams of meth. The complaint notes that
these amounts dont count sales going back more than five months prior to the
investigation, when NOD first created his Silk Road vendor account.
Cryptome has published a copy of the complaint (PDF) against Sadler. A copy
of Sadlers case docket is here. NODs reputation on the Silk Road also was
discussed for several months on this Reddit thread.
Many readers of last weeks story on the Silk Road takedown have been asking
what is known about the locations of the Silk Road servers that were copied
by the FBI. Its still unclear how agents gained access to those servers, but
a civil forfeiture complaint released by the Justice Department shows that
they were aware of five, geographically dispersed servers that were
supporting the Silk Road, either by directly hosting the site and/or hosting
the Bitcoin wallets that the Silk Road maintains for buyers and sellers.
Two of those servers were located in Iceland, one in Latvia, another in
Switzerland, and apparently one in the United States. See the map above.
As if the subset of Bitcoin users who frequented the Silk Road already didnt
have enough to worry about, there are indications that the individual(s)
responsible for creating a competing Tor-based drug market  SheepMarketplace
 may have made some missteps that could make it easier for authorities to
discover the true location of that fraud bazaar as well. Check out this
Reddit thread for more on that.
Also, there are some indications that a Silk Road 2.0 is in the works, at
least according to DailyGadgetry.com. If that doesnt work out, perhaps
would-be future Dread Pirate Robertses will turn to Bitwasp, a budding Github
project which aims to provide open source code for setting up standalone
markets using Bitcoin.
I think what youre going to see is that a lot of me-too communities spring
up and get squished pretty quickly, said Nicholas Weaver, a researcher at
the International Computer Science Institute (ICSI) and at University of
California San Diego. Part of the reason why the Silk Road was so useful was
that it was so popular, and a half dozen smaller markets could be far less
efficient than these larger markets. But personally, Im betting well soon
see a fair number of them.
Finally, it seems a large number of Bitcoin users have been spending tiny
fractions of their coinage to send messages to the FBIs Bitcoin address on
Blockchain. Some of the love letters to the FBI are amusing, such as, All
your Bitcoins are belong to us, while others sound a defiant tone, including
this one: One star is born as another fades away. Which one will come next?
is my favorite riddle. Said a girl puffing rings in a dot, dot, dash haze.
No worry, No hurry. They cant stop the signal.
Update, Oct. 8, 2013: The BBC is reporting that four men have been arrested
in the U.K. for alleged drug offenses on the Silk Road, and that more arrests
are expected in the coming weeks. The BBC quotes the U.K. National Crime
Agency as saying such sites would are a key priority.

@_date: 2013-10-09 11:37:07
@_author: Eugen Leitl 
@_subject: Attacking Tor: how the NSA targets users' online anonymity 
(Use VM jails with amnesiac distros like Tails for daily browsing, separate security compartments using CubeOS and related, use air gap with USB sneakernet (using *nix with no USB autorun) to encrypt/decrypt and maintain sensitive information in general).
Attacking Tor: how the NSA targets users' online anonymity
Secret servers and a privileged position on the internet's backbone used to
identify users and attack target computers
Bruce Schneier
theguardian.com, Friday 4 October 2013 15.50 BST
Tor is a well-designed and robust anonymity tool, and successfully attacking
it is difficult. Photograph: Magdalena Rehova/Alamy
The online anonymity network Tor is a high-priority target for the National
Security Agency. The work of attacking Tor is done by the NSA's application
vulnerabilities branch, which is part of the systems intelligence
directorate, or SID. The majority of NSA employees work in SID, which is
tasked with collecting data from communications systems around the world.
According to a top-secret NSA presentation provided by the whistleblower
Edward Snowden, one successful technique the NSA has developed involves
exploiting the Tor browser bundle, a collection of programs designed to make
it easy for people to install and use the software. The trick identified Tor
users on the internet and then executes an attack against their Firefox web
The NSA refers to these capabilities as CNE, or computer network
The first step of this process is finding Tor users. To accomplish this, the
NSA relies on its vast capability to monitor large parts of the internet.
This is done via the agency's partnership with US telecoms firms under
programs codenamed Stormbrew, Fairview, Oakstar and Blarney.
The NSA creates "fingerprints" that detect http requests from the Tor network
to particular servers. These fingerprints are loaded into NSA database
systems like XKeyscore, a bespoke collection and analysis tool which NSA
boasts allows its analysts to see "almost everything" a target does on the
Using powerful data analysis tools with codenames such as Turbulence, Turmoil
and Tumult, the NSA automatically sifts through the enormous amount of
internet traffic that it sees, looking for Tor connections.
Last month, Brazilian TV news show Fantastico showed screenshots of an NSA
tool that had the ability to identify Tor users by monitoring internet
The very feature that makes Tor a powerful anonymity service, and the fact
that all Tor users look alike on the internet, makes it easy to differentiate
Tor users from other web users. On the other hand, the anonymity provided by
Tor makes it impossible for the NSA to know who the user is, or whether or
not the user is in the US.
After identifying an individual Tor user on the internet, the NSA uses its
network of secret internet servers to redirect those users to another set of
secret internet servers, with the codename FoxAcid, to infect the user's
computer. FoxAcid is an NSA system designed to act as a matchmaker between
potential targets and attacks developed by the NSA, giving the agency
opportunity to launch prepared attacks against their systems.
Once the computer is successfully attacked, it secretly calls back to a
FoxAcid server, which then performs additional attacks on the target computer
to ensure that it remains compromised long-term, and continues to provide
eavesdropping information back to the NSA.
Exploiting the Tor browser bundle
Tor is a well-designed and robust anonymity tool, and successfully attacking
it is difficult. The NSA attacks we found individually target Tor users by
exploiting vulnerabilities in their Firefox browsers, and not the Tor
application directly.
This, too, is difficult. Tor users often turn off vulnerable services like
scripts and Flash when using Tor, making it difficult to target those
services. Even so, the NSA uses a series of native Firefox vulnerabilities to
attack users of the Tor browser bundle.
According to the training presentation provided by Snowden,
EgotisticalGiraffe exploits a type confusion vulnerability in E4X, which is
an XML extension for Javascript. This vulnerability exists in Firefox 11.0 
16.0.2, as well as Firefox 10.0 ESR  the Firefox version used until recently
in the Tor browser bundle. According to another document, the vulnerability
exploited by EgotisticalGiraffe was inadvertently fixed when Mozilla removed
the E4X library with the vulnerability, and when Tor added that Firefox
version into the Tor browser bundle, but NSA were confident that they would
be able to find a replacement Firefox exploit that worked against version
17.0 ESR.
The Quantum system
To trick targets into visiting a FoxAcid server, the NSA relies on its secret
partnerships with US telecoms companies. As part of the Turmoil system, the
NSA places secret servers, codenamed Quantum, at key places on the internet
backbone. This placement ensures that they can react faster than other
websites can. By exploiting that speed difference, these servers can
impersonate a visited website to the target before the legitimate website can
respond, thereby tricking the target's browser to visit a Foxacid server.
In the academic literature, these are called "man-in-the-middle" attacks, and
have been known to the commercial and academic security communities. More
specifically, they are examples of "man-on-the-side" attacks.
They are hard for any organization other than the NSA to reliably execute,
because they require the attacker to have a privileged position on the
internet backbone, and exploit a "race condition" between the NSA server and
the legitimate website. This top-secret NSA diagram, made public last month,
shows a Quantum server impersonating Google in this type of attack.
The NSA uses these fast Quantum servers to execute a packet injection attack,
which surreptitiously redirects the target to the FoxAcid server. An article
in the German magazine Spiegel, based on additional top secret Snowden
documents, mentions an NSA developed attack technology with the name of
QuantumInsert that performs redirection attacks. Another top-secret Tor
presentation provided by Snowden mentions QuantumCookie to force cookies onto
target browsers, and another Quantum program to "degrade/deny/disrupt Tor
This same technique is used by the Chinese government to block its citizens
from reading censored internet content, and has been hypothesized as a
probable NSA attack technique.
The FoxAcid system
According to various top-secret documents provided by Snowden, FoxAcid is the
NSA codename for what the NSA calls an "exploit orchestrator," an
internet-enabled system capable of attacking target computers in a variety of
different ways. It is a Windows 2003 computer configured with custom software
and a series of Perl scripts. These servers are run by the NSA's tailored
access operations, or TAO, group. TAO is another subgroup of the systems
intelligence directorate.
The servers are on the public internet. They have normal-looking domain
names, and can be visited by any browser from anywhere; ownership of those
domains cannot be traced back to the NSA.
However, if a browser tries to visit a FoxAcid server with a special URL,
called a FoxAcid tag, the server attempts to infect that browser, and then
the computer, in an effort to take control of it. The NSA can trick browsers
into using that URL using a variety of methods, including the race-condition
attack mentioned above and frame injection attacks.
FoxAcid tags are designed to look innocuous, so that anyone who sees them
would not be suspicious. An example of one such tag [LINK REMOVED] is given
in another top-secret training presentation provided by Snowden.
There is no currently registered domain name by that name; it is just an
example for internal NSA training purposes.
The training material states that merely trying to visit the homepage of a
real FoxAcid server will not result in any attack, and that a specialized URL
is required. This URL would be created by TAO for a specific NSA operation,
and unique to that operation and target. This allows the FoxAcid server to
know exactly who the target is when his computer contacts it.
According to Snowden, FoxAcid is a general CNE system, used for many types of
attacks other than the Tor attacks described here. It is designed to be
modular, with flexibility that allows TAO to swap and replace exploits if
they are discovered, and only run certain exploits against certain types of
The most valuable exploits are saved for the most important targets.
Low-value exploits are run against technically sophisticated targets where
the chance of detection is high. TAO maintains a library of exploits, each
based on a different vulnerability in a system. Different exploits are
authorized against different targets, depending on the value of the target,
the target's technical sophistication, the value of the exploit, and other
In the case of Tor users, FoxAcid might use EgotisticalGiraffe against their
Firefox browsers.
FoxAcid servers also have sophisticated capabilities to avoid detection and
to ensure successful infection of its targets. One of the top-secret
documents provided by Snowden demonstrates how FoxAcid can circumvent
commercial products that prevent malicious software from making changes to a
system that survive a reboot process.
According to a top-secret operational management procedures manual provided
by Snowden, once a target is successfully exploited it is infected with one
of several payloads. Two basic payloads mentioned in the manual, are designed
to collect configuration and location information from the target computer so
an analyst can determine how to further infect the computer.
These decisions are made in part by the technical sophistication of the
target and the security software installed on the target computer; called
Personal Security Products or PSP, in the manual.
FoxAcid payloads are updated regularly by TAO. For example, the manual refers
to version 8.2.1.1 of one of them.
FoxAcid servers also have sophisticated capabilities to avoid detection and
to ensure successful infection of its targets. The operations manual states
that a FoxAcid payload with the codename DireScallop can circumvent
commercial products that prevent malicious software from making changes to a
system that survive a reboot process.
The NSA also uses phishing attacks to induce users to click on FoxAcid tags.
TAO additionally uses FoxAcid to exploit callbacks  which is the general
term for a computer infected by some automatic means  calling back to the
NSA for more instructions and possibly to upload data from the target
According to a top-secret operational management procedures manual, FoxAcid
servers configured to receive callbacks are codenamed FrugalShot. After a
callback, the FoxAcid server may run more exploits to ensure that the target
computer remains compromised long term, as well as install "implants"
designed to exfiltrate data.
By 2008, the NSA was getting so much FoxAcid callback data that they needed
to build a special system to manage it all.

@_date: 2013-10-10 10:36:44
@_author: Eugen Leitl 
@_subject: NSA data centre power surges & unknowns... 
You obviously have to consider not just the known unknowns, but also
unknown unknowns. FWIW, I much doubt they can factor large numbers with QC (if you want to make sure, do a lit review on QC,
pull up the list of names, and see whether some of them suddenly
stopped publishing, or greatly reduced their publishing rate), but public key cryptosystems do have a slight smell about them lately.
We definitely need more diversity in cryptosystems, and should revert
to systems which are more well-understood, and focus on future systems
that are simple to analyze.

@_date: 2013-10-10 14:13:36
@_author: Eugen Leitl 
@_subject: Cryptographers condemn US =?utf-8?Q?Nation?= 
but mathematicians shrug.
 Liberation Technologies ,
 cypherpunks
Researchers split over NSA hacking
Cryptographers condemn US National Security Agencys tapping and tampering,
but mathematicians shrug.
Ann Finkbeiner 08 October 2013
The National Security Agency is the largest employer of mathematicians in the
United States.
PATRICK SEMANSKY/ASSOCIATED PRESS
The US National Security Agency (NSA) has upset a great many people this
year. Since June, newspapers have been using documents leaked by former
intelligence worker Edward Snowden to show how the secretive but powerful
agency has spied on the communications of US citizens and foreign
governments. Last month, the media reported that the NSA, which is based in
Fort Meade, Maryland, had undermined Internet security standards. The
revelations have sparked international outrage at the highest levels  even
the president of Brazil cancelled a visit to the United States because of the
Yet amid the uproar, NSA-supported mathematicians and computer scientists
have remained mostly quiet, to the growing frustration of others in similar
fields. Most have never met a funding source they do not like, says Phillip
Rogaway, a computer scientist at the University of California, Davis, who has
sworn not to accept NSA funding and is critical of other researchers
silence. And most of us have little sense of social responsibility.
Mathematicians and the NSA are certainly interdependent. The agency declares
that it is the United States largest maths employer, and Samuel Rankin,
director of the Washington DC office of the American Mathematical Society,
estimates that the agency hires 3040 mathematicians every year. The NSA
routinely holds job fairs on university campuses, and academic researchers
can work at the agency on sabbaticals. In 2013, the agencys mathematical
sciences programme offered more than US$3.3 million in research grants.
Furthermore, the NSA has designated more than 150 colleges and universities
as centres of excellence, which qualifies students and faculty members for
extra support. It can also fund research indirectly through other agencies,
and so the total amount of support may be much higher. A leaked budget
document says that the NSA spends more than $400 million a year on research
and technology  although only a fraction of this money might go to research
outside the agency itself.
I understand whats in the newspapers, but the NSA is funding serious
long-term fundamental research and Im happy theyre doing it. Many US
researchers, especially those towards the basic-research end of the spectrum,
are comfortable with the NSAs need for their expertise. Christopher Monroe,
a physicist at the University of Maryland in College Park, is among them. He
previously had an NSA grant for basic research on controlling cold atoms,
which can form the basis of the qubits of information in quantum computers.
He notes that he is free to publish in the open literature, and he has no
problems with the NSA research facilities in physical sciences,
telecommunications and languages that sit on his campus. Monroe is
sympathetic to the NSAs need to track the development of quantum computers
that could one day be used to crack codes beyond the ability of conventional
machines. I understand whats in the newspapers, he says, but the NSA is
funding serious long-term fundamental research and Im happy theyre doing
Dena Tsamitis, director of education, outreach and training at Carnegie
Mellon Universitys cybersecurity research centre in Pittsburgh,
Pennsylvania, also wants to maintain the relationship. She oversees visitors
and recruiters from the NSA but her centre gets no direct funding. She says
that her graduate students understand the NSAs public surveillance to be a
policy decision, not a technology decision. Our students are most interested
in the technology. And the NSA, she says  echoing many other researchers 
has very interesting technology problems.
The academics who are professionally uneasy with the NSA tend to lie on the
applied end of the spectrum: they work on computer security and cryptography
rather than pure mathematics and basic physics. Matthew Green, a
cryptographer at Johns Hopkins University in Baltimore, Maryland, says that
these researchers are unsettled in part because they are dependent on
protocols developed by the US National Institute of Standards and Technology
(NIST) to govern most encrypted web traffic. When it was revealed that the
NSA had inserted a back door into the NIST standards to allow snooping,
some of them felt betrayed. We certainly had no idea that they were
tampering with products or standards, says Green. He is one of 47
technologists who on 4 October sent a letter to the director of a group
created last month by US President Barack Obama to review NSA practices,
protesting because the group does not include any independent technologists.
Edward Felten, who studies computer security at Princeton University in New
Jersey, says that the NSAs breach of security standards means that
cryptographers will need to change what they call their threat model  the
set of assumptions about possible attacks to guard against. Now the attacks
might come from the home team. There was a sense of certain lines that NSA
wouldnt cross, says Felten, and now were not so sure about that.
Nature 502, 152 (10 October 2013) doi:10.1038/502152a

@_date: 2013-10-11 13:42:13
@_author: Eugen Leitl 
@_subject: who are the service operators here? 
I think we need more hidden services to make the darknet more attractive,
less exits. The open Internet has been dead for a while, time to accept it.
Running a non-exit relay from home is still worthwhile, since it raises the bar for physical access, and also increases the traffic background.
Decentral search is pretty important, we could really use lots of
YaCy nodes as hidden services -- indexing not just the hidden web, of
I wish there was a library of different privacy-based appliances in
virtual formats (.ovf) which are kept up to date for easy deployment
(even though running it on bare iron would be preferable). That would
seem to be a lot of work, though, and run into trust issues.

@_date: 2013-10-11 17:53:25
@_author: Eugen Leitl 
@_subject: who are the service operators here? 
Their official position IIRC is that they discourage VM use,
so they might not want to offer a virtual appliance.
While they're technically correct, there's value in virtual
network plumbing, so you can build up separated compartments, and
routers which force everything through Tor.
It would reduce the threshold of entry, even though there
are ways of detecting that you're running in a hypervisor
jail, and break out of it.

@_date: 2013-10-12 11:28:36
@_author: Eugen Leitl 
@_subject: who are the service operators here? 
Certainly nice growth, but realistically won't be sustained post-Snowden.
Most-used services on the Internet is search, and there's just one
useful search engine in onionland: 3g2upl4pq6kufc4m.onion and it's
not operated by multiple, independent, noncommercial parties.

@_date: 2013-10-14 15:36:14
@_author: Eugen Leitl 
@_subject: funding Tor development 
Guys, in order to minimize Tor Project's dependance on
federal funding and/or increase what they can do it
would be great to have some additional funding ~10 kUSD/month.
If anyone is aware of anyone who can provide funding at
that level or higher, please contact execdir at torproject.org

@_date: 2013-10-14 20:15:42
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
The worst is that the entire trainwreck has been so
predictable, right from the start.

@_date: 2013-10-15 09:50:12
@_author: Eugen Leitl 
@_subject: NSA collects millions of e-mail address books globally 
NSA collects millions of e-mail address books globally
Video: In June, President Obama said the NSAs email collecting program does
not apply to U.S. citizens.
By Barton Gellman and Ashkan Soltani, Tuesday, October 15, 12:53 AM E-mail
the writer
The National Security Agency is harvesting hundreds of millions of contact
lists from personal e-mail and instant messaging accounts around the world,
many of them belonging to Americans, according to senior intelligence
officials and top-secret documents provided by former NSA contractor Edward
The collection program, which has not been disclosed before, intercepts
e-mail address books and buddy lists from instant messaging services as
they move across global data links. Online services often transmit those
contacts when a user logs on, composes a message, or synchronizes a computer
or mobile device with information stored on remote servers.
Rather than targeting individual users, the NSA is gathering contact lists in
large numbers that amount to a sizable fraction of the worlds e-mail and
instant messaging accounts. Analysis of that data enables the agency to
search for hidden connections and to map relationships within a much smaller
universe of foreign intelligence targets.
During a single day last year, the NSAs Special Source Operations branch
collected 444,743 e-mail address books from Yahoo, 105,068 from Hotmail,
82,857 from Facebook, 33,697 from Gmail and 22,881 from unspecified other
providers, according to an internal NSA PowerPoint presentation. Those
figures, described as a typical daily intake in the document, correspond to a
rate of more than 250million a year.
Each day, the presentation said, the NSA collects contacts from an estimated
500,000 buddy lists on live-chat services as well as from the inbox displays
of Web-based e-mail accounts.
The collection depends on secret arrangements with foreign telecommunications
companies or allied intelligence services in control of facilities that
direct traffic along the Internets main data routes.
Although the collection takes place overseas, two senior U.S. intelligence
officials acknowledged that it sweeps in the contacts of many Americans. They
declined to offer an estimate but did not dispute that the number is likely
to be in the millions or tens of millions.
A spokesman for the Office of the Director of National Intelligence, which
oversees the NSA, said the agency is focused on discovering and developing
intelligence about valid foreign intelligence targets like terrorists, human
traffickers and drug smugglers. We are not interested in personal information
about ordinary Americans.
The spokesman, Shawn Turner, added that rules approved by the attorney
general require the NSA to minimize the acquisition, use and dissemination
of information that identifies a U.S. citizen or permanent resident.
The NSAs collection of nearly all U.S. call records, under a separate
program, has generated significant controversy since it was revealed in June.
The NSAs director, Gen. Keith B. Alexander, has defended bulk collection
as an essential counterterrorism and foreign intelligence tool, saying, You
need the haystack to find the needle.
Contact lists stored online provide the NSA with far richer sources of data
than call records alone. Address books commonly include not only names and
e-mail addresses, but also telephone numbers, street addresses, and business
and family information. Inbox listings of e-mail accounts stored in the
cloud sometimes contain content, such as the first few lines of a message.
Taken together, the data would enable the NSA, if permitted, to draw detailed
maps of a persons life, as told by personal, professional, political and
religious connections. The picture can also be misleading, creating false
associations with ex-spouses or people with whom an account holder has had
no contact in many years.
The NSA has not been authorized by Congress or the special intelligence court
that oversees foreign surveillance to collect contact lists in bulk, and
senior intelligence officials said it would be illegal to do so from
facilities in the United States. The agency avoids the restrictions in the
Foreign Intelligence Surveillance Act by intercepting contact lists from
access points all over the world, one official said, speaking on the
condition of anonymity to discuss the classified program. None of those are
on U.S. territory.
Because of the method employed, the agency is not legally required or
technically able to restrict its intake to contact lists belonging to
specified foreign intelligence targets, he said.
When information passes through the overseas collection apparatus, the
official added, the assumption is youre not a U.S. person.
In practice, data from Americans is collected in large volumes  in part
because they live and work overseas, but also because data crosses
international boundaries even when its American owners stay at home. Large
technology companies, including Google and Facebook, maintain data centers
around the world to balance loads on their servers and work around outages.
A senior U.S. intelligence official said the privacy of Americans is
protected, despite mass collection, because we have checks and balances
built into our tools.
NSA analysts, he said, may not search within the contacts database or
distribute information from it unless they can make the case that something
in there is a valid foreign intelligence target in and of itself.
In this program, the NSA is obliged to make that case only to itself or
others in the executive branch. With few exceptions, intelligence operations
overseas fall solely within the presidents legal purview. The Foreign
Intelligence Surveillance Act, enacted in 1978, imposes restrictions only on
electronic surveillance that targets Americans or takes place on U.S.
By contrast, the NSA draws on authority in the Patriot Act for its bulk
collection of domestic phone records, and it gathers online records from U.S.
Internet companies, in a program known as PRISM, under powers granted by
Congress in the FISA Amendments Act. Those operations are overseen by the
Foreign Intelligence Surveillance Court.
Sen. Dianne Feinstein, the California Democrat who chairs the Senate
Intelligence Committee, said in August that the committee has less
information about, and conducts less oversight of, intelligence gathering
that relies solely on presidential authority. She said she planned to ask for
more briefings on those programs.
In general, the committee is far less aware of operations conducted under
12333, said a senior committee staff member, referring to Executive Order
12333, which defines the basic powers and responsibilities of the
intelligence agencies. I believe the NSA would answer questions if we asked
them, and if we knew to ask them, but it would not routinely report these
things, and, in general, they would not fall within the focus of the
Because the agency captures contact lists on the fly as they cross major
Internet switches, rather than at rest on computer servers, the NSA has no
need to notify the U.S. companies that host the information or to ask for
help from them.
We have neither knowledge of nor participation in this mass collection of
web-mail addresses or chat lists by the government, said Google spokeswoman
Niki Fenwick.
At Microsoft, spokeswoman Nicole Miller said the company does not provide
any government with direct or unfettered access to our customers data,
adding that we would have significant concerns if these allegations about
government actions are true.
Facebook spokeswoman Jodi Seth said that we did not know and did not assist
in the NSAs interception of contact lists.
It is unclear why the NSA collects more than twice as many address books from
Yahoo than the other big services combined. One possibility is that Yahoo,
unlike other service providers, has left connections to its users unencrypted
by default.
Suzanne Philion, a Yahoo spokeswoman, said Monday in response to an inquiry
from The Washington Post that, beginning in January, Yahoo would begin
encrypting all its e-mail connections.
Google was the first to secure all its e-mail connections, turning on SSL
encryption globally in 2010. People with inside knowledge said the move was
intended in part to thwart large-scale collection of its users information
by the NSA and other intelligence agencies.
The volume of NSA contacts collection is so high that it has occasionally
threatened to overwhelm storage repositories, forcing the agency to halt its
intake with emergency detasking orders. Three NSA documents describe
short-term efforts to build an across-the-board technology throttle for
truly heinous data and longer-term efforts to filter out information that
the NSA does not need.
Spam has proven to be a significant problem for the NSA  clogging databases
with information that holds no foreign intelligence value. The majority of
all e-mails, one NSA document says, are SPAM from fake addresses and never
delivered to targets.
In fall 2011, according to an NSA presentation, the Yahoo account of an
Iranian target was hacked by an unknown actor, who used it to send spam.
The Iranian had a number of Yahoo groups in his/her contact list, some with
many hundreds or thousands of members.
The cascading effects of repeated spam messages, compounded by the automatic
addition of the Iranians contacts to other peoples address books, led to a
massive spike in the volume of traffic collected by the Australian
intelligence service on the NSAs behalf.
After nine days of data- bombing, the Iranians contact book and contact
books for several people within it were emergency detasked.
In a briefing from the NSAs Large Access Exploitation working group, that
example was used to illustrate the need to narrow the criteria for data
interception. It called for a shifting collection philosophy: Memorialize
what you need vs. Order one of everything off the menu and eat what you
Julie Tate contributed to this report. Soltani is an independent security
researcher and consultant.

@_date: 2013-10-15 11:08:29
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
The future that never was was built with Lisp machines and NeWS.
Twatr who?

@_date: 2013-10-15 14:23:46
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
Latest TBB3: Within our dataset of several million visitors, only one in 466 browsers have the same fingerprint as yours.
Currently, we estimate that your browser has a fingerprint that conveys 8.86 bits of identifying information.

@_date: 2013-10-15 14:27:04
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
As long as you're jailing your browser into an amnesiac
compartment and run TBB (latest 3 alpha is pretty good)
your risk is minimal.

@_date: 2013-10-15 14:37:44
@_author: Eugen Leitl 
@_subject: Bitcoin mining efficiency and Botnets 
Make something requiring huge LUTs, and in-memory access. That is not ASICable or FPGAble.
Doubling rate is now 3 years by end of this year instead
of 18 months, according to AMD. Moore is dead, long live Moore (in 3d volume integration
of molecular components, coming in a couple decades).

@_date: 2013-10-15 16:21:36
@_author: Eugen Leitl 
@_subject: Bitcoin mining efficiency and Botnets 
Never mentioned Bitcoin, and I would agree in principle.
Due to network effect and apparent good design Bitcoin may
last a lot longer than its detractors like to think, but it will fall, eventually. I disagree there's palpable progress in QC inasmuch practical
computing is concerned, at least in the open literature.
DNA computers basically don't work.
You're sampling conformation space of a linear molecule with
lots of viscous drag. There is very little infinity in that.

@_date: 2013-10-15 20:48:55
@_author: Eugen Leitl 
@_subject: Lessons from Silk Road: don't host your virtual illegal drug bazaar 
Lessons from Silk Road: don't host your virtual illegal drug bazaar in
By Adrianne Jeffries on October 14, 2013 11:47 am Email
When it comes to protecting your virtual black market from the Federal Bureau
of Investigation (FBI), some countries are better than others. As it turns
out, Iceland is probably not where you want to be. While the country may have
protected WikiLeaks from the Americans, it's not harboring the recently
busted illegal drug bazaar Silk Road. The Reykjavik Metropolitan Police have
confirmed that they handed over data on the Silk Road at the request of
American authorities.
It's unclear how much information Iceland turned over, but the FBI claims two
Silk Road servers were based there. Icelandic police say the site was
actually hosted there. Since Iceland does not have a formal Mutual Legal
Assistance Treaty (MLAT) with the US, it appears that the FBI negotiated a
special one-time agreement in order to get the data.
It still looks like the bulk of the information that broke open the case did
not come from Iceland, however. The complaint says "an image of the Silk Road
Web Server was made on or about July 23rd, 2013, and produced thereafter to
the FBI" as a result of a request made to a foreign country under a formal
"AN IMAGE OF THE SILK ROAD WEB SERVER WAS MADE ON OR ABOUT JULY 23RD, 2013."
That image, or bit-for-bit copy, of the Silk Road server gave authorities
access to private messages between the Silk Road's owner and other members of
the site. It was instrumental in seizing the site and arresting Ross
Ulbricht, the man police allege was behind the Silk Road.
Runa Sandvik, who works on the anonymizing network Tor, has been trying to
figure out which country handed over that server image. She initially ruled
out Iceland because it does not have an MLAT with the US. Various Silk Road
content was also hosted in the US, Latvia, and Malaysia. Latvia and Malaysia
are both MLAT signatories. If the request was indeed made under an MLAT, it
looks like the image either came from one of those countries or another that
has not been revealed yet by the FBI.
Another possibility is that the FBI's complaint erroneously claimed the
request was made under an MLAT, when the reality was less formal. Either way,
future virtual drug kingpins now know that Iceland is no safe haven.
Correction: An earlier version of this story said that Malaysia is not an
MLAT signatory; that is incorrect. Malaysia and the US signed an MLAT in

@_date: 2013-10-16 08:24:04
@_author: Eugen Leitl 
@_subject: Bitcoin mining efficiency and Botnets 
Difficulty is adaptive, so it will go down if hash rate goes down.
It's not a one-way ratchet.

@_date: 2013-10-16 09:43:10
@_author: Eugen Leitl 
@_subject: The NSA back door to NIST 
Thomas C. Hales (University of Pittsburgh)
(This article will be published in the Notices of the American Mathematical
Use once. Die once.  activist saying about insecure communication
This article gives a brief mathematical description of the NIST standard for
cryptographically secure pseudo-random number generation by elliptic curves,
the back door to the algorithm discovered by Ferguson and Shumow, and finally
the design of the back door based on the Diffie-Hellman key exchange
NIST (the National Institute for Standards and Technology) of the U.S.
Department of Commerce derives its mandate from the U.S. Constitution,
through the congressional power to fix the standard of weights and
measures. In brief, NIST establishes the basic standards of science and
commerce. Whatever NIST says about cryptography becomes implemented in
cryptographic applications throughout U.S. government agencies. Its influence
leads to the widespread use of its standards in industry and the broad
adoption of its standards internationally.
Through the Snowden disclosures, the NIST standard for pseudo-random number
generation has fallen into disrepute. Here I describe the back door to the
NIST standard for pseudo-random number generation in elementary and
mathematically precise terms. The NIST standard offers three methods for
pseudo-random number generation [NIST]. My remarks are limited to the third
of the three methods, which is based on elliptic curves.
Random number generators can either be truly random (obtaining their values
from randomness in the physical world such as a quantum mechanical process)
or pseudo-random (obtaining their values from a deterministic algorithm, yet
displaying a semblance of randomness). The significance of random number
generation within the theory of algorithms can be gauged by Knuths
multivolume book, The Art of Computer Programming. It devotes a massive 193
pages (half of volume two) to the subject! A subclass of pseudo-random number
generators are cryptographically secure, intended for use in cryptographic
applications such as key generation, one-way hash functions, signature
schemes, private key cryptosystems, and zero knowledge interactive proofs
Elliptic curves as pseudo-random number generators
The NIST standard gives a list of explicit mathematical data (E,p,n,f,P,Q) to
be used for pseudo-random number generation [NIST]. Here E is an elliptic
curve defined over a finite field \mathbb{F}_p of prime order p. The group
E(\mathbb{F}_p) has order n, which is prime for all of the curves that occur
in the NIST standard. The elements of the group E(\mathbb{F}_p) consist of
the set of points on an affine curve, together with a point at infinity which
serves as the identity element of the group. The affine curve is defined by
an equation y^2 = f(x) for some explicit cubic polynomial f in
\mathbb{F}_p[x]. Finally, P and Q are given points on the affine curve.
NIST gives a few sets of data and in each case the prime number p is large.
(The smallest is greater than 10^{77}.) No explanation is given of the
particular choices (E,p,n,f,P,Q). We are told to use these data and not to
question why. The standard stipulates that one of the following NIST
approved curves with associated points shall be used in applications
requiring certification under FIPS-140 [U.S. government computer security
When A is any point other than the identity in E(\mathbb{F}_p), we may
evaluate the coordinate function x at A, to obtain x(A)\in \mathbb{F}_p. By
further lifting \mathbb{F}_p to a set of representatives in \mathbb{Z}, we
obtain a function by composition x1 : E(\mathbb{F}_p)\setminus\{0\}~ \to~
\mathbb{F}_p~\to~ \mathbb{Z}. Write (n,A)\mapsto n * A for the
\mathbb{Z}-module action of \mathbb{Z} on E. (We write powers of the group
element A using multiplicative rather than exponential notation.)
The pseudo-random bit generator is initialized with a random integer seed s,
obtained by some different process such as a separate random number
generator. What is important for us is that the number s represents the
hidden internal state of the algorithm. The hidden state must be kept secret
for the pseudo-randomness to be effective. (Once the state is disclosed, a
pseudo-random sequence becomes predictable and useless for many cryptographic
The essence of the pseudo-random bit generator can be written in the
Objective Caml language as follows. In the syntax of this language, each
phrase (let x = a in ) defines the value of x to be a. The last line of the
block of code gives the output of the function.
let pseudo_random s =
 let r = x1 (s * P) in
 let s' = x1 (r * P) in
 let t = x1 (r * Q) in
 let b = extract_bits t in
  (s',b);
That is, we successively apply the integer s or r to the point P or the point
Q and take the x1 coordinate of the resulting point, then extract some bits
from the number t. The integer s becomes the new secret internal state to be
fed into the next iteration of the function. The output b is passed to the
consumer of pseudo-random bits. This output may become publicly known. The
function extract_bits operates by converting t to a list of bits, discarding
the 16 most significant bits (for reasons that do not matter to this
discussion), and giving the remaining bits as output. According to NIST
standards, by iterating this function, updating the internal state at each
iteration, a cryptographically secure stream b  of pseudo-random bits is
The back door
This algorithm is fatally flawed, as Ferguson and Shumow pointed out
[Shumow-Ferguson]. Since P and Q are non-identity elements of a cyclic group
of prime order, each is a multiple of the other. Write P = e * Q, for some
integer e. We show that once we have e in hand, it is a simple matter to
determine the secret internal state s of the pseudo-random bit generator by
observing the output b, and thus to compromise the entire system.
The function extract_bits discards 16 bits. Given the output b, we take the
2^{16} (a small number of) possible preimages t of b under extract_bits. For
each t, the coordinate x is known, and solving a quadratic, there are at most
two possibilities for the coordinate y of a point A on the elliptic curve
such that t = x1 (A). One such A is r * Q. For each A, we compute e * A. One
of the small number of possibilities for e * A is
e * (r * Q) = r * (e * Q) = r * P.     (1)
Finally s = x1 (r * P). In short, the internal state s can be be narrowed
down to a small number of possibilities by an examination of the
pseudo-random output bitstream. Shumow and Ferguson state that in
experiments, 32 bytes of output was sufficient to uniquely identify the
internal state of the PRNG [pseudo-random number generator].
The back door to the algorithm is the number e such that P = e * Q. To use
the back door, one must know of the value e. The NIST standard does not
disclose e (of course!), and extensive cryptographic experience suggests that
it is hard to compute e from the coordinates of P and Q (unless you happen to
own a quantum computer). This is the problem of discrete logarithms. But
starting with e, there is no difficulty in creating a pair P and Q. The back
door is universal: a single number e gives back door access to the internal
state of the algorithm of all users worldwide.
It is a matter of public fact that the NSA was tightly involved in the
writing of the standard. Indeed, NIST is required by law to consult with NSA
in creating its standard. According to the New York Times, classified NSA
memos appear to confirm that the fatal weakness, discovered by two Microsoft
cryptographers in 2007, was engineered by the agency [NYT]. The news article
goes on to say that eventually, NSA became the sole editor and then pushed
aggressively to make this the standard for the 163 member countries of the
International Organization for Standardization. Further historical and social
context appears in [Wired]. NSA had facile access to the crown jewel e and
motive to seize it. Draw your own conclusions.
1. This back door to this algorithm is extremely elementary from a
mathematical perspective. We wrote the essential algorithm in six lines of
computer code, even if more supporting code is needed to make it industrial
strength. The algorithm could be explained to undergraduate math majors, or
sufficiently advanced high-school students. The story also has the spy-agency
intrigue to make a good math club talk or a special lecture in an elementary
abstract algebra course. We essentially just need to understand that an
elliptic curve is an abelian group whose elements (other than the identity
element) are determined by two numbers x and y, that y is the root of a
quadratic when x is given, and that every non-identity element of a cyclic
group of prime order is a generator. Easy stuff.
2. Without prior knowledge of the back door, how difficult would it be to
rediscover the possible existence of a back door? An analysis of the argument
shows the required level of creativity is that of an undergraduate homework
problem. We must think to write the element P as a multiple of the generator
Q in a cyclic group of prime order. This a student learns in the first weeks
of undergraduate algebra.
The rest of the process of inverting the pseudo-random number generator is
determined by the definition of the function itself: simply take each step
defining the function and reverse the steps, asking for the preimage of the
function at each step of its definition, working from the output back to the
secret state s. Once the question of inverting the function is asked, it is
easy to do the group theory, even if it is computationally difficult to write
e explicitly.
One-way functions are a standard tool in the cryptographers bag. Every
professional who has been trained to analyze cryptographic algorithms knows
to ask the question of invertibility. It is unsettling that NIST and others
do not seem to have asked this basic question.
Diffie-Hellman key exchange
In what follows, let us assume that someone, whom we will call the Spy, has
access to the back door e. How is it possible for the Spy and the end user
(the User) of the NIST algorithm to come into possession of the same shared
secret (the internal state of the pseudo-random number generator), when all
communication between them is public? Information flows from the Spy to the
User through the published NIST standard, and from the User back to the Spy
through the public output of the pseudo-random generator. The back door must
have a remarkable cryptographic design to permit a secret to pass across
these public channels, yet prevent the secret from becoming known to a third
As we now explain, the design of the back door to NIST is based on a
well-known algorithm in cryptography called the Diffie-Hellman key exchange
[Diffie-Hellman]. This is an algorithm to share a secret between two parties,
when there is a possibility that the channel of communication is being
monitored. In the current context, the Spy has full knowledge of the
Diffie-Hellman key exchange for what it is. However, the User participates in
the exchange innocently and unwittingly, by blindly following the rules of
the NIST protocol.
The Diffie-Hellman key exchange requires a group, which we will take to be a
cyclic group E of order n (to preserve notation). The group E, its order n,
and a generator Q are made public. To share a secret, the first party (the
Spy), picks a random number e, which is kept secret, and publishes P = e * Q
to the world. The second party (the User) picks a random number r, which is
kept secret, and publishes r * Q. Then by Equation (1), the Spy who knows e
and r *Q, and the User who knows r and e * Q can both compute (r e) * Q = r *
P, which is the shared secret. (In our context, the shared secret determines
the internal state s of the pseudo-random number generator.) If E is a group
in which the public knowledge E, n, Q, P = e * Q, r * Q does not allow the
easy computation of (r e) * Q, then the shared secret is protected from
public disclosure by the difficulty of the computation. In this way, the only
two who learn the internal state of the pseudo-random number generator are
the Spy and the User.
What we have described here is not an imaginary scenario: NIST documents do
in fact publish the data E, n, Q, and P, needed to initiate the
Diffie-Hellman exchange. A user, when making public the output from the
pseudo-random number generator, does in fact complete the exchange.
Diffie-Hellman is Diffie-Hellman, whether it has been advertised as such or
To say that the Diffie-Hellman key exchange algorithm is well-known is a vast
understatement. This algorithm is a significant lesson in virtually every
first course in cryptography everywhere in the world. Building on Merkle, the
Diffie-Hellman paper, by starting the entire field of public key
cryptography, is one of the most influential papers in cryptography ever
What is the significance of all this? It is no secret that the NSA employs
some of the worlds keenest cryptographic minds. They all know
Diffie-Hellman. In my opinion, an algorithm that has been designed by NSA
with a clear mathematical structure giving them exclusive back door access is
no accident, particularly in light of the Snowden documents. This is a work
of experts.
[NIST] E. Barker and J. Kelsey, Recommendation for random number generation
using deterministic random bit generators. NIST Special Publication 800-90A
(2012), [Diffie-Hellman] W. Diffie and M. Hellman, New directions in cryptography.
IEEE Transactions on Information Theory 22 (1976), 644-654.
[Luby] M. Luby, Pseudorandomness and cryptographic applications, Princeton
University Press, 1996.
[NYT] N. Perloth, J. Larson, and S. Shane. N.S.A. able to foil basic
safeguards of privacy on web, September 5, 2013, New York Times,
[Shumow-Ferguson] D. Shumow and N. Ferguson, On the possibility of a back
door in the NIST SP800-90 dual EC PRNG,
 2007.
[Wired] K. Zetter, How a crypto `backdoor pitted the tech world against the
NSA, Wired (Sept 24, 2013),

@_date: 2013-10-16 10:26:43
@_author: Eugen Leitl 
@_subject: Curious use of cpunks list [Brian Carroll] 
The author is almost certainly schizophrenic, but he's
not disruptive, and occasionally amusing. I don't see
any reasons for action.

@_date: 2013-10-16 16:34:12
@_author: Eugen Leitl 
@_subject: The NSA's New Code Breakers 
(thank, John, worth reposting full-text)
The NSA's New Code Breakers
America's using front companies, break-in artists, and hacktivists to spy on
everyone -- and only North Korea seems able to resist.
BY MATTHEW M. AID | OCTOBER 15, 2013
There was a time when the code breakers of the National Security Agency
actually took the lead in solving enemy encryption systems. These days, not
so much. In today's NSA, it's hackers, break-in artists, corporate liaisons,
and shadow salesman using front companies who are at the forefront of this
effort. Even so-called "hacktivists" play an unwitting role in helping the
NSA gain access to computer networks -- both hostile and friendly.
Just about the only place that's somewhat immune to the NSA's new style of
code-breaking attacks? North Korea, because it's so disconnected from the
rest of the world's networks.
Former U.S. intelligence officials confirm that the more than 1,500
cryptanalysts, mathematicians, scientists, engineers, and computer
technicians who comprise NSA's elite cryptanalytic unit, the Office of
Cryptanalysis and Exploitation Services (S31), have had a remarkably large
number of code-breaking successes against foreign targets since the 9/11
attacks. But these wins were largely dependent on clandestine intelligence
activities for much of their success in penetrating foreign communications
networks and encryption systems, and not the more traditional cryptanalytic
attacks on encrypted messages that were the norm during the Cold War era.
Prior to 9/11, NSA's cryptanalysts used their huge stable of supercomputers
to break cipher systems using what is referred to as "brute force methods" --
using the super computers to run every cipher permutation until the message
or messages in question become readable. It was a long, tedious, and
extremely costly process (today NSA spends over $247 million a year to buy
and maintain its state-of-the-art supercomputer systems just for
cryptanalytic use). But it did work if there were inherent vulnerabilities or
structural weakness in the cipher being attacked, or if the system's users
did not practice proper communications security procedures, such as changing
the cipher keys and passwords frequently.
The NSA today has more supercomputers than ever and the agency still employs
a number of puzzle-solvers, linguists, and math geeks. But these classic
cryptanalysts have, in part, given way to a new breed.
You won't learn this in the files leaked by former NSA contractor Edward
Snowden -- at least not directly. According to individuals who have reviewed
the entire collection of 50,000 documents provided to the media by Snowden,
what is missing from the papers is any document which lays out in detail just
how successful the agency's code-breaking efforts have been. There are
numerous documents in the Snowden collection describing individual NSA
cryptologic programs, such as NSA's mostly unsuccessful multi-year effort to
crack the encryption protection used by the anonymizer service Tor. But no
reports describing the agency's cryptanalytic successes and failures have
been found in the Snowden collection to date.
Interviews with current and former intelligence officials conducted over the
past two months have revealed that since 9/11, NSA's computer scientists,
electronic engineers, software programmers, and collection specialists have
been remarkably inventive in finding new and innovative ways to circumvent
the protections supposedly offered by encryption systems by compromising them
through clandestine means. Among these clandestine means are CIA and FBI
"black bag jobs," as well as secret efforts by the U.S. intelligence
community to interdict the shipment of advanced encryption technology to
America's enemies around the world, inserting "back doors" into
commercially-available computer, communications and encryption technologies
which allow NSA to covertly access these systems without the users knowing
But the most sensitive of these clandestine techniques, and by far the most
productive to date, is to covertly hack into targeted computers and copy the
documents and message traffic stored on these machines before they are
encrypted, a process known within NSA as "Endpoint" operations.
Responsibility for conducting these Endpoint operations rests with the
computer hackers of NSA's cyberespionage unit, the Office of Tailored Access
Operations (TAO).
According to sources familiar with the organization's operations, TAO has
been enormously successful over the past 12 years in covertly inserting
highly sophisticated spyware into the hard drives of over 80,000 computer
systems around the world, although this number could be much higher. And
according to the sources, these implants are designed in such a way that they
cannot be detected by currently available commercial computer security
software. It has been suggested to me by a reliable source that "this is not
an accident," with the insinuation being that many of the biggest
commercially-available computer security software systems made in the United
States and overseas have been compromised by NSA, either covertly or with the
knowledge and consent of the companies that manufacture these systems.
Former agency personnel confirm that in innumerable instances these TAO
implants have allowed NSA's analysts to copy and read all of the unencrypted
documents stored on the targeted computer's hard drive, as well as copy every
document and email message produced and/or transmitted by the machine. But
more importantly, TAO has helped NSA's cryptanalysts solve several hundred
foreign government and commercial encryption systems because these spyware
implants, if properly inserted into the computer, can covertly alter its
security software as well as copy the encryption system's technical
parameters, especially the system's encryption algorithm and access
passwords, in a way that cannot be detected. These implants can compromise
the encryption systems used by not only the targeted computer, but also all
other computer systems that it communicates with using encryption technology.
According to confidential sources familiar with TAO's operations, many of
NSA's cryptanalytic "success stories" against high-priority targets such as
Russia and the People's Republic of China in recent years have been the
direct result of TAO's cyberespionage efforts. For example, sources confirm
that much of what the U.S. intelligence community knows about China's
computer hacking efforts against targets in the United States, Europe, and
Asia stems from TAO's intelligence collection efforts since 2005, when TAO
reportedly achieved a major technical breakthrough against a Chinese target.
But TAO doesn't just spy on America's rivals. In 2012, the group reportedly
compromised the encryption system used by an important G8 country to transmit
sensitive diplomatic communications via satellite to its embassies around the
world. The same is true with a number of countries in the Middle East and
South Asia, including Egypt, Syria, Iran, and Pakistan, although the details
of these successes are not yet known. And finally, sources report that TAO
has successfully compromised the privacy protection systems currently used on
a range of 4G cell phones and hand-held devices, thanks in large part to help
from a major American telecommunications company.
There are high-profile targets that have proven resistant to TAO's
cyberespionage efforts over the years, however. For example, TAO has
reportedly had virtually no success penetrating North Korean government
computer systems or networks because there are so few of them and they are
heavily protected from access to the outside world.
Over time, TAO has become increasingly accomplished at its mission, thanks in
part to the high-level cooperation that it secretly receives from the "big
three" American telecommunications companies (AT&T, Verizon, and Sprint),
most of the large U.S.-based internet service providers, and many of the top
computer security software manufacturers and consulting companies. According
to a February 2012 budget document (.pdf) published earlier this year by
ProPublica, these companies "Insert vulnerabilities into commercial
encryption systems, IT systems, networks, and endpoint communications devices
used by targets" on behalf of TAO.
TAO is also very active in the global computer security industry marketplace,
using the CIA, Defense Intelligence Agency, and State Department to help it
keep close tabs on the latest computer security devices and software systems
being developed around the world. And while details are lacking, informed
sources report that TAO has been active in covertly buying up commercially
available "hacker tools" or spyware software systems from individuals and
companies in the United States and overseas, particularly in Western Europe,
to help facilitate its ever-growing computer network exploitation efforts.
The extreme sensitivity of TAO's collection efforts has required the NSA to
take extraordinary steps to try to disguise its computer hacking activities.
For instance, current and former intelligence sources confirm that TAO
increasingly depends on clandestine techniques, such as commercial cover, to
hide its activities. TAO uses an array of commercial business entities, some
of them proprietary companies established specifically for this purpose, to
try to hide its global computer hacking activities from computer security
experts in a maze of interlocking computer servers and command-and-control
systems located in the United States and overseas that have no discernible
link to NSA or the U.S. government.
These sources also say that TAO gets a lot of help from politically-motivated
hackers, or "hacktivists," who unintentionally help NSA by providing ideas to
improve TAO's collection efforts. (Exactly which hacktivists have been
particularly helpful, these sources wouldn't say.) Working closely with NSA's
computer security experts at the NSA/CSS Threat Operations Center, TAO
personnel perform detailed forensic post-mortem studies of every major
successful computer penetration operation around the world. Some of these are
pulled off by criminal outfits, some by government-backed groups, others by
political actors. In each case, the agency's personnel looks for new
techniques or procedures that they can use to get inside computer systems
around the world.
There is no question that TAO's future looked incredibly bright before the
first newspaper articles began appearing in the British and American press in
June 2013 based on documents leaked by Snowden. Now, industry sources
familiar with TAO say that the organization's future prospects have dimmed
A number of foreign-based computer systems and IT networks that formerly were
major producers of intelligence information for TAO have over the past three
months changed security procedures and encryption systems, routed traffic to
more secure computer nodes or servers, erected new firewalls, or have gone
offline altogether. According to recent press reports, the Russian government
for a time reverted back to using manual typewriters rather than commit
sensitive information to their computer systems. And a number of European
countries and Brazil have begun shifting their most sensitive data and
communications traffic to secure networks that they hope will be resistant to
NSA's intrusive surveillance activities.
But this is, I am sure, just the tip of the iceberg. I have no doubt that the
damage to TAO's foreign intelligence collection capabilities and its ability
to facilitate the solution of foreign encryption systems by NSA's
cryptanalysts has been substantial. The big question that will determine
TAO's future prospects is whether the damage done so far proves to be

@_date: 2013-10-17 08:29:08
@_author: Eugen Leitl 
@_subject: Curious use of cpunks list [Brian Carroll] 
If we had good PRNGs everywhere, with lots of trustable physical entropy
stirred in then nobody would care about talking about these.
It would be boring, since a solved problem.
Now show me a cryptographic quality PRNG with a few MBytes of
internal state. Best, a whole robust family of them. See? That's
some quality trolling, right there.

@_date: 2013-10-17 09:49:09
@_author: Eugen Leitl 
@_subject: [tor-talk] Roger's status report, September/October 2013 
Reply-To: tor-talk at lists.torproject.org
Six things I did in September/October 2013:
1) Released Tor 0.2.4.17-rc:
including writing the fix to prioritize NTor handshakes so Tor 0.2.4.x
remains usable despite the five million new bot users:
Released Tor 0.2.5.1-alpha:
2) Wrote many blog posts:
with a follow-up summary at
and also answered hundreds of blog comments / questions.
3) Talked to many many journalists to explain Tor and the Internet.
My most useful quotes went to Bruce Schneier:
and Brian Fung:
and Dan Goodin:
4) Helped the Tor Stack Exchange beta get off the ground:
I zipped up to 1000+ reputation from answering questions in the first
few days, but then I disappeared because I was distracted by other work.
Hopefully other people have filled in the gap.
5) Helped sort out the 2013 Q4 budget, and also get the new SponsorO
projects off the ground:
6) Attended the SponsorF "red team assessment" where they funded some
smart DPI developers to evaluate and try to break Obfsproxy and Flash
Proxy. So far so good -- one of the outcomes is that we should set up
a performance testbed for Flash Proxy to see if we can replicate their
"sometimes when I upload a bunch of stuff it takes a long time" behavior.
I plan to talk to Arlo, once I'm back online, about doing that.

@_date: 2013-10-17 10:29:45
@_author: Eugen Leitl 
@_subject: Cryptographer Adi Shamir Prevented from Attending NSA History 
cypherpunks
Cryptographer Adi Shamir Prevented from Attending NSA History Conference
Categories: Science, Secrecy
In this email message to colleagues, Israeli cryptographer Adi Shamir
recounts the difficulties he faced in getting a visa to attend the 2013
Cryptologic History Symposium sponsored by the National Security Agency. Adi
Shamir is the S in the RSA public-key algorithm and is one of the finest
cryptologists in the world today, according to historian David Kahn. The NSA
Symposium begins tomorrow. For the reasons described below, Dr. Shamir will
not be there.
The purpose of this email is to explain why I will not be able to attend the
forthcoming meeting of the History of Cryptology conference, even though I
submitted a paper which was formally accepted. As an active participant in
the exciting developments in academic cryptography in the last 35 years, I
thought that it would be a wonderful opportunity to meet all of you, but
unfortunately the US bureaucracy has made this impossible.
The story is too long to describe in detail, so I will only provide its main
highlights here. I planned to visit the US for several months, in order to
attend the Crypto 2013 conference, the History of Cryptology conference, and
to visit several universities and research institutes in between in order to
meet colleagues and give scientific lectures. To do all of these, I needed a
new J1 visa, and I filed the visa application at the beginning of June, two
and a half months before my planned departure to the Crypto conference in mid
August. I applied so early since it was really important for me to attend the
Crypto conference  I was one of the founders of this flagship annual
academic event (I actually gave the opening talk in the first session of the
first meeting of this conference in 1981) and I did my best to attend all its
meetings in the last 32 years.
To make a long story short, after applying some pressure and pulling a lot of
strings, I finally got the visa stamped in my passport on September 30-th,
exactly four months after filing my application, and way beyond the requested
start date of my visit. I was lucky in some sense, since on the next day the
US government went into shutdown, and I have no idea how this could have
affected my case. Needless to say, the long uncertainty had put all my travel
plans (flights, accomodations, lecture commitments, etc) into total disarray.
It turns out that I am not alone, and many foreign scientists are now facing
the same situation. Here is what the president of the Weizmann Institute of
Science (where I work in Israel) wrote in July 2013 to the US Ambassador in
Im allowing myself to write you again, on the same topic, and related to
the major difficulties the scientists of the Weizmann Institute of Science
are experiencing in order to get Visa to the US. In my humble opinion, we are
heading toward a disaster, and I have heard many people, among them our top
scientists, saying that they are not willing anymore to visit the US, and
collaborate with American scientists, because of the difficulties. It is
clear that scientists have been singled out, since I hear that other simple
citizen, do get their visa in a short time.
Even the president of the US National Academy of Science (of which I am a
member) tried to intervene, without results. He was very sympathetic, writing
to me at some stage:
Dear Professor Shamir
I have been hoping, day by day, that your visa had come through. It is very
disappointing to receive your latest report. We continue to try by seeking
extra attention from the U. S. Department of State, which has the sole
authority in these matters. As you know, the officers of the Department of
State in embassies around the world also have much authority. I am personally
very sympathetic and hopeful that your efforts and patience will still yield
results but also realize that this episode has been very trying. We hope to
hear of a last-minute success.
Yours sincerely, Ralph J. Cicerone
What does all of this have to do with the History of Cryptology conference?
In January 2013 I submitted a paper titled The Cryptology of John Nash From
a Modern Perspective to the conference, and a short time afterwards I was
told by the organizers that it was accepted. In July 2013 I told the
NSA-affiliated conference organizers that I was having some problems in
getting my visa, and gently asked whether they could do something about it.
Always eager to help, the NSA people leaped into action, and immediately sent
me a short email written with a lot of tact:
The trouble you are having is regrettableSorry you wont be able to come to
our conference. We have submitted our program and did not include you on it.
I must admit that in my 35 years of attending many conferences, it had never
happened to me that an accepted paper of mine was yanked out from the
official program in such a unilateral way. However, since I never try to go
to places where I do not feel wanted, I decided to inform MIT that a window
had become available in my busy schedule. They immediately invited me to
visit them on October 17 and 18, and to give a major lecture during my visit.
Naturally, I accepted their gracious invitation.
The final twist in this saga happened a few days ago, when out of the blue I
was suddenly reinvited by the conference organizers to attend the event and
to present my paper. However, this is too late now, since I am already fully
committed to my visit to MIT.
So what is the bottom line of this whole unhappy episode? Clearly, no one in
the US is trying to see the big picture, and the heavy handed visa
bureaucracy you have created seems to be collapsing under its own weight.
This is not a security issue  I have been to the US close to a hundred times
so far (including some multi-year visits), and had never overstayed my visas.
In addition, the number of terrorists among the members of the US National
Academy of Science is rather small. As a friend of the US I am deeply worried
that if you continue to delay visas in such a way, the only thing you will
achieve is to alienate many world-famous foreign scientists, forcing them to
increase their cooperation with European or Chinese scientists whose
countries roll the red carpet for such visits. Is this really in the US best
Best personal wishes, and apologies for not being able to meet you in person,
Adi Shamir

@_date: 2013-10-17 13:15:10
@_author: Eugen Leitl 
@_subject: Trekkie finally got fired -- it's a good start 
Keith Alexander, NSA Head, Stepping Down
Tyler Durden's pictureSubmitted by Tyler Durden on 10/16/2013 18:10 -0400
After eight years at the helm of "America's secret cyber army", NSA head
Keith Alexander, has decided to spend more time with his family and less time
with yours, and is stepping down. According to US officials, the director of
the NSA and his deputy are expected to depart in coming months, in a move
that almost certainly would not have happened without the involvement of
America's most infamous whitsleblower currently self-exiled in Russia, Edward
Snowden in a development which according to Reuters, "could give Obama a
chance to reshape the eavesdropping agency."
It is unclear what he would "reshape" it into: at last check the Stasi
headquarters in Berlin did not have quite the capacity to house the Cray
supercomputers needed to make sure that anyone and everyone caught selling
stocks gets a lifetime audit guarantee from the IRS.
We are confident, however, that with the surge in government-employed
architects coming back to "work" from their 17 days paid vacation, someone
will have an idea or two.
Army General Keith Alexander's eight-year tenure was rocked this year by
revelations contained in documents leaked by former NSA contractor Edward
Snowden about the agency's widespread scooping up of telephone, e-mail and
social media data.
Alexander has formalized plans to leave by next March or April, while his
civilian deputy, John "Chris" Inglis, is due to retire by year's end,
according to U.S. officials who spoke on condition of anonymity.
It also wasn't clear who would replace the man who once upon a time made his
office into a replica of the bridge of the Starship Enterprise, although
there certainly are candidates.
One leading candidate to replace Alexander is Vice Admiral Michael Rogers,
currently commander of the U.S. Navy's 10th Fleet and U.S. Fleet Cyber
Command, officials told Reuters. The 10th Fleet and Fleet Cyber Command both
have their headquarters at Fort Meade, Maryland, between Washington and
Baltimore. The NSA is also headquartered at Fort Meade.
There has been no final decision on selecting Rogers to succeed Alexander,
and other candidates may be considered, the officials said.  More
importantly, the question is whether with America's domestic epsionage and
email address book collection efforts exposed for the entire world to see,
courtesy of Edward Snowden, will Obama decide to engage in a strategic shift
in policy, or merely double down and install RFID chips into every newborn
While both men are leaving voluntarily, the dual vacancies give Obama an
opportunity both to install new leadership following Snowden's revelations
and to decide whether the NSA and Cyber Command should have separate leaders.
Cyber Command, which has grown significantly in recent years, has the
authority to engage in both defensive and offensive operations in cyberspace.
Many NSA veterans argue that having the same person lead the spy agency and
Cyber Command diminishes the emphasis on the NSA's work and its unique
Rogers has been the Navy's top cyber commander since September 2011. Prior to
that, he was director of intelligence for the U.S. Joint Chiefs of Staff and
for the U.S. Pacific Command.
Rogers is "a good leader, very insightful and well thought of within the
community," said a U.S. defense official who was not authorized to speak
publicly on the matter.
Rogers has worked hard to ensure that the Navy has sufficient sailors trained
to take on added cyber responsibilities for U.S. Cyber Command, the official
Sorry, we forgot to add "rhetorical" before question.

@_date: 2013-10-17 15:40:29
@_author: Eugen Leitl 
@_subject: NSA's key role in targeted killings 
Documents reveal NSAs extensive involvement in targeted killing program
Video: In June, President Obama said the NSAs programs help us prevent
terrorist attacks.
By Greg Miller, Julie Tate and Barton Gellman, Thursday, October 17, 2:07 AM
E-mail the writers
It was an innocuous e-mail, one of millions sent every day by spouses with
updates on the situation at home. But this one was of particular interest to
the National Security Agency and contained clues that put the senders
husband in the crosshairs of a CIA drone.
Days later, Hassan Ghul  an associate of Osama bin Laden who provided a
critical piece of intelligence that helped the CIA find the al-Qaeda leader 
was killed by a drone strike in Pakistans tribal belt.
The U.S. government has never publicly acknowledged killing Ghul. But
documents provided to The Washington Post by former NSA contractor Edward
Snowden confirm his demise in October 2012 and reveal the agencys extensive
involvement in the targeted killing program that has served as a centerpiece
of President Obamas counterterrorism strategy.
An al-Qaeda operative who had a knack for surfacing at dramatic moments in
the post-Sept. 11 story line, Ghul was an emissary to Iraq for the terrorist
group at the height of that war. He was captured in 2004 and helped expose
bin Ladens courier network before spending two years at a secret CIA prison.
Then, in 2006, the United States delivered him to his native Pakistan, where
he was released and returned to the al-Qaeda fold.
But beyond filling in gaps about Ghul, the documents provide the most
detailed account of the intricate collaboration between the CIA and the NSA
in the drone campaign.
The Post is withholding many details about those missions, at the request of
U.S. intelligence officials who cited potential damage to ongoing operations
and national security.
The NSA is focused on discovering and developing intelligence about valid
foreign intelligence targets, an NSA spokeswoman said in a statement
provided to The Post on Wednesday, adding that the agencys operations
protect the nation and its interests from threats such as terrorism and the
proliferation of weapons of mass destruction.
In the search for targets, the NSA has draped a surveillance blanket over
dozens of square miles of northwest Pakistan. In Ghuls case, the agency
deployed an arsenal of cyber-espionage tools, secretly seizing control of
laptops, siphoning audio files and other messages, and tracking radio
transmissions to determine where Ghul might bed down.
The e-mail from Ghuls wife about her current living conditions contained
enough detail to confirm the coordinates of that household, according to a
document summarizing the mission. This information enabled a capture/kill
operation against an individual believed to be Hassan Ghul on October 1, it
The file is part of a collection of records in the Snowden trove that make
clear that the drone campaign  often depicted as the CIAs exclusive domain
 relies heavily on the NSAs ability to vacuum up enormous quantities of
e-mail, phone calls and other fragments of signals intelligence, or SIGINT.
To handle the expanding workload, the NSA created a secret unit known as the
Counter-Terrorism Mission Aligned Cell, or CT MAC, to concentrate the
agencys vast resources on hard-to-find terrorism targets. The unit spent a
year tracking Ghul and his courier network, tunneling into an array of
systems and devices, before he was killed. Without those penetrations, the
document concluded, this opportunity would not have been possible.
At a time when the NSA is facing intense criticism for gathering data on
Americans, the drone files may bolster the agencys case that its resources
are focused on fighting terrorism and supporting U.S. operations overseas.
Ours is a noble cause, NSA Director Keith B. Alexander said during a public
event last month. Our job is to defend this nation and to protect our civil
liberties and privacy.
The documents do not explain how the Ghul e-mail was obtained or whether it
was intercepted using legal authorities that have emerged as a source of
controversy in recent months and enable the NSA to compel technology giants
including Microsoft and Google to turn over information about their users.
Nor is there a reference to another NSA program facing scrutiny after
Snowdens leaks, its metadata collection of numbers dialed by nearly every
person in the United States.
To the contrary, the records indicate that the agency depends heavily on
highly targeted network penetrations to gather information that wouldnt
otherwise be trapped in surveillance nets that it has set at key Internet
The new documents are self-congratulatory in tone, drafted to tout the NSAs
counterterrorism capabilities. One is titled CT MAC Hassan Gul Success. The
files make no mention of other agencies roles in a drone program that
escalated dramatically in 2009 and 2010 before tapering off in recent years.
Even so, former CIA officials said the files are an accurate reflection of
the NSAs contribution to finding targets in a campaign that has killed more
than 3,000 people, including thousands of alleged militants and hundreds of
civilians, in Pakistan, according to independent surveys. The officials said
the agency has assigned senior analysts to the CIAs Counterterrorism Center,
and deployed others to work alongside CIA counterparts at almost every major
U.S. embassy or military base overseas.
NSA threw the kitchen sink at the FATA, said a former U.S. intelligence
official with experience in Afghanistan and Pakistan, referring to the
Federally Administered Tribal Areas, the region in northwest Pakistan where
al-Qaedas leadership is based.
NSA employees rarely ventured beyond the security gates of the U.S. Embassy
in Islamabad, officials said. Surveillance operations that required placing a
device or sensor near an al-Qaeda compound were handled by the CIAs
Information Operations Center, which specializes in high-tech devices and
close-in surveillance work.
But if you wanted huge coverage of the FATA, NSA had 10 times the manpower,
20 times the budget and 100 times the brainpower, the former intelligence
official said, comparing the surveillance resources of the NSA to the smaller
capabilities of the agency's IOC. The two agencies are the largest in the
U.S. intelligence community, with budgets last year of $14.7 billion for the
CIA and $10.8 billion for the NSA. We provided the map, the former official
said, and they just filled in the pieces.
In broad terms, the NSA relies on increasingly sophisticated versions of
online attacks that are well-known among security experts. Many rely on
software implants developed by the agencys Tailored Access Operations
division with code-names such as UNITEDRAKE and VALIDATOR. In other cases,
the agency runs man-in-the-middle attacks in which it positions itself
unnoticed midstream between computers communicating with one another,
diverting files for real-time alerts and longer-term analysis in data
Through these and other tactics, the NSA is able to extract vast quantities
of digital information, including audio files, imagery and keystroke logs.
The operations amount to silent raids on suspected safe houses and often are
carried out by experts sitting behind desks thousands of miles from their
The reach of the NSAs Tailored Access Operations division extends far beyond
Pakistan. Other documents describe efforts to tunnel into systems used by
al-Qaeda affiliates in Yemen and Africa, each breach exposing other
An operation against a suspected facilitator for al-Qaedas branch in Yemen
led to a trove of files that could be used to help NSA map out the movement
of terrorists and aspiring extremists between Yemen, Syria, Turkey, Egypt,
Libya and Iran, according to the documents. This may enable NSA to better
flag the movement of these individuals to allied security services that can
put individuals on no-fly lists or monitor them once in country.
A single penetration yielded 90 encrypted al-Qaeda documents, 16 encryption
keys, 30 unencrypted messages as well as thousands of chat logs, according
to an inventory described in one of the Snowden documents.
The operations are so easy, in some cases, that the NSA is able to start
downloading data in less time than it takes the targeted machine to boot up.
Last year, a user account on a social media Web site provided an instant
portal to an al-Qaeda operatives hard drive. Within minutes, we
successfully exploited the target, the document said.
The hunt for Ghul followed a more elaborate path.
Ghul, who is listed in other documents as Mustafa Haji Muhammad Khan, had
surfaced on U.S. radar as early as 2003, when an al-Qaeda detainee disclosed
that Ghul escorted one of the intended hijackers to a Pakistani safe house a
year before the Sept. 11, 2001, attacks.
A trusted facilitator and courier, Ghul was dispatched to Iraq in 2003 to
deliver a message to Abu Musab al-Zarqawi, the al-Qaeda firebrand who angered
the networks leaders in Pakistan by launching attacks that often slaughtered
innocent Muslims.
When Ghul made another attempt to enter Iraq in 2004, he was detained by
Kurdish authorities in an operation directed by the CIA. Almost immediately,
Ghul provided a piece of intelligence that would prove more consequential
than he may have anticipated: He disclosed that bin Laden relied on a trusted
courier known as al-Kuwaiti.
The ripples from that revelation wouldnt subside for years. The CIA went on
to determine the true identity of al-Kuwaiti and followed him to a heavily
fortified compound in Abbottabad, Pakistan, where bin Laden was killed in
Because of the courier tip, Ghul became an unwitting figure in the
contentious debate over CIA interrogation measures. He was held at a CIA
black site in Eastern Europe, according to declassified Justice Department
memos, where he was slapped and subjected to stress positions and sleep
deprivation to break his will.
Defenders of the interrogation program have cited Ghuls courier disclosure
as evidence that the agencys interrogation program was crucial to getting
bin Laden. But others, including former CIA operatives directly involved in
Ghuls case, said that he identified the courier while he was being
interrogated by Kurdish authorities, who posed questions scripted by CIA
analysts in the background.
The debate resurfaced amid the release of the movie Zero Dark Thirty last
year, in which a detainees slip after a brutal interrogation sequence is
depicted as a breakthrough in the bin Laden hunt. Ghuls case also has been
explored in detail in a 6,000-page investigation of the CIA interrogation
program by the Senate Intelligence Committee that has yet to be released.
Sen. Dianne Feinstein (D-Calif.), the chairman of the panel, sought to settle
the Ghul debate in a statement last year that alluded to his role but didnt
mention him by name.
The CIA detainee who provided the most significant information about the
courier provided the information prior to being subjected to coercive
interrogation techniques, Feinstein said in the statement, which was signed
by Sen. Carl Levin (D-Mich.).
The George W. Bush administrations decision to close the secret CIA prisons
in 2006 set off a scramble to place prisoners whom the agency did not regard
as dangerous or valuable enough to transfer to Guantanamo Bay. Ghul was not
among the original 14 high-value CIA detainees sent to the U.S. installation
in Cuba. Instead, he was turned over to the CIAs counterpart in Pakistan,
with ostensible assurances that he would remain in custody.
A year later, Ghul was released. There was no public explanation from
Pakistani authorities. CIA officials have noted that Ghul had ties to
Lashkar-e-Taiba, a militant group supported by Pakistans intelligence
service. By 2007, he had returned to al-Qaedas stronghold in Waziristan.
In 2011, the Treasury Department named Ghul a target of U.S. counterterrorism
sanctions. Since his release, the department said, he had helped al-Qaeda
reestablish logistics networks, enabling al-Qaeda to move people and money in
and out of the country. The NSA document described Ghul as al-Qaedas chief
of military operations and detailed a broad surveillance effort to find him.
The most critical piece came with a discovery that provided a vector for
compounds used by Ghul, the document said. After months of investigation, and
surveillance by CIA drones, the e-mail from his wife erased any remaining
Even after Ghul was killed in Mir Ali, the NSAs role in the drone strike
wasnt done. Although the attack was aimed at an individual believed to be
the correct target, the outcome wasnt certain until later when, through
SIGINT, it was confirmed that Hassan Ghul was in fact killed.

@_date: 2013-10-17 22:45:05
@_author: Eugen Leitl 
@_subject: Curious RNG stalemate [was: use of cpunks] 
There's an ARM system in there: but in principle you can resurrect something like that, or
wait until the company sees fit to sell that product again.
You don't need radiation. 12 USD USB SDR can sample 1.5 Msamples/s
at 8 bit, and is as simple as it gets, and is amplifies effectively quantum
noise. I'm not sure how complex is, but you can certainly decap a representative sample from
each lot to validate it.
Seems like a decent business idea.

@_date: 2013-10-18 09:54:46
@_author: Eugen Leitl 
@_subject: Curious RNG stalemate [was: use of cpunks] 
Are they?
This is analog electronics 101. All you have is to sample
that at sufficient rate on the cheap. That used to be a problem, but
no longer is
We do not want a dinky little entropy drip. We want a
regular firehose. The USB RTL samples at 1.4 MSamples/s. Total part costs is probably 20 USD, in bulk.
Why is nobody selling a kit like that? Because worrying about
sufficient entropy in crypto settings is a terribly niche thing.
Now try for a decent clock. (Hint: time-nuts. And did you
know they use CSACs for IED trigger jamming?).

@_date: 2013-10-18 10:37:13
@_author: Eugen Leitl 
@_subject: Curious RNG stalemate [was: use of cpunks] 
I have a couple older VIA C3 with hardware RNG, bought long ago for just that purpose. What kind of motherboard is in there, do you know?
It is unauditable, just as any integrated RNG sources. Which
is not that big of problem, if you mix in enough external entropy
from a trusted source. The trusted source need to be sufficiently
simple to be validated by inspection. You can source RTL-SDRs
from many sources. All you need is to match impedance and output
power from your analog white noise circuit to goldilocks level.
In case anyone is interested,
But there is still no simple kit you could directly plug into your
coax socket. That is a threshold of entry too high for people
who can't tell which part of the soldering iron is the hot one.

@_date: 2013-10-18 11:02:42
@_author: Eugen Leitl 
@_subject: HTML List Abuse (was: "please ignore: this is only a test") 
Many people concerned with security use text-only MUAs,
as that works well over low-bandwidth mobile links and
gives less attack surface against compromises.
The less complexity, the less lines of codes and code
complexity and easier to debug. E.g. by not discarding
HTML-only (but giving preference to plain text in
multipart messages) I'm running risk for having this system
compromised, even if I render via a text browser
like links. That's ok, I consider this system sacrificial.
Rendering rich content in a GUI is courting disaster.
You will get nailed, and be it just malware from spam.
You can assume that people who care know this, so
text-only correlates with old hands and/or high clue.

@_date: 2013-10-18 16:55:46
@_author: Eugen Leitl 
@_subject: Police warning after drug traffickers' cyber-attack 
Eat your heart out, William Gibson.
Police warning after drug traffickers' cyber-attack
By Tom Bateman
Reporter, Today programme
Drug traffickers hacked into the computer controlling shipping containers at
the port of Antwerp
Earlier this year drug traffickers hacked into the computer controlling
shipping containers at the port of Antwerp
The head of Europe's crime fighting agency has warned of the growing risk of
organised crime groups using cyber-attacks to allow them to traffic drugs.
The director of Europol, Rob Wainwright, says the internet is being used to
facilitate the international drug trafficking business.
His comments follow a cyber-attack on the Belgian port of Antwerp.
Drug traffickers recruited hackers to breach IT systems that controlled the
movement and location of containers.
Police carried out a series of raids in Belgium and Holland earlier this
year, seizing computer-hacking equipment as well as large quantities of
cocaine and heroin, guns and a suitcase full of cash.
Fifteen people are currently awaiting trial in the two countries.
Mr Wainwright says the alleged plot demonstrates how the internet is being
used as a "freelance marketplace" in which drug trafficking groups recruit
hackers to help them carry out cyber-attacks "to order".
"[The case] is an example of how organised crime is becoming more
enterprising, especially online," he says.
A Europol official tells Tom Bateman how traffickers hacked into the IT
system at Antwerp port "We have effectively a service-orientated industry
where organised crime groups are paying for specialist hacking skills that
they can acquire online," he adds.
Vanishing containers
The attack on the port of Antwerp is thought to have taken place over a
two-year period from June 2011.
Prosecutors say a Dutch-based trafficking group hid cocaine and heroin among
legitimate cargoes, including timber and bananas shipped in containers from
South America.
The organised crime group allegedly used hackers based in Belgium to
infiltrate computer networks in at least two companies operating in the port
of Antwerp.
The breach allowed hackers to access secure data giving them the location and
security details of containers, meaning the traffickers could send in lorry
drivers to steal the cargo before the legitimate owner arrived.
Workers were first alerted to the plot when entire containers began to
disappear from the port without explanation.
"These criminal organisations always look for a new way to get drugs out of
the harbour," says Danny Decraene who heads the Antwerp organised crime unit
of the Belgian Federal Police.
Bag of cash seized by Belgian police
This suitcase, containing 1.3m euros, was seized by Belgian police during
raids on drug traffickers
"In this case they hired hackers [who were] very high level, intelligent
guys, doing a lot of software work," he adds.
He says the operation to hack the port companies took place in a number of
phases, starting with malicious software being emailed to staff, allowing the
organised crime group to access data remotely.
When the initial breach was discovered and a firewall installed to prevent
further attacks, hackers broke into the premises and fitted key-logging
devices onto computers.
This allowed them to gain wireless access to keystrokes typed by staff as
well as screen grabs from their monitors.
Assault rifle attack
Mr Decraene says the total quantity of drugs trafficked by the group is
unknown, but in a series of raids earlier this year police seized more than a
tonne of cocaine, with a street value of 130m, and a similar amount of
In January a lorry driver unconnected to the plot was shot at after he had
unwittingly driven a container allegedly filled with cocaine from the
terminal at Antwerp.
The attack took place in the province of Limburg, where suspects armed with
AK-47 assault rifles fired at the driver, who was unharmed.
Following the cyber-attack in Antwerp, a joint operation by Belgian and Dutch
police resulted in raids on more than 20 homes and businesses.
Officers seized six firearms including a machine gun and silencer,
bullet-proof vests, and 1.3m euros (1.1m) in cash inside a suitcase.
Mr Wainwright says the IT attack is consistent with a "new business model" of
organised crime activity and he says he expects this kind of cyber-security
breach to "become a more significant feature in future" of drug trafficking.
"What it means therefore is that the police need to change the way they
operate - they have to become much more tech savvy," he says.
"But also I think governments and parliaments need to help us to make sure
therefore that we have the right laws to fight back against this massive
exploitation of the internet," he adds.
Container companies operating out of the port of Antwerp say their IT
security has now been improved.

@_date: 2013-10-19 16:02:44
@_author: Eugen Leitl 
@_subject: HTML List Abuse (was: "please ignore: this is only a test") 
Moon Jones sees no added value as he subscribes to the very same
lists as me. (There is added value for less omniscient/omnipresent, though in order to see it you have to see it from my point of view, and it's not super-big -- I'm mostly a Layer 8 router).
I presume filtering for duplicates is easier if I do bounces,
so I'll do more of that in future.  The relevance is in the followup threads others generate.
I don't do helpdesks, sorry.

@_date: 2013-10-19 16:22:01
@_author: Eugen Leitl 
@_subject: HTML List Abuse (was: "please ignore: this is only a test") 
I'm highly sympathetic to your plight, and suggest the
following solution: install a procmail recipe to filter
out dupes with the same message ID (e.g. <5261AAC3.6050102 at mbox301.swipnet.se> in case of the mail I'm replying to) and/or matching Resent-Message-ID: with leitl.org behind it.

@_date: 2013-10-19 18:18:01
@_author: Eugen Leitl 
@_subject: Cheney afraid of terrist h4x0rs 
Cheney had heart device partially disabled to prevent a terrorist from
sending a fatal shock
Olivia Harris, Pool, File/Associated Press -  In an interview with CBS 60
Minutes, former Vice President Dick Cheney says he once feared that
terrorists could use the electrical device that had been implanted near his
heart to kill him and had his doctor disable its wireless function.
By Associated Press, Saturday, October 19, 1:34 AM
WASHINGTON  Former Vice President Dick Cheney says he once feared that
terrorists could use the electrical device that had been implanted near his
heart to kill him and had his doctor disable its wireless function.
Cheney has a history of heart trouble, suffering the first of five heart
attacks at age 37. He underwent a heart transplant last year at age 71.
In an interview with CBS 60 Minutes, Cheney says doctors replaced an
implanted defibrillator near his heart in 2007. The device can detect
irregular heartbeats and control them with electrical jolts.
Cheney says that he and his doctor, cardiologist Jonathan Reiner, turned off
the devices wireless function in case a terrorist tried to send his heart a
fatal shock.
Years later, Cheney watched an episode of the Showtime series Homeland in
which such a scenario was part of the plot.
I found it credible, Cheney tells 60 Minutes in a segment to be aired
Sunday. I know from the experience we had, and the necessity for adjusting
my own device, that it was an accurate portrayal of what was possible.
Cheney and Reiner are promoting a book they co-authored, Heart: An American
Medical Odyssey.
In the 60 Minutes interview, Reiner says he worried that Cheney couldnt
stand the pressure that came on Sept. 11, 2001, the day terrorists attacked
the U.S. Medical tests seen that morning showed Cheney had elevated levels of
potassium in his blood, a condition called hyperkalemia, which could lead to
abnormal heart rhythms and cardiac arrest.
Reiner says he watched news coverage of the days events on television and
thought, Oh, great, the vice president is going to die tonight from

@_date: 2013-10-21 14:10:49
@_author: Eugen Leitl 
@_subject: The Most Lethal Weapon Americans Faced in Iraq 
(did you see the LEDs blink?)
October 18, 2013, 10:35 am Comment
The Most Lethal Weapon Americans Faced in Iraq
By JOHN ISMAY
In the first part of this series, At War explored the various conventional
weapons used by insurgents in Iraq, as evidenced by reports, called
storyboards, written by United States forces detailing the contents of
captured weapons caches. Often times these weapons had been considered
obsolete before 2003. But they were well known to Western intelligence
services and militaries.
Today, we look at weapons that the American military could not have
reasonably foreseen entering the fray, but that caused large numbers of
casualties. These are the improvised weapons that were made by hand, or in
small shops, and that, with one exception, were not made in industrial
Improvised Explosive Devices
At the time these storyboards were written, improvised explosive devices, or
I.E.D.s, caused approximately 80 percent of all coalition casualties.
 Page 1 of  27 
A network of insurgents financed, designed and manufactured these weapons.
Skilled bomb makers worked in clandestine shops, and leaders of I.E.D.
networks sent bomb emplacers to bury or hide their improvised bombs along
routes American patrols were expected to take.
Standard bomb-making equipment showed up again and again in the caches,
including: multimeters for checking the electrical continuity in circuits;
personal mobile radios for transmitting firing signals; switches to close
circuits; electric blasting caps; detonating cord for when multiple charges
were used.
Earlier firing systems often employed a variety of radio-controlled features.
Keyless entry fobs for automobiles, garage door openers, toy car controllers
 these all provided parts for initiating bombs, at least until coalition
electronic countermeasures made them almost completely ineffective. Other
common articles took their place.
Insurgents stripped timers from washing machines, or bought them by the
hundreds from commercial sources. Motion sensors meant to open grocery store
doors or to turn on security floodlights also found their way into bomb-maker
supply bins. These devices could trip a switch and initiate an explosion when
a soldier crossed their path.
The first bomb emplacers, many of them uneducated youth, sometimes blew
themselves up while connecting the basic components of their weapons: power
source, switch and explosive charge. They were supposed to connect these
parts with an open circuit, since connecting a closed circuit would send
current to an electric blasting cap. If that happened, it usually meant
instant death for the emplacer. To make bomb emplacement less
catastrophically failure-prone, bomb makers searched for devices that could
mechanically break the electric circuit. The washing machine timer was one
that worked. All the emplacer had to do was wind it up before connecting the
circuit and he would have a set amount of time to escape before the bomb was
armed. The use of these timers showed an adaptive enemy who learned from his
Explosively Formed Penetrators and Iranian C4
The single most lethal weapon American forces faced in Iraq was the
explosively formed penetrator, or E.F.P. Unlike other I.E.D. charges, E.F.P.
warheads required some skilled milling as well as heavy presses to produce.
Certain copper alloys were used as well, and analysis of their construction
was used to pinpoint the manufacturers.
What makes E.F.P.s so deadly is that they form slugs at detonation that
maintain their shape over distances of over 100 yards or more, traveling at
speeds of nearly a mile per second. This allowed insurgent forces to hide
these weapons far from the road, better camouflaging them and making them far
more deadly. In some I.E.D. factories, American forces found E.F.P.s
camouflaged to look like trash or rocks.
Much has been made of E.F.P.s generally being new Iranian weapons, but
that conflates two unrelated facts. First, E.F.P.s technology was invented
in the late 1930s by the oil industry to punch holes through the metal pipe
in wells and into the rock outside. These are called oil well perforators or
perforator guns. Any country engaged in oil field development has access to
E.F.P.s. Iran lists their domestically produced perforators for sale online.
Second, militaries applied this technology to anti-armor weapons as early as
World War II. (The United States military currently employs several weapons
incorporating E.F.P. warheads, to include the M2 SLAM, the TOW-2B, and the
M303 SOF Demolition Kit.)
But they became known as Iranian weapons because American intelligence
agencies reported that Iran passed E.F.P. technology to the Lebanese militia
Hezbollah, which in turn passed E.F.P. kits to proxy groups fighting in Iraq.
In the case of the Iraqi insurgent weapons, E.F.P.s arrived in kit form, and
were hand-packed with plastic explosives by bomb makers in Iraq just before
use. For their explosive charges, insurgents often turned to an Iranian copy
of an American staple: C4, packaged nearly identically to the original
1.25-lb M112 blocks. (Of note, the American M112 blocks changed their
markings slightly in 1996 once chemical tracers, called taggants, were added
in accordance with federal law; Iranian M112 block markings mimic the
pre-1996 markings.) According to an official with the Bureau of Alcohol,
Tobacco, Firearms and Explosives, manufacturing C4 is not difficult for any
nation capable of making industrial chemicals.
Homemade Explosives
Not long after the invasion, insurgents began mixing their own batches of
explosives and using them against their American adversaries. At first, these
mixtures were referred to simply as U.B.E.  unknown bulk explosive. Later,
the term HME, for homemade explosive, came into wide use.
As an agrarian society, Iraq had a nonstop demand for nitrated fertilizers 
urea and ammonium nitrate being the most common. Ground urea, mixed with
nitric acid, drained and dried, is a powerful explosive. Some caches held
bags of hexamethylenetetranitramine, which when mixed with nitric acids
produces a powerful explosive known as RDX. Still others combined ammonium
nitrate and diesel fuel oil to create the same explosive Timothy McVeigh used
to level the Alfred P. Murrah Federal Building in Oklahoma City in 1995.
Fertilizer plants, such as this one at Baiji, produced 500,000 tons of
fertilizer per year.
When homemade explosives first came into wide use in Iraq, American military
officers initially thought it was a sign that the insurgents were running out
of conventional or military-grade, munitions. That assumption had no basis
in fact. What it did signal was that the enemy had realized that bulk
explosives were more valuable and, in certain situations, more lethal.
Experience showed that a large enough charge could destroy any armor, or at
least wreak enough damage to cause casualties inside the targeted vehicle. In
Afghanistan, homemade explosives became such a problem for NATO forces that
President Hamid Karzais government banned ammonium nitrate in 2010.
End State
Although the last United States Army mission to destroy excess ordnance ended
in November 2011, violence in Iraq has continued well past the withdrawal of
the last American combat forces. According to the United Nations, nearly
1,000 Iraqi civilians were killed in September alone, amid levels of violence
last seen in 2008.
Between 2003 and 2010, the State Department spent more than $200 million on
destroying unexploded munitions in the country. Groups like Mines Advisory
Group continue their work in Iraq as well.
In July 2012, the State Departments own Web site gives an idea of the
challenges that lie ahead: In spite of progress, at least 719 square miles of
land is still contaminated by as many as 20 million land mines and millions
of pieces of unexploded ordnance. More than 1,600 municipalities are
affected, as are huge swathes of farmland, meaning clearing those explosives
will be an economic necessity. And as American forces discovered early in the
insurgency  and which Iraqis know all too well  every weapon and every
explosive that is not disposed of will eventually be put to destructive use
by some faction.
John Ismay is a former U.S. Navy Explosive Ordnance Disposal officer who
served in Iraq in 2007, and is now a member of Columbia Journalism Schools
class of 2014. Follow him on Twitter ( and on his blog

@_date: 2013-10-21 14:18:22
@_author: Eugen Leitl 
@_subject: The Secret History of =?utf-8?Q?Iraq?= =?utf-8?B?4oCZcw==?= 
(notice the date)
The Secret History of Iraqs Invisible War
BY NOAH SHACHTMAN 06.14.114:00 AM
In the early years of the Iraq war, the U.S. military developed a technology
so secret that soldiers would refuse to acknowledge its existence, and
reporters mentioning the gear were promptly escorted out of the country. That
equipment  a radio-frequency jammer  was upgraded several times, and
eventually robbed the Iraq insurgency of its most potent weapon, the
remote-controlled bomb. But the dark veil surrounding the jammers remained
largely intact, even after the Pentagon bought more than 50,000 units at a
cost of over $17 billion.
Recently, however, I received an unusual offer from ITT, the defense
contractor which made the vast majority of those 50,000 jammers. Company
executives were ready to discuss the jammer  its evolution, and its
capabilities. They were finally able to retell the largely-hidden battles for
the electromagnetic spectrum that raged, invisibly, as the insurgencies
carried on. They were prepared to bring me into the R&D facility where
company technicians were developing what could amount to the ultimate weapon
of this electromagnetic war: a tool that offers the promise of not only
jamming bombs, but finding them, interrupting GPS signals, eavesdropping on
enemy communications, and disrupting drones, too. The first of the these
machines begins field-testing next month.
On a fist-clenchingly cold winter morning, I took a train across the Hudson
River to the secret jammer lab.
Tucked behind a Target and an Olive Garden knock-off, the flat, anonymous
office building gives no hint of whats inside. Nor do the blank,
fluorescent-lit halls. But open a door off of one of those halls, and people
start screaming.
Screens off! barks a man with a fullbacks build. Turn off the test
equipment! On the ceiling, a yellow alarm light flashes and spins  the sign
that someone without a security clearance is in a classified facility.
Afghan militants began attacking U.S. troops with improvised explosive
devices in the first days after the October 2001 invasion. By early 02,
al-Qaida bomb-makers were cramming radio frequency receivers and simple
digital signal decoders into the bases of Japan InstaLite fluorescent lamps.
Then theyd connect the two-and-a-half inch wide lamp bases to firing
circuits, and to Soviet-era munitions. The result was a crude,
radio-controlled weapon dubbed the Spider by the Americans. With it, an
attacker could wait for his prey, set off the bomb at just the right moment 
and never have to worry about getting caught. When the explosion happened,
hed be hundreds of yards away.
Worse, U.S. forces had no way of blocking the Spiders triggering signal.
Military bomb squads carried around a few half-assed jammers. But they
couldnt be mounted on vehicles, and they were too weak to provide
protection beyond a few yards, Rick Atkinson notes in his exquisite history,
Left of Boom: The Struggle to Defeat Roadside Bombs.
If somebody sits a kilometer away with a radio and targets our guys, weve
got no ability to get him. Navy engineers hustled to build something a
little stronger, and a little more portable. By November of 2002, they had a
jammer called Acorn that was hard-wired to stop Spiders. It wasnt much. As a
so-called active jammer, the Acorn put out a relatively-indiscriminate
barrage signal that ate up power and generated all kinds of interference.
That kept its effective radiated power  the amount of signal hitting any one
bomb receiver  low. The signal was so weak, the jammer had to be left on and
screaming constantly. Otherwise, troops would be inside the bombs danger
radius before they ever had a chance to block it. Worse, it could only block
the specific receivers used in Spiders. If the bombers switched frequencies,
the countermeasure would be useless.
Meanwhile, the Army looked for ways to modify its Shortstop Electronic
Protection System, designed to shield troops from artillery and mortar fire.
This was a so-called reactive countermeasure. It monitored the airwaves,
listening for one of the radio signals used by the munitions proximity
fuses. Once the countermeasure heard that signal, Shortstop recorded it,
modified it, and then blasted it back at the munition. By confusing the
weapons with their own signals, Shortstop could fool the shells into
prematurely detonating.
The soldiers tweaked the Shortstop to scan for radio-controlled bombs
triggering frequencies, and to rely on a Humvees power supply. The wife of
one Fort Monmouth engineer collected miniature kitchen witches that inspired
a new name for the device: Warlock Green, Atkinson recounts.
Five Warlock Greens accompanied U.S. forces into Iraq in March, 2003. By
mid-summer, there were 100 jammers in the warzone. It wasnt nearly enough.
Iraqs militants had learned from their compatriots in Afghanistan, and were
setting off remotely-detonated explosives everywhere.
Just like the first turn of this improvised explosive device (IED) war, the
electronic countermeasures were having trouble keeping up with the bombs. It
took Warlock Green, ultimately manufactured by the EDO Corporation, a couple
of seconds to record, modify, and rebroadcast a triggering signal. An
insurgent bomber could set off an explosive in a few fractions of a second,
if he had a simple, low-powered trigger, like a garage door opener. The
jammer didnt have time to catch up.
The jammers could only cover a small slice of the radio frequency spectrum.
Whenever the insurgents should change triggers  from say, door openers to
key fobs  the jammer-makers would have to go back to the drawing board.
Warlock Greens could be reprogrammed, within limits. The Acorns couldnt; the
new threats rendered them useless.
Every time we put a countermeasure in the field  especially with Warlock 
they were able to outstrip it, says Paul Mueller, a long-time defense
executive, who supervised jammer-building operations at EDO  and at the ITT
Corporation. They were a step ahead of us.
Every time we used a countermeasure, they were able to outstrip it. But
with insurgents setting off 50 IEDs a week, even the step-behind jammers were
better than no jammers at all. By May 1, 2004  one year to the day since
President George W. Bush declared the end of major combat operations  the
improvised bombs had wounded more than 2,000 American troops in Iraq. The
IEDs killed 57 servicemembers in April alone, and injured another 691. IEDs
are my number-one threat in Iraq. I want a full-court press on IEDs, Gen.
John Abizaid, then the top military commander in the Middle East, wrote in a
June 2004 memo.
In the early fall of 2004, the Army signed a contract for 1,000 Warlocks. By
March, 2005, the Army upped that order to 8,000 jammers. It was a high-tech,
electromagnetic surge. And it was meant to send the militants sliding back
down the scale of sophistication. If somebody can sit a click [kilometer]
away with a radio and target our guys, weve got almost no ability to get
him, says a source familiar with the jammer buildup. But if hes doing the
Wile E. Coyote thing, and pushing down that plunger, at least weve got some
chance to shoot him before he gets it down.
All the big defense contractors  and lots of little ones  got into the
electronic countermeasure business. The Marines bought one model; the Army
another; Special Operations Forces, a third. The Army began buying Warlock
Reds  small, active jammers that blocked out the low-powered triggers that
Warlock Green couldnt stop in time. Warlock Blue was a wearable jammer, to
protect the infantryman on patrol. Each countermeasure had its shortcomings;
Warlock Blue, for instance, was a half-watt jammer at a time when some
engineers suspected that 50 watts might be too weak, Atkinson notes. But no
commander could afford to wait for a perfect, common bomb-stopper; too many
men were getting blown up. By May 1, 2005, the number of U.S. troops wounded
by the bombs had climbed to more than 7,700.
There were drawbacks to throwing all those countermeasures into the field at
once. Warlock Green would sometimes mistake Warlock Reds signal for an
enemys, and go after it. That would lock the jammers in a so-called deadly
embrace, cancelling one another out.
When the Warlocks were operational, they wreaked havoc with both the
remote-controlled robots that were supposed to handle bombs at a safe
distance and the radios soldiers used to warn each other about upcoming
threats. Warlock Red prevented communications from three of the Armys most
common radio systems, according to a classified report released by WikiLeaks.
The report recommended keeping radios and countermeasures in different
vehicles to prevent the electronic fratricide. Of course, that meant a
soldier with a jammer in his Humvee was cut off from the rest of his convoy.
For reporters, pointing out these drawbacks  in fact, pointing out anything
about the jammers  risked a swift military response. In Baghdad, a top
official with the Joint IED Task Force called me an al-Qaida ally for putting
together a Wired.com report on counter-IED technologies based on other
publicly-available information. A few months later, David Axe mentioned the
Warlocks in a post for Defensetech.org from Iraq. Shortly after the post went
live, Axe was detained, and was promptly thrown out of the country.
Even more secret were the flights of the jammers in the sky. The Navys EA-6
Prowlers could not only block triggering signals; they could remotely
detonate the bombs, as well. But they had to be very, very careful. U.S.
vehicles equipped with jammers had to get off of the roads, or risk the
deadliest embrace of all. Pilots had to make sure that civilians were nowhere
nearby, when they set the bombs off.
Despite the hiccups, the jammers were saving lives  including, I believe, my
In July of 2005, I found myself at a rubble-strewn intersection of two
highways, not far from Iraqs Abu Ghraib prison. The Explosive Ordnance
Disposal team I was traveling with called this place the Death X, because
of all the attacks nearby. The bomb squad was called out to the area because
of a suspicious package  a package that turned out to be nothing more than a
balled-up pair of pants. But on the way back from the incident, our Humvee
rolled over an artillery shell, buried in the highways middle lane and wired
to a radio. An improvised bomb.
The IED didnt go off, for reasons that werent completely clear. The Death X
bomber might have gotten cold feet. More likely, one of Warlocks in the
Humvee prevented him from detonating the weapon.
That same day, I took a Black Hawk ride to the town of Mahmudiya, just south
of Baghdad. At the outpost there, I met Staff Sgt. Johnnie Mason (pictured),
who showed off the cordless phone than nearly killed him. It was wired to a
series of artillery shells, and stuffed under a row of human corpses, rotting
by a canal in the 118 degree heat.
The dead bodies, they smelled like catfish bait.
When Mason  a lanky, 31 year-old Texan with big brown eyes and a goofy smile
 came across the bomb, he wanted to puke into his Kevlar protective suit.
The dead bodies, they smelled like catfish bait. But there was no time to
heave. Mason knew the weapon was live, and that he was outside his Warlocks
protective bubble. He figured he only had a moment or two to act before a
bomber remotely detonated his device. So Mason jumped behind a three-foot
berm, and crouched into a fetal position before the shock wave hit him. It
was too fast for me to think, Oh God, Im gonna die, Mason said. It was
just instant fear.
The bomb was less than twenty feet away when it went off. Dirt flew up.
Shards of bomb zipped through the air. The shockwave knocked Mason over. But
he was intact, somehow.
Masons partner, Pfc. Brian James, ran over. Are you alright? he yelled.
Where you at?
Im in Iraq, Brook! Mason shouted back. Brook was his wifes name.
Mason sat down for fifteen minutes, drank some water. And then he went right
back to the bodies. Before the explosion, he noticed a second shell, 20
meters away. So Mason took a couple pounds of C4 plastic explosive to
demolish the thing. I still had a job to do, he told me.
Five months later, on the 19th of December, Mason found himself on another
highway, responding to another suspicious package call. His team stumbled on
another IED, practically beneath their feet. Insurgents were routinely luring
bomb squads with one weapon in an attempt to kill them with the second. In
this case, the tactic worked.
Mason told everyone to clear out of the way while he tried to disarm the
device. Then the bomb went off.
Johnnie Mason was buried at Arlington Cemetery on January 10, 2006.
2006 rolled on. The insurgency in Iraq got worse. Much worse. The number of
troops wounded by bombs hit 15,000, and kept going. Explosively formed
projectiles  bombs that shot out jet of molten, armor-piercing metal  went
from a macabre curiosity to something like a staple of the insurgent arsenal.
There seemed to be no end to the carnage.
Militant bombmakers increasingly turned to long range cordless telephones and
cell phones for their triggers. That was a serious issue. The digital devices
were built to overcome dropped packets, reflected signals, and transmission
errors. Warlock Greens trick of fooling a trigger with its own, modified
signal didnt work. The gadgets were used to the hiccups.
The deadly embrace between the jammers began to loosen.
Behind the scenes, however, there were signs of improvement. The Navy sent to
Iraq hundreds of electronic warfare specialists, to bring the cacophony
produced by 14 kinds of jammers into some sort of harmony. Protocols were
established, to allow one device to send its signal and then go silent for a
few milliseconds, so another gadget could broadcast; that allowed Warlock Red
and Warlock Green to be packaged into a single, combination unit. The deadly
embrace between the jammers began to loosen. The Pentagons IED task force
became the Joint IED Defeat Organization, or JIEDDO, with a $3.6 billion
annual budget to tame the homemade bomb threat. Mongtomery Meigs, the retired
four-star general in charge of the organization, worked to unravel the
bureaucratic tangle that tied up bomb trigger analysis. The intelligence
specialists at the Combined Explosive Exploitation Cells got faster and
faster at analyzing which frequencies the insurgents were using. That, in
turn, allowed the jammers to be updated more quickly, so they could counter
emerging threats.
Most importantly, perhaps, a new generation of jammers entered the
battlefield, thanks to JIEDDOs billions. Some, like the Marines Chameleon
countermeasure, could cover a broad range of frequencies, from low-powered
triggers (like key fobs) to high-powered ones (like walkie-talkies). In
February of 06, the Corps announced they were buying 4,000 of the 125-pound,
Humvee-mounted systems.
Warlock Duke used a technique called set-on jamming to overcome the more
advanced digital triggers. Like Green, Duke would listen for a malicious
signal. But rather than confuse a receiver with a modified version of its own
signal, Duke had a series of built-in jamming responses, designed to fool
very specific devices. If Duke heard a particular FM walkie-talkie, Duke
would send out a specific FM spoof. It was actually a cruder technique than
Greens. And it relied on very detailed knowledge about exactly which threats
were in which area. But it worked. Tens of thousands were eventually fielded.
And slowly, slowly, the percentage of radio-controlled bombs as a whole began
to fall. Then they began to disappear altogether.
Electronic warfare defensive systems were instrumental in saving thousands
of Soldiers and Marines from being casualties in Iraq, emails retired Lt.
Gen. Michael Oates, who led the 10th Mountain Division during its tour in
Iraq at the time, and then became director of JIEDDO. The high use of remote
controlled detonation capability was a significant and effective threat
until the jammers were developed.
By the time I returned to Iraq, in the summer of 2007, IEDs had become relics
in broad swaths of the country. The insurgents had largely abandoned their
tool of choice.
It was not altogether good news.
North of Baghdad, insurgents took insulated copper threads, some not much
thicker than a hair, and buried them in the dust. Then they strung them out
for as long as a kilometer. At one end was an insurgent triggerman. At the
other, an explosively formed projectile. It was a crude approach to killing 
even more primitive than those first bombs planted in Afghanistan. But it was
lethally effective.
These command wire bombs had a fatal flaw, however. Insurgents had to stick
around to set them off. That made them vulnerable to American counter-attacks
and preemption. And that brought the number of bombs and bomb fatalities way
down. In December of 2007, only nine U.S. troops were killed by IEDs, and
another 166 were wounded. It was still an awful toll. But it was a tiny
fraction of the 69 slain and 473 injured in December of 2006.
All the gadgets built for Iraq were worthless against Afghanistans throwback
The casualty figures continued to fall as the military began to field a third
generation countermeasure  one that could stomp out a huge swath of radio
triggers with all sorts of jamming techniques. In April of 2007, the Pentagon
signed a deal with EDO for up to 10,000 of the so-called CVRJs. Shortly
thereafter, ITT bought EDO, and began to crank out the machines. The CVRJ
held up to 15 mission loads at once, quadrupled the number of simultaneous
channels it could jam on, and doubled the spectral coverage of pre-existing
systems. More importantly, the CVRJ could be reprogrammed on the fly: not
just the frequencies it covered, but the specific responses it used to
counter particular threats. For the first time ever, says Mueller, the
EDO-turned-ITT executive, we had a canvas to create a painting.
That enabled CVRJ to target the most advanced triggers  the ones which
relied on the latest mobile and long-range cordless phones. The new phones
hopped between frequencies and spread their signal across the spectrum to
overcome interference. That made them much harder to jam. But the phones have
a potential flaw. They relied on software protocols to establish connections
between transmitter and receiver. Those protocols could be spoofed, keeping
the connection from ever happening. That is, if you had a fully programmable
countermeasure, like CVRJ.
In the broadest sense, the strategy behind the U.S. jammer buildup had
succeeded. Thanks to the Americans bleeding edge technologies, the militants
had dropped back down the ladder of sophistication. They were now taking the
Wile E. Coyote approach  pushing down the plunger to detonate the bomb  and
suffering for it. That was the whole intent of the program: pushing the
enemy back to archaic means, says a source familiar with the effort. So
theyd actually have to face you and fight you.
In Afghanistan, however, the terrain favored the low tech. All the gadgets
the Americans had bought and built for Iraq proved largely worthless against
a new slew of throwback threats. The bombs were largely made of wood and
fertilizer, making them practically invisible to metal detectors. No command
wires were needed to set them off; just the pressure of an unlucky boot. The
placement of the bombs added to their effectiveness. The U.S. militarys new
hard-shelled, blast-deflecting vehicles were built for Iraqs well-paved
roads. So the insurgents put their explosives in the gullies and the mud
paths, where the trucks were useless. The bomb-handling robots couldnt
handle the rough terrain, either. And, during the summer, the weather was so
hot, EOD technicians didnt even bother wearing their protective suits.
As the fighting grew more intense  and the U.S.-led coalition poured more
troops into the Afghan campaign  the total number of bombs there crept up,
from 1,931 in 2006 to 3,276 in 2008. By July, 2010, that figure had reached
nearly 1,400 explosives found or detonated a month. Its stayed about that
high ever since.
The deaths and injuries caused by these bombs continued to mount, as well. In
July 2008, 25 American troops were wounded by Afghan IEDs. In July 2009, that
figure was 174. In July 2010, the number was 378 injured  about 15 times
higher than the casualty count from two years before.
JIEDDO shifted its focus to compensate. Jammers alone werent going to do
much against these no-tech weapons. The organization spent more on
surveillance and intelligence analysts, trying to find ways to crack apart
Afghanistans IED networks.
But even if those networks are shredded tomorrow, theres a sense in the
Pentagon that the improvised bomb has now become a permanent threat. Over the
last six months, theres been an average of 245 jury-rigged explosives found
or detonated  outside of Iraq and Afghanistan. The IED has gone global.
The lab where ITT engineers work on the fifth generation of bomb-stoppers
looks like a schoolroom  from the desks facing the front of the room to the
guy with the ponytail and circular glasses delivering the lecture. Behind the
guy  hes an engineer, not an English prof  are two screens. One shows a
CGI version of a jammers guts: the amplifiers, the transceivers, what have
you. The other screen shows a map of a military base, covered in red and
green. It shows how the countermeasure might perform with that configuration.
The Pentagon cant afford any more to crank out yet another stop-gap
countermeasure for yet another kind of bomb. So the military is instead
backing the development of a jammer that can be used anywhere, and for years
to come. The system is awkwardly known as Joint Counter Radio-Controlled
Improvised Explosive Device Electronic Warfare 3.3. An initial batch of 21 of
these JCREW machines are supposed to ship to the military in July for field
testing. If it passes those trials, among other hurdles, up to 20,000 of the
uber jammers could eventually be built.
Aircraft, vehicles, ships, and troops are all on the new jammers target
list.  But before it gets into troops hands, the countermeasure gets
simulated here. Lower the antenna from 15 feet to five makes more red
splotches appear on the map, indicating gaps in jammer coverage. Add a bigger
amplifier, and some of the red goes away.
ITT has bigger ambitions for its JCREW machine than simple bomb-blocking.
Step through a door, and theres a more traditional-looking electronics
workroom: cable-strewn benches, and machines stacked head-high. Guys with
soldering irons connect wires to boxey machines. The goal here isnt to see
how the countermeasures block signals. Its to see how they talk to one
another. Theres a JCREW jammer designed for vehicles, another for individual
troops, and a third to protect bases. All of the machines are meant to work
The JCREW 3.3s are supposed to be fully networkable, and able to communicate
over the militarys wireless battlefield networks. That should save them some
power and interference if youve got four jammers in a convoy, for instance,
one can silence a receiver while the other three quiet down. Or maybe that
jammer can spot the threat, record its signal and location, and transmit that
information back to headquarters. In that way, the new machine becomes more
than a single bomb-beater. The system might help track down the explosives,
and the guys who planted them. It could be configured to listen in on
communications  those cell phones are for more than triggering explosives,
after all. Hell, if the machines are passing data back and forth, they could
work as radios themselves, in theory.
With proper power management and frequency coordination, the new JCREW could
have a whole new range of potential targets, according to a company
briefing. Those include information systems and infrastructure, drones,
communications grids, sensors, position, navigation and timing capabilities
(thats shorthand for GPS signals), as well as aircraft, vehicles, ships,
troops. In other words: everything.
For now, these are just ideas, not orders. Its all on the roadmap,
potentially, Mueller says. How much we actually do remains to be seen.
But one thing is for sure: its a long way from stopping crude triggers,
stuffed into disposable lamps. Its a long way from frantically tweaking
electronics in the hope of somehow keeping thirty soldiers a day from being
blown up. Its a long way from the near decade-long fight against
remote-controlled bombs in which the enemy had the advantage of being the
first mover. This may be the chance to get ahead, before the next wave of
terror weapons hits.
Photos: USMC, Wikimedia, Noah Shachtman, ITT

@_date: 2013-10-21 14:34:48
@_author: Eugen Leitl 
@_subject: russian FSB requires all ISPs to give them access to metadata by 1 
Source: Not less than 12 hours logging of (all? or meta?) data,
with direct acess given to FSB (SORM, almost certainly
a VPN gateway to FSB like German SINA Box).

@_date: 2013-10-22 10:51:56
@_author: Eugen Leitl 
@_subject: Enigmabox releases source 
Just got word, Enigmabox has published source and
put up first documentation on Roll your own Enigmabox: Not too sure how to get a Debian 7 with minimum pain,
pfSense offers dd'able images. Voyage Linux or Debian for Alix?

@_date: 2013-10-22 11:55:52
@_author: Eugen Leitl 
@_subject: Undernet IPv6 Interop [was: Enigmabox/cjdns] 
Yes. If people are not familiar with cjdns, here's a good
intro I've asked about this a while back among a few IPv6 people, and it does not seem to be a problem. The keys/addresses are randomly generated and are all in FC00::/8. 120 bits is a lot of space. cjdns interoperates fine with dual-stack. The interesting
part is L2 routing over own infrastructure, and eventual
ASIC/FPGAfication of the router.

@_date: 2013-10-25 11:45:13
@_author: Eugen Leitl 
@_subject: Gentlemen do not read each other's mail... 
I see zero evidence that anyone is furious. It's pure political theater to appease those few percent of voting cattle that are privacy-minded. Notice everybody is carefully staying away from mandating simple
and the only measures which would work: strong end to end encryption,
with secrets held by end users, in tamper-proofed compartments.
Because this would seriously compromise their own surveillance
capability. And we certainly can't have that, oh noes.
People in power are used that the common laws are strictly for
the commons, so for those few clueless the outrage to be no
longer exempt might be even genuine.
So ruthlessly machiavellian, or clueless and entitled, pick
your poison.

@_date: 2013-10-28 08:20:42
@_author: Eugen Leitl 
@_subject: Another Snowden News Story. Another Lesson in Proper 
No. Trying to keep short-attention-span people engaged. It might not make a differences, but not even trying
would be foolish.

@_date: 2013-10-28 08:58:24
@_author: Eugen Leitl 
@_subject: Armed agents seize records of reporter, Washington Times prepares 
Armed agents seize records of reporter, Washington Times prepares legal
** FILE ** Associated Press** FILE ** Associated Press By Guy Taylor-The
Washington Times Friday, October 25, 2013
The Washington Times
Maryland state police and federal agents used a search warrant in an
unrelated criminal investigation to seize the private reporting files of an
award-winning former investigative journalist for The Washington Times who
had exposed problems in the Homeland Security Department's Federal Air
Marshal Service.
Reporter Audrey Hudson said the investigators, who included an agent for
Homeland's Coast Guard service, took her private notes and government
documents that she had obtained under the Freedom of Information Act during a
predawn raid of her family home on Aug. 6.
SEE ALSO: Judicial Watch sues IRS for stonewalling on tea party FOIA The
documents, some which chronicled her sources and her work at the Times about
problems inside the Homeland Security Department, were seized under a warrant
to search for unregistered firearms and a potato gun suspected of belonging
to her husband, Paul Flanagan, a Coast Guard employee. Mr. Flanagan has not
been charged with any wrongdoing since the raid.
The warrant, obtained by the Times, offered no specific permission to seize
reporting notes or files.
The Washington Times said Friday it is preparing legal action to fight what
it called an unwarranted intrusion on the First Amendment.
While we appreciate law enforcements right to investigate legitimate
concerns, there is no reason for agents to use an unrelated gun case to seize
the First Amendment protected materials of a reporter, Times Editor John
Solomon said. This violates the very premise of a free press, and it raises
additional concerns when one of the seizing agencies was a frequent target of
the reporters work.
Homelands conduct in seizing privileged reporters notes and Freedom of
Information Act documents raises serious Fourth Amendment issues, and our
lawyers are preparing an appropriate legal response, he said.
Maryland State Police declined comment, except to say that evidence and
information developed during this investigation is currently under review by
both the Anne Arundel County State's Attorney's Office and the United State's
Attorney's Office, and that a determination has yet to be made on any
PHOTOS: Families suspect SEAL Team 6 crash was inside job The U.S. Coast
Guard confirmed it seized and reviewed Ms. Hudsons documents but insisted it
did nothing wrong.
Capt. Tony Hahn, a spokesman at Coast Guard headquarters in Washington, said
the Coast Guard Investigative Service (CGIS) was involved in the case because
Mrs. Hudsons husband, Mr. Flanagan, is a Coast Guard employee.
During the search of the home, said Capt. Hahn, the CGIS agent discovered
government documents labeled FOUO  For Official Use Only and LES  Law
Enforcement Sensitive.
The files that contained these documents were cataloged on the search
warrant inventory and taken from the premises, he said. The documents were
reviewed with the source agency and determined to be obtained properly
through the Freedom of Information Act.
Ms. Hudson described a harrowing ordeal the morning her family home was
The agents, who had arrived a 4:30 a.m. in full body armor, collected several
small arms during the raid, although no charges have been filed against Mr.
Flanagan, 54, during the nearly three months since.
Mrs. Hudson, 50, says that while the authorities were raiding her house,
Coast Guard investigator Miguel Bosch  who formerly worked at the marshal
service  began asking questions about whether she was the same Audrey
Hudson who had written the air marshal stories for The Washington Times.
Mrs. Hudson says she responded that she was.
It was not until roughly a month later, Mrs. Hudson says, that she realized
the agents had quietly seized five files from her private office  including
handwritten and typed notes from interviews with numerous confidential
sources related to her exclusive reporting on the air marshals service.
The search warrant for the raid, issued to Maryland State Trooper Victor
Hodgin by a district court judge, made no reference to the documents. A copy
obtained by The Times indicates that the search was to be narrowly focused on
the pursuit of firearms and their accessories and/or parts, as well as
any communications that that might be found in Mrs. Hudson and Mrs.
Flanagans home related to the acquisition of firearms or accessories.
David W. Fischer, a private attorney contacted by the couple, says that the
raid is a potential violation of Mrs. Hudsons constitutional rights.
Obviously, the warrant is about a gun, nothing about reporters notes, he
said. It would be a blatant constitutional violation to take that stuff if
the search warrant didnt specifically say so.
This is a situation where they picked very specifically through her stuff
and took documents that the Coast Guard, or the Department of Homeland
Security, would be very interested in, he added.
The raid could constitute illegal search and seizure under the Fourth
Amendment  and the fact that the materials were related to her work as a
reporter could First Amendment freedom of the press protections.
Once the documents had been cleared, Homeland decided to return the
documents to Mr. Flanagan and Mrs. Hudson, Capt. Hahn said.
The Coast Guard, like the Federal Air Marshal Service is an agency within the
U.S. Department of Homeland Security.
A Reporters Word
What concerns Mrs. Hudson and The Times is the fact that private reporting
documents were seized during the search being conducted on totally unrelated
While Mr. Flanagan has a police record from the mid-1980s related to the
unlawful possession of firearms, including automatic weapons, Mrs. Hudson
fears her private documents may have been the real target of the search.
They tore my office apart more than any other room in my house, she said,
adding agents did not take other potentially non-TSA-related documents from
the office.
I had a box full of [Department of Defense] notes, she said. They didnt
touch those.
Some of the files included notes that she had used to expose how the Federal
Air Marshal Service had lied to Congress during the years after the Sept. 11,
2001, terrorist attacks about the number of airline flights that the service
was actually protecting against another terrorist attack.
A story written by Mrs. Hudson for The Times in March 2005, revealed how air
marshals were protecting less than 10 percent of domestic and international
flights during the month of December 2004, and that the number of flights
Homeland Security officials were providing to Congress was higher than the
actual number of marshals it employed.
Mrs. Hudson says that the experience of having a half-dozen armed officers
rifle through my personal belongings for the three-hour search was
But when the files were returned to me and I saw all the notes that had been
in their possession for a month, it was gut-wrenching, she said.
That her private files were seized, says Mrs. Hudson, is particularly
disturbing because of interactions that she and her husband had during the
search of their home, as well as months afterwards, with Coast Guard
investigator Miguel Bosch. According to his profile on the networking site
LinkedIn, Mr. Bosch worked at the Federal Air Marshal Service from April 2001
through November 2007.
It was Mr. Bosch, Mrs. Hudson says, who asked her during the Aug. 6 search if
she was the same Audrey Hudson who had written the air marshal stories. It
was also Mr. Bosch, she says, who phoned Mr. Flanagan a month later to say
that documents taken during the search had been cleared.
During the call, according Mrs. Hudson, Mr. Bosch said the files had been
taken to make sure that they contained only FOIA-able information and that
he had circulated them to the Transportation Security Administration, which
oversees the Federal Air Marshal Service, in order to verify that it was
legitimate for her to possess such information.
Essentially, the files that included the identities of numerous government
whistleblowers were turned over to the same government agency and officials
who they were exposing for wrongdoing, Mrs. Hudson said.
Reached on the telephone by a reporter for The Times, Mr. Bosch refused to
comment on whether or not journalist-related documents were seized during the
search of Mrs. Hudsons home.
I got to get on the phone with Coast Guard legal before I talk with you,
Mr. Bosch said. Its still an open investigation.
Asked specifically whether documents related to Mrs. Hudsons reporting
activities were taken during the search, he responded: There was a lot of
stuff taken.
Legitimate Case?
The U.S. Coast Guard maintains that it has done nothing wrong in the case and
that the investigation into Mrs. Hudsons husband is based on legitimate
suspicion that he was illegally in possession of firearms.
The warrant outlines how Mr. Flanagan was found guilty in 1985  when he was
25  of resisting arrest in Prince Georges County, Maryland.
The charge of carrying a concealed deadly weapon was dropped, but a year
later, the U.S. Marshal Service arrested Mr. Flanagan for possession of a
machine gun. The warrant also indicates that Mr. Flanagan was also arrested
in 1996 by police in Anne Arundel County, Maryland,for possessing a handgun
in his vehicle.
The warrant outlines how sometime this year Mr. Flanagan drew the interest of
the U.S. Bureau of Alcohol, Tobacco, Firearms and Explosives after allegedly
attempting to purchase possible machine gun parts from a Swedish national.
The warrant says the information was handed to the Coast Guards
investigative service  since Mr. Flanagan worked at the agency  which
conducted an interview during which Flanagan was evasive but stated he did
receive a potato gun but it was defective and it was thrown away.
The term potato gun is slang used during the illegal importation of
silencers, according to the warrant.
Mrs. Hudson says the potato gun claim is outrageous.
She says that her husband did in fact purchase a potato launcher from an
online company based in Sweden five years ago as a novelty item, but it was
discarded within as few weeks because it did not work.
She noted that the law enforcement agents who raided her home did not take a
golf ball launcher that also belonged to her husband as a novelty item.
They did, however, confiscate small arms belonging to Mrs. Hudson that she
had legally registered with the Maryland State Police as far back as 2005.
The search warrant allowed for the weapons to be confiscated, and Mrs. Hudson
says the agents told her that because her husband had pled guilty to a
resisting arrest charge nearly 30 years ago, she was not allowed to possess
the guns under state law. The guns she owned were for recreational shooting,
she says, as well as for security concerns resulting from many of her
I swear to God, were not smuggling machine gun parts from Sweden, said
Mrs. Hudson, adding that the potato launcher in question didnt even work.
Mrs. Hudson has been a reporter in Washington, D.C. for nearly 15 years, and
covered Homeland Security for the Times after the Sept. 11, 2001, terrorist
attacks through December 2009.
Her investigations have sparked numerous congressional investigations that
led to laws signed by former Presidents George W. Bush and Bill Clinton. She
has won numerous journalism awards for her investigations, including the
prestigious Sigma Delta Chi bronze medal for public service, the Society of
Professional Journalists Dateline Award in Investigative Reporting, and was
nominated twice by The Times for the Pulitzer Prize.
Protecting confidential sources is a part of my honor and hits me at my
ethical core, said Mrs. Hudson. To have someone steal my source information
and know it could impact peoples careers, is disgusting, a massive
overreach. This kind of conduct is intimidation clearly aimed at silencing a
vigorous press.
Read more:
 Follow us:  on Twitter

@_date: 2013-10-28 17:03:12
@_author: Eugen Leitl 
@_subject: The Battle for Power on the Internet 
forkit! , tt silklist
 cypherpunks
The Battle for Power on the Internet
Distributed citizen groups and nimble hackers once had the edge. Now
governments and corporations are catching up. Who will dominate in the
decades ahead?
BRUCE SCHNEIER OCT 24 2013, 7:07 AM ET
Vivek Prakash/Reuters
Were in the middle of an epic battle for power in cyberspace. On one side
are the traditional, organized, institutional powers such as governments and
large multinational corporations. On the other are the distributed and
nimble: grassroots movements, dissident groups, hackers, and criminals.
Initially, the Internet empowered the second side. It gave them a place to
coordinate and communicate efficiently, and made them seem unbeatable. But
now, the more traditional institutional powers are winning, and winning big.
How these two side fare in the long term, and the fate of the rest of us who
dont fall into either group, is an open questionand one vitally important
to the future of the Internet.
In the Internets early days, there was a lot of talk about its natural
lawshow it would upend traditional power blocks, empower the masses, and
spread freedom throughout the world. The international nature of the Internet
bypassed circumvented national laws. Anonymity was easy. Censorship was
impossible. Police were clueless about cybercrime. And bigger changes seemed
inevitable. Digital cash would undermine national sovereignty. Citizen
journalism would topple traditional media, corporate PR, and political
parties. Easy digital copying would destroy the traditional movie and music
industries. Web marketing would allow even the smallest companies to compete
against corporate giants. It really would be a new world order.
This was a utopian vision, but some of it did come to pass. Internet
marketing has transformed commerce. The entertainment industries have been
transformed by things like MySpace and YouTube, and are now more open to
outsiders. Mass media has changed dramatically, and some of the most
influential people in the media have come from the blogging world. There are
new ways to organize politically and run elections. Crowdfunding has made
tens of thousands of projects possible to finance, and crowdsourcing made
more types of projects possible. Facebook and Twitter really did help topple
But that is just one side of the Internets disruptive character. The
Internet has emboldened traditional power as well.
On the corporate side, power is consolidating, a result of two current trends
in computing. First, the rise of cloud computing means that we no longer have
control of our data. Our e-mail, photos, calendars, address books, messages,
and documents are on servers belonging to Google, Apple, Microsoft, Facebook,
and so on. And second, we are increasingly accessing our data using devices
that we have much less control over: iPhones, iPads, Android phones, Kindles,
ChromeBooks, and so on. Unlike traditional operating systems, those devices
are controlled much more tightly by the vendors, who limit what software can
run, what they can do, how theyre updated, and so on. Even Windows 8 and
Apples Mountain Lion operating system are heading in the direction of more
vendor control.
I have previously characterized this model of computing as feudal. Users
pledge their allegiance to more powerful companies who, in turn, promise to
protect them from both sysadmin duties and security threats. Its a metaphor
thats rich in history and in fiction, and a model thats increasingly
permeating computing today.
Medieval feudalism was a hierarchical political system, with obligations in
both directions. Lords offered protection, and vassals offered service. The
lord-peasant relationship was similar, with a much greater power
differential. It was a response to a dangerous world.
Feudal security consolidates power in the hands of the few. Internet
companies, like lords before them, act in their own self-interest. They use
their relationship with us to increase their profits, sometimes at our
expense. They act arbitrarily. They make mistakes. Theyre deliberatelyand
incidentallychanging social norms. Medieval feudalism gave the lords vast
powers over the landless peasants; were seeing the same thing on the
Its not all bad, of course. We, especially those of us who are not
technical, like the convenience, redundancy, portability, automation, and
shareability of vendor-managed devices. We like cloud backup. We like
automatic updates. We like not having to deal with security ourselves. We
like that Facebook just worksfrom any device, anywhere.
Government power is also increasing on the Internet. There is more government
surveillance than ever before. There is more government censorship than ever
before. There is more government propaganda, and an increasing number of
governments are controlling what their users can and cannot do on the
Internet. Totalitarian governments are embracing a growing cyber
sovereignty movement to further consolidate their power. And the cyberwar
arms race is on, pumping an enormous amount of money into cyber-weapons and
consolidated cyber-defenses, further increasing government power.
Technology magnifies power in general, but rates of adoption are different.
In many cases, the interests of corporate and government powers are aligning.
Both corporations and governments benefit from ubiquitous surveillance, and
the NSA is using Google, Facebook, Verizon, and others to get access to data
it couldnt otherwise. The entertainment industry is looking to governments
to enforce its antiquated business models. Commercial security equipment from
companies like BlueCoat and Sophos is being used by oppressive governments to
surveil and censor their citizens. The same facial recognition technology
that Disney uses in its theme parks can also identify protesters in China and
Occupy Wall Street activists in New York. Think of it as a public/private
surveillance partnership.
What happened? How, in those early Internet years, did we get the future so
The truth is that technology magnifies power in general, but rates of
adoption are different. The unorganized, the distributed, the marginal, the
dissidents, the powerless, the criminal: They can make use of new
technologies very quickly. And when those groups discovered the Internet,
suddenly they had power. But later, when the already-powerful big
institutions finally figured out how to harness the Internet, they had more
power to magnify. Thats the difference: The distributed were more nimble and
were faster to make use of their new power, while the institutional were
slower but were able to use their power more effectively.
So while the Syrian dissidents used Facebook to organize, the Syrian
government used Facebook to identify dissidents to arrest.
All isnt lost for distributed power, though. For institutional power, the
Internet is a change in degree, but for distributed power its a qualitative
one. The Internet gives decentralized groupsfor the first timethe ability
to coordinate. This can have incredible ramifications, as we saw in the
SOPA/PIPA debate, Gezi, Brazil, and the rising use of crowdfunding. It can
invert power dynamics, even in the presence of surveillance censorship and
use control. But aside from political coordination, the Internet allows for
social coordination as well to unite, for example, ethnic diasporas, gender
minorities, sufferers of rare diseases, and people with obscure interests.
This isnt static: Technological advances continue to provide advantage to
the nimble. I discussed this trend in my book Liars and Outliers. If you
think of security as an arms race between attackers and defenders, any
technological advance gives one side or the other a temporary advantage. But
most of the time, a new technology benefits the nimble first. They are not
hindered by bureaucracyand sometimes not by laws or ethics either. They can
evolve faster.
We saw it with the Internet. As soon as the Internet started being used for
commerce, a new breed of cybercriminal emerged, immediately able to take
advantage of the new technology. It took police a decade to catch up. And we
saw it on social media, as political dissidents made use of its
organizational powers before totalitarian regimes did.
Which type of power dominates in the coming decades?
Right now, it looks like traditional power.
This delay is what I call a security gap. Its greater when theres more
technology, and in times of rapid technological change. Basically, if there
are more innovations to exploit, there will be more damage resulting from
society's inability to keep up with exploiters of all of them. And since our
world is one in which theres more technology than ever before, and a faster
rate of technological change than ever before, we should expect to see a
greater security gap than ever before. In other words, there will be an
increasing time period during which nimble distributed powers can make use of
new technologies before slow institutional powers can make better use of
those technologies.
This is the battle: quick vs. strong. To return to medieval metaphors, you
can think of a nimble distributed powerwhether marginal, dissident, or
criminalas Robin Hood; and ponderous institutional powersboth government
and corporateas the feudal lords.
So who wins? Which type of power dominates in the coming decades?
Right now, it looks like traditional power. Ubiquitous surveillance means
that its easier for the government to identify dissidents than it is for the
dissidents to remain anonymous. Data monitoring means easier for the Great
Firewall of China to block data than it is for people to circumvent it. The
way we all use the Internet makes it much easier for the NSA to spy on
everyone than it is for anyone to maintain privacy. And even though it is
easy to circumvent digital copy protection, most users still cant do it.
The problem is that leveraging Internet power requires technical expertise.
Those with sufficient ability will be able to stay ahead of institutional
powers. Whether its setting up your own e-mail server, effectively using
encryption and anonymity tools, or breaking copy protection, there will
always be technologies that can evade institutional powers. This is why
cybercrime is still pervasive, even as police savvy increases; why
technically capable whistleblowers can do so much damage; and why
organizations like Anonymous are still a viable social and political force.
Assuming technology continues to advanceand theres no reason to believe it
wontthere will always be a security gap in which technically advanced Robin
Hoods can operate.
Most people, though, are stuck in the middle. These are people who have dont
have the technical ability to evade either the large governments and
corporations, avoid the criminal and hacker groups who prey on us, or join
any resistance or dissident movements. These are the people who accept
default configuration options, arbitrary terms of service, NSA-installed back
doors, and the occasional complete loss of their data. These are the people
who get increasingly isolated as government and corporate power align. In the
feudal world, these are the hapless peasants. And its even worse when the
feudal lordsor any powersfight each other. As anyone watching Game of
Thrones knows, peasants get trampled when powers fight: when Facebook,
Google, Apple, and Amazon fight it out in the market; when the U.S., EU,
China, and Russia fight it out in geopolitics; or when its the U.S. vs. the
terrorists or China vs. its dissidents.
The abuse will only get worse as technology continues to advance. In the
battle between institutional power and distributed power, more technology
means more damage. Weve already seen this: Cybercriminals can rob more
people more quickly than criminals who have to physically visit everyone they
rob. Digital pirates can make more copies of more things much more quickly
than their analog forebears. And well see it in the future: 3D printers mean
that the computer restriction debate will soon involves guns, not movies. Big
data will mean that more companies will be able to identify and track you
more easily. Its the same problem as the weapons of mass destruction fear:
terrorists with nuclear or biological weapons can do a lot more damage than
terrorists with conventional explosives. And by the same token, terrorists
with large-scale cyberweapons can potentially do more damage than terrorists
with those same bombs.
The more destabilizing the technologies, the greater the rhetoric of fear,
and the stronger institutional powers will get.  Its a numbers game. Very
broadly, because of the way humans behave as a species and as a society,
every society is going to have a certain amount of crime. And theres a
particular crime rate society is willing to tolerate. With historically
inefficient criminals, we were willing to live with some percentage of
criminals in our society. As technology makes each individual criminal more
powerful, the percentage we can tolerate decreases. Again, remember the
weapons of mass destruction debate: As the amount of damage each individual
terrorist can do increases, we need to do increasingly more to prevent even a
single terrorist from succeeding.
The more destabilizing the technologies, the greater the rhetoric of fear,
and the stronger institutional powers will get. This means increasingly
repressive security measures, even if the security gap means that such
measures become increasingly ineffective. And it will squeeze the peasants in
the middle even more.
Without the protection of his own feudal lord, the peasant was subject to
abuse both by criminals and other feudal lords. But both corporations and the
governmentand often the two in cahootsare using their power to their own
advantage, trampling on our rights in the process. And without the technical
savvy to become Robin Hoods ourselves, we have no recourse but to submit to
whatever the ruling institutional power wants.
So what happens as technology increases? Is a police state the only effective
way to control distributed power and keep our society safe? Or do the fringe
elements inevitably destroy society as technology increases their power?
Probably neither doomsday scenario will come to pass, but figuring out a
stable middle ground is hard. These questions are complicated, and dependent
on future technological advances that we cannot predict. But they are
primarily political questions, and any solutions will be political.
In the short term, we need more transparency and oversight. The more we know
of what institutional powers are doing, the more we can trust that they are
not abusing their authority. We have long known this to be true in
government, but we have increasingly ignored it in our fear of terrorism and
other modern threats. This is also true for corporate power. Unfortunately,
market dynamics will not necessarily force corporations to be transparent; we
need laws to do that. The same is true for decentralized power; transparency
is how well differentiate political dissidents from criminal organizations.
Oversight is also critically important, and is another long-understood
mechanism for checking power. This can be a combination of things: courts
that act as third-party advocates for the rule of law rather than
rubber-stamp organizations, legislatures that understand the technologies and
how they affect power balances, and vibrant public-sector press and watchdog
groups that analyze and debate the actions of those wielding power.
Transparency and oversight give us the confidence to trust institutional
powers to fight the bad side of distributed power, while still allowing the
good side to flourish. For if were going to entrust our security to
institutional powers, we need to know they will act in our interests and not
abuse that power. Otherwise, democracy fails.
In the longer term, we need to work to reduce power differences. The key to
all of this is access to data. On the Internet, data is power. To the extent
the powerless have access to it, they gain in power. To the extent that the
already powerful have access to it, they further consolidate their power. As
we look to reducing power imbalances, we have to look at data: data privacy
for individuals, mandatory disclosure laws for corporations, and open
government laws.
Medieval feudalism evolved into a more balanced relationship in which lords
had responsibilities as well as rights. Todays Internet feudalism is both
ad-hoc and one-sided. Those in power have a lot of rights, but increasingly
few responsibilities or limits. We need to rebalance this relationship. In
medieval Europe, the rise of the centralized state and the rule of law
provided the stability that feudalism lacked. The Magna Carta first forced
responsibilities on governments and put humans on the long road toward
government by the people and for the people. In addition to re-reigning in
government power, we need similar restrictions on corporate power: a new
Magna Carta focused on the institutions that abuse power in the 21st century.
Todays Internet is a fortuitous accident: a combination of an initial lack
of commercial interests, government benign neglect, military requirements for
survivability and resilience, and computer engineers building open systems
that worked simply and easily. Corporations have turned the Internet into an
enormous revenue generator, and theyre not going to back down easily.
Neither will governments, which have harnessed the Internet for political
Were at the beginning of some critical debates about the future of the
Internet: the proper role of law enforcement, the character of ubiquitous
surveillance, the collection and retention of our entire lifes history, how
automatic algorithms should judge us, government control over the Internet,
cyberwar rules of engagement, national sovereignty on the Internet,
limitations on the power of corporations over our data, the ramifications of
information consumerism, and so on.
Data is the pollution problem of the information age. All computer processes
produce it. It stays around. How we deal with ithow we reuse and recycle it,
who has access to it, how we dispose of it, and what laws regulate itis
central to how the information age functions. And I believe that just as we
look back at the early decades of the industrial age and wonder how society
could ignore pollution in their rush to build an industrial world, our
grandchildren will look back at us during these early decades of the
information age and judge us on how we dealt with the rebalancing of power
resulting from all this new data.
This wont be an easy period for us as we try to work these issues out.
Historically, no shift in power has ever been easy. Corporations have turned
our personal data into an enormous revenue generator, and theyre not going
to back down. Neither will governments, who have harnessed that same data for
their own purposes. But we have a duty to tackle this problem.
I cant tell you what the result will be. These are all complicated issues,
and require meaningful debate, international cooperation, and innovative
solutions. We need to decide on the proper balance between institutional and
decentralized power, and how to build tools that amplify what is good in each
while suppressing the bad.

@_date: 2013-10-29 11:32:44
@_author: Eugen Leitl 
@_subject: Cameron doesn't understand everybody's been playing nice so far 
David Cameron makes veiled threat to media over NSA and GCHQ leaks
Prime minister alludes to courts and D notices and singles out the Guardian
over coverage of Edward Snowden saga
Nicholas Watt, chief political correspondent The Guardian, Monday 28 October
2013 18.10 GMT
Cameron tours the Mini car plant in Oxford. The prime minister claims he
doesn't want to have to take legal action against the Guardian and other
newspapers over intelligence leaks but would rather talk to them. Photograph:
Ben Birchall/PA
David Cameron has called on the Guardian and other newspapers to show "social
responsibility" in the reporting of the leaked NSA files to avoid high court
injunctions or the use of D notices to prevent the publication of information
that could damage national security.
In a statement to MPs on Monday about last week's European summit in
Brussels, where he warned of the dangers of a "lah-di-dah, airy-fairy view"
about the dangers of leaks, the prime minister said his preference was to
talk to newspapers rather than resort to the courts. But he said it would be
difficult to avoid acting if newspapers declined to heed government advice.
The prime minister issued the warning after the Tory MP Julian Smith quoted a
report in Monday's edition of the Sun that said Britain's intelligence
agencies believed details from the NSA files leaked by the US whistleblower
Edward Snowden had hampered their work.
The Sun quoted a "top surveillance source" as saying that terrorists had
"gone quiet" after the publication of details about NSA and GCHQ operations.
Cameron told MPs: "We have a free press, it's very important the press feels
it is not pre-censored from what it writes and all the rest of it.
"The approach we have taken is to try to talk to the press and explain how
damaging some of these things can be and that is why the Guardian did
actually destroy some of the information and disks that they have. But
they've now gone on and printed further material which is damaging.
"I don't want to have to use injunctions or D notices or the other tougher
measures. I think it's much better to appeal to newspapers' sense of social
responsibility. But if they don't demonstrate some social responsibility it
would be very difficult for government to stand back and not to act."
The Guardian agreed to allow officials from GCHQ to oversee the destruction
of hard drives in July, after the government threatened to use an injunction
to block publication of information from the NSA files.
Alan Rusbridger, the editor-in-chief of the Guardian, said the destruction of
the hard drives allowed the Guardian to continue reporting on the NSA files
from its New York office.
The D-notice system is a voluntary code between government departments with
responsibility for national security and the media. A notice can be issued to
the media to prevent "inadvertent public disclosure of information that would
compromise UK military and intelligence operations and methods".
Cameron had earlier indicated that the oversight of Britain's intelligence
agencies may have to evolve in light of the revelations about the reach of
new technology. He told MPs: "We have parliamentary scrutiny of our
intelligence agencies through the intelligence and security committee and we
have strengthened that oversight.
"Our agencies operate under the law and their work is overseen by
intelligence commissioners. Of course as technology develops and as the
threats we face evolve so we need to make sure that the scrutiny and the
frameworks in place remain strong and effective."
Parliament's intelligence and security committee announced earlier this month
that it is to scutinise the extent of mass surveillance in response to the
concerns raised by the Snowden leaks.
The prime minister issued his warning to newspapers after Ed Miliband raised
concerns about the reports last week that the US has monitored the mobile
phone of the German chancellor Angela Merkel.
Miliband said: "I join the prime minister in his support for the work of our
intelligence services. It is vital, it keeps us safe and, by its very nature,
it goes unrecognised. I join the prime minister in applauding the men and
women who work for our intelligence agencies.
"We can all understand the deep concerns that recent reports have caused in
some European countries, especially Germany. As well as providing that
support for intelligence services it is right that every country ensures
proper oversight of those activities."
Julian Smith, who recently wrote to the Metropolitan police to assess whether
the Guardian has broken the law in publishing details from the NSA files,
asked the PM in the Commons: "Following the Sun's revelations this morning
about the impact of the Snowden leaks, is it not time that any newspaper that
may have crossed the line on national security comes forward and voluntarily
works with the government to mitigate further risks to our citizens?"

@_date: 2013-10-31 21:23:52
@_author: Eugen Leitl 
@_subject: Meet =?utf-8?B?4oCcYmFkQklPUyw=?= =?utf-8?B?4oCd?= the mysterious 
tt forkit!  Meet badBIOS, the mysterious Mac and PC malware that jumps airgaps
Like a super strain of bacteria, the rootkit plaguing Dragos Ruiu is
by Dan Goodin - Oct 31 2013, 3:07pm CET
BLACK HAT HACKING
Aurich Lawson / Thinkstock
Three years ago, security consultant Dragos Ruiu was in his lab when he
noticed something highly unusual: his MacBook Air, on which he had just
installed a fresh copy of OS X, spontaneously updated the firmware that helps
it boot. Stranger still, when Ruiu then tried to boot the machine off a CD
ROM, it refused. He also found that the machine could delete data and undo
configuration changes with no prompting. He didn't know it then, but that odd
firmware update would become a high-stakes malware mystery that would consume
most of his waking hours.
In the following months, Ruiu observed more odd phenomena that seemed
straight out of a science-fiction thriller. A computer running the Open BSD
operating system also began to modify its settings and delete its data
without explanation or prompting. His network transmitted data specific to
the Internet's next-generation IPv6 networking protocol, even from computers
that were supposed to have IPv6 completely disabled. Strangest of all was the
ability of infected machines to transmit small amounts of network data with
other infected machines even when their power cords and Ethernet cables were
unplugged and their Wi-Fi and Bluetooth cards were removed. Further
investigation soon showed that the list of affected operating systems also
included multiple variants of Windows and Linux.
"We were like, 'Okay, we're totally owned,'" Ruiu told Ars. "'We have to
erase all our systems and start from scratch,' which we did. It was a very
painful exercise. I've been suspicious of stuff around here ever since."
In the intervening three years, Ruiu said, the infections have persisted,
almost like a strain of bacteria that's able to survive extreme antibiotic
therapies. Within hours or weeks of wiping an infected computer clean, the
odd behavior would return. The most visible sign of contamination is a
machine's inability to boot off a CD, but other, more subtle behaviors can be
observed when using tools such as Process Monitor, which is designed for
troubleshooting and forensic investigations.
Another intriguing characteristic: in addition to jumping "airgaps" designed
to isolate infected or sensitive machines from all other networked computers,
the malware seems to have self-healing capabilities.
"We had an air-gapped computer that just had its [firmware] BIOS reflashed, a
fresh disk drive installed, and zero data on it, installed from a Windows
system CD," Ruiu said. "At one point, we were editing some of the components
and our registry editor got disabled. It was like: wait a minute, how can
that happen? How can the machine react and attack the software that we're
using to attack it? This is an air-gapped machine and all of the sudden the
search function in the registry editor stopped working when we were using it
to search for their keys."
Over the past two weeks, Ruiu has taken to Twitter, Facebook, and Google Plus
to document his investigative odyssey and share a theory that has captured
the attention of some of the world's foremost security experts. The malware,
Ruiu believes, is transmitted though USB drives to infect the lowest levels
of computer hardware. With the ability to target a computer's Basic
Input/Output System (BIOS), Unified Extensible Firmware Interface (UEFI), and
possibly other firmware standards, the malware can attack a wide variety of
platforms, escape common forms of detection, and survive most attempts to
eradicate it.
But the story gets stranger still. In posts here, here, and here, Ruiu
posited another theory that sounds like something from the screenplay of a
post-apocalyptic movie: "badBIOS," as Ruiu dubbed the malware, has the
ability to use high-frequency transmissions passed between computer speakers
and microphones to bridge airgaps.
Bigfoot in the age of the advanced persistent threat
At times as I've reported this story, its outline has struck me as the stuff
of urban legend, the advanced persistent threat equivalent of a Bigfoot
sighting. Indeed, Ruiu has conceded that while several fellow security
experts have assisted his investigation, none has peer reviewed his process
or the tentative findings that he's beginning to draw. (A compilation of
Ruiu's observations is here.)
Also unexplained is why Ruiu would be on the receiving end of such an
advanced and exotic attack. As a security professional, the organizer of the
internationally renowned CanSecWest and PacSec conferences, and the founder
of the Pwn2Own hacking competition, he is no doubt an attractive target to
state-sponsored spies and financially motivated hackers. But he's no more
attractive a target than hundreds or thousands of his peers, who have so far
not reported the kind of odd phenomena that has afflicted Ruiu's computers
and networks.
In contrast to the skepticism that's common in the security and hacking
cultures, Ruiu's peers have mostly responded with deep-seated concern and
even fascination to his dispatches about badBIOS.
"Everybody in security needs to follow  and watch his analysis of
 Alex Stamos, one of the more trusted and sober security
researchers, wrote in a tweet last week. Jeff Mossthe founder of the Defcon
and Blackhat security conferences who in 2009 began advising Department of
Homeland Security Secretary Janet Napolitano on matters of computer
securityretweeted the statement and added: "No joke it's really serious."
Plenty of others agree.
"Dragos is definitely one of the good reliable guys, and I have never ever
even remotely thought him dishonest," security researcher Arrigo Triulzi told
Ars. "Nothing of what he describes is science fiction taken individually, but
we have not seen it in the wild ever."
Been there, done that
Triulzi said he's seen plenty of firmware-targeting malware in the
laboratory. A client of his once infected the UEFI-based BIOS of his Mac
laptop as part of an experiment. Five years ago, Triulzi himself developed
proof-of-concept malware that stealthily infected the network interface
controllers that sit on a computer motherboard and provide the Ethernet jack
that connects the machine to a network. His research built off of work by
John Heasman that demonstrated how to plant hard-to-detect malware known as a
rootkit in a computer's peripheral component interconnect, the
Intel-developed connection that attaches hardware devices to a CPU.
It's also possible to use high-frequency sounds broadcast over speakers to
send network packets. Early networking standards used the technique, said
security expert Rob Graham. Ultrasonic-based networking is also the subject
of a great deal of research, including this project by scientists at MIT.
Of course, it's one thing for researchers in the lab to demonstrate viable
firmware-infecting rootkits and ultra high-frequency networking techniques.
But as Triulzi suggested, it's another thing entirely to seamlessly fuse the
two together and use the weapon in the real world against a seasoned security
consultant. What's more, use of a USB stick to infect an array of computer
platforms at the BIOS level rivals the payload delivery system found in the
state-sponsored Stuxnet worm unleashed to disrupt Iran's nuclear program. And
the reported ability of badBIOS to bridge airgaps also has parallels to
Flame, another state-sponsored piece of malware that used Bluetooth radio
signals to communicate with devices not connected to the Internet.
"Really, everything Dragos reports is something that's easily within the
capabilities of a lot of people," said Graham, who is CEO of penetration
testing firm Errata Security. "I could, if I spent a year, write a BIOS that
does everything Dragos said badBIOS is doing. To communicate over ultrahigh
frequency sound waves between computers is really, really easy."
Coincidentally, Italian newspapers this week reported that Russian spies
attempted to monitor attendees of last month's G20 economic summit by giving
them memory sticks and recharging cables programmed to intercept their
For most of the three years that Ruiu has been wrestling with badBIOS, its
infection mechanism remained a mystery. A month or two ago, after buying a
new computer, he noticed that it was almost immediately infected as soon as
he plugged one of his USB drives into it. He soon theorized that infected
computers have the ability to contaminate USB devices and vice versa.
"The suspicion right now is there's some kind of buffer overflow in the way
the BIOS is reading the drive itself, and they're reprogramming the flash
controller to overflow the BIOS and then adding a section to the BIOS table,"
he explained.
He still doesn't know if a USB stick was the initial infection trigger for
his MacBook Air three years ago, or if the USB devices were infected only
after they came into contact with his compromised machines, which he said now
number between one and two dozen. He said he has been able to identify a
variety of USB sticks that infect any computer they are plugged into. At next
month's PacSec conference, Ruiu said he plans to get access to expensive USB
analysis hardware that he hopes will provide new clues behind the infection
He said he suspects badBIOS is only the initial module of a multi-staged
payload that has the ability to infect the Windows, Mac OS X, BSD, and Linux
operating systems.
Dragos Ruiu
Julia Wolf
"It's going out over the network to get something or it's going out to the
USB key that it was infected from," he theorized. "That's also the conjecture
of why it's not booting CDs. It's trying to keep its claws, as it were, on
the machine. It doesn't want you to boot another OS it might not have code
for." To put it another way, he said, badBIOS "is the tip of the warhead, as
it were."
Things kept getting fixed
Ruiu said he arrived at the theory about badBIOS's high-frequency networking
capability after observing encrypted data packets being sent to and from an
infected laptop that had no obvious network connection withbut was in close
proximity toanother badBIOS-infected computer. The packets were transmitted
even when the laptop had its Wi-Fi and Bluetooth cards removed. Ruiu also
disconnected the machine's power cord so it ran only on battery to rule out
the possibility it was receiving signals over the electrical connection. Even
then, forensic tools showed the packets continued to flow over the airgapped
machine. Then, when Ruiu removed the internal speaker and microphone
connected to the airgapped machine, the packets suddenly stopped.
With the speakers and mic intact, Ruiu said, the isolated computer seemed to
be using the high-frequency connection to maintain the integrity of the
badBIOS infection as he worked to dismantle software components the malware
relied on.
"The airgapped machine is acting like it's connected to the Internet," he
said. "Most of the problems we were having is we were slightly disabling bits
of the components of the system. It would not let us disable some things.
Things kept getting fixed automatically as soon as we tried to break them. It
was weird."
It's too early to say with confidence that what Ruiu has been observing is a
USB-transmitted rootkit that can burrow into a computer's lowest levels and
use it as a jumping off point to infect a variety of operating systems with
malware that can't be detected. It's even harder to know for sure that
infected systems are using high-frequency sounds to communicate with isolated
machines. But after almost two weeks of online discussion, no one has been
able to rule out these troubling scenarios, either.
"It looks like the state of the art in intrusion stuff is a lot more advanced
than we assumed it was," Ruiu concluded in an interview. "The take-away from
this is a lot of our forensic procedures are weak when faced with challenges
like this. A lot of companies have to take a lot more care when they use
forensic data if they're faced with sophisticated attackers."

@_date: 2013-10-01 13:30:25
@_author: Eugen Leitl 
@_subject: Surveillance 
It's Six Eyes, as Sweden is also part of the big vacuum, due to
special geography.

@_date: 2013-10-01 13:32:46
@_author: Eugen Leitl 
@_subject: [tor-relays] Relay security, re: local network 
Hash: SHA1
That reminds me of a question I've been meaning to ask lately...
Has anyone tried running Tor on top of OSv (
As I understand it, OSv is an ultra-small OS which is Linux
API-compatible and designed for running a single app only atop a
virtualization stack.  For example, it should, in theory, be possible
to run the Tor daemon within a copy of OSv, that would be the only
application running inside of that VM, and it should be running like
greased lightning because it would be the only process running in that VM.
Granted, it is fairly new so I do not believe anyone has done any
serious security analysis of OSv, but it seems like it would be an
ideal candidate for a very high performance Tor node.

@_date: 2013-10-01 16:27:33
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] homomorphic coin value (validatable but 
Thanks for providing the impetus to write down the current state, the
efficient version of which I only figured out a few days ago :)
I have been researching this for a few months on and off, because it seems
like an interesting construct in its own right, a different aspect of
payment privacy (eg for auditable but commercial sensistive information) but
also that other than its direct use it may enable some features that we have
not thought of yet.
I moved it to bitcointalk:
Its efficient finally (after many dead ends): approximately 2x cost of
current in terms of coin size and coin verification cost, however it also
gives some perf advantages back in a different way - necessary changes to
schnorr (EC version of Schnorr based proofs) allow n of n multiparty sigs,
or k of n multiparty sigs for the verification cost and signature size of
one pair of ECS signatures, for n > 2 its a space and efficiency improvement
over current bitcoin.

@_date: 2013-10-01 16:58:00
@_author: Eugen Leitl 
@_subject: [cryptography] The Compromised Internet 
Hash: SHA1
If enough hams (or one sufficiently angry lone ham operator) decide
that this is a problem they'll organize a turkey hunt to triangulate
the operator(s) and politely ask them to stop before the feds get
called in.  The thinking behind this seems to be that the amateur
community has been graciously granted a small portion of the RF
spectrum to experiment with.  People (licensed hams or otherwise) who
do specifically prohibited things within the amateur bands (like
transmitting encrypted traffic or undocumented digital protocols
(which may be indistinguishable from encrypted traffic)) can get some
or all of the amateur band taken away.  A lot of time and effort are
spent every year by ham operators who don't want this, that, or the
other sliver of the amateur band reassigned away from amateur use, and
someone doing something dodgy within those spectra could have
disasterous consequences.
When Project Byzantium was adding amateur radio support for ISC
milestone  these regulations were noted and discussed at length
during initial reasearch.  We also spoke with the ARRL during
development, which expressed similar sentiments about crypto in the
amateur bands (and passing traffic from unlicensed network users over
the amateur band, incidentally).
That would probably fall under jamming, which is definitely against
ham ethics.
The hams I've spoken to seem to, but they also seem to fall into the
camp of "It's on the amateur bands, so if it's something I'd want to
encrypt I'm not going to talk about it while chewing the rag anyway."

@_date: 2013-10-07 10:02:01
@_author: Eugen Leitl 
@_subject: [tor-talk] Silk Road taken down by FBI 
We know that Freedom Hosting platform was compromised, and
dropped malware via a known vulnerability in the TBB.
We do not know how exactly TSR was taken down.
There are reasons to suspect that the official story
might be a parallel construct.
The rise in Tor traffic well predates the events, and seems
to be entirely attributable to C&C traffic of a botnet.

@_date: 2013-10-07 11:25:43
@_author: Eugen Leitl 
@_subject: [tor-talk] Silk Road taken down by FBI 
Let's say you run a piece of buggy PHP code as a hidden service, on a mass hoster allowing easy signups and installation
of own code, with no hard separation of service hosted, and possibly not even firewall the VM traffic, forcing it through Tor.
While it's possible they knew the physical host already,
there are certainly far easier ways to nail your ass, given
the above.
It would be interesting to post a hidden service with actionable
content as a honeypot with everything done right, to see what the parallel construct story would emerge. No, I'm not volunteering.

@_date: 2013-10-07 11:37:56
@_author: Eugen Leitl 
@_subject: Analysis of Silk =?utf-8?B?Um9hZOKAmQ==?= =?utf-8?Q?s?= Historical 
Analysis of Silk Roads Historical Impact on Bitcoin
Oct 3, 2013 Posted By Jonathan Stacke In Featured, News	 Tagged Bitcoin,
Price, Silk Road, Volume	 Comments 11
Silk Road, the online drug bazaar that has eluded authorities and been
ingrained in the bitcoin narrative for years, was shut down yesterday. Ross
Ulbricht was named in the court documents outlining Silk Roads activities,
as were a number of key data points that offer insights into the impact the
worlds most infamous retail website has had on bitcoin.
Ulbricht was caught as a result of human error and excessive risks related to
physical delivery of false identification being delivered to his home address
in San Francisco from Canada. After tracking the package, authorities found
their way to Ulbricht and were able to compile a significant case against him
(more details in the official complaint embedded below). Notably, it does not
appear he was tracked as the result of any underlying flaws with tor, used
for anonymous web browsing, or bitcoin, the only currency accepted on Silk
For years the cloaked narcotics website has found its way into
bitcoin-oriented conversations, but only now are the qualitative and
quantitative data points available to asses Silk Roads true impact on the
fledgling digital currency.
A History of Influence
Facts offered by federal prosecutors overlayed onto bitcoin trading data
tells a convincing story about the intertwined histories of bitcoin and Silk
Road. It appears that a significant portion of bitcoins early traction and
price gains can be traced directly to Silk Road, with that impact waning over
time, most dramatically in the past six months.
On December 30, 2010, bitcoin was traded at $0.30/BTC. The court documents
filed yesterday point to Silk Roads first known publicity occurring via
posts from Ulbricht on internet forums and an explanatory WordPress page
beginning on January 27, 2011. Bitcoin tripled in value, reaching parity with
USD, just two weeks later on February 8.
early 2011
Bitcoin then traded between between $0.65 and $0.80 for the next two months
until interest was reignited by coverage in major publications, including
TIME Magazine and The New York Times. In the weeks following the NYC piece,
bitcoin prices and volume exploded, drawing significant attention from the
media. Notably, Gawker broke a story about the Silk Road itself, pushing up
the last gain of one of bitcoins early bubbles.
As bitcoin reached a remarkable 100x year-to-date growth at $30/BTC on June
7, the relationship between Silk Road and bitcoin would see its first true
test. On June 8, 2011, Senators Charles Shumer and Joe Manchin wrote a letter
to Attorney General Eric Holder, urging him to investigate bitcoin for its
relationship to online narcotics purchases, as well as urge [Holder] to take
immediate action and shut down the Silk Road network. Bitcoin plunged 66% to
$10 over the next three days, trending downward to $2 by November 2011. It
would seem that in 2011, direct use of bitcoin on Silk Road or speculators on
its adoption comprised between 66% and 93% of the currencys value.
2011 bubble
Over the next few months as the calendar rolled over into 2012, once again
coverage from a number of important press outlets like TIME and Wired rallied
enthusiasm for bitcoin, pushing prices up to a stabilized $5 by February.
According to the complaint released yesterday, that is also around the time
Ulbricht began to add features to Silk Road, including the establishment of a
forum and stealth mode for top vendors.
In June of 2012, bitcoin began another rally. By this time, infrastructure in
the bitcoin world had begun to increase dramatically, including the first
bitcoin ASIC companies to begin advertising products and new exchanges being
formed. Gawker ran another story about Silk Road in July 2012, which appears
to have had positive impact on bitcoin prices, though not nearly to the
extent it did previously. The months following proved to be highly
transitional, with Bitcoin Foundation putting a public face on the new
industry and early 2013 seeing the European financial troubles that led to
the climb to $260 in April of this year and unprecedented global attention.
Just a few weeks later the markets would see another test of the relationship
between Bitcoin and Silk Road. Between April 24 and May 1, Silk Road suffered
a series of DDoS attacks that sent bitcoin prices sliding downwards. The
negative price action was timed perfectly with the attacks, indicating a
strong relationship. While the drop was significant at 35% initially before
leveling off around a 25% loss  it was notably lighter than the impact of
negative Silk Road news previously.
april 2013 ddos
Looking at the impact from the most recent news, we see a similar pattern
emerging. Despite being the definitive end of Silk Road, with its founder
detained and the logos of federal agencies plastered across the site, the
impact on bitcoin prices was relatively muted. On the initial news break
USD/BTC rates fell 20-35%, depending on the exchange, before settling around
10-15% lower than before the news shortly thereafter.
October 2013
Quantifiable Impact
Also contained within the filings were a number of aggregate statistics about
Silk Roads transactional volume that shed significant light on how much of
the bitcoin market was built around the companys narcotics trade.
Specifically, the complaint states that sites total revenue between February
2011 and July 2013 was 9.5 million bitcoin. Over that same period
approximately 225 million bitcoin were transacted over the block chain, of
which the 9.5 million in Silk Road sales accounted for just 4%.
Similarly, total exchange volume over the same period was roughly 75 million
bitcoin, making Silk Road approximately 12% of total volume. This, of course,
assumes all bitcoins used for purchases on the site were purchased on
exchanges rather than obtained from in person transactions, mining, earnings,
gifts or reused by sellers to purchase from others on the site.
Important to remember is that these figures are aggregate stats over two
years of revenue. Unless fiat-equivalent sales on Silk Road were growing
exponentially alongside bitcoin exchange rates over the past two years, this
also means the bitcoin volume listed in the filing is front loaded into the
periods when more bitcoins were required for the same fiat equivalent
purchasing power. This coincides with the market reactions that also
indicates a significantly reduced importance of Silk Road on the bitcoin
Looking Forward
The bitcoin markets as a whole seem well poised to move forward. An unknown
has been removed from the ecosystem, but a number of concerns remain.
While bitoin will likely recover, there are probably more than a few
concerned bitcoin users right now. The contents of the filing pertained
almost exclusively to the charges against Ulbricht, but give little insight
into what other information was obtained. Whether or not home addresses or
bitcoin addresses of Silk Road users were retained in some way is still
unclear and the extent to which such matters are prosecutable has yet to be
There is also a strong likelihood of copycat sites arising. While the recent
action may deter US citizens, Silk Road was known for its global reach,
meaning an aspiring entrepreneur could run a similar company from anywhere in
the world. The business model is proven and the technology still apparently
sound and repeatable. The downfall was related to human error, which was
clearly outlined in the filing, creating an advanced watchlist for the next
person to avoid. The barriers to entry are remarkably low and now paired with
a known surplus of both demand and supply in the marketplace.
While Silk Roads early impact on digital currency appears to have been quite
significant, any new participant at this stage will likely encounter the same
decreasing importance to the broader bitcoin ecosystem.

@_date: 2013-10-07 12:43:36
@_author: Eugen Leitl 
@_subject: Russia to monitor 'all communications' at Winter Olympics in Sochi 
Russia to monitor 'all communications' at Winter Olympics in Sochi
Exclusive: Investigation uncovers FSB surveillance system  branded 'Prism on
steroids'  to listen to all athletes and visitors
Shaun Walker in Moscow
The Guardian, Sunday 6 October 2013 15.31 BST
Sochi, venue for 2014 Winter Olympics
The Black Sea resort of Sochi has apparently been wired so that the FSB can
log all visitor communications. Photograph: Ignat Kozlov/AP
Athletes and spectators attending the Winter Olympics in Sochi in February
will face some of the most invasive and systematic spying and surveillance in
the history of the Games, documents shared with the Guardian show.
Russia's powerful FSB security service plans to ensure that no communication
by competitors or spectators goes unmonitored during the event, according to
a dossier compiled by a team of Russian investigative journalists looking
into preparations for the 2014 Games.
In a ceremony on Red Square on Sunday afternoon, the president, Vladimir
Putin, held the Olympic flame aloft and sent it on its epic journey around
the country, saying Russia and its people had always been imbued with the
qualities of "openness and friendship", making Sochi the perfect destination
for the Olympics.
But government procurement documents and tenders from Russian communication
companies indicate that newly installed telephone and internet spying
capabilities will give the FSB free rein to intercept any telephony or data
traffic and even track the use of sensitive words or phrases mentioned in
emails, webchats and on social media.
The journalists, Andrei Soldatov and Irina Borogan, who are experts on the
Russian security services, collated dozens of open source technical documents
published on the Zakupki government procurement agency website, as well as
public records of government oversight agencies. They found that major
amendments have been made to telephone and Wi-Fi networks in the Black Sea
resort to ensure extensive and all-permeating monitoring and filtering of all
traffic, using Sorm, Russia's system for intercepting phone and internet
Putin at a Sochi Olympic flame ceremony in Moscow on Sunday. Photograph: Ivan
The Sorm system is being modernised across Russia, but particular attention
has been paid to Sochi given the large number of foreign visitors expected
next year. Technical specifications set out by the Russian state telecoms
agency also show that a controversial technology known as deep packet
inspection, which allows intelligence agencies to filter users by particular
keywords, is being installed across Russia's networks, and is required to be
compatible with the Sorm system.
"For example you can use the keyword Navalny, and work out which people in a
particular region are using the word Navalny," says Soldatov, referring to
Alexei Navalny, Russia's best-known opposition politician. "Then, those
people can be tracked further."
Ron Deibert, a professor at the University of Toronto and director of Citizen
Lab, which co-operated with the Sochi research, describes the Sorm amendments
as "Prism on steroids", referring to the programme used by the NSA in the US
and revealed to the Guardian by the whistleblower Edward Snowden. "The scope
and scale of Russian surveillance are similar to the disclosures about the US
programme but there are subtle differences to the regulations," says Deibert.
"We know from Snowden's disclosures that many of the checks were weak or
sidestepped in the US, but in the Russian system permanent access for Sorm is
a requirement of building the infrastructure."
"Even as recently as the Beijing Olympics, the sophistication of surveillance
and tracking capabilities were nowhere near where they are today."
Gus Hosein, executive director of Privacy International, which also
co-operated with the research, said: "Since 2008, more people are travelling
with smartphones with far more data than back then, so there is more to spy
Wary of Sorm's capabilities, earlier this year a leaflet from the US state
department's bureau of diplomatic security warned anyone travelling to the
Games to be extremely cautious with communications.
"Business travellers should be particularly aware that trade secrets,
negotiating positions, and other sensitive information may be taken and
shared with competitors, counterparts, and/or Russian regulatory and legal
entities," the document reads. The advice contains an extraordinary list of
precautions for visitors who wish to ensure safe communications, such as
removing batteries from phones when not in use and only travelling with
"clean" devices.
Soldatov and Borogan have discovered that the FSB has been working since 2010
to upgrade the Sorm system to ensure it can cope with the extra traffic
during the Games. All telephone and ISP providers have to install Sorm boxes
in their technology by law, and once installed, the FSB can access data
without the provider ever knowing, meaning every phone call or internet
communication can be logged. Although the FSB technically requires a warrant
to intercept a communication, it is not obliged to show it to anyone.
Tellingly, the FSB has appointed one of its top counterintelligence chiefs,
Oleg Syromolotov, to be in charge at Sochi: security will thus be overseen by
someone who has spent his career chasing foreign spies rather than
Another target may well be gay rights, likely to be one of the biggest issues
of the Games. Putin has said that competitors who wear rainbow pins, for
example, will not be arrested under the country's controversial new law that
bans "homosexual propaganda". However, it is likely that any attempts to
stage any kind of rally or gathering to support gay rights will be ruthlessly
broken up by police, as has been the case on numerous occasions in Russian
cities in the past. Using DPI, Russian authorities will be able to identify,
tag and follow all visitors to the Olympics, both Russian and foreign, who
are discussing gay issues, and possibly planning to organise protests.
"Athletes may have particular political views, or they may be openly gay,"
says Deibert. "I think given recent developments in Russia, we have to be
worried about these issues."
At a rare FSB press conference this week, an official, Alexei Lavrishchev,
denied security and surveillance at the Games would be excessive, and said
that the London Olympics featured far more intrusive measures. "There, they
even put CCTV cameras in, excuse me for saying it, the toilets," said
Lavrishchev. "We are not taking this kind of measure."
The FSB did not respond to a request for comment from the Guardian, while a
spokesperson for the Sochi Olympics referred all requests to the security
services. But Russian authorities often express a belief that NGOs working on
human rights and other issues have subversive agendas dictated from abroad,
and the FSB apparently feels that with so many potentially dangerous
foreigners descending on the Black Sea resort for the Olympics, it has a duty
to keep an eye on them.
In the end, the goal is overarching, but simple, says Soldatov: "Russian
authorities want to make sure that every connection and every move made
online in Sochi during the Olympics will be absolutely transparent to the
secret services of the country."

@_date: 2013-10-07 13:18:17
@_author: Eugen Leitl 
@_subject: [tor-talk] Freenet and hidden services 
Hash: SHA512
I consider Tahoe-LAFS to be the (current) best solution for this. It
provides a distributed data store, which can be used for hosting (with
a Javascript "web server"). I know Tahoe works with Tor via SOCKS but
I don't personally know of any active networks. Tahoe has been used in
I2P as a distributed data store for a long time, and there are several
"deepsites" hosted in it. We are actively working to make Tahoe
integrate better with Tor/I2P.
Zooko recently posted a *much* better summary of this:

@_date: 2013-10-07 13:55:36
@_author: Eugen Leitl 
@_subject: <nettime> A CEO who resisted NSA spying is out of prison. 
A good point. I deal with that by
alternative_order text/plain text/html text/enrichened
auto_view text/html
which calls links via /etc/mailcap
text/plain; less '%s'; needsterminal
text/html; /usr/bin/sensible-browser '%s'; description=HTML Text; nametemplate=%s.html
How exploitable is /usr/bin/links?

@_date: 2013-10-07 16:50:38
@_author: Eugen Leitl 
@_subject: interesting commercial cjdns project: Enigmabox 
Just came across  which is a commercial
project using cjdns/Hyperboria for transport and offers end to end encrypted VoIP and operates http (and more?) exits.
The hardware seems to be PCEngines ALIX. It doesn't ship
with Tor, but Tor can be used with it. Don't see any open
source, but users are getting root access on the system.

@_date: 2013-10-07 17:16:29
@_author: Eugen Leitl 
@_subject: Bruce Schneier on the good, old air gap 
Want to Evade NSA Spying? Dont Connect to the Internet
BY BRUCE SCHNEIER 10.07.13 6:30 AM
Photo: Ariel Zambelich / WIRED; Illustration: Ross Patton / WIRED
Since I started working with Snowdens documents, I have been using a number
of tools to try to stay secure from the NSA. The advice I shared included
using Tor, preferring certain cryptography over others, and using
public-domain encryption wherever possible.
I also recommended using an air gap, which physically isolates a computer or
local network of computers from the internet. (The name comes from the
literal gap of air between the computer and the internet; the word predates
wireless networks.)
But this is more complicated than it sounds, and requires explanation.
Since we know that computers connected to the internet are vulnerable to
outside hacking, an air gap should protect against those attacks. There are a
lot of systems that use  or should use  air gaps: classified military
networks, nuclear power plant controls, medical equipment, avionics, and so
Osama Bin Laden used one. I hope human rights organizations in repressive
countries are doing the same.
Air gaps might be conceptually simple, but theyre hard to maintain in
practice. The truth is that nobody wants a computer that never receives files
from the internet and never sends files out into the internet. What they want
is a computer thats not directly connected to the internet, albeit with some
secure way of moving files on and off.
But every time a file moves back or forth, theres the potential for attack.
And air gaps have been breached. Stuxnet was a U.S. and Israeli
military-grade piece of malware that attacked the Natanz nuclear plant in
Iran. It successfully jumped the air gap and penetrated the Natanz network.
Another piece of malware named agent.btz, probably Chinese in origin,
successfully jumped the air gap protecting U.S. military networks.
These attacks work by exploiting security vulnerabilities in the removable
media used to transfer files on and off the air gapped computers.
Bruce Schneier is a security technologist and author. His latest book is
Liars and Outliers: Enabling the Trust Society Needs to Survive.
Since working with Snowdens NSA files, I have tried to maintain a single
air-gapped computer. It turned out to be harder than I expected, and I have
ten rules for anyone trying to do the same:
1. When you set up your computer, connect it to the internet as little as
possible. Its impossible to completely avoid connecting the computer to the
internet, but try to configure it all at once and as anonymously as possible.
I purchased my computer off-the-shelf in a big box store, then went to a
friends network and downloaded everything I needed in a single session. (The
ultra-paranoid way to do this is to buy two identical computers, configure
one using the above method, upload the results to a cloud-based anti-virus
checker, and transfer the results of that to the air gap machine using a
one-way process.)
2. Install the minimum software set you need to do your job, and disable all
operating system services that you wont need. The less software you install,
the less an attacker has available to exploit. I downloaded and installed
OpenOffice, a PDF reader, a text editor, TrueCrypt, and BleachBit. Thats
all. (No, I dont have any inside knowledge about TrueCrypt, and theres a
lot about it that makes me suspicious. But for Windows full-disk encryption
its that, Microsofts BitLocker, or Symantecs PGPDisk  and I am more
worried about large U.S. corporations being pressured by the NSA than I am
about TrueCrypt.)
3. Once you have your computer configured, never directly connect it to the
internet again. Consider physically disabling the wireless capability, so it
doesnt get turned on by accident.
4. If you need to install new software, download it anonymously from a random
network, put it on some removable media, and then manually transfer it to the
air gapped computer. This is by no means perfect, but its an attempt to make
it harder for the attacker to target your computer.
5. Turn off all auto-run features. This should be standard practice for all
the computers you own, but its especially important for an air-gapped
computer. Agent.btz used autorun to infect U.S. military computers.
6. Minimize the amount of executable code you move onto the air-gapped
computer. Text files are best. Microsoft Office files and PDFs are more
dangerous, since they might have embedded macros. Turn off all macro
capabilities you can on the air-gapped computer. Dont worry too much about
patching your system; in general, the risk of the executable code is worse
than the risk of not having your patches up to date. Youre not on the
internet, after all.
7. Only use trusted media to move files on and off air-gapped computers. A
USB stick you purchase from a store is safer than one given to you by someone
you dont know  or one you find in a parking lot.
8. For file transfer, a writable optical disk (CD or DVD) is safer than a USB
stick. Malware can silently write data to a USB stick, but it cant spin the
CD-R up to 1000 rpm without your noticing. This means that the malware can
only write to the disk when you write to the disk. You can also verify how
much data has been written to the CD by physically checking the back of it.
If youve only written one file, but it looks like three-quarters of the CD
was burned, you have a problem. Note: the first company to market a USB stick
with a light that indicates a write operation  not read or write; Ive got
one of those  wins a prize.
9. When moving files on and off your air-gapped computer, use the absolute
smallest storage device you can. And fill up the entire device with random
files. If an air-gapped computer is compromised, the malware is going to try
to sneak data off it using that media. While malware can easily hide stolen
files from you, it cant break the laws of physics. So if you use a tiny
transfer device, it can only steal a very small amount of data at a time. If
you use a large device, it can take that much more. Business-card-sized
mini-CDs can have capacity as low as 30 MB. I still see 1-GB USB sticks for
10. Consider encrypting everything you move on and off the air-gapped
computer. Sometimes youll be moving public files and it wont matter, but
sometimes you wont be, and it will. And if youre using optical media, those
disks will be impossible to erase. Strong encryption solves these problems.
And dont forget to encrypt the computer as well; whole-disk encryption is
the best.
One thing I didnt do, although its worth considering, is use a stateless
operating system like Tails. You can configure Tails with a persistent volume
to save your data, but no operating system changes are ever saved. Booting
Tails from a read-only DVD  you can keep your data on an encrypted USB stick
 is even more secure. Of course, this is not foolproof, but it greatly
reduces the potential avenues for attack.
Yes, all this is advice for the paranoid. And its probably impossible to
enforce for any network more complicated than a single computer with a single
user. But if youre thinking about setting up an air-gapped computer, you
already believe that some very powerful attackers are after you personally.
If youre going to use an air gap, use it properly.
Of course you can take things further. I have met people who have physically
removed the camera, microphone, and wireless capability altogether. But
thats too much paranoia for me right now.

@_date: 2013-10-07 23:55:49
@_author: Eugen Leitl 
@_subject: Bruce Schneier on the good, old air gap 
That advice is not exactly targeted towards Jane Doe. Some people don't have mobile phones. Others leave them at home,
or remove the power pack when it matters.
No. You just need to buy an offline machine, e.g. a used notebook. Separation by air gap was SOP in the intelligence community before virtualization allowed to separate trust compartments in one machine.
I trust air gap much more than hypervisors.
I don't understand the problem. Bruce gave good basic opsec advice,
what's the problem with following it up in practice but to tamper-proof
against evil maid attacks?

@_date: 2013-10-08 17:15:50
@_author: Eugen Leitl 
@_subject: Feds Arrest Alleged Top Silk Road Drug Seller 
Feds Arrest Alleged Top Silk Road Drug Seller
Federal authorities last week arrested a Washington state man accused of
being one of the most active and sought-after drug dealers on the online
black market known as the Silk Road. Meanwhile, new details about the
recent coordinated takedown of the Silk Road became public, as other former
buyers and sellers on the fraud bazaar pondered who might be next and whether
competing online drug markets will move in to fill the void.
NOD's feedback from Silk Road buyers, according to the government. A complaint unsealed Oct. 2 by the U.S. District Court for the Western
District of Washington at Seattle alleges that Steven Lloyd Sadler, 40, of
Bellevue, Wash., used the nickname NOD on the Silk Road, and was among the
top one percent of sellers on the Silk Road, selling high-quality cocaine,
heroin and methamphetamine in small, individual-use amounts to hundreds of
buyers around the world.
Investigators with the FBI and U.S. Post Office inspectors say they tracked
dozens of packages containing drugs allegedly shipped by Sadler and a woman
who was living with him at the time of his arrest. Authorities tied Sadler to
the Silk Road after intercepting a package of cocaine and heroin destined for
an Alaskan resident. That resident agreed to cooperate with authorities in
the hopes of reducing his own sentence, and said hed purchased the drugs
from NOD via the Silk Road.
Agents in Seattle sought and were granted permission to place GPS tracking
devices on Sadlers car and that of his roommate, Jenna White, also charged
in this case. Investigators allege that the tracking showed the two traveled
to at least 38 post offices in the Seattle area during the surveillance
Interestingly, the investigators used the feedback on NODs Silk Road seller
profile to get a sense of the volume of drugs he sold. Much like eBay
sellers, merchants on the Silk Road are evaluated by previous buyers, who are
encouraged to leave feedback about the quality of the sellers goods and
services. According to the government, NOD had 1,400 reviews for individual
sales/purchases of small amounts of drugs, including: 2,269.5 grams of
cocaine, 593 grams of heroin and 105 grams of meth. The complaint notes that
these amounts dont count sales going back more than five months prior to the
investigation, when NOD first created his Silk Road vendor account.
Cryptome has published a copy of the complaint (PDF) against Sadler. A copy
of Sadlers case docket is here. NODs reputation on the Silk Road also was
discussed for several months on this Reddit thread.
Many readers of last weeks story on the Silk Road takedown have been asking
what is known about the locations of the Silk Road servers that were copied
by the FBI. Its still unclear how agents gained access to those servers, but
a civil forfeiture complaint released by the Justice Department shows that
they were aware of five, geographically dispersed servers that were
supporting the Silk Road, either by directly hosting the site and/or hosting
the Bitcoin wallets that the Silk Road maintains for buyers and sellers.
Two of those servers were located in Iceland, one in Latvia, another in
Switzerland, and apparently one in the United States. See the map above.
As if the subset of Bitcoin users who frequented the Silk Road already didnt
have enough to worry about, there are indications that the individual(s)
responsible for creating a competing Tor-based drug market  SheepMarketplace
 may have made some missteps that could make it easier for authorities to
discover the true location of that fraud bazaar as well. Check out this
Reddit thread for more on that.
Also, there are some indications that a Silk Road 2.0 is in the works, at
least according to DailyGadgetry.com. If that doesnt work out, perhaps
would-be future Dread Pirate Robertses will turn to Bitwasp, a budding Github
project which aims to provide open source code for setting up standalone
markets using Bitcoin.
I think what youre going to see is that a lot of me-too communities spring
up and get squished pretty quickly, said Nicholas Weaver, a researcher at
the International Computer Science Institute (ICSI) and at University of
California San Diego. Part of the reason why the Silk Road was so useful was
that it was so popular, and a half dozen smaller markets could be far less
efficient than these larger markets. But personally, Im betting well soon
see a fair number of them.
Finally, it seems a large number of Bitcoin users have been spending tiny
fractions of their coinage to send messages to the FBIs Bitcoin address on
Blockchain. Some of the love letters to the FBI are amusing, such as, All
your Bitcoins are belong to us, while others sound a defiant tone, including
this one: One star is born as another fades away. Which one will come next?
is my favorite riddle. Said a girl puffing rings in a dot, dot, dash haze.
No worry, No hurry. They cant stop the signal.
Update, Oct. 8, 2013: The BBC is reporting that four men have been arrested
in the U.K. for alleged drug offenses on the Silk Road, and that more arrests
are expected in the coming weeks. The BBC quotes the U.K. National Crime
Agency as saying such sites would are a key priority.

@_date: 2013-10-09 11:37:07
@_author: Eugen Leitl 
@_subject: Attacking Tor: how the NSA targets users' online anonymity 
(Use VM jails with amnesiac distros like Tails for daily browsing, separate security compartments using CubeOS and related, use air gap with USB sneakernet (using *nix with no USB autorun) to encrypt/decrypt and maintain sensitive information in general).
Attacking Tor: how the NSA targets users' online anonymity
Secret servers and a privileged position on the internet's backbone used to
identify users and attack target computers
Bruce Schneier
theguardian.com, Friday 4 October 2013 15.50 BST
Tor is a well-designed and robust anonymity tool, and successfully attacking
it is difficult. Photograph: Magdalena Rehova/Alamy
The online anonymity network Tor is a high-priority target for the National
Security Agency. The work of attacking Tor is done by the NSA's application
vulnerabilities branch, which is part of the systems intelligence
directorate, or SID. The majority of NSA employees work in SID, which is
tasked with collecting data from communications systems around the world.
According to a top-secret NSA presentation provided by the whistleblower
Edward Snowden, one successful technique the NSA has developed involves
exploiting the Tor browser bundle, a collection of programs designed to make
it easy for people to install and use the software. The trick identified Tor
users on the internet and then executes an attack against their Firefox web
The NSA refers to these capabilities as CNE, or computer network
The first step of this process is finding Tor users. To accomplish this, the
NSA relies on its vast capability to monitor large parts of the internet.
This is done via the agency's partnership with US telecoms firms under
programs codenamed Stormbrew, Fairview, Oakstar and Blarney.
The NSA creates "fingerprints" that detect http requests from the Tor network
to particular servers. These fingerprints are loaded into NSA database
systems like XKeyscore, a bespoke collection and analysis tool which NSA
boasts allows its analysts to see "almost everything" a target does on the
Using powerful data analysis tools with codenames such as Turbulence, Turmoil
and Tumult, the NSA automatically sifts through the enormous amount of
internet traffic that it sees, looking for Tor connections.
Last month, Brazilian TV news show Fantastico showed screenshots of an NSA
tool that had the ability to identify Tor users by monitoring internet
The very feature that makes Tor a powerful anonymity service, and the fact
that all Tor users look alike on the internet, makes it easy to differentiate
Tor users from other web users. On the other hand, the anonymity provided by
Tor makes it impossible for the NSA to know who the user is, or whether or
not the user is in the US.
After identifying an individual Tor user on the internet, the NSA uses its
network of secret internet servers to redirect those users to another set of
secret internet servers, with the codename FoxAcid, to infect the user's
computer. FoxAcid is an NSA system designed to act as a matchmaker between
potential targets and attacks developed by the NSA, giving the agency
opportunity to launch prepared attacks against their systems.
Once the computer is successfully attacked, it secretly calls back to a
FoxAcid server, which then performs additional attacks on the target computer
to ensure that it remains compromised long-term, and continues to provide
eavesdropping information back to the NSA.
Exploiting the Tor browser bundle
Tor is a well-designed and robust anonymity tool, and successfully attacking
it is difficult. The NSA attacks we found individually target Tor users by
exploiting vulnerabilities in their Firefox browsers, and not the Tor
application directly.
This, too, is difficult. Tor users often turn off vulnerable services like
scripts and Flash when using Tor, making it difficult to target those
services. Even so, the NSA uses a series of native Firefox vulnerabilities to
attack users of the Tor browser bundle.
According to the training presentation provided by Snowden,
EgotisticalGiraffe exploits a type confusion vulnerability in E4X, which is
an XML extension for Javascript. This vulnerability exists in Firefox 11.0 
16.0.2, as well as Firefox 10.0 ESR  the Firefox version used until recently
in the Tor browser bundle. According to another document, the vulnerability
exploited by EgotisticalGiraffe was inadvertently fixed when Mozilla removed
the E4X library with the vulnerability, and when Tor added that Firefox
version into the Tor browser bundle, but NSA were confident that they would
be able to find a replacement Firefox exploit that worked against version
17.0 ESR.
The Quantum system
To trick targets into visiting a FoxAcid server, the NSA relies on its secret
partnerships with US telecoms companies. As part of the Turmoil system, the
NSA places secret servers, codenamed Quantum, at key places on the internet
backbone. This placement ensures that they can react faster than other
websites can. By exploiting that speed difference, these servers can
impersonate a visited website to the target before the legitimate website can
respond, thereby tricking the target's browser to visit a Foxacid server.
In the academic literature, these are called "man-in-the-middle" attacks, and
have been known to the commercial and academic security communities. More
specifically, they are examples of "man-on-the-side" attacks.
They are hard for any organization other than the NSA to reliably execute,
because they require the attacker to have a privileged position on the
internet backbone, and exploit a "race condition" between the NSA server and
the legitimate website. This top-secret NSA diagram, made public last month,
shows a Quantum server impersonating Google in this type of attack.
The NSA uses these fast Quantum servers to execute a packet injection attack,
which surreptitiously redirects the target to the FoxAcid server. An article
in the German magazine Spiegel, based on additional top secret Snowden
documents, mentions an NSA developed attack technology with the name of
QuantumInsert that performs redirection attacks. Another top-secret Tor
presentation provided by Snowden mentions QuantumCookie to force cookies onto
target browsers, and another Quantum program to "degrade/deny/disrupt Tor
This same technique is used by the Chinese government to block its citizens
from reading censored internet content, and has been hypothesized as a
probable NSA attack technique.
The FoxAcid system
According to various top-secret documents provided by Snowden, FoxAcid is the
NSA codename for what the NSA calls an "exploit orchestrator," an
internet-enabled system capable of attacking target computers in a variety of
different ways. It is a Windows 2003 computer configured with custom software
and a series of Perl scripts. These servers are run by the NSA's tailored
access operations, or TAO, group. TAO is another subgroup of the systems
intelligence directorate.
The servers are on the public internet. They have normal-looking domain
names, and can be visited by any browser from anywhere; ownership of those
domains cannot be traced back to the NSA.
However, if a browser tries to visit a FoxAcid server with a special URL,
called a FoxAcid tag, the server attempts to infect that browser, and then
the computer, in an effort to take control of it. The NSA can trick browsers
into using that URL using a variety of methods, including the race-condition
attack mentioned above and frame injection attacks.
FoxAcid tags are designed to look innocuous, so that anyone who sees them
would not be suspicious. An example of one such tag [LINK REMOVED] is given
in another top-secret training presentation provided by Snowden.
There is no currently registered domain name by that name; it is just an
example for internal NSA training purposes.
The training material states that merely trying to visit the homepage of a
real FoxAcid server will not result in any attack, and that a specialized URL
is required. This URL would be created by TAO for a specific NSA operation,
and unique to that operation and target. This allows the FoxAcid server to
know exactly who the target is when his computer contacts it.
According to Snowden, FoxAcid is a general CNE system, used for many types of
attacks other than the Tor attacks described here. It is designed to be
modular, with flexibility that allows TAO to swap and replace exploits if
they are discovered, and only run certain exploits against certain types of
The most valuable exploits are saved for the most important targets.
Low-value exploits are run against technically sophisticated targets where
the chance of detection is high. TAO maintains a library of exploits, each
based on a different vulnerability in a system. Different exploits are
authorized against different targets, depending on the value of the target,
the target's technical sophistication, the value of the exploit, and other
In the case of Tor users, FoxAcid might use EgotisticalGiraffe against their
Firefox browsers.
FoxAcid servers also have sophisticated capabilities to avoid detection and
to ensure successful infection of its targets. One of the top-secret
documents provided by Snowden demonstrates how FoxAcid can circumvent
commercial products that prevent malicious software from making changes to a
system that survive a reboot process.
According to a top-secret operational management procedures manual provided
by Snowden, once a target is successfully exploited it is infected with one
of several payloads. Two basic payloads mentioned in the manual, are designed
to collect configuration and location information from the target computer so
an analyst can determine how to further infect the computer.
These decisions are made in part by the technical sophistication of the
target and the security software installed on the target computer; called
Personal Security Products or PSP, in the manual.
FoxAcid payloads are updated regularly by TAO. For example, the manual refers
to version 8.2.1.1 of one of them.
FoxAcid servers also have sophisticated capabilities to avoid detection and
to ensure successful infection of its targets. The operations manual states
that a FoxAcid payload with the codename DireScallop can circumvent
commercial products that prevent malicious software from making changes to a
system that survive a reboot process.
The NSA also uses phishing attacks to induce users to click on FoxAcid tags.
TAO additionally uses FoxAcid to exploit callbacks  which is the general
term for a computer infected by some automatic means  calling back to the
NSA for more instructions and possibly to upload data from the target
According to a top-secret operational management procedures manual, FoxAcid
servers configured to receive callbacks are codenamed FrugalShot. After a
callback, the FoxAcid server may run more exploits to ensure that the target
computer remains compromised long term, as well as install "implants"
designed to exfiltrate data.
By 2008, the NSA was getting so much FoxAcid callback data that they needed
to build a special system to manage it all.

@_date: 2013-10-10 10:36:44
@_author: Eugen Leitl 
@_subject: NSA data centre power surges & unknowns... 
You obviously have to consider not just the known unknowns, but also
unknown unknowns. FWIW, I much doubt they can factor large numbers with QC (if you want to make sure, do a lit review on QC,
pull up the list of names, and see whether some of them suddenly
stopped publishing, or greatly reduced their publishing rate), but public key cryptosystems do have a slight smell about them lately.
We definitely need more diversity in cryptosystems, and should revert
to systems which are more well-understood, and focus on future systems
that are simple to analyze.

@_date: 2013-10-10 14:13:36
@_author: Eugen Leitl 
@_subject: Cryptographers condemn US =?utf-8?Q?Nation?= 
but mathematicians shrug.
Researchers split over NSA hacking
Cryptographers condemn US National Security Agencys tapping and tampering,
but mathematicians shrug.
Ann Finkbeiner 08 October 2013
The National Security Agency is the largest employer of mathematicians in the
United States.
PATRICK SEMANSKY/ASSOCIATED PRESS
The US National Security Agency (NSA) has upset a great many people this
year. Since June, newspapers have been using documents leaked by former
intelligence worker Edward Snowden to show how the secretive but powerful
agency has spied on the communications of US citizens and foreign
governments. Last month, the media reported that the NSA, which is based in
Fort Meade, Maryland, had undermined Internet security standards. The
revelations have sparked international outrage at the highest levels  even
the president of Brazil cancelled a visit to the United States because of the
Yet amid the uproar, NSA-supported mathematicians and computer scientists
have remained mostly quiet, to the growing frustration of others in similar
fields. Most have never met a funding source they do not like, says Phillip
Rogaway, a computer scientist at the University of California, Davis, who has
sworn not to accept NSA funding and is critical of other researchers
silence. And most of us have little sense of social responsibility.
Mathematicians and the NSA are certainly interdependent. The agency declares
that it is the United States largest maths employer, and Samuel Rankin,
director of the Washington DC office of the American Mathematical Society,
estimates that the agency hires 3040 mathematicians every year. The NSA
routinely holds job fairs on university campuses, and academic researchers
can work at the agency on sabbaticals. In 2013, the agencys mathematical
sciences programme offered more than US$3.3 million in research grants.
Furthermore, the NSA has designated more than 150 colleges and universities
as centres of excellence, which qualifies students and faculty members for
extra support. It can also fund research indirectly through other agencies,
and so the total amount of support may be much higher. A leaked budget
document says that the NSA spends more than $400 million a year on research
and technology  although only a fraction of this money might go to research
outside the agency itself.
I understand whats in the newspapers, but the NSA is funding serious
long-term fundamental research and Im happy theyre doing it. Many US
researchers, especially those towards the basic-research end of the spectrum,
are comfortable with the NSAs need for their expertise. Christopher Monroe,
a physicist at the University of Maryland in College Park, is among them. He
previously had an NSA grant for basic research on controlling cold atoms,
which can form the basis of the qubits of information in quantum computers.
He notes that he is free to publish in the open literature, and he has no
problems with the NSA research facilities in physical sciences,
telecommunications and languages that sit on his campus. Monroe is
sympathetic to the NSAs need to track the development of quantum computers
that could one day be used to crack codes beyond the ability of conventional
machines. I understand whats in the newspapers, he says, but the NSA is
funding serious long-term fundamental research and Im happy theyre doing
Dena Tsamitis, director of education, outreach and training at Carnegie
Mellon Universitys cybersecurity research centre in Pittsburgh,
Pennsylvania, also wants to maintain the relationship. She oversees visitors
and recruiters from the NSA but her centre gets no direct funding. She says
that her graduate students understand the NSAs public surveillance to be a
policy decision, not a technology decision. Our students are most interested
in the technology. And the NSA, she says  echoing many other researchers 
has very interesting technology problems.
The academics who are professionally uneasy with the NSA tend to lie on the
applied end of the spectrum: they work on computer security and cryptography
rather than pure mathematics and basic physics. Matthew Green, a
cryptographer at Johns Hopkins University in Baltimore, Maryland, says that
these researchers are unsettled in part because they are dependent on
protocols developed by the US National Institute of Standards and Technology
(NIST) to govern most encrypted web traffic. When it was revealed that the
NSA had inserted a back door into the NIST standards to allow snooping,
some of them felt betrayed. We certainly had no idea that they were
tampering with products or standards, says Green. He is one of 47
technologists who on 4 October sent a letter to the director of a group
created last month by US President Barack Obama to review NSA practices,
protesting because the group does not include any independent technologists.
Edward Felten, who studies computer security at Princeton University in New
Jersey, says that the NSAs breach of security standards means that
cryptographers will need to change what they call their threat model  the
set of assumptions about possible attacks to guard against. Now the attacks
might come from the home team. There was a sense of certain lines that NSA
wouldnt cross, says Felten, and now were not so sure about that.
Nature 502, 152 (10 October 2013) doi:10.1038/502152a

@_date: 2013-10-11 13:42:13
@_author: Eugen Leitl 
@_subject: who are the service operators here? 
I think we need more hidden services to make the darknet more attractive,
less exits. The open Internet has been dead for a while, time to accept it.
Running a non-exit relay from home is still worthwhile, since it raises the bar for physical access, and also increases the traffic background.
Decentral search is pretty important, we could really use lots of
YaCy nodes as hidden services -- indexing not just the hidden web, of
I wish there was a library of different privacy-based appliances in
virtual formats (.ovf) which are kept up to date for easy deployment
(even though running it on bare iron would be preferable). That would
seem to be a lot of work, though, and run into trust issues.

@_date: 2013-10-11 17:53:25
@_author: Eugen Leitl 
@_subject: who are the service operators here? 
Their official position IIRC is that they discourage VM use,
so they might not want to offer a virtual appliance.
While they're technically correct, there's value in virtual
network plumbing, so you can build up separated compartments, and
routers which force everything through Tor.
It would reduce the threshold of entry, even though there
are ways of detecting that you're running in a hypervisor
jail, and break out of it.

@_date: 2013-10-12 11:28:36
@_author: Eugen Leitl 
@_subject: who are the service operators here? 
Certainly nice growth, but realistically won't be sustained post-Snowden.
Most-used services on the Internet is search, and there's just one
useful search engine in onionland: 3g2upl4pq6kufc4m.onion and it's
not operated by multiple, independent, noncommercial parties.

@_date: 2013-10-14 15:36:14
@_author: Eugen Leitl 
@_subject: funding Tor development 
Guys, in order to minimize Tor Project's dependance on
federal funding and/or increase what they can do it
would be great to have some additional funding ~10 kUSD/month.
If anyone is aware of anyone who can provide funding at
that level or higher, please contact execdir at torproject.org

@_date: 2013-10-14 20:15:42
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
The worst is that the entire trainwreck has been so
predictable, right from the start.

@_date: 2013-10-15 09:50:12
@_author: Eugen Leitl 
@_subject: NSA collects millions of e-mail address books globally 
NSA collects millions of e-mail address books globally
Video: In June, President Obama said the NSAs email collecting program does
not apply to U.S. citizens.
By Barton Gellman and Ashkan Soltani, Tuesday, October 15, 12:53 AM E-mail
the writer
The National Security Agency is harvesting hundreds of millions of contact
lists from personal e-mail and instant messaging accounts around the world,
many of them belonging to Americans, according to senior intelligence
officials and top-secret documents provided by former NSA contractor Edward
The collection program, which has not been disclosed before, intercepts
e-mail address books and buddy lists from instant messaging services as
they move across global data links. Online services often transmit those
contacts when a user logs on, composes a message, or synchronizes a computer
or mobile device with information stored on remote servers.
Rather than targeting individual users, the NSA is gathering contact lists in
large numbers that amount to a sizable fraction of the worlds e-mail and
instant messaging accounts. Analysis of that data enables the agency to
search for hidden connections and to map relationships within a much smaller
universe of foreign intelligence targets.
During a single day last year, the NSAs Special Source Operations branch
collected 444,743 e-mail address books from Yahoo, 105,068 from Hotmail,
82,857 from Facebook, 33,697 from Gmail and 22,881 from unspecified other
providers, according to an internal NSA PowerPoint presentation. Those
figures, described as a typical daily intake in the document, correspond to a
rate of more than 250million a year.
Each day, the presentation said, the NSA collects contacts from an estimated
500,000 buddy lists on live-chat services as well as from the inbox displays
of Web-based e-mail accounts.
The collection depends on secret arrangements with foreign telecommunications
companies or allied intelligence services in control of facilities that
direct traffic along the Internets main data routes.
Although the collection takes place overseas, two senior U.S. intelligence
officials acknowledged that it sweeps in the contacts of many Americans. They
declined to offer an estimate but did not dispute that the number is likely
to be in the millions or tens of millions.
A spokesman for the Office of the Director of National Intelligence, which
oversees the NSA, said the agency is focused on discovering and developing
intelligence about valid foreign intelligence targets like terrorists, human
traffickers and drug smugglers. We are not interested in personal information
about ordinary Americans.
The spokesman, Shawn Turner, added that rules approved by the attorney
general require the NSA to minimize the acquisition, use and dissemination
of information that identifies a U.S. citizen or permanent resident.
The NSAs collection of nearly all U.S. call records, under a separate
program, has generated significant controversy since it was revealed in June.
The NSAs director, Gen. Keith B. Alexander, has defended bulk collection
as an essential counterterrorism and foreign intelligence tool, saying, You
need the haystack to find the needle.
Contact lists stored online provide the NSA with far richer sources of data
than call records alone. Address books commonly include not only names and
e-mail addresses, but also telephone numbers, street addresses, and business
and family information. Inbox listings of e-mail accounts stored in the
cloud sometimes contain content, such as the first few lines of a message.
Taken together, the data would enable the NSA, if permitted, to draw detailed
maps of a persons life, as told by personal, professional, political and
religious connections. The picture can also be misleading, creating false
associations with ex-spouses or people with whom an account holder has had
no contact in many years.
The NSA has not been authorized by Congress or the special intelligence court
that oversees foreign surveillance to collect contact lists in bulk, and
senior intelligence officials said it would be illegal to do so from
facilities in the United States. The agency avoids the restrictions in the
Foreign Intelligence Surveillance Act by intercepting contact lists from
access points all over the world, one official said, speaking on the
condition of anonymity to discuss the classified program. None of those are
on U.S. territory.
Because of the method employed, the agency is not legally required or
technically able to restrict its intake to contact lists belonging to
specified foreign intelligence targets, he said.
When information passes through the overseas collection apparatus, the
official added, the assumption is youre not a U.S. person.
In practice, data from Americans is collected in large volumes  in part
because they live and work overseas, but also because data crosses
international boundaries even when its American owners stay at home. Large
technology companies, including Google and Facebook, maintain data centers
around the world to balance loads on their servers and work around outages.
A senior U.S. intelligence official said the privacy of Americans is
protected, despite mass collection, because we have checks and balances
built into our tools.
NSA analysts, he said, may not search within the contacts database or
distribute information from it unless they can make the case that something
in there is a valid foreign intelligence target in and of itself.
In this program, the NSA is obliged to make that case only to itself or
others in the executive branch. With few exceptions, intelligence operations
overseas fall solely within the presidents legal purview. The Foreign
Intelligence Surveillance Act, enacted in 1978, imposes restrictions only on
electronic surveillance that targets Americans or takes place on U.S.
By contrast, the NSA draws on authority in the Patriot Act for its bulk
collection of domestic phone records, and it gathers online records from U.S.
Internet companies, in a program known as PRISM, under powers granted by
Congress in the FISA Amendments Act. Those operations are overseen by the
Foreign Intelligence Surveillance Court.
Sen. Dianne Feinstein, the California Democrat who chairs the Senate
Intelligence Committee, said in August that the committee has less
information about, and conducts less oversight of, intelligence gathering
that relies solely on presidential authority. She said she planned to ask for
more briefings on those programs.
In general, the committee is far less aware of operations conducted under
12333, said a senior committee staff member, referring to Executive Order
12333, which defines the basic powers and responsibilities of the
intelligence agencies. I believe the NSA would answer questions if we asked
them, and if we knew to ask them, but it would not routinely report these
things, and, in general, they would not fall within the focus of the
Because the agency captures contact lists on the fly as they cross major
Internet switches, rather than at rest on computer servers, the NSA has no
need to notify the U.S. companies that host the information or to ask for
help from them.
We have neither knowledge of nor participation in this mass collection of
web-mail addresses or chat lists by the government, said Google spokeswoman
Niki Fenwick.
At Microsoft, spokeswoman Nicole Miller said the company does not provide
any government with direct or unfettered access to our customers data,
adding that we would have significant concerns if these allegations about
government actions are true.
Facebook spokeswoman Jodi Seth said that we did not know and did not assist
in the NSAs interception of contact lists.
It is unclear why the NSA collects more than twice as many address books from
Yahoo than the other big services combined. One possibility is that Yahoo,
unlike other service providers, has left connections to its users unencrypted
by default.
Suzanne Philion, a Yahoo spokeswoman, said Monday in response to an inquiry
from The Washington Post that, beginning in January, Yahoo would begin
encrypting all its e-mail connections.
Google was the first to secure all its e-mail connections, turning on SSL
encryption globally in 2010. People with inside knowledge said the move was
intended in part to thwart large-scale collection of its users information
by the NSA and other intelligence agencies.
The volume of NSA contacts collection is so high that it has occasionally
threatened to overwhelm storage repositories, forcing the agency to halt its
intake with emergency detasking orders. Three NSA documents describe
short-term efforts to build an across-the-board technology throttle for
truly heinous data and longer-term efforts to filter out information that
the NSA does not need.
Spam has proven to be a significant problem for the NSA  clogging databases
with information that holds no foreign intelligence value. The majority of
all e-mails, one NSA document says, are SPAM from fake addresses and never
delivered to targets.
In fall 2011, according to an NSA presentation, the Yahoo account of an
Iranian target was hacked by an unknown actor, who used it to send spam.
The Iranian had a number of Yahoo groups in his/her contact list, some with
many hundreds or thousands of members.
The cascading effects of repeated spam messages, compounded by the automatic
addition of the Iranians contacts to other peoples address books, led to a
massive spike in the volume of traffic collected by the Australian
intelligence service on the NSAs behalf.
After nine days of data- bombing, the Iranians contact book and contact
books for several people within it were emergency detasked.
In a briefing from the NSAs Large Access Exploitation working group, that
example was used to illustrate the need to narrow the criteria for data
interception. It called for a shifting collection philosophy: Memorialize
what you need vs. Order one of everything off the menu and eat what you
Julie Tate contributed to this report. Soltani is an independent security
researcher and consultant.

@_date: 2013-10-15 11:08:29
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
The future that never was was built with Lisp machines and NeWS.
Twatr who?

@_date: 2013-10-15 14:23:46
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
Latest TBB3: Within our dataset of several million visitors, only one in 466 browsers have the same fingerprint as yours.
Currently, we estimate that your browser has a fingerprint that conveys 8.86 bits of identifying information.

@_date: 2013-10-15 14:27:04
@_author: Eugen Leitl 
@_subject: [linux-elitists] Browser fingerprinting 
As long as you're jailing your browser into an amnesiac
compartment and run TBB (latest 3 alpha is pretty good)
your risk is minimal.

@_date: 2013-10-15 14:37:44
@_author: Eugen Leitl 
@_subject: Bitcoin mining efficiency and Botnets 
Make something requiring huge LUTs, and in-memory access. That is not ASICable or FPGAble.
Doubling rate is now 3 years by end of this year instead
of 18 months, according to AMD. Moore is dead, long live Moore (in 3d volume integration
of molecular components, coming in a couple decades).

@_date: 2013-10-15 16:21:36
@_author: Eugen Leitl 
@_subject: Bitcoin mining efficiency and Botnets 
Never mentioned Bitcoin, and I would agree in principle.
Due to network effect and apparent good design Bitcoin may
last a lot longer than its detractors like to think, but it will fall, eventually. I disagree there's palpable progress in QC inasmuch practical
computing is concerned, at least in the open literature.
DNA computers basically don't work.
You're sampling conformation space of a linear molecule with
lots of viscous drag. There is very little infinity in that.

@_date: 2013-10-15 20:48:55
@_author: Eugen Leitl 
@_subject: Lessons from Silk Road: don't host your virtual illegal drug bazaar 
Lessons from Silk Road: don't host your virtual illegal drug bazaar in
By Adrianne Jeffries on October 14, 2013 11:47 am Email
When it comes to protecting your virtual black market from the Federal Bureau
of Investigation (FBI), some countries are better than others. As it turns
out, Iceland is probably not where you want to be. While the country may have
protected WikiLeaks from the Americans, it's not harboring the recently
busted illegal drug bazaar Silk Road. The Reykjavik Metropolitan Police have
confirmed that they handed over data on the Silk Road at the request of
American authorities.
It's unclear how much information Iceland turned over, but the FBI claims two
Silk Road servers were based there. Icelandic police say the site was
actually hosted there. Since Iceland does not have a formal Mutual Legal
Assistance Treaty (MLAT) with the US, it appears that the FBI negotiated a
special one-time agreement in order to get the data.
It still looks like the bulk of the information that broke open the case did
not come from Iceland, however. The complaint says "an image of the Silk Road
Web Server was made on or about July 23rd, 2013, and produced thereafter to
the FBI" as a result of a request made to a foreign country under a formal
"AN IMAGE OF THE SILK ROAD WEB SERVER WAS MADE ON OR ABOUT JULY 23RD, 2013."
That image, or bit-for-bit copy, of the Silk Road server gave authorities
access to private messages between the Silk Road's owner and other members of
the site. It was instrumental in seizing the site and arresting Ross
Ulbricht, the man police allege was behind the Silk Road.
Runa Sandvik, who works on the anonymizing network Tor, has been trying to
figure out which country handed over that server image. She initially ruled
out Iceland because it does not have an MLAT with the US. Various Silk Road
content was also hosted in the US, Latvia, and Malaysia. Latvia and Malaysia
are both MLAT signatories. If the request was indeed made under an MLAT, it
looks like the image either came from one of those countries or another that
has not been revealed yet by the FBI.
Another possibility is that the FBI's complaint erroneously claimed the
request was made under an MLAT, when the reality was less formal. Either way,
future virtual drug kingpins now know that Iceland is no safe haven.
Correction: An earlier version of this story said that Malaysia is not an
MLAT signatory; that is incorrect. Malaysia and the US signed an MLAT in

@_date: 2013-10-16 08:24:04
@_author: Eugen Leitl 
@_subject: Bitcoin mining efficiency and Botnets 
Difficulty is adaptive, so it will go down if hash rate goes down.
It's not a one-way ratchet.

@_date: 2013-10-16 09:43:10
@_author: Eugen Leitl 
@_subject: The NSA back door to NIST 
Thomas C. Hales (University of Pittsburgh)
(This article will be published in the Notices of the American Mathematical
Use once. Die once.  activist saying about insecure communication
This article gives a brief mathematical description of the NIST standard for
cryptographically secure pseudo-random number generation by elliptic curves,
the back door to the algorithm discovered by Ferguson and Shumow, and finally
the design of the back door based on the Diffie-Hellman key exchange
NIST (the National Institute for Standards and Technology) of the U.S.
Department of Commerce derives its mandate from the U.S. Constitution,
through the congressional power to fix the standard of weights and
measures. In brief, NIST establishes the basic standards of science and
commerce. Whatever NIST says about cryptography becomes implemented in
cryptographic applications throughout U.S. government agencies. Its influence
leads to the widespread use of its standards in industry and the broad
adoption of its standards internationally.
Through the Snowden disclosures, the NIST standard for pseudo-random number
generation has fallen into disrepute. Here I describe the back door to the
NIST standard for pseudo-random number generation in elementary and
mathematically precise terms. The NIST standard offers three methods for
pseudo-random number generation [NIST]. My remarks are limited to the third
of the three methods, which is based on elliptic curves.
Random number generators can either be truly random (obtaining their values
from randomness in the physical world such as a quantum mechanical process)
or pseudo-random (obtaining their values from a deterministic algorithm, yet
displaying a semblance of randomness). The significance of random number
generation within the theory of algorithms can be gauged by Knuths
multivolume book, The Art of Computer Programming. It devotes a massive 193
pages (half of volume two) to the subject! A subclass of pseudo-random number
generators are cryptographically secure, intended for use in cryptographic
applications such as key generation, one-way hash functions, signature
schemes, private key cryptosystems, and zero knowledge interactive proofs
Elliptic curves as pseudo-random number generators
The NIST standard gives a list of explicit mathematical data (E,p,n,f,P,Q) to
be used for pseudo-random number generation [NIST]. Here E is an elliptic
curve defined over a finite field \mathbb{F}_p of prime order p. The group
E(\mathbb{F}_p) has order n, which is prime for all of the curves that occur
in the NIST standard. The elements of the group E(\mathbb{F}_p) consist of
the set of points on an affine curve, together with a point at infinity which
serves as the identity element of the group. The affine curve is defined by
an equation y^2 = f(x) for some explicit cubic polynomial f in
\mathbb{F}_p[x]. Finally, P and Q are given points on the affine curve.
NIST gives a few sets of data and in each case the prime number p is large.
(The smallest is greater than 10^{77}.) No explanation is given of the
particular choices (E,p,n,f,P,Q). We are told to use these data and not to
question why. The standard stipulates that one of the following NIST
approved curves with associated points shall be used in applications
requiring certification under FIPS-140 [U.S. government computer security
When A is any point other than the identity in E(\mathbb{F}_p), we may
evaluate the coordinate function x at A, to obtain x(A)\in \mathbb{F}_p. By
further lifting \mathbb{F}_p to a set of representatives in \mathbb{Z}, we
obtain a function by composition x1 : E(\mathbb{F}_p)\setminus\{0\}~ \to~
\mathbb{F}_p~\to~ \mathbb{Z}. Write (n,A)\mapsto n * A for the
\mathbb{Z}-module action of \mathbb{Z} on E. (We write powers of the group
element A using multiplicative rather than exponential notation.)
The pseudo-random bit generator is initialized with a random integer seed s,
obtained by some different process such as a separate random number
generator. What is important for us is that the number s represents the
hidden internal state of the algorithm. The hidden state must be kept secret
for the pseudo-randomness to be effective. (Once the state is disclosed, a
pseudo-random sequence becomes predictable and useless for many cryptographic
The essence of the pseudo-random bit generator can be written in the
Objective Caml language as follows. In the syntax of this language, each
phrase (let x = a in ) defines the value of x to be a. The last line of the
block of code gives the output of the function.
let pseudo_random s =
 let r = x1 (s * P) in
 let s' = x1 (r * P) in
 let t = x1 (r * Q) in
 let b = extract_bits t in
  (s',b);
That is, we successively apply the integer s or r to the point P or the point
Q and take the x1 coordinate of the resulting point, then extract some bits
from the number t. The integer s becomes the new secret internal state to be
fed into the next iteration of the function. The output b is passed to the
consumer of pseudo-random bits. This output may become publicly known. The
function extract_bits operates by converting t to a list of bits, discarding
the 16 most significant bits (for reasons that do not matter to this
discussion), and giving the remaining bits as output. According to NIST
standards, by iterating this function, updating the internal state at each
iteration, a cryptographically secure stream b  of pseudo-random bits is
The back door
This algorithm is fatally flawed, as Ferguson and Shumow pointed out
[Shumow-Ferguson]. Since P and Q are non-identity elements of a cyclic group
of prime order, each is a multiple of the other. Write P = e * Q, for some
integer e. We show that once we have e in hand, it is a simple matter to
determine the secret internal state s of the pseudo-random bit generator by
observing the output b, and thus to compromise the entire system.
The function extract_bits discards 16 bits. Given the output b, we take the
2^{16} (a small number of) possible preimages t of b under extract_bits. For
each t, the coordinate x is known, and solving a quadratic, there are at most
two possibilities for the coordinate y of a point A on the elliptic curve
such that t = x1 (A). One such A is r * Q. For each A, we compute e * A. One
of the small number of possibilities for e * A is
e * (r * Q) = r * (e * Q) = r * P.     (1)
Finally s = x1 (r * P). In short, the internal state s can be be narrowed
down to a small number of possibilities by an examination of the
pseudo-random output bitstream. Shumow and Ferguson state that in
experiments, 32 bytes of output was sufficient to uniquely identify the
internal state of the PRNG [pseudo-random number generator].
The back door to the algorithm is the number e such that P = e * Q. To use
the back door, one must know of the value e. The NIST standard does not
disclose e (of course!), and extensive cryptographic experience suggests that
it is hard to compute e from the coordinates of P and Q (unless you happen to
own a quantum computer). This is the problem of discrete logarithms. But
starting with e, there is no difficulty in creating a pair P and Q. The back
door is universal: a single number e gives back door access to the internal
state of the algorithm of all users worldwide.
It is a matter of public fact that the NSA was tightly involved in the
writing of the standard. Indeed, NIST is required by law to consult with NSA
in creating its standard. According to the New York Times, classified NSA
memos appear to confirm that the fatal weakness, discovered by two Microsoft
cryptographers in 2007, was engineered by the agency [NYT]. The news article
goes on to say that eventually, NSA became the sole editor and then pushed
aggressively to make this the standard for the 163 member countries of the
International Organization for Standardization. Further historical and social
context appears in [Wired]. NSA had facile access to the crown jewel e and
motive to seize it. Draw your own conclusions.
1. This back door to this algorithm is extremely elementary from a
mathematical perspective. We wrote the essential algorithm in six lines of
computer code, even if more supporting code is needed to make it industrial
strength. The algorithm could be explained to undergraduate math majors, or
sufficiently advanced high-school students. The story also has the spy-agency
intrigue to make a good math club talk or a special lecture in an elementary
abstract algebra course. We essentially just need to understand that an
elliptic curve is an abelian group whose elements (other than the identity
element) are determined by two numbers x and y, that y is the root of a
quadratic when x is given, and that every non-identity element of a cyclic
group of prime order is a generator. Easy stuff.
2. Without prior knowledge of the back door, how difficult would it be to
rediscover the possible existence of a back door? An analysis of the argument
shows the required level of creativity is that of an undergraduate homework
problem. We must think to write the element P as a multiple of the generator
Q in a cyclic group of prime order. This a student learns in the first weeks
of undergraduate algebra.
The rest of the process of inverting the pseudo-random number generator is
determined by the definition of the function itself: simply take each step
defining the function and reverse the steps, asking for the preimage of the
function at each step of its definition, working from the output back to the
secret state s. Once the question of inverting the function is asked, it is
easy to do the group theory, even if it is computationally difficult to write
e explicitly.
One-way functions are a standard tool in the cryptographers bag. Every
professional who has been trained to analyze cryptographic algorithms knows
to ask the question of invertibility. It is unsettling that NIST and others
do not seem to have asked this basic question.
Diffie-Hellman key exchange
In what follows, let us assume that someone, whom we will call the Spy, has
access to the back door e. How is it possible for the Spy and the end user
(the User) of the NIST algorithm to come into possession of the same shared
secret (the internal state of the pseudo-random number generator), when all
communication between them is public? Information flows from the Spy to the
User through the published NIST standard, and from the User back to the Spy
through the public output of the pseudo-random generator. The back door must
have a remarkable cryptographic design to permit a secret to pass across
these public channels, yet prevent the secret from becoming known to a third
As we now explain, the design of the back door to NIST is based on a
well-known algorithm in cryptography called the Diffie-Hellman key exchange
[Diffie-Hellman]. This is an algorithm to share a secret between two parties,
when there is a possibility that the channel of communication is being
monitored. In the current context, the Spy has full knowledge of the
Diffie-Hellman key exchange for what it is. However, the User participates in
the exchange innocently and unwittingly, by blindly following the rules of
the NIST protocol.
The Diffie-Hellman key exchange requires a group, which we will take to be a
cyclic group E of order n (to preserve notation). The group E, its order n,
and a generator Q are made public. To share a secret, the first party (the
Spy), picks a random number e, which is kept secret, and publishes P = e * Q
to the world. The second party (the User) picks a random number r, which is
kept secret, and publishes r * Q. Then by Equation (1), the Spy who knows e
and r *Q, and the User who knows r and e * Q can both compute (r e) * Q = r *
P, which is the shared secret. (In our context, the shared secret determines
the internal state s of the pseudo-random number generator.) If E is a group
in which the public knowledge E, n, Q, P = e * Q, r * Q does not allow the
easy computation of (r e) * Q, then the shared secret is protected from
public disclosure by the difficulty of the computation. In this way, the only
two who learn the internal state of the pseudo-random number generator are
the Spy and the User.
What we have described here is not an imaginary scenario: NIST documents do
in fact publish the data E, n, Q, and P, needed to initiate the
Diffie-Hellman exchange. A user, when making public the output from the
pseudo-random number generator, does in fact complete the exchange.
Diffie-Hellman is Diffie-Hellman, whether it has been advertised as such or
To say that the Diffie-Hellman key exchange algorithm is well-known is a vast
understatement. This algorithm is a significant lesson in virtually every
first course in cryptography everywhere in the world. Building on Merkle, the
Diffie-Hellman paper, by starting the entire field of public key
cryptography, is one of the most influential papers in cryptography ever
What is the significance of all this? It is no secret that the NSA employs
some of the worlds keenest cryptographic minds. They all know
Diffie-Hellman. In my opinion, an algorithm that has been designed by NSA
with a clear mathematical structure giving them exclusive back door access is
no accident, particularly in light of the Snowden documents. This is a work
of experts.
[NIST] E. Barker and J. Kelsey, Recommendation for random number generation
using deterministic random bit generators. NIST Special Publication 800-90A
(2012), [Diffie-Hellman] W. Diffie and M. Hellman, New directions in cryptography.
IEEE Transactions on Information Theory 22 (1976), 644-654.
[Luby] M. Luby, Pseudorandomness and cryptographic applications, Princeton
University Press, 1996.
[NYT] N. Perloth, J. Larson, and S. Shane. N.S.A. able to foil basic
safeguards of privacy on web, September 5, 2013, New York Times,
[Shumow-Ferguson] D. Shumow and N. Ferguson, On the possibility of a back
door in the NIST SP800-90 dual EC PRNG,
 2007.
[Wired] K. Zetter, How a crypto `backdoor pitted the tech world against the
NSA, Wired (Sept 24, 2013),

@_date: 2013-10-16 10:26:43
@_author: Eugen Leitl 
@_subject: Curious use of cpunks list [Brian Carroll] 
The author is almost certainly schizophrenic, but he's
not disruptive, and occasionally amusing. I don't see
any reasons for action.

@_date: 2013-10-16 16:34:12
@_author: Eugen Leitl 
@_subject: The NSA's New Code Breakers 
(thank, John, worth reposting full-text)
The NSA's New Code Breakers
America's using front companies, break-in artists, and hacktivists to spy on
everyone -- and only North Korea seems able to resist.
BY MATTHEW M. AID | OCTOBER 15, 2013
There was a time when the code breakers of the National Security Agency
actually took the lead in solving enemy encryption systems. These days, not
so much. In today's NSA, it's hackers, break-in artists, corporate liaisons,
and shadow salesman using front companies who are at the forefront of this
effort. Even so-called "hacktivists" play an unwitting role in helping the
NSA gain access to computer networks -- both hostile and friendly.
Just about the only place that's somewhat immune to the NSA's new style of
code-breaking attacks? North Korea, because it's so disconnected from the
rest of the world's networks.
Former U.S. intelligence officials confirm that the more than 1,500
cryptanalysts, mathematicians, scientists, engineers, and computer
technicians who comprise NSA's elite cryptanalytic unit, the Office of
Cryptanalysis and Exploitation Services (S31), have had a remarkably large
number of code-breaking successes against foreign targets since the 9/11
attacks. But these wins were largely dependent on clandestine intelligence
activities for much of their success in penetrating foreign communications
networks and encryption systems, and not the more traditional cryptanalytic
attacks on encrypted messages that were the norm during the Cold War era.
Prior to 9/11, NSA's cryptanalysts used their huge stable of supercomputers
to break cipher systems using what is referred to as "brute force methods" --
using the super computers to run every cipher permutation until the message
or messages in question become readable. It was a long, tedious, and
extremely costly process (today NSA spends over $247 million a year to buy
and maintain its state-of-the-art supercomputer systems just for
cryptanalytic use). But it did work if there were inherent vulnerabilities or
structural weakness in the cipher being attacked, or if the system's users
did not practice proper communications security procedures, such as changing
the cipher keys and passwords frequently.
The NSA today has more supercomputers than ever and the agency still employs
a number of puzzle-solvers, linguists, and math geeks. But these classic
cryptanalysts have, in part, given way to a new breed.
You won't learn this in the files leaked by former NSA contractor Edward
Snowden -- at least not directly. According to individuals who have reviewed
the entire collection of 50,000 documents provided to the media by Snowden,
what is missing from the papers is any document which lays out in detail just
how successful the agency's code-breaking efforts have been. There are
numerous documents in the Snowden collection describing individual NSA
cryptologic programs, such as NSA's mostly unsuccessful multi-year effort to
crack the encryption protection used by the anonymizer service Tor. But no
reports describing the agency's cryptanalytic successes and failures have
been found in the Snowden collection to date.
Interviews with current and former intelligence officials conducted over the
past two months have revealed that since 9/11, NSA's computer scientists,
electronic engineers, software programmers, and collection specialists have
been remarkably inventive in finding new and innovative ways to circumvent
the protections supposedly offered by encryption systems by compromising them
through clandestine means. Among these clandestine means are CIA and FBI
"black bag jobs," as well as secret efforts by the U.S. intelligence
community to interdict the shipment of advanced encryption technology to
America's enemies around the world, inserting "back doors" into
commercially-available computer, communications and encryption technologies
which allow NSA to covertly access these systems without the users knowing
But the most sensitive of these clandestine techniques, and by far the most
productive to date, is to covertly hack into targeted computers and copy the
documents and message traffic stored on these machines before they are
encrypted, a process known within NSA as "Endpoint" operations.
Responsibility for conducting these Endpoint operations rests with the
computer hackers of NSA's cyberespionage unit, the Office of Tailored Access
Operations (TAO).
According to sources familiar with the organization's operations, TAO has
been enormously successful over the past 12 years in covertly inserting
highly sophisticated spyware into the hard drives of over 80,000 computer
systems around the world, although this number could be much higher. And
according to the sources, these implants are designed in such a way that they
cannot be detected by currently available commercial computer security
software. It has been suggested to me by a reliable source that "this is not
an accident," with the insinuation being that many of the biggest
commercially-available computer security software systems made in the United
States and overseas have been compromised by NSA, either covertly or with the
knowledge and consent of the companies that manufacture these systems.
Former agency personnel confirm that in innumerable instances these TAO
implants have allowed NSA's analysts to copy and read all of the unencrypted
documents stored on the targeted computer's hard drive, as well as copy every
document and email message produced and/or transmitted by the machine. But
more importantly, TAO has helped NSA's cryptanalysts solve several hundred
foreign government and commercial encryption systems because these spyware
implants, if properly inserted into the computer, can covertly alter its
security software as well as copy the encryption system's technical
parameters, especially the system's encryption algorithm and access
passwords, in a way that cannot be detected. These implants can compromise
the encryption systems used by not only the targeted computer, but also all
other computer systems that it communicates with using encryption technology.
According to confidential sources familiar with TAO's operations, many of
NSA's cryptanalytic "success stories" against high-priority targets such as
Russia and the People's Republic of China in recent years have been the
direct result of TAO's cyberespionage efforts. For example, sources confirm
that much of what the U.S. intelligence community knows about China's
computer hacking efforts against targets in the United States, Europe, and
Asia stems from TAO's intelligence collection efforts since 2005, when TAO
reportedly achieved a major technical breakthrough against a Chinese target.
But TAO doesn't just spy on America's rivals. In 2012, the group reportedly
compromised the encryption system used by an important G8 country to transmit
sensitive diplomatic communications via satellite to its embassies around the
world. The same is true with a number of countries in the Middle East and
South Asia, including Egypt, Syria, Iran, and Pakistan, although the details
of these successes are not yet known. And finally, sources report that TAO
has successfully compromised the privacy protection systems currently used on
a range of 4G cell phones and hand-held devices, thanks in large part to help
from a major American telecommunications company.
There are high-profile targets that have proven resistant to TAO's
cyberespionage efforts over the years, however. For example, TAO has
reportedly had virtually no success penetrating North Korean government
computer systems or networks because there are so few of them and they are
heavily protected from access to the outside world.
Over time, TAO has become increasingly accomplished at its mission, thanks in
part to the high-level cooperation that it secretly receives from the "big
three" American telecommunications companies (AT&T, Verizon, and Sprint),
most of the large U.S.-based internet service providers, and many of the top
computer security software manufacturers and consulting companies. According
to a February 2012 budget document (.pdf) published earlier this year by
ProPublica, these companies "Insert vulnerabilities into commercial
encryption systems, IT systems, networks, and endpoint communications devices
used by targets" on behalf of TAO.
TAO is also very active in the global computer security industry marketplace,
using the CIA, Defense Intelligence Agency, and State Department to help it
keep close tabs on the latest computer security devices and software systems
being developed around the world. And while details are lacking, informed
sources report that TAO has been active in covertly buying up commercially
available "hacker tools" or spyware software systems from individuals and
companies in the United States and overseas, particularly in Western Europe,
to help facilitate its ever-growing computer network exploitation efforts.
The extreme sensitivity of TAO's collection efforts has required the NSA to
take extraordinary steps to try to disguise its computer hacking activities.
For instance, current and former intelligence sources confirm that TAO
increasingly depends on clandestine techniques, such as commercial cover, to
hide its activities. TAO uses an array of commercial business entities, some
of them proprietary companies established specifically for this purpose, to
try to hide its global computer hacking activities from computer security
experts in a maze of interlocking computer servers and command-and-control
systems located in the United States and overseas that have no discernible
link to NSA or the U.S. government.
These sources also say that TAO gets a lot of help from politically-motivated
hackers, or "hacktivists," who unintentionally help NSA by providing ideas to
improve TAO's collection efforts. (Exactly which hacktivists have been
particularly helpful, these sources wouldn't say.) Working closely with NSA's
computer security experts at the NSA/CSS Threat Operations Center, TAO
personnel perform detailed forensic post-mortem studies of every major
successful computer penetration operation around the world. Some of these are
pulled off by criminal outfits, some by government-backed groups, others by
political actors. In each case, the agency's personnel looks for new
techniques or procedures that they can use to get inside computer systems
around the world.
There is no question that TAO's future looked incredibly bright before the
first newspaper articles began appearing in the British and American press in
June 2013 based on documents leaked by Snowden. Now, industry sources
familiar with TAO say that the organization's future prospects have dimmed
A number of foreign-based computer systems and IT networks that formerly were
major producers of intelligence information for TAO have over the past three
months changed security procedures and encryption systems, routed traffic to
more secure computer nodes or servers, erected new firewalls, or have gone
offline altogether. According to recent press reports, the Russian government
for a time reverted back to using manual typewriters rather than commit
sensitive information to their computer systems. And a number of European
countries and Brazil have begun shifting their most sensitive data and
communications traffic to secure networks that they hope will be resistant to
NSA's intrusive surveillance activities.
But this is, I am sure, just the tip of the iceberg. I have no doubt that the
damage to TAO's foreign intelligence collection capabilities and its ability
to facilitate the solution of foreign encryption systems by NSA's
cryptanalysts has been substantial. The big question that will determine
TAO's future prospects is whether the damage done so far proves to be

@_date: 2013-10-17 08:29:08
@_author: Eugen Leitl 
@_subject: Curious use of cpunks list [Brian Carroll] 
If we had good PRNGs everywhere, with lots of trustable physical entropy
stirred in then nobody would care about talking about these.
It would be boring, since a solved problem.
Now show me a cryptographic quality PRNG with a few MBytes of
internal state. Best, a whole robust family of them. See? That's
some quality trolling, right there.

@_date: 2013-10-17 09:49:09
@_author: Eugen Leitl 
@_subject: [tor-talk] Roger's status report, September/October 2013 
Reply-To: tor-talk at lists.torproject.org
Six things I did in September/October 2013:
1) Released Tor 0.2.4.17-rc:
including writing the fix to prioritize NTor handshakes so Tor 0.2.4.x
remains usable despite the five million new bot users:
Released Tor 0.2.5.1-alpha:
2) Wrote many blog posts:
with a follow-up summary at
and also answered hundreds of blog comments / questions.
3) Talked to many many journalists to explain Tor and the Internet.
My most useful quotes went to Bruce Schneier:
and Brian Fung:
and Dan Goodin:
4) Helped the Tor Stack Exchange beta get off the ground:
I zipped up to 1000+ reputation from answering questions in the first
few days, but then I disappeared because I was distracted by other work.
Hopefully other people have filled in the gap.
5) Helped sort out the 2013 Q4 budget, and also get the new SponsorO
projects off the ground:
6) Attended the SponsorF "red team assessment" where they funded some
smart DPI developers to evaluate and try to break Obfsproxy and Flash
Proxy. So far so good -- one of the outcomes is that we should set up
a performance testbed for Flash Proxy to see if we can replicate their
"sometimes when I upload a bunch of stuff it takes a long time" behavior.
I plan to talk to Arlo, once I'm back online, about doing that.

@_date: 2013-10-17 10:29:45
@_author: Eugen Leitl 
@_subject: Cryptographer Adi Shamir Prevented from Attending NSA History 
Cryptographer Adi Shamir Prevented from Attending NSA History Conference
Categories: Science, Secrecy
In this email message to colleagues, Israeli cryptographer Adi Shamir
recounts the difficulties he faced in getting a visa to attend the 2013
Cryptologic History Symposium sponsored by the National Security Agency. Adi
Shamir is the S in the RSA public-key algorithm and is one of the finest
cryptologists in the world today, according to historian David Kahn. The NSA
Symposium begins tomorrow. For the reasons described below, Dr. Shamir will
not be there.
The purpose of this email is to explain why I will not be able to attend the
forthcoming meeting of the History of Cryptology conference, even though I
submitted a paper which was formally accepted. As an active participant in
the exciting developments in academic cryptography in the last 35 years, I
thought that it would be a wonderful opportunity to meet all of you, but
unfortunately the US bureaucracy has made this impossible.
The story is too long to describe in detail, so I will only provide its main
highlights here. I planned to visit the US for several months, in order to
attend the Crypto 2013 conference, the History of Cryptology conference, and
to visit several universities and research institutes in between in order to
meet colleagues and give scientific lectures. To do all of these, I needed a
new J1 visa, and I filed the visa application at the beginning of June, two
and a half months before my planned departure to the Crypto conference in mid
August. I applied so early since it was really important for me to attend the
Crypto conference  I was one of the founders of this flagship annual
academic event (I actually gave the opening talk in the first session of the
first meeting of this conference in 1981) and I did my best to attend all its
meetings in the last 32 years.
To make a long story short, after applying some pressure and pulling a lot of
strings, I finally got the visa stamped in my passport on September 30-th,
exactly four months after filing my application, and way beyond the requested
start date of my visit. I was lucky in some sense, since on the next day the
US government went into shutdown, and I have no idea how this could have
affected my case. Needless to say, the long uncertainty had put all my travel
plans (flights, accomodations, lecture commitments, etc) into total disarray.
It turns out that I am not alone, and many foreign scientists are now facing
the same situation. Here is what the president of the Weizmann Institute of
Science (where I work in Israel) wrote in July 2013 to the US Ambassador in
Im allowing myself to write you again, on the same topic, and related to
the major difficulties the scientists of the Weizmann Institute of Science
are experiencing in order to get Visa to the US. In my humble opinion, we are
heading toward a disaster, and I have heard many people, among them our top
scientists, saying that they are not willing anymore to visit the US, and
collaborate with American scientists, because of the difficulties. It is
clear that scientists have been singled out, since I hear that other simple
citizen, do get their visa in a short time.
Even the president of the US National Academy of Science (of which I am a
member) tried to intervene, without results. He was very sympathetic, writing
to me at some stage:
Dear Professor Shamir
I have been hoping, day by day, that your visa had come through. It is very
disappointing to receive your latest report. We continue to try by seeking
extra attention from the U. S. Department of State, which has the sole
authority in these matters. As you know, the officers of the Department of
State in embassies around the world also have much authority. I am personally
very sympathetic and hopeful that your efforts and patience will still yield
results but also realize that this episode has been very trying. We hope to
hear of a last-minute success.
Yours sincerely, Ralph J. Cicerone
What does all of this have to do with the History of Cryptology conference?
In January 2013 I submitted a paper titled The Cryptology of John Nash From
a Modern Perspective to the conference, and a short time afterwards I was
told by the organizers that it was accepted. In July 2013 I told the
NSA-affiliated conference organizers that I was having some problems in
getting my visa, and gently asked whether they could do something about it.
Always eager to help, the NSA people leaped into action, and immediately sent
me a short email written with a lot of tact:
The trouble you are having is regrettableSorry you wont be able to come to
our conference. We have submitted our program and did not include you on it.
I must admit that in my 35 years of attending many conferences, it had never
happened to me that an accepted paper of mine was yanked out from the
official program in such a unilateral way. However, since I never try to go
to places where I do not feel wanted, I decided to inform MIT that a window
had become available in my busy schedule. They immediately invited me to
visit them on October 17 and 18, and to give a major lecture during my visit.
Naturally, I accepted their gracious invitation.
The final twist in this saga happened a few days ago, when out of the blue I
was suddenly reinvited by the conference organizers to attend the event and
to present my paper. However, this is too late now, since I am already fully
committed to my visit to MIT.
So what is the bottom line of this whole unhappy episode? Clearly, no one in
the US is trying to see the big picture, and the heavy handed visa
bureaucracy you have created seems to be collapsing under its own weight.
This is not a security issue  I have been to the US close to a hundred times
so far (including some multi-year visits), and had never overstayed my visas.
In addition, the number of terrorists among the members of the US National
Academy of Science is rather small. As a friend of the US I am deeply worried
that if you continue to delay visas in such a way, the only thing you will
achieve is to alienate many world-famous foreign scientists, forcing them to
increase their cooperation with European or Chinese scientists whose
countries roll the red carpet for such visits. Is this really in the US best
Best personal wishes, and apologies for not being able to meet you in person,
Adi Shamir

@_date: 2013-10-17 13:15:10
@_author: Eugen Leitl 
@_subject: Trekkie finally got fired -- it's a good start 
Keith Alexander, NSA Head, Stepping Down
Tyler Durden's pictureSubmitted by Tyler Durden on 10/16/2013 18:10 -0400
After eight years at the helm of "America's secret cyber army", NSA head
Keith Alexander, has decided to spend more time with his family and less time
with yours, and is stepping down. According to US officials, the director of
the NSA and his deputy are expected to depart in coming months, in a move
that almost certainly would not have happened without the involvement of
America's most infamous whitsleblower currently self-exiled in Russia, Edward
Snowden in a development which according to Reuters, "could give Obama a
chance to reshape the eavesdropping agency."
It is unclear what he would "reshape" it into: at last check the Stasi
headquarters in Berlin did not have quite the capacity to house the Cray
supercomputers needed to make sure that anyone and everyone caught selling
stocks gets a lifetime audit guarantee from the IRS.
We are confident, however, that with the surge in government-employed
architects coming back to "work" from their 17 days paid vacation, someone
will have an idea or two.
Army General Keith Alexander's eight-year tenure was rocked this year by
revelations contained in documents leaked by former NSA contractor Edward
Snowden about the agency's widespread scooping up of telephone, e-mail and
social media data.
Alexander has formalized plans to leave by next March or April, while his
civilian deputy, John "Chris" Inglis, is due to retire by year's end,
according to U.S. officials who spoke on condition of anonymity.
It also wasn't clear who would replace the man who once upon a time made his
office into a replica of the bridge of the Starship Enterprise, although
there certainly are candidates.
One leading candidate to replace Alexander is Vice Admiral Michael Rogers,
currently commander of the U.S. Navy's 10th Fleet and U.S. Fleet Cyber
Command, officials told Reuters. The 10th Fleet and Fleet Cyber Command both
have their headquarters at Fort Meade, Maryland, between Washington and
Baltimore. The NSA is also headquartered at Fort Meade.
There has been no final decision on selecting Rogers to succeed Alexander,
and other candidates may be considered, the officials said.  More
importantly, the question is whether with America's domestic epsionage and
email address book collection efforts exposed for the entire world to see,
courtesy of Edward Snowden, will Obama decide to engage in a strategic shift
in policy, or merely double down and install RFID chips into every newborn
While both men are leaving voluntarily, the dual vacancies give Obama an
opportunity both to install new leadership following Snowden's revelations
and to decide whether the NSA and Cyber Command should have separate leaders.
Cyber Command, which has grown significantly in recent years, has the
authority to engage in both defensive and offensive operations in cyberspace.
Many NSA veterans argue that having the same person lead the spy agency and
Cyber Command diminishes the emphasis on the NSA's work and its unique
Rogers has been the Navy's top cyber commander since September 2011. Prior to
that, he was director of intelligence for the U.S. Joint Chiefs of Staff and
for the U.S. Pacific Command.
Rogers is "a good leader, very insightful and well thought of within the
community," said a U.S. defense official who was not authorized to speak
publicly on the matter.
Rogers has worked hard to ensure that the Navy has sufficient sailors trained
to take on added cyber responsibilities for U.S. Cyber Command, the official
Sorry, we forgot to add "rhetorical" before question.

@_date: 2013-10-17 15:40:29
@_author: Eugen Leitl 
@_subject: NSA's key role in targeted killings 
Documents reveal NSAs extensive involvement in targeted killing program
Video: In June, President Obama said the NSAs programs help us prevent
terrorist attacks.
By Greg Miller, Julie Tate and Barton Gellman, Thursday, October 17, 2:07 AM
E-mail the writers
It was an innocuous e-mail, one of millions sent every day by spouses with
updates on the situation at home. But this one was of particular interest to
the National Security Agency and contained clues that put the senders
husband in the crosshairs of a CIA drone.
Days later, Hassan Ghul  an associate of Osama bin Laden who provided a
critical piece of intelligence that helped the CIA find the al-Qaeda leader 
was killed by a drone strike in Pakistans tribal belt.
The U.S. government has never publicly acknowledged killing Ghul. But
documents provided to The Washington Post by former NSA contractor Edward
Snowden confirm his demise in October 2012 and reveal the agencys extensive
involvement in the targeted killing program that has served as a centerpiece
of President Obamas counterterrorism strategy.
An al-Qaeda operative who had a knack for surfacing at dramatic moments in
the post-Sept. 11 story line, Ghul was an emissary to Iraq for the terrorist
group at the height of that war. He was captured in 2004 and helped expose
bin Ladens courier network before spending two years at a secret CIA prison.
Then, in 2006, the United States delivered him to his native Pakistan, where
he was released and returned to the al-Qaeda fold.
But beyond filling in gaps about Ghul, the documents provide the most
detailed account of the intricate collaboration between the CIA and the NSA
in the drone campaign.
The Post is withholding many details about those missions, at the request of
U.S. intelligence officials who cited potential damage to ongoing operations
and national security.
The NSA is focused on discovering and developing intelligence about valid
foreign intelligence targets, an NSA spokeswoman said in a statement
provided to The Post on Wednesday, adding that the agencys operations
protect the nation and its interests from threats such as terrorism and the
proliferation of weapons of mass destruction.
In the search for targets, the NSA has draped a surveillance blanket over
dozens of square miles of northwest Pakistan. In Ghuls case, the agency
deployed an arsenal of cyber-espionage tools, secretly seizing control of
laptops, siphoning audio files and other messages, and tracking radio
transmissions to determine where Ghul might bed down.
The e-mail from Ghuls wife about her current living conditions contained
enough detail to confirm the coordinates of that household, according to a
document summarizing the mission. This information enabled a capture/kill
operation against an individual believed to be Hassan Ghul on October 1, it
The file is part of a collection of records in the Snowden trove that make
clear that the drone campaign  often depicted as the CIAs exclusive domain
 relies heavily on the NSAs ability to vacuum up enormous quantities of
e-mail, phone calls and other fragments of signals intelligence, or SIGINT.
To handle the expanding workload, the NSA created a secret unit known as the
Counter-Terrorism Mission Aligned Cell, or CT MAC, to concentrate the
agencys vast resources on hard-to-find terrorism targets. The unit spent a
year tracking Ghul and his courier network, tunneling into an array of
systems and devices, before he was killed. Without those penetrations, the
document concluded, this opportunity would not have been possible.
At a time when the NSA is facing intense criticism for gathering data on
Americans, the drone files may bolster the agencys case that its resources
are focused on fighting terrorism and supporting U.S. operations overseas.
Ours is a noble cause, NSA Director Keith B. Alexander said during a public
event last month. Our job is to defend this nation and to protect our civil
liberties and privacy.
The documents do not explain how the Ghul e-mail was obtained or whether it
was intercepted using legal authorities that have emerged as a source of
controversy in recent months and enable the NSA to compel technology giants
including Microsoft and Google to turn over information about their users.
Nor is there a reference to another NSA program facing scrutiny after
Snowdens leaks, its metadata collection of numbers dialed by nearly every
person in the United States.
To the contrary, the records indicate that the agency depends heavily on
highly targeted network penetrations to gather information that wouldnt
otherwise be trapped in surveillance nets that it has set at key Internet
The new documents are self-congratulatory in tone, drafted to tout the NSAs
counterterrorism capabilities. One is titled CT MAC Hassan Gul Success. The
files make no mention of other agencies roles in a drone program that
escalated dramatically in 2009 and 2010 before tapering off in recent years.
Even so, former CIA officials said the files are an accurate reflection of
the NSAs contribution to finding targets in a campaign that has killed more
than 3,000 people, including thousands of alleged militants and hundreds of
civilians, in Pakistan, according to independent surveys. The officials said
the agency has assigned senior analysts to the CIAs Counterterrorism Center,
and deployed others to work alongside CIA counterparts at almost every major
U.S. embassy or military base overseas.
NSA threw the kitchen sink at the FATA, said a former U.S. intelligence
official with experience in Afghanistan and Pakistan, referring to the
Federally Administered Tribal Areas, the region in northwest Pakistan where
al-Qaedas leadership is based.
NSA employees rarely ventured beyond the security gates of the U.S. Embassy
in Islamabad, officials said. Surveillance operations that required placing a
device or sensor near an al-Qaeda compound were handled by the CIAs
Information Operations Center, which specializes in high-tech devices and
close-in surveillance work.
But if you wanted huge coverage of the FATA, NSA had 10 times the manpower,
20 times the budget and 100 times the brainpower, the former intelligence
official said, comparing the surveillance resources of the NSA to the smaller
capabilities of the agency's IOC. The two agencies are the largest in the
U.S. intelligence community, with budgets last year of $14.7 billion for the
CIA and $10.8 billion for the NSA. We provided the map, the former official
said, and they just filled in the pieces.
In broad terms, the NSA relies on increasingly sophisticated versions of
online attacks that are well-known among security experts. Many rely on
software implants developed by the agencys Tailored Access Operations
division with code-names such as UNITEDRAKE and VALIDATOR. In other cases,
the agency runs man-in-the-middle attacks in which it positions itself
unnoticed midstream between computers communicating with one another,
diverting files for real-time alerts and longer-term analysis in data
Through these and other tactics, the NSA is able to extract vast quantities
of digital information, including audio files, imagery and keystroke logs.
The operations amount to silent raids on suspected safe houses and often are
carried out by experts sitting behind desks thousands of miles from their
The reach of the NSAs Tailored Access Operations division extends far beyond
Pakistan. Other documents describe efforts to tunnel into systems used by
al-Qaeda affiliates in Yemen and Africa, each breach exposing other
An operation against a suspected facilitator for al-Qaedas branch in Yemen
led to a trove of files that could be used to help NSA map out the movement
of terrorists and aspiring extremists between Yemen, Syria, Turkey, Egypt,
Libya and Iran, according to the documents. This may enable NSA to better
flag the movement of these individuals to allied security services that can
put individuals on no-fly lists or monitor them once in country.
A single penetration yielded 90 encrypted al-Qaeda documents, 16 encryption
keys, 30 unencrypted messages as well as thousands of chat logs, according
to an inventory described in one of the Snowden documents.
The operations are so easy, in some cases, that the NSA is able to start
downloading data in less time than it takes the targeted machine to boot up.
Last year, a user account on a social media Web site provided an instant
portal to an al-Qaeda operatives hard drive. Within minutes, we
successfully exploited the target, the document said.
The hunt for Ghul followed a more elaborate path.
Ghul, who is listed in other documents as Mustafa Haji Muhammad Khan, had
surfaced on U.S. radar as early as 2003, when an al-Qaeda detainee disclosed
that Ghul escorted one of the intended hijackers to a Pakistani safe house a
year before the Sept. 11, 2001, attacks.
A trusted facilitator and courier, Ghul was dispatched to Iraq in 2003 to
deliver a message to Abu Musab al-Zarqawi, the al-Qaeda firebrand who angered
the networks leaders in Pakistan by launching attacks that often slaughtered
innocent Muslims.
When Ghul made another attempt to enter Iraq in 2004, he was detained by
Kurdish authorities in an operation directed by the CIA. Almost immediately,
Ghul provided a piece of intelligence that would prove more consequential
than he may have anticipated: He disclosed that bin Laden relied on a trusted
courier known as al-Kuwaiti.
The ripples from that revelation wouldnt subside for years. The CIA went on
to determine the true identity of al-Kuwaiti and followed him to a heavily
fortified compound in Abbottabad, Pakistan, where bin Laden was killed in
Because of the courier tip, Ghul became an unwitting figure in the
contentious debate over CIA interrogation measures. He was held at a CIA
black site in Eastern Europe, according to declassified Justice Department
memos, where he was slapped and subjected to stress positions and sleep
deprivation to break his will.
Defenders of the interrogation program have cited Ghuls courier disclosure
as evidence that the agencys interrogation program was crucial to getting
bin Laden. But others, including former CIA operatives directly involved in
Ghuls case, said that he identified the courier while he was being
interrogated by Kurdish authorities, who posed questions scripted by CIA
analysts in the background.
The debate resurfaced amid the release of the movie Zero Dark Thirty last
year, in which a detainees slip after a brutal interrogation sequence is
depicted as a breakthrough in the bin Laden hunt. Ghuls case also has been
explored in detail in a 6,000-page investigation of the CIA interrogation
program by the Senate Intelligence Committee that has yet to be released.
Sen. Dianne Feinstein (D-Calif.), the chairman of the panel, sought to settle
the Ghul debate in a statement last year that alluded to his role but didnt
mention him by name.
The CIA detainee who provided the most significant information about the
courier provided the information prior to being subjected to coercive
interrogation techniques, Feinstein said in the statement, which was signed
by Sen. Carl Levin (D-Mich.).
The George W. Bush administrations decision to close the secret CIA prisons
in 2006 set off a scramble to place prisoners whom the agency did not regard
as dangerous or valuable enough to transfer to Guantanamo Bay. Ghul was not
among the original 14 high-value CIA detainees sent to the U.S. installation
in Cuba. Instead, he was turned over to the CIAs counterpart in Pakistan,
with ostensible assurances that he would remain in custody.
A year later, Ghul was released. There was no public explanation from
Pakistani authorities. CIA officials have noted that Ghul had ties to
Lashkar-e-Taiba, a militant group supported by Pakistans intelligence
service. By 2007, he had returned to al-Qaedas stronghold in Waziristan.
In 2011, the Treasury Department named Ghul a target of U.S. counterterrorism
sanctions. Since his release, the department said, he had helped al-Qaeda
reestablish logistics networks, enabling al-Qaeda to move people and money in
and out of the country. The NSA document described Ghul as al-Qaedas chief
of military operations and detailed a broad surveillance effort to find him.
The most critical piece came with a discovery that provided a vector for
compounds used by Ghul, the document said. After months of investigation, and
surveillance by CIA drones, the e-mail from his wife erased any remaining
Even after Ghul was killed in Mir Ali, the NSAs role in the drone strike
wasnt done. Although the attack was aimed at an individual believed to be
the correct target, the outcome wasnt certain until later when, through
SIGINT, it was confirmed that Hassan Ghul was in fact killed.

@_date: 2013-10-17 22:45:05
@_author: Eugen Leitl 
@_subject: Curious RNG stalemate [was: use of cpunks] 
There's an ARM system in there: but in principle you can resurrect something like that, or
wait until the company sees fit to sell that product again.
You don't need radiation. 12 USD USB SDR can sample 1.5 Msamples/s
at 8 bit, and is as simple as it gets, and is amplifies effectively quantum
noise. I'm not sure how complex is, but you can certainly decap a representative sample from
each lot to validate it.
Seems like a decent business idea.

@_date: 2013-10-18 09:54:46
@_author: Eugen Leitl 
@_subject: Curious RNG stalemate [was: use of cpunks] 
Are they?
This is analog electronics 101. All you have is to sample
that at sufficient rate on the cheap. That used to be a problem, but
no longer is
We do not want a dinky little entropy drip. We want a
regular firehose. The USB RTL samples at 1.4 MSamples/s. Total part costs is probably 20 USD, in bulk.
Why is nobody selling a kit like that? Because worrying about
sufficient entropy in crypto settings is a terribly niche thing.
Now try for a decent clock. (Hint: time-nuts. And did you
know they use CSACs for IED trigger jamming?).

@_date: 2013-10-18 10:37:13
@_author: Eugen Leitl 
@_subject: Curious RNG stalemate [was: use of cpunks] 
I have a couple older VIA C3 with hardware RNG, bought long ago for just that purpose. What kind of motherboard is in there, do you know?
It is unauditable, just as any integrated RNG sources. Which
is not that big of problem, if you mix in enough external entropy
from a trusted source. The trusted source need to be sufficiently
simple to be validated by inspection. You can source RTL-SDRs
from many sources. All you need is to match impedance and output
power from your analog white noise circuit to goldilocks level.
In case anyone is interested,
But there is still no simple kit you could directly plug into your
coax socket. That is a threshold of entry too high for people
who can't tell which part of the soldering iron is the hot one.

@_date: 2013-10-18 11:02:42
@_author: Eugen Leitl 
@_subject: HTML List Abuse (was: "please ignore: this is only a test") 
Many people concerned with security use text-only MUAs,
as that works well over low-bandwidth mobile links and
gives less attack surface against compromises.
The less complexity, the less lines of codes and code
complexity and easier to debug. E.g. by not discarding
HTML-only (but giving preference to plain text in
multipart messages) I'm running risk for having this system
compromised, even if I render via a text browser
like links. That's ok, I consider this system sacrificial.
Rendering rich content in a GUI is courting disaster.
You will get nailed, and be it just malware from spam.
You can assume that people who care know this, so
text-only correlates with old hands and/or high clue.

@_date: 2013-10-18 16:55:46
@_author: Eugen Leitl 
@_subject: Police warning after drug traffickers' cyber-attack 
Eat your heart out, William Gibson.
Police warning after drug traffickers' cyber-attack
By Tom Bateman
Reporter, Today programme
Drug traffickers hacked into the computer controlling shipping containers at
the port of Antwerp
Earlier this year drug traffickers hacked into the computer controlling
shipping containers at the port of Antwerp
The head of Europe's crime fighting agency has warned of the growing risk of
organised crime groups using cyber-attacks to allow them to traffic drugs.
The director of Europol, Rob Wainwright, says the internet is being used to
facilitate the international drug trafficking business.
His comments follow a cyber-attack on the Belgian port of Antwerp.
Drug traffickers recruited hackers to breach IT systems that controlled the
movement and location of containers.
Police carried out a series of raids in Belgium and Holland earlier this
year, seizing computer-hacking equipment as well as large quantities of
cocaine and heroin, guns and a suitcase full of cash.
Fifteen people are currently awaiting trial in the two countries.
Mr Wainwright says the alleged plot demonstrates how the internet is being
used as a "freelance marketplace" in which drug trafficking groups recruit
hackers to help them carry out cyber-attacks "to order".
"[The case] is an example of how organised crime is becoming more
enterprising, especially online," he says.
A Europol official tells Tom Bateman how traffickers hacked into the IT
system at Antwerp port "We have effectively a service-orientated industry
where organised crime groups are paying for specialist hacking skills that
they can acquire online," he adds.
Vanishing containers
The attack on the port of Antwerp is thought to have taken place over a
two-year period from June 2011.
Prosecutors say a Dutch-based trafficking group hid cocaine and heroin among
legitimate cargoes, including timber and bananas shipped in containers from
South America.
The organised crime group allegedly used hackers based in Belgium to
infiltrate computer networks in at least two companies operating in the port
of Antwerp.
The breach allowed hackers to access secure data giving them the location and
security details of containers, meaning the traffickers could send in lorry
drivers to steal the cargo before the legitimate owner arrived.
Workers were first alerted to the plot when entire containers began to
disappear from the port without explanation.
"These criminal organisations always look for a new way to get drugs out of
the harbour," says Danny Decraene who heads the Antwerp organised crime unit
of the Belgian Federal Police.
Bag of cash seized by Belgian police
This suitcase, containing 1.3m euros, was seized by Belgian police during
raids on drug traffickers
"In this case they hired hackers [who were] very high level, intelligent
guys, doing a lot of software work," he adds.
He says the operation to hack the port companies took place in a number of
phases, starting with malicious software being emailed to staff, allowing the
organised crime group to access data remotely.
When the initial breach was discovered and a firewall installed to prevent
further attacks, hackers broke into the premises and fitted key-logging
devices onto computers.
This allowed them to gain wireless access to keystrokes typed by staff as
well as screen grabs from their monitors.
Assault rifle attack
Mr Decraene says the total quantity of drugs trafficked by the group is
unknown, but in a series of raids earlier this year police seized more than a
tonne of cocaine, with a street value of 130m, and a similar amount of
In January a lorry driver unconnected to the plot was shot at after he had
unwittingly driven a container allegedly filled with cocaine from the
terminal at Antwerp.
The attack took place in the province of Limburg, where suspects armed with
AK-47 assault rifles fired at the driver, who was unharmed.
Following the cyber-attack in Antwerp, a joint operation by Belgian and Dutch
police resulted in raids on more than 20 homes and businesses.
Officers seized six firearms including a machine gun and silencer,
bullet-proof vests, and 1.3m euros (1.1m) in cash inside a suitcase.
Mr Wainwright says the IT attack is consistent with a "new business model" of
organised crime activity and he says he expects this kind of cyber-security
breach to "become a more significant feature in future" of drug trafficking.
"What it means therefore is that the police need to change the way they
operate - they have to become much more tech savvy," he says.
"But also I think governments and parliaments need to help us to make sure
therefore that we have the right laws to fight back against this massive
exploitation of the internet," he adds.
Container companies operating out of the port of Antwerp say their IT
security has now been improved.

@_date: 2013-10-19 16:02:44
@_author: Eugen Leitl 
@_subject: HTML List Abuse (was: "please ignore: this is only a test") 
Moon Jones sees no added value as he subscribes to the very same
lists as me. (There is added value for less omniscient/omnipresent, though in order to see it you have to see it from my point of view, and it's not super-big -- I'm mostly a Layer 8 router).
I presume filtering for duplicates is easier if I do bounces,
so I'll do more of that in future.  The relevance is in the followup threads others generate.
I don't do helpdesks, sorry.

@_date: 2013-10-19 16:22:01
@_author: Eugen Leitl 
@_subject: HTML List Abuse (was: "please ignore: this is only a test") 
I'm highly sympathetic to your plight, and suggest the
following solution: install a procmail recipe to filter
out dupes with the same message ID (e.g. <5261AAC3.6050102 at mbox301.swipnet.se> in case of the mail I'm replying to) and/or matching Resent-Message-ID: with leitl.org behind it.

@_date: 2013-10-19 18:18:01
@_author: Eugen Leitl 
@_subject: Cheney afraid of terrist h4x0rs 
Cheney had heart device partially disabled to prevent a terrorist from
sending a fatal shock
Olivia Harris, Pool, File/Associated Press -  In an interview with CBS 60
Minutes, former Vice President Dick Cheney says he once feared that
terrorists could use the electrical device that had been implanted near his
heart to kill him and had his doctor disable its wireless function.
By Associated Press, Saturday, October 19, 1:34 AM
WASHINGTON  Former Vice President Dick Cheney says he once feared that
terrorists could use the electrical device that had been implanted near his
heart to kill him and had his doctor disable its wireless function.
Cheney has a history of heart trouble, suffering the first of five heart
attacks at age 37. He underwent a heart transplant last year at age 71.
In an interview with CBS 60 Minutes, Cheney says doctors replaced an
implanted defibrillator near his heart in 2007. The device can detect
irregular heartbeats and control them with electrical jolts.
Cheney says that he and his doctor, cardiologist Jonathan Reiner, turned off
the devices wireless function in case a terrorist tried to send his heart a
fatal shock.
Years later, Cheney watched an episode of the Showtime series Homeland in
which such a scenario was part of the plot.
I found it credible, Cheney tells 60 Minutes in a segment to be aired
Sunday. I know from the experience we had, and the necessity for adjusting
my own device, that it was an accurate portrayal of what was possible.
Cheney and Reiner are promoting a book they co-authored, Heart: An American
Medical Odyssey.
In the 60 Minutes interview, Reiner says he worried that Cheney couldnt
stand the pressure that came on Sept. 11, 2001, the day terrorists attacked
the U.S. Medical tests seen that morning showed Cheney had elevated levels of
potassium in his blood, a condition called hyperkalemia, which could lead to
abnormal heart rhythms and cardiac arrest.
Reiner says he watched news coverage of the days events on television and
thought, Oh, great, the vice president is going to die tonight from

@_date: 2013-10-21 14:10:49
@_author: Eugen Leitl 
@_subject: The Most Lethal Weapon Americans Faced in Iraq 
(did you see the LEDs blink?)
October 18, 2013, 10:35 am Comment
The Most Lethal Weapon Americans Faced in Iraq
By JOHN ISMAY
In the first part of this series, At War explored the various conventional
weapons used by insurgents in Iraq, as evidenced by reports, called
storyboards, written by United States forces detailing the contents of
captured weapons caches. Often times these weapons had been considered
obsolete before 2003. But they were well known to Western intelligence
services and militaries.
Today, we look at weapons that the American military could not have
reasonably foreseen entering the fray, but that caused large numbers of
casualties. These are the improvised weapons that were made by hand, or in
small shops, and that, with one exception, were not made in industrial
Improvised Explosive Devices
At the time these storyboards were written, improvised explosive devices, or
I.E.D.s, caused approximately 80 percent of all coalition casualties.
 Page 1 of  27 
A network of insurgents financed, designed and manufactured these weapons.
Skilled bomb makers worked in clandestine shops, and leaders of I.E.D.
networks sent bomb emplacers to bury or hide their improvised bombs along
routes American patrols were expected to take.
Standard bomb-making equipment showed up again and again in the caches,
including: multimeters for checking the electrical continuity in circuits;
personal mobile radios for transmitting firing signals; switches to close
circuits; electric blasting caps; detonating cord for when multiple charges
were used.
Earlier firing systems often employed a variety of radio-controlled features.
Keyless entry fobs for automobiles, garage door openers, toy car controllers
 these all provided parts for initiating bombs, at least until coalition
electronic countermeasures made them almost completely ineffective. Other
common articles took their place.
Insurgents stripped timers from washing machines, or bought them by the
hundreds from commercial sources. Motion sensors meant to open grocery store
doors or to turn on security floodlights also found their way into bomb-maker
supply bins. These devices could trip a switch and initiate an explosion when
a soldier crossed their path.
The first bomb emplacers, many of them uneducated youth, sometimes blew
themselves up while connecting the basic components of their weapons: power
source, switch and explosive charge. They were supposed to connect these
parts with an open circuit, since connecting a closed circuit would send
current to an electric blasting cap. If that happened, it usually meant
instant death for the emplacer. To make bomb emplacement less
catastrophically failure-prone, bomb makers searched for devices that could
mechanically break the electric circuit. The washing machine timer was one
that worked. All the emplacer had to do was wind it up before connecting the
circuit and he would have a set amount of time to escape before the bomb was
armed. The use of these timers showed an adaptive enemy who learned from his
Explosively Formed Penetrators and Iranian C4
The single most lethal weapon American forces faced in Iraq was the
explosively formed penetrator, or E.F.P. Unlike other I.E.D. charges, E.F.P.
warheads required some skilled milling as well as heavy presses to produce.
Certain copper alloys were used as well, and analysis of their construction
was used to pinpoint the manufacturers.
What makes E.F.P.s so deadly is that they form slugs at detonation that
maintain their shape over distances of over 100 yards or more, traveling at
speeds of nearly a mile per second. This allowed insurgent forces to hide
these weapons far from the road, better camouflaging them and making them far
more deadly. In some I.E.D. factories, American forces found E.F.P.s
camouflaged to look like trash or rocks.
Much has been made of E.F.P.s generally being new Iranian weapons, but
that conflates two unrelated facts. First, E.F.P.s technology was invented
in the late 1930s by the oil industry to punch holes through the metal pipe
in wells and into the rock outside. These are called oil well perforators or
perforator guns. Any country engaged in oil field development has access to
E.F.P.s. Iran lists their domestically produced perforators for sale online.
Second, militaries applied this technology to anti-armor weapons as early as
World War II. (The United States military currently employs several weapons
incorporating E.F.P. warheads, to include the M2 SLAM, the TOW-2B, and the
M303 SOF Demolition Kit.)
But they became known as Iranian weapons because American intelligence
agencies reported that Iran passed E.F.P. technology to the Lebanese militia
Hezbollah, which in turn passed E.F.P. kits to proxy groups fighting in Iraq.
In the case of the Iraqi insurgent weapons, E.F.P.s arrived in kit form, and
were hand-packed with plastic explosives by bomb makers in Iraq just before
use. For their explosive charges, insurgents often turned to an Iranian copy
of an American staple: C4, packaged nearly identically to the original
1.25-lb M112 blocks. (Of note, the American M112 blocks changed their
markings slightly in 1996 once chemical tracers, called taggants, were added
in accordance with federal law; Iranian M112 block markings mimic the
pre-1996 markings.) According to an official with the Bureau of Alcohol,
Tobacco, Firearms and Explosives, manufacturing C4 is not difficult for any
nation capable of making industrial chemicals.
Homemade Explosives
Not long after the invasion, insurgents began mixing their own batches of
explosives and using them against their American adversaries. At first, these
mixtures were referred to simply as U.B.E.  unknown bulk explosive. Later,
the term HME, for homemade explosive, came into wide use.
As an agrarian society, Iraq had a nonstop demand for nitrated fertilizers 
urea and ammonium nitrate being the most common. Ground urea, mixed with
nitric acid, drained and dried, is a powerful explosive. Some caches held
bags of hexamethylenetetranitramine, which when mixed with nitric acids
produces a powerful explosive known as RDX. Still others combined ammonium
nitrate and diesel fuel oil to create the same explosive Timothy McVeigh used
to level the Alfred P. Murrah Federal Building in Oklahoma City in 1995.
Fertilizer plants, such as this one at Baiji, produced 500,000 tons of
fertilizer per year.
When homemade explosives first came into wide use in Iraq, American military
officers initially thought it was a sign that the insurgents were running out
of conventional or military-grade, munitions. That assumption had no basis
in fact. What it did signal was that the enemy had realized that bulk
explosives were more valuable and, in certain situations, more lethal.
Experience showed that a large enough charge could destroy any armor, or at
least wreak enough damage to cause casualties inside the targeted vehicle. In
Afghanistan, homemade explosives became such a problem for NATO forces that
President Hamid Karzais government banned ammonium nitrate in 2010.
End State
Although the last United States Army mission to destroy excess ordnance ended
in November 2011, violence in Iraq has continued well past the withdrawal of
the last American combat forces. According to the United Nations, nearly
1,000 Iraqi civilians were killed in September alone, amid levels of violence
last seen in 2008.
Between 2003 and 2010, the State Department spent more than $200 million on
destroying unexploded munitions in the country. Groups like Mines Advisory
Group continue their work in Iraq as well.
In July 2012, the State Departments own Web site gives an idea of the
challenges that lie ahead: In spite of progress, at least 719 square miles of
land is still contaminated by as many as 20 million land mines and millions
of pieces of unexploded ordnance. More than 1,600 municipalities are
affected, as are huge swathes of farmland, meaning clearing those explosives
will be an economic necessity. And as American forces discovered early in the
insurgency  and which Iraqis know all too well  every weapon and every
explosive that is not disposed of will eventually be put to destructive use
by some faction.
John Ismay is a former U.S. Navy Explosive Ordnance Disposal officer who
served in Iraq in 2007, and is now a member of Columbia Journalism Schools
class of 2014. Follow him on Twitter ( and on his blog

@_date: 2013-10-21 14:18:22
@_author: Eugen Leitl 
@_subject: The Secret History of =?utf-8?Q?Iraq?= =?utf-8?B?4oCZcw==?= 
(notice the date)
The Secret History of Iraqs Invisible War
BY NOAH SHACHTMAN 06.14.114:00 AM
In the early years of the Iraq war, the U.S. military developed a technology
so secret that soldiers would refuse to acknowledge its existence, and
reporters mentioning the gear were promptly escorted out of the country. That
equipment  a radio-frequency jammer  was upgraded several times, and
eventually robbed the Iraq insurgency of its most potent weapon, the
remote-controlled bomb. But the dark veil surrounding the jammers remained
largely intact, even after the Pentagon bought more than 50,000 units at a
cost of over $17 billion.
Recently, however, I received an unusual offer from ITT, the defense
contractor which made the vast majority of those 50,000 jammers. Company
executives were ready to discuss the jammer  its evolution, and its
capabilities. They were finally able to retell the largely-hidden battles for
the electromagnetic spectrum that raged, invisibly, as the insurgencies
carried on. They were prepared to bring me into the R&D facility where
company technicians were developing what could amount to the ultimate weapon
of this electromagnetic war: a tool that offers the promise of not only
jamming bombs, but finding them, interrupting GPS signals, eavesdropping on
enemy communications, and disrupting drones, too. The first of the these
machines begins field-testing next month.
On a fist-clenchingly cold winter morning, I took a train across the Hudson
River to the secret jammer lab.
Tucked behind a Target and an Olive Garden knock-off, the flat, anonymous
office building gives no hint of whats inside. Nor do the blank,
fluorescent-lit halls. But open a door off of one of those halls, and people
start screaming.
Screens off! barks a man with a fullbacks build. Turn off the test
equipment! On the ceiling, a yellow alarm light flashes and spins  the sign
that someone without a security clearance is in a classified facility.
Afghan militants began attacking U.S. troops with improvised explosive
devices in the first days after the October 2001 invasion. By early 02,
al-Qaida bomb-makers were cramming radio frequency receivers and simple
digital signal decoders into the bases of Japan InstaLite fluorescent lamps.
Then theyd connect the two-and-a-half inch wide lamp bases to firing
circuits, and to Soviet-era munitions. The result was a crude,
radio-controlled weapon dubbed the Spider by the Americans. With it, an
attacker could wait for his prey, set off the bomb at just the right moment 
and never have to worry about getting caught. When the explosion happened,
hed be hundreds of yards away.
Worse, U.S. forces had no way of blocking the Spiders triggering signal.
Military bomb squads carried around a few half-assed jammers. But they
couldnt be mounted on vehicles, and they were too weak to provide
protection beyond a few yards, Rick Atkinson notes in his exquisite history,
Left of Boom: The Struggle to Defeat Roadside Bombs.
If somebody sits a kilometer away with a radio and targets our guys, weve
got no ability to get him. Navy engineers hustled to build something a
little stronger, and a little more portable. By November of 2002, they had a
jammer called Acorn that was hard-wired to stop Spiders. It wasnt much. As a
so-called active jammer, the Acorn put out a relatively-indiscriminate
barrage signal that ate up power and generated all kinds of interference.
That kept its effective radiated power  the amount of signal hitting any one
bomb receiver  low. The signal was so weak, the jammer had to be left on and
screaming constantly. Otherwise, troops would be inside the bombs danger
radius before they ever had a chance to block it. Worse, it could only block
the specific receivers used in Spiders. If the bombers switched frequencies,
the countermeasure would be useless.
Meanwhile, the Army looked for ways to modify its Shortstop Electronic
Protection System, designed to shield troops from artillery and mortar fire.
This was a so-called reactive countermeasure. It monitored the airwaves,
listening for one of the radio signals used by the munitions proximity
fuses. Once the countermeasure heard that signal, Shortstop recorded it,
modified it, and then blasted it back at the munition. By confusing the
weapons with their own signals, Shortstop could fool the shells into
prematurely detonating.
The soldiers tweaked the Shortstop to scan for radio-controlled bombs
triggering frequencies, and to rely on a Humvees power supply. The wife of
one Fort Monmouth engineer collected miniature kitchen witches that inspired
a new name for the device: Warlock Green, Atkinson recounts.
Five Warlock Greens accompanied U.S. forces into Iraq in March, 2003. By
mid-summer, there were 100 jammers in the warzone. It wasnt nearly enough.
Iraqs militants had learned from their compatriots in Afghanistan, and were
setting off remotely-detonated explosives everywhere.
Just like the first turn of this improvised explosive device (IED) war, the
electronic countermeasures were having trouble keeping up with the bombs. It
took Warlock Green, ultimately manufactured by the EDO Corporation, a couple
of seconds to record, modify, and rebroadcast a triggering signal. An
insurgent bomber could set off an explosive in a few fractions of a second,
if he had a simple, low-powered trigger, like a garage door opener. The
jammer didnt have time to catch up.
The jammers could only cover a small slice of the radio frequency spectrum.
Whenever the insurgents should change triggers  from say, door openers to
key fobs  the jammer-makers would have to go back to the drawing board.
Warlock Greens could be reprogrammed, within limits. The Acorns couldnt; the
new threats rendered them useless.
Every time we put a countermeasure in the field  especially with Warlock 
they were able to outstrip it, says Paul Mueller, a long-time defense
executive, who supervised jammer-building operations at EDO  and at the ITT
Corporation. They were a step ahead of us.
Every time we used a countermeasure, they were able to outstrip it. But
with insurgents setting off 50 IEDs a week, even the step-behind jammers were
better than no jammers at all. By May 1, 2004  one year to the day since
President George W. Bush declared the end of major combat operations  the
improvised bombs had wounded more than 2,000 American troops in Iraq. The
IEDs killed 57 servicemembers in April alone, and injured another 691. IEDs
are my number-one threat in Iraq. I want a full-court press on IEDs, Gen.
John Abizaid, then the top military commander in the Middle East, wrote in a
June 2004 memo.
In the early fall of 2004, the Army signed a contract for 1,000 Warlocks. By
March, 2005, the Army upped that order to 8,000 jammers. It was a high-tech,
electromagnetic surge. And it was meant to send the militants sliding back
down the scale of sophistication. If somebody can sit a click [kilometer]
away with a radio and target our guys, weve got almost no ability to get
him, says a source familiar with the jammer buildup. But if hes doing the
Wile E. Coyote thing, and pushing down that plunger, at least weve got some
chance to shoot him before he gets it down.
All the big defense contractors  and lots of little ones  got into the
electronic countermeasure business. The Marines bought one model; the Army
another; Special Operations Forces, a third. The Army began buying Warlock
Reds  small, active jammers that blocked out the low-powered triggers that
Warlock Green couldnt stop in time. Warlock Blue was a wearable jammer, to
protect the infantryman on patrol. Each countermeasure had its shortcomings;
Warlock Blue, for instance, was a half-watt jammer at a time when some
engineers suspected that 50 watts might be too weak, Atkinson notes. But no
commander could afford to wait for a perfect, common bomb-stopper; too many
men were getting blown up. By May 1, 2005, the number of U.S. troops wounded
by the bombs had climbed to more than 7,700.
There were drawbacks to throwing all those countermeasures into the field at
once. Warlock Green would sometimes mistake Warlock Reds signal for an
enemys, and go after it. That would lock the jammers in a so-called deadly
embrace, cancelling one another out.
When the Warlocks were operational, they wreaked havoc with both the
remote-controlled robots that were supposed to handle bombs at a safe
distance and the radios soldiers used to warn each other about upcoming
threats. Warlock Red prevented communications from three of the Armys most
common radio systems, according to a classified report released by WikiLeaks.
The report recommended keeping radios and countermeasures in different
vehicles to prevent the electronic fratricide. Of course, that meant a
soldier with a jammer in his Humvee was cut off from the rest of his convoy.
For reporters, pointing out these drawbacks  in fact, pointing out anything
about the jammers  risked a swift military response. In Baghdad, a top
official with the Joint IED Task Force called me an al-Qaida ally for putting
together a Wired.com report on counter-IED technologies based on other
publicly-available information. A few months later, David Axe mentioned the
Warlocks in a post for Defensetech.org from Iraq. Shortly after the post went
live, Axe was detained, and was promptly thrown out of the country.
Even more secret were the flights of the jammers in the sky. The Navys EA-6
Prowlers could not only block triggering signals; they could remotely
detonate the bombs, as well. But they had to be very, very careful. U.S.
vehicles equipped with jammers had to get off of the roads, or risk the
deadliest embrace of all. Pilots had to make sure that civilians were nowhere
nearby, when they set the bombs off.
Despite the hiccups, the jammers were saving lives  including, I believe, my
In July of 2005, I found myself at a rubble-strewn intersection of two
highways, not far from Iraqs Abu Ghraib prison. The Explosive Ordnance
Disposal team I was traveling with called this place the Death X, because
of all the attacks nearby. The bomb squad was called out to the area because
of a suspicious package  a package that turned out to be nothing more than a
balled-up pair of pants. But on the way back from the incident, our Humvee
rolled over an artillery shell, buried in the highways middle lane and wired
to a radio. An improvised bomb.
The IED didnt go off, for reasons that werent completely clear. The Death X
bomber might have gotten cold feet. More likely, one of Warlocks in the
Humvee prevented him from detonating the weapon.
That same day, I took a Black Hawk ride to the town of Mahmudiya, just south
of Baghdad. At the outpost there, I met Staff Sgt. Johnnie Mason (pictured),
who showed off the cordless phone than nearly killed him. It was wired to a
series of artillery shells, and stuffed under a row of human corpses, rotting
by a canal in the 118 degree heat.
The dead bodies, they smelled like catfish bait.
When Mason  a lanky, 31 year-old Texan with big brown eyes and a goofy smile
 came across the bomb, he wanted to puke into his Kevlar protective suit.
The dead bodies, they smelled like catfish bait. But there was no time to
heave. Mason knew the weapon was live, and that he was outside his Warlocks
protective bubble. He figured he only had a moment or two to act before a
bomber remotely detonated his device. So Mason jumped behind a three-foot
berm, and crouched into a fetal position before the shock wave hit him. It
was too fast for me to think, Oh God, Im gonna die, Mason said. It was
just instant fear.
The bomb was less than twenty feet away when it went off. Dirt flew up.
Shards of bomb zipped through the air. The shockwave knocked Mason over. But
he was intact, somehow.
Masons partner, Pfc. Brian James, ran over. Are you alright? he yelled.
Where you at?
Im in Iraq, Brook! Mason shouted back. Brook was his wifes name.
Mason sat down for fifteen minutes, drank some water. And then he went right
back to the bodies. Before the explosion, he noticed a second shell, 20
meters away. So Mason took a couple pounds of C4 plastic explosive to
demolish the thing. I still had a job to do, he told me.
Five months later, on the 19th of December, Mason found himself on another
highway, responding to another suspicious package call. His team stumbled on
another IED, practically beneath their feet. Insurgents were routinely luring
bomb squads with one weapon in an attempt to kill them with the second. In
this case, the tactic worked.
Mason told everyone to clear out of the way while he tried to disarm the
device. Then the bomb went off.
Johnnie Mason was buried at Arlington Cemetery on January 10, 2006.
2006 rolled on. The insurgency in Iraq got worse. Much worse. The number of
troops wounded by bombs hit 15,000, and kept going. Explosively formed
projectiles  bombs that shot out jet of molten, armor-piercing metal  went
from a macabre curiosity to something like a staple of the insurgent arsenal.
There seemed to be no end to the carnage.
Militant bombmakers increasingly turned to long range cordless telephones and
cell phones for their triggers. That was a serious issue. The digital devices
were built to overcome dropped packets, reflected signals, and transmission
errors. Warlock Greens trick of fooling a trigger with its own, modified
signal didnt work. The gadgets were used to the hiccups.
The deadly embrace between the jammers began to loosen.
Behind the scenes, however, there were signs of improvement. The Navy sent to
Iraq hundreds of electronic warfare specialists, to bring the cacophony
produced by 14 kinds of jammers into some sort of harmony. Protocols were
established, to allow one device to send its signal and then go silent for a
few milliseconds, so another gadget could broadcast; that allowed Warlock Red
and Warlock Green to be packaged into a single, combination unit. The deadly
embrace between the jammers began to loosen. The Pentagons IED task force
became the Joint IED Defeat Organization, or JIEDDO, with a $3.6 billion
annual budget to tame the homemade bomb threat. Mongtomery Meigs, the retired
four-star general in charge of the organization, worked to unravel the
bureaucratic tangle that tied up bomb trigger analysis. The intelligence
specialists at the Combined Explosive Exploitation Cells got faster and
faster at analyzing which frequencies the insurgents were using. That, in
turn, allowed the jammers to be updated more quickly, so they could counter
emerging threats.
Most importantly, perhaps, a new generation of jammers entered the
battlefield, thanks to JIEDDOs billions. Some, like the Marines Chameleon
countermeasure, could cover a broad range of frequencies, from low-powered
triggers (like key fobs) to high-powered ones (like walkie-talkies). In
February of 06, the Corps announced they were buying 4,000 of the 125-pound,
Humvee-mounted systems.
Warlock Duke used a technique called set-on jamming to overcome the more
advanced digital triggers. Like Green, Duke would listen for a malicious
signal. But rather than confuse a receiver with a modified version of its own
signal, Duke had a series of built-in jamming responses, designed to fool
very specific devices. If Duke heard a particular FM walkie-talkie, Duke
would send out a specific FM spoof. It was actually a cruder technique than
Greens. And it relied on very detailed knowledge about exactly which threats
were in which area. But it worked. Tens of thousands were eventually fielded.
And slowly, slowly, the percentage of radio-controlled bombs as a whole began
to fall. Then they began to disappear altogether.
Electronic warfare defensive systems were instrumental in saving thousands
of Soldiers and Marines from being casualties in Iraq, emails retired Lt.
Gen. Michael Oates, who led the 10th Mountain Division during its tour in
Iraq at the time, and then became director of JIEDDO. The high use of remote
controlled detonation capability was a significant and effective threat
until the jammers were developed.
By the time I returned to Iraq, in the summer of 2007, IEDs had become relics
in broad swaths of the country. The insurgents had largely abandoned their
tool of choice.
It was not altogether good news.
North of Baghdad, insurgents took insulated copper threads, some not much
thicker than a hair, and buried them in the dust. Then they strung them out
for as long as a kilometer. At one end was an insurgent triggerman. At the
other, an explosively formed projectile. It was a crude approach to killing 
even more primitive than those first bombs planted in Afghanistan. But it was
lethally effective.
These command wire bombs had a fatal flaw, however. Insurgents had to stick
around to set them off. That made them vulnerable to American counter-attacks
and preemption. And that brought the number of bombs and bomb fatalities way
down. In December of 2007, only nine U.S. troops were killed by IEDs, and
another 166 were wounded. It was still an awful toll. But it was a tiny
fraction of the 69 slain and 473 injured in December of 2006.
All the gadgets built for Iraq were worthless against Afghanistans throwback
The casualty figures continued to fall as the military began to field a third
generation countermeasure  one that could stomp out a huge swath of radio
triggers with all sorts of jamming techniques. In April of 2007, the Pentagon
signed a deal with EDO for up to 10,000 of the so-called CVRJs. Shortly
thereafter, ITT bought EDO, and began to crank out the machines. The CVRJ
held up to 15 mission loads at once, quadrupled the number of simultaneous
channels it could jam on, and doubled the spectral coverage of pre-existing
systems. More importantly, the CVRJ could be reprogrammed on the fly: not
just the frequencies it covered, but the specific responses it used to
counter particular threats. For the first time ever, says Mueller, the
EDO-turned-ITT executive, we had a canvas to create a painting.
That enabled CVRJ to target the most advanced triggers  the ones which
relied on the latest mobile and long-range cordless phones. The new phones
hopped between frequencies and spread their signal across the spectrum to
overcome interference. That made them much harder to jam. But the phones have
a potential flaw. They relied on software protocols to establish connections
between transmitter and receiver. Those protocols could be spoofed, keeping
the connection from ever happening. That is, if you had a fully programmable
countermeasure, like CVRJ.
In the broadest sense, the strategy behind the U.S. jammer buildup had
succeeded. Thanks to the Americans bleeding edge technologies, the militants
had dropped back down the ladder of sophistication. They were now taking the
Wile E. Coyote approach  pushing down the plunger to detonate the bomb  and
suffering for it. That was the whole intent of the program: pushing the
enemy back to archaic means, says a source familiar with the effort. So
theyd actually have to face you and fight you.
In Afghanistan, however, the terrain favored the low tech. All the gadgets
the Americans had bought and built for Iraq proved largely worthless against
a new slew of throwback threats. The bombs were largely made of wood and
fertilizer, making them practically invisible to metal detectors. No command
wires were needed to set them off; just the pressure of an unlucky boot. The
placement of the bombs added to their effectiveness. The U.S. militarys new
hard-shelled, blast-deflecting vehicles were built for Iraqs well-paved
roads. So the insurgents put their explosives in the gullies and the mud
paths, where the trucks were useless. The bomb-handling robots couldnt
handle the rough terrain, either. And, during the summer, the weather was so
hot, EOD technicians didnt even bother wearing their protective suits.
As the fighting grew more intense  and the U.S.-led coalition poured more
troops into the Afghan campaign  the total number of bombs there crept up,
from 1,931 in 2006 to 3,276 in 2008. By July, 2010, that figure had reached
nearly 1,400 explosives found or detonated a month. Its stayed about that
high ever since.
The deaths and injuries caused by these bombs continued to mount, as well. In
July 2008, 25 American troops were wounded by Afghan IEDs. In July 2009, that
figure was 174. In July 2010, the number was 378 injured  about 15 times
higher than the casualty count from two years before.
JIEDDO shifted its focus to compensate. Jammers alone werent going to do
much against these no-tech weapons. The organization spent more on
surveillance and intelligence analysts, trying to find ways to crack apart
Afghanistans IED networks.
But even if those networks are shredded tomorrow, theres a sense in the
Pentagon that the improvised bomb has now become a permanent threat. Over the
last six months, theres been an average of 245 jury-rigged explosives found
or detonated  outside of Iraq and Afghanistan. The IED has gone global.
The lab where ITT engineers work on the fifth generation of bomb-stoppers
looks like a schoolroom  from the desks facing the front of the room to the
guy with the ponytail and circular glasses delivering the lecture. Behind the
guy  hes an engineer, not an English prof  are two screens. One shows a
CGI version of a jammers guts: the amplifiers, the transceivers, what have
you. The other screen shows a map of a military base, covered in red and
green. It shows how the countermeasure might perform with that configuration.
The Pentagon cant afford any more to crank out yet another stop-gap
countermeasure for yet another kind of bomb. So the military is instead
backing the development of a jammer that can be used anywhere, and for years
to come. The system is awkwardly known as Joint Counter Radio-Controlled
Improvised Explosive Device Electronic Warfare 3.3. An initial batch of 21 of
these JCREW machines are supposed to ship to the military in July for field
testing. If it passes those trials, among other hurdles, up to 20,000 of the
uber jammers could eventually be built.
Aircraft, vehicles, ships, and troops are all on the new jammers target
list.  But before it gets into troops hands, the countermeasure gets
simulated here. Lower the antenna from 15 feet to five makes more red
splotches appear on the map, indicating gaps in jammer coverage. Add a bigger
amplifier, and some of the red goes away.
ITT has bigger ambitions for its JCREW machine than simple bomb-blocking.
Step through a door, and theres a more traditional-looking electronics
workroom: cable-strewn benches, and machines stacked head-high. Guys with
soldering irons connect wires to boxey machines. The goal here isnt to see
how the countermeasures block signals. Its to see how they talk to one
another. Theres a JCREW jammer designed for vehicles, another for individual
troops, and a third to protect bases. All of the machines are meant to work
The JCREW 3.3s are supposed to be fully networkable, and able to communicate
over the militarys wireless battlefield networks. That should save them some
power and interference if youve got four jammers in a convoy, for instance,
one can silence a receiver while the other three quiet down. Or maybe that
jammer can spot the threat, record its signal and location, and transmit that
information back to headquarters. In that way, the new machine becomes more
than a single bomb-beater. The system might help track down the explosives,
and the guys who planted them. It could be configured to listen in on
communications  those cell phones are for more than triggering explosives,
after all. Hell, if the machines are passing data back and forth, they could
work as radios themselves, in theory.
With proper power management and frequency coordination, the new JCREW could
have a whole new range of potential targets, according to a company
briefing. Those include information systems and infrastructure, drones,
communications grids, sensors, position, navigation and timing capabilities
(thats shorthand for GPS signals), as well as aircraft, vehicles, ships,
troops. In other words: everything.
For now, these are just ideas, not orders. Its all on the roadmap,
potentially, Mueller says. How much we actually do remains to be seen.
But one thing is for sure: its a long way from stopping crude triggers,
stuffed into disposable lamps. Its a long way from frantically tweaking
electronics in the hope of somehow keeping thirty soldiers a day from being
blown up. Its a long way from the near decade-long fight against
remote-controlled bombs in which the enemy had the advantage of being the
first mover. This may be the chance to get ahead, before the next wave of
terror weapons hits.
Photos: USMC, Wikimedia, Noah Shachtman, ITT

@_date: 2013-10-21 14:34:48
@_author: Eugen Leitl 
@_subject: russian FSB requires all ISPs to give them access to metadata by 1 
Source: Not less than 12 hours logging of (all? or meta?) data,
with direct acess given to FSB (SORM, almost certainly
a VPN gateway to FSB like German SINA Box).

@_date: 2013-10-22 10:51:56
@_author: Eugen Leitl 
@_subject: Enigmabox releases source 
Just got word, Enigmabox has published source and
put up first documentation on Roll your own Enigmabox: Not too sure how to get a Debian 7 with minimum pain,
pfSense offers dd'able images. Voyage Linux or Debian for Alix?

@_date: 2013-10-22 11:55:52
@_author: Eugen Leitl 
@_subject: Undernet IPv6 Interop [was: Enigmabox/cjdns] 
Yes. If people are not familiar with cjdns, here's a good
intro I've asked about this a while back among a few IPv6 people, and it does not seem to be a problem. The keys/addresses are randomly generated and are all in FC00::/8. 120 bits is a lot of space. cjdns interoperates fine with dual-stack. The interesting
part is L2 routing over own infrastructure, and eventual
ASIC/FPGAfication of the router.

@_date: 2013-10-25 11:45:13
@_author: Eugen Leitl 
@_subject: Gentlemen do not read each other's mail... 
I see zero evidence that anyone is furious. It's pure political theater to appease those few percent of voting cattle that are privacy-minded. Notice everybody is carefully staying away from mandating simple
and the only measures which would work: strong end to end encryption,
with secrets held by end users, in tamper-proofed compartments.
Because this would seriously compromise their own surveillance
capability. And we certainly can't have that, oh noes.
People in power are used that the common laws are strictly for
the commons, so for those few clueless the outrage to be no
longer exempt might be even genuine.
So ruthlessly machiavellian, or clueless and entitled, pick
your poison.

@_date: 2013-10-28 08:20:42
@_author: Eugen Leitl 
@_subject: Another Snowden News Story. Another Lesson in Proper 
No. Trying to keep short-attention-span people engaged. It might not make a differences, but not even trying
would be foolish.

@_date: 2013-10-28 08:58:24
@_author: Eugen Leitl 
@_subject: Armed agents seize records of reporter, Washington Times prepares 
Armed agents seize records of reporter, Washington Times prepares legal
** FILE ** Associated Press** FILE ** Associated Press By Guy Taylor-The
Washington Times Friday, October 25, 2013
The Washington Times
Maryland state police and federal agents used a search warrant in an
unrelated criminal investigation to seize the private reporting files of an
award-winning former investigative journalist for The Washington Times who
had exposed problems in the Homeland Security Department's Federal Air
Marshal Service.
Reporter Audrey Hudson said the investigators, who included an agent for
Homeland's Coast Guard service, took her private notes and government
documents that she had obtained under the Freedom of Information Act during a
predawn raid of her family home on Aug. 6.
SEE ALSO: Judicial Watch sues IRS for stonewalling on tea party FOIA The
documents, some which chronicled her sources and her work at the Times about
problems inside the Homeland Security Department, were seized under a warrant
to search for unregistered firearms and a potato gun suspected of belonging
to her husband, Paul Flanagan, a Coast Guard employee. Mr. Flanagan has not
been charged with any wrongdoing since the raid.
The warrant, obtained by the Times, offered no specific permission to seize
reporting notes or files.
The Washington Times said Friday it is preparing legal action to fight what
it called an unwarranted intrusion on the First Amendment.
While we appreciate law enforcements right to investigate legitimate
concerns, there is no reason for agents to use an unrelated gun case to seize
the First Amendment protected materials of a reporter, Times Editor John
Solomon said. This violates the very premise of a free press, and it raises
additional concerns when one of the seizing agencies was a frequent target of
the reporters work.
Homelands conduct in seizing privileged reporters notes and Freedom of
Information Act documents raises serious Fourth Amendment issues, and our
lawyers are preparing an appropriate legal response, he said.
Maryland State Police declined comment, except to say that evidence and
information developed during this investigation is currently under review by
both the Anne Arundel County State's Attorney's Office and the United State's
Attorney's Office, and that a determination has yet to be made on any
PHOTOS: Families suspect SEAL Team 6 crash was inside job The U.S. Coast
Guard confirmed it seized and reviewed Ms. Hudsons documents but insisted it
did nothing wrong.
Capt. Tony Hahn, a spokesman at Coast Guard headquarters in Washington, said
the Coast Guard Investigative Service (CGIS) was involved in the case because
Mrs. Hudsons husband, Mr. Flanagan, is a Coast Guard employee.
During the search of the home, said Capt. Hahn, the CGIS agent discovered
government documents labeled FOUO  For Official Use Only and LES  Law
Enforcement Sensitive.
The files that contained these documents were cataloged on the search
warrant inventory and taken from the premises, he said. The documents were
reviewed with the source agency and determined to be obtained properly
through the Freedom of Information Act.
Ms. Hudson described a harrowing ordeal the morning her family home was
The agents, who had arrived a 4:30 a.m. in full body armor, collected several
small arms during the raid, although no charges have been filed against Mr.
Flanagan, 54, during the nearly three months since.
Mrs. Hudson, 50, says that while the authorities were raiding her house,
Coast Guard investigator Miguel Bosch  who formerly worked at the marshal
service  began asking questions about whether she was the same Audrey
Hudson who had written the air marshal stories for The Washington Times.
Mrs. Hudson says she responded that she was.
It was not until roughly a month later, Mrs. Hudson says, that she realized
the agents had quietly seized five files from her private office  including
handwritten and typed notes from interviews with numerous confidential
sources related to her exclusive reporting on the air marshals service.
The search warrant for the raid, issued to Maryland State Trooper Victor
Hodgin by a district court judge, made no reference to the documents. A copy
obtained by The Times indicates that the search was to be narrowly focused on
the pursuit of firearms and their accessories and/or parts, as well as
any communications that that might be found in Mrs. Hudson and Mrs.
Flanagans home related to the acquisition of firearms or accessories.
David W. Fischer, a private attorney contacted by the couple, says that the
raid is a potential violation of Mrs. Hudsons constitutional rights.
Obviously, the warrant is about a gun, nothing about reporters notes, he
said. It would be a blatant constitutional violation to take that stuff if
the search warrant didnt specifically say so.
This is a situation where they picked very specifically through her stuff
and took documents that the Coast Guard, or the Department of Homeland
Security, would be very interested in, he added.
The raid could constitute illegal search and seizure under the Fourth
Amendment  and the fact that the materials were related to her work as a
reporter could First Amendment freedom of the press protections.
Once the documents had been cleared, Homeland decided to return the
documents to Mr. Flanagan and Mrs. Hudson, Capt. Hahn said.
The Coast Guard, like the Federal Air Marshal Service is an agency within the
U.S. Department of Homeland Security.
A Reporters Word
What concerns Mrs. Hudson and The Times is the fact that private reporting
documents were seized during the search being conducted on totally unrelated
While Mr. Flanagan has a police record from the mid-1980s related to the
unlawful possession of firearms, including automatic weapons, Mrs. Hudson
fears her private documents may have been the real target of the search.
They tore my office apart more than any other room in my house, she said,
adding agents did not take other potentially non-TSA-related documents from
the office.
I had a box full of [Department of Defense] notes, she said. They didnt
touch those.
Some of the files included notes that she had used to expose how the Federal
Air Marshal Service had lied to Congress during the years after the Sept. 11,
2001, terrorist attacks about the number of airline flights that the service
was actually protecting against another terrorist attack.
A story written by Mrs. Hudson for The Times in March 2005, revealed how air
marshals were protecting less than 10 percent of domestic and international
flights during the month of December 2004, and that the number of flights
Homeland Security officials were providing to Congress was higher than the
actual number of marshals it employed.
Mrs. Hudson says that the experience of having a half-dozen armed officers
rifle through my personal belongings for the three-hour search was
But when the files were returned to me and I saw all the notes that had been
in their possession for a month, it was gut-wrenching, she said.
That her private files were seized, says Mrs. Hudson, is particularly
disturbing because of interactions that she and her husband had during the
search of their home, as well as months afterwards, with Coast Guard
investigator Miguel Bosch. According to his profile on the networking site
LinkedIn, Mr. Bosch worked at the Federal Air Marshal Service from April 2001
through November 2007.
It was Mr. Bosch, Mrs. Hudson says, who asked her during the Aug. 6 search if
she was the same Audrey Hudson who had written the air marshal stories. It
was also Mr. Bosch, she says, who phoned Mr. Flanagan a month later to say
that documents taken during the search had been cleared.
During the call, according Mrs. Hudson, Mr. Bosch said the files had been
taken to make sure that they contained only FOIA-able information and that
he had circulated them to the Transportation Security Administration, which
oversees the Federal Air Marshal Service, in order to verify that it was
legitimate for her to possess such information.
Essentially, the files that included the identities of numerous government
whistleblowers were turned over to the same government agency and officials
who they were exposing for wrongdoing, Mrs. Hudson said.
Reached on the telephone by a reporter for The Times, Mr. Bosch refused to
comment on whether or not journalist-related documents were seized during the
search of Mrs. Hudsons home.
I got to get on the phone with Coast Guard legal before I talk with you,
Mr. Bosch said. Its still an open investigation.
Asked specifically whether documents related to Mrs. Hudsons reporting
activities were taken during the search, he responded: There was a lot of
stuff taken.
Legitimate Case?
The U.S. Coast Guard maintains that it has done nothing wrong in the case and
that the investigation into Mrs. Hudsons husband is based on legitimate
suspicion that he was illegally in possession of firearms.
The warrant outlines how Mr. Flanagan was found guilty in 1985  when he was
25  of resisting arrest in Prince Georges County, Maryland.
The charge of carrying a concealed deadly weapon was dropped, but a year
later, the U.S. Marshal Service arrested Mr. Flanagan for possession of a
machine gun. The warrant also indicates that Mr. Flanagan was also arrested
in 1996 by police in Anne Arundel County, Maryland,for possessing a handgun
in his vehicle.
The warrant outlines how sometime this year Mr. Flanagan drew the interest of
the U.S. Bureau of Alcohol, Tobacco, Firearms and Explosives after allegedly
attempting to purchase possible machine gun parts from a Swedish national.
The warrant says the information was handed to the Coast Guards
investigative service  since Mr. Flanagan worked at the agency  which
conducted an interview during which Flanagan was evasive but stated he did
receive a potato gun but it was defective and it was thrown away.
The term potato gun is slang used during the illegal importation of
silencers, according to the warrant.
Mrs. Hudson says the potato gun claim is outrageous.
She says that her husband did in fact purchase a potato launcher from an
online company based in Sweden five years ago as a novelty item, but it was
discarded within as few weeks because it did not work.
She noted that the law enforcement agents who raided her home did not take a
golf ball launcher that also belonged to her husband as a novelty item.
They did, however, confiscate small arms belonging to Mrs. Hudson that she
had legally registered with the Maryland State Police as far back as 2005.
The search warrant allowed for the weapons to be confiscated, and Mrs. Hudson
says the agents told her that because her husband had pled guilty to a
resisting arrest charge nearly 30 years ago, she was not allowed to possess
the guns under state law. The guns she owned were for recreational shooting,
she says, as well as for security concerns resulting from many of her
I swear to God, were not smuggling machine gun parts from Sweden, said
Mrs. Hudson, adding that the potato launcher in question didnt even work.
Mrs. Hudson has been a reporter in Washington, D.C. for nearly 15 years, and
covered Homeland Security for the Times after the Sept. 11, 2001, terrorist
attacks through December 2009.
Her investigations have sparked numerous congressional investigations that
led to laws signed by former Presidents George W. Bush and Bill Clinton. She
has won numerous journalism awards for her investigations, including the
prestigious Sigma Delta Chi bronze medal for public service, the Society of
Professional Journalists Dateline Award in Investigative Reporting, and was
nominated twice by The Times for the Pulitzer Prize.
Protecting confidential sources is a part of my honor and hits me at my
ethical core, said Mrs. Hudson. To have someone steal my source information
and know it could impact peoples careers, is disgusting, a massive
overreach. This kind of conduct is intimidation clearly aimed at silencing a
vigorous press.
Read more:
 Follow us:  on Twitter

@_date: 2013-10-28 17:03:12
@_author: Eugen Leitl 
@_subject: The Battle for Power on the Internet 
The Battle for Power on the Internet
Distributed citizen groups and nimble hackers once had the edge. Now
governments and corporations are catching up. Who will dominate in the
decades ahead?
BRUCE SCHNEIER OCT 24 2013, 7:07 AM ET
Vivek Prakash/Reuters
Were in the middle of an epic battle for power in cyberspace. On one side
are the traditional, organized, institutional powers such as governments and
large multinational corporations. On the other are the distributed and
nimble: grassroots movements, dissident groups, hackers, and criminals.
Initially, the Internet empowered the second side. It gave them a place to
coordinate and communicate efficiently, and made them seem unbeatable. But
now, the more traditional institutional powers are winning, and winning big.
How these two side fare in the long term, and the fate of the rest of us who
dont fall into either group, is an open questionand one vitally important
to the future of the Internet.
In the Internets early days, there was a lot of talk about its natural
lawshow it would upend traditional power blocks, empower the masses, and
spread freedom throughout the world. The international nature of the Internet
bypassed circumvented national laws. Anonymity was easy. Censorship was
impossible. Police were clueless about cybercrime. And bigger changes seemed
inevitable. Digital cash would undermine national sovereignty. Citizen
journalism would topple traditional media, corporate PR, and political
parties. Easy digital copying would destroy the traditional movie and music
industries. Web marketing would allow even the smallest companies to compete
against corporate giants. It really would be a new world order.
This was a utopian vision, but some of it did come to pass. Internet
marketing has transformed commerce. The entertainment industries have been
transformed by things like MySpace and YouTube, and are now more open to
outsiders. Mass media has changed dramatically, and some of the most
influential people in the media have come from the blogging world. There are
new ways to organize politically and run elections. Crowdfunding has made
tens of thousands of projects possible to finance, and crowdsourcing made
more types of projects possible. Facebook and Twitter really did help topple
But that is just one side of the Internets disruptive character. The
Internet has emboldened traditional power as well.
On the corporate side, power is consolidating, a result of two current trends
in computing. First, the rise of cloud computing means that we no longer have
control of our data. Our e-mail, photos, calendars, address books, messages,
and documents are on servers belonging to Google, Apple, Microsoft, Facebook,
and so on. And second, we are increasingly accessing our data using devices
that we have much less control over: iPhones, iPads, Android phones, Kindles,
ChromeBooks, and so on. Unlike traditional operating systems, those devices
are controlled much more tightly by the vendors, who limit what software can
run, what they can do, how theyre updated, and so on. Even Windows 8 and
Apples Mountain Lion operating system are heading in the direction of more
vendor control.
I have previously characterized this model of computing as feudal. Users
pledge their allegiance to more powerful companies who, in turn, promise to
protect them from both sysadmin duties and security threats. Its a metaphor
thats rich in history and in fiction, and a model thats increasingly
permeating computing today.
Medieval feudalism was a hierarchical political system, with obligations in
both directions. Lords offered protection, and vassals offered service. The
lord-peasant relationship was similar, with a much greater power
differential. It was a response to a dangerous world.
Feudal security consolidates power in the hands of the few. Internet
companies, like lords before them, act in their own self-interest. They use
their relationship with us to increase their profits, sometimes at our
expense. They act arbitrarily. They make mistakes. Theyre deliberatelyand
incidentallychanging social norms. Medieval feudalism gave the lords vast
powers over the landless peasants; were seeing the same thing on the
Its not all bad, of course. We, especially those of us who are not
technical, like the convenience, redundancy, portability, automation, and
shareability of vendor-managed devices. We like cloud backup. We like
automatic updates. We like not having to deal with security ourselves. We
like that Facebook just worksfrom any device, anywhere.
Government power is also increasing on the Internet. There is more government
surveillance than ever before. There is more government censorship than ever
before. There is more government propaganda, and an increasing number of
governments are controlling what their users can and cannot do on the
Internet. Totalitarian governments are embracing a growing cyber
sovereignty movement to further consolidate their power. And the cyberwar
arms race is on, pumping an enormous amount of money into cyber-weapons and
consolidated cyber-defenses, further increasing government power.
Technology magnifies power in general, but rates of adoption are different.
In many cases, the interests of corporate and government powers are aligning.
Both corporations and governments benefit from ubiquitous surveillance, and
the NSA is using Google, Facebook, Verizon, and others to get access to data
it couldnt otherwise. The entertainment industry is looking to governments
to enforce its antiquated business models. Commercial security equipment from
companies like BlueCoat and Sophos is being used by oppressive governments to
surveil and censor their citizens. The same facial recognition technology
that Disney uses in its theme parks can also identify protesters in China and
Occupy Wall Street activists in New York. Think of it as a public/private
surveillance partnership.
What happened? How, in those early Internet years, did we get the future so
The truth is that technology magnifies power in general, but rates of
adoption are different. The unorganized, the distributed, the marginal, the
dissidents, the powerless, the criminal: They can make use of new
technologies very quickly. And when those groups discovered the Internet,
suddenly they had power. But later, when the already-powerful big
institutions finally figured out how to harness the Internet, they had more
power to magnify. Thats the difference: The distributed were more nimble and
were faster to make use of their new power, while the institutional were
slower but were able to use their power more effectively.
So while the Syrian dissidents used Facebook to organize, the Syrian
government used Facebook to identify dissidents to arrest.
All isnt lost for distributed power, though. For institutional power, the
Internet is a change in degree, but for distributed power its a qualitative
one. The Internet gives decentralized groupsfor the first timethe ability
to coordinate. This can have incredible ramifications, as we saw in the
SOPA/PIPA debate, Gezi, Brazil, and the rising use of crowdfunding. It can
invert power dynamics, even in the presence of surveillance censorship and
use control. But aside from political coordination, the Internet allows for
social coordination as well to unite, for example, ethnic diasporas, gender
minorities, sufferers of rare diseases, and people with obscure interests.
This isnt static: Technological advances continue to provide advantage to
the nimble. I discussed this trend in my book Liars and Outliers. If you
think of security as an arms race between attackers and defenders, any
technological advance gives one side or the other a temporary advantage. But
most of the time, a new technology benefits the nimble first. They are not
hindered by bureaucracyand sometimes not by laws or ethics either. They can
evolve faster.
We saw it with the Internet. As soon as the Internet started being used for
commerce, a new breed of cybercriminal emerged, immediately able to take
advantage of the new technology. It took police a decade to catch up. And we
saw it on social media, as political dissidents made use of its
organizational powers before totalitarian regimes did.
Which type of power dominates in the coming decades?
Right now, it looks like traditional power.
This delay is what I call a security gap. Its greater when theres more
technology, and in times of rapid technological change. Basically, if there
are more innovations to exploit, there will be more damage resulting from
society's inability to keep up with exploiters of all of them. And since our
world is one in which theres more technology than ever before, and a faster
rate of technological change than ever before, we should expect to see a
greater security gap than ever before. In other words, there will be an
increasing time period during which nimble distributed powers can make use of
new technologies before slow institutional powers can make better use of
those technologies.
This is the battle: quick vs. strong. To return to medieval metaphors, you
can think of a nimble distributed powerwhether marginal, dissident, or
criminalas Robin Hood; and ponderous institutional powersboth government
and corporateas the feudal lords.
So who wins? Which type of power dominates in the coming decades?
Right now, it looks like traditional power. Ubiquitous surveillance means
that its easier for the government to identify dissidents than it is for the
dissidents to remain anonymous. Data monitoring means easier for the Great
Firewall of China to block data than it is for people to circumvent it. The
way we all use the Internet makes it much easier for the NSA to spy on
everyone than it is for anyone to maintain privacy. And even though it is
easy to circumvent digital copy protection, most users still cant do it.
The problem is that leveraging Internet power requires technical expertise.
Those with sufficient ability will be able to stay ahead of institutional
powers. Whether its setting up your own e-mail server, effectively using
encryption and anonymity tools, or breaking copy protection, there will
always be technologies that can evade institutional powers. This is why
cybercrime is still pervasive, even as police savvy increases; why
technically capable whistleblowers can do so much damage; and why
organizations like Anonymous are still a viable social and political force.
Assuming technology continues to advanceand theres no reason to believe it
wontthere will always be a security gap in which technically advanced Robin
Hoods can operate.
Most people, though, are stuck in the middle. These are people who have dont
have the technical ability to evade either the large governments and
corporations, avoid the criminal and hacker groups who prey on us, or join
any resistance or dissident movements. These are the people who accept
default configuration options, arbitrary terms of service, NSA-installed back
doors, and the occasional complete loss of their data. These are the people
who get increasingly isolated as government and corporate power align. In the
feudal world, these are the hapless peasants. And its even worse when the
feudal lordsor any powersfight each other. As anyone watching Game of
Thrones knows, peasants get trampled when powers fight: when Facebook,
Google, Apple, and Amazon fight it out in the market; when the U.S., EU,
China, and Russia fight it out in geopolitics; or when its the U.S. vs. the
terrorists or China vs. its dissidents.
The abuse will only get worse as technology continues to advance. In the
battle between institutional power and distributed power, more technology
means more damage. Weve already seen this: Cybercriminals can rob more
people more quickly than criminals who have to physically visit everyone they
rob. Digital pirates can make more copies of more things much more quickly
than their analog forebears. And well see it in the future: 3D printers mean
that the computer restriction debate will soon involves guns, not movies. Big
data will mean that more companies will be able to identify and track you
more easily. Its the same problem as the weapons of mass destruction fear:
terrorists with nuclear or biological weapons can do a lot more damage than
terrorists with conventional explosives. And by the same token, terrorists
with large-scale cyberweapons can potentially do more damage than terrorists
with those same bombs.
The more destabilizing the technologies, the greater the rhetoric of fear,
and the stronger institutional powers will get.  Its a numbers game. Very
broadly, because of the way humans behave as a species and as a society,
every society is going to have a certain amount of crime. And theres a
particular crime rate society is willing to tolerate. With historically
inefficient criminals, we were willing to live with some percentage of
criminals in our society. As technology makes each individual criminal more
powerful, the percentage we can tolerate decreases. Again, remember the
weapons of mass destruction debate: As the amount of damage each individual
terrorist can do increases, we need to do increasingly more to prevent even a
single terrorist from succeeding.
The more destabilizing the technologies, the greater the rhetoric of fear,
and the stronger institutional powers will get. This means increasingly
repressive security measures, even if the security gap means that such
measures become increasingly ineffective. And it will squeeze the peasants in
the middle even more.
Without the protection of his own feudal lord, the peasant was subject to
abuse both by criminals and other feudal lords. But both corporations and the
governmentand often the two in cahootsare using their power to their own
advantage, trampling on our rights in the process. And without the technical
savvy to become Robin Hoods ourselves, we have no recourse but to submit to
whatever the ruling institutional power wants.
So what happens as technology increases? Is a police state the only effective
way to control distributed power and keep our society safe? Or do the fringe
elements inevitably destroy society as technology increases their power?
Probably neither doomsday scenario will come to pass, but figuring out a
stable middle ground is hard. These questions are complicated, and dependent
on future technological advances that we cannot predict. But they are
primarily political questions, and any solutions will be political.
In the short term, we need more transparency and oversight. The more we know
of what institutional powers are doing, the more we can trust that they are
not abusing their authority. We have long known this to be true in
government, but we have increasingly ignored it in our fear of terrorism and
other modern threats. This is also true for corporate power. Unfortunately,
market dynamics will not necessarily force corporations to be transparent; we
need laws to do that. The same is true for decentralized power; transparency
is how well differentiate political dissidents from criminal organizations.
Oversight is also critically important, and is another long-understood
mechanism for checking power. This can be a combination of things: courts
that act as third-party advocates for the rule of law rather than
rubber-stamp organizations, legislatures that understand the technologies and
how they affect power balances, and vibrant public-sector press and watchdog
groups that analyze and debate the actions of those wielding power.
Transparency and oversight give us the confidence to trust institutional
powers to fight the bad side of distributed power, while still allowing the
good side to flourish. For if were going to entrust our security to
institutional powers, we need to know they will act in our interests and not
abuse that power. Otherwise, democracy fails.
In the longer term, we need to work to reduce power differences. The key to
all of this is access to data. On the Internet, data is power. To the extent
the powerless have access to it, they gain in power. To the extent that the
already powerful have access to it, they further consolidate their power. As
we look to reducing power imbalances, we have to look at data: data privacy
for individuals, mandatory disclosure laws for corporations, and open
government laws.
Medieval feudalism evolved into a more balanced relationship in which lords
had responsibilities as well as rights. Todays Internet feudalism is both
ad-hoc and one-sided. Those in power have a lot of rights, but increasingly
few responsibilities or limits. We need to rebalance this relationship. In
medieval Europe, the rise of the centralized state and the rule of law
provided the stability that feudalism lacked. The Magna Carta first forced
responsibilities on governments and put humans on the long road toward
government by the people and for the people. In addition to re-reigning in
government power, we need similar restrictions on corporate power: a new
Magna Carta focused on the institutions that abuse power in the 21st century.
Todays Internet is a fortuitous accident: a combination of an initial lack
of commercial interests, government benign neglect, military requirements for
survivability and resilience, and computer engineers building open systems
that worked simply and easily. Corporations have turned the Internet into an
enormous revenue generator, and theyre not going to back down easily.
Neither will governments, which have harnessed the Internet for political
Were at the beginning of some critical debates about the future of the
Internet: the proper role of law enforcement, the character of ubiquitous
surveillance, the collection and retention of our entire lifes history, how
automatic algorithms should judge us, government control over the Internet,
cyberwar rules of engagement, national sovereignty on the Internet,
limitations on the power of corporations over our data, the ramifications of
information consumerism, and so on.
Data is the pollution problem of the information age. All computer processes
produce it. It stays around. How we deal with ithow we reuse and recycle it,
who has access to it, how we dispose of it, and what laws regulate itis
central to how the information age functions. And I believe that just as we
look back at the early decades of the industrial age and wonder how society
could ignore pollution in their rush to build an industrial world, our
grandchildren will look back at us during these early decades of the
information age and judge us on how we dealt with the rebalancing of power
resulting from all this new data.
This wont be an easy period for us as we try to work these issues out.
Historically, no shift in power has ever been easy. Corporations have turned
our personal data into an enormous revenue generator, and theyre not going
to back down. Neither will governments, who have harnessed that same data for
their own purposes. But we have a duty to tackle this problem.
I cant tell you what the result will be. These are all complicated issues,
and require meaningful debate, international cooperation, and innovative
solutions. We need to decide on the proper balance between institutional and
decentralized power, and how to build tools that amplify what is good in each
while suppressing the bad.

@_date: 2013-10-29 11:32:44
@_author: Eugen Leitl 
@_subject: Cameron doesn't understand everybody's been playing nice so far 
David Cameron makes veiled threat to media over NSA and GCHQ leaks
Prime minister alludes to courts and D notices and singles out the Guardian
over coverage of Edward Snowden saga
Nicholas Watt, chief political correspondent The Guardian, Monday 28 October
2013 18.10 GMT
Cameron tours the Mini car plant in Oxford. The prime minister claims he
doesn't want to have to take legal action against the Guardian and other
newspapers over intelligence leaks but would rather talk to them. Photograph:
Ben Birchall/PA
David Cameron has called on the Guardian and other newspapers to show "social
responsibility" in the reporting of the leaked NSA files to avoid high court
injunctions or the use of D notices to prevent the publication of information
that could damage national security.
In a statement to MPs on Monday about last week's European summit in
Brussels, where he warned of the dangers of a "lah-di-dah, airy-fairy view"
about the dangers of leaks, the prime minister said his preference was to
talk to newspapers rather than resort to the courts. But he said it would be
difficult to avoid acting if newspapers declined to heed government advice.
The prime minister issued the warning after the Tory MP Julian Smith quoted a
report in Monday's edition of the Sun that said Britain's intelligence
agencies believed details from the NSA files leaked by the US whistleblower
Edward Snowden had hampered their work.
The Sun quoted a "top surveillance source" as saying that terrorists had
"gone quiet" after the publication of details about NSA and GCHQ operations.
Cameron told MPs: "We have a free press, it's very important the press feels
it is not pre-censored from what it writes and all the rest of it.
"The approach we have taken is to try to talk to the press and explain how
damaging some of these things can be and that is why the Guardian did
actually destroy some of the information and disks that they have. But
they've now gone on and printed further material which is damaging.
"I don't want to have to use injunctions or D notices or the other tougher
measures. I think it's much better to appeal to newspapers' sense of social
responsibility. But if they don't demonstrate some social responsibility it
would be very difficult for government to stand back and not to act."
The Guardian agreed to allow officials from GCHQ to oversee the destruction
of hard drives in July, after the government threatened to use an injunction
to block publication of information from the NSA files.
Alan Rusbridger, the editor-in-chief of the Guardian, said the destruction of
the hard drives allowed the Guardian to continue reporting on the NSA files
from its New York office.
The D-notice system is a voluntary code between government departments with
responsibility for national security and the media. A notice can be issued to
the media to prevent "inadvertent public disclosure of information that would
compromise UK military and intelligence operations and methods".
Cameron had earlier indicated that the oversight of Britain's intelligence
agencies may have to evolve in light of the revelations about the reach of
new technology. He told MPs: "We have parliamentary scrutiny of our
intelligence agencies through the intelligence and security committee and we
have strengthened that oversight.
"Our agencies operate under the law and their work is overseen by
intelligence commissioners. Of course as technology develops and as the
threats we face evolve so we need to make sure that the scrutiny and the
frameworks in place remain strong and effective."
Parliament's intelligence and security committee announced earlier this month
that it is to scutinise the extent of mass surveillance in response to the
concerns raised by the Snowden leaks.
The prime minister issued his warning to newspapers after Ed Miliband raised
concerns about the reports last week that the US has monitored the mobile
phone of the German chancellor Angela Merkel.
Miliband said: "I join the prime minister in his support for the work of our
intelligence services. It is vital, it keeps us safe and, by its very nature,
it goes unrecognised. I join the prime minister in applauding the men and
women who work for our intelligence agencies.
"We can all understand the deep concerns that recent reports have caused in
some European countries, especially Germany. As well as providing that
support for intelligence services it is right that every country ensures
proper oversight of those activities."
Julian Smith, who recently wrote to the Metropolitan police to assess whether
the Guardian has broken the law in publishing details from the NSA files,
asked the PM in the Commons: "Following the Sun's revelations this morning
about the impact of the Snowden leaks, is it not time that any newspaper that
may have crossed the line on national security comes forward and voluntarily
works with the government to mitigate further risks to our citizens?"

@_date: 2013-10-31 21:23:52
@_author: Eugen Leitl 
@_subject: Meet =?utf-8?B?4oCcYmFkQklPUyw=?= =?utf-8?B?4oCd?= the mysterious 
Meet badBIOS, the mysterious Mac and PC malware that jumps airgaps
Like a super strain of bacteria, the rootkit plaguing Dragos Ruiu is
by Dan Goodin - Oct 31 2013, 3:07pm CET
BLACK HAT HACKING
Aurich Lawson / Thinkstock
Three years ago, security consultant Dragos Ruiu was in his lab when he
noticed something highly unusual: his MacBook Air, on which he had just
installed a fresh copy of OS X, spontaneously updated the firmware that helps
it boot. Stranger still, when Ruiu then tried to boot the machine off a CD
ROM, it refused. He also found that the machine could delete data and undo
configuration changes with no prompting. He didn't know it then, but that odd
firmware update would become a high-stakes malware mystery that would consume
most of his waking hours.
In the following months, Ruiu observed more odd phenomena that seemed
straight out of a science-fiction thriller. A computer running the Open BSD
operating system also began to modify its settings and delete its data
without explanation or prompting. His network transmitted data specific to
the Internet's next-generation IPv6 networking protocol, even from computers
that were supposed to have IPv6 completely disabled. Strangest of all was the
ability of infected machines to transmit small amounts of network data with
other infected machines even when their power cords and Ethernet cables were
unplugged and their Wi-Fi and Bluetooth cards were removed. Further
investigation soon showed that the list of affected operating systems also
included multiple variants of Windows and Linux.
"We were like, 'Okay, we're totally owned,'" Ruiu told Ars. "'We have to
erase all our systems and start from scratch,' which we did. It was a very
painful exercise. I've been suspicious of stuff around here ever since."
In the intervening three years, Ruiu said, the infections have persisted,
almost like a strain of bacteria that's able to survive extreme antibiotic
therapies. Within hours or weeks of wiping an infected computer clean, the
odd behavior would return. The most visible sign of contamination is a
machine's inability to boot off a CD, but other, more subtle behaviors can be
observed when using tools such as Process Monitor, which is designed for
troubleshooting and forensic investigations.
Another intriguing characteristic: in addition to jumping "airgaps" designed
to isolate infected or sensitive machines from all other networked computers,
the malware seems to have self-healing capabilities.
"We had an air-gapped computer that just had its [firmware] BIOS reflashed, a
fresh disk drive installed, and zero data on it, installed from a Windows
system CD," Ruiu said. "At one point, we were editing some of the components
and our registry editor got disabled. It was like: wait a minute, how can
that happen? How can the machine react and attack the software that we're
using to attack it? This is an air-gapped machine and all of the sudden the
search function in the registry editor stopped working when we were using it
to search for their keys."
Over the past two weeks, Ruiu has taken to Twitter, Facebook, and Google Plus
to document his investigative odyssey and share a theory that has captured
the attention of some of the world's foremost security experts. The malware,
Ruiu believes, is transmitted though USB drives to infect the lowest levels
of computer hardware. With the ability to target a computer's Basic
Input/Output System (BIOS), Unified Extensible Firmware Interface (UEFI), and
possibly other firmware standards, the malware can attack a wide variety of
platforms, escape common forms of detection, and survive most attempts to
eradicate it.
But the story gets stranger still. In posts here, here, and here, Ruiu
posited another theory that sounds like something from the screenplay of a
post-apocalyptic movie: "badBIOS," as Ruiu dubbed the malware, has the
ability to use high-frequency transmissions passed between computer speakers
and microphones to bridge airgaps.
Bigfoot in the age of the advanced persistent threat
At times as I've reported this story, its outline has struck me as the stuff
of urban legend, the advanced persistent threat equivalent of a Bigfoot
sighting. Indeed, Ruiu has conceded that while several fellow security
experts have assisted his investigation, none has peer reviewed his process
or the tentative findings that he's beginning to draw. (A compilation of
Ruiu's observations is here.)
Also unexplained is why Ruiu would be on the receiving end of such an
advanced and exotic attack. As a security professional, the organizer of the
internationally renowned CanSecWest and PacSec conferences, and the founder
of the Pwn2Own hacking competition, he is no doubt an attractive target to
state-sponsored spies and financially motivated hackers. But he's no more
attractive a target than hundreds or thousands of his peers, who have so far
not reported the kind of odd phenomena that has afflicted Ruiu's computers
and networks.
In contrast to the skepticism that's common in the security and hacking
cultures, Ruiu's peers have mostly responded with deep-seated concern and
even fascination to his dispatches about badBIOS.
"Everybody in security needs to follow  and watch his analysis of
 Alex Stamos, one of the more trusted and sober security
researchers, wrote in a tweet last week. Jeff Mossthe founder of the Defcon
and Blackhat security conferences who in 2009 began advising Department of
Homeland Security Secretary Janet Napolitano on matters of computer
securityretweeted the statement and added: "No joke it's really serious."
Plenty of others agree.
"Dragos is definitely one of the good reliable guys, and I have never ever
even remotely thought him dishonest," security researcher Arrigo Triulzi told
Ars. "Nothing of what he describes is science fiction taken individually, but
we have not seen it in the wild ever."
Been there, done that
Triulzi said he's seen plenty of firmware-targeting malware in the
laboratory. A client of his once infected the UEFI-based BIOS of his Mac
laptop as part of an experiment. Five years ago, Triulzi himself developed
proof-of-concept malware that stealthily infected the network interface
controllers that sit on a computer motherboard and provide the Ethernet jack
that connects the machine to a network. His research built off of work by
John Heasman that demonstrated how to plant hard-to-detect malware known as a
rootkit in a computer's peripheral component interconnect, the
Intel-developed connection that attaches hardware devices to a CPU.
It's also possible to use high-frequency sounds broadcast over speakers to
send network packets. Early networking standards used the technique, said
security expert Rob Graham. Ultrasonic-based networking is also the subject
of a great deal of research, including this project by scientists at MIT.
Of course, it's one thing for researchers in the lab to demonstrate viable
firmware-infecting rootkits and ultra high-frequency networking techniques.
But as Triulzi suggested, it's another thing entirely to seamlessly fuse the
two together and use the weapon in the real world against a seasoned security
consultant. What's more, use of a USB stick to infect an array of computer
platforms at the BIOS level rivals the payload delivery system found in the
state-sponsored Stuxnet worm unleashed to disrupt Iran's nuclear program. And
the reported ability of badBIOS to bridge airgaps also has parallels to
Flame, another state-sponsored piece of malware that used Bluetooth radio
signals to communicate with devices not connected to the Internet.
"Really, everything Dragos reports is something that's easily within the
capabilities of a lot of people," said Graham, who is CEO of penetration
testing firm Errata Security. "I could, if I spent a year, write a BIOS that
does everything Dragos said badBIOS is doing. To communicate over ultrahigh
frequency sound waves between computers is really, really easy."
Coincidentally, Italian newspapers this week reported that Russian spies
attempted to monitor attendees of last month's G20 economic summit by giving
them memory sticks and recharging cables programmed to intercept their
For most of the three years that Ruiu has been wrestling with badBIOS, its
infection mechanism remained a mystery. A month or two ago, after buying a
new computer, he noticed that it was almost immediately infected as soon as
he plugged one of his USB drives into it. He soon theorized that infected
computers have the ability to contaminate USB devices and vice versa.
"The suspicion right now is there's some kind of buffer overflow in the way
the BIOS is reading the drive itself, and they're reprogramming the flash
controller to overflow the BIOS and then adding a section to the BIOS table,"
he explained.
He still doesn't know if a USB stick was the initial infection trigger for
his MacBook Air three years ago, or if the USB devices were infected only
after they came into contact with his compromised machines, which he said now
number between one and two dozen. He said he has been able to identify a
variety of USB sticks that infect any computer they are plugged into. At next
month's PacSec conference, Ruiu said he plans to get access to expensive USB
analysis hardware that he hopes will provide new clues behind the infection
He said he suspects badBIOS is only the initial module of a multi-staged
payload that has the ability to infect the Windows, Mac OS X, BSD, and Linux
operating systems.
Dragos Ruiu
Julia Wolf
"It's going out over the network to get something or it's going out to the
USB key that it was infected from," he theorized. "That's also the conjecture
of why it's not booting CDs. It's trying to keep its claws, as it were, on
the machine. It doesn't want you to boot another OS it might not have code
for." To put it another way, he said, badBIOS "is the tip of the warhead, as
it were."
Things kept getting fixed
Ruiu said he arrived at the theory about badBIOS's high-frequency networking
capability after observing encrypted data packets being sent to and from an
infected laptop that had no obvious network connection withbut was in close
proximity toanother badBIOS-infected computer. The packets were transmitted
even when the laptop had its Wi-Fi and Bluetooth cards removed. Ruiu also
disconnected the machine's power cord so it ran only on battery to rule out
the possibility it was receiving signals over the electrical connection. Even
then, forensic tools showed the packets continued to flow over the airgapped
machine. Then, when Ruiu removed the internal speaker and microphone
connected to the airgapped machine, the packets suddenly stopped.
With the speakers and mic intact, Ruiu said, the isolated computer seemed to
be using the high-frequency connection to maintain the integrity of the
badBIOS infection as he worked to dismantle software components the malware
relied on.
"The airgapped machine is acting like it's connected to the Internet," he
said. "Most of the problems we were having is we were slightly disabling bits
of the components of the system. It would not let us disable some things.
Things kept getting fixed automatically as soon as we tried to break them. It
was weird."
It's too early to say with confidence that what Ruiu has been observing is a
USB-transmitted rootkit that can burrow into a computer's lowest levels and
use it as a jumping off point to infect a variety of operating systems with
malware that can't be detected. It's even harder to know for sure that
infected systems are using high-frequency sounds to communicate with isolated
machines. But after almost two weeks of online discussion, no one has been
able to rule out these troubling scenarios, either.
"It looks like the state of the art in intrusion stuff is a lot more advanced
than we assumed it was," Ruiu concluded in an interview. "The take-away from
this is a lot of our forensic procedures are weak when faced with challenges
like this. A lot of companies have to take a lot more care when they use
forensic data if they're faced with sophisticated attackers."

@_date: 2013-09-02 09:49:03
@_author: Eugen Leitl 
@_subject: [tor-talk] New paper : Users Get Routed: Traffic Correlation on Tor 
X-Mailer: Sylpheed 3.4.0beta4 (GTK+ 2.24.10; x86_64-pc-linux-gnu)
Reply-To: tor-talk
Hi all,
Heads up on a new paper suggesting that its possible to unmask
Tor users using traffic correlation:
    Code here:
    Would be interested in hearing the opinions of the core Tor
develpoment team on this stuff.

@_date: 2013-09-03 13:16:43
@_author: Eugen Leitl 
@_subject: building a community on RetroShare 
One of my RS identities is
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: OpenPGP:SDK v0.9
-----END PGP PUBLIC KEY BLOCK-----
see you there.

@_date: 2013-09-04 15:22:03
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] 0.8.4 released, fixes critical 
Bitcoin-Qt version 0.8.4 is now available from:
  This is a maintenance release to fix a critical bug and three
security issues; we urge all users to upgrade.
There were no changes from 0.8.4 release candidate 2, so if you are running
0.8.4rc2 you do not need to upgrade.
Please report bugs using the issue tracker at github:
  How to Upgrade
An attacker could send a series of messages that resulted in
an integer division-by-zero error in the Bloom Filter handling
code, causing the Bitcoin-Qt or bitcoind process to crash.
Bloom filters were introduced with version 0.8, so versions 0.8.0
through 0.8.3 are vulnerable to this critical denial-of-service attack.
A constant-time algorithm is now used to check RPC password
guess attempts; fixes Implement a better fix for the fill-memory-with-orphan-transactions
attack that was fixed in 0.8.3. See
for a description of the weaknesses of the previous fix.
Bugs fixed
Fix multi-block reorg transaction resurrection.
Fix non-standard disconnected transactions causing mempool orphans.
This bug could cause nodes running with the -debug flag to crash.
OSX: use 'FD_FULLSYNC' with LevelDB, which will (hopefully!)
prevent the database corruption issues many people have
experienced on OSX.
Linux: clicking on bitcoin: links was broken if you were using
a Gnome-based desktop.
Fix a hang-at-shutdown bug that only affects users that compile
their own version of Bitcoin against Boost versions 1.50-1.52.
Other changes
Checkpoint at block 250,000 to speed up initial block downloads
and make the progress indicator when downloading more accurate.
Thanks to everybody who contributed to the 0.8.4 releases!
Pieter Wuille
Warren Togami
Patrick Strateman
Gregory Maxwell
Sergio Demian Lerner
Cory Fields
Matt Corallo
Gavin Andresen

@_date: 2013-09-04 22:12:40
@_author: Eugen Leitl 
@_subject: NSA Laughs at PCs, Prefers Hacking Routers and Switches 
NANOG list NSA Laughs at PCs, Prefers Hacking Routers and Switches
BY KIM ZETTER09.04.136:30 AM
Photo: Santiago Cabezas/Flickr
The NSA runs a massive, full-time hacking operation targeting foreign
systems, the latest leaks from Edward Snowden show. But unlike conventional
cybercriminals, the agency is less interested in hacking PCs and Macs.
Instead, Americas spooks have their eyes on the internet routers and
switches that form the basic infrastructure of the net, and are largely
overlooked as security vulnerabilities.
Under a $652-million program codenamed Genie, U.S. intel agencies have
hacked into foreign computers and networks to monitor communications crossing
them and to establish control over them, according to a secret black budget
document leaked to the Washington Post. U.S. intelligence agencies conducted
231 offensive cyber operations in 2011 to penetrate the computer networks of
targets abroad.
This included not only installing covert implants in foreign desktop
computers but also on routers and firewalls  tens of thousands of machines
every year in all. According to the Post, the government planned to expand
the program to cover millions of additional foreign machines in the future
and preferred hacking routers to individual PCs because it gave agencies
access to data from entire networks of computers instead of just individual
Most of the hacks targeted the systems and communications of top adversaries
like China, Russia, Iran and North Korea and included activities around
nuclear proliferation.
The NSAs focus on routers highlights an often-overlooked attack vector with
huge advantages for the intruder, says Marc Maiffret, chief technology
officer at security firm Beyond Trust. Hacking routers is an ideal way for an
intelligence or military agency to maintain a persistent hold on network
traffic because the systems arent updated with new software very often or
patched in the way that Windows and Linux systems are.
No one updates their routers, he says. If you think people are bad about
patching Windows and Linux (which they are) then they are  horrible about
updating their networking gear because it is too critical, and usually they
dont have redundancy to be able to do it properly.
He also notes that routers dont have security software that can help detect
a breach.
The challenge [with desktop systems] is that while antivirus dont work well
on your desktop, they at least do something [to detect attacks], he says.
But you dont even have an integrity check for the most part on routers and
other such devices like IP cameras.
Hijacking routers and switches could allow the NSA to do more than just
eavesdrop on all the communications crossing that equipment. It would also
let them bring down networks or prevent certain communication, such as
military orders, from getting through, though the Post story doesnt report
any such activities. With control of routers, the NSA could re-route traffic
to a different location, or intelligence agencies could alter it for
disinformation campaigns, such as planting information that would have a
detrimental political effect or altering orders to re-route troops or
supplies in a military operation.
According to the budget document, the CIAs Tailored Access Programs and
NSAs software engineers possess templates for breaking into common brands
and models of routers, switches and firewalls.
The article doesnt say it, but this would likely involve pre-written scripts
or backdoor tools and root kits for attacking known but unpatched
vulnerabilities in these systems, as well as for attacking zero-day
vulnerabilities that are yet unknown to the vendor and customers.
[Router software is] just an operating system and can be hacked just as
Windows or Linux would be hacked, Maiffret says. Theyve tried to harden
them a little bit more [than these other systems], but for folks at a place
like the NSA or any other major government intelligence agency, its pretty
standard fare of having a ready-to-go backdoor for your [off-the-shelf] Cisco
or Juniper models.
Not all of the activity mentioned in the budget document involved remote
hacking. In some cases, according to the document, the operations involved
clandestine activity by the CIA or military intelligence units to physically
place hardware implants or software modifications to aid the spying.
Much more often, an implant is coded entirely in software by an NSA group
called Tailored Access Operations (TAO), the Post writes in its story about
the document. As its name suggests, TAO builds attack tools that are
custom-fitted to their targets.
A handful of security researchers have uncovered vulnerabilities in routers
in recent years that could be used to do the kind of hacking described in the
budget document.
In 2005, security researcher Mike Lynn found a serious vulnerability in Cisco
IOS, the operating system running on millions of Cisco routers around the
Lynn discovered the vulnerability after his employer, Internet Security
Systems, asked him to reverse-engineer the Cisco operating system to see if
he could find security problems with it. Cisco makes the majority of the
routers that operate the backbone of the internet as well as many company
networks and critical infrastructure systems. The Cisco IOS is as ubiquitous
in the backbone as the Windows operating system is on desktops.
The vulnerability Lynn found, in a new version of the operation system that
Cisco planned to release at the time, would have allowed someone to create a
router worm that would shut down every Cisco router through which it passed,
bringing down a nations critical infrastructure. It also would have allowed
an attacker to gain complete control of the router to sniff all traffic
passing through a network in order to read, record or alter it, or simply
prevent traffic from reaching its recipient.
Once Lynn found the vulnerability, it took him six months to develop a
working exploit to attack it.
Lynn had planned to discuss the vulnerability at the Black Hat security
conference in Las Vegas, until Cisco intervened and forced him to pull the
talk under threat of a lawsuit.
But if Lynn knew about the vulnerability, there were likely others who did as
well  including intelligence agencies and criminal hackers.
Source code for Ciscos IOS has been stolen at least twice, either by
entities who were interested in studying the software to gain a competitive
advantage or to uncover vulnerabilities that would allow someone to hack or
control them.
Other researchers have uncovered different vulnerabilities in other Cisco
routers that are commonly used in small businesses and home offices.
Every year at computer security conferences  including the Black Hat
conference where NSA Director Keith Alexander presented a keynote this year 
U.S. intelligence agencies and contractors from around the world attend to
discover information about new vulnerabilities that might be exploited and to
hire talented researchers and hackers capable of finding more vulnerabilities
in systems.
In 2008, a researcher at Core Security Technologies developed a root kit for
the Cisco IOS that was designed to give an attacker a persistent foothold on
a Cisco router while remaining undetected.
According to the Post story, the NSA designs most of the offensive tools it
uses in its Genie operation, but it spent $25.1 million in one year for
additional covert purchases of software vulnerabilities from private
malware vendors who operate on the grey market  closed markets that peddle
vulnerabilities and exploits to law enforcement and intelligence agencies, as
opposed to the black market that sells them to cyber criminals.
The price of vulnerabilities and exploits varies, depending on a number of
factors. Vulnerabilities and exploits can sell for anywhere from $50,000 to
more than a million, depending on the exclusivity of the purchase  some
vulnerabilities are sold to multiple parties with the understanding that
others are using it as well  and their ubiquity. A vulnerability that exists
in multiple versions of an operating system is more valuable than a
vulnerability that exists in just one version. A class of vulnerability that
crosses multiple browser brands is also more valuable than a single
vulnerability that just affects the Safari browser or Chrome.
The Stuxnet cyber weapon that was reportedly created by the U.S. and Israel
to sabotage centrifuges used in Irans uranium enrichment program, used five
zero-day exploits to spread itself among systems in Iran, including a rare
exploit that attacked the .LNK function in multiple versions of the Windows
operating system in order to spread the worm silently via infected USB
Ubiquitous router vulnerabilities are difficult to find since there are so
many different configurations for routers, and an attack that works against
one router configuration might not work for another. But a vulnerability that
affects the core operating system is much more valuable since it is less
likely to be dependent on the configuration. Maiffret says there hasnt been
a lot of public research on router vulnerabilities, but whenever someone has
taken a look at them, they have found security holes in them.
Theyre always successful in finding something, he says.
Once a vulnerability becomes known to the software maker and is patched, it
loses a lot of its value. But because many users and administrators do not
patch their systems, some vulnerabilities can be used effectively for years,
even after a patch is available. The Conficker worm, for example, continued
to infect millions of computers long after Microsoft released a patch that
should have stopped the worm from spreading.
Routers in particular often remain unpatched because system administrators
dont think they will be targeted and because administrators are concerned
about network outages that could occur while the patch is applied or if the
patch is faulty.
Kim Zetter is a senior reporter at Wired covering cybercrime, privacy,
security and civil liberties.
Read more by Kim Zetter
Follow  and  on Twitter.

@_date: 2013-09-04 22:16:12
@_author: Eugen Leitl 
@_subject: [tor-talk] Exit node stats collection? 
Hash: SHA1
I do not know if this link has been posted yet, but this jumped out at
me this morning - it's a technique for correlating publically known
Tor nodes against hidden services:
Thoughts from the community?

@_date: 2013-09-05 12:05:49
@_author: Eugen Leitl 
@_subject: Content and popularity analysis of Tor hidden services 
Content and popularity analysis of Tor hidden services
July 29, 2013
Alex Biryukov
University of Luxembourg alex.biryukov
Ivan Pustogarov University of Luxembourg ivan.pustogarov
Ralf-Philipp Weinmann University of Luxembourg ralf-philipp.weinmann
Tor hidden services allow running Internet services while protecting the
location of the servers. Their main purpose is to enable freedom of speech
even in situations in which powerful adversaries try to suppress it. However,
providing location privacy and client anonymity also makes Tor hidden
services an attractive platform for every kind of imaginable shady service.
The ease with which Tor hidden services can be set up has spurred a huge
growth of anonymously provided Internet services of both types. In this paper
we analyse the landscape of Tor hidden services. We have studied Tor hidden
services after collecting 39824 hidden service descriptors on 4th of Feb 2013
by exploiting protocol and implementation aws in Tor: we scanned them for
open ports; in the case of HTTP services, we analysed and classified their
content. We also estimated the popularity of hidden services by looking at
the request rate for hidden service descriptors by clients. We found that
while the content of Tor hidden services is rather varied, the most popular
hidden services are related to botnets.
Tor, hidden services, port scanning, classification

@_date: 2013-09-05 13:19:33
@_author: Eugen Leitl 
@_subject: PayPal freezes MailPile's account 
Why, why did they keep 45 kUSD worth of funds in an
account run by known jerks? Friends don't let friends
use PayPal.

@_date: 2013-09-05 15:13:32
@_author: Eugen Leitl 
@_subject: US stops jailed activist Barrett Brown from discussing leaks 
cypherpunks
US stops jailed activist Barrett Brown from discussing leaks prosecution
Federal court order prohibits Brown from talking to the media in what critics
say is latest in crackdown on investigative journalism
Ed Pilkington in New York
theguardian.com, Wednesday 4 September 2013 22.50 BST
Barrett Brown, Anonymous spokesman
Brown's lawyer says the gagging order is a breach of Brown's first amendment
rights. Photograph: Nikki Loehr
A federal court in Dallas, Texas has imposed a gag order on the jailed
activist-journalist Barrett Brown and his legal team that prevents them from
talking to the media about his prosecution in which he faces up to 100 years
in prison for alleged offences relating to his work exposing online
The court order, imposed by the district court for the northern district of
Texas at the request of the US government, prohibits the defendant and his
defence team, as well as prosecutors, from making "any statement to members
of any television, radio, newspaper, magazine, internet (including, but not
limited to, bloggers), or other media organization about this case, other
than matters of public interest."
It goes on to warn Brown and his lawyers that "no person covered by this
order shall circumvent its effect by actions that indirectly, but
deliberately, bring about a violation of this order".
According to Dell Cameron of Vice magazine, who attended the hearing, the
government argued that the gag order was needed in order to protect Brown
from prejudicing his right to a fair trial by making comments to reporters.
But media observers seen the hearing in the opposite light: as the latest in
a succession of prosecutorial moves under the Obama administration to
crack-down on investigative journalism, official leaking, hacking and online
Brown's lead defence attorney, Ahmed Ghappour, has countered in court
filings, the most recent of which was lodged with the court Wednesday, that
the government's request for a gag order is unfounded as it is based on false
accusations and misrepresentations.
The lawyer says the gagging order is a breach of Brown's first amendment
rights as an author who continues to write from his prison cell on issues
unconnected to his own case for the Guardian and other media outlets.
In his memo to the court for today's hearing, Ghappour writes that Brown's
July article for the Guardian "contains no statements whatsoever about this
trial, the charges underlying the indictment, the alleged acts underlying the
three indictments against Mr Brown, or even facts arguably related to this
The gag order does give Brown some room to carry on his journalistic work
from prison. It says that he will be allowed to continue publishing articles
on topics "not related to the counts on which he stands indicted".
Following the imposition of the order, Ghappour told the Guardian: "The
defense's overriding concern is that Mr Brown continue to be able to exercise
his first amendment right as a journalist. The order preserves that ability."
The lawyer adds that since the current defence team took over in May, Brown
has made only three statements to the media, two of which where articles that
did not concern his trial while the third ran no risk of tainting the jury
pool. "Defendant believes that a gag order is unwarranted because there is no
substantial, or even reasonable, likelihood of prejudice to a fair trial
based on statements made by defendant or his counsel since May 1, 2013."
Brown, 32, was arrested in Dallas on 12 September last year and has been in
prison ever since, charged with 17 counts that include threatening a federal
agent, concealing evidence and disseminating stolen information. He faces a
possible maximum sentence of 100 years in custody.
Before his arrest, Brown became known as a specialist writer on the US
government's use of private military contractors and cybersecurity firms to
conduct online snooping on the public. He was regularly quoted by the media
as an expert on Anonymous, the loose affiliation of hackers that caused
headaches for the US government and several corporate giants, and was
frequently referred to as the group's spokesperson, though he says the
connection was overblown.
In 2011, through the research site he set up called Project PM, he
investigated thousands of emails that had been hacked by Anonymous from the
computer system of a private security firm, HB Gary Federal. His work helped
to reveal that the firm had proposed a dark arts effort to besmirch the
reputations of WikiLeaks supporters and prominent liberal journalists and
activists including the Guardian's Glenn Greenwald.
In 2012, Brown similarly pored over millions of emails hacked by Anonymous
from the private intelligence company Stratfor. It was during his work on the
Stratfor hack that Brown committed his most serious offence, according to US
prosecutors  he posted a link in a chat room that connected users to
Stratfor documents that had been released online.
The released documents included a list of email addresses and credit card
numbers belonging to Stratfor subscribers. For posting that link, Brown is
accused of disseminating stolen information  a charge with media
commentators have warned criminalises the very act of linking.
As Geoffrey King, Internet Advocacy Coordinator for the Committee to Protect
Journalists, has put it, the Barrett Brown case "could criminalize the
routine journalistic practice of linking to documents publicly available on
the internet, which would seem to be protected by the first amendment to the
US constitution under current doctrine".
In its motion to the Dallas district court, US prosecutors accuse Brown and
his associates of having "solicited the services of the media or media-types
to discuss his case" and of continuing to "manipulate the public through
press and social media comments".
It further accuses Ghappour of "co-ordinating" and "approving" the use of the
media, and alleges that between them they have spread "gross fabrications and
substantially false recitations of facts and law which may harm both the
government and the defence during jury selection".
But Ghappour in his legal response has pointed out that several of the
specific accusations raised by the government are inaccurate. Prosecutors
refer to an article in the Guardian by Greenwald published on 21 March 2013
based partly on an interview between the journalist and Brown, yet as
Ghappour points out that piece was posted on the Guardian website before the
accused's current legal team had been appointed.
Under his legal advice, Ghappour writes, Brown has maintained "radio silence"
over his case and has given no further interviews, thus negating the
government's case for a gagging order.

@_date: 2013-09-05 15:16:35
@_author: Eugen Leitl 
@_subject: Spy Files: New WikiLeaks docs expose secretive, unruly surveillance 
cypherpunks info zs-p2p
 doctrinezero ExI chat list Spy Files: New WikiLeaks docs expose secretive, unruly surveillance industry
Published time: September 04, 2013 16:06 Edited time: September 05, 2013 10:00 Get short URL
Screenshot from a leaked documentScreenshot from a leaked document
Central Asia, Information Technology, Intelligence, Internet, Middle East,
The growing surveillance industry complex is providing governments with
increasingly sophisticated spying software to track and control their
citizens, the latest documents obtained by the pro-transparency group,
WikiLeaks reveal.
A trove of documents, outlining the activities of dozens of companies
operating in the ever-expanding electronic snooping industry, were made
available by the pro-transparency group on Wednesday.
Lawful interception, mass monitoring, network recording, signals and
communication intelligence, and tactical interception devices were among the
services and products provided by a litany of Western based firms, as
outlined in hundreds of pages of documents covering trade brochures, internal
memos, and invoices. "WikiLeaks' Spy Files  is part of our ongoing commitment to shining a light
on the secretive mass surveillance industry. This publication doubles the
WikiLeaks Spy Files database, the accompanying press release cites Julian
Assange. The WikiLeaks Spy Files form a valuable resource for journalists
and citizens alike, detailing and explaining how secretive state intelligence
agencies are merging with the corporate world in their bid to harvest all
human electronic communication." One 2011 document showed how companies such as UK-based Gamma Group,
German-based Desoma and Swiss-based Dreamlab are working in concert to
create Telecommunications Intelligence Systems for different
telecommunications networks to fulfill the customers needs regarding
massive data interception and retention.
In March, Gamma International, which is a subsidiary of Gamma group, made
Reporters Without Borders 'Corporate Enemies of the Internet' list for 2013,
which singled out five digital mercenaries who sell their surveillance
technology to authoritarian regimes.
The firms FinFisher Suite (which includes Trojans to infect PCs, mobile
phones, other consumer electronics and servers, as well as technical
consulting), is considered to be one of the most sophisticated in the world.
During the search of an Egyptian intelligence agency office in 2011, human
rights activists found a contract proposal from Gamma International to sell
FinFisher to Egypt.
Bill Marczak, a computer science doctoral candidate at the University of
California, helped investigate the use of FinFisher spyware against activists
and journalists in Bahrain in 2012, as well as in other states.
We dont have any sort of contracts, so that we could see financial dealings
between companies and these governments. The only indications that we have as
to where the spyware has been used are based on the research. In cases that
weve seen the spyware has been targeted against activists and journalists in
a particular country. Weve been scanning the internet looking for this
technology. So we found, as I said, spywares in Bahrain. We saw it being
targeted against Bahraini journalists and activists last year. Weve also
found servers for the spyware in a number of other countries, such as
Turkmenistan, Qatar, Ethiopia, Marczak told RT.
RT was the only Russian broadcaster that collaborated with WikiLeaks in this
investigation, which also brought into the spotlight other companies
including Cobham, Amees, Digital Barriers, ETL group, UTIMACO, Telesoft
Technologies and Trovicor.
Trovicor, incidentally, also features among Reporters Without Borders
digital mercenaries. The firm, whose monitoring centers are capable of
intercepting phone calls, text messages, voice over IP calls (like Skype) and
Internet traffic, has also been accused by of helping Bahrain imprison and
torture activists and journalists.   Screenshot from a leaked documentScreenshot from a leaked document
While a smoking gun in the form of government contracts or invoices was not
forthcoming, internal documents discovered by WikiLeaks do confirm that the
firms dealings with autocratic states.
In a December 2010 correspondence between Nicolas Mayencourt, the CEO of
Dreamlab Technologies AG, and Thomas Fischer from Gamma Groups Germany-based
branch Gamma International GmbH, a quotation concerning the Monitoring
system for iproxy (infection proxy)-project is provided for an unspecified
end customer in Oman.
One concern involved keeping the client [Oman] aware of any changes made to
the proxy [intermediary] server infected with their software for the sake of
culling information from select targets.
During the integration tests in Oman in September 2010 the end customer
figured out that not all of the components of the iproxy infrastructure are
under their  full control. It is, for example possible that changes of the
Oman-network may occur without their knowledge. Thus, it might occur that
ISPs [Internet service providers] may modify some of the current
configuration. Therefore, the question arose whether it is possible to
identify such a modification in the network setup by monitoring the whole
iproxy infrastructure.
monitoring of the iproxy infrastructure including all components of the
systems was derived. This requirement is discussed and a proposal for
solution is described in this offer.
The infection process as was conducted on-site in Oman in 2010 can be
conducted in two different variants, as described in a separate document,
System Manual Project O, prepared for the Gulf client.
The first is described as a binary infection, whereby binaries (non-text
computer files) are infected after being downloaded by the configured target.
In order to do this, the software analyzes the data streams on the NDPs
[network data processors] at both of the Internet exchanges (IX). As soon as
a matching type of binary is downloaded, the infection mechanism is
initiated, then it attaches loader and payload (trojan) to the binary.
Screenshot from a leaked documentScreenshot from a leaked document
The second method is described as update infection, which works by sending
counterfeit server responses to predefined applications (for example iTunes,
Winamp, OpenOffice and SimpleLite), when they are searching for updates.
Data can be captured both through traditional public switch telephone
networks (PSTN), mobile providers and internet protocol suites across a range
of devices.
The users information, including his or her IP address, user name, [cell]
phone number, the date time and identity of the person being communicated
with, and the method or protocol (mail, WWW, Skype, chat, voice, fax, and
SMS) are all up for grabs.
Upon being captured, the data is stored in a Data Warehouse and retrieved
on command.
Quotations for the project, enumerated in Swiss francs (CHF), are broken down
in multiple categories:
Monitoring and alarming 83,355.00 Services provided by Dreamlab 34,400.00 Training 5,400.00 Annual solution maintenance 24,000.00 Redundant monitoring implementation 57,955.00 Services provided by Dreamlab for redundancy 5,760.00 Annual solution maintenance for redundant system 12,000.00 Note: 1 CHF = 1.06720 USD
Although such software does have legitimate applications for law enforcement,
it can easily be used to stifle civil society, as Marczak argues was the case
in Bahrain. Apart from journalists and activists, he noted that in the Malaysia and
Ethiopia, members of the political opposition were apparently being targeted
as well. One piece of FinFisher spyware discovered, for example, contained
details relating to the upcoming Malaysian elections.
You couldnt say exactly who was targeted against, but the use of
election-related content suggests politically motivated targeting. We also
found a sample of this spyware that appeared to be targeted at activists in
Ethiopia. The spyware contained a picture of Ethiopian opposition leaders
that was displayed when the user opened it. By opening the picture the user
copied the spyware, he said.

@_date: 2013-09-06 11:01:50
@_author: Eugen Leitl 
@_subject: [cryptography] regarding the NSA crypto "breakthrough" 
It is reported that the journalists deliberately withheld details
which are available in Snowden's original documents. Somebody
better leak these, fast.
The claims are that some code and magic constants have been weakened,
but also that NSA still has problems with some methods.
We need to know.
Obviously, as a short-term workaround there's fallback to
expensive/inconvenient methods like one-time pads, but long-term
we obviously need new cyphers. Not tainted by any TLA poison.

@_date: 2013-09-06 11:37:53
@_author: Eugen Leitl 
@_subject: The US government has betrayed the Internet. We need to take it back 
The US government has betrayed the Internet. We need to take it back
The NSA has undermined a fundamental social contract. We engineers built the
Internet  and now we have to fix it
Bruce Schneier
The Guardian, Thursday 5 September 2013 20.04 BST
Internet business cables in California.
'Dismantling the surveillance state won't be easy. But whatever happens,
we're going to be breaking new ground.' Photograph: Bob Sacha/Corbis
Government and industry have betrayed the Internet, and us.
By subverting the Internet at every level to make it a vast, multi-layered
and robust surveillance platform, the NSA has undermined a fundamental social
contract. The companies that build and manage our Internet infrastructure,
the companies that create and sell us our hardware and software, or the
companies that host our data: we can no longer trust them to be ethical
Internet stewards.
This is not the Internet the world needs, or the Internet its creators
envisioned. We need to take it back.
And by we, I mean the engineering community.
Yes, this is primarily a political problem, a policy matter that requires
political intervention.
But this is also an engineering problem, and there are several things
engineers can  and should  do.
One, we should expose. If you do not have a security clearance, and if you
have not received a National Security Letter, you are not bound by a federal
confidentially requirements or a gag order. If you have been contacted by the
NSA to subvert a product or protocol, you need to come forward with your
story. Your employer obligations don't cover illegal or unethical activity.
If you work with classified data and are truly brave, expose what you know.
We need whistleblowers.
We need to know how exactly how the NSA and other agencies are subverting
routers, switches, the Internet backbone, encryption technologies and cloud
systems. I already have five stories from people like you, and I've just
started collecting. I want 50. There's safety in numbers, and this form of
civil disobedience is the moral thing to do.
Two, we can design. We need to figure out how to re-engineer the Internet to
prevent this kind of wholesale spying. We need new techniques to prevent
communications intermediaries from leaking private information.
We can make surveillance expensive again. In particular, we need open
protocols, open implementations, open systems  these will be harder for the
NSA to subvert.
The Internet Engineering Task Force, the group that defines the standards
that make the Internet run, has a meeting planned for early November in
Vancouver. This group needs to dedicate its next meeting to this task. This
is an emergency, and demands an emergency response.
Three, we can influence governance. I have resisted saying this up to now,
and I am saddened to say it, but the US has proved to be an unethical steward
of the Internet. The UK is no better. The NSA's actions are legitimizing the
Internet abuses by China, Russia, Iran and others. We need to figure out new
means of Internet governance, ones that makes it harder for powerful tech
countries to monitor everything. For example, we need to demand transparency,
oversight, and accountability from our governments and corporations.
Unfortunately, this is going play directly into the hands of totalitarian
governments that want to control their country's Internet for even more
extreme forms of surveillance. We need to figure out how to prevent that,
too. We need to avoid the mistakes of the International Telecommunications
Union, which has become a forum to legitimize bad government behavior, and
create truly international governance that can't be dominated or abused by
any one country.
Generations from now, when people look back on these early decades of the
Internet, I hope they will not be disappointed in us. We can ensure that they
don't only if each of us makes this a priority, and engages in the debate. We
have a moral duty to do this, and we have no time to lose.
Dismantling the surveillance state won't be easy. Has any country that
engaged in mass surveillance of its own citizens voluntarily given up that
capability? Has any mass surveillance country avoided becoming totalitarian?
Whatever happens, we're going to be breaking new ground.
Again, the politics of this is a bigger task than the engineering, but the
engineering is critical. We need to demand that real technologists be
involved in any key government decision making on these issues. We've had
enough of lawyers and politicians not fully understanding technology; we need
technologists at the table when we build tech policy.
To the engineers, I say this: we built the Internet, and some of us have
helped to subvert it. Now, those of us who love liberty have to fix it.
 Bruce Schneier writes about security, technology, and people. His latest
book is Liars and Outliers: Enabling the Trust That Society Needs to Thrive.
He is working for the Guardian on other NSA stories

@_date: 2013-09-06 12:25:15
@_author: Eugen Leitl 
@_subject: PayPal freezes MailPile's account 
I've used Kickstarter from Germany. Amazon is present in many countries
beyond US/UK.

@_date: 2013-09-06 21:06:50
@_author: Eugen Leitl 
@_subject: Old list archives 
An excellent idea. Unfortunately, I lost my 1980s/90s
emails due to a shredded RAID.
I will put up a mirror as well. mbox format is perfect.

@_date: 2013-09-08 19:09:06
@_author: Eugen Leitl 
@_subject: [linux-elitists] Surveillance 
Anyone with CA/package signing opsec clue willing to help Linux
distros with advice to improve package signing security?

@_date: 2013-09-09 10:42:47
@_author: Eugen Leitl 
@_subject: Quark : A Web Browser with a Formally Verified Kernel 
Quark : A Web Browser with a Formally Verified Kernel
University of California, San Diego
Computer Science and Engineering
Quark is an experimental, formally verified browser. Watch it run popular sites like GMail, Facebook, and Amazon! [video 1] [video
Web browsers mediate access to valuable private data in domains ranging from
health care to banking. Despite this critical role, attackers routinely
exploit browser vulnerabilities to exfiltrate private data and take over the
underlying system. We present Quark, a browser whose kernel has been
implemented and verified in the Coq proof assistant. We give a specification
of our kernel, show that the implementation satisfies the specification, and
finally show that the specification implies several security properties,
including tab non-interference, cookie integrity and confidentiality, and
address bar integrity.
Our Web browser, Quark, exploits formal verification and enables us to verify
security properties for a million lines of code while reasoning about only a
few hundreds. To achieve this goal, Quark is structured similarly to Google
Chrome. It consists of a small browser kernel which mediates access to system
resources for all other browser components. These other components run in
sandboxes which only allow the component to communicate with the kernel. In
this way, Quark is able to make strong guarantees about a million lines of
code (e.g., the renderer, JavaScript implementation, JPEG decoders, etc.)
while only using a proof assistant to reason about a few hundred lines of
code for the Quark kernel. Because the underlying system is protected from
Quark's untrusted components (i.e., everything other than the kernel) we were
free to adopt state-of-the-art implementations and thus Quark is able to run
popular, complex Web sites like Facebook and GMail.
Establishing Browser Security Guarantees through Formal Shim Verification
[Tech Report] USENIX Security 2012 Dongseok Jang, Zachary Tatlock, Sorin Lerner Source code(.tar.gz) (Version 0.1, 08/07/2012, 1.3MB)
Dongseok Jang	
Zachary Tatlock	
Sorin Lerner

@_date: 2013-09-09 11:23:29
@_author: Eugen Leitl 
@_subject: IETF: Security and Pervasive Monitoring 
forkit! , tt
Security and Pervasive Monitoring
The Internet community and the IETF care deeply about how much we can trust
commonly used Internet services and the protocols that these services use.
So the reports about large-scale monitoring of Internet traffic and users
disturbs us greatly.  We knew of interception of targeted individuals and
other monitoring activities, but the scale of recently reported monitoring is
surprising. Such scale was not envisaged during the design of many Internet
protocols, but we are considering the consequence of these kinds of attacks.
Of course, it is hard to know for sure from current reports what attack
techniques may be in use.  As such, it is not so easy to comment on the
specifics from an IETF perspective.  Still, the IETF has some long standing
general principles that we can talk about, and we can also talk about some of
the actions we are taking.
In 1996, RFC 1984 articulated the view that encryption is an important tool
to protect privacy of communications, and that as such it should be
encouraged and available to all.  In 2002, we decided that IETF standard
protocols must include appropriate strong security mechanisms, and
established this doctrine as a best current practice, documented in RFC 3365.
Earlier, in 2000 the IETF decided not to consider requirements for
wiretapping when creating and maintaining IETF standards, for reasons stated
in RFC 2804. Note that IETF participants exist with positions at all points
of the privacy/surveillance continuum, as seen in the discussions that lead
to RFC 2804.
As privacy has become increasingly important, the Internet Architecture Board
(IAB) developed guidance for handling privacy considerations in protocol
specifications, and documented that in RFC 6973. And there are ongoing
developments in security and privacy happening within the IETF all the time,
for example work has just started on version 1.3 of the Transport Layer
Security (TLS, RFC 5246) protocol which aims to provide better
confidentiality during the early phases of the cryptographic handshake that
underlies much secure Internet traffic.
Recent days have also seen an extended and welcome discussion triggered by
calls for the IETF to build better protections against wide-spread
As that discussion makes clear, IETF participants want to build secure and
deployable systems for all Internet users.  Indeed, addressing security and
new vulnerabilities has been a topic in the IETF for as long as the
organisation has existed.  Technology alone is, however, not the only factor.
Operational practices, laws, and other similar factors also matter. First of
all, existing IETF security technologies, if used more widely, can definitely
help.  But technical issues outside the IETFs control, for example endpoint
security, or the properties of specific products or implementations also
affect the end result in major ways. So at the end of the day, no amount of
communication security helps you if you do not trust the party you are
communicating with or the devices you are using. Nonetheless, were confident
the IETF can and will do more to make our protocols work more securely and
offer better privacy features that can be used by implementations of all
So with the understanding of limitations of technology-only solutions, the
IETF is continuing its mission to improve security in the Internet.  The
recent revelations provide additional motivation for doing this, as well as
highlighting the need to consider new threat models.
We should seize this opportunity to take a hard look at what we can do
better.  Again, it is important to understand the limitations of technology
alone. But here are some examples of things that are already ongoing:
Were having a discussion as part of the development of HTTP/2.0 as to how to
make more and better use of TLS, for example to perhaps enable clients to
require the use of security and not just have to react to the HTTP or HTTPS
URLs chosen by servers.
Were having discussions as to how to handle the potentially new threat model
demonstrated by the recent revelations so that future protocol designs can
take into account potential pervasive monitoring as a known threat model.
Were considering ways in which better use can be made of existing protocol
features, for example, better guidance as to how to deploy TLS with Perfect
Forward Secrecy, which makes applications running over TLS more robust if
server private keys later leak out.
Were constantly updating specifications to deprecate older, weaker
cryptographic algorithms and allocate code points for currently strong
algorithm choices so those can be used with Internet protocols.
And we are confident that discussions on this topic will motivate IETF
participants to do more work on these and further related topics.
But dont think about all this just in terms of the recent revelations.  The
security and privacy of the Internet in general is still a challenge even
ignoring pervasive monitoring, and if there are improvements from the above,
those will be generally useful for many reasons and for many years to come.
Perhaps this years discussions is a way to motivate the world to move from
by default insecure communications to by default secure.  Publicity and
motivation are important, too. There is plenty to do for all of us, from
users enabling additional security tools to implementors ensuring that their
products are secure.
In the Vancouver IETF meeting, there will be time dedicated to discuss this,
and we ask that those interested in working on this topic contribute to the
analysis and develop proposals in this area.  Those contributions are very
welcome and can start now and continue in Vancouver and beyond.
Relevant mailing lists (from most specific to most general) include:
The perpass mailing list (perpass recently set up to consider how
the IETF ought react to pervasive monitoring
The ietf security area mailing list (saag for general security
The ietf main mailing list (ietf for general discussion
Jari Arkko, Chair of the IETF and Stephen Farrell, IETF Security Area
This entry was posted in IETF on 2013/09/07.

@_date: 2013-09-09 11:35:05
@_author: Eugen Leitl 
@_subject: [liberationtech] Meet the 'cowboy' in charge of the NSA 
Looks paywalled. Can someone liberate the document, and repost
it here?

@_date: 2013-09-09 13:06:14
@_author: Eugen Leitl 
@_subject: [cryptography] New NSA Slides and Details Released last night 
David D
Sent: Monday, September 09, 2013 12:07 PM
Lots of gems in this video:
cryptography mailing list

@_date: 2013-09-09 13:05:45
@_author: Eugen Leitl 
@_subject: [liberationtech] Meet the 'cowboy' in charge of the NSA 
9 September 2013 The Cowboy of the NSA Keith Alexander

@_date: 2013-09-09 14:40:10
@_author: Eugen Leitl 
@_subject: Scott Aaaronson: NSA: Possibly breaking US laws, but still bound by 
cryptography Cryptography List NSA: Possibly breaking US laws, but still bound by laws of computational
Last week, I got an email from a journalist with the following inquiry.  The
recent Snowden revelations, which made public for the first time the US
governments black budget, contained the following enigmatic line from the
Director of National Intelligence: We are investing in groundbreaking
cryptanalytic capabilities to defeat adversarial cryptography and exploit
internet traffic.  So, the journalist wanted to know, what could these
groundbreaking capabilities be?  And in particular, was it possible that
the NSA was buying quantum computers from D-Wave, and using them to run
Shors algorithm to break the RSA cryptosystem?
I replied that, yes, thats possible, but only in the same sense that its
possible that the NSA is using the Easter Bunny for the same purpose.  (For
one thing, D-Wave themselves have said repeatedly that they have no interest
in Shors algorithm or factoring.  Admittedly, I guess thats what D-Wave
would say, were they making deals with NSA on the sly!  But its also what
the Easter Bunny would say.)  More generally, I said that if the open
scientific worlds understanding is anywhere close to correct, then quantum
computing might someday become a practical threat to cryptographic security,
but it isnt one yet.
That, of course, raised the extremely interesting question of what
groundbreaking capabilities the Director of National Intelligence was
referring to.  I said my personal guess was that, with ~99% probability, he
meant various implementation vulnerabilities and side-channel attacksthe
sort of thing that we know has compromised deployed cryptosystems many times
in the past, but where its very easy to believe that the NSA is ahead of the
open world.  With ~1% probability, I guessed, the NSA made some sort of big
improvement in classical algorithms for factoring, discrete log, or other
number-theoretic problems.  (I wouldve guessed even less than 1% probability
for the latter, before the recent breakthrough by Joux solving discrete log
in fields of small characteristic in quasipolynomial time.)
Then, on Thursday, a big New York Times article appeared, based on 50,000 or
so documents that Snowden leaked to the Guardian and that still arent
public.  (See also an important Guardian piece by security expert Bruce
Schneier, and accompanying Q&A.)  While a lot remains vague, there might be
more public information right now about current NSA cryptanalytic
capabilities than theres ever been.
So, how did my uninformed, armchair guesses fare?  Its only halfway into the
NYT article that we start getting some hints:
The files show that the agency is still stymied by some encryption, as Mr.
Snowden suggested in a question-and-answer session on The Guardians Web site
in June.
Properly implemented strong crypto systems are one of the few things that
you can rely on, he said, though cautioning that the N.S.A. often bypasses
the encryption altogether by targeting the computers at one end or the other
and grabbing text before it is encrypted or after it is decrypted
Because strong encryption can be so effective, classified N.S.A. documents
make clear, the agencys success depends on working with Internet companies 
by getting their voluntary collaboration, forcing their cooperation with
court orders or surreptitiously stealing their encryption keys or altering
their software or hardware
Simultaneously, the N.S.A. has been deliberately weakening the international
encryption standards adopted by developers. One goal in the agencys 2013
budget request was to influence policies, standards and specifications for
commercial public key technologies, the most common encryption method.
Cryptographers have long suspected that the agency planted vulnerabilities in
a standard adopted in 2006 by the National Institute of Standards and
Technology and later by the International Organization for Standardization,
which has 163 countries as members.
Classified N.S.A. memos appear to confirm that the fatal weakness, discovered
by two Microsoft cryptographers in 2007, was engineered by the agency. The
N.S.A. wrote the standard and aggressively pushed it on the international
group, privately calling the effort a challenge in finesse.
So, in pointing to implementation vulnerabilities as the most likely
possibility for an NSA breakthrough, I might have actually erred a bit too
far on the side of technological interestingness.  It seems that a large part
of what the NSA has been doing has simply been strong-arming Internet
companies and standards bodies into giving it backdoors.  To put it bluntly:
sure, if it wants to, the NSA can probably read your email.  But that isnt
mathematical cryptographys faultany more than it would be mathematical
cryptos fault if goons broke into your house and carted away your laptop.
On the contrary, properly-implemented, backdoor-less strong crypto is
something that apparently scares the NSA enough that they go to some lengths
to keep it from being widely used.
I should add that, regardless of how NSA collects all the private information
it doesby beating crypto in a fair fight (!) or, more likely, by
exploiting backdoors that it itself installedthe mere fact that it collects
so much is of course unsettling enough from a civil-liberties perspective.
So Im glad that the Snowden revelations have sparked a public debate in the
US about how much surveillance we as a society want (i.e., the balance
between preventing 9/11 and preventing Orwell), what safeguards are in place
to prevent abuses, and whether those safeguards actually work.  Such a public
debate is essential if were serious about calling ourselves a democracy.
At the same time, to me, perhaps the most shocking feature of the Snowden
revelations is just how unshocking theyve been.  So far, I havent seen
anything that shows the extent of NSAs surveillance to be greater than what
I wouldve considered plausible a priori.  Indeed, the following could serve
as a one-sentence summary of what weve learned from Snowden:
Yes, the NSA is, in fact, doing the questionable things that anyone not
living in a cave had long assumed they were doingthat assumption being so
ingrained in nerd culture that countless jokes are based around it.
(Come to think of it, people living in caves might have been even more
certain that the NSA was doing those things.  Maybe thats why they moved to
So, rather than dwelling on civil liberties, national security, yadda yadda
yadda, let me move on to discuss the implications of the Snowden revelations
for something that really matters: a 6-year-old storm in theoretical computer
sciences academic teacup.  As many readers of this blog might know, Neal
Koblitza respected mathematician and pioneer of elliptic curve cryptography,
who (from numerous allusions in his writings) appears to have some
connections at the NSApublished a series of scathing articles, in the
Notices of the American Mathematical Society and elsewhere, attacking the
theoretical computer science approach to cryptography.  Koblitzs criticisms
were varied and entertainingly-expressed: the computer scientists are too
sloppy, deadline-driven, self-promoting, and corporate-influenced; overly
trusting of so-called security proofs (a term they shouldnt even use,
given how many errors and exaggerated claims they make); absurdly overreliant
on asymptotic analysis; bodacious in introducing dubious new hardness
assumptions that they then declare to be standard; and woefully out of
touch with cryptographic realities.  Koblitz seemed to suggest that, rather
than demanding the security reductions so beloved by theoretical computer
scientists, people would do better to rest the security of their
cryptosystems on two alternative pillars: first, standards set by
organizations like the NSA with actual real-world experience; and second, the
judgments of mathematicians with  taste and experience, who can just see
whats likely to be vulnerable and what isnt.
Back in 2007, my mathematician friend Greg Kuperberg pointed out the irony to
me: here we had a mathematician, lambasting computer scientists for trying to
do for cryptography what mathematics itself has sought to do for everything
since Euclid!  That is, when you see an unruly mess of insights, related to
each other in some tangled way, systematize and organize it.  Turn the tangle
into a hierarchical tree (or dag).  Isolate the minimal assumptions (one-way
functions?  decisional Diffie-Hellman?) on which each conclusion can be
based, and spell out all the logical steps needed to get from here to
thereeven if the steps seem obvious or boring.  Any time anyone has tried to
do that, its been easy for the natives of the unruly wilderness to laugh at
the systematizing newcomers: the latter often know the terrain less well, and
take ten times as long to reach conclusions that are ten times less
interesting.  And yet, in case after case, the clarity and rigor of the
systematizing approach has eventually won out.  So it seems weird for a
mathematician, of all people, to bet against the systematizing approach when
applied to cryptography.
The reason Im dredging up this old dispute now, is that I think the recent
NSA revelations might put it in a slightly new light.  In his articlewhose
main purpose is to offer practical advice on how to safeguard ones
communications against eavesdropping by NSA or othersBruce Schneier offers
the following tip:
Prefer conventional discrete-log-based systems over elliptic-curve systems;
the latter have constants that the NSA influences when they can.
Here Schneier is pointing out a specific issue with ECC, which would be
solved if we could merely ensure that NSA or other interested parties
werent providing input into which elliptic curves to use.  But I think
theres also a broader issue: that, in cryptography, its unwise to trust any
standard because of the prestige, real-world experience, mathematical good
taste, or whatever else of the people or organizations proposing it.  What
was long a plausible conjecturethat the NSA covertly influences
cryptographic standards to give itself backdoors, and that
otherwise-inexplicable vulnerabilities in deployed cryptosystems are
sometimes there because the NSA wanted them therenow looks close to an
established fact.  In cryptography, then, its not just for idle academic
reasons that youd like a publicly-available trail of research papers and
source code, open to criticism and improvement by anyone, that takes you all
the way from the presumed hardness of an underlying mathematical problem to
the security of your system under whichever class of attacks is relevant to
Schneiers final piece of advice is this: Trust the math.  Encryption is
your friend.
Trust the math.  On that note, heres a slightly-embarrassing confession.
When Im watching a suspense movie (or a TV show like Homeland), and I reach
one of those nail-biting scenes where the protagonist discovers that
everything she ever believed is a lie, I sometimes mentally recite the proof
of the Karp-Lipton Theorem.  It always calms me down.  Even if the entire
universe turned out to be a cruel illusion, it would still be the case that
NP  P/poly would collapse the polynomial hierarchy, and I can tell you
exactly why.  It would likewise be the case that you couldnt break the GGM
pseudorandom function without also breaking the underlying pseudorandom
generator on which its based.  Math could be defined as that which can still
be trusted, even when you cant trust anything else.
This entry was posted on Sunday, September 8th, 2013 at 11:31 am	 and
is filed under Complexity, Nerd Interest. You can follow any responses to
this entry through the RSS 2.0 feed. You can leave a response, or trackback
from your own site.
24 Responses to NSA: Possibly breaking US laws, but still bound by laws of
computational complexity Aaronson on crypto. Schneier elliptic-curve
systems; the latter have constants that the NSA influences when they can. |
Gordon's shares Says: Comment  September 8th, 2013 at 1:22 pm [] Link.
Trust math, but not NSA mathematicians. []
Douglas Knight Says: Comment  September 8th, 2013 at 1:35 pm Could you be
more specific about what you mean by the hypothetical big improvement on
number theory algorithms that is covered by your 1%?
Do elliptic curve algorithms count? Does an L(1/4) algorithm count, or only
quasi-polynomial? What if they cant break all instances, but, as has
repeatedly happened, they discovered bad primes or bad exponents that make
particular keys weak? Breaking a random half of all keys is almost as good as
breaking all of them. Schneiers condemnation of ECC seems to require more
than 1% chance NSA knows something special about ECC.
PS  David Jao, commenting on Schneiers blog says that we can and do use
cryptography to prevent NSA from meddling with mystery constants. He says
that the ECC standard curves are generated by SHA-1, so to meddle, NSA would
have to break the has function. (But if half of curves are bad, thats easy.)
Anonymous Says: Comment  September 8th, 2013 at 1:45 pm
You are making good and interesting points. However, Koblitz also has some
valid criticisms of TCS even if his conclusions are not valid. The
mathematical models we built in TCS are useless if they dont relate to the
practice and we know many of our standard models are not good enough
approximation of the reality and arguably there isnt enough effort to deal
with these issues. Technical heavy weight lifting is used as the ultimate
criteria for judging the value of research projects inside the community.
Also I think you are exaggerating what most cryptographers expected that NSA
was doing. I have heard several famous crypto experts quite surprised by
these revelations and it has shaken their trust in the government
institutions. I never understood why some people presume that government is a
benevolent entity, such beliefs in government institutions seems like
ideology to me.
Daniel Armak Says: Comment  September 8th, 2013 at 2:06 pm
You can trust the math itself, and so can Bruce Schneier and a few tens of
thousands of other people. But everyone else who cant grok the entire
mathematical arguments for each cryptographical system, or doesnt want to
spend a long time studying it, must trust the word of people like you. And
since the NSA can and does subvert people like you, who do original work and
analyze others work and sit on standards committees, not to mention the
programmers who implement it in code, what are we to do?
Daniel W. Says: Comment  September 8th, 2013 at 2:33 pm
In my mind, the best circumstantial evidence that the NSA has not practically
broken any of the major cryptosystems is the following:, if they had, they
would most likely keep this as a highly guarded secret to be used only
against high value targets rather than as a means of monitoring potential
terrorists. It would most likely be contained within a small circle and not
mentioned in power-point presentations to low-level analysts.
Of course, the above argument may be flawed by assuming the NSA has too high
of a level of competence.
T H Ray Says: Comment  September 8th, 2013 at 2:43 pm
  the clarity and rigor of the systematizing approach has eventually won
No doubt. In Euclids time as well as the present, though, it is helpful to
have something to systematize. Making that assumption available and
convenient is what mathematicians do.
Scott Says: Comment  September 8th, 2013 at 3:02 pm
Daniel Armak You can trust the math itself, and so can Bruce Schneier and a few tens of
thousands of other people. But everyone else  must trust the word of people
like you.  You raise an excellent point, which I think applies even more
broadly than you say. For one thing, I merely understand some of the general
ideas: I havent gone through every detail of the math used by the crypto in
my web browser, and I dare say that most professional cryptographers havent
For another, the point is much broader than cryptography: how can you trust
quantum mechanics, if you havent done the requisite experiments yourself?
The physicists couldve all been bought off by some anti-realist cabal. :-)
Or how can you trust that the government isnt putting mind-control drugs
into the fruit you buy in the supermarket, etc. etc.
So were extremely lucky that science hit on a solution to these problemsthe
only workable solution, reallyback in the 17th century. The solution is to
open up every question to scrutiny, discussion, and challenge by any
interested person. Assertions gain credibility by surviving public
criticismand thats just as true in math as it is in experimental sciences.
I believe many theorems even though I havent checked the proofs myself,
because I know that if there were an error, then someone else couldve made a
name for themselves by finding it.
Now, for this Popperian dynamic to work, the whole process has to be carried
out in the open: if I thought someone who found a fatal flaw in a proof would
only tell their friends, then that doesnt do me any good. Thats why the
dividing line between crypto as black art and modern crypto happened
precisely when new discoveries started being published in the open
literature, rather than being filed in a drawer at NSA or GCHQ.
wolfgang Says: Comment  September 8th, 2013 at 3:20 pm
Unfortunately, this xkcd.com/538/ had it right imho.
Scott Says: Comment  September 8th, 2013 at 3:20 pm
Daniel W.  If the NSA had really broken strong cryptosystems, then why
would they have resorted to so many covert tactics (or, in the case of the
Clipper Chip, overt attempts) to prevent people from using strong crypto,
unless NSA has a backdoor? I suppose its all elaborate psychological
warfare, to prevent us from discovering the fact that these cryptosystems
were broken? And that even Snowden himself is part of the NSAs master plan?
At least in my book, every time you claim that what looks on its face like
evidence for X, is really evidence for a powerful cabal trying to prevent
everyone from discovering not(X), the plausibility of your theory gets cut by
a factor of maybe 50,000. This is directly related to the fact that I dont
believe any conspiracy theoriesas in zero, not one.
Scott Says: Comment  September 8th, 2013 at 3:32 pm
Douglas Knight  Sure, dramatic improvements in elliptic-curve algorithms
would certainly countas would merely subexponential algorithms, were the
improvements large enough to threaten key sizes that the academic
cryptographers considered safe.
More broadly, though, youre entirely right that theres not a sharp line
between improved number-theory algorithms and implementation
vulnerabilities. Often, whats happened in practice is that an
implementation vulnerability has opened the way for an attack that still
requires interesting and nontrivial number theory. But I suppose that sort of
thing would still belong to the 99% part of my probability estimate. In the
1% part, I really had in mind something that would give theoretical
cryptographers a heart attack (like, I dunno, factoring in L(1/10), or
elliptic curve discrete log in quasipolynomial time).
Scott Says: Comment  September 8th, 2013 at 5:03 pm
Anonymous You are making good and interesting points. However, Koblitz also has some
valid criticisms of TCS even if his conclusions are not valid.  I completely
agree that Koblitz has some valid criticisms.
However, Ive read pretty much all of his and Menezess anti-TCS screeds, and
to me what hes doing seems, if you like, too easy to be helpful. Koblitzs
favorite M.O. is to recount various slip-ups by people in the Goldreich
school of crypto and laugh at them: haha, they talk about provable
security, but there was a bug in their proof! or their security definition
left out an important class of side-channel attacks! Then, with even more
glee, Koblitz relates how the hapless computer scientists put out a new paper
supposedly fixing the problem, but that paper had its own problems, and so
The trouble is, that is indeed what a bunch of incompetent buffoons would
look like, but its also what science looks like! :-) Koblitz never seems to
want to acknowledge that the end result of the process is better scientific
understanding and more secure cryptosystems than before (even if still not
Also, of course, Koblitz almost defiantly refuses to suggest any better
mathematical foundations for cryptography, besides the reduction-based
foundations that were built up over the last 30 years. I.e., its not that
instead of adaptive chosen ciphertext attack, he has a better definition to
propose, or that instead of bodacious new hardness assumptions, he can give
a single assumption that suffices for everything. Instead, what he appears to
want is simply a return to the black art era of cryptography, when security
arguments boiled down to we tried to break it and failed or trust us, we
have better mathematical taste than you.
The trouble is, I cant think of a single case in the history of science when
mathematical foundations as well-developed as cryptographys now are, were
simply abandoned wholesale without better mathematical foundations to replace
them. So intellectually, Koblitz strikes me as someone whos throwing spears
at battle-tanks. Being the excellent marksman that he is, he actually scores
some hitsbut the reduction-encrusted battle-tanks are still going to win in
the end.
The mathematical models we built in TCS are useless if they dont relate to
the practice and we know many of our standard models are not good enough
approximation of the reality and arguably there isnt enough effort to deal
with these issues.  Would one also say that the mathematical foundations of
topologyopen sets, Urysohns Lemma, etc.are useless if they dont relate to
the practice of tying and untying knots? I think thats a pretty close
analogy for the relationship between what, say, Goldreich or Goldwasser or
Micali do, and the actual practice of cryptography. In both cases, yes,
theres some relation between the intellectual foundations on the bottom and
the beautiful ornaments on top, but not surprisingly there are many floors in
between. Starting from a one-way function, for example, you first have to
construct a quasi-regular one-way function, then a pseudoentropy generator,
then a pseudorandom generator, then a pseudorandom function, and then maybe
you can start to think about building (say) a rudimentary private-key
cryptosystem or signature scheme.
Also I think you are exaggerating what most cryptographers expected that NSA
was doing. I have heard several famous crypto experts quite surprised by
these revelations and it has shaken their trust in the government
institutions. I never understood why some people presume that government is a
benevolent entity, such beliefs in government institutions seems like
ideology to me.  My situation is different: I never had any real doubt that
NSA was doing such things; the thing I genuinely dont know is whether they
have good reasons to be doing them. I consider it conceivable that the NSA
has indeed stopped many terrorist attacks or other international disasters
that we never hear aboutin which case, the strongest case in their favor
might be stronger than the strongest case that can ever be made publicly. The
fact that President Obama, whos so reasonable on so many issues, has implied
as much is evidence for that view from my perspective. On the other hand, I
also consider it conceivable that the current eavesdropping regime is purely
a result of the universal tendency of bureaucracies to expand, justify
themselves, and zealously guard their power and privileges. Or it could be
some combination of the two.
For me, though, the deciding consideration is that, even in a fantasy world
where the NSAs actions had always been 100% justified, Id still want them
to be more accountable to the public than they are now. Trust that we have
our reasons, even though we cant tell you what they are simply doesnt work
over the long term in a democracy, even if the trust is justified at any
particular time or in any particular case (and of course, often it hasnt
Anonymous Says: Comment  September 8th, 2013 at 8:05 pm
I agree with you that his attitude is not constructive criticism. I would
even go further than you and say it is stupid to forget the science of crypto
and go back to purely engineering art treatment.
Regarding reasonability of what NSA does, NSA and its backers would of course
claim these tools are useful. To be honest, security was a weak point of
Obamas campaign, he is not really knowledgeable in these issues and he has
not gone and will not go against his advisers if they tell him these tools
are necessary to fight terrorism. However, as far as I have heard, they have
hard time convincing anyone outside executive branch that these tools have
been as useful as they are claiming. How many major terrorist plots they have
been uncovered and prevented using these tools? It seems that they are using
these tools for a very wide range of activities including industrial and
political espionage on foreign governments and companies and gain political
and commercial advantage (what they call US national interests, not just
securing Americans against terrorists). Does anyone really believe that EU or
Brazil or liberal NGOs will launch a terrorist attack on US? FBIs actions
against Dr. King is telling how far they would go. They use the fear factor
of a possible terrorist attacks to justify these actions to the public,
however the laws allow them to do whatever they want to and when there are
restrictions (like the fourth amendments) they find ways to circumvents them
(e.g. by colliding with foreign intelligence services like GCHQ to spy on
American citizens) or change the interpretations of those laws. We are very
lucky that many influential Americans in the previous generations had a
negative view of the federal government and wanted to restrict its powers as
much as possible, restrictions which are being removed in practice (partly
because some people want to settle sociopolitical disputes present in the
country using the governments power). I dont see why so much power should
be invested in a single authority with almost no real public supervision and
scrutiny (a role that media was playing to some extent in previous decades
but is coming under heavy pressure from government as Manning, Swartz,
Snowden,  cases demonstrate). And even when courts find that someone in the
government has seriously violated the laws the president forgives them and
they avoid real punishment (as Scoot Libby case demonstrates).
It is not just US government, there is a trend in western liberal
democracies. It is simply unbelievable that the UK security forces used a law
passed to fight terrorism to hold the partner of a Guardian journalist for 9
hours without a lawyer and without the protection of Miranda rights against
self-incrimination. Anyone who thinks that security forces will only use the
authority and tools they obtain to the limited extent of the original goal
suffers from extreme nativity. They will use any tools in their disposal to
the fullest extent they can to achieve what they perceive to be the goals of
their institution. When they perceive journalists like Greenwald as a threat
to the national interests they use these tools to fight them which includes
intimidating the partner of a journalist using terrorism fighting powers. I
still fund it really hard to believe that we have gone so far in the
direction of an Orwellian society.
What can theoretical computer science offer biology? | Theory, Evolution, and
Games Group Says: Comment  September 9th, 2013 at 2:16 am
[] the aid that cstheory can offer to biological understanding. In
yesterdays post on the NSA and computational complexity, Aaronson  with
attribution to mathematician Greg Kuperberg  provided the following []
Paul Beame Says: Comment  September 9th, 2013 at 2:45 am
Some of the NSA revelations have been no surprise at all. It was well known
in the 1980s, particularly after the publication of The Puzzle Palace, that
the NSA was tapping all the trans-Atlantic telephone cables; gathering up of
all e-mail to foreign addresses seems like more of the same.
The relationship of the NSA with TCS cryptographers has been pretty shaky. I
recall attending a theory of cryptography workshop at MITs Endicott House in
June 1985 with one or two official NSA attendees. At the time, there were one
or two TCS attendees known to have NSA funding and the NSA people wanted to
recruit more. In announcing their desire to sponsor more TCS cryptographers,
one of the NSA people cast a pall over the meeting by saying: If you are
interested, just mention it in a phone conversation with one of your friends
and well get back to you. This didnt exactly endear them to anyone.
J Says: Comment  September 9th, 2013 at 2:51 am
Math could be defined as that which can still be trusted, even when you
cant trust anything else
Wait till someone shows multiplication and addition have same complexity or
possible Voevodskys/Nelsons worst nightmare comes true
Scott Says: Comment  September 9th, 2013 at 4:20 am
J  Multiplication and addition having the same complexity (and yes, its
conceivable that theres a linear-time multiplication algorithm) wouldnt do
anything whatsoever to undermine my trust in mathwhy would it?
Also, even if ZF set theory were shown to be inconsistent (and it wont be
:-) ), that wouldnt do anything whatsoever to undermine my trust in theorems
about (say) finite groups, or low-dimensional topology, or theoretical
computer sciencein fact, about anything that doesnt involve transfinite
sets. It would merely tell me that there was a need (and, of course, an
exciting opportunity) to rethink the foundations. Thats something that
already happened 100+ years ago (the renovations causing virtually no damage
to the higher floors), and that could conceivably happen again.
Vitruvius Says: Comment  September 9th, 2013 at 4:58 am
I agree, Scott, with your general position that any time one claims that
evidence for x is really evidence for a powerful cabal trying to prevent
everyone from discovering not(x) ones credibility drops by an irrecoverably
large factor, and I agree with you that math can be defined as that which
can still be trusted, even when you cant trust anything else (as you put
it), yet that still begs the question of how we the people decide what to
trust to be valid math.
Similarly, while your suggestion to open up every question to scrutiny,
discussion, and challenge by any interested person may be necessary in order
to establish public trust, it isnt sufficient because we still have the
problem of deciding which such interested persons to trust, and which to
write off as conspiracy theorists in their own right. How do we feasibly
decide, in effect, whether Ehrenhaft is a crackpot (as it were), and whether
Snowden himself is part of the NSAs master plan (as you playfully alluded
To that end you may be interested in Why Doesnt the Public Trust
Scientists?, a lecture by The Right Honourable Professor The Baroness ONeill
of Bengarve, Emeritus Professor of Philosophy at the University of Cambridge
and past Principal of Newnham College, Cambridge, which she presented in 2005
as part of the Science Futures series by the San Diego Science and Technology
Councils Center for Ethics in Science and Technology.
Note that while scientists are the titular and exemplary referent matter in
that lecture, Baroness ONeills talk actually considers a range of questions
in regard of public trust, including the roles of professional organizations,
trustworthiness (which cant replace trust because of the quis custodiet
ipsos custodes problem), statutory regulation, post hoc accountability, &c,
which apply more broadly to the matters of public trust in any and every
profession and institution, including politics and the law.
ONeill argues, if I may be so bold as to suggest a prcis, that going back
through the 17th century (as you noted) western liberal democracies have
indeed evolved a multipartite methodology that does tend work in practice and
that may well be the best we can get in principal, though it remains unclear
to me how well we are applying those techniques to matters of state security
in general, and how effectively you folks in the United States of America are
applying those techniques to your vaunted Agency in particular.
Scott Says: Comment  September 9th, 2013 at 5:01 am
Paul Beame  Ive actually heard that joke many times, in other variants.
(Interested in career opportunities at the NSA? Call your mom and let her
know!) I didnt know that NSA people themselves used the joke at
conferences, but it doesnt surprise me at all.
J Says: Comment  September 9th, 2013 at 6:39 am Multiplication and
addition having the same complexity (and yes, its conceivable that theres a
linear-time multiplication algorithm) wouldnt do anything whatsoever to
undermine my trust in mathwhy would it?
I thought I read somewhere that if addition and multiplication turn out to be
similar in complexity, then it would imply something is wrong with
On the same vein think of the generalization of scheme theory that Mochizuki
claims to have undertaken to take apart + and x in ring structure.
I would think something fundamentally would have changed in our picture if
they turn to be similar in complexity.
J Says: Comment  September 9th, 2013 at 6:47 am
Atleast for computational purposes, the multiplicative group structure and
additive group structure of $\Bbb Z$ seem to be coinciding. This seems wrong.
I cannot directly relate to $Z \bmod p$ but this seems to have implication to
Discrete Log. An implication for this may not be beyond reach for atleast a
few other rings as well.
Scott Says: Comment  September 9th, 2013 at 7:02 am
J  Well, we already have a remarkable O(n logn loglogn) multiplication
algorithm (due to Frer, and building on many previous works), and it hasnt
created any problem for the foundations of mathematics that I know about.
Meanwhile, just like for most problems, we currently have no lower bound for
multiplication better than the trivial (n). I suppose Id guess that (n
logn) is some sort of barrier, but not with any strength of conviction: if a
linear-time algorithm were discovered, it certainly wouldnt cause me to
doubt the consistency of ZF set theory. :-)
Scott Says: Comment  September 9th, 2013 at 7:16 am
Vitruvius it remains unclear to me  how effectively you folks in the United States of
America are applying those techniques to your vaunted Agency in particular.
As long as were trading mild national barbs, youre Canadian? You guys do
have the Communications Security Establishment, which according to the NYT
article is one of only four foreign agencies (along with Britains,
Australias, and New Zealands) that knows the full extent of the NSAs
decoding capabilities and is cleared for its Bullrun program. Though I
confess that, when I try to imagine Canadas CSE, I come up with something
like the following:
Read this gentlemans private email? Ooo, nooo, that doesnt sound terribly
polite, eh?
J Says: Comment  September 9th, 2013 at 7:21 am
Professor I am well aware of all $n^{1+\epsilon}$ algorithms and Schonages
$O(n)$ algorithm on multitape machines. I cannot find the reference I am
thinking. It was written by a TCS theorist. I would seriously think that the
standard ring structure in $\Bbb Z$ could be modeled differently. I do not
know if ZF would be affected. However the question of treating x and +
differently for computation purposes compare to mathematical purposes arises
making things murky.
I am not implicating ZF with $O(n)$ algorithms for standard x operations on
the standard structure of $\Bbb Z$. The ZFC comment was a second piece of
mathematical conundrum some reputed folks have raised awareness about for a
need to be more well-grounded and it rang well with your statement on truth
in math as we know it. (Unrelated but bringing in  $Z$ has been a puzzle
before as well  it is the simplest ring with a spectrum of prime ideals
whose dimension is unclear to be interpreted in a standard way)
Scott Says: Comment  September 9th, 2013 at 7:23 am
Wolfgang Unfortunately, this xkcd.com/538/ had it right imho.
YES! I especially liked the mouseover text (Actual actual reality: nobody
cares about his secrets).

@_date: 2013-09-09 16:37:13
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Blockchain archival 
Not quite true, as I said balance-at-point-in-time would solve that (and make the storage requirements much lower)
For bitcoin to grow beyond interesting experiment into global everyday use a number of things would have to happen, not least of which is taking 'average punter' into account. Whilst new ideas can filter into the general consciousness over time,sometimes concepts have to go with 'what already works' :)
People's concept of money hasn't really changed in over 1,000 years - it remains 'something of known value i can exchange for something else'.
No-one outside of bitcoin dev's and early adopters really gets the one-shot concept of addresses - possibly rightly so - keeping issues of it lowering levels of anonymity etc out of the discussion - it doesn't fit with the mindset people have - it's difficult enough getting merchants to setup separate addresses for each client, one per transaction is simply a waste (of addresses, storage, blockchain size, numnber of inputs|outputs when spending etc)
I'm sure the wife would love a new handbag everytime she gets some money, but the real-world just isnt like that ;)
Addresses are perceived as the equivalent of a jar you stick your coins in. You can have lots of jars. Each jar can be for a specific reason or whatever, but the analogy is there.
Wallets are like a box you keep some of your jars in. With the added interesting concept that a jar can be in multiple boxes at the same time. Only the person with the right 'key' can open the jar and take the However unlike the 3 money boxes I have behind me right now - which i can take 1 single penny out of one and put it into another - if I want to move bitcoins from one addresses (jar) to another *of my own* I have to pay a fee. Worse still if the jar doesnt have much in it I'm denied that ability.
End user will neither understand why or want to pay the fee, for dealing with their own coins.
If a jar breaks I can just tip the contents into a new one - unless I'm very careless, the amount in the new one = the amount in the old one - people will want/need it to work like that.
Similarly if you do have all these addresses around, you may want (as good housekeeping) discard some of them (after moving the cash).
So having the ability to specify address to send from is essential (and a sadly missing feature of the QT client)
'intra-wallet' transfers with an 'also discard the sending address' would be a way of (once confirmed) stopping any further use of that address (denied any further transactions by miners ?) and when balance-at-point-in-time is implemented, a way of shrinking the storage for all other bitcoin users (who chosse not to have a full transaction If i send luke 10, and luke sends me back 3, i have 3, luke has 7.
If luke sends me 2, and i send luke 1, i have 4 and luke has 6.
To verify my ability to send jeff 4, all that is needed is to know that I have 4, not all the transactions that led to that state - thats how its done now, thats not necessarily efficient as bitcoin grows
If luke sends me 4 more, i now have 4 again, luke has 3
If i send 1 to each of the children, they have 1 each (*4)
Having a 'family' wallet means when on holiday they can have that rental of quad-bikes - to send the rental company 4 the client only needs to know that those addresses now have 1 each in them, not all the previous transactions - if they didnt exist at the point-in-time balance, then yes, it would need to know about the luke>rob>kids transactions, but thats all
I moved to a new netbook recently - it took 140 *hours* to d/load and process the blockchain (yes the wifi was that bad), I heard from one of our clients that (although they only had the client running during working hours) that to their desktop it was over 9 days before it had caught up.
If all I was d/loading were the transactions since the last difficulty change (as one example of a fixed point), and the remaining balance on any not-discarded address as at that point it would have been much much quicker, and not be shagging my shiny new hard drive.
There's more but it's 4.45 in the morning, and I cant think coherently until after a few hours kip and some good coffee :)

@_date: 2013-09-09 22:01:19
@_author: Eugen Leitl 
@_subject: hardware RNG 
I would use a cheap analog circuit like and let your audio card to A/D. Bonus points: there are already entropy gathering daemons which
use soundcard input.
Even cheaper: hang a cheap microphone into a fan exhaust. Noise definitely not white,
but certainly more entropy than just looking at lowest bits of A/D.

@_date: 2013-09-10 10:23:04
@_author: Eugen Leitl 
@_subject: hardware RNG 
Many cheap embeddes have hardware RNGs -- e.g. ALIX (Geode),
which can take e.g. HiFn 7955 on a mini-PCI, plus mixing in
some entropy from e.g. an USB device is not that expensive.

@_date: 2013-09-10 18:15:37
@_author: Eugen Leitl 
@_subject: generating noisy samples at a high rate with RTLSDR 
Just remembered another cheap option for generating a lot
of noisy samples: Especially, with wideband RF noise source.

@_date: 2013-09-10 18:55:46
@_author: Eugen Leitl 
@_subject: generating noisy samples at a high rate with RTLSDR 
That's exactly what you need, if you want to get entropy
from the real world. Wide-band white noise generator circuits up to 300 MHz are very cheap and easy.
This gives you some 1.4 Msamples @ 8 bit. With a wideband
white noise source there will be several bits of entropy
in each sample, estimated.

@_date: 2013-09-11 13:21:29
@_author: Eugen Leitl 
@_subject: SPDZ, a practical protocol for Multi-Party Computation 
Breakthrough in cryptography could result in more secure computing
Tags: computer science, research, security, cryptography
Nigel Smart, Professor of Cryptology New research to be presented at the 18th European Symposium on Research in
Computer Security (ESORICS 2013) this week could result in a sea change in
how to secure computations.
The collaborative work between the University of Bristol and Aarhus
University (Denmark) will be presented by Bristol PhD student Peter Scholl
from the Department of Computer Science.
The paper, entitled 'Practical covertly secure MPC for dishonest majority -
or: Breaking the SPDZ limits', builds upon earlier joint work between Bristol
and Aarhus and fills in the missing pieces of the jigsaw from the groups
prior work that was presented at the CRYPTO conference in Santa Barbara last
The SPDZ protocol (pronounced "Speedz") is a co-development between Bristol
and Aarhus and provides the fastest protocol known to implement a theoretical
idea called "Multi-Party Computation".
The idea behind Multi-Party Computation is that it should enable two or more
people to compute any function of their choosing on their secret inputs,
without revealing their inputs to either party. One example is an election,
voters want their vote to be counted but they do not want their vote made
The protocol developed by the universities turns Multi-Party Computation from
a theoretical tool into a practical reality. Using the SPDZ protocol the team
can now compute complex functions in a secure manner, enabling possible
applications in the finance, drugs and chemical industries where computation
often needs to be performed on secret data.
Nigel Smart, Professor of Cryptology in the University of Bristol's
Department of Computer Science and leader on the project, said: "We have
demonstrated our protocol to various groups and organisations across the
world, and everyone is impressed by how fast we can actually perform secure
"Only a few years ago such a theoretical idea becoming reality was considered
Alice in Wonderland style over ambitious hope. However, we in Bristol
realised around five years ago that a number of advances in different areas
would enable the pipe dream to be achieved. It is great that we have been
able to demonstrate our foresight was correct."
The University of Bristol is now starting to consider commercialising the
protocol via a company Dyadic Security Limited, co-founded by Professor Smart
and Professor Yehuda Lindell from Bar-Ilan University in Israel.
Note: This story has been adapted from a news release issued by the
University of Bristol

@_date: 2013-09-11 13:40:10
@_author: Eugen Leitl 
@_subject: WREN: The First Satellite YOU Can Fly 
The only satellite in Earth orbit that YOU can control DIRECTLY ! You are the
pilot. Launch is this year!
Even nowadays space is not opened to the public, but we will change that -
this year !
We are four guys in a garage, and we have dedicated ourselves to open space
for everyone. For that purpose we designed the miniaturized satellite WREN.
Its a so called Pocketqub-Femtosatellite. It has only 5x5x5cm of volume and
250g of mass, and fits perfectly into your hand, like a tennis ball. Despite
of its size, it even has real thrusters.
It can be remotely positioned by you in every direction and it has a camera
onboard for taking pictures from outer space. It will be released into a
polar orbit before the end of this year on board of the UNISAT-5 deployer,
which is launched inside a DNEPR Rocket from Yasni in Russia.
It will race around the globe every 98 minutes, passing every point of the
earth during each day, seven days a week, just waiting for the command to be
remotely flown by you.
System overview
WREN System Overview
WREN is equipped with a camera, a gyro and a magnetic field sensor. Those
three components will form an adaptive feedback guidance system which helps
you to easily navigate the satellite by your own by using its momentum wheels
and microthrusters. The camera is equipped with an image processing system
which can find the position of the sun and the earth automatically. This
technology will make the control of the satellite more easy. With the camera
system you can of course remotely take pictures of the earth, the sun and
other space objects. You can navigate the satellite directly in order to make
your own picture.
The communication up- and downlink will be performed at 437,405 MHz, a
frequency in the 70cm amateur radio band which has been kindly assigned to us
by the International Amateur Radio Union (IARU). Wren will be flying in a sun
synchronous orbit at 700km of altitude at an incredible speed of 7500
m/second, so that it will take only 98 minutes to fly one time all around the
planet. Practically, a link is possible for about 10 minutes from a single
ground station, up to three times a day. The mission control software is
equipped with prediction algorithms in order to predict the flyby- time
according to your location, so you can prepare yourself for the upcoming
communication window and take control over the satellite again.
We hope that amateur radio enthusiasts will join our network and provide a
link from time to time to use WRENs lifetime as long as possible.
Send a message into deep space
You can send a message into deep space. Of course it will be also receptable
on earth. Everytime WREN sends his status to earth, it will also send out one
of the saved messages.
If WREN survives for years, your message will be sent several times into the
deep far universe.
Project Status
The rocket launch is scheduled for November this year.
Wren is currently in the final assembly process and will be integrated into
the deployer in October this year, after the shaker test.
We will be helped out with a professional ground station after launch for the
first weeks, but we want to build our own mobile groundstation to be able to
establish the link for you anytime.
We will publish the plans for the groundstation as soon as it is ready and
working, so everybody can build it!
How do we get into space so cheaply?
Bringing one kilogram of mass into orbit costs about 50000$. Rockets must
carry their fuel all the way up, so the laws of physics make them big, heavy
and expensive.
So how do we fly so relatively cheaply?
First, we are light, about 250 grams. And we fly piggyback on a bigger
satellite called "UNISAT-5".  This satellite, together with some others, are
all stored in one rocket, so the costs for the launch will be shared
according to the mass. Wren will be stored in a deployment unit called MRFOD.
Wren will be waiting inside this MRFOD in the satellite "UNISAT-5" for his
release into the open space
The rocket will go up in November and will release UNISAT-5 and other
satellites. Wren will be released into space out of Unisat about one month
Please Spread the message
We want to bring space into your living room. To achieve this we need your
help, not only by asking you for backing us with money but also by telling
the story to everybody you know who may be interested in space. We also need
amateur radio guys who would like to take part in project and follow Wren all
along its way around the planet by listening its beacon and messages you
pledged for, being heard. Our blogs and webpages, reports and videos are just
a few components of the whole message. You are the messengers, you are the
carrier of the idea of transporting space into everybody's living room - and
beyond!

@_date: 2013-09-11 15:49:33
@_author: Eugen Leitl 
@_subject: NIST reopens RNG public comment period 
Sep. 9, 2013
SP 800-90 A Rev 1 B and C
DRAFT Draft SP 800-90 Series: Random Bit Generators 800-90 A Rev. 1: Recommendation for Random Number Generation Using Deterministic Random Bit Generators 800-90 B: Recommendation for the Entropy Sources Used for Random Bit Generation 800-90 C: Recommendation for Random Bit Generator (RBG) Constructions
In light of recent reports, NIST is reopening the public comment period for Special Publication 800-90A and draft Special Publications 800-90B and 800-90C.
NIST is interested in public review and comment to ensure that the recommendations are accurate and provide the strongest cryptographic recommendations possible.
The public comments will close on November 6, 2013. Comments should be sent to RBG_Comments In addition, the Computer Security Division has released a supplemental ITL Security Bulletin titled "NIST Opens Draft Special Publication 800-90A, Recommendation for Random Number Generation Using Deterministic Random Bit Generators, For Review and Comment (Supplemental ITL Bulletin for September 2013)" to support the draft revision effort.
Draft SP 800-90 A Rev. 1 (721 KB) Draft SP 800-90 B (800 KB) Draft SP 800-90 C (1.1 MB)

@_date: 2013-09-13 11:49:24
@_author: Eugen Leitl 
@_subject: Stealthy Dopant-Level Hardware Trojans 
Stealthy Dopant-Level Hardware Trojans ?
Georg T. Becker1
, Francesco Regazzoni2
, Christof Paar1,3 , and Wayne P. Burleson1
1University of Massachusetts Amherst, USA
2TU Delft, The Netherlands and ALaRI - University of Lugano, Switzerland
3Horst ortz Institut for IT-Security, Ruhr-Universiat Bochum, Germany
Abstract. In recent years, hardware Trojans have drawn the attention of governments and
industry as well as the scientific community. One of the main concerns is
that integrated circuits, e.g., for military or critical infrastructure
applications, could be maliciously manipulated during the manufacturing
process, which often takes place abroad. However, since there have been no
reported hardware Trojans in practice yet, little is known about how such a
Trojan would look like, and how dicult it would be in practice to implement
In this paper we propose an extremely stealthy approach for implementing
hardware Trojans below the gate level, and we evaluate their impact on the
security of the target device. Instead of adding additional circuitry to the
target design, we insert our hardware Trojans by changing the dopant polarity
of existing transistors. Since the modified circuit appears legitimate on all
wiring layers (including all metal and polysilicon), our family of Trojans is
resistant to most detection techniques, including fine-grain optical
inspection and checking against "golden chips".  We demonstrate the
ectiveness of our approach by inserting Trojans into two designs | a digital
post-processing derived from Intel's cryptographically secure RNG design used
in the Ivy Bridge processors and a side-channel resistant SBox implementation
and by exploring their detectability and their ects on security.
Keywords: Hardware Trojans, malicious hardware, layout modifications, Trojan

@_date: 2013-09-18 19:08:22
@_author: Eugen Leitl 
@_subject: Zero Reserve - A distributed Bitcoin exchange 
Zero Reserve - A distributed Bitcoin exchange
tl;dr: Proposal and prototype for a distributed exchange not requiring a banking gateway. Implemented as a plugin for Retroshare. Licensed under the LGPL.
The Achilles heel of Bitcoin is the exchanges. Centralized as they are, they can be shut down by a number of means, by a number of players. Should that happen, price discovery of Bitcoin will not work any more. To address that, we offer a distributed exchange without the need of the banking system. Some intro and marketing blurb is here:
A tech paper is here:
And the code is here:
In short, ZR uses the Ripple idea of Ryan Fugger to get money in and out of the exchange. ZR has nothing to do whatsoever with ripple.com, however. As such, there is no need for XRP. There is no pre-mining, no company, just code.
Now the caveat: This is prototype software. Anything may or may not work. Security is only what the underlying Retroshare provides. The distributed order book works, but is still insecure. Currencies are therefore only defunct or fantasy currencies such as German Papermark(1923). Nothing you do has any effect on the blockchain.
The next steps are:
- hook up to the blockchain (using Amir Taakis excellent libbitcoin)
- providing basic wallet functionality
- provide authentication for anything beyond F2F.
I see no reason why it wouldnt work on OSX, but ZR was never built on it. It does build and run on Linux and Windows, though.
Once you are on Retroshare and have some friends, you should be able to use this link to get and subscribe to the Zero Reserve Forum:
One of my RS identities:
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: OpenPGP:SDK v0.9
-----END PGP PUBLIC KEY BLOCK-----

@_date: 2013-09-24 15:18:55
@_author: Eugen Leitl 
@_subject: How a Crypto =?utf-8?B?4oCYQmFja2Rvb3I=?= =?utf-8?B?4oCZ?= Pitted 
zs-p2p forkit! ,
 ExI chat list , doctrinezero
How a Crypto Backdoor Pitted the Tech World Against the NSA
BY KIM ZETTER09.24.136:30 AM
Illustration: alengo/Getty Images
In August 2007, a young programmer in Microsofts Windows security group
stood up to give a five-minute turbo talk at the annual Crypto conference in
Santa Barbara.  It was a Tuesday evening, part of the conferences
traditional rump session, when a hodge-podge of short talks are presented
outside of the conferences main lineup. To draw attendees away from the wine
and beer that competed for their attention at that hour, presenters sometimes
tried to sex up their talks with provocative titles like Does Bob Go to
Prison? or How to Steal Cars  A Practical Attack on KeeLoq or The Only
Rump Session Talk With Pamela Anderson.
Dan Shumow and his Microsoft colleague Niels Ferguson titled theirs,
provocatively, On the Possibility of a Back Door in the NIST SP800-90 Dual
Ec Prng. It was a title only a crypto geek would love or get.
The talk was only nine slides long (.pdf). But those nine slides were
potentially dynamite. They laid out a case showing that a new encryption
standard, given a stamp of approval by the U.S. government, possessed a
glaring weakness that made an algorithm in it susceptible to cracking. But
the weakness they described wasnt just an average vulnerability, it had the
kind of properties one would want if one were intentionally inserting a
backdoor to make the algorithm susceptible to cracking by design.
For such a dramatic presentation  by mathematicians standards  the
reaction to it was surprisingly muted. I think folks thought, Well thats
interesting, and, Wow, it looks like maybe there was a flaw in the
design, says a senior Microsoft manager who was at the talk. But there
wasnt a huge reaction.
Six years later, thats all changed.
Early this month the New York Times drew a connection between their talk and
memos leaked by Edward Snowden, classified Top Secret, that apparently
confirms that the weakness in the standard and so-called Dual_EC_DRBG
algorithm was indeed a backdoor. The Times story implies that the backdoor
was intentionally put there by the NSA as part of a $250-million, decade-long
covert operation by the agency to weaken and undermine the integrity of a
number of encryption systems used by millions of people around the world.
The Times story has kindled a firestorm over the integrity of the byzantine
process that produces security standards. The National Institute of Standards
and Technology, which approved Dual_EC_DRBG and the standard, is now facing a
crisis of confidence, having been forced to re-open the standard for public
discussion, while security and crypto firms scramble to unravel how deeply
the suspect algorithm infiltrated their code, if at all. On Thursday,
corporate giant RSA Security publicly renounced Dual_EC_DRBG, while also
conceding that its commercial suite of cryptographic libraries had been using
the bad algorithm as its default algorithm for years.
But beneath the flames, a surprising uncertainty is still smoldering over
whether Dual_EC_DRBG really is backdoored. The Times, crypto experts note,
hasnt released the memos that purport to prove the existence of a backdoor,
and the papers direct quotes from the classified documents dont mention any
backdoor in the algorithm or efforts by the NSA to weaken it or the standard.
They only discuss efforts to push the standard through committees for
Jon Callas, the CTO of Silent Circle, whose company offers encrypted phone
communication, delivered a different rump session talk at the Crypto
conference in 2007 and saw the presentation by Shumow. He says he wasnt
alarmed by it at the time and still has doubts that what was exposed was
actually a backdoor, in part because the algorithm is so badly done.
If [NSA] spent $250 million weakening the standard and this is the best that
they could do, then we have nothing to fear from them, he says. Because
this was really ham-fisted. When you put on your conspiratorial hat about
what the NSA would be doing, you would expect something more devious,
Machiavellian  and this thing is just laughably bad. This is Boris and
Natasha sort of stuff.
Indeed, the Microsoft presenters themselves  who declined to comment for
this article  didnt press the backdoor theory in their talk. They didnt
mention NSA at all, and went out of their way to avoid accusing NIST of
anything. WE ARE NOT SAYING: NIST intentionally put a back door in this
PRNG, read the last slide of their deck.
The Microsoft manager who spoke with WIRED on condition of anonymity thinks
the provocative title of the 2007 presentation overstates the issue with the
algorithm and is being misinterpreted  that perhaps reporters at the Times
read something in a classified document showing that the NSA worked on the
algorithm and pushed it through the standards process, and quickly took it as
proof that the title of the 2007 talk had been right to call the weakness in
the standard and algorithm a backdoor.
But Paul Kocher, president and chief scientist of Cryptography Research, says
that regardless of the lack of evidence in the Times story, he discounts the
bad cryptography explanation for the weakness, in favor of the backdoor
Bad cryptography happens through laziness and ignorance, he says. But in
this case, a great deal of effort went into creating this and choosing a
structure that happens to be amenable to attack.
Whats mathematically creative [with this algorithm] is that when you look
at it, you cant even prove whether there is a backdoor or not, which is very
bizarre in cryptography, he says. Usually the presence of a backdoor is
something you can prove is there, because you can see it and exploit it. In
my entire career in cryptography, Ive never seen a vulnerability like this.
National Security Agency headquarters, Fort Meade, Maryland. Photo: Wikipedia
Its not the first time the NSA has been accused of installing backdoors.
Crypto trapdoors, real and imagined, have been part of NSA lore for decades.
In some ways the current controversy echoes the long-ago debate over the
first U.S. Data Encryption Standard in the 1970s. The NSA was widely
suspected of weakening DES to make it more crackable by the agency by
tinkering with a table of numeric constants called an S-Box and shortening
the algorithms key length. In 1994, though, the NSA was exonerated when it
turned out that the agency had actually changed the S-Box numbers to harden
DES against a code-breaking technique that had been known only within NSA at
the time.
In 1995, another case came up that seemed to confirm suspicions about the
NSA. The Baltimore Sun reported that year that the NSA had inserted a
backdoor into cryptographic machines made by the respected Swiss company
Crypto AG, apparently substantiating longstanding rumors to that effect.
Then in 1999, Microsoft inadvertently kicked off another controversy when it
leaked its internal name for a cryptographic signing key built into Windows
NT. The key was called _NSAKEY, spawning speculation that Microsoft had
secretly given the agency the power to write and sign its own updates to
Windows NTs crypto engine. Microsoft said this was incorrect, that the key
was an internal Microsoft key only and that it was called _NSAKEY because
the NSA was the technical reviewing authority for U.S. export controls. The
key was part of Microsofts compliance with U.S. export laws.
Suspicions about the NSA and backdoors were lingering in 2006 when Shumow and
Ferguson began looking at Dual_EC_DRBG after NIST approved it for inclusion
in a standard (.pdf). The standard discussed four federally sanctioned random
number generators approved for use in encrypting government classified and
unclassified-but-sensitive communication.
Each of the four algorithms was based on a different cryptographic design
family. One was based on hash functions, one on so-called HMAC (hash-based
message authentication code), one on block ciphers and the fourth one was
based on elliptic curves. The NSA had been pushing elliptic curve
cryptography for a number of years, and it publicly championed the last one 
Dual_EC_DRBG  to be included in the standard.
Elliptic curve algorithms are based on slightly different mathematics than
the more common RSA algorithm, and the NSA believes theyre the future of
cryptography, asserting that elliptic curve algorithms are smaller, faster
and offer better security.
But as Shumow and Ferguson examined the properties of the elliptic curve
random number generator in the standard, to determine how to incorporate it
into the Windows operating system, a couple of strange things stood out.
First, the random number generator was very slow  two to three orders of
magnitude slower than another algorithm in the standard.
Second, it didnt seem to be very secure.
There was a property [in it] that seemed to make the prediction-resistance
of the algorithm not what you would necessarily want it to be, the Microsoft
manager says. In non-geek speak, there was a weakness that made the random
number generator not so random.
Good random number generation is at the core of encryption, and a weak RNG
can undo the entire encryption system. Random number generators play a role
in creating cryptographic keys, in opening secure communications between
users and web sites and in resetting passwords for email accounts. Without
assured randomness, an attacker can predict what the system will generate and
undermine the algorithm.
Shumow and Ferguson found that the obstacles to predicting what the random
number generator would generate was low. It wasnt a catastrophic problem,
but it seemed strange for a security system being promulgated by the
Then they noticed something else.
The standard for implementing the algorithm included a list of constants 
static numbers  that were used in the elliptic curve on which the random
number generator was based. Whoever generated the constants, which served as
a kind of public key for the algorithm, could have generated a second set of
numbers at the same time  a private key.
Anyone possessing that second set of numbers would have whats known in the
cryptography community as trapdoor information  that is, they would be
able to essentially unlock the encryption algorithm by predicting what the
random number generator generated. And, Shumow and Ferguson realized, they
could predict this after seeing as few as 32 bytes of output from the
generator. With a very small sample, they could crack the entire encryption
system used to secure the output.
Even if no one knows the secret numbers, the fact that the backdoor is
present makes Dual_EC_DRBG very fragile, cryptographer Bruce Schneier wrote
at the time, in a piece for WIRED. If someone were to solve just one
instance of the algorithms elliptic-curve problem, he would effectively have
the keys to the kingdom. He could then use it for whatever nefarious purpose
he wanted. Or he could publish his result, and render every implementation of
the random-number generator completely insecure.
No one knew who had produced the constants, but it was assumed that because
the NSA had pushed the algorithm into the standard, the agency had generated
the numbers. The spy agency might also, then, have generated a secret key.
Schneier called it scary stuff indeed, but he also said at the time that it
made no sense as a backdoor, since it was so obvious to anyone who looked at
the algorithm and standard that there was this flaw in it. As a result,
developers of web sites and software applications wouldnt use it to help
secure their products and systems, he said.
But in fact, many developers did use it.
The U.S. government has enormous purchasing power, and vendors soon were
forced to implement the suspect standard as a condition of selling their
products to federal agencies under so-called FIPS certification requirements.
Microsoft added support for the standard, including the elliptic curve
random-number generator, in a Vista update in February 2008, though it did
not make the problematic generator the default algorithm.
Asked why Microsoft supported the algorithm when two of its own employees had
shown it to be weakened, a second Microsoft senior manager who spoke with
WIRED said that while the weakness in the algorithm and standard was weird
it wasnt a smoking gun. It was more of an odd property.
Microsoft decided to include the algorithm in its operating system because a
major customer was asking for it, because it had been sanctioned by NIST, and
because it wasnt going to be enabled as the default algorithm in the system,
thus having no impact on other customers.
In fact it is nearly impossible for any user to implement or to get this
particular random number generator instantiating on their machines without
going into the guts of the machine and reconfiguring it, he says.
Other major companies, like Cisco and RSA, added it as well. NIST in fact
provides a lengthy list of companies that have included it in their
libraries, though the list doesnt say which companies made it the default
algorithm in their library or which products have been developed that invoke
the algorithm.
A Cisco spokesman told WIRED that the algorithm was implemented in its
standard crypto library around mid-2012, a library that is used in more than
120 product lines, but the algorithm is not the default, and the default
algorithm cannot be changed by users. The company is currently completing an
internal audit of all of its products that leverage the NIST standard.
RSA, however, made the algorithm the default in its BShare toolkit for Java
and C developers until this week when it told WIRED that it was changing the
default following the renewed controversy over it. The company sent an
advisory to developer customers strongly urging them to change the default
to one of a number of other random number generator algorithms RSA supports.
RSA also changed the default on its own end in BSafe and in an RSA key
management system. The company is currently doing an internal review of all
of its products to see where the algorithm gets invoked in order to change
RSA actually added the algorithm to its libraries in 2004 or 2005, before
NIST approved it for the standard in 2006 and before the government made it a
requirement for FIPS certification, says Sam Curry, the companys chief
technology officer. The company then made it the default algorithm in BSafe
and in its key management system after the algorithm was added to the
standard. Curry said that elliptic curve algorithms were all the rage at the
time and RSA chose it as the default because it provided certain advantages
over the other random number generators, including what he says was better
Cryptography is a changing field. Some algorithms go up and some come down
and we make the best decisions we can in any point in time, he says.A lot
of the hash-based algorithms were getting struck down by some weaknesses in
how they chose numbers and in fact what kind of sample set they chose for
initial seeding. From our perspective it looked like elliptic curve would be
immune to those things.
Curry says the fact that the algorithm is slower actually provides it with
better security in at least one respect.
The length of time that you have to gather samples will determine the
strength of your random number generation. So the fact that its slower
sometimes gives it a wider sample set to do initial seeding, he says.
Precisely because it takes a little longer, it actually winds up giving you
more randomness in your initial seeding, and that can be an advantage.
Despite the renewed controversy over the algorithm and standard, Microsoft
managers say they still dont think the weaknesses constitute an intentional
Callas agrees. He thinks it is simply bad cryptography that was included in
the standard to round-out the selection so that there would be at least one
elliptic curve algorithm in the standard.
But one advantage to having the algorithm supported in products like Vista 
and which may be the reason the NSA pushed it into the standard  is that
even if its not the default algorithm for encryption on a system, as long as
its an option on the system, an intruder, like the NSA, can get into the
system and change the registry to make it the default algorithm used for
encryption, thereby theoretically making it easy for the NSA to undermine the
encryption and spy on users of the machine.
Schneier says this is a much more efficient and stealth way of undermining
the encryption than simply installing a keystroke logger or other Trojan
malware that could be detected.
A Trojan is really, really big. You cant say that was a mistake. Its a
massive piece of code collecting keystrokes, he said. But changing a
bit-one to a bit-two [in the registry to change the default random number
generator on the machine] is probably going to be undetected. It is a low
conspiracy, highly deniable way of getting a backdoor. So theres a benefit
to getting it into the library and into the product.
To date, the only confirmation that the algorithm has a backdoor comes in the
Times story, based on NSA documents leaked by Edward Snowden, which the Times
and two other media outlets saw.
[I]nternal memos leaked by a former NSA contractor, Edward Snowden, suggest
that the NSA generated one of the random number generators used in a 2006
NIST standard  called the Dual EC DRBG standard  which contains a back door
for the NSA, the Times wrote.
An editorial published by the Times this weekend re-asserted the claim:
Unbeknown to the many users of the system, a different government arm, the
National Security Agency, secretly inserted a back door into the system
that allowed federal spies to crack open any data that was encoded using its
But all of the quotes that the Times published from the memos refer to the
NSA getting the standard passed by an international standards body; they do
not say the NSA intentionally weakened the algorithm and standard, though the
Times implies that this is what the memos mean by tying them to the 2007
presentation by Shumow and Ferguson.
NIST has denied any knowledge of a backdoor and has also denied that the NSA
authored its standard. The institute has, however, re-opened the standard for
public comment as a result of the controversy and strongly urged against
using the algorithm in question until the matter could be resolved. The
public comments period will close Nov. 6.
Even without more explicit confirmation that the weaknesses in the algorithm
and standard constitute a backdoor, Kocher and Schneier believe they do.
It is extraordinarily bad cryptography, says Kocher. If you look at the
NSAs role in creating standards [over the years] and its general
cryptographic sophistication, none of it makes sense if there isnt a
backdoor in this.
Schneier agrees and says the NSA has done too many other things for him to
think, when he sees government-mandated crypto thats weak, that its just by
If we were living in a kinder world, that would be a plausible explanation,
he says. But were living in a very malicious world, it turns out.
He adds that the uncertainty around the algorithm and standard is the worst
part of the whole matter.
This is the worst problem that the NSA has done, Schneier says. They have
so undermined the fundamental trust in the internet, that we dont know what
to trust. We have to suspect everything. Were never sure. Thats the
greatest damage.

@_date: 2013-09-24 16:52:50
@_author: Eugen Leitl 
@_subject: Dissentr: A High-Latency Overlay Mix Network 
Note: This project was created as part of a 36-hour hackathon - and primarily as a proof of concept. While the ideas may be sound, and the prototype may work as designed, the protocols involved in this specific project have not been peer-reviewed, and so I cannot recommend that the network be used for anything requiring serious privacy.
A High-Latency Overlay Mix Network
Essentially, Dissentr is a security-minded network, inspired by Tor, with a few important characteristics which serve to differentiate it.
Tor is a low-latency network. This makes it ideal for real time activities like web browsing, but as a result, opens it up to attacks involving large-scale traffic analysis methods known as end-to-end correlation. In these attacks, an adversary with the ability to analyze massive amounts of traffic in a short period of time is able to match up traffic entering the network with the corresponding traffic which will inevitably soon exit it.
Dissentr manages to protect against these sorts of attacks by being engineered as a high-latency network. Assuming any given node has not been compromised, that node will intentionally hold off on forwarding its traffic to the next node in the network until it is able to forward a large amount of data in bulk, rendering the aforementioned end-to-end correlation far less feasible. For an excellent discussion on this attack, and possible countermeasures, see Practical Traffic Analysis: Extending and Resisting Statistical Disclosure.
Much like any mix network, Dissentr models its network as a graph of nodes, each responsible for handling the relay of traffic as it moves along some path through the network. Where Dissentr differs from a network such as Tor is in how this path is constructed. In Dissentr, the network is constructed out of cascades (A term I first heard described by Ian Goldberg, but I've been unable to pin down an original source for): essentially directed, acyclic sub-graphs, in which a node defines a set of "trusted" nodes, through which they are willing to relay traffic through. Dissentr simplifies this model by only allowing for nodes of out-degree 1, at this time. This construction brings about a number of useful results:
In the event that a node is known to be compromised, individual nodes are allowed the ability to either remove themselves from a cascade, or bypass untrusted nodes entirely, without the necessity of a trusted third-party.
The network is protected from "supernode invasions," in which an attacker floods the network with compromised nodes, in the hopes of either endangering the network's health, or placing the security of users passing through their nodes at risk of traffic interception, and subsequent analysis. This can be guaranteed because cascades are constructed by virtue of a measure of trust between node-operators, and so long as there exists some non-zero subset of trusted operators, they retain the ability to form a cascade of their own, effectively shutting out the efforts of such an attacker.
As mentioned previously, the high-latency nature of the network causes a shift in the sorts of activities best facilitated by its use, however, there do exist some unique opportunities which I have neither seen implemented in the context of a mix network, nor discussed in the literature.
A personal favourite idea revolves around creating a platform for political blogging, which, assuming a noisy enough network, would offer political dissidents the ability to freely write about issues of corruption or government abuse, without many of the risks associated with using a lower-latency network like Tor. If it takes a week for a blog post to appear in circulation after the author posts it to the network, it becomes magnitudes more difficult for any assailant to trace the authorship of that blog post - especially if that author never visited the website which hosts their content in the first place!
It also becomes a fairly trivial exercise to adapt the network to act as a mixing service for digital currency such as Bitcoin. Furthermore, by breaking the network into a number of smaller, disjoint networks for that purpose, one is be able to counter many of the current attacks which target existing mixing services.
I again emphasize that the cryptosystem in place is the result of a rather rushed 48-hour hackathon - in a production system, I would recommend implementing a peer-reviewed cryptosystem, such as the very lightweight Sphinx, or, pending their coming proof of security, the recently proposed Ibis. That being said, Dissentr works as follows:
Every node in the network maintains an RSA-keypair, with the public key being exposed to every node in a given cascade.
When a client wishes to send a message M through the network, they choose some cascade C.
For each node in the cascade, beginning with the exit node, and continuing through to the entrance node, the client generates an AES CFB128 key, which it uses to encrypt M. The key is then encrypted using that node's public RSA key.
M, now encrypted with AES CFB128 for every node in the cascade, is then passed to the entrance node along with the encrypted AES keys. The entrance node then uses its private RSA key to decrypt the AES key, so that it can subsequently decrypt M, yielding yet another cipher text.
This process is repeated for every node in the cascade, until the final node decrypts M to a plaintext, which it then handles accordingly.
Building and Running it
If, after all of my warnings, you still want to see it in action, it's dead-easy to get setup. All you'll need is Erlang installed (Tested on R16B02), along with Elixir. From there, you'll want to invoke the following from within Dissentr's directory, on every machine you want to host a node:
iex --sname {Any name, different per machine} --cookie {Any string, common between all machines} -S mix
This will stick you into a REPL, loaded with Dissentr's namespaces and dependencies. Sorry, there's no interface yet. From there, if you're using more than one machine, you'll want to link them all together, by running the following on every machine you want to host a node on. Since Erlang node connections are transitive, you won't have to do this for every pair of nodes.:
The hostname in question can be found in the iex prompt. Most likely it will be something
Now, just spawn a few nodes to create a network. I've got some temporary methods in place for making this easy, using some hardcoded keys stored in example_data/ for testing. Ideally, each node will be hosted on a different machine, but for testing purposes it doesn't matter. Within your prompt, execute the following:
Dissentr.Cascade.add_node(:node1, nil, 1)
Dissentr.Cascade.add_node(:node2, :node1, 2)
Dissentr.Cascade.add_node(:node3, :node2, 3)
Dissentr.Cascade.add_node(:node4, :node3, 4)
Dissentr.Cascade.add_node(:node5, :node4, 5)
Finally, to send an encrypted message, run the following, substituting the node and message as desired:
Dissentr.Cascade.mix(:node3, "Something, something, NSA")
If all went well, you should see a debug statement print out the plaintext message, on the machine which is hosting :node1

@_date: 2013-09-25 09:56:29
@_author: Eugen Leitl 
@_subject: DARK WALLET: A RADICAL WAY TO BITCOIN 
"radical", huh.
DARK WALLET: A RADICAL WAY TO BITCOIN
POSTED BY MICHAEL DEL CASTILLO
Cody Wilson is a twenty-five-year-old former law student at the University of
Texas at Austin. He is also the inventor of the Liberator, a gun made almost
entirely from plastic pieces created with a 3-D printer; he also uploaded to
the Internet a blueprint that anyone could use to print such a gun.
Wilson, who espouses libertarian views, created the blueprint to make a
point: information should be free. Not everyone agreed with him. In May,
after Wilson successfully fired the gun at a range near Austin and posted the
design online, the State Department requested that those files be removed
from the Web site of his nonprofit, Defense Distributed.
Wilson compliedbut not before the files had been downloaded two hundred
thousand times, igniting a debate about whether there should be limits to the
free flow of information over the Internet, and over the role of the
government in enforcing those restrictions.
Wilson lives in a utopian world in which contraband will be only a notional
concept, because enforcement will require policing ideas and blueprints, not
simply goods, Jacob Silverman wrote in a piece about Wilson and the
Liberator in May.
A native of Cabot, Arkansasa small suburb of Little RockWilson said that
the State Departments action persuaded him to drop out of law school and
pursue revolutionary activities full-time. In fact, he had been planning his
next endeavor for a while. When Indiegogo, a crowdfunding site, booted
Defense Distributeds campaign in August, 2012, for violating its terms of
serviceIndiegogo said the project related to the sale of firearms; Wilson
said it was for the creation of informationWilson began to raise money by
asking people to support him using a currency called Bitcoin: encrypted,
difficult-to-trace bits of code that function like cash and can be exchanged
over the Internet without a bank or a PayPal account.
Wilson said that he eventually raised two hundred bitcoins for the
Liberatorthe equivalent of twenty-seven thousand dollars, according to the
current exchange rate. His efforts attracted the attention of a
twenty-five-year-old Brit named Amir Taaki, who e-mailed him with an
invitation to speak at the Bitcoin 2012 Conference, in London. He accepted.
Wilson and Taaki met in person for the first time in January of 2013, when
Taaki took Wilson to visit a workspace for hackers is Bratislava, Slovakia,
and to anarchist squats in London. They reconnected in Berlin that July and
began hashing out a plan to use the as of yet unregulated, untaxed, nearly
untraceable currency in a way that would, like the Liberator, undermine the
ability of governments to regulate the activities of their citizens.
In the Bitcoin world, where banks no longer serve as intermediaries between
people and their money, bank accounts have been replaced by online wallets
that people can use to virtually store and send bitcoins.
Wilson and Taakis project, tentatively known as Dark Wallet, is a simple
wallet designed to be easier to use for people who arent tech-savvy; they
hope that in turn accelerates the currencys rate of adoption around the
world. The wallet will be open-source and free to use. Eventually, Wilson and
Taaki hope to create a vast stable of Bitcoin-related tools.
The goal, for Wilson, is similar to what he tried to do with the Liberator:
use technology to remove government intervention from his life, and from the
lives of like-minded people.
Unlike many current Bitcoin wallets, which can be difficult to download and
cumbersome to use, Wilson and Taaki are designing Dark Wallet, they told me,
as an easy-to-install plug-in that sits discreetly on users Chrome or
Firefox browsers. Made for Windows, Mac, and Linux computers, Dark Wallet
would move most of the energy-sucking process of insuring theres only one of
each bitcoin in circulation, and that they arent spent in two places at the
same time, to separate servers.
Wilson still lives in Austin, working remotely on Dark Wallet with Taaki, who
lives in an anarchist compound called Calafou, outside of Barcelona, and
writes most of the code behind the wallet. Taaki and Vitalik Buterin, the
co-founder of Bitcoin Magazine, a periodical covering the currency, are part
of a Calafou-based organization called unSystem, which came up with the idea
for the wallet; theyre working with a team of developers from around the
world. Wilson, who will manage the development team behind Dark Wallet,
making sure they meet their targets on time, is also producing a video and
other material for a crowdfunding campaign to raise money for the project.
Dark Wallet should be ready sometime in January or February of 2014, Taaki
said, though hes not committing to anything. Itll launch when its ready,
he said. And the details of an upcoming crowdfunding campaign have still yet
to be solidified, though Taaki and Wilson expect it to launch sometime in
The person or group that, in 2008, created Bitcointhat is, released the
protocol that defined what Bitcoin would becalled itself Satoshi Nakamoto.
The online comments that Satoshi Nakamoto made before disappearing
completely, in 2012, indicate that the creator of Bitcoin, like Wilson, was
deeply mistrustful of economic institutions and designed the currency to be
intentionally subversive.
Bitcoin is created, or mined, as its called, by powerful computers that
race to solve complex math problems and are rewarded for their work with the
encrypted code that is a bitcoin. Today there are 11.7 million of the coins
in existence, worth an estimated $1.6 billion, though their value fluctuates
dramatically. Nakamoto set the number of coins entering circulation to halve
every four years until 2140, when they will plateau at twenty-one million
coins and never be produced again.
Because no one can arbitrarily decide to print more bitcoins, and because no
banks intermediate the storage and spending of the currency, the value of a
bitcoin is determined by market demand. Wilson finds this very attractive.
But where a currency exists, capitalism will inevitably find it. In recent
months, Bitcoin has caught the attention of entrepreneurs, many funded by
venture-capital firms, who have begun building Bitcoin-related start-ups. The
companies include exchanges where people can trade bitcoins, along with
services that let people store and spend the currency in places ranging from
Amazon-style online markets to brick-and-mortar bars and restaurants.
The mainstream entrepreneurs who are interested in Bitcoin have found a haven
in a nonprofit called the Bitcoin Foundation. Writing about Bitcoin in April,
Maria Bustillos described its executives as a rational and sober group of
adult administrators who stand in contrast with the image of Bitcoin users
as wild-eyed kids camping out in half-deserted lofts. Members of the
foundation met in August with several federal agencies, including the Federal
Reserve, the F.B.I., and the Secret Service. On the surface, the meeting was
an educational exercise, meant to explain how Bitcoin works, but many
observers assume it was a step toward regulating the currency.
The foundation, which celebrates its first anniversary this month, calls
itself an advocacy group dedicated to serving the business, technology,
government relations, and public affairs needs of the Bitcoin community. One
goal, according to Jon Matonis, its executive director of the Bitcoin
Foundation, is to educate both public and private interestsincluding the
governmentabout how the currency operates. (The Foundation is not
pro-regulation as some have claimed, but it is pro-education, Matonis has
written, adding that he supports bitcoin education for legislative and
regulatory entities and that lobbying on behalf of Bitcoin is not
necessarily anti-market.)
Wilson, not surprisingly, sees working with the government as a betrayal of
Bitcoins fundamental purpose. The public faces of Bitcoin are acting as
counter-revolutionaries, he told me. Theyre actively working to try to
diffuse it, and to pollute it. He was referring, he said, not only to the
Bitcoin Foundation but to venture capitalists and entrepreneurs in New York
and Silicon Valley who increasingly embrace the currency as a way to profit,
but dont share his revolutionary aims. (Matonis said he is aware of Wilsons
concerns. I dont see my role as advancing crony capitalism, he said.)
Wilson believes Bitcoin should remain the backbone of a separate economy that
undermines the governments ability to collect taxes and to control the value
of currencynot be subsumed into the mainstream economy.
The state is basically allowed because we have all chosen to use these
certain institutions to channel our activity and commerce, he told me. But
when we are enabled, through alternative means and technologies, to channel
our commerce as we will, channel our production as we will, the state simply
Not everyone agrees, of course, that society would benefit from the
disappearance of governments. Wilson used the Liberator to make the point
that the government shouldnt regulate the flow of information; he wants to
use Bitcoin to help build an economy outside of the governments reach.
But his ideology, taken to its logical conclusion, would also leave services
like roads, libraries, fire fighting, and policing in the hands of the
private sectorwhose interests may not be aligned, Wilsons critics argue,
with those of the public at large.
Wilson knows that he could see blowback for his stance against the
foundation: as a self-described crypto-anarchist, perhaps he shouldnt be
so concerned with who is or isnt determining the currencys future. And if
the U.S. government attempts to regulate the currency, which seems likely,
Wilson will also find himself once again in direct opposition to the
Wilson and the suit-and-tie-wearing people at the Bitcoin Foundation share a
common interest in bringing Bitcoin to as many people as possible. The
foundation seems willing to play nicely with the establishment, and has been
open to hearing about the interests of old-school players like venture
capitalists and government regulators. Wilson, however, who was only recently
firing an illicit gun into the desert, isnt looking only for a new currency
but for another way to liberate himselfand othersfrom government oversight.
Michael del Castillo is the technology and innovation reporter at Upstart
Business Journal, a member of American City Business Journals, which is a
sister publication to Cond Nast. A graduate of Columbia University, he is
also the cofounder of Literary Manhattan, a nonprofit dedicated to promoting
Manhattans literary community and creating new ways to appreciate
Illustration by Grafilu.

@_date: 2013-09-25 14:18:08
@_author: Eugen Leitl 
@_subject: [Cryptography] Hardware Trojan Protection 
On 9/22/13 at 6:07 PM, leichter (Jerry Leichter) wrote in
another thread:
You might get a reasonable level of protection implementing the core
of the crypto operations in a hardware security module (HSM) using
Field Programmable Gate Arrays (FPGA) or Complex Programmable Logic
Device (CPLD). There is an open source set of tools for programming
these beasts based on Python called MyHDL . The EFF DES
cracker may have some useful ideas too.
The largest of these devices are also pressing the current chip
limits. There isn't a lot of extra space for Trojans. In addition,
knowing what to look at is somewhat difficult if pin assignments etc
are changed from chip to chip at random.
As with any system, there are tool chain issues. Open source helps,
but there is always the Key Thompson attack. The best solution I can
think of is to audit the output. Look very carefully at the output of
the tool chain, and at the final piece that loads the configuration
data into the device.
Cheers - Bill

@_date: 2013-09-25 22:21:00
@_author: Eugen Leitl 
@_subject: The Compromised Internet 
About your only choices are hams or (slightly higher budget)
microsats with onboard flash and DTN (notice you can deliver
packets during flyby). Hams also do launch microsats,
so there's some overlap. I've been waiting for consumer
phased arrays, just saw Locata VRay today -- perhaps not
for much longer now. Prime your phased array with s00per-s3kr1t
sat ephemerides, and you're good to go. Really hard to
jam, too -- optical ones impossible to jam, even.
For very high latency you could just use a global sneakernet.
 has some numbers. You could probably
already run stock Usenet over uucp over that.

@_date: 2013-09-25 22:45:25
@_author: Eugen Leitl 
@_subject: The Compromised Internet 
It's not mathematics, it's braindead algorithms. Geographic routing
needs no admin chatter. You only need to handle the edge cases.
Notice that 40 GBit/s fiber WAN is low end, while your LoS WLAN will
have trouble transporting even 10 MBit/s in adverse weather.

@_date: 2013-09-26 08:19:00
@_author: Eugen Leitl 
@_subject: [cryptography] The Compromised Internet 
Here's a potentially disruptive technology for global communication
that bypasses the fiber infrastructure, and hence more difficult
to tap and almost impossible to disrupt by other means than
total orbit denial weapons.
NASA prepares to launch 600Mbps space laser system to replace conventional radio links
By Sebastian Anthony on August 29, 2013 at 10:05 am19 Comments
NASA is preparing to launch the Lunar Laser Communications Demonstration (LLCD), a testbed that will use lasers to send and receive data between Earth and the Moon. This will be the first time that NASA uses lasers instead of conventional S-band radio waves to communicate with spacecraft, allowing for massive data rates of up to 600 megabits per second, while also consuming much less power and requiring much smaller antennae. Ultimately, shifting to laser-based communications will allow NASA to receive much more data from spacecraft, allowing them to be outfitted with high-res cameras and other modern sensors that generate more data than S-band links can support.
Optical communications, as opposed to radio frequency (RF) communications (or simply radio), are desirable for three key reasons: Massive bandwidth, higher security, and lower output power requirements. All of these traits derive from the frequency of optical and radio waves. While S-band signals are in the 2-4GHz range (similar to your GSM, LTE, or WiFi link), the laser light used by the LLCD (near-infrared in this case) is measured in hundreds of terahertz. As a result, the wavelength of S-band signals is around 10cm, while near-infrared has a wavelength of just 1000nm  or about 100,000 times shorter. Not only can you cram a lot more data into into the same physical space, but theres also terahertz (compared to megahertz in the S band) of free, unlicensed space that can be used.
A diagram of the LLCD architecture
Because the wavelength is smaller, the sending and receiving antennae can also be a lot smaller, allowing for smaller/lighter spacecraft and much easier reception here on Earth. By the time a conventional RF signal arrives at Earth from outer space, the beam can cover an area as wide as 100 miles, requiring very large dish antennae (such as the Deep Space Network) to pick those signals up. Receiving laser signals, which are 100,000 times shorter, requires a much smaller dish. As a corollary, due to these beams being much tighter, theyre much harder for an enemy to snoop on, thus increasing security. Transmitting data via laser also requires less power than RF.
NASA's LLCD laser link diagram
The LLCD will be deployed upon the Lunar Atmosphere Dust Environment Explorer (LADEE), which is scheduled for launch in September. LADEE (which could be pronounced lay-dee or lad-ee, were not sure) will orbit the Moon, seeking to confirm whether the mysterious glow observed by Apollo astronauts was caused by dust in the lunar atmosphere. Thanks to the LLCD, NASA will have a 20Mbps uplink to LADEE (apparently 4,800 times faster than existing S-band uplinks), and LADEE will have a 600Mbps downlink to NASA (five times faster than current state-of-the-art lunar-distance links). The mission will only last for 30 days, after which, if its a success, NASA will launch the long-duration Lunar Communications Relay Demonstration (LCRD), which will hitch a ride aboard a commercial Loral satellite. The LCRD will allow NASA to perform further testing of space laser communications, with the hope of eventually replacing RF links in future spacecraft.
Moving forward, space laser communications will allow for the creation of spacecraft that are smaller, cheaper, and capable of more advanced functionality. With 600Mbps of downlink capacity, well be able to outfit spacecraft with high-resolution cameras and other advanced sensors that generate vast amounts of data  and view that data in real time, rather than waiting for the data to slowly dribble over the airwaves.

@_date: 2013-09-26 08:51:21
@_author: Eugen Leitl 
@_subject: Fwd: [cryptography] The Compromised Internet 
This was an off-list exchange actually, but what the hell.
LEO is a volume, not a surface. You can have as many flocks up
there as you like, if you can afford it.
I'm optimizing against people who walk up, and dismantle your
wireless mesh, or down the Internet in your country. It's really
hard to jam the sky, especially in VIS range.
Yes, you can fry them with ground laser or fill up orbit
with tungsten pellets. However, such things are quite frowned
upon, especially the latter option.
Surprise me.

@_date: 2013-09-26 16:17:09
@_author: Eugen Leitl 
@_subject: Fwd: [cryptography] The Compromised Internet 
If the VPN bridges go down, you're back to mice and pumpkins.
There are obvious values in urban-area public meshes, and long
distance WLAN, but it's no way to deliver messages globally,
even as simple as texting equivalent. The buck does definitely
stop when surf is lapping at your toes.
What is exactly is wrong with frequent fliers carrying
smartphones with or similar?
You need to track a given small, rapidly moving patch of sky in realtime, whether by parabol dish, amateur astronomic instrument, or phased array flat plate or half-dome. The bird is serving hundreds or thousands people ground-side as it passes by. If you really want to jam all these
at the same time you'll need a nuke.
Taking out the bird from the ground turns a game of
cat and mouse, if you're dumping phonesats by the
satbusload -- these are short-lived, anyway, and need
to be constantly replenished. Orbital denial against small cross-section targets in a really low orbit which can be replenished cheaply will make every country with space access very mad at you, which is dangerous to your None of the approaches are mutually exclusive.
Use meshes, link them up via VPN tunnels across
Internet, use DTN with avian carriers, or phonesats.

@_date: 2013-09-26 17:02:18
@_author: Eugen Leitl 
@_subject: Fwd: [cryptography] The Compromised Internet 
They want to pick up a parabolic dish, a LoS laser or a
phased array tracking a point source overhead, all sending
at maybe 5-10 W power? Sure, if your sky is thick with mapping drones. Sounds like
a fifth world problem.
Isotropic radiators with high power are easy to spot.
Dynamic tight beams need at least a passing point of alignment
to get a position fix on the ground station. NSA sigint
used that microwave LoS interception, but this wouldn't
scale for millions of users and very brief low-power
bursts during random alignment events.
Or maybe you just buy  or the lower-grade
gear for LoS.
Phased arrays which are flat or half domes are compact and don't
look like anything from air. If you're clever, you can integrate
these into a PV panel.

@_date: 2013-09-26 17:50:39
@_author: Eugen Leitl 
@_subject: sneakernet calculation 
You overestimate the amount of useful content the Internet
carries. Let's assume you just want to deliver text messages
hand-entered by people. Let's say 10^9 people/day care to enter some ~kByte of text. That's a mere TByte/day, uncompressed.

@_date: 2013-09-27 13:52:19
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
Hash: SHA1
DLP (data loss prevention) products usually have MITM capability, to
make sure that proprietary information isn't being exfiltrated.  Also,
some companies have full packet capture policies.  The technology is
out there and people buy and use it.  Whether or not they're going to
care about Bitcoin URIs in the short term, I don't know.
Some of the companies documented here have such products:
You are correct in that the incentive to carry out MITM attacks in
this use case may not be there.  However, detecting transactions may
be more useful to an attacker than meddling with them.

@_date: 2013-09-27 16:53:39
@_author: Eugen Leitl 
@_subject: What the heck is going on with =?utf-8?Q?N?= 
zs-p2p
What the heck is going on with NISTs cryptographic standard, SHA-3?
by Joseph Lorenzo Hall [1]
September 24, 2013
(Warning: this is a fairly technical post about cryptographic standards
The cryptographic community has been deeply shaken since revelations earlier
this month [2] that the National Security Agency (NSA) has been using a
number of underhanded methods  stealing encryption keys, subverting
standards setting processes, planting backdoors in products  to undermine
much of the encryption used online. This includes crucial pieces of
e-commerce like HTTPS (SSL/TLS) and Virtual Private Networks (VPN) that we
use each day to purchase things online, to socialize in private, and that
businesses use to communicate confidential and proprietary information. While
the reporting has been vague and hasnt pointed to specific software versions
or protocols that have been compromised, last week RSA Security  a major
supplier of cryptographic software and hardware  initiated a product recall
[3] of sorts, warning users that one of its popular software encryption
products contained a likely NSA-planted backdoor. The practical implication
of the RSA recall is that much of the encryption that used this product since
2007 isnt nearly as secure as it was supposed to be.
Those of us who follow developments in the cryptographic community have
noticed another troubling development: there are a number of cryptographers
upset with how the National Institute of Standards and Technology (NIST) is
standardizing a new set of encryption algorithms called SHA-3 (which stands
for the third version of the Secure Hashing Algorithm). The remainder of this
post explains what is going on with SHA-3 and how NIST could diffuse this
particular controversy while it still has the chance.
(Warning: In this post, Im assuming the reader is familiar with the concepts
underlying basic encryption tools, called cryptographic primitives, such as
hash functions [4], digital signatures [5], and message authentication codes
What is SHA-3?
SHA-3 is the next generation hash algorithm being standardized by NIST. In
2005, researchers developed an attack [7] that called into question the
security guarantees of an earlier secure hash algorithm, SHA-1. The
characteristics of this 2005 attack seemed to hint that it could be refined
to attack many of the secure hash functions at the time, including SHA-0,
MD4, MD5 and even SHA-2. At the time, for many cryptographers, the message
was clear: a new hash algorithm is needed and it should be based on
completely different underlying mathematics that are not susceptible to the
attacks threatening known hash functions. To be clear: SHA-1 is thought to be
on its way out, as people expect the earlier attacks to be improved
considerably in the coming years and there hasnt been any result that calls
into question the soundness of SHA-2 at all. Attacks always improve, so its
imperative that there is an alternative hash function ready to go when and if
the floor falls out of the earlier hash functions.
NISTs cryptographic technology group [8] is world-renowned for cryptographic
algorithm standardization. In 2007, NIST began the process to develop and
standardize a new secure hash algorithm that would be called SHA-3. The
process for choosing a new algorithm was designed as a competition: new
candidate algorithms were submitted by more than 60 research teams and over
five years the entrants were whittled down to a set of finalists, from which
a winner was chosen. In October of last year, NIST announced [9] that a team
of Italian and Belgian cryptographers had won the competition with their
submission named, Keccak (pronounced KECH-ack).
What has NIST done with SHA-3?
Since the announcement of Keccak as the winner, NIST has been working hard to
turn Keccak into a standard. That is, NIST cant just point to the academic
paper and materials submitted by the Keccak team and call that a standard.
NIST has to write the algorithm up in a standards-compliant format and
include it in other NIST cryptographic standards documents, such as a
successor to the Secure Hash Standard document (FIPS Publication 180-4) [10].
Heres where the controversy starts.
One of the most accomplished civilian cryptographers, NISTs John Kelsey,
gave an invited talk at a conference in August, the Workshop on Cryptographic
Hardware and Embedded Systems 2013 (CHES13) [11], where he described some of
the changes NIST has made to Keccak in turning it into a standard. The
changes were detailed in five slides (slides 44-48) of Kelseys slide deck
for his talk [12]. Two major changes puzzled some in attendance:
In the name of increased performance (running faster in software and
hardware), the security levels of Keccak were drastically reduced. The four
versions of the winning Keccak algorithm had security levels of 224-bits,
256-bits, 384-bits, and 512-bits. However, from Kelseys slides, NIST intends
to standardize only two versions, a 128-bit and a 256-bit version.  Some of
the internals of the algorithm had been tweaked by NIST  some in cooperation
with the team that submitted Keccak  to improve performance and allow for
new types of applications.  Essentially, NIST had changed Keccak to something
very different from what won the 5-year competition. Since this talk,
cryptographers have been abuzz with this news and generally very critical of
the changes (e.g., folks like Marsh Ray on Twitter [13]).
What are the issues with SHA-3 standardization?
So, whats the big deal? Well, the problems here cluster in five areas:
Process: From a simple due process perspective, after a five-year hard-fought
competition, to make large changes to the winning algorithm is simply
problematic. The algorithm being standardized is very different from the
winning Keccak, which beat 62 other high-powered cryptography research groups
in a 5-year competition. (To be fair, its not like these changes came out of
the blue. However, given the new political environment reality itself has
changed.) No security improvement: The SHA-3 version of Keccak being proposed
appears to provide essentially the same level of security guarantees as
SHA-2, its predecessor. If we are going to develop a next generation hash,
there certainly should be standardized versions that provide a higher
security level than the older hash functions! NIST, in the original call for
submissions, specifically asked for four versions in each submission, with at
least two that would be stronger than what was currently available, so its
hard to understand this post-competition weakening.  Unclear implications of
internal changes: The changes made to Keccak to get to SHA-3 may be so
substantial as to render the cryptanalysis that was performed during the
competition moot. That is, all the intense number crunching cryptographers
performed during the competition to try and break the submitted ciphers to
prove their strength/weakness simply doesnt apply to the modified form of
Keccak that NIST is working on.  No real need for high-performance hashes:
NIST said it weakened the security levels of the winning Keccak submission to
boost performance. (Weaker versions of hash functions run faster.) However,
there is not clearly a need for another fast hash algorithm. For example, to
get exceedingly technical for a moment: in communications security, hashes
are used for a few purposes and most are computed on small inputs  where
performance isnt a concern  and in cases where performance is a concern due
to large inputs (e.g., with message authentication codes or MACs), many
applications are moving away from hash-based MACs (HMAC) to other types of
MACs like GMAC [14] that are not based on hash functions.  NISTs reputation
is undermined: Kelseys CHES13 talk was given in mid-August, two weeks
before the NSA encryption revelations. Those revelations [2] suggest that
NSA, through an intelligence program called BULLRUN actively worked to
undermine NISTs effort to standardize strong cryptography. NIST could not
have known how the changes it made might appear once that reporting had cast
a pall over NIST cryptographic standards setting. The changes made to Keccak
undoubtedly weaken the algorithm, calling NISTs motives into question in
light of the NSA revelations (regardless of their actual intentions).  None
of this is irreversible.
What could NIST do to diffuse this controversy?
Kelseys slides indicate that NIST is on track to standardize the
NIST-modified version of Keccak as SHA-3 and issue a draft standard in late
October for public comment. If the issues above are not addressed in that
draft standard, there will be considerable hue and cry from the cryptographic
community and it will only serve to reinforce the more general concerns about
NISTs cooperation with the NSA. Its in no ones interest to feed the flames
of NIST scaremongering and we all have an interest in NIST as a trusted place
for science and standardization. In that spirit, there are a number of things
NIST can do to calm this storm (and please consider joining NISTs Hash Forum
[15] to discuss this further):
Add back high-security modes: NIST must ensure that SHA-3 has strong modes of
operation. NIST should at least add back in a 512-bit security level version
of Keccak so those users who want exceedingly high security and dont worry
as much about performance have a standardized mode that they can use. In
fact, if NIST is worried about performance, it probably makes sense to
standardize the as-submitted versions of Keccak (224, 256, 384, 512-bit
security levels) and add in a much weaker but high-performance 128-bit
version for those users who want to make that trade-off. This would be the
Kumbaya solution, as it would have five security levels with both the
NIST-modified versions and the as-submitted Keccak versions.  Justify
optimizations and internal changes: NIST has obviously made significant
internal changes to the Keccak algorithm. This means that the NIST-modified
Keccak and the winner of the SHA-3 competition are likely to be very
different. To be sure, there are probably some very good reasons for the
changes, but we dont know what they are, and it would be unfortunate to
learn them simply in the draft standard as published in October. Extensive
changes should technically be subject to the cryptanalysis that was brought
to bear during the actual competition. Unfortunately, it will be impossible
to muster the cryptographic scrutiny necessary to examine the NIST-modified
Keccak as the resources and teams that worked on this during the competition
are no longer available. Here, it makes sense for NIST to standardize both
the winning version of Keccak and NISTs optimized version (SHA-3-Opt
maybe?), so that implementers can have their pick of whether they want the
Keccak that was subject to the grueling competition or an improved version
that hasnt been subject to as much scrutiny.  Improve the standardization
process: No one doubts that NIST runs high-quality cryptographic
competitions. The many-year competitions that resulted in AES (the Advanced
Encryption Standard) and SHA-3 marshaled the most gifted cryptographic
thinkers in the world to shake down very exotic forms of mathematics to
result in very strong, clever and useful practical outcomes. The resulting
algorithms look indistinguishable from magic to many of us who are not
steeped in the fine art of cryptography. However, the process of getting from
the algorithm that won the competition to a standard is a dark and mysterious
process, and it need not be. While the relationship between NSA and NIST has
always made many of us uneasy, in light of recent revelations, its
especially important that this standardization step be open and transparent
with a formal process that works to ensure that all decisions are made in a
well-documented manner and that conditions that ensured an algorithm
withstood withering scrutiny during a competition do not subsequently change
dramatically during the standardization process.  At CDT, we work hard to
make sure that standards processes serve the public interest in an open, free
and innovative Internet. Well be advocating for changes in standards
processes at NIST so that it remains an unbiased, trusted, and scientific
venue for developing cybersecurity and cryptographic standards.
UPDATE [2013-09-24T17:41:24]: Changed title to better reflect that SHA-3 is
not an encryption standard but a hash function standard (without using "hash
function" in the title). Better qualified that SHA-1 is likely weak in the
face of government-level adversaries. Further update [2013-09-25T06:09:38]:
clarified that SHA-1 is essentially on its way out.
Copyright  2013 by Center for Democracy & Technology.
The content throughout this website that originates with CDT can be freely
copied and used as long as you make no substantive changes and clearly give
us credit. Details.
Source URL: [1] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15]

@_date: 2013-09-02 09:49:03
@_author: Eugen Leitl 
@_subject: [tor-talk] New paper : Users Get Routed: Traffic Correlation on Tor 
X-Mailer: Sylpheed 3.4.0beta4 (GTK+ 2.24.10; x86_64-pc-linux-gnu)
Reply-To: tor-talk at lists.torproject.org
Hi all,
Heads up on a new paper suggesting that its possible to unmask
Tor users using traffic correlation:
    Code here:
    Would be interested in hearing the opinions of the core Tor
develpoment team on this stuff.

@_date: 2013-09-03 13:16:43
@_author: Eugen Leitl 
@_subject: building a community on RetroShare 
One of my RS identities is
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: OpenPGP:SDK v0.9
-----END PGP PUBLIC KEY BLOCK-----
see you there.

@_date: 2013-09-04 15:22:03
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] 0.8.4 released, fixes critical 
Bitcoin-Qt version 0.8.4 is now available from:
  This is a maintenance release to fix a critical bug and three
security issues; we urge all users to upgrade.
There were no changes from 0.8.4 release candidate 2, so if you are running
0.8.4rc2 you do not need to upgrade.
Please report bugs using the issue tracker at github:
  How to Upgrade
An attacker could send a series of messages that resulted in
an integer division-by-zero error in the Bloom Filter handling
code, causing the Bitcoin-Qt or bitcoind process to crash.
Bloom filters were introduced with version 0.8, so versions 0.8.0
through 0.8.3 are vulnerable to this critical denial-of-service attack.
A constant-time algorithm is now used to check RPC password
guess attempts; fixes Implement a better fix for the fill-memory-with-orphan-transactions
attack that was fixed in 0.8.3. See
for a description of the weaknesses of the previous fix.
Bugs fixed
Fix multi-block reorg transaction resurrection.
Fix non-standard disconnected transactions causing mempool orphans.
This bug could cause nodes running with the -debug flag to crash.
OSX: use 'FD_FULLSYNC' with LevelDB, which will (hopefully!)
prevent the database corruption issues many people have
experienced on OSX.
Linux: clicking on bitcoin: links was broken if you were using
a Gnome-based desktop.
Fix a hang-at-shutdown bug that only affects users that compile
their own version of Bitcoin against Boost versions 1.50-1.52.
Other changes
Checkpoint at block 250,000 to speed up initial block downloads
and make the progress indicator when downloading more accurate.
Thanks to everybody who contributed to the 0.8.4 releases!
Pieter Wuille
Warren Togami
Patrick Strateman
Gregory Maxwell
Sergio Demian Lerner
Cory Fields
Matt Corallo
Gavin Andresen

@_date: 2013-09-04 22:12:40
@_author: Eugen Leitl 
@_subject: NSA Laughs at PCs, Prefers Hacking Routers and Switches 
NANOG list NSA Laughs at PCs, Prefers Hacking Routers and Switches
BY KIM ZETTER09.04.136:30 AM
Photo: Santiago Cabezas/Flickr
The NSA runs a massive, full-time hacking operation targeting foreign
systems, the latest leaks from Edward Snowden show. But unlike conventional
cybercriminals, the agency is less interested in hacking PCs and Macs.
Instead, Americas spooks have their eyes on the internet routers and
switches that form the basic infrastructure of the net, and are largely
overlooked as security vulnerabilities.
Under a $652-million program codenamed Genie, U.S. intel agencies have
hacked into foreign computers and networks to monitor communications crossing
them and to establish control over them, according to a secret black budget
document leaked to the Washington Post. U.S. intelligence agencies conducted
231 offensive cyber operations in 2011 to penetrate the computer networks of
targets abroad.
This included not only installing covert implants in foreign desktop
computers but also on routers and firewalls  tens of thousands of machines
every year in all. According to the Post, the government planned to expand
the program to cover millions of additional foreign machines in the future
and preferred hacking routers to individual PCs because it gave agencies
access to data from entire networks of computers instead of just individual
Most of the hacks targeted the systems and communications of top adversaries
like China, Russia, Iran and North Korea and included activities around
nuclear proliferation.
The NSAs focus on routers highlights an often-overlooked attack vector with
huge advantages for the intruder, says Marc Maiffret, chief technology
officer at security firm Beyond Trust. Hacking routers is an ideal way for an
intelligence or military agency to maintain a persistent hold on network
traffic because the systems arent updated with new software very often or
patched in the way that Windows and Linux systems are.
No one updates their routers, he says. If you think people are bad about
patching Windows and Linux (which they are) then they are  horrible about
updating their networking gear because it is too critical, and usually they
dont have redundancy to be able to do it properly.
He also notes that routers dont have security software that can help detect
a breach.
The challenge [with desktop systems] is that while antivirus dont work well
on your desktop, they at least do something [to detect attacks], he says.
But you dont even have an integrity check for the most part on routers and
other such devices like IP cameras.
Hijacking routers and switches could allow the NSA to do more than just
eavesdrop on all the communications crossing that equipment. It would also
let them bring down networks or prevent certain communication, such as
military orders, from getting through, though the Post story doesnt report
any such activities. With control of routers, the NSA could re-route traffic
to a different location, or intelligence agencies could alter it for
disinformation campaigns, such as planting information that would have a
detrimental political effect or altering orders to re-route troops or
supplies in a military operation.
According to the budget document, the CIAs Tailored Access Programs and
NSAs software engineers possess templates for breaking into common brands
and models of routers, switches and firewalls.
The article doesnt say it, but this would likely involve pre-written scripts
or backdoor tools and root kits for attacking known but unpatched
vulnerabilities in these systems, as well as for attacking zero-day
vulnerabilities that are yet unknown to the vendor and customers.
[Router software is] just an operating system and can be hacked just as
Windows or Linux would be hacked, Maiffret says. Theyve tried to harden
them a little bit more [than these other systems], but for folks at a place
like the NSA or any other major government intelligence agency, its pretty
standard fare of having a ready-to-go backdoor for your [off-the-shelf] Cisco
or Juniper models.
Not all of the activity mentioned in the budget document involved remote
hacking. In some cases, according to the document, the operations involved
clandestine activity by the CIA or military intelligence units to physically
place hardware implants or software modifications to aid the spying.
Much more often, an implant is coded entirely in software by an NSA group
called Tailored Access Operations (TAO), the Post writes in its story about
the document. As its name suggests, TAO builds attack tools that are
custom-fitted to their targets.
A handful of security researchers have uncovered vulnerabilities in routers
in recent years that could be used to do the kind of hacking described in the
budget document.
In 2005, security researcher Mike Lynn found a serious vulnerability in Cisco
IOS, the operating system running on millions of Cisco routers around the
Lynn discovered the vulnerability after his employer, Internet Security
Systems, asked him to reverse-engineer the Cisco operating system to see if
he could find security problems with it. Cisco makes the majority of the
routers that operate the backbone of the internet as well as many company
networks and critical infrastructure systems. The Cisco IOS is as ubiquitous
in the backbone as the Windows operating system is on desktops.
The vulnerability Lynn found, in a new version of the operation system that
Cisco planned to release at the time, would have allowed someone to create a
router worm that would shut down every Cisco router through which it passed,
bringing down a nations critical infrastructure. It also would have allowed
an attacker to gain complete control of the router to sniff all traffic
passing through a network in order to read, record or alter it, or simply
prevent traffic from reaching its recipient.
Once Lynn found the vulnerability, it took him six months to develop a
working exploit to attack it.
Lynn had planned to discuss the vulnerability at the Black Hat security
conference in Las Vegas, until Cisco intervened and forced him to pull the
talk under threat of a lawsuit.
But if Lynn knew about the vulnerability, there were likely others who did as
well  including intelligence agencies and criminal hackers.
Source code for Ciscos IOS has been stolen at least twice, either by
entities who were interested in studying the software to gain a competitive
advantage or to uncover vulnerabilities that would allow someone to hack or
control them.
Other researchers have uncovered different vulnerabilities in other Cisco
routers that are commonly used in small businesses and home offices.
Every year at computer security conferences  including the Black Hat
conference where NSA Director Keith Alexander presented a keynote this year 
U.S. intelligence agencies and contractors from around the world attend to
discover information about new vulnerabilities that might be exploited and to
hire talented researchers and hackers capable of finding more vulnerabilities
in systems.
In 2008, a researcher at Core Security Technologies developed a root kit for
the Cisco IOS that was designed to give an attacker a persistent foothold on
a Cisco router while remaining undetected.
According to the Post story, the NSA designs most of the offensive tools it
uses in its Genie operation, but it spent $25.1 million in one year for
additional covert purchases of software vulnerabilities from private
malware vendors who operate on the grey market  closed markets that peddle
vulnerabilities and exploits to law enforcement and intelligence agencies, as
opposed to the black market that sells them to cyber criminals.
The price of vulnerabilities and exploits varies, depending on a number of
factors. Vulnerabilities and exploits can sell for anywhere from $50,000 to
more than a million, depending on the exclusivity of the purchase  some
vulnerabilities are sold to multiple parties with the understanding that
others are using it as well  and their ubiquity. A vulnerability that exists
in multiple versions of an operating system is more valuable than a
vulnerability that exists in just one version. A class of vulnerability that
crosses multiple browser brands is also more valuable than a single
vulnerability that just affects the Safari browser or Chrome.
The Stuxnet cyber weapon that was reportedly created by the U.S. and Israel
to sabotage centrifuges used in Irans uranium enrichment program, used five
zero-day exploits to spread itself among systems in Iran, including a rare
exploit that attacked the .LNK function in multiple versions of the Windows
operating system in order to spread the worm silently via infected USB
Ubiquitous router vulnerabilities are difficult to find since there are so
many different configurations for routers, and an attack that works against
one router configuration might not work for another. But a vulnerability that
affects the core operating system is much more valuable since it is less
likely to be dependent on the configuration. Maiffret says there hasnt been
a lot of public research on router vulnerabilities, but whenever someone has
taken a look at them, they have found security holes in them.
Theyre always successful in finding something, he says.
Once a vulnerability becomes known to the software maker and is patched, it
loses a lot of its value. But because many users and administrators do not
patch their systems, some vulnerabilities can be used effectively for years,
even after a patch is available. The Conficker worm, for example, continued
to infect millions of computers long after Microsoft released a patch that
should have stopped the worm from spreading.
Routers in particular often remain unpatched because system administrators
dont think they will be targeted and because administrators are concerned
about network outages that could occur while the patch is applied or if the
patch is faulty.
Kim Zetter is a senior reporter at Wired covering cybercrime, privacy,
security and civil liberties.
Read more by Kim Zetter
Follow  and  on Twitter.

@_date: 2013-09-04 22:16:12
@_author: Eugen Leitl 
@_subject: [tor-talk] Exit node stats collection? 
Hash: SHA1
I do not know if this link has been posted yet, but this jumped out at
me this morning - it's a technique for correlating publically known
Tor nodes against hidden services:
Thoughts from the community?

@_date: 2013-09-05 12:05:49
@_author: Eugen Leitl 
@_subject: Content and popularity analysis of Tor hidden services 
Content and popularity analysis of Tor hidden services
July 29, 2013
Alex Biryukov
University of Luxembourg alex.biryukov at uni.lu
Ivan Pustogarov University of Luxembourg ivan.pustogarov at uni.lu
Ralf-Philipp Weinmann University of Luxembourg ralf-philipp.weinmann at uni.lu
Tor hidden services allow running Internet services while protecting the
location of the servers. Their main purpose is to enable freedom of speech
even in situations in which powerful adversaries try to suppress it. However,
providing location privacy and client anonymity also makes Tor hidden
services an attractive platform for every kind of imaginable shady service.
The ease with which Tor hidden services can be set up has spurred a huge
growth of anonymously provided Internet services of both types. In this paper
we analyse the landscape of Tor hidden services. We have studied Tor hidden
services after collecting 39824 hidden service descriptors on 4th of Feb 2013
by exploiting protocol and implementation aws in Tor: we scanned them for
open ports; in the case of HTTP services, we analysed and classified their
content. We also estimated the popularity of hidden services by looking at
the request rate for hidden service descriptors by clients. We found that
while the content of Tor hidden services is rather varied, the most popular
hidden services are related to botnets.
Tor, hidden services, port scanning, classification

@_date: 2013-09-05 13:19:33
@_author: Eugen Leitl 
@_subject: PayPal freezes MailPile's account 
Why, why did they keep 45 kUSD worth of funds in an
account run by known jerks? Friends don't let friends
use PayPal.

@_date: 2013-09-05 15:13:32
@_author: Eugen Leitl 
@_subject: US stops jailed activist Barrett Brown from discussing leaks 
cypherpunks
US stops jailed activist Barrett Brown from discussing leaks prosecution
Federal court order prohibits Brown from talking to the media in what critics
say is latest in crackdown on investigative journalism
Ed Pilkington in New York
theguardian.com, Wednesday 4 September 2013 22.50 BST
Barrett Brown, Anonymous spokesman
Brown's lawyer says the gagging order is a breach of Brown's first amendment
rights. Photograph: Nikki Loehr
A federal court in Dallas, Texas has imposed a gag order on the jailed
activist-journalist Barrett Brown and his legal team that prevents them from
talking to the media about his prosecution in which he faces up to 100 years
in prison for alleged offences relating to his work exposing online
The court order, imposed by the district court for the northern district of
Texas at the request of the US government, prohibits the defendant and his
defence team, as well as prosecutors, from making "any statement to members
of any television, radio, newspaper, magazine, internet (including, but not
limited to, bloggers), or other media organization about this case, other
than matters of public interest."
It goes on to warn Brown and his lawyers that "no person covered by this
order shall circumvent its effect by actions that indirectly, but
deliberately, bring about a violation of this order".
According to Dell Cameron of Vice magazine, who attended the hearing, the
government argued that the gag order was needed in order to protect Brown
from prejudicing his right to a fair trial by making comments to reporters.
But media observers seen the hearing in the opposite light: as the latest in
a succession of prosecutorial moves under the Obama administration to
crack-down on investigative journalism, official leaking, hacking and online
Brown's lead defence attorney, Ahmed Ghappour, has countered in court
filings, the most recent of which was lodged with the court Wednesday, that
the government's request for a gag order is unfounded as it is based on false
accusations and misrepresentations.
The lawyer says the gagging order is a breach of Brown's first amendment
rights as an author who continues to write from his prison cell on issues
unconnected to his own case for the Guardian and other media outlets.
In his memo to the court for today's hearing, Ghappour writes that Brown's
July article for the Guardian "contains no statements whatsoever about this
trial, the charges underlying the indictment, the alleged acts underlying the
three indictments against Mr Brown, or even facts arguably related to this
The gag order does give Brown some room to carry on his journalistic work
from prison. It says that he will be allowed to continue publishing articles
on topics "not related to the counts on which he stands indicted".
Following the imposition of the order, Ghappour told the Guardian: "The
defense's overriding concern is that Mr Brown continue to be able to exercise
his first amendment right as a journalist. The order preserves that ability."
The lawyer adds that since the current defence team took over in May, Brown
has made only three statements to the media, two of which where articles that
did not concern his trial while the third ran no risk of tainting the jury
pool. "Defendant believes that a gag order is unwarranted because there is no
substantial, or even reasonable, likelihood of prejudice to a fair trial
based on statements made by defendant or his counsel since May 1, 2013."
Brown, 32, was arrested in Dallas on 12 September last year and has been in
prison ever since, charged with 17 counts that include threatening a federal
agent, concealing evidence and disseminating stolen information. He faces a
possible maximum sentence of 100 years in custody.
Before his arrest, Brown became known as a specialist writer on the US
government's use of private military contractors and cybersecurity firms to
conduct online snooping on the public. He was regularly quoted by the media
as an expert on Anonymous, the loose affiliation of hackers that caused
headaches for the US government and several corporate giants, and was
frequently referred to as the group's spokesperson, though he says the
connection was overblown.
In 2011, through the research site he set up called Project PM, he
investigated thousands of emails that had been hacked by Anonymous from the
computer system of a private security firm, HB Gary Federal. His work helped
to reveal that the firm had proposed a dark arts effort to besmirch the
reputations of WikiLeaks supporters and prominent liberal journalists and
activists including the Guardian's Glenn Greenwald.
In 2012, Brown similarly pored over millions of emails hacked by Anonymous
from the private intelligence company Stratfor. It was during his work on the
Stratfor hack that Brown committed his most serious offence, according to US
prosecutors  he posted a link in a chat room that connected users to
Stratfor documents that had been released online.
The released documents included a list of email addresses and credit card
numbers belonging to Stratfor subscribers. For posting that link, Brown is
accused of disseminating stolen information  a charge with media
commentators have warned criminalises the very act of linking.
As Geoffrey King, Internet Advocacy Coordinator for the Committee to Protect
Journalists, has put it, the Barrett Brown case "could criminalize the
routine journalistic practice of linking to documents publicly available on
the internet, which would seem to be protected by the first amendment to the
US constitution under current doctrine".
In its motion to the Dallas district court, US prosecutors accuse Brown and
his associates of having "solicited the services of the media or media-types
to discuss his case" and of continuing to "manipulate the public through
press and social media comments".
It further accuses Ghappour of "co-ordinating" and "approving" the use of the
media, and alleges that between them they have spread "gross fabrications and
substantially false recitations of facts and law which may harm both the
government and the defence during jury selection".
But Ghappour in his legal response has pointed out that several of the
specific accusations raised by the government are inaccurate. Prosecutors
refer to an article in the Guardian by Greenwald published on 21 March 2013
based partly on an interview between the journalist and Brown, yet as
Ghappour points out that piece was posted on the Guardian website before the
accused's current legal team had been appointed.
Under his legal advice, Ghappour writes, Brown has maintained "radio silence"
over his case and has given no further interviews, thus negating the
government's case for a gagging order.

@_date: 2013-09-05 15:16:35
@_author: Eugen Leitl 
@_subject: Spy Files: New WikiLeaks docs expose secretive, unruly surveillance 
cypherpunks info zs-p2p
 doctrinezero ExI chat list Spy Files: New WikiLeaks docs expose secretive, unruly surveillance industry
Published time: September 04, 2013 16:06 Edited time: September 05, 2013 10:00 Get short URL
Screenshot from a leaked documentScreenshot from a leaked document
Central Asia, Information Technology, Intelligence, Internet, Middle East,
The growing surveillance industry complex is providing governments with
increasingly sophisticated spying software to track and control their
citizens, the latest documents obtained by the pro-transparency group,
WikiLeaks reveal.
A trove of documents, outlining the activities of dozens of companies
operating in the ever-expanding electronic snooping industry, were made
available by the pro-transparency group on Wednesday.
Lawful interception, mass monitoring, network recording, signals and
communication intelligence, and tactical interception devices were among the
services and products provided by a litany of Western based firms, as
outlined in hundreds of pages of documents covering trade brochures, internal
memos, and invoices. "WikiLeaks' Spy Files  is part of our ongoing commitment to shining a light
on the secretive mass surveillance industry. This publication doubles the
WikiLeaks Spy Files database, the accompanying press release cites Julian
Assange. The WikiLeaks Spy Files form a valuable resource for journalists
and citizens alike, detailing and explaining how secretive state intelligence
agencies are merging with the corporate world in their bid to harvest all
human electronic communication." One 2011 document showed how companies such as UK-based Gamma Group,
German-based Desoma and Swiss-based Dreamlab are working in concert to
create Telecommunications Intelligence Systems for different
telecommunications networks to fulfill the customers needs regarding
massive data interception and retention.
In March, Gamma International, which is a subsidiary of Gamma group, made
Reporters Without Borders 'Corporate Enemies of the Internet' list for 2013,
which singled out five digital mercenaries who sell their surveillance
technology to authoritarian regimes.
The firms FinFisher Suite (which includes Trojans to infect PCs, mobile
phones, other consumer electronics and servers, as well as technical
consulting), is considered to be one of the most sophisticated in the world.
During the search of an Egyptian intelligence agency office in 2011, human
rights activists found a contract proposal from Gamma International to sell
FinFisher to Egypt.
Bill Marczak, a computer science doctoral candidate at the University of
California, helped investigate the use of FinFisher spyware against activists
and journalists in Bahrain in 2012, as well as in other states.
We dont have any sort of contracts, so that we could see financial dealings
between companies and these governments. The only indications that we have as
to where the spyware has been used are based on the research. In cases that
weve seen the spyware has been targeted against activists and journalists in
a particular country. Weve been scanning the internet looking for this
technology. So we found, as I said, spywares in Bahrain. We saw it being
targeted against Bahraini journalists and activists last year. Weve also
found servers for the spyware in a number of other countries, such as
Turkmenistan, Qatar, Ethiopia, Marczak told RT.
RT was the only Russian broadcaster that collaborated with WikiLeaks in this
investigation, which also brought into the spotlight other companies
including Cobham, Amees, Digital Barriers, ETL group, UTIMACO, Telesoft
Technologies and Trovicor.
Trovicor, incidentally, also features among Reporters Without Borders
digital mercenaries. The firm, whose monitoring centers are capable of
intercepting phone calls, text messages, voice over IP calls (like Skype) and
Internet traffic, has also been accused by of helping Bahrain imprison and
torture activists and journalists.   Screenshot from a leaked documentScreenshot from a leaked document
While a smoking gun in the form of government contracts or invoices was not
forthcoming, internal documents discovered by WikiLeaks do confirm that the
firms dealings with autocratic states.
In a December 2010 correspondence between Nicolas Mayencourt, the CEO of
Dreamlab Technologies AG, and Thomas Fischer from Gamma Groups Germany-based
branch Gamma International GmbH, a quotation concerning the Monitoring
system for iproxy (infection proxy)-project is provided for an unspecified
end customer in Oman.
One concern involved keeping the client [Oman] aware of any changes made to
the proxy [intermediary] server infected with their software for the sake of
culling information from select targets.
During the integration tests in Oman in September 2010 the end customer
figured out that not all of the components of the iproxy infrastructure are
under their  full control. It is, for example possible that changes of the
Oman-network may occur without their knowledge. Thus, it might occur that
ISPs [Internet service providers] may modify some of the current
configuration. Therefore, the question arose whether it is possible to
identify such a modification in the network setup by monitoring the whole
iproxy infrastructure.
monitoring of the iproxy infrastructure including all components of the
systems was derived. This requirement is discussed and a proposal for
solution is described in this offer.
The infection process as was conducted on-site in Oman in 2010 can be
conducted in two different variants, as described in a separate document,
System Manual Project O, prepared for the Gulf client.
The first is described as a binary infection, whereby binaries (non-text
computer files) are infected after being downloaded by the configured target.
In order to do this, the software analyzes the data streams on the NDPs
[network data processors] at both of the Internet exchanges (IX). As soon as
a matching type of binary is downloaded, the infection mechanism is
initiated, then it attaches loader and payload (trojan) to the binary.
Screenshot from a leaked documentScreenshot from a leaked document
The second method is described as update infection, which works by sending
counterfeit server responses to predefined applications (for example iTunes,
Winamp, OpenOffice and SimpleLite), when they are searching for updates.
Data can be captured both through traditional public switch telephone
networks (PSTN), mobile providers and internet protocol suites across a range
of devices.
The users information, including his or her IP address, user name, [cell]
phone number, the date time and identity of the person being communicated
with, and the method or protocol (mail, WWW, Skype, chat, voice, fax, and
SMS) are all up for grabs.
Upon being captured, the data is stored in a Data Warehouse and retrieved
on command.
Quotations for the project, enumerated in Swiss francs (CHF), are broken down
in multiple categories:
Monitoring and alarming 83,355.00 Services provided by Dreamlab 34,400.00 Training 5,400.00 Annual solution maintenance 24,000.00 Redundant monitoring implementation 57,955.00 Services provided by Dreamlab for redundancy 5,760.00 Annual solution maintenance for redundant system 12,000.00 Note: 1 CHF = 1.06720 USD
Although such software does have legitimate applications for law enforcement,
it can easily be used to stifle civil society, as Marczak argues was the case
in Bahrain. Apart from journalists and activists, he noted that in the Malaysia and
Ethiopia, members of the political opposition were apparently being targeted
as well. One piece of FinFisher spyware discovered, for example, contained
details relating to the upcoming Malaysian elections.
You couldnt say exactly who was targeted against, but the use of
election-related content suggests politically motivated targeting. We also
found a sample of this spyware that appeared to be targeted at activists in
Ethiopia. The spyware contained a picture of Ethiopian opposition leaders
that was displayed when the user opened it. By opening the picture the user
copied the spyware, he said.

@_date: 2013-09-06 11:01:50
@_author: Eugen Leitl 
@_subject: [cryptography] regarding the NSA crypto "breakthrough" 
It is reported that the journalists deliberately withheld details
which are available in Snowden's original documents. Somebody
better leak these, fast.
The claims are that some code and magic constants have been weakened,
but also that NSA still has problems with some methods.
We need to know.
Obviously, as a short-term workaround there's fallback to
expensive/inconvenient methods like one-time pads, but long-term
we obviously need new cyphers. Not tainted by any TLA poison.

@_date: 2013-09-06 11:37:53
@_author: Eugen Leitl 
@_subject: The US government has betrayed the Internet. We need to take it back 
The US government has betrayed the Internet. We need to take it back
The NSA has undermined a fundamental social contract. We engineers built the
Internet  and now we have to fix it
Bruce Schneier
The Guardian, Thursday 5 September 2013 20.04 BST
Internet business cables in California.
'Dismantling the surveillance state won't be easy. But whatever happens,
we're going to be breaking new ground.' Photograph: Bob Sacha/Corbis
Government and industry have betrayed the Internet, and us.
By subverting the Internet at every level to make it a vast, multi-layered
and robust surveillance platform, the NSA has undermined a fundamental social
contract. The companies that build and manage our Internet infrastructure,
the companies that create and sell us our hardware and software, or the
companies that host our data: we can no longer trust them to be ethical
Internet stewards.
This is not the Internet the world needs, or the Internet its creators
envisioned. We need to take it back.
And by we, I mean the engineering community.
Yes, this is primarily a political problem, a policy matter that requires
political intervention.
But this is also an engineering problem, and there are several things
engineers can  and should  do.
One, we should expose. If you do not have a security clearance, and if you
have not received a National Security Letter, you are not bound by a federal
confidentially requirements or a gag order. If you have been contacted by the
NSA to subvert a product or protocol, you need to come forward with your
story. Your employer obligations don't cover illegal or unethical activity.
If you work with classified data and are truly brave, expose what you know.
We need whistleblowers.
We need to know how exactly how the NSA and other agencies are subverting
routers, switches, the Internet backbone, encryption technologies and cloud
systems. I already have five stories from people like you, and I've just
started collecting. I want 50. There's safety in numbers, and this form of
civil disobedience is the moral thing to do.
Two, we can design. We need to figure out how to re-engineer the Internet to
prevent this kind of wholesale spying. We need new techniques to prevent
communications intermediaries from leaking private information.
We can make surveillance expensive again. In particular, we need open
protocols, open implementations, open systems  these will be harder for the
NSA to subvert.
The Internet Engineering Task Force, the group that defines the standards
that make the Internet run, has a meeting planned for early November in
Vancouver. This group needs to dedicate its next meeting to this task. This
is an emergency, and demands an emergency response.
Three, we can influence governance. I have resisted saying this up to now,
and I am saddened to say it, but the US has proved to be an unethical steward
of the Internet. The UK is no better. The NSA's actions are legitimizing the
Internet abuses by China, Russia, Iran and others. We need to figure out new
means of Internet governance, ones that makes it harder for powerful tech
countries to monitor everything. For example, we need to demand transparency,
oversight, and accountability from our governments and corporations.
Unfortunately, this is going play directly into the hands of totalitarian
governments that want to control their country's Internet for even more
extreme forms of surveillance. We need to figure out how to prevent that,
too. We need to avoid the mistakes of the International Telecommunications
Union, which has become a forum to legitimize bad government behavior, and
create truly international governance that can't be dominated or abused by
any one country.
Generations from now, when people look back on these early decades of the
Internet, I hope they will not be disappointed in us. We can ensure that they
don't only if each of us makes this a priority, and engages in the debate. We
have a moral duty to do this, and we have no time to lose.
Dismantling the surveillance state won't be easy. Has any country that
engaged in mass surveillance of its own citizens voluntarily given up that
capability? Has any mass surveillance country avoided becoming totalitarian?
Whatever happens, we're going to be breaking new ground.
Again, the politics of this is a bigger task than the engineering, but the
engineering is critical. We need to demand that real technologists be
involved in any key government decision making on these issues. We've had
enough of lawyers and politicians not fully understanding technology; we need
technologists at the table when we build tech policy.
To the engineers, I say this: we built the Internet, and some of us have
helped to subvert it. Now, those of us who love liberty have to fix it.
 Bruce Schneier writes about security, technology, and people. His latest
book is Liars and Outliers: Enabling the Trust That Society Needs to Thrive.
He is working for the Guardian on other NSA stories

@_date: 2013-09-06 12:25:15
@_author: Eugen Leitl 
@_subject: PayPal freezes MailPile's account 
I've used Kickstarter from Germany. Amazon is present in many countries
beyond US/UK.

@_date: 2013-09-06 21:06:50
@_author: Eugen Leitl 
@_subject: Old list archives 
An excellent idea. Unfortunately, I lost my 1980s/90s
emails due to a shredded RAID.
I will put up a mirror as well. mbox format is perfect.

@_date: 2013-09-08 19:09:06
@_author: Eugen Leitl 
@_subject: [linux-elitists] Surveillance 
Anyone with CA/package signing opsec clue willing to help Linux
distros with advice to improve package signing security?

@_date: 2013-09-09 10:42:47
@_author: Eugen Leitl 
@_subject: Quark : A Web Browser with a Formally Verified Kernel 
Quark : A Web Browser with a Formally Verified Kernel
University of California, San Diego
Computer Science and Engineering
Quark is an experimental, formally verified browser. Watch it run popular sites like GMail, Facebook, and Amazon! [video 1] [video
Web browsers mediate access to valuable private data in domains ranging from
health care to banking. Despite this critical role, attackers routinely
exploit browser vulnerabilities to exfiltrate private data and take over the
underlying system. We present Quark, a browser whose kernel has been
implemented and verified in the Coq proof assistant. We give a specification
of our kernel, show that the implementation satisfies the specification, and
finally show that the specification implies several security properties,
including tab non-interference, cookie integrity and confidentiality, and
address bar integrity.
Our Web browser, Quark, exploits formal verification and enables us to verify
security properties for a million lines of code while reasoning about only a
few hundreds. To achieve this goal, Quark is structured similarly to Google
Chrome. It consists of a small browser kernel which mediates access to system
resources for all other browser components. These other components run in
sandboxes which only allow the component to communicate with the kernel. In
this way, Quark is able to make strong guarantees about a million lines of
code (e.g., the renderer, JavaScript implementation, JPEG decoders, etc.)
while only using a proof assistant to reason about a few hundred lines of
code for the Quark kernel. Because the underlying system is protected from
Quark's untrusted components (i.e., everything other than the kernel) we were
free to adopt state-of-the-art implementations and thus Quark is able to run
popular, complex Web sites like Facebook and GMail.
Establishing Browser Security Guarantees through Formal Shim Verification
[Tech Report] USENIX Security 2012 Dongseok Jang, Zachary Tatlock, Sorin Lerner Source code(.tar.gz) (Version 0.1, 08/07/2012, 1.3MB)
Dongseok Jang	
Zachary Tatlock	
Sorin Lerner

@_date: 2013-09-09 11:23:29
@_author: Eugen Leitl 
@_subject: IETF: Security and Pervasive Monitoring 
forkit! , tt
Security and Pervasive Monitoring
The Internet community and the IETF care deeply about how much we can trust
commonly used Internet services and the protocols that these services use.
So the reports about large-scale monitoring of Internet traffic and users
disturbs us greatly.  We knew of interception of targeted individuals and
other monitoring activities, but the scale of recently reported monitoring is
surprising. Such scale was not envisaged during the design of many Internet
protocols, but we are considering the consequence of these kinds of attacks.
Of course, it is hard to know for sure from current reports what attack
techniques may be in use.  As such, it is not so easy to comment on the
specifics from an IETF perspective.  Still, the IETF has some long standing
general principles that we can talk about, and we can also talk about some of
the actions we are taking.
In 1996, RFC 1984 articulated the view that encryption is an important tool
to protect privacy of communications, and that as such it should be
encouraged and available to all.  In 2002, we decided that IETF standard
protocols must include appropriate strong security mechanisms, and
established this doctrine as a best current practice, documented in RFC 3365.
Earlier, in 2000 the IETF decided not to consider requirements for
wiretapping when creating and maintaining IETF standards, for reasons stated
in RFC 2804. Note that IETF participants exist with positions at all points
of the privacy/surveillance continuum, as seen in the discussions that lead
to RFC 2804.
As privacy has become increasingly important, the Internet Architecture Board
(IAB) developed guidance for handling privacy considerations in protocol
specifications, and documented that in RFC 6973. And there are ongoing
developments in security and privacy happening within the IETF all the time,
for example work has just started on version 1.3 of the Transport Layer
Security (TLS, RFC 5246) protocol which aims to provide better
confidentiality during the early phases of the cryptographic handshake that
underlies much secure Internet traffic.
Recent days have also seen an extended and welcome discussion triggered by
calls for the IETF to build better protections against wide-spread
As that discussion makes clear, IETF participants want to build secure and
deployable systems for all Internet users.  Indeed, addressing security and
new vulnerabilities has been a topic in the IETF for as long as the
organisation has existed.  Technology alone is, however, not the only factor.
Operational practices, laws, and other similar factors also matter. First of
all, existing IETF security technologies, if used more widely, can definitely
help.  But technical issues outside the IETFs control, for example endpoint
security, or the properties of specific products or implementations also
affect the end result in major ways. So at the end of the day, no amount of
communication security helps you if you do not trust the party you are
communicating with or the devices you are using. Nonetheless, were confident
the IETF can and will do more to make our protocols work more securely and
offer better privacy features that can be used by implementations of all
So with the understanding of limitations of technology-only solutions, the
IETF is continuing its mission to improve security in the Internet.  The
recent revelations provide additional motivation for doing this, as well as
highlighting the need to consider new threat models.
We should seize this opportunity to take a hard look at what we can do
better.  Again, it is important to understand the limitations of technology
alone. But here are some examples of things that are already ongoing:
Were having a discussion as part of the development of HTTP/2.0 as to how to
make more and better use of TLS, for example to perhaps enable clients to
require the use of security and not just have to react to the HTTP or HTTPS
URLs chosen by servers.
Were having discussions as to how to handle the potentially new threat model
demonstrated by the recent revelations so that future protocol designs can
take into account potential pervasive monitoring as a known threat model.
Were considering ways in which better use can be made of existing protocol
features, for example, better guidance as to how to deploy TLS with Perfect
Forward Secrecy, which makes applications running over TLS more robust if
server private keys later leak out.
Were constantly updating specifications to deprecate older, weaker
cryptographic algorithms and allocate code points for currently strong
algorithm choices so those can be used with Internet protocols.
And we are confident that discussions on this topic will motivate IETF
participants to do more work on these and further related topics.
But dont think about all this just in terms of the recent revelations.  The
security and privacy of the Internet in general is still a challenge even
ignoring pervasive monitoring, and if there are improvements from the above,
those will be generally useful for many reasons and for many years to come.
Perhaps this years discussions is a way to motivate the world to move from
by default insecure communications to by default secure.  Publicity and
motivation are important, too. There is plenty to do for all of us, from
users enabling additional security tools to implementors ensuring that their
products are secure.
In the Vancouver IETF meeting, there will be time dedicated to discuss this,
and we ask that those interested in working on this topic contribute to the
analysis and develop proposals in this area.  Those contributions are very
welcome and can start now and continue in Vancouver and beyond.
Relevant mailing lists (from most specific to most general) include:
The perpass mailing list (perpass at ietf.org), recently set up to consider how
the IETF ought react to pervasive monitoring
The ietf security area mailing list (saag at ietf.org), for general security
The ietf main mailing list (ietf at ietf.org), for general discussion
Jari Arkko, Chair of the IETF and Stephen Farrell, IETF Security Area
This entry was posted in IETF on 2013/09/07.

@_date: 2013-09-09 11:35:05
@_author: Eugen Leitl 
@_subject: [liberationtech] Meet the 'cowboy' in charge of the NSA 
Looks paywalled. Can someone liberate the document, and repost
it here?

@_date: 2013-09-09 13:06:14
@_author: Eugen Leitl 
@_subject: [cryptography] New NSA Slides and Details Released last night 
David D
Sent: Monday, September 09, 2013 12:07 PM
Lots of gems in this video:
cryptography mailing list
cryptography at randombit.net

@_date: 2013-09-09 13:05:45
@_author: Eugen Leitl 
@_subject: [liberationtech] Meet the 'cowboy' in charge of the NSA 
9 September 2013 The Cowboy of the NSA Keith Alexander

@_date: 2013-09-09 14:40:10
@_author: Eugen Leitl 
@_subject: Scott Aaaronson: NSA: Possibly breaking US laws, but still bound by 
cryptography Cryptography List NSA: Possibly breaking US laws, but still bound by laws of computational
Last week, I got an email from a journalist with the following inquiry.  The
recent Snowden revelations, which made public for the first time the US
governments black budget, contained the following enigmatic line from the
Director of National Intelligence: We are investing in groundbreaking
cryptanalytic capabilities to defeat adversarial cryptography and exploit
internet traffic.  So, the journalist wanted to know, what could these
groundbreaking capabilities be?  And in particular, was it possible that
the NSA was buying quantum computers from D-Wave, and using them to run
Shors algorithm to break the RSA cryptosystem?
I replied that, yes, thats possible, but only in the same sense that its
possible that the NSA is using the Easter Bunny for the same purpose.  (For
one thing, D-Wave themselves have said repeatedly that they have no interest
in Shors algorithm or factoring.  Admittedly, I guess thats what D-Wave
would say, were they making deals with NSA on the sly!  But its also what
the Easter Bunny would say.)  More generally, I said that if the open
scientific worlds understanding is anywhere close to correct, then quantum
computing might someday become a practical threat to cryptographic security,
but it isnt one yet.
That, of course, raised the extremely interesting question of what
groundbreaking capabilities the Director of National Intelligence was
referring to.  I said my personal guess was that, with ~99% probability, he
meant various implementation vulnerabilities and side-channel attacksthe
sort of thing that we know has compromised deployed cryptosystems many times
in the past, but where its very easy to believe that the NSA is ahead of the
open world.  With ~1% probability, I guessed, the NSA made some sort of big
improvement in classical algorithms for factoring, discrete log, or other
number-theoretic problems.  (I wouldve guessed even less than 1% probability
for the latter, before the recent breakthrough by Joux solving discrete log
in fields of small characteristic in quasipolynomial time.)
Then, on Thursday, a big New York Times article appeared, based on 50,000 or
so documents that Snowden leaked to the Guardian and that still arent
public.  (See also an important Guardian piece by security expert Bruce
Schneier, and accompanying Q&A.)  While a lot remains vague, there might be
more public information right now about current NSA cryptanalytic
capabilities than theres ever been.
So, how did my uninformed, armchair guesses fare?  Its only halfway into the
NYT article that we start getting some hints:
The files show that the agency is still stymied by some encryption, as Mr.
Snowden suggested in a question-and-answer session on The Guardians Web site
in June.
Properly implemented strong crypto systems are one of the few things that
you can rely on, he said, though cautioning that the N.S.A. often bypasses
the encryption altogether by targeting the computers at one end or the other
and grabbing text before it is encrypted or after it is decrypted
Because strong encryption can be so effective, classified N.S.A. documents
make clear, the agencys success depends on working with Internet companies 
by getting their voluntary collaboration, forcing their cooperation with
court orders or surreptitiously stealing their encryption keys or altering
their software or hardware
Simultaneously, the N.S.A. has been deliberately weakening the international
encryption standards adopted by developers. One goal in the agencys 2013
budget request was to influence policies, standards and specifications for
commercial public key technologies, the most common encryption method.
Cryptographers have long suspected that the agency planted vulnerabilities in
a standard adopted in 2006 by the National Institute of Standards and
Technology and later by the International Organization for Standardization,
which has 163 countries as members.
Classified N.S.A. memos appear to confirm that the fatal weakness, discovered
by two Microsoft cryptographers in 2007, was engineered by the agency. The
N.S.A. wrote the standard and aggressively pushed it on the international
group, privately calling the effort a challenge in finesse.
So, in pointing to implementation vulnerabilities as the most likely
possibility for an NSA breakthrough, I might have actually erred a bit too
far on the side of technological interestingness.  It seems that a large part
of what the NSA has been doing has simply been strong-arming Internet
companies and standards bodies into giving it backdoors.  To put it bluntly:
sure, if it wants to, the NSA can probably read your email.  But that isnt
mathematical cryptographys faultany more than it would be mathematical
cryptos fault if goons broke into your house and carted away your laptop.
On the contrary, properly-implemented, backdoor-less strong crypto is
something that apparently scares the NSA enough that they go to some lengths
to keep it from being widely used.
I should add that, regardless of how NSA collects all the private information
it doesby beating crypto in a fair fight (!) or, more likely, by
exploiting backdoors that it itself installedthe mere fact that it collects
so much is of course unsettling enough from a civil-liberties perspective.
So Im glad that the Snowden revelations have sparked a public debate in the
US about how much surveillance we as a society want (i.e., the balance
between preventing 9/11 and preventing Orwell), what safeguards are in place
to prevent abuses, and whether those safeguards actually work.  Such a public
debate is essential if were serious about calling ourselves a democracy.
At the same time, to me, perhaps the most shocking feature of the Snowden
revelations is just how unshocking theyve been.  So far, I havent seen
anything that shows the extent of NSAs surveillance to be greater than what
I wouldve considered plausible a priori.  Indeed, the following could serve
as a one-sentence summary of what weve learned from Snowden:
Yes, the NSA is, in fact, doing the questionable things that anyone not
living in a cave had long assumed they were doingthat assumption being so
ingrained in nerd culture that countless jokes are based around it.
(Come to think of it, people living in caves might have been even more
certain that the NSA was doing those things.  Maybe thats why they moved to
So, rather than dwelling on civil liberties, national security, yadda yadda
yadda, let me move on to discuss the implications of the Snowden revelations
for something that really matters: a 6-year-old storm in theoretical computer
sciences academic teacup.  As many readers of this blog might know, Neal
Koblitza respected mathematician and pioneer of elliptic curve cryptography,
who (from numerous allusions in his writings) appears to have some
connections at the NSApublished a series of scathing articles, in the
Notices of the American Mathematical Society and elsewhere, attacking the
theoretical computer science approach to cryptography.  Koblitzs criticisms
were varied and entertainingly-expressed: the computer scientists are too
sloppy, deadline-driven, self-promoting, and corporate-influenced; overly
trusting of so-called security proofs (a term they shouldnt even use,
given how many errors and exaggerated claims they make); absurdly overreliant
on asymptotic analysis; bodacious in introducing dubious new hardness
assumptions that they then declare to be standard; and woefully out of
touch with cryptographic realities.  Koblitz seemed to suggest that, rather
than demanding the security reductions so beloved by theoretical computer
scientists, people would do better to rest the security of their
cryptosystems on two alternative pillars: first, standards set by
organizations like the NSA with actual real-world experience; and second, the
judgments of mathematicians with  taste and experience, who can just see
whats likely to be vulnerable and what isnt.
Back in 2007, my mathematician friend Greg Kuperberg pointed out the irony to
me: here we had a mathematician, lambasting computer scientists for trying to
do for cryptography what mathematics itself has sought to do for everything
since Euclid!  That is, when you see an unruly mess of insights, related to
each other in some tangled way, systematize and organize it.  Turn the tangle
into a hierarchical tree (or dag).  Isolate the minimal assumptions (one-way
functions?  decisional Diffie-Hellman?) on which each conclusion can be
based, and spell out all the logical steps needed to get from here to
thereeven if the steps seem obvious or boring.  Any time anyone has tried to
do that, its been easy for the natives of the unruly wilderness to laugh at
the systematizing newcomers: the latter often know the terrain less well, and
take ten times as long to reach conclusions that are ten times less
interesting.  And yet, in case after case, the clarity and rigor of the
systematizing approach has eventually won out.  So it seems weird for a
mathematician, of all people, to bet against the systematizing approach when
applied to cryptography.
The reason Im dredging up this old dispute now, is that I think the recent
NSA revelations might put it in a slightly new light.  In his articlewhose
main purpose is to offer practical advice on how to safeguard ones
communications against eavesdropping by NSA or othersBruce Schneier offers
the following tip:
Prefer conventional discrete-log-based systems over elliptic-curve systems;
the latter have constants that the NSA influences when they can.
Here Schneier is pointing out a specific issue with ECC, which would be
solved if we could merely ensure that NSA or other interested parties
werent providing input into which elliptic curves to use.  But I think
theres also a broader issue: that, in cryptography, its unwise to trust any
standard because of the prestige, real-world experience, mathematical good
taste, or whatever else of the people or organizations proposing it.  What
was long a plausible conjecturethat the NSA covertly influences
cryptographic standards to give itself backdoors, and that
otherwise-inexplicable vulnerabilities in deployed cryptosystems are
sometimes there because the NSA wanted them therenow looks close to an
established fact.  In cryptography, then, its not just for idle academic
reasons that youd like a publicly-available trail of research papers and
source code, open to criticism and improvement by anyone, that takes you all
the way from the presumed hardness of an underlying mathematical problem to
the security of your system under whichever class of attacks is relevant to
Schneiers final piece of advice is this: Trust the math.  Encryption is
your friend.
Trust the math.  On that note, heres a slightly-embarrassing confession.
When Im watching a suspense movie (or a TV show like Homeland), and I reach
one of those nail-biting scenes where the protagonist discovers that
everything she ever believed is a lie, I sometimes mentally recite the proof
of the Karp-Lipton Theorem.  It always calms me down.  Even if the entire
universe turned out to be a cruel illusion, it would still be the case that
NP  P/poly would collapse the polynomial hierarchy, and I can tell you
exactly why.  It would likewise be the case that you couldnt break the GGM
pseudorandom function without also breaking the underlying pseudorandom
generator on which its based.  Math could be defined as that which can still
be trusted, even when you cant trust anything else.
This entry was posted on Sunday, September 8th, 2013 at 11:31 am	 and
is filed under Complexity, Nerd Interest. You can follow any responses to
this entry through the RSS 2.0 feed. You can leave a response, or trackback
from your own site.
24 Responses to NSA: Possibly breaking US laws, but still bound by laws of
computational complexity Aaronson on crypto. Schneier elliptic-curve
systems; the latter have constants that the NSA influences when they can. |
Gordon's shares Says: Comment  September 8th, 2013 at 1:22 pm [] Link.
Trust math, but not NSA mathematicians. []
Douglas Knight Says: Comment  September 8th, 2013 at 1:35 pm Could you be
more specific about what you mean by the hypothetical big improvement on
number theory algorithms that is covered by your 1%?
Do elliptic curve algorithms count? Does an L(1/4) algorithm count, or only
quasi-polynomial? What if they cant break all instances, but, as has
repeatedly happened, they discovered bad primes or bad exponents that make
particular keys weak? Breaking a random half of all keys is almost as good as
breaking all of them. Schneiers condemnation of ECC seems to require more
than 1% chance NSA knows something special about ECC.
PS  David Jao, commenting on Schneiers blog says that we can and do use
cryptography to prevent NSA from meddling with mystery constants. He says
that the ECC standard curves are generated by SHA-1, so to meddle, NSA would
have to break the has function. (But if half of curves are bad, thats easy.)
Anonymous Says: Comment  September 8th, 2013 at 1:45 pm
You are making good and interesting points. However, Koblitz also has some
valid criticisms of TCS even if his conclusions are not valid. The
mathematical models we built in TCS are useless if they dont relate to the
practice and we know many of our standard models are not good enough
approximation of the reality and arguably there isnt enough effort to deal
with these issues. Technical heavy weight lifting is used as the ultimate
criteria for judging the value of research projects inside the community.
Also I think you are exaggerating what most cryptographers expected that NSA
was doing. I have heard several famous crypto experts quite surprised by
these revelations and it has shaken their trust in the government
institutions. I never understood why some people presume that government is a
benevolent entity, such beliefs in government institutions seems like
ideology to me.
Daniel Armak Says: Comment  September 8th, 2013 at 2:06 pm
You can trust the math itself, and so can Bruce Schneier and a few tens of
thousands of other people. But everyone else who cant grok the entire
mathematical arguments for each cryptographical system, or doesnt want to
spend a long time studying it, must trust the word of people like you. And
since the NSA can and does subvert people like you, who do original work and
analyze others work and sit on standards committees, not to mention the
programmers who implement it in code, what are we to do?
Daniel W. Says: Comment  September 8th, 2013 at 2:33 pm
In my mind, the best circumstantial evidence that the NSA has not practically
broken any of the major cryptosystems is the following:, if they had, they
would most likely keep this as a highly guarded secret to be used only
against high value targets rather than as a means of monitoring potential
terrorists. It would most likely be contained within a small circle and not
mentioned in power-point presentations to low-level analysts.
Of course, the above argument may be flawed by assuming the NSA has too high
of a level of competence.
T H Ray Says: Comment  September 8th, 2013 at 2:43 pm
  the clarity and rigor of the systematizing approach has eventually won
No doubt. In Euclids time as well as the present, though, it is helpful to
have something to systematize. Making that assumption available and
convenient is what mathematicians do.
Scott Says: Comment  September 8th, 2013 at 3:02 pm
Daniel Armak You can trust the math itself, and so can Bruce Schneier and a few tens of
thousands of other people. But everyone else  must trust the word of people
like you.  You raise an excellent point, which I think applies even more
broadly than you say. For one thing, I merely understand some of the general
ideas: I havent gone through every detail of the math used by the crypto in
my web browser, and I dare say that most professional cryptographers havent
For another, the point is much broader than cryptography: how can you trust
quantum mechanics, if you havent done the requisite experiments yourself?
The physicists couldve all been bought off by some anti-realist cabal. :-)
Or how can you trust that the government isnt putting mind-control drugs
into the fruit you buy in the supermarket, etc. etc.
So were extremely lucky that science hit on a solution to these problemsthe
only workable solution, reallyback in the 17th century. The solution is to
open up every question to scrutiny, discussion, and challenge by any
interested person. Assertions gain credibility by surviving public
criticismand thats just as true in math as it is in experimental sciences.
I believe many theorems even though I havent checked the proofs myself,
because I know that if there were an error, then someone else couldve made a
name for themselves by finding it.
Now, for this Popperian dynamic to work, the whole process has to be carried
out in the open: if I thought someone who found a fatal flaw in a proof would
only tell their friends, then that doesnt do me any good. Thats why the
dividing line between crypto as black art and modern crypto happened
precisely when new discoveries started being published in the open
literature, rather than being filed in a drawer at NSA or GCHQ.
wolfgang Says: Comment  September 8th, 2013 at 3:20 pm
Unfortunately, this xkcd.com/538/ had it right imho.
Scott Says: Comment  September 8th, 2013 at 3:20 pm
Daniel W.  If the NSA had really broken strong cryptosystems, then why
would they have resorted to so many covert tactics (or, in the case of the
Clipper Chip, overt attempts) to prevent people from using strong crypto,
unless NSA has a backdoor? I suppose its all elaborate psychological
warfare, to prevent us from discovering the fact that these cryptosystems
were broken? And that even Snowden himself is part of the NSAs master plan?
At least in my book, every time you claim that what looks on its face like
evidence for X, is really evidence for a powerful cabal trying to prevent
everyone from discovering not(X), the plausibility of your theory gets cut by
a factor of maybe 50,000. This is directly related to the fact that I dont
believe any conspiracy theoriesas in zero, not one.
Scott Says: Comment  September 8th, 2013 at 3:32 pm
Douglas Knight  Sure, dramatic improvements in elliptic-curve algorithms
would certainly countas would merely subexponential algorithms, were the
improvements large enough to threaten key sizes that the academic
cryptographers considered safe.
More broadly, though, youre entirely right that theres not a sharp line
between improved number-theory algorithms and implementation
vulnerabilities. Often, whats happened in practice is that an
implementation vulnerability has opened the way for an attack that still
requires interesting and nontrivial number theory. But I suppose that sort of
thing would still belong to the 99% part of my probability estimate. In the
1% part, I really had in mind something that would give theoretical
cryptographers a heart attack (like, I dunno, factoring in L(1/10), or
elliptic curve discrete log in quasipolynomial time).
Scott Says: Comment  September 8th, 2013 at 5:03 pm
Anonymous You are making good and interesting points. However, Koblitz also has some
valid criticisms of TCS even if his conclusions are not valid.  I completely
agree that Koblitz has some valid criticisms.
However, Ive read pretty much all of his and Menezess anti-TCS screeds, and
to me what hes doing seems, if you like, too easy to be helpful. Koblitzs
favorite M.O. is to recount various slip-ups by people in the Goldreich
school of crypto and laugh at them: haha, they talk about provable
security, but there was a bug in their proof! or their security definition
left out an important class of side-channel attacks! Then, with even more
glee, Koblitz relates how the hapless computer scientists put out a new paper
supposedly fixing the problem, but that paper had its own problems, and so
The trouble is, that is indeed what a bunch of incompetent buffoons would
look like, but its also what science looks like! :-) Koblitz never seems to
want to acknowledge that the end result of the process is better scientific
understanding and more secure cryptosystems than before (even if still not
Also, of course, Koblitz almost defiantly refuses to suggest any better
mathematical foundations for cryptography, besides the reduction-based
foundations that were built up over the last 30 years. I.e., its not that
instead of adaptive chosen ciphertext attack, he has a better definition to
propose, or that instead of bodacious new hardness assumptions, he can give
a single assumption that suffices for everything. Instead, what he appears to
want is simply a return to the black art era of cryptography, when security
arguments boiled down to we tried to break it and failed or trust us, we
have better mathematical taste than you.
The trouble is, I cant think of a single case in the history of science when
mathematical foundations as well-developed as cryptographys now are, were
simply abandoned wholesale without better mathematical foundations to replace
them. So intellectually, Koblitz strikes me as someone whos throwing spears
at battle-tanks. Being the excellent marksman that he is, he actually scores
some hitsbut the reduction-encrusted battle-tanks are still going to win in
the end.
The mathematical models we built in TCS are useless if they dont relate to
the practice and we know many of our standard models are not good enough
approximation of the reality and arguably there isnt enough effort to deal
with these issues.  Would one also say that the mathematical foundations of
topologyopen sets, Urysohns Lemma, etc.are useless if they dont relate to
the practice of tying and untying knots? I think thats a pretty close
analogy for the relationship between what, say, Goldreich or Goldwasser or
Micali do, and the actual practice of cryptography. In both cases, yes,
theres some relation between the intellectual foundations on the bottom and
the beautiful ornaments on top, but not surprisingly there are many floors in
between. Starting from a one-way function, for example, you first have to
construct a quasi-regular one-way function, then a pseudoentropy generator,
then a pseudorandom generator, then a pseudorandom function, and then maybe
you can start to think about building (say) a rudimentary private-key
cryptosystem or signature scheme.
Also I think you are exaggerating what most cryptographers expected that NSA
was doing. I have heard several famous crypto experts quite surprised by
these revelations and it has shaken their trust in the government
institutions. I never understood why some people presume that government is a
benevolent entity, such beliefs in government institutions seems like
ideology to me.  My situation is different: I never had any real doubt that
NSA was doing such things; the thing I genuinely dont know is whether they
have good reasons to be doing them. I consider it conceivable that the NSA
has indeed stopped many terrorist attacks or other international disasters
that we never hear aboutin which case, the strongest case in their favor
might be stronger than the strongest case that can ever be made publicly. The
fact that President Obama, whos so reasonable on so many issues, has implied
as much is evidence for that view from my perspective. On the other hand, I
also consider it conceivable that the current eavesdropping regime is purely
a result of the universal tendency of bureaucracies to expand, justify
themselves, and zealously guard their power and privileges. Or it could be
some combination of the two.
For me, though, the deciding consideration is that, even in a fantasy world
where the NSAs actions had always been 100% justified, Id still want them
to be more accountable to the public than they are now. Trust that we have
our reasons, even though we cant tell you what they are simply doesnt work
over the long term in a democracy, even if the trust is justified at any
particular time or in any particular case (and of course, often it hasnt
Anonymous Says: Comment  September 8th, 2013 at 8:05 pm
I agree with you that his attitude is not constructive criticism. I would
even go further than you and say it is stupid to forget the science of crypto
and go back to purely engineering art treatment.
Regarding reasonability of what NSA does, NSA and its backers would of course
claim these tools are useful. To be honest, security was a weak point of
Obamas campaign, he is not really knowledgeable in these issues and he has
not gone and will not go against his advisers if they tell him these tools
are necessary to fight terrorism. However, as far as I have heard, they have
hard time convincing anyone outside executive branch that these tools have
been as useful as they are claiming. How many major terrorist plots they have
been uncovered and prevented using these tools? It seems that they are using
these tools for a very wide range of activities including industrial and
political espionage on foreign governments and companies and gain political
and commercial advantage (what they call US national interests, not just
securing Americans against terrorists). Does anyone really believe that EU or
Brazil or liberal NGOs will launch a terrorist attack on US? FBIs actions
against Dr. King is telling how far they would go. They use the fear factor
of a possible terrorist attacks to justify these actions to the public,
however the laws allow them to do whatever they want to and when there are
restrictions (like the fourth amendments) they find ways to circumvents them
(e.g. by colliding with foreign intelligence services like GCHQ to spy on
American citizens) or change the interpretations of those laws. We are very
lucky that many influential Americans in the previous generations had a
negative view of the federal government and wanted to restrict its powers as
much as possible, restrictions which are being removed in practice (partly
because some people want to settle sociopolitical disputes present in the
country using the governments power). I dont see why so much power should
be invested in a single authority with almost no real public supervision and
scrutiny (a role that media was playing to some extent in previous decades
but is coming under heavy pressure from government as Manning, Swartz,
Snowden,  cases demonstrate). And even when courts find that someone in the
government has seriously violated the laws the president forgives them and
they avoid real punishment (as Scoot Libby case demonstrates).
It is not just US government, there is a trend in western liberal
democracies. It is simply unbelievable that the UK security forces used a law
passed to fight terrorism to hold the partner of a Guardian journalist for 9
hours without a lawyer and without the protection of Miranda rights against
self-incrimination. Anyone who thinks that security forces will only use the
authority and tools they obtain to the limited extent of the original goal
suffers from extreme nativity. They will use any tools in their disposal to
the fullest extent they can to achieve what they perceive to be the goals of
their institution. When they perceive journalists like Greenwald as a threat
to the national interests they use these tools to fight them which includes
intimidating the partner of a journalist using terrorism fighting powers. I
still fund it really hard to believe that we have gone so far in the
direction of an Orwellian society.
What can theoretical computer science offer biology? | Theory, Evolution, and
Games Group Says: Comment  September 9th, 2013 at 2:16 am
[] the aid that cstheory can offer to biological understanding. In
yesterdays post on the NSA and computational complexity, Aaronson  with
attribution to mathematician Greg Kuperberg  provided the following []
Paul Beame Says: Comment  September 9th, 2013 at 2:45 am
Some of the NSA revelations have been no surprise at all. It was well known
in the 1980s, particularly after the publication of The Puzzle Palace, that
the NSA was tapping all the trans-Atlantic telephone cables; gathering up of
all e-mail to foreign addresses seems like more of the same.
The relationship of the NSA with TCS cryptographers has been pretty shaky. I
recall attending a theory of cryptography workshop at MITs Endicott House in
June 1985 with one or two official NSA attendees. At the time, there were one
or two TCS attendees known to have NSA funding and the NSA people wanted to
recruit more. In announcing their desire to sponsor more TCS cryptographers,
one of the NSA people cast a pall over the meeting by saying: If you are
interested, just mention it in a phone conversation with one of your friends
and well get back to you. This didnt exactly endear them to anyone.
J Says: Comment  September 9th, 2013 at 2:51 am
Math could be defined as that which can still be trusted, even when you
cant trust anything else
Wait till someone shows multiplication and addition have same complexity or
possible Voevodskys/Nelsons worst nightmare comes true
Scott Says: Comment  September 9th, 2013 at 4:20 am
J  Multiplication and addition having the same complexity (and yes, its
conceivable that theres a linear-time multiplication algorithm) wouldnt do
anything whatsoever to undermine my trust in mathwhy would it?
Also, even if ZF set theory were shown to be inconsistent (and it wont be
:-) ), that wouldnt do anything whatsoever to undermine my trust in theorems
about (say) finite groups, or low-dimensional topology, or theoretical
computer sciencein fact, about anything that doesnt involve transfinite
sets. It would merely tell me that there was a need (and, of course, an
exciting opportunity) to rethink the foundations. Thats something that
already happened 100+ years ago (the renovations causing virtually no damage
to the higher floors), and that could conceivably happen again.
Vitruvius Says: Comment  September 9th, 2013 at 4:58 am
I agree, Scott, with your general position that any time one claims that
evidence for x is really evidence for a powerful cabal trying to prevent
everyone from discovering not(x) ones credibility drops by an irrecoverably
large factor, and I agree with you that math can be defined as that which
can still be trusted, even when you cant trust anything else (as you put
it), yet that still begs the question of how we the people decide what to
trust to be valid math.
Similarly, while your suggestion to open up every question to scrutiny,
discussion, and challenge by any interested person may be necessary in order
to establish public trust, it isnt sufficient because we still have the
problem of deciding which such interested persons to trust, and which to
write off as conspiracy theorists in their own right. How do we feasibly
decide, in effect, whether Ehrenhaft is a crackpot (as it were), and whether
Snowden himself is part of the NSAs master plan (as you playfully alluded
To that end you may be interested in Why Doesnt the Public Trust
Scientists?, a lecture by The Right Honourable Professor The Baroness ONeill
of Bengarve, Emeritus Professor of Philosophy at the University of Cambridge
and past Principal of Newnham College, Cambridge, which she presented in 2005
as part of the Science Futures series by the San Diego Science and Technology
Councils Center for Ethics in Science and Technology.
Note that while scientists are the titular and exemplary referent matter in
that lecture, Baroness ONeills talk actually considers a range of questions
in regard of public trust, including the roles of professional organizations,
trustworthiness (which cant replace trust because of the quis custodiet
ipsos custodes problem), statutory regulation, post hoc accountability, &c,
which apply more broadly to the matters of public trust in any and every
profession and institution, including politics and the law.
ONeill argues, if I may be so bold as to suggest a prcis, that going back
through the 17th century (as you noted) western liberal democracies have
indeed evolved a multipartite methodology that does tend work in practice and
that may well be the best we can get in principal, though it remains unclear
to me how well we are applying those techniques to matters of state security
in general, and how effectively you folks in the United States of America are
applying those techniques to your vaunted Agency in particular.
Scott Says: Comment  September 9th, 2013 at 5:01 am
Paul Beame  Ive actually heard that joke many times, in other variants.
(Interested in career opportunities at the NSA? Call your mom and let her
know!) I didnt know that NSA people themselves used the joke at
conferences, but it doesnt surprise me at all.
J Says: Comment  September 9th, 2013 at 6:39 am Multiplication and
addition having the same complexity (and yes, its conceivable that theres a
linear-time multiplication algorithm) wouldnt do anything whatsoever to
undermine my trust in mathwhy would it?
I thought I read somewhere that if addition and multiplication turn out to be
similar in complexity, then it would imply something is wrong with
On the same vein think of the generalization of scheme theory that Mochizuki
claims to have undertaken to take apart + and x in ring structure.
I would think something fundamentally would have changed in our picture if
they turn to be similar in complexity.
J Says: Comment  September 9th, 2013 at 6:47 am
Atleast for computational purposes, the multiplicative group structure and
additive group structure of $\Bbb Z$ seem to be coinciding. This seems wrong.
I cannot directly relate to $Z \bmod p$ but this seems to have implication to
Discrete Log. An implication for this may not be beyond reach for atleast a
few other rings as well.
Scott Says: Comment  September 9th, 2013 at 7:02 am
J  Well, we already have a remarkable O(n logn loglogn) multiplication
algorithm (due to Frer, and building on many previous works), and it hasnt
created any problem for the foundations of mathematics that I know about.
Meanwhile, just like for most problems, we currently have no lower bound for
multiplication better than the trivial (n). I suppose Id guess that (n
logn) is some sort of barrier, but not with any strength of conviction: if a
linear-time algorithm were discovered, it certainly wouldnt cause me to
doubt the consistency of ZF set theory. :-)
Scott Says: Comment  September 9th, 2013 at 7:16 am
Vitruvius it remains unclear to me  how effectively you folks in the United States of
America are applying those techniques to your vaunted Agency in particular.
As long as were trading mild national barbs, youre Canadian? You guys do
have the Communications Security Establishment, which according to the NYT
article is one of only four foreign agencies (along with Britains,
Australias, and New Zealands) that knows the full extent of the NSAs
decoding capabilities and is cleared for its Bullrun program. Though I
confess that, when I try to imagine Canadas CSE, I come up with something
like the following:
Read this gentlemans private email? Ooo, nooo, that doesnt sound terribly
polite, eh?
J Says: Comment  September 9th, 2013 at 7:21 am
Professor I am well aware of all $n^{1+\epsilon}$ algorithms and Schonages
$O(n)$ algorithm on multitape machines. I cannot find the reference I am
thinking. It was written by a TCS theorist. I would seriously think that the
standard ring structure in $\Bbb Z$ could be modeled differently. I do not
know if ZF would be affected. However the question of treating x and +
differently for computation purposes compare to mathematical purposes arises
making things murky.
I am not implicating ZF with $O(n)$ algorithms for standard x operations on
the standard structure of $\Bbb Z$. The ZFC comment was a second piece of
mathematical conundrum some reputed folks have raised awareness about for a
need to be more well-grounded and it rang well with your statement on truth
in math as we know it. (Unrelated but bringing in  $Z$ has been a puzzle
before as well  it is the simplest ring with a spectrum of prime ideals
whose dimension is unclear to be interpreted in a standard way)
Scott Says: Comment  September 9th, 2013 at 7:23 am
Wolfgang Unfortunately, this xkcd.com/538/ had it right imho.
YES! I especially liked the mouseover text (Actual actual reality: nobody
cares about his secrets).

@_date: 2013-09-09 16:37:13
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Blockchain archival 
Not quite true, as I said balance-at-point-in-time would solve that (and make the storage requirements much lower)
For bitcoin to grow beyond interesting experiment into global everyday use a number of things would have to happen, not least of which is taking 'average punter' into account. Whilst new ideas can filter into the general consciousness over time,sometimes concepts have to go with 'what already works' :)
People's concept of money hasn't really changed in over 1,000 years - it remains 'something of known value i can exchange for something else'.
No-one outside of bitcoin dev's and early adopters really gets the one-shot concept of addresses - possibly rightly so - keeping issues of it lowering levels of anonymity etc out of the discussion - it doesn't fit with the mindset people have - it's difficult enough getting merchants to setup separate addresses for each client, one per transaction is simply a waste (of addresses, storage, blockchain size, numnber of inputs|outputs when spending etc)
I'm sure the wife would love a new handbag everytime she gets some money, but the real-world just isnt like that ;)
Addresses are perceived as the equivalent of a jar you stick your coins in. You can have lots of jars. Each jar can be for a specific reason or whatever, but the analogy is there.
Wallets are like a box you keep some of your jars in. With the added interesting concept that a jar can be in multiple boxes at the same time. Only the person with the right 'key' can open the jar and take the However unlike the 3 money boxes I have behind me right now - which i can take 1 single penny out of one and put it into another - if I want to move bitcoins from one addresses (jar) to another *of my own* I have to pay a fee. Worse still if the jar doesnt have much in it I'm denied that ability.
End user will neither understand why or want to pay the fee, for dealing with their own coins.
If a jar breaks I can just tip the contents into a new one - unless I'm very careless, the amount in the new one = the amount in the old one - people will want/need it to work like that.
Similarly if you do have all these addresses around, you may want (as good housekeeping) discard some of them (after moving the cash).
So having the ability to specify address to send from is essential (and a sadly missing feature of the QT client)
'intra-wallet' transfers with an 'also discard the sending address' would be a way of (once confirmed) stopping any further use of that address (denied any further transactions by miners ?) and when balance-at-point-in-time is implemented, a way of shrinking the storage for all other bitcoin users (who chosse not to have a full transaction If i send luke 10, and luke sends me back 3, i have 3, luke has 7.
If luke sends me 2, and i send luke 1, i have 4 and luke has 6.
To verify my ability to send jeff 4, all that is needed is to know that I have 4, not all the transactions that led to that state - thats how its done now, thats not necessarily efficient as bitcoin grows
If luke sends me 4 more, i now have 4 again, luke has 3
If i send 1 to each of the children, they have 1 each (*4)
Having a 'family' wallet means when on holiday they can have that rental of quad-bikes - to send the rental company 4 the client only needs to know that those addresses now have 1 each in them, not all the previous transactions - if they didnt exist at the point-in-time balance, then yes, it would need to know about the luke>rob>kids transactions, but thats all
I moved to a new netbook recently - it took 140 *hours* to d/load and process the blockchain (yes the wifi was that bad), I heard from one of our clients that (although they only had the client running during working hours) that to their desktop it was over 9 days before it had caught up.
If all I was d/loading were the transactions since the last difficulty change (as one example of a fixed point), and the remaining balance on any not-discarded address as at that point it would have been much much quicker, and not be shagging my shiny new hard drive.
There's more but it's 4.45 in the morning, and I cant think coherently until after a few hours kip and some good coffee :)

@_date: 2013-09-09 22:01:19
@_author: Eugen Leitl 
@_subject: hardware RNG 
I would use a cheap analog circuit like and let your audio card to A/D. Bonus points: there are already entropy gathering daemons which
use soundcard input.
Even cheaper: hang a cheap microphone into a fan exhaust. Noise definitely not white,
but certainly more entropy than just looking at lowest bits of A/D.

@_date: 2013-09-10 10:23:04
@_author: Eugen Leitl 
@_subject: hardware RNG 
Many cheap embeddes have hardware RNGs -- e.g. ALIX (Geode),
which can take e.g. HiFn 7955 on a mini-PCI, plus mixing in
some entropy from e.g. an USB device is not that expensive.

@_date: 2013-09-10 18:15:37
@_author: Eugen Leitl 
@_subject: generating noisy samples at a high rate with RTLSDR 
Just remembered another cheap option for generating a lot
of noisy samples: Especially, with wideband RF noise source.

@_date: 2013-09-10 18:55:46
@_author: Eugen Leitl 
@_subject: generating noisy samples at a high rate with RTLSDR 
That's exactly what you need, if you want to get entropy
from the real world. Wide-band white noise generator circuits up to 300 MHz are very cheap and easy.
This gives you some 1.4 Msamples @ 8 bit. With a wideband
white noise source there will be several bits of entropy
in each sample, estimated.

@_date: 2013-09-11 13:21:29
@_author: Eugen Leitl 
@_subject: SPDZ, a practical protocol for Multi-Party Computation 
Breakthrough in cryptography could result in more secure computing
Tags: computer science, research, security, cryptography
Nigel Smart, Professor of Cryptology New research to be presented at the 18th European Symposium on Research in
Computer Security (ESORICS 2013) this week could result in a sea change in
how to secure computations.
The collaborative work between the University of Bristol and Aarhus
University (Denmark) will be presented by Bristol PhD student Peter Scholl
from the Department of Computer Science.
The paper, entitled 'Practical covertly secure MPC for dishonest majority -
or: Breaking the SPDZ limits', builds upon earlier joint work between Bristol
and Aarhus and fills in the missing pieces of the jigsaw from the groups
prior work that was presented at the CRYPTO conference in Santa Barbara last
The SPDZ protocol (pronounced "Speedz") is a co-development between Bristol
and Aarhus and provides the fastest protocol known to implement a theoretical
idea called "Multi-Party Computation".
The idea behind Multi-Party Computation is that it should enable two or more
people to compute any function of their choosing on their secret inputs,
without revealing their inputs to either party. One example is an election,
voters want their vote to be counted but they do not want their vote made
The protocol developed by the universities turns Multi-Party Computation from
a theoretical tool into a practical reality. Using the SPDZ protocol the team
can now compute complex functions in a secure manner, enabling possible
applications in the finance, drugs and chemical industries where computation
often needs to be performed on secret data.
Nigel Smart, Professor of Cryptology in the University of Bristol's
Department of Computer Science and leader on the project, said: "We have
demonstrated our protocol to various groups and organisations across the
world, and everyone is impressed by how fast we can actually perform secure
"Only a few years ago such a theoretical idea becoming reality was considered
Alice in Wonderland style over ambitious hope. However, we in Bristol
realised around five years ago that a number of advances in different areas
would enable the pipe dream to be achieved. It is great that we have been
able to demonstrate our foresight was correct."
The University of Bristol is now starting to consider commercialising the
protocol via a company Dyadic Security Limited, co-founded by Professor Smart
and Professor Yehuda Lindell from Bar-Ilan University in Israel.
Note: This story has been adapted from a news release issued by the
University of Bristol

@_date: 2013-09-11 13:40:10
@_author: Eugen Leitl 
@_subject: WREN: The First Satellite YOU Can Fly 
The only satellite in Earth orbit that YOU can control DIRECTLY ! You are the
pilot. Launch is this year!
Even nowadays space is not opened to the public, but we will change that -
this year !
We are four guys in a garage, and we have dedicated ourselves to open space
for everyone. For that purpose we designed the miniaturized satellite WREN.
Its a so called Pocketqub-Femtosatellite. It has only 5x5x5cm of volume and
250g of mass, and fits perfectly into your hand, like a tennis ball. Despite
of its size, it even has real thrusters.
It can be remotely positioned by you in every direction and it has a camera
onboard for taking pictures from outer space. It will be released into a
polar orbit before the end of this year on board of the UNISAT-5 deployer,
which is launched inside a DNEPR Rocket from Yasni in Russia.
It will race around the globe every 98 minutes, passing every point of the
earth during each day, seven days a week, just waiting for the command to be
remotely flown by you.
System overview
WREN System Overview
WREN is equipped with a camera, a gyro and a magnetic field sensor. Those
three components will form an adaptive feedback guidance system which helps
you to easily navigate the satellite by your own by using its momentum wheels
and microthrusters. The camera is equipped with an image processing system
which can find the position of the sun and the earth automatically. This
technology will make the control of the satellite more easy. With the camera
system you can of course remotely take pictures of the earth, the sun and
other space objects. You can navigate the satellite directly in order to make
your own picture.
The communication up- and downlink will be performed at 437,405 MHz, a
frequency in the 70cm amateur radio band which has been kindly assigned to us
by the International Amateur Radio Union (IARU). Wren will be flying in a sun
synchronous orbit at 700km of altitude at an incredible speed of 7500
m/second, so that it will take only 98 minutes to fly one time all around the
planet. Practically, a link is possible for about 10 minutes from a single
ground station, up to three times a day. The mission control software is
equipped with prediction algorithms in order to predict the flyby- time
according to your location, so you can prepare yourself for the upcoming
communication window and take control over the satellite again.
We hope that amateur radio enthusiasts will join our network and provide a
link from time to time to use WRENs lifetime as long as possible.
Send a message into deep space
You can send a message into deep space. Of course it will be also receptable
on earth. Everytime WREN sends his status to earth, it will also send out one
of the saved messages.
If WREN survives for years, your message will be sent several times into the
deep far universe.
Project Status
The rocket launch is scheduled for November this year.
Wren is currently in the final assembly process and will be integrated into
the deployer in October this year, after the shaker test.
We will be helped out with a professional ground station after launch for the
first weeks, but we want to build our own mobile groundstation to be able to
establish the link for you anytime.
We will publish the plans for the groundstation as soon as it is ready and
working, so everybody can build it!
How do we get into space so cheaply?
Bringing one kilogram of mass into orbit costs about 50000$. Rockets must
carry their fuel all the way up, so the laws of physics make them big, heavy
and expensive.
So how do we fly so relatively cheaply?
First, we are light, about 250 grams. And we fly piggyback on a bigger
satellite called "UNISAT-5".  This satellite, together with some others, are
all stored in one rocket, so the costs for the launch will be shared
according to the mass. Wren will be stored in a deployment unit called MRFOD.
Wren will be waiting inside this MRFOD in the satellite "UNISAT-5" for his
release into the open space
The rocket will go up in November and will release UNISAT-5 and other
satellites. Wren will be released into space out of Unisat about one month
Please Spread the message
We want to bring space into your living room. To achieve this we need your
help, not only by asking you for backing us with money but also by telling
the story to everybody you know who may be interested in space. We also need
amateur radio guys who would like to take part in project and follow Wren all
along its way around the planet by listening its beacon and messages you
pledged for, being heard. Our blogs and webpages, reports and videos are just
a few components of the whole message. You are the messengers, you are the
carrier of the idea of transporting space into everybody's living room - and
beyond!

@_date: 2013-09-11 15:49:33
@_author: Eugen Leitl 
@_subject: NIST reopens RNG public comment period 
Sep. 9, 2013
SP 800-90 A Rev 1 B and C
DRAFT Draft SP 800-90 Series: Random Bit Generators 800-90 A Rev. 1: Recommendation for Random Number Generation Using Deterministic Random Bit Generators 800-90 B: Recommendation for the Entropy Sources Used for Random Bit Generation 800-90 C: Recommendation for Random Bit Generator (RBG) Constructions
In light of recent reports, NIST is reopening the public comment period for Special Publication 800-90A and draft Special Publications 800-90B and 800-90C.
NIST is interested in public review and comment to ensure that the recommendations are accurate and provide the strongest cryptographic recommendations possible.
The public comments will close on November 6, 2013. Comments should be sent to RBG_Comments at nist.gov. In addition, the Computer Security Division has released a supplemental ITL Security Bulletin titled "NIST Opens Draft Special Publication 800-90A, Recommendation for Random Number Generation Using Deterministic Random Bit Generators, For Review and Comment (Supplemental ITL Bulletin for September 2013)" to support the draft revision effort.
Draft SP 800-90 A Rev. 1 (721 KB) Draft SP 800-90 B (800 KB) Draft SP 800-90 C (1.1 MB)

@_date: 2013-09-13 11:49:24
@_author: Eugen Leitl 
@_subject: Stealthy Dopant-Level Hardware Trojans 
Stealthy Dopant-Level Hardware Trojans ?
Georg T. Becker1
, Francesco Regazzoni2
, Christof Paar1,3 , and Wayne P. Burleson1
1University of Massachusetts Amherst, USA
2TU Delft, The Netherlands and ALaRI - University of Lugano, Switzerland
3Horst ortz Institut for IT-Security, Ruhr-Universiat Bochum, Germany
Abstract. In recent years, hardware Trojans have drawn the attention of governments and
industry as well as the scientific community. One of the main concerns is
that integrated circuits, e.g., for military or critical infrastructure
applications, could be maliciously manipulated during the manufacturing
process, which often takes place abroad. However, since there have been no
reported hardware Trojans in practice yet, little is known about how such a
Trojan would look like, and how dicult it would be in practice to implement
In this paper we propose an extremely stealthy approach for implementing
hardware Trojans below the gate level, and we evaluate their impact on the
security of the target device. Instead of adding additional circuitry to the
target design, we insert our hardware Trojans by changing the dopant polarity
of existing transistors. Since the modified circuit appears legitimate on all
wiring layers (including all metal and polysilicon), our family of Trojans is
resistant to most detection techniques, including fine-grain optical
inspection and checking against "golden chips".  We demonstrate the
ectiveness of our approach by inserting Trojans into two designs | a digital
post-processing derived from Intel's cryptographically secure RNG design used
in the Ivy Bridge processors and a side-channel resistant SBox implementation
and by exploring their detectability and their ects on security.
Keywords: Hardware Trojans, malicious hardware, layout modifications, Trojan

@_date: 2013-09-18 19:08:22
@_author: Eugen Leitl 
@_subject: Zero Reserve - A distributed Bitcoin exchange 
Zero Reserve - A distributed Bitcoin exchange
tl;dr: Proposal and prototype for a distributed exchange not requiring a banking gateway. Implemented as a plugin for Retroshare. Licensed under the LGPL.
The Achilles heel of Bitcoin is the exchanges. Centralized as they are, they can be shut down by a number of means, by a number of players. Should that happen, price discovery of Bitcoin will not work any more. To address that, we offer a distributed exchange without the need of the banking system. Some intro and marketing blurb is here:
A tech paper is here:
And the code is here:
In short, ZR uses the Ripple idea of Ryan Fugger to get money in and out of the exchange. ZR has nothing to do whatsoever with ripple.com, however. As such, there is no need for XRP. There is no pre-mining, no company, just code.
Now the caveat: This is prototype software. Anything may or may not work. Security is only what the underlying Retroshare provides. The distributed order book works, but is still insecure. Currencies are therefore only defunct or fantasy currencies such as German Papermark(1923). Nothing you do has any effect on the blockchain.
The next steps are:
- hook up to the blockchain (using Amir Taakis excellent libbitcoin)
- providing basic wallet functionality
- provide authentication for anything beyond F2F.
I see no reason why it wouldnt work on OSX, but ZR was never built on it. It does build and run on Linux and Windows, though.
Once you are on Retroshare and have some friends, you should be able to use this link to get and subscribe to the Zero Reserve Forum:
One of my RS identities:
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: OpenPGP:SDK v0.9
-----END PGP PUBLIC KEY BLOCK-----

@_date: 2013-09-24 15:18:55
@_author: Eugen Leitl 
@_subject: How a Crypto =?utf-8?B?4oCYQmFja2Rvb3I=?= =?utf-8?B?4oCZ?= Pitted 
zs-p2p forkit! ,
 ExI chat list , doctrinezero
How a Crypto Backdoor Pitted the Tech World Against the NSA
BY KIM ZETTER09.24.136:30 AM
Illustration: alengo/Getty Images
In August 2007, a young programmer in Microsofts Windows security group
stood up to give a five-minute turbo talk at the annual Crypto conference in
Santa Barbara.  It was a Tuesday evening, part of the conferences
traditional rump session, when a hodge-podge of short talks are presented
outside of the conferences main lineup. To draw attendees away from the wine
and beer that competed for their attention at that hour, presenters sometimes
tried to sex up their talks with provocative titles like Does Bob Go to
Prison? or How to Steal Cars  A Practical Attack on KeeLoq or The Only
Rump Session Talk With Pamela Anderson.
Dan Shumow and his Microsoft colleague Niels Ferguson titled theirs,
provocatively, On the Possibility of a Back Door in the NIST SP800-90 Dual
Ec Prng. It was a title only a crypto geek would love or get.
The talk was only nine slides long (.pdf). But those nine slides were
potentially dynamite. They laid out a case showing that a new encryption
standard, given a stamp of approval by the U.S. government, possessed a
glaring weakness that made an algorithm in it susceptible to cracking. But
the weakness they described wasnt just an average vulnerability, it had the
kind of properties one would want if one were intentionally inserting a
backdoor to make the algorithm susceptible to cracking by design.
For such a dramatic presentation  by mathematicians standards  the
reaction to it was surprisingly muted. I think folks thought, Well thats
interesting, and, Wow, it looks like maybe there was a flaw in the
design, says a senior Microsoft manager who was at the talk. But there
wasnt a huge reaction.
Six years later, thats all changed.
Early this month the New York Times drew a connection between their talk and
memos leaked by Edward Snowden, classified Top Secret, that apparently
confirms that the weakness in the standard and so-called Dual_EC_DRBG
algorithm was indeed a backdoor. The Times story implies that the backdoor
was intentionally put there by the NSA as part of a $250-million, decade-long
covert operation by the agency to weaken and undermine the integrity of a
number of encryption systems used by millions of people around the world.
The Times story has kindled a firestorm over the integrity of the byzantine
process that produces security standards. The National Institute of Standards
and Technology, which approved Dual_EC_DRBG and the standard, is now facing a
crisis of confidence, having been forced to re-open the standard for public
discussion, while security and crypto firms scramble to unravel how deeply
the suspect algorithm infiltrated their code, if at all. On Thursday,
corporate giant RSA Security publicly renounced Dual_EC_DRBG, while also
conceding that its commercial suite of cryptographic libraries had been using
the bad algorithm as its default algorithm for years.
But beneath the flames, a surprising uncertainty is still smoldering over
whether Dual_EC_DRBG really is backdoored. The Times, crypto experts note,
hasnt released the memos that purport to prove the existence of a backdoor,
and the papers direct quotes from the classified documents dont mention any
backdoor in the algorithm or efforts by the NSA to weaken it or the standard.
They only discuss efforts to push the standard through committees for
Jon Callas, the CTO of Silent Circle, whose company offers encrypted phone
communication, delivered a different rump session talk at the Crypto
conference in 2007 and saw the presentation by Shumow. He says he wasnt
alarmed by it at the time and still has doubts that what was exposed was
actually a backdoor, in part because the algorithm is so badly done.
If [NSA] spent $250 million weakening the standard and this is the best that
they could do, then we have nothing to fear from them, he says. Because
this was really ham-fisted. When you put on your conspiratorial hat about
what the NSA would be doing, you would expect something more devious,
Machiavellian  and this thing is just laughably bad. This is Boris and
Natasha sort of stuff.
Indeed, the Microsoft presenters themselves  who declined to comment for
this article  didnt press the backdoor theory in their talk. They didnt
mention NSA at all, and went out of their way to avoid accusing NIST of
anything. WE ARE NOT SAYING: NIST intentionally put a back door in this
PRNG, read the last slide of their deck.
The Microsoft manager who spoke with WIRED on condition of anonymity thinks
the provocative title of the 2007 presentation overstates the issue with the
algorithm and is being misinterpreted  that perhaps reporters at the Times
read something in a classified document showing that the NSA worked on the
algorithm and pushed it through the standards process, and quickly took it as
proof that the title of the 2007 talk had been right to call the weakness in
the standard and algorithm a backdoor.
But Paul Kocher, president and chief scientist of Cryptography Research, says
that regardless of the lack of evidence in the Times story, he discounts the
bad cryptography explanation for the weakness, in favor of the backdoor
Bad cryptography happens through laziness and ignorance, he says. But in
this case, a great deal of effort went into creating this and choosing a
structure that happens to be amenable to attack.
Whats mathematically creative [with this algorithm] is that when you look
at it, you cant even prove whether there is a backdoor or not, which is very
bizarre in cryptography, he says. Usually the presence of a backdoor is
something you can prove is there, because you can see it and exploit it. In
my entire career in cryptography, Ive never seen a vulnerability like this.
National Security Agency headquarters, Fort Meade, Maryland. Photo: Wikipedia
Its not the first time the NSA has been accused of installing backdoors.
Crypto trapdoors, real and imagined, have been part of NSA lore for decades.
In some ways the current controversy echoes the long-ago debate over the
first U.S. Data Encryption Standard in the 1970s. The NSA was widely
suspected of weakening DES to make it more crackable by the agency by
tinkering with a table of numeric constants called an S-Box and shortening
the algorithms key length. In 1994, though, the NSA was exonerated when it
turned out that the agency had actually changed the S-Box numbers to harden
DES against a code-breaking technique that had been known only within NSA at
the time.
In 1995, another case came up that seemed to confirm suspicions about the
NSA. The Baltimore Sun reported that year that the NSA had inserted a
backdoor into cryptographic machines made by the respected Swiss company
Crypto AG, apparently substantiating longstanding rumors to that effect.
Then in 1999, Microsoft inadvertently kicked off another controversy when it
leaked its internal name for a cryptographic signing key built into Windows
NT. The key was called _NSAKEY, spawning speculation that Microsoft had
secretly given the agency the power to write and sign its own updates to
Windows NTs crypto engine. Microsoft said this was incorrect, that the key
was an internal Microsoft key only and that it was called _NSAKEY because
the NSA was the technical reviewing authority for U.S. export controls. The
key was part of Microsofts compliance with U.S. export laws.
Suspicions about the NSA and backdoors were lingering in 2006 when Shumow and
Ferguson began looking at Dual_EC_DRBG after NIST approved it for inclusion
in a standard (.pdf). The standard discussed four federally sanctioned random
number generators approved for use in encrypting government classified and
unclassified-but-sensitive communication.
Each of the four algorithms was based on a different cryptographic design
family. One was based on hash functions, one on so-called HMAC (hash-based
message authentication code), one on block ciphers and the fourth one was
based on elliptic curves. The NSA had been pushing elliptic curve
cryptography for a number of years, and it publicly championed the last one 
Dual_EC_DRBG  to be included in the standard.
Elliptic curve algorithms are based on slightly different mathematics than
the more common RSA algorithm, and the NSA believes theyre the future of
cryptography, asserting that elliptic curve algorithms are smaller, faster
and offer better security.
But as Shumow and Ferguson examined the properties of the elliptic curve
random number generator in the standard, to determine how to incorporate it
into the Windows operating system, a couple of strange things stood out.
First, the random number generator was very slow  two to three orders of
magnitude slower than another algorithm in the standard.
Second, it didnt seem to be very secure.
There was a property [in it] that seemed to make the prediction-resistance
of the algorithm not what you would necessarily want it to be, the Microsoft
manager says. In non-geek speak, there was a weakness that made the random
number generator not so random.
Good random number generation is at the core of encryption, and a weak RNG
can undo the entire encryption system. Random number generators play a role
in creating cryptographic keys, in opening secure communications between
users and web sites and in resetting passwords for email accounts. Without
assured randomness, an attacker can predict what the system will generate and
undermine the algorithm.
Shumow and Ferguson found that the obstacles to predicting what the random
number generator would generate was low. It wasnt a catastrophic problem,
but it seemed strange for a security system being promulgated by the
Then they noticed something else.
The standard for implementing the algorithm included a list of constants 
static numbers  that were used in the elliptic curve on which the random
number generator was based. Whoever generated the constants, which served as
a kind of public key for the algorithm, could have generated a second set of
numbers at the same time  a private key.
Anyone possessing that second set of numbers would have whats known in the
cryptography community as trapdoor information  that is, they would be
able to essentially unlock the encryption algorithm by predicting what the
random number generator generated. And, Shumow and Ferguson realized, they
could predict this after seeing as few as 32 bytes of output from the
generator. With a very small sample, they could crack the entire encryption
system used to secure the output.
Even if no one knows the secret numbers, the fact that the backdoor is
present makes Dual_EC_DRBG very fragile, cryptographer Bruce Schneier wrote
at the time, in a piece for WIRED. If someone were to solve just one
instance of the algorithms elliptic-curve problem, he would effectively have
the keys to the kingdom. He could then use it for whatever nefarious purpose
he wanted. Or he could publish his result, and render every implementation of
the random-number generator completely insecure.
No one knew who had produced the constants, but it was assumed that because
the NSA had pushed the algorithm into the standard, the agency had generated
the numbers. The spy agency might also, then, have generated a secret key.
Schneier called it scary stuff indeed, but he also said at the time that it
made no sense as a backdoor, since it was so obvious to anyone who looked at
the algorithm and standard that there was this flaw in it. As a result,
developers of web sites and software applications wouldnt use it to help
secure their products and systems, he said.
But in fact, many developers did use it.
The U.S. government has enormous purchasing power, and vendors soon were
forced to implement the suspect standard as a condition of selling their
products to federal agencies under so-called FIPS certification requirements.
Microsoft added support for the standard, including the elliptic curve
random-number generator, in a Vista update in February 2008, though it did
not make the problematic generator the default algorithm.
Asked why Microsoft supported the algorithm when two of its own employees had
shown it to be weakened, a second Microsoft senior manager who spoke with
WIRED said that while the weakness in the algorithm and standard was weird
it wasnt a smoking gun. It was more of an odd property.
Microsoft decided to include the algorithm in its operating system because a
major customer was asking for it, because it had been sanctioned by NIST, and
because it wasnt going to be enabled as the default algorithm in the system,
thus having no impact on other customers.
In fact it is nearly impossible for any user to implement or to get this
particular random number generator instantiating on their machines without
going into the guts of the machine and reconfiguring it, he says.
Other major companies, like Cisco and RSA, added it as well. NIST in fact
provides a lengthy list of companies that have included it in their
libraries, though the list doesnt say which companies made it the default
algorithm in their library or which products have been developed that invoke
the algorithm.
A Cisco spokesman told WIRED that the algorithm was implemented in its
standard crypto library around mid-2012, a library that is used in more than
120 product lines, but the algorithm is not the default, and the default
algorithm cannot be changed by users. The company is currently completing an
internal audit of all of its products that leverage the NIST standard.
RSA, however, made the algorithm the default in its BShare toolkit for Java
and C developers until this week when it told WIRED that it was changing the
default following the renewed controversy over it. The company sent an
advisory to developer customers strongly urging them to change the default
to one of a number of other random number generator algorithms RSA supports.
RSA also changed the default on its own end in BSafe and in an RSA key
management system. The company is currently doing an internal review of all
of its products to see where the algorithm gets invoked in order to change
RSA actually added the algorithm to its libraries in 2004 or 2005, before
NIST approved it for the standard in 2006 and before the government made it a
requirement for FIPS certification, says Sam Curry, the companys chief
technology officer. The company then made it the default algorithm in BSafe
and in its key management system after the algorithm was added to the
standard. Curry said that elliptic curve algorithms were all the rage at the
time and RSA chose it as the default because it provided certain advantages
over the other random number generators, including what he says was better
Cryptography is a changing field. Some algorithms go up and some come down
and we make the best decisions we can in any point in time, he says.A lot
of the hash-based algorithms were getting struck down by some weaknesses in
how they chose numbers and in fact what kind of sample set they chose for
initial seeding. From our perspective it looked like elliptic curve would be
immune to those things.
Curry says the fact that the algorithm is slower actually provides it with
better security in at least one respect.
The length of time that you have to gather samples will determine the
strength of your random number generation. So the fact that its slower
sometimes gives it a wider sample set to do initial seeding, he says.
Precisely because it takes a little longer, it actually winds up giving you
more randomness in your initial seeding, and that can be an advantage.
Despite the renewed controversy over the algorithm and standard, Microsoft
managers say they still dont think the weaknesses constitute an intentional
Callas agrees. He thinks it is simply bad cryptography that was included in
the standard to round-out the selection so that there would be at least one
elliptic curve algorithm in the standard.
But one advantage to having the algorithm supported in products like Vista 
and which may be the reason the NSA pushed it into the standard  is that
even if its not the default algorithm for encryption on a system, as long as
its an option on the system, an intruder, like the NSA, can get into the
system and change the registry to make it the default algorithm used for
encryption, thereby theoretically making it easy for the NSA to undermine the
encryption and spy on users of the machine.
Schneier says this is a much more efficient and stealth way of undermining
the encryption than simply installing a keystroke logger or other Trojan
malware that could be detected.
A Trojan is really, really big. You cant say that was a mistake. Its a
massive piece of code collecting keystrokes, he said. But changing a
bit-one to a bit-two [in the registry to change the default random number
generator on the machine] is probably going to be undetected. It is a low
conspiracy, highly deniable way of getting a backdoor. So theres a benefit
to getting it into the library and into the product.
To date, the only confirmation that the algorithm has a backdoor comes in the
Times story, based on NSA documents leaked by Edward Snowden, which the Times
and two other media outlets saw.
[I]nternal memos leaked by a former NSA contractor, Edward Snowden, suggest
that the NSA generated one of the random number generators used in a 2006
NIST standard  called the Dual EC DRBG standard  which contains a back door
for the NSA, the Times wrote.
An editorial published by the Times this weekend re-asserted the claim:
Unbeknown to the many users of the system, a different government arm, the
National Security Agency, secretly inserted a back door into the system
that allowed federal spies to crack open any data that was encoded using its
But all of the quotes that the Times published from the memos refer to the
NSA getting the standard passed by an international standards body; they do
not say the NSA intentionally weakened the algorithm and standard, though the
Times implies that this is what the memos mean by tying them to the 2007
presentation by Shumow and Ferguson.
NIST has denied any knowledge of a backdoor and has also denied that the NSA
authored its standard. The institute has, however, re-opened the standard for
public comment as a result of the controversy and strongly urged against
using the algorithm in question until the matter could be resolved. The
public comments period will close Nov. 6.
Even without more explicit confirmation that the weaknesses in the algorithm
and standard constitute a backdoor, Kocher and Schneier believe they do.
It is extraordinarily bad cryptography, says Kocher. If you look at the
NSAs role in creating standards [over the years] and its general
cryptographic sophistication, none of it makes sense if there isnt a
backdoor in this.
Schneier agrees and says the NSA has done too many other things for him to
think, when he sees government-mandated crypto thats weak, that its just by
If we were living in a kinder world, that would be a plausible explanation,
he says. But were living in a very malicious world, it turns out.
He adds that the uncertainty around the algorithm and standard is the worst
part of the whole matter.
This is the worst problem that the NSA has done, Schneier says. They have
so undermined the fundamental trust in the internet, that we dont know what
to trust. We have to suspect everything. Were never sure. Thats the
greatest damage.

@_date: 2013-09-24 16:52:50
@_author: Eugen Leitl 
@_subject: Dissentr: A High-Latency Overlay Mix Network 
Note: This project was created as part of a 36-hour hackathon - and primarily as a proof of concept. While the ideas may be sound, and the prototype may work as designed, the protocols involved in this specific project have not been peer-reviewed, and so I cannot recommend that the network be used for anything requiring serious privacy.
A High-Latency Overlay Mix Network
Essentially, Dissentr is a security-minded network, inspired by Tor, with a few important characteristics which serve to differentiate it.
Tor is a low-latency network. This makes it ideal for real time activities like web browsing, but as a result, opens it up to attacks involving large-scale traffic analysis methods known as end-to-end correlation. In these attacks, an adversary with the ability to analyze massive amounts of traffic in a short period of time is able to match up traffic entering the network with the corresponding traffic which will inevitably soon exit it.
Dissentr manages to protect against these sorts of attacks by being engineered as a high-latency network. Assuming any given node has not been compromised, that node will intentionally hold off on forwarding its traffic to the next node in the network until it is able to forward a large amount of data in bulk, rendering the aforementioned end-to-end correlation far less feasible. For an excellent discussion on this attack, and possible countermeasures, see Practical Traffic Analysis: Extending and Resisting Statistical Disclosure.
Much like any mix network, Dissentr models its network as a graph of nodes, each responsible for handling the relay of traffic as it moves along some path through the network. Where Dissentr differs from a network such as Tor is in how this path is constructed. In Dissentr, the network is constructed out of cascades (A term I first heard described by Ian Goldberg, but I've been unable to pin down an original source for): essentially directed, acyclic sub-graphs, in which a node defines a set of "trusted" nodes, through which they are willing to relay traffic through. Dissentr simplifies this model by only allowing for nodes of out-degree 1, at this time. This construction brings about a number of useful results:
In the event that a node is known to be compromised, individual nodes are allowed the ability to either remove themselves from a cascade, or bypass untrusted nodes entirely, without the necessity of a trusted third-party.
The network is protected from "supernode invasions," in which an attacker floods the network with compromised nodes, in the hopes of either endangering the network's health, or placing the security of users passing through their nodes at risk of traffic interception, and subsequent analysis. This can be guaranteed because cascades are constructed by virtue of a measure of trust between node-operators, and so long as there exists some non-zero subset of trusted operators, they retain the ability to form a cascade of their own, effectively shutting out the efforts of such an attacker.
As mentioned previously, the high-latency nature of the network causes a shift in the sorts of activities best facilitated by its use, however, there do exist some unique opportunities which I have neither seen implemented in the context of a mix network, nor discussed in the literature.
A personal favourite idea revolves around creating a platform for political blogging, which, assuming a noisy enough network, would offer political dissidents the ability to freely write about issues of corruption or government abuse, without many of the risks associated with using a lower-latency network like Tor. If it takes a week for a blog post to appear in circulation after the author posts it to the network, it becomes magnitudes more difficult for any assailant to trace the authorship of that blog post - especially if that author never visited the website which hosts their content in the first place!
It also becomes a fairly trivial exercise to adapt the network to act as a mixing service for digital currency such as Bitcoin. Furthermore, by breaking the network into a number of smaller, disjoint networks for that purpose, one is be able to counter many of the current attacks which target existing mixing services.
I again emphasize that the cryptosystem in place is the result of a rather rushed 48-hour hackathon - in a production system, I would recommend implementing a peer-reviewed cryptosystem, such as the very lightweight Sphinx, or, pending their coming proof of security, the recently proposed Ibis. That being said, Dissentr works as follows:
Every node in the network maintains an RSA-keypair, with the public key being exposed to every node in a given cascade.
When a client wishes to send a message M through the network, they choose some cascade C.
For each node in the cascade, beginning with the exit node, and continuing through to the entrance node, the client generates an AES CFB128 key, which it uses to encrypt M. The key is then encrypted using that node's public RSA key.
M, now encrypted with AES CFB128 for every node in the cascade, is then passed to the entrance node along with the encrypted AES keys. The entrance node then uses its private RSA key to decrypt the AES key, so that it can subsequently decrypt M, yielding yet another cipher text.
This process is repeated for every node in the cascade, until the final node decrypts M to a plaintext, which it then handles accordingly.
Building and Running it
If, after all of my warnings, you still want to see it in action, it's dead-easy to get setup. All you'll need is Erlang installed (Tested on R16B02), along with Elixir. From there, you'll want to invoke the following from within Dissentr's directory, on every machine you want to host a node:
iex --sname {Any name, different per machine} --cookie {Any string, common between all machines} -S mix
This will stick you into a REPL, loaded with Dissentr's namespaces and dependencies. Sorry, there's no interface yet. From there, if you're using more than one machine, you'll want to link them all together, by running the following on every machine you want to host a node on. Since Erlang node connections are transitive, you won't have to do this for every pair of nodes.:
The hostname in question can be found in the iex prompt. Most likely it will be something at domain.
Now, just spawn a few nodes to create a network. I've got some temporary methods in place for making this easy, using some hardcoded keys stored in example_data/ for testing. Ideally, each node will be hosted on a different machine, but for testing purposes it doesn't matter. Within your prompt, execute the following:
Dissentr.Cascade.add_node(:node1, nil, 1)
Dissentr.Cascade.add_node(:node2, :node1, 2)
Dissentr.Cascade.add_node(:node3, :node2, 3)
Dissentr.Cascade.add_node(:node4, :node3, 4)
Dissentr.Cascade.add_node(:node5, :node4, 5)
Finally, to send an encrypted message, run the following, substituting the node and message as desired:
Dissentr.Cascade.mix(:node3, "Something, something, NSA")
If all went well, you should see a debug statement print out the plaintext message, on the machine which is hosting :node1

@_date: 2013-09-25 09:56:29
@_author: Eugen Leitl 
@_subject: DARK WALLET: A RADICAL WAY TO BITCOIN 
"radical", huh.
DARK WALLET: A RADICAL WAY TO BITCOIN
POSTED BY MICHAEL DEL CASTILLO
Cody Wilson is a twenty-five-year-old former law student at the University of
Texas at Austin. He is also the inventor of the Liberator, a gun made almost
entirely from plastic pieces created with a 3-D printer; he also uploaded to
the Internet a blueprint that anyone could use to print such a gun.
Wilson, who espouses libertarian views, created the blueprint to make a
point: information should be free. Not everyone agreed with him. In May,
after Wilson successfully fired the gun at a range near Austin and posted the
design online, the State Department requested that those files be removed
from the Web site of his nonprofit, Defense Distributed.
Wilson compliedbut not before the files had been downloaded two hundred
thousand times, igniting a debate about whether there should be limits to the
free flow of information over the Internet, and over the role of the
government in enforcing those restrictions.
Wilson lives in a utopian world in which contraband will be only a notional
concept, because enforcement will require policing ideas and blueprints, not
simply goods, Jacob Silverman wrote in a piece about Wilson and the
Liberator in May.
A native of Cabot, Arkansasa small suburb of Little RockWilson said that
the State Departments action persuaded him to drop out of law school and
pursue revolutionary activities full-time. In fact, he had been planning his
next endeavor for a while. When Indiegogo, a crowdfunding site, booted
Defense Distributeds campaign in August, 2012, for violating its terms of
serviceIndiegogo said the project related to the sale of firearms; Wilson
said it was for the creation of informationWilson began to raise money by
asking people to support him using a currency called Bitcoin: encrypted,
difficult-to-trace bits of code that function like cash and can be exchanged
over the Internet without a bank or a PayPal account.
Wilson said that he eventually raised two hundred bitcoins for the
Liberatorthe equivalent of twenty-seven thousand dollars, according to the
current exchange rate. His efforts attracted the attention of a
twenty-five-year-old Brit named Amir Taaki, who e-mailed him with an
invitation to speak at the Bitcoin 2012 Conference, in London. He accepted.
Wilson and Taaki met in person for the first time in January of 2013, when
Taaki took Wilson to visit a workspace for hackers is Bratislava, Slovakia,
and to anarchist squats in London. They reconnected in Berlin that July and
began hashing out a plan to use the as of yet unregulated, untaxed, nearly
untraceable currency in a way that would, like the Liberator, undermine the
ability of governments to regulate the activities of their citizens.
In the Bitcoin world, where banks no longer serve as intermediaries between
people and their money, bank accounts have been replaced by online wallets
that people can use to virtually store and send bitcoins.
Wilson and Taakis project, tentatively known as Dark Wallet, is a simple
wallet designed to be easier to use for people who arent tech-savvy; they
hope that in turn accelerates the currencys rate of adoption around the
world. The wallet will be open-source and free to use. Eventually, Wilson and
Taaki hope to create a vast stable of Bitcoin-related tools.
The goal, for Wilson, is similar to what he tried to do with the Liberator:
use technology to remove government intervention from his life, and from the
lives of like-minded people.
Unlike many current Bitcoin wallets, which can be difficult to download and
cumbersome to use, Wilson and Taaki are designing Dark Wallet, they told me,
as an easy-to-install plug-in that sits discreetly on users Chrome or
Firefox browsers. Made for Windows, Mac, and Linux computers, Dark Wallet
would move most of the energy-sucking process of insuring theres only one of
each bitcoin in circulation, and that they arent spent in two places at the
same time, to separate servers.
Wilson still lives in Austin, working remotely on Dark Wallet with Taaki, who
lives in an anarchist compound called Calafou, outside of Barcelona, and
writes most of the code behind the wallet. Taaki and Vitalik Buterin, the
co-founder of Bitcoin Magazine, a periodical covering the currency, are part
of a Calafou-based organization called unSystem, which came up with the idea
for the wallet; theyre working with a team of developers from around the
world. Wilson, who will manage the development team behind Dark Wallet,
making sure they meet their targets on time, is also producing a video and
other material for a crowdfunding campaign to raise money for the project.
Dark Wallet should be ready sometime in January or February of 2014, Taaki
said, though hes not committing to anything. Itll launch when its ready,
he said. And the details of an upcoming crowdfunding campaign have still yet
to be solidified, though Taaki and Wilson expect it to launch sometime in
The person or group that, in 2008, created Bitcointhat is, released the
protocol that defined what Bitcoin would becalled itself Satoshi Nakamoto.
The online comments that Satoshi Nakamoto made before disappearing
completely, in 2012, indicate that the creator of Bitcoin, like Wilson, was
deeply mistrustful of economic institutions and designed the currency to be
intentionally subversive.
Bitcoin is created, or mined, as its called, by powerful computers that
race to solve complex math problems and are rewarded for their work with the
encrypted code that is a bitcoin. Today there are 11.7 million of the coins
in existence, worth an estimated $1.6 billion, though their value fluctuates
dramatically. Nakamoto set the number of coins entering circulation to halve
every four years until 2140, when they will plateau at twenty-one million
coins and never be produced again.
Because no one can arbitrarily decide to print more bitcoins, and because no
banks intermediate the storage and spending of the currency, the value of a
bitcoin is determined by market demand. Wilson finds this very attractive.
But where a currency exists, capitalism will inevitably find it. In recent
months, Bitcoin has caught the attention of entrepreneurs, many funded by
venture-capital firms, who have begun building Bitcoin-related start-ups. The
companies include exchanges where people can trade bitcoins, along with
services that let people store and spend the currency in places ranging from
Amazon-style online markets to brick-and-mortar bars and restaurants.
The mainstream entrepreneurs who are interested in Bitcoin have found a haven
in a nonprofit called the Bitcoin Foundation. Writing about Bitcoin in April,
Maria Bustillos described its executives as a rational and sober group of
adult administrators who stand in contrast with the image of Bitcoin users
as wild-eyed kids camping out in half-deserted lofts. Members of the
foundation met in August with several federal agencies, including the Federal
Reserve, the F.B.I., and the Secret Service. On the surface, the meeting was
an educational exercise, meant to explain how Bitcoin works, but many
observers assume it was a step toward regulating the currency.
The foundation, which celebrates its first anniversary this month, calls
itself an advocacy group dedicated to serving the business, technology,
government relations, and public affairs needs of the Bitcoin community. One
goal, according to Jon Matonis, its executive director of the Bitcoin
Foundation, is to educate both public and private interestsincluding the
governmentabout how the currency operates. (The Foundation is not
pro-regulation as some have claimed, but it is pro-education, Matonis has
written, adding that he supports bitcoin education for legislative and
regulatory entities and that lobbying on behalf of Bitcoin is not
necessarily anti-market.)
Wilson, not surprisingly, sees working with the government as a betrayal of
Bitcoins fundamental purpose. The public faces of Bitcoin are acting as
counter-revolutionaries, he told me. Theyre actively working to try to
diffuse it, and to pollute it. He was referring, he said, not only to the
Bitcoin Foundation but to venture capitalists and entrepreneurs in New York
and Silicon Valley who increasingly embrace the currency as a way to profit,
but dont share his revolutionary aims. (Matonis said he is aware of Wilsons
concerns. I dont see my role as advancing crony capitalism, he said.)
Wilson believes Bitcoin should remain the backbone of a separate economy that
undermines the governments ability to collect taxes and to control the value
of currencynot be subsumed into the mainstream economy.
The state is basically allowed because we have all chosen to use these
certain institutions to channel our activity and commerce, he told me. But
when we are enabled, through alternative means and technologies, to channel
our commerce as we will, channel our production as we will, the state simply
Not everyone agrees, of course, that society would benefit from the
disappearance of governments. Wilson used the Liberator to make the point
that the government shouldnt regulate the flow of information; he wants to
use Bitcoin to help build an economy outside of the governments reach.
But his ideology, taken to its logical conclusion, would also leave services
like roads, libraries, fire fighting, and policing in the hands of the
private sectorwhose interests may not be aligned, Wilsons critics argue,
with those of the public at large.
Wilson knows that he could see blowback for his stance against the
foundation: as a self-described crypto-anarchist, perhaps he shouldnt be
so concerned with who is or isnt determining the currencys future. And if
the U.S. government attempts to regulate the currency, which seems likely,
Wilson will also find himself once again in direct opposition to the
Wilson and the suit-and-tie-wearing people at the Bitcoin Foundation share a
common interest in bringing Bitcoin to as many people as possible. The
foundation seems willing to play nicely with the establishment, and has been
open to hearing about the interests of old-school players like venture
capitalists and government regulators. Wilson, however, who was only recently
firing an illicit gun into the desert, isnt looking only for a new currency
but for another way to liberate himselfand othersfrom government oversight.
Michael del Castillo is the technology and innovation reporter at Upstart
Business Journal, a member of American City Business Journals, which is a
sister publication to Cond Nast. A graduate of Columbia University, he is
also the cofounder of Literary Manhattan, a nonprofit dedicated to promoting
Manhattans literary community and creating new ways to appreciate
Illustration by Grafilu.

@_date: 2013-09-25 14:18:08
@_author: Eugen Leitl 
@_subject: [Cryptography] Hardware Trojan Protection 
On 9/22/13 at 6:07 PM, leichter at lrw.com (Jerry Leichter) wrote in
another thread:
You might get a reasonable level of protection implementing the core
of the crypto operations in a hardware security module (HSM) using
Field Programmable Gate Arrays (FPGA) or Complex Programmable Logic
Device (CPLD). There is an open source set of tools for programming
these beasts based on Python called MyHDL . The EFF DES
cracker may have some useful ideas too.
The largest of these devices are also pressing the current chip
limits. There isn't a lot of extra space for Trojans. In addition,
knowing what to look at is somewhat difficult if pin assignments etc
are changed from chip to chip at random.
As with any system, there are tool chain issues. Open source helps,
but there is always the Key Thompson attack. The best solution I can
think of is to audit the output. Look very carefully at the output of
the tool chain, and at the final piece that loads the configuration
data into the device.
Cheers - Bill

@_date: 2013-09-25 22:21:00
@_author: Eugen Leitl 
@_subject: The Compromised Internet 
About your only choices are hams or (slightly higher budget)
microsats with onboard flash and DTN (notice you can deliver
packets during flyby). Hams also do launch microsats,
so there's some overlap. I've been waiting for consumer
phased arrays, just saw Locata VRay today -- perhaps not
for much longer now. Prime your phased array with s00per-s3kr1t
sat ephemerides, and you're good to go. Really hard to
jam, too -- optical ones impossible to jam, even.
For very high latency you could just use a global sneakernet.
 has some numbers. You could probably
already run stock Usenet over uucp over that.

@_date: 2013-09-25 22:45:25
@_author: Eugen Leitl 
@_subject: The Compromised Internet 
It's not mathematics, it's braindead algorithms. Geographic routing
needs no admin chatter. You only need to handle the edge cases.
Notice that 40 GBit/s fiber WAN is low end, while your LoS WLAN will
have trouble transporting even 10 MBit/s in adverse weather.

@_date: 2013-09-26 08:19:00
@_author: Eugen Leitl 
@_subject: [cryptography] The Compromised Internet 
Here's a potentially disruptive technology for global communication
that bypasses the fiber infrastructure, and hence more difficult
to tap and almost impossible to disrupt by other means than
total orbit denial weapons.
NASA prepares to launch 600Mbps space laser system to replace conventional radio links
By Sebastian Anthony on August 29, 2013 at 10:05 am19 Comments
NASA is preparing to launch the Lunar Laser Communications Demonstration (LLCD), a testbed that will use lasers to send and receive data between Earth and the Moon. This will be the first time that NASA uses lasers instead of conventional S-band radio waves to communicate with spacecraft, allowing for massive data rates of up to 600 megabits per second, while also consuming much less power and requiring much smaller antennae. Ultimately, shifting to laser-based communications will allow NASA to receive much more data from spacecraft, allowing them to be outfitted with high-res cameras and other modern sensors that generate more data than S-band links can support.
Optical communications, as opposed to radio frequency (RF) communications (or simply radio), are desirable for three key reasons: Massive bandwidth, higher security, and lower output power requirements. All of these traits derive from the frequency of optical and radio waves. While S-band signals are in the 2-4GHz range (similar to your GSM, LTE, or WiFi link), the laser light used by the LLCD (near-infrared in this case) is measured in hundreds of terahertz. As a result, the wavelength of S-band signals is around 10cm, while near-infrared has a wavelength of just 1000nm  or about 100,000 times shorter. Not only can you cram a lot more data into into the same physical space, but theres also terahertz (compared to megahertz in the S band) of free, unlicensed space that can be used.
A diagram of the LLCD architecture
Because the wavelength is smaller, the sending and receiving antennae can also be a lot smaller, allowing for smaller/lighter spacecraft and much easier reception here on Earth. By the time a conventional RF signal arrives at Earth from outer space, the beam can cover an area as wide as 100 miles, requiring very large dish antennae (such as the Deep Space Network) to pick those signals up. Receiving laser signals, which are 100,000 times shorter, requires a much smaller dish. As a corollary, due to these beams being much tighter, theyre much harder for an enemy to snoop on, thus increasing security. Transmitting data via laser also requires less power than RF.
NASA's LLCD laser link diagram
The LLCD will be deployed upon the Lunar Atmosphere Dust Environment Explorer (LADEE), which is scheduled for launch in September. LADEE (which could be pronounced lay-dee or lad-ee, were not sure) will orbit the Moon, seeking to confirm whether the mysterious glow observed by Apollo astronauts was caused by dust in the lunar atmosphere. Thanks to the LLCD, NASA will have a 20Mbps uplink to LADEE (apparently 4,800 times faster than existing S-band uplinks), and LADEE will have a 600Mbps downlink to NASA (five times faster than current state-of-the-art lunar-distance links). The mission will only last for 30 days, after which, if its a success, NASA will launch the long-duration Lunar Communications Relay Demonstration (LCRD), which will hitch a ride aboard a commercial Loral satellite. The LCRD will allow NASA to perform further testing of space laser communications, with the hope of eventually replacing RF links in future spacecraft.
Moving forward, space laser communications will allow for the creation of spacecraft that are smaller, cheaper, and capable of more advanced functionality. With 600Mbps of downlink capacity, well be able to outfit spacecraft with high-resolution cameras and other advanced sensors that generate vast amounts of data  and view that data in real time, rather than waiting for the data to slowly dribble over the airwaves.

@_date: 2013-09-26 08:51:21
@_author: Eugen Leitl 
@_subject: Fwd: [cryptography] The Compromised Internet 
This was an off-list exchange actually, but what the hell.
LEO is a volume, not a surface. You can have as many flocks up
there as you like, if you can afford it.
I'm optimizing against people who walk up, and dismantle your
wireless mesh, or down the Internet in your country. It's really
hard to jam the sky, especially in VIS range.
Yes, you can fry them with ground laser or fill up orbit
with tungsten pellets. However, such things are quite frowned
upon, especially the latter option.
Surprise me.

@_date: 2013-09-26 16:17:09
@_author: Eugen Leitl 
@_subject: Fwd: [cryptography] The Compromised Internet 
If the VPN bridges go down, you're back to mice and pumpkins.
There are obvious values in urban-area public meshes, and long
distance WLAN, but it's no way to deliver messages globally,
even as simple as texting equivalent. The buck does definitely
stop when surf is lapping at your toes.
What is exactly is wrong with frequent fliers carrying
smartphones with or similar?
You need to track a given small, rapidly moving patch of sky in realtime, whether by parabol dish, amateur astronomic instrument, or phased array flat plate or half-dome. The bird is serving hundreds or thousands people ground-side as it passes by. If you really want to jam all these
at the same time you'll need a nuke.
Taking out the bird from the ground turns a game of
cat and mouse, if you're dumping phonesats by the
satbusload -- these are short-lived, anyway, and need
to be constantly replenished. Orbital denial against small cross-section targets in a really low orbit which can be replenished cheaply will make every country with space access very mad at you, which is dangerous to your None of the approaches are mutually exclusive.
Use meshes, link them up via VPN tunnels across
Internet, use DTN with avian carriers, or phonesats.

@_date: 2013-09-26 17:02:18
@_author: Eugen Leitl 
@_subject: Fwd: [cryptography] The Compromised Internet 
They want to pick up a parabolic dish, a LoS laser or a
phased array tracking a point source overhead, all sending
at maybe 5-10 W power? Sure, if your sky is thick with mapping drones. Sounds like
a fifth world problem.
Isotropic radiators with high power are easy to spot.
Dynamic tight beams need at least a passing point of alignment
to get a position fix on the ground station. NSA sigint
used that microwave LoS interception, but this wouldn't
scale for millions of users and very brief low-power
bursts during random alignment events.
Or maybe you just buy  or the lower-grade
gear for LoS.
Phased arrays which are flat or half domes are compact and don't
look like anything from air. If you're clever, you can integrate
these into a PV panel.

@_date: 2013-09-26 17:50:39
@_author: Eugen Leitl 
@_subject: sneakernet calculation 
You overestimate the amount of useful content the Internet
carries. Let's assume you just want to deliver text messages
hand-entered by people. Let's say 10^9 people/day care to enter some ~kByte of text. That's a mere TByte/day, uncompressed.

@_date: 2013-09-27 13:52:19
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
Hash: SHA1
DLP (data loss prevention) products usually have MITM capability, to
make sure that proprietary information isn't being exfiltrated.  Also,
some companies have full packet capture policies.  The technology is
out there and people buy and use it.  Whether or not they're going to
care about Bitcoin URIs in the short term, I don't know.
Some of the companies documented here have such products:
You are correct in that the incentive to carry out MITM attacks in
this use case may not be there.  However, detecting transactions may
be more useful to an attacker than meddling with them.

@_date: 2013-09-27 16:53:39
@_author: Eugen Leitl 
@_subject: What the heck is going on with =?utf-8?Q?N?= 
zs-p2p
What the heck is going on with NISTs cryptographic standard, SHA-3?
by Joseph Lorenzo Hall [1]
September 24, 2013
(Warning: this is a fairly technical post about cryptographic standards
The cryptographic community has been deeply shaken since revelations earlier
this month [2] that the National Security Agency (NSA) has been using a
number of underhanded methods  stealing encryption keys, subverting
standards setting processes, planting backdoors in products  to undermine
much of the encryption used online. This includes crucial pieces of
e-commerce like HTTPS (SSL/TLS) and Virtual Private Networks (VPN) that we
use each day to purchase things online, to socialize in private, and that
businesses use to communicate confidential and proprietary information. While
the reporting has been vague and hasnt pointed to specific software versions
or protocols that have been compromised, last week RSA Security  a major
supplier of cryptographic software and hardware  initiated a product recall
[3] of sorts, warning users that one of its popular software encryption
products contained a likely NSA-planted backdoor. The practical implication
of the RSA recall is that much of the encryption that used this product since
2007 isnt nearly as secure as it was supposed to be.
Those of us who follow developments in the cryptographic community have
noticed another troubling development: there are a number of cryptographers
upset with how the National Institute of Standards and Technology (NIST) is
standardizing a new set of encryption algorithms called SHA-3 (which stands
for the third version of the Secure Hashing Algorithm). The remainder of this
post explains what is going on with SHA-3 and how NIST could diffuse this
particular controversy while it still has the chance.
(Warning: In this post, Im assuming the reader is familiar with the concepts
underlying basic encryption tools, called cryptographic primitives, such as
hash functions [4], digital signatures [5], and message authentication codes
What is SHA-3?
SHA-3 is the next generation hash algorithm being standardized by NIST. In
2005, researchers developed an attack [7] that called into question the
security guarantees of an earlier secure hash algorithm, SHA-1. The
characteristics of this 2005 attack seemed to hint that it could be refined
to attack many of the secure hash functions at the time, including SHA-0,
MD4, MD5 and even SHA-2. At the time, for many cryptographers, the message
was clear: a new hash algorithm is needed and it should be based on
completely different underlying mathematics that are not susceptible to the
attacks threatening known hash functions. To be clear: SHA-1 is thought to be
on its way out, as people expect the earlier attacks to be improved
considerably in the coming years and there hasnt been any result that calls
into question the soundness of SHA-2 at all. Attacks always improve, so its
imperative that there is an alternative hash function ready to go when and if
the floor falls out of the earlier hash functions.
NISTs cryptographic technology group [8] is world-renowned for cryptographic
algorithm standardization. In 2007, NIST began the process to develop and
standardize a new secure hash algorithm that would be called SHA-3. The
process for choosing a new algorithm was designed as a competition: new
candidate algorithms were submitted by more than 60 research teams and over
five years the entrants were whittled down to a set of finalists, from which
a winner was chosen. In October of last year, NIST announced [9] that a team
of Italian and Belgian cryptographers had won the competition with their
submission named, Keccak (pronounced KECH-ack).
What has NIST done with SHA-3?
Since the announcement of Keccak as the winner, NIST has been working hard to
turn Keccak into a standard. That is, NIST cant just point to the academic
paper and materials submitted by the Keccak team and call that a standard.
NIST has to write the algorithm up in a standards-compliant format and
include it in other NIST cryptographic standards documents, such as a
successor to the Secure Hash Standard document (FIPS Publication 180-4) [10].
Heres where the controversy starts.
One of the most accomplished civilian cryptographers, NISTs John Kelsey,
gave an invited talk at a conference in August, the Workshop on Cryptographic
Hardware and Embedded Systems 2013 (CHES13) [11], where he described some of
the changes NIST has made to Keccak in turning it into a standard. The
changes were detailed in five slides (slides 44-48) of Kelseys slide deck
for his talk [12]. Two major changes puzzled some in attendance:
In the name of increased performance (running faster in software and
hardware), the security levels of Keccak were drastically reduced. The four
versions of the winning Keccak algorithm had security levels of 224-bits,
256-bits, 384-bits, and 512-bits. However, from Kelseys slides, NIST intends
to standardize only two versions, a 128-bit and a 256-bit version.  Some of
the internals of the algorithm had been tweaked by NIST  some in cooperation
with the team that submitted Keccak  to improve performance and allow for
new types of applications.  Essentially, NIST had changed Keccak to something
very different from what won the 5-year competition. Since this talk,
cryptographers have been abuzz with this news and generally very critical of
the changes (e.g., folks like Marsh Ray on Twitter [13]).
What are the issues with SHA-3 standardization?
So, whats the big deal? Well, the problems here cluster in five areas:
Process: From a simple due process perspective, after a five-year hard-fought
competition, to make large changes to the winning algorithm is simply
problematic. The algorithm being standardized is very different from the
winning Keccak, which beat 62 other high-powered cryptography research groups
in a 5-year competition. (To be fair, its not like these changes came out of
the blue. However, given the new political environment reality itself has
changed.) No security improvement: The SHA-3 version of Keccak being proposed
appears to provide essentially the same level of security guarantees as
SHA-2, its predecessor. If we are going to develop a next generation hash,
there certainly should be standardized versions that provide a higher
security level than the older hash functions! NIST, in the original call for
submissions, specifically asked for four versions in each submission, with at
least two that would be stronger than what was currently available, so its
hard to understand this post-competition weakening.  Unclear implications of
internal changes: The changes made to Keccak to get to SHA-3 may be so
substantial as to render the cryptanalysis that was performed during the
competition moot. That is, all the intense number crunching cryptographers
performed during the competition to try and break the submitted ciphers to
prove their strength/weakness simply doesnt apply to the modified form of
Keccak that NIST is working on.  No real need for high-performance hashes:
NIST said it weakened the security levels of the winning Keccak submission to
boost performance. (Weaker versions of hash functions run faster.) However,
there is not clearly a need for another fast hash algorithm. For example, to
get exceedingly technical for a moment: in communications security, hashes
are used for a few purposes and most are computed on small inputs  where
performance isnt a concern  and in cases where performance is a concern due
to large inputs (e.g., with message authentication codes or MACs), many
applications are moving away from hash-based MACs (HMAC) to other types of
MACs like GMAC [14] that are not based on hash functions.  NISTs reputation
is undermined: Kelseys CHES13 talk was given in mid-August, two weeks
before the NSA encryption revelations. Those revelations [2] suggest that
NSA, through an intelligence program called BULLRUN actively worked to
undermine NISTs effort to standardize strong cryptography. NIST could not
have known how the changes it made might appear once that reporting had cast
a pall over NIST cryptographic standards setting. The changes made to Keccak
undoubtedly weaken the algorithm, calling NISTs motives into question in
light of the NSA revelations (regardless of their actual intentions).  None
of this is irreversible.
What could NIST do to diffuse this controversy?
Kelseys slides indicate that NIST is on track to standardize the
NIST-modified version of Keccak as SHA-3 and issue a draft standard in late
October for public comment. If the issues above are not addressed in that
draft standard, there will be considerable hue and cry from the cryptographic
community and it will only serve to reinforce the more general concerns about
NISTs cooperation with the NSA. Its in no ones interest to feed the flames
of NIST scaremongering and we all have an interest in NIST as a trusted place
for science and standardization. In that spirit, there are a number of things
NIST can do to calm this storm (and please consider joining NISTs Hash Forum
[15] to discuss this further):
Add back high-security modes: NIST must ensure that SHA-3 has strong modes of
operation. NIST should at least add back in a 512-bit security level version
of Keccak so those users who want exceedingly high security and dont worry
as much about performance have a standardized mode that they can use. In
fact, if NIST is worried about performance, it probably makes sense to
standardize the as-submitted versions of Keccak (224, 256, 384, 512-bit
security levels) and add in a much weaker but high-performance 128-bit
version for those users who want to make that trade-off. This would be the
Kumbaya solution, as it would have five security levels with both the
NIST-modified versions and the as-submitted Keccak versions.  Justify
optimizations and internal changes: NIST has obviously made significant
internal changes to the Keccak algorithm. This means that the NIST-modified
Keccak and the winner of the SHA-3 competition are likely to be very
different. To be sure, there are probably some very good reasons for the
changes, but we dont know what they are, and it would be unfortunate to
learn them simply in the draft standard as published in October. Extensive
changes should technically be subject to the cryptanalysis that was brought
to bear during the actual competition. Unfortunately, it will be impossible
to muster the cryptographic scrutiny necessary to examine the NIST-modified
Keccak as the resources and teams that worked on this during the competition
are no longer available. Here, it makes sense for NIST to standardize both
the winning version of Keccak and NISTs optimized version (SHA-3-Opt
maybe?), so that implementers can have their pick of whether they want the
Keccak that was subject to the grueling competition or an improved version
that hasnt been subject to as much scrutiny.  Improve the standardization
process: No one doubts that NIST runs high-quality cryptographic
competitions. The many-year competitions that resulted in AES (the Advanced
Encryption Standard) and SHA-3 marshaled the most gifted cryptographic
thinkers in the world to shake down very exotic forms of mathematics to
result in very strong, clever and useful practical outcomes. The resulting
algorithms look indistinguishable from magic to many of us who are not
steeped in the fine art of cryptography. However, the process of getting from
the algorithm that won the competition to a standard is a dark and mysterious
process, and it need not be. While the relationship between NSA and NIST has
always made many of us uneasy, in light of recent revelations, its
especially important that this standardization step be open and transparent
with a formal process that works to ensure that all decisions are made in a
well-documented manner and that conditions that ensured an algorithm
withstood withering scrutiny during a competition do not subsequently change
dramatically during the standardization process.  At CDT, we work hard to
make sure that standards processes serve the public interest in an open, free
and innovative Internet. Well be advocating for changes in standards
processes at NIST so that it remains an unbiased, trusted, and scientific
venue for developing cybersecurity and cryptographic standards.
UPDATE [2013-09-24T17:41:24]: Changed title to better reflect that SHA-3 is
not an encryption standard but a hash function standard (without using "hash
function" in the title). Better qualified that SHA-1 is likely weak in the
face of government-level adversaries. Further update [2013-09-25T06:09:38]:
clarified that SHA-1 is essentially on its way out.
Copyright  2013 by Center for Democracy & Technology.
The content throughout this website that originates with CDT can be freely
copied and used as long as you make no substantive changes and clearly give
us credit. Details.
Source URL: [1] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15]

@_date: 2013-09-02 09:49:03
@_author: Eugen Leitl 
@_subject: [tor-talk] New paper : Users Get Routed: Traffic Correlation on Tor 
X-Mailer: Sylpheed 3.4.0beta4 (GTK+ 2.24.10; x86_64-pc-linux-gnu)
Reply-To: tor-talk at lists.torproject.org
Hi all,
Heads up on a new paper suggesting that its possible to unmask
Tor users using traffic correlation:
    Code here:
    Would be interested in hearing the opinions of the core Tor
develpoment team on this stuff.

@_date: 2013-09-03 13:16:43
@_author: Eugen Leitl 
@_subject: building a community on RetroShare 
One of my RS identities is
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: OpenPGP:SDK v0.9
-----END PGP PUBLIC KEY BLOCK-----
see you there.

@_date: 2013-09-04 15:22:03
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] 0.8.4 released, fixes critical 
Bitcoin-Qt version 0.8.4 is now available from:
  This is a maintenance release to fix a critical bug and three
security issues; we urge all users to upgrade.
There were no changes from 0.8.4 release candidate 2, so if you are running
0.8.4rc2 you do not need to upgrade.
Please report bugs using the issue tracker at github:
  How to Upgrade
An attacker could send a series of messages that resulted in
an integer division-by-zero error in the Bloom Filter handling
code, causing the Bitcoin-Qt or bitcoind process to crash.
Bloom filters were introduced with version 0.8, so versions 0.8.0
through 0.8.3 are vulnerable to this critical denial-of-service attack.
A constant-time algorithm is now used to check RPC password
guess attempts; fixes Implement a better fix for the fill-memory-with-orphan-transactions
attack that was fixed in 0.8.3. See
for a description of the weaknesses of the previous fix.
Bugs fixed
Fix multi-block reorg transaction resurrection.
Fix non-standard disconnected transactions causing mempool orphans.
This bug could cause nodes running with the -debug flag to crash.
OSX: use 'FD_FULLSYNC' with LevelDB, which will (hopefully!)
prevent the database corruption issues many people have
experienced on OSX.
Linux: clicking on bitcoin: links was broken if you were using
a Gnome-based desktop.
Fix a hang-at-shutdown bug that only affects users that compile
their own version of Bitcoin against Boost versions 1.50-1.52.
Other changes
Checkpoint at block 250,000 to speed up initial block downloads
and make the progress indicator when downloading more accurate.
Thanks to everybody who contributed to the 0.8.4 releases!
Pieter Wuille
Warren Togami
Patrick Strateman
Gregory Maxwell
Sergio Demian Lerner
Cory Fields
Matt Corallo
Gavin Andresen

@_date: 2013-09-04 22:12:40
@_author: Eugen Leitl 
@_subject: NSA Laughs at PCs, Prefers Hacking Routers and Switches 
NSA Laughs at PCs, Prefers Hacking Routers and Switches
BY KIM ZETTER09.04.136:30 AM
Photo: Santiago Cabezas/Flickr
The NSA runs a massive, full-time hacking operation targeting foreign
systems, the latest leaks from Edward Snowden show. But unlike conventional
cybercriminals, the agency is less interested in hacking PCs and Macs.
Instead, Americas spooks have their eyes on the internet routers and
switches that form the basic infrastructure of the net, and are largely
overlooked as security vulnerabilities.
Under a $652-million program codenamed Genie, U.S. intel agencies have
hacked into foreign computers and networks to monitor communications crossing
them and to establish control over them, according to a secret black budget
document leaked to the Washington Post. U.S. intelligence agencies conducted
231 offensive cyber operations in 2011 to penetrate the computer networks of
targets abroad.
This included not only installing covert implants in foreign desktop
computers but also on routers and firewalls  tens of thousands of machines
every year in all. According to the Post, the government planned to expand
the program to cover millions of additional foreign machines in the future
and preferred hacking routers to individual PCs because it gave agencies
access to data from entire networks of computers instead of just individual
Most of the hacks targeted the systems and communications of top adversaries
like China, Russia, Iran and North Korea and included activities around
nuclear proliferation.
The NSAs focus on routers highlights an often-overlooked attack vector with
huge advantages for the intruder, says Marc Maiffret, chief technology
officer at security firm Beyond Trust. Hacking routers is an ideal way for an
intelligence or military agency to maintain a persistent hold on network
traffic because the systems arent updated with new software very often or
patched in the way that Windows and Linux systems are.
No one updates their routers, he says. If you think people are bad about
patching Windows and Linux (which they are) then they are  horrible about
updating their networking gear because it is too critical, and usually they
dont have redundancy to be able to do it properly.
He also notes that routers dont have security software that can help detect
a breach.
The challenge [with desktop systems] is that while antivirus dont work well
on your desktop, they at least do something [to detect attacks], he says.
But you dont even have an integrity check for the most part on routers and
other such devices like IP cameras.
Hijacking routers and switches could allow the NSA to do more than just
eavesdrop on all the communications crossing that equipment. It would also
let them bring down networks or prevent certain communication, such as
military orders, from getting through, though the Post story doesnt report
any such activities. With control of routers, the NSA could re-route traffic
to a different location, or intelligence agencies could alter it for
disinformation campaigns, such as planting information that would have a
detrimental political effect or altering orders to re-route troops or
supplies in a military operation.
According to the budget document, the CIAs Tailored Access Programs and
NSAs software engineers possess templates for breaking into common brands
and models of routers, switches and firewalls.
The article doesnt say it, but this would likely involve pre-written scripts
or backdoor tools and root kits for attacking known but unpatched
vulnerabilities in these systems, as well as for attacking zero-day
vulnerabilities that are yet unknown to the vendor and customers.
[Router software is] just an operating system and can be hacked just as
Windows or Linux would be hacked, Maiffret says. Theyve tried to harden
them a little bit more [than these other systems], but for folks at a place
like the NSA or any other major government intelligence agency, its pretty
standard fare of having a ready-to-go backdoor for your [off-the-shelf] Cisco
or Juniper models.
Not all of the activity mentioned in the budget document involved remote
hacking. In some cases, according to the document, the operations involved
clandestine activity by the CIA or military intelligence units to physically
place hardware implants or software modifications to aid the spying.
Much more often, an implant is coded entirely in software by an NSA group
called Tailored Access Operations (TAO), the Post writes in its story about
the document. As its name suggests, TAO builds attack tools that are
custom-fitted to their targets.
A handful of security researchers have uncovered vulnerabilities in routers
in recent years that could be used to do the kind of hacking described in the
budget document.
In 2005, security researcher Mike Lynn found a serious vulnerability in Cisco
IOS, the operating system running on millions of Cisco routers around the
Lynn discovered the vulnerability after his employer, Internet Security
Systems, asked him to reverse-engineer the Cisco operating system to see if
he could find security problems with it. Cisco makes the majority of the
routers that operate the backbone of the internet as well as many company
networks and critical infrastructure systems. The Cisco IOS is as ubiquitous
in the backbone as the Windows operating system is on desktops.
The vulnerability Lynn found, in a new version of the operation system that
Cisco planned to release at the time, would have allowed someone to create a
router worm that would shut down every Cisco router through which it passed,
bringing down a nations critical infrastructure. It also would have allowed
an attacker to gain complete control of the router to sniff all traffic
passing through a network in order to read, record or alter it, or simply
prevent traffic from reaching its recipient.
Once Lynn found the vulnerability, it took him six months to develop a
working exploit to attack it.
Lynn had planned to discuss the vulnerability at the Black Hat security
conference in Las Vegas, until Cisco intervened and forced him to pull the
talk under threat of a lawsuit.
But if Lynn knew about the vulnerability, there were likely others who did as
well  including intelligence agencies and criminal hackers.
Source code for Ciscos IOS has been stolen at least twice, either by
entities who were interested in studying the software to gain a competitive
advantage or to uncover vulnerabilities that would allow someone to hack or
control them.
Other researchers have uncovered different vulnerabilities in other Cisco
routers that are commonly used in small businesses and home offices.
Every year at computer security conferences  including the Black Hat
conference where NSA Director Keith Alexander presented a keynote this year 
U.S. intelligence agencies and contractors from around the world attend to
discover information about new vulnerabilities that might be exploited and to
hire talented researchers and hackers capable of finding more vulnerabilities
in systems.
In 2008, a researcher at Core Security Technologies developed a root kit for
the Cisco IOS that was designed to give an attacker a persistent foothold on
a Cisco router while remaining undetected.
According to the Post story, the NSA designs most of the offensive tools it
uses in its Genie operation, but it spent $25.1 million in one year for
additional covert purchases of software vulnerabilities from private
malware vendors who operate on the grey market  closed markets that peddle
vulnerabilities and exploits to law enforcement and intelligence agencies, as
opposed to the black market that sells them to cyber criminals.
The price of vulnerabilities and exploits varies, depending on a number of
factors. Vulnerabilities and exploits can sell for anywhere from $50,000 to
more than a million, depending on the exclusivity of the purchase  some
vulnerabilities are sold to multiple parties with the understanding that
others are using it as well  and their ubiquity. A vulnerability that exists
in multiple versions of an operating system is more valuable than a
vulnerability that exists in just one version. A class of vulnerability that
crosses multiple browser brands is also more valuable than a single
vulnerability that just affects the Safari browser or Chrome.
The Stuxnet cyber weapon that was reportedly created by the U.S. and Israel
to sabotage centrifuges used in Irans uranium enrichment program, used five
zero-day exploits to spread itself among systems in Iran, including a rare
exploit that attacked the .LNK function in multiple versions of the Windows
operating system in order to spread the worm silently via infected USB
Ubiquitous router vulnerabilities are difficult to find since there are so
many different configurations for routers, and an attack that works against
one router configuration might not work for another. But a vulnerability that
affects the core operating system is much more valuable since it is less
likely to be dependent on the configuration. Maiffret says there hasnt been
a lot of public research on router vulnerabilities, but whenever someone has
taken a look at them, they have found security holes in them.
Theyre always successful in finding something, he says.
Once a vulnerability becomes known to the software maker and is patched, it
loses a lot of its value. But because many users and administrators do not
patch their systems, some vulnerabilities can be used effectively for years,
even after a patch is available. The Conficker worm, for example, continued
to infect millions of computers long after Microsoft released a patch that
should have stopped the worm from spreading.
Routers in particular often remain unpatched because system administrators
dont think they will be targeted and because administrators are concerned
about network outages that could occur while the patch is applied or if the
patch is faulty.
Kim Zetter is a senior reporter at Wired covering cybercrime, privacy,
security and civil liberties.
Read more by Kim Zetter
Follow  and  on Twitter.

@_date: 2013-09-04 22:16:12
@_author: Eugen Leitl 
@_subject: [tor-talk] Exit node stats collection? 
Hash: SHA1
I do not know if this link has been posted yet, but this jumped out at
me this morning - it's a technique for correlating publically known
Tor nodes against hidden services:
Thoughts from the community?

@_date: 2013-09-05 12:05:49
@_author: Eugen Leitl 
@_subject: Content and popularity analysis of Tor hidden services 
Content and popularity analysis of Tor hidden services
July 29, 2013
Alex Biryukov
University of Luxembourg alex.biryukov at uni.lu
Ivan Pustogarov University of Luxembourg ivan.pustogarov at uni.lu
Ralf-Philipp Weinmann University of Luxembourg ralf-philipp.weinmann at uni.lu
Tor hidden services allow running Internet services while protecting the
location of the servers. Their main purpose is to enable freedom of speech
even in situations in which powerful adversaries try to suppress it. However,
providing location privacy and client anonymity also makes Tor hidden
services an attractive platform for every kind of imaginable shady service.
The ease with which Tor hidden services can be set up has spurred a huge
growth of anonymously provided Internet services of both types. In this paper
we analyse the landscape of Tor hidden services. We have studied Tor hidden
services after collecting 39824 hidden service descriptors on 4th of Feb 2013
by exploiting protocol and implementation aws in Tor: we scanned them for
open ports; in the case of HTTP services, we analysed and classified their
content. We also estimated the popularity of hidden services by looking at
the request rate for hidden service descriptors by clients. We found that
while the content of Tor hidden services is rather varied, the most popular
hidden services are related to botnets.
Tor, hidden services, port scanning, classification

@_date: 2013-09-05 13:19:33
@_author: Eugen Leitl 
@_subject: PayPal freezes MailPile's account 
Why, why did they keep 45 kUSD worth of funds in an
account run by known jerks? Friends don't let friends
use PayPal.

@_date: 2013-09-05 15:13:32
@_author: Eugen Leitl 
@_subject: US stops jailed activist Barrett Brown from discussing leaks 
US stops jailed activist Barrett Brown from discussing leaks prosecution
Federal court order prohibits Brown from talking to the media in what critics
say is latest in crackdown on investigative journalism
Ed Pilkington in New York
theguardian.com, Wednesday 4 September 2013 22.50 BST
Barrett Brown, Anonymous spokesman
Brown's lawyer says the gagging order is a breach of Brown's first amendment
rights. Photograph: Nikki Loehr
A federal court in Dallas, Texas has imposed a gag order on the jailed
activist-journalist Barrett Brown and his legal team that prevents them from
talking to the media about his prosecution in which he faces up to 100 years
in prison for alleged offences relating to his work exposing online
The court order, imposed by the district court for the northern district of
Texas at the request of the US government, prohibits the defendant and his
defence team, as well as prosecutors, from making "any statement to members
of any television, radio, newspaper, magazine, internet (including, but not
limited to, bloggers), or other media organization about this case, other
than matters of public interest."
It goes on to warn Brown and his lawyers that "no person covered by this
order shall circumvent its effect by actions that indirectly, but
deliberately, bring about a violation of this order".
According to Dell Cameron of Vice magazine, who attended the hearing, the
government argued that the gag order was needed in order to protect Brown
from prejudicing his right to a fair trial by making comments to reporters.
But media observers seen the hearing in the opposite light: as the latest in
a succession of prosecutorial moves under the Obama administration to
crack-down on investigative journalism, official leaking, hacking and online
Brown's lead defence attorney, Ahmed Ghappour, has countered in court
filings, the most recent of which was lodged with the court Wednesday, that
the government's request for a gag order is unfounded as it is based on false
accusations and misrepresentations.
The lawyer says the gagging order is a breach of Brown's first amendment
rights as an author who continues to write from his prison cell on issues
unconnected to his own case for the Guardian and other media outlets.
In his memo to the court for today's hearing, Ghappour writes that Brown's
July article for the Guardian "contains no statements whatsoever about this
trial, the charges underlying the indictment, the alleged acts underlying the
three indictments against Mr Brown, or even facts arguably related to this
The gag order does give Brown some room to carry on his journalistic work
from prison. It says that he will be allowed to continue publishing articles
on topics "not related to the counts on which he stands indicted".
Following the imposition of the order, Ghappour told the Guardian: "The
defense's overriding concern is that Mr Brown continue to be able to exercise
his first amendment right as a journalist. The order preserves that ability."
The lawyer adds that since the current defence team took over in May, Brown
has made only three statements to the media, two of which where articles that
did not concern his trial while the third ran no risk of tainting the jury
pool. "Defendant believes that a gag order is unwarranted because there is no
substantial, or even reasonable, likelihood of prejudice to a fair trial
based on statements made by defendant or his counsel since May 1, 2013."
Brown, 32, was arrested in Dallas on 12 September last year and has been in
prison ever since, charged with 17 counts that include threatening a federal
agent, concealing evidence and disseminating stolen information. He faces a
possible maximum sentence of 100 years in custody.
Before his arrest, Brown became known as a specialist writer on the US
government's use of private military contractors and cybersecurity firms to
conduct online snooping on the public. He was regularly quoted by the media
as an expert on Anonymous, the loose affiliation of hackers that caused
headaches for the US government and several corporate giants, and was
frequently referred to as the group's spokesperson, though he says the
connection was overblown.
In 2011, through the research site he set up called Project PM, he
investigated thousands of emails that had been hacked by Anonymous from the
computer system of a private security firm, HB Gary Federal. His work helped
to reveal that the firm had proposed a dark arts effort to besmirch the
reputations of WikiLeaks supporters and prominent liberal journalists and
activists including the Guardian's Glenn Greenwald.
In 2012, Brown similarly pored over millions of emails hacked by Anonymous
from the private intelligence company Stratfor. It was during his work on the
Stratfor hack that Brown committed his most serious offence, according to US
prosecutors  he posted a link in a chat room that connected users to
Stratfor documents that had been released online.
The released documents included a list of email addresses and credit card
numbers belonging to Stratfor subscribers. For posting that link, Brown is
accused of disseminating stolen information  a charge with media
commentators have warned criminalises the very act of linking.
As Geoffrey King, Internet Advocacy Coordinator for the Committee to Protect
Journalists, has put it, the Barrett Brown case "could criminalize the
routine journalistic practice of linking to documents publicly available on
the internet, which would seem to be protected by the first amendment to the
US constitution under current doctrine".
In its motion to the Dallas district court, US prosecutors accuse Brown and
his associates of having "solicited the services of the media or media-types
to discuss his case" and of continuing to "manipulate the public through
press and social media comments".
It further accuses Ghappour of "co-ordinating" and "approving" the use of the
media, and alleges that between them they have spread "gross fabrications and
substantially false recitations of facts and law which may harm both the
government and the defence during jury selection".
But Ghappour in his legal response has pointed out that several of the
specific accusations raised by the government are inaccurate. Prosecutors
refer to an article in the Guardian by Greenwald published on 21 March 2013
based partly on an interview between the journalist and Brown, yet as
Ghappour points out that piece was posted on the Guardian website before the
accused's current legal team had been appointed.
Under his legal advice, Ghappour writes, Brown has maintained "radio silence"
over his case and has given no further interviews, thus negating the
government's case for a gagging order.

@_date: 2013-09-05 15:16:35
@_author: Eugen Leitl 
@_subject: Spy Files: New WikiLeaks docs expose secretive, unruly surveillance 
Spy Files: New WikiLeaks docs expose secretive, unruly surveillance industry
Published time: September 04, 2013 16:06 Edited time: September 05, 2013 10:00 Get short URL
Screenshot from a leaked documentScreenshot from a leaked document
Central Asia, Information Technology, Intelligence, Internet, Middle East,
The growing surveillance industry complex is providing governments with
increasingly sophisticated spying software to track and control their
citizens, the latest documents obtained by the pro-transparency group,
WikiLeaks reveal.
A trove of documents, outlining the activities of dozens of companies
operating in the ever-expanding electronic snooping industry, were made
available by the pro-transparency group on Wednesday.
Lawful interception, mass monitoring, network recording, signals and
communication intelligence, and tactical interception devices were among the
services and products provided by a litany of Western based firms, as
outlined in hundreds of pages of documents covering trade brochures, internal
memos, and invoices. "WikiLeaks' Spy Files  is part of our ongoing commitment to shining a light
on the secretive mass surveillance industry. This publication doubles the
WikiLeaks Spy Files database, the accompanying press release cites Julian
Assange. The WikiLeaks Spy Files form a valuable resource for journalists
and citizens alike, detailing and explaining how secretive state intelligence
agencies are merging with the corporate world in their bid to harvest all
human electronic communication." One 2011 document showed how companies such as UK-based Gamma Group,
German-based Desoma and Swiss-based Dreamlab are working in concert to
create Telecommunications Intelligence Systems for different
telecommunications networks to fulfill the customers needs regarding
massive data interception and retention.
In March, Gamma International, which is a subsidiary of Gamma group, made
Reporters Without Borders 'Corporate Enemies of the Internet' list for 2013,
which singled out five digital mercenaries who sell their surveillance
technology to authoritarian regimes.
The firms FinFisher Suite (which includes Trojans to infect PCs, mobile
phones, other consumer electronics and servers, as well as technical
consulting), is considered to be one of the most sophisticated in the world.
During the search of an Egyptian intelligence agency office in 2011, human
rights activists found a contract proposal from Gamma International to sell
FinFisher to Egypt.
Bill Marczak, a computer science doctoral candidate at the University of
California, helped investigate the use of FinFisher spyware against activists
and journalists in Bahrain in 2012, as well as in other states.
We dont have any sort of contracts, so that we could see financial dealings
between companies and these governments. The only indications that we have as
to where the spyware has been used are based on the research. In cases that
weve seen the spyware has been targeted against activists and journalists in
a particular country. Weve been scanning the internet looking for this
technology. So we found, as I said, spywares in Bahrain. We saw it being
targeted against Bahraini journalists and activists last year. Weve also
found servers for the spyware in a number of other countries, such as
Turkmenistan, Qatar, Ethiopia, Marczak told RT.
RT was the only Russian broadcaster that collaborated with WikiLeaks in this
investigation, which also brought into the spotlight other companies
including Cobham, Amees, Digital Barriers, ETL group, UTIMACO, Telesoft
Technologies and Trovicor.
Trovicor, incidentally, also features among Reporters Without Borders
digital mercenaries. The firm, whose monitoring centers are capable of
intercepting phone calls, text messages, voice over IP calls (like Skype) and
Internet traffic, has also been accused by of helping Bahrain imprison and
torture activists and journalists.   Screenshot from a leaked documentScreenshot from a leaked document
While a smoking gun in the form of government contracts or invoices was not
forthcoming, internal documents discovered by WikiLeaks do confirm that the
firms dealings with autocratic states.
In a December 2010 correspondence between Nicolas Mayencourt, the CEO of
Dreamlab Technologies AG, and Thomas Fischer from Gamma Groups Germany-based
branch Gamma International GmbH, a quotation concerning the Monitoring
system for iproxy (infection proxy)-project is provided for an unspecified
end customer in Oman.
One concern involved keeping the client [Oman] aware of any changes made to
the proxy [intermediary] server infected with their software for the sake of
culling information from select targets.
During the integration tests in Oman in September 2010 the end customer
figured out that not all of the components of the iproxy infrastructure are
under their  full control. It is, for example possible that changes of the
Oman-network may occur without their knowledge. Thus, it might occur that
ISPs [Internet service providers] may modify some of the current
configuration. Therefore, the question arose whether it is possible to
identify such a modification in the network setup by monitoring the whole
iproxy infrastructure.
monitoring of the iproxy infrastructure including all components of the
systems was derived. This requirement is discussed and a proposal for
solution is described in this offer.
The infection process as was conducted on-site in Oman in 2010 can be
conducted in two different variants, as described in a separate document,
System Manual Project O, prepared for the Gulf client.
The first is described as a binary infection, whereby binaries (non-text
computer files) are infected after being downloaded by the configured target.
In order to do this, the software analyzes the data streams on the NDPs
[network data processors] at both of the Internet exchanges (IX). As soon as
a matching type of binary is downloaded, the infection mechanism is
initiated, then it attaches loader and payload (trojan) to the binary.
Screenshot from a leaked documentScreenshot from a leaked document
The second method is described as update infection, which works by sending
counterfeit server responses to predefined applications (for example iTunes,
Winamp, OpenOffice and SimpleLite), when they are searching for updates.
Data can be captured both through traditional public switch telephone
networks (PSTN), mobile providers and internet protocol suites across a range
of devices.
The users information, including his or her IP address, user name, [cell]
phone number, the date time and identity of the person being communicated
with, and the method or protocol (mail, WWW, Skype, chat, voice, fax, and
SMS) are all up for grabs.
Upon being captured, the data is stored in a Data Warehouse and retrieved
on command.
Quotations for the project, enumerated in Swiss francs (CHF), are broken down
in multiple categories:
Monitoring and alarming 83,355.00 Services provided by Dreamlab 34,400.00 Training 5,400.00 Annual solution maintenance 24,000.00 Redundant monitoring implementation 57,955.00 Services provided by Dreamlab for redundancy 5,760.00 Annual solution maintenance for redundant system 12,000.00 Note: 1 CHF = 1.06720 USD
Although such software does have legitimate applications for law enforcement,
it can easily be used to stifle civil society, as Marczak argues was the case
in Bahrain. Apart from journalists and activists, he noted that in the Malaysia and
Ethiopia, members of the political opposition were apparently being targeted
as well. One piece of FinFisher spyware discovered, for example, contained
details relating to the upcoming Malaysian elections.
You couldnt say exactly who was targeted against, but the use of
election-related content suggests politically motivated targeting. We also
found a sample of this spyware that appeared to be targeted at activists in
Ethiopia. The spyware contained a picture of Ethiopian opposition leaders
that was displayed when the user opened it. By opening the picture the user
copied the spyware, he said.

@_date: 2013-09-06 11:01:50
@_author: Eugen Leitl 
@_subject: [cryptography] regarding the NSA crypto "breakthrough" 
It is reported that the journalists deliberately withheld details
which are available in Snowden's original documents. Somebody
better leak these, fast.
The claims are that some code and magic constants have been weakened,
but also that NSA still has problems with some methods.
We need to know.
Obviously, as a short-term workaround there's fallback to
expensive/inconvenient methods like one-time pads, but long-term
we obviously need new cyphers. Not tainted by any TLA poison.

@_date: 2013-09-06 11:37:53
@_author: Eugen Leitl 
@_subject: The US government has betrayed the Internet. We need to take it back 
The US government has betrayed the Internet. We need to take it back
The NSA has undermined a fundamental social contract. We engineers built the
Internet  and now we have to fix it
Bruce Schneier
The Guardian, Thursday 5 September 2013 20.04 BST
Internet business cables in California.
'Dismantling the surveillance state won't be easy. But whatever happens,
we're going to be breaking new ground.' Photograph: Bob Sacha/Corbis
Government and industry have betrayed the Internet, and us.
By subverting the Internet at every level to make it a vast, multi-layered
and robust surveillance platform, the NSA has undermined a fundamental social
contract. The companies that build and manage our Internet infrastructure,
the companies that create and sell us our hardware and software, or the
companies that host our data: we can no longer trust them to be ethical
Internet stewards.
This is not the Internet the world needs, or the Internet its creators
envisioned. We need to take it back.
And by we, I mean the engineering community.
Yes, this is primarily a political problem, a policy matter that requires
political intervention.
But this is also an engineering problem, and there are several things
engineers can  and should  do.
One, we should expose. If you do not have a security clearance, and if you
have not received a National Security Letter, you are not bound by a federal
confidentially requirements or a gag order. If you have been contacted by the
NSA to subvert a product or protocol, you need to come forward with your
story. Your employer obligations don't cover illegal or unethical activity.
If you work with classified data and are truly brave, expose what you know.
We need whistleblowers.
We need to know how exactly how the NSA and other agencies are subverting
routers, switches, the Internet backbone, encryption technologies and cloud
systems. I already have five stories from people like you, and I've just
started collecting. I want 50. There's safety in numbers, and this form of
civil disobedience is the moral thing to do.
Two, we can design. We need to figure out how to re-engineer the Internet to
prevent this kind of wholesale spying. We need new techniques to prevent
communications intermediaries from leaking private information.
We can make surveillance expensive again. In particular, we need open
protocols, open implementations, open systems  these will be harder for the
NSA to subvert.
The Internet Engineering Task Force, the group that defines the standards
that make the Internet run, has a meeting planned for early November in
Vancouver. This group needs to dedicate its next meeting to this task. This
is an emergency, and demands an emergency response.
Three, we can influence governance. I have resisted saying this up to now,
and I am saddened to say it, but the US has proved to be an unethical steward
of the Internet. The UK is no better. The NSA's actions are legitimizing the
Internet abuses by China, Russia, Iran and others. We need to figure out new
means of Internet governance, ones that makes it harder for powerful tech
countries to monitor everything. For example, we need to demand transparency,
oversight, and accountability from our governments and corporations.
Unfortunately, this is going play directly into the hands of totalitarian
governments that want to control their country's Internet for even more
extreme forms of surveillance. We need to figure out how to prevent that,
too. We need to avoid the mistakes of the International Telecommunications
Union, which has become a forum to legitimize bad government behavior, and
create truly international governance that can't be dominated or abused by
any one country.
Generations from now, when people look back on these early decades of the
Internet, I hope they will not be disappointed in us. We can ensure that they
don't only if each of us makes this a priority, and engages in the debate. We
have a moral duty to do this, and we have no time to lose.
Dismantling the surveillance state won't be easy. Has any country that
engaged in mass surveillance of its own citizens voluntarily given up that
capability? Has any mass surveillance country avoided becoming totalitarian?
Whatever happens, we're going to be breaking new ground.
Again, the politics of this is a bigger task than the engineering, but the
engineering is critical. We need to demand that real technologists be
involved in any key government decision making on these issues. We've had
enough of lawyers and politicians not fully understanding technology; we need
technologists at the table when we build tech policy.
To the engineers, I say this: we built the Internet, and some of us have
helped to subvert it. Now, those of us who love liberty have to fix it.
 Bruce Schneier writes about security, technology, and people. His latest
book is Liars and Outliers: Enabling the Trust That Society Needs to Thrive.
He is working for the Guardian on other NSA stories

@_date: 2013-09-06 12:25:15
@_author: Eugen Leitl 
@_subject: PayPal freezes MailPile's account 
I've used Kickstarter from Germany. Amazon is present in many countries
beyond US/UK.

@_date: 2013-09-06 21:06:50
@_author: Eugen Leitl 
@_subject: Old list archives 
An excellent idea. Unfortunately, I lost my 1980s/90s
emails due to a shredded RAID.
I will put up a mirror as well. mbox format is perfect.

@_date: 2013-09-08 19:09:06
@_author: Eugen Leitl 
@_subject: [linux-elitists] Surveillance 
Anyone with CA/package signing opsec clue willing to help Linux
distros with advice to improve package signing security?

@_date: 2013-09-09 10:42:47
@_author: Eugen Leitl 
@_subject: Quark : A Web Browser with a Formally Verified Kernel 
Quark : A Web Browser with a Formally Verified Kernel
University of California, San Diego
Computer Science and Engineering
Quark is an experimental, formally verified browser. Watch it run popular sites like GMail, Facebook, and Amazon! [video 1] [video
Web browsers mediate access to valuable private data in domains ranging from
health care to banking. Despite this critical role, attackers routinely
exploit browser vulnerabilities to exfiltrate private data and take over the
underlying system. We present Quark, a browser whose kernel has been
implemented and verified in the Coq proof assistant. We give a specification
of our kernel, show that the implementation satisfies the specification, and
finally show that the specification implies several security properties,
including tab non-interference, cookie integrity and confidentiality, and
address bar integrity.
Our Web browser, Quark, exploits formal verification and enables us to verify
security properties for a million lines of code while reasoning about only a
few hundreds. To achieve this goal, Quark is structured similarly to Google
Chrome. It consists of a small browser kernel which mediates access to system
resources for all other browser components. These other components run in
sandboxes which only allow the component to communicate with the kernel. In
this way, Quark is able to make strong guarantees about a million lines of
code (e.g., the renderer, JavaScript implementation, JPEG decoders, etc.)
while only using a proof assistant to reason about a few hundred lines of
code for the Quark kernel. Because the underlying system is protected from
Quark's untrusted components (i.e., everything other than the kernel) we were
free to adopt state-of-the-art implementations and thus Quark is able to run
popular, complex Web sites like Facebook and GMail.
Establishing Browser Security Guarantees through Formal Shim Verification
[Tech Report] USENIX Security 2012 Dongseok Jang, Zachary Tatlock, Sorin Lerner Source code(.tar.gz) (Version 0.1, 08/07/2012, 1.3MB)
Dongseok Jang	
Zachary Tatlock	
Sorin Lerner

@_date: 2013-09-09 11:23:29
@_author: Eugen Leitl 
@_subject: IETF: Security and Pervasive Monitoring 
Security and Pervasive Monitoring
The Internet community and the IETF care deeply about how much we can trust
commonly used Internet services and the protocols that these services use.
So the reports about large-scale monitoring of Internet traffic and users
disturbs us greatly.  We knew of interception of targeted individuals and
other monitoring activities, but the scale of recently reported monitoring is
surprising. Such scale was not envisaged during the design of many Internet
protocols, but we are considering the consequence of these kinds of attacks.
Of course, it is hard to know for sure from current reports what attack
techniques may be in use.  As such, it is not so easy to comment on the
specifics from an IETF perspective.  Still, the IETF has some long standing
general principles that we can talk about, and we can also talk about some of
the actions we are taking.
In 1996, RFC 1984 articulated the view that encryption is an important tool
to protect privacy of communications, and that as such it should be
encouraged and available to all.  In 2002, we decided that IETF standard
protocols must include appropriate strong security mechanisms, and
established this doctrine as a best current practice, documented in RFC 3365.
Earlier, in 2000 the IETF decided not to consider requirements for
wiretapping when creating and maintaining IETF standards, for reasons stated
in RFC 2804. Note that IETF participants exist with positions at all points
of the privacy/surveillance continuum, as seen in the discussions that lead
to RFC 2804.
As privacy has become increasingly important, the Internet Architecture Board
(IAB) developed guidance for handling privacy considerations in protocol
specifications, and documented that in RFC 6973. And there are ongoing
developments in security and privacy happening within the IETF all the time,
for example work has just started on version 1.3 of the Transport Layer
Security (TLS, RFC 5246) protocol which aims to provide better
confidentiality during the early phases of the cryptographic handshake that
underlies much secure Internet traffic.
Recent days have also seen an extended and welcome discussion triggered by
calls for the IETF to build better protections against wide-spread
As that discussion makes clear, IETF participants want to build secure and
deployable systems for all Internet users.  Indeed, addressing security and
new vulnerabilities has been a topic in the IETF for as long as the
organisation has existed.  Technology alone is, however, not the only factor.
Operational practices, laws, and other similar factors also matter. First of
all, existing IETF security technologies, if used more widely, can definitely
help.  But technical issues outside the IETFs control, for example endpoint
security, or the properties of specific products or implementations also
affect the end result in major ways. So at the end of the day, no amount of
communication security helps you if you do not trust the party you are
communicating with or the devices you are using. Nonetheless, were confident
the IETF can and will do more to make our protocols work more securely and
offer better privacy features that can be used by implementations of all
So with the understanding of limitations of technology-only solutions, the
IETF is continuing its mission to improve security in the Internet.  The
recent revelations provide additional motivation for doing this, as well as
highlighting the need to consider new threat models.
We should seize this opportunity to take a hard look at what we can do
better.  Again, it is important to understand the limitations of technology
alone. But here are some examples of things that are already ongoing:
Were having a discussion as part of the development of HTTP/2.0 as to how to
make more and better use of TLS, for example to perhaps enable clients to
require the use of security and not just have to react to the HTTP or HTTPS
URLs chosen by servers.
Were having discussions as to how to handle the potentially new threat model
demonstrated by the recent revelations so that future protocol designs can
take into account potential pervasive monitoring as a known threat model.
Were considering ways in which better use can be made of existing protocol
features, for example, better guidance as to how to deploy TLS with Perfect
Forward Secrecy, which makes applications running over TLS more robust if
server private keys later leak out.
Were constantly updating specifications to deprecate older, weaker
cryptographic algorithms and allocate code points for currently strong
algorithm choices so those can be used with Internet protocols.
And we are confident that discussions on this topic will motivate IETF
participants to do more work on these and further related topics.
But dont think about all this just in terms of the recent revelations.  The
security and privacy of the Internet in general is still a challenge even
ignoring pervasive monitoring, and if there are improvements from the above,
those will be generally useful for many reasons and for many years to come.
Perhaps this years discussions is a way to motivate the world to move from
by default insecure communications to by default secure.  Publicity and
motivation are important, too. There is plenty to do for all of us, from
users enabling additional security tools to implementors ensuring that their
products are secure.
In the Vancouver IETF meeting, there will be time dedicated to discuss this,
and we ask that those interested in working on this topic contribute to the
analysis and develop proposals in this area.  Those contributions are very
welcome and can start now and continue in Vancouver and beyond.
Relevant mailing lists (from most specific to most general) include:
The perpass mailing list (perpass at ietf.org), recently set up to consider how
the IETF ought react to pervasive monitoring
The ietf security area mailing list (saag at ietf.org), for general security
The ietf main mailing list (ietf at ietf.org), for general discussion
Jari Arkko, Chair of the IETF and Stephen Farrell, IETF Security Area
This entry was posted in IETF on 2013/09/07.

@_date: 2013-09-09 11:35:05
@_author: Eugen Leitl 
@_subject: [liberationtech] Meet the 'cowboy' in charge of the NSA 
Looks paywalled. Can someone liberate the document, and repost
it here?

@_date: 2013-09-09 13:06:14
@_author: Eugen Leitl 
@_subject: [cryptography] New NSA Slides and Details Released last night 
David D
Sent: Monday, September 09, 2013 12:07 PM
Lots of gems in this video:
cryptography mailing list
cryptography at randombit.net

@_date: 2013-09-09 13:05:45
@_author: Eugen Leitl 
@_subject: [liberationtech] Meet the 'cowboy' in charge of the NSA 
9 September 2013 The Cowboy of the NSA Keith Alexander

@_date: 2013-09-09 14:40:10
@_author: Eugen Leitl 
@_subject: Scott Aaaronson: NSA: Possibly breaking US laws, but still bound by 
NSA: Possibly breaking US laws, but still bound by laws of computational
Last week, I got an email from a journalist with the following inquiry.  The
recent Snowden revelations, which made public for the first time the US
governments black budget, contained the following enigmatic line from the
Director of National Intelligence: We are investing in groundbreaking
cryptanalytic capabilities to defeat adversarial cryptography and exploit
internet traffic.  So, the journalist wanted to know, what could these
groundbreaking capabilities be?  And in particular, was it possible that
the NSA was buying quantum computers from D-Wave, and using them to run
Shors algorithm to break the RSA cryptosystem?
I replied that, yes, thats possible, but only in the same sense that its
possible that the NSA is using the Easter Bunny for the same purpose.  (For
one thing, D-Wave themselves have said repeatedly that they have no interest
in Shors algorithm or factoring.  Admittedly, I guess thats what D-Wave
would say, were they making deals with NSA on the sly!  But its also what
the Easter Bunny would say.)  More generally, I said that if the open
scientific worlds understanding is anywhere close to correct, then quantum
computing might someday become a practical threat to cryptographic security,
but it isnt one yet.
That, of course, raised the extremely interesting question of what
groundbreaking capabilities the Director of National Intelligence was
referring to.  I said my personal guess was that, with ~99% probability, he
meant various implementation vulnerabilities and side-channel attacksthe
sort of thing that we know has compromised deployed cryptosystems many times
in the past, but where its very easy to believe that the NSA is ahead of the
open world.  With ~1% probability, I guessed, the NSA made some sort of big
improvement in classical algorithms for factoring, discrete log, or other
number-theoretic problems.  (I wouldve guessed even less than 1% probability
for the latter, before the recent breakthrough by Joux solving discrete log
in fields of small characteristic in quasipolynomial time.)
Then, on Thursday, a big New York Times article appeared, based on 50,000 or
so documents that Snowden leaked to the Guardian and that still arent
public.  (See also an important Guardian piece by security expert Bruce
Schneier, and accompanying Q&A.)  While a lot remains vague, there might be
more public information right now about current NSA cryptanalytic
capabilities than theres ever been.
So, how did my uninformed, armchair guesses fare?  Its only halfway into the
NYT article that we start getting some hints:
The files show that the agency is still stymied by some encryption, as Mr.
Snowden suggested in a question-and-answer session on The Guardians Web site
in June.
Properly implemented strong crypto systems are one of the few things that
you can rely on, he said, though cautioning that the N.S.A. often bypasses
the encryption altogether by targeting the computers at one end or the other
and grabbing text before it is encrypted or after it is decrypted
Because strong encryption can be so effective, classified N.S.A. documents
make clear, the agencys success depends on working with Internet companies 
by getting their voluntary collaboration, forcing their cooperation with
court orders or surreptitiously stealing their encryption keys or altering
their software or hardware
Simultaneously, the N.S.A. has been deliberately weakening the international
encryption standards adopted by developers. One goal in the agencys 2013
budget request was to influence policies, standards and specifications for
commercial public key technologies, the most common encryption method.
Cryptographers have long suspected that the agency planted vulnerabilities in
a standard adopted in 2006 by the National Institute of Standards and
Technology and later by the International Organization for Standardization,
which has 163 countries as members.
Classified N.S.A. memos appear to confirm that the fatal weakness, discovered
by two Microsoft cryptographers in 2007, was engineered by the agency. The
N.S.A. wrote the standard and aggressively pushed it on the international
group, privately calling the effort a challenge in finesse.
So, in pointing to implementation vulnerabilities as the most likely
possibility for an NSA breakthrough, I might have actually erred a bit too
far on the side of technological interestingness.  It seems that a large part
of what the NSA has been doing has simply been strong-arming Internet
companies and standards bodies into giving it backdoors.  To put it bluntly:
sure, if it wants to, the NSA can probably read your email.  But that isnt
mathematical cryptographys faultany more than it would be mathematical
cryptos fault if goons broke into your house and carted away your laptop.
On the contrary, properly-implemented, backdoor-less strong crypto is
something that apparently scares the NSA enough that they go to some lengths
to keep it from being widely used.
I should add that, regardless of how NSA collects all the private information
it doesby beating crypto in a fair fight (!) or, more likely, by
exploiting backdoors that it itself installedthe mere fact that it collects
so much is of course unsettling enough from a civil-liberties perspective.
So Im glad that the Snowden revelations have sparked a public debate in the
US about how much surveillance we as a society want (i.e., the balance
between preventing 9/11 and preventing Orwell), what safeguards are in place
to prevent abuses, and whether those safeguards actually work.  Such a public
debate is essential if were serious about calling ourselves a democracy.
At the same time, to me, perhaps the most shocking feature of the Snowden
revelations is just how unshocking theyve been.  So far, I havent seen
anything that shows the extent of NSAs surveillance to be greater than what
I wouldve considered plausible a priori.  Indeed, the following could serve
as a one-sentence summary of what weve learned from Snowden:
Yes, the NSA is, in fact, doing the questionable things that anyone not
living in a cave had long assumed they were doingthat assumption being so
ingrained in nerd culture that countless jokes are based around it.
(Come to think of it, people living in caves might have been even more
certain that the NSA was doing those things.  Maybe thats why they moved to
So, rather than dwelling on civil liberties, national security, yadda yadda
yadda, let me move on to discuss the implications of the Snowden revelations
for something that really matters: a 6-year-old storm in theoretical computer
sciences academic teacup.  As many readers of this blog might know, Neal
Koblitza respected mathematician and pioneer of elliptic curve cryptography,
who (from numerous allusions in his writings) appears to have some
connections at the NSApublished a series of scathing articles, in the
Notices of the American Mathematical Society and elsewhere, attacking the
theoretical computer science approach to cryptography.  Koblitzs criticisms
were varied and entertainingly-expressed: the computer scientists are too
sloppy, deadline-driven, self-promoting, and corporate-influenced; overly
trusting of so-called security proofs (a term they shouldnt even use,
given how many errors and exaggerated claims they make); absurdly overreliant
on asymptotic analysis; bodacious in introducing dubious new hardness
assumptions that they then declare to be standard; and woefully out of
touch with cryptographic realities.  Koblitz seemed to suggest that, rather
than demanding the security reductions so beloved by theoretical computer
scientists, people would do better to rest the security of their
cryptosystems on two alternative pillars: first, standards set by
organizations like the NSA with actual real-world experience; and second, the
judgments of mathematicians with  taste and experience, who can just see
whats likely to be vulnerable and what isnt.
Back in 2007, my mathematician friend Greg Kuperberg pointed out the irony to
me: here we had a mathematician, lambasting computer scientists for trying to
do for cryptography what mathematics itself has sought to do for everything
since Euclid!  That is, when you see an unruly mess of insights, related to
each other in some tangled way, systematize and organize it.  Turn the tangle
into a hierarchical tree (or dag).  Isolate the minimal assumptions (one-way
functions?  decisional Diffie-Hellman?) on which each conclusion can be
based, and spell out all the logical steps needed to get from here to
thereeven if the steps seem obvious or boring.  Any time anyone has tried to
do that, its been easy for the natives of the unruly wilderness to laugh at
the systematizing newcomers: the latter often know the terrain less well, and
take ten times as long to reach conclusions that are ten times less
interesting.  And yet, in case after case, the clarity and rigor of the
systematizing approach has eventually won out.  So it seems weird for a
mathematician, of all people, to bet against the systematizing approach when
applied to cryptography.
The reason Im dredging up this old dispute now, is that I think the recent
NSA revelations might put it in a slightly new light.  In his articlewhose
main purpose is to offer practical advice on how to safeguard ones
communications against eavesdropping by NSA or othersBruce Schneier offers
the following tip:
Prefer conventional discrete-log-based systems over elliptic-curve systems;
the latter have constants that the NSA influences when they can.
Here Schneier is pointing out a specific issue with ECC, which would be
solved if we could merely ensure that NSA or other interested parties
werent providing input into which elliptic curves to use.  But I think
theres also a broader issue: that, in cryptography, its unwise to trust any
standard because of the prestige, real-world experience, mathematical good
taste, or whatever else of the people or organizations proposing it.  What
was long a plausible conjecturethat the NSA covertly influences
cryptographic standards to give itself backdoors, and that
otherwise-inexplicable vulnerabilities in deployed cryptosystems are
sometimes there because the NSA wanted them therenow looks close to an
established fact.  In cryptography, then, its not just for idle academic
reasons that youd like a publicly-available trail of research papers and
source code, open to criticism and improvement by anyone, that takes you all
the way from the presumed hardness of an underlying mathematical problem to
the security of your system under whichever class of attacks is relevant to
Schneiers final piece of advice is this: Trust the math.  Encryption is
your friend.
Trust the math.  On that note, heres a slightly-embarrassing confession.
When Im watching a suspense movie (or a TV show like Homeland), and I reach
one of those nail-biting scenes where the protagonist discovers that
everything she ever believed is a lie, I sometimes mentally recite the proof
of the Karp-Lipton Theorem.  It always calms me down.  Even if the entire
universe turned out to be a cruel illusion, it would still be the case that
NP  P/poly would collapse the polynomial hierarchy, and I can tell you
exactly why.  It would likewise be the case that you couldnt break the GGM
pseudorandom function without also breaking the underlying pseudorandom
generator on which its based.  Math could be defined as that which can still
be trusted, even when you cant trust anything else.
This entry was posted on Sunday, September 8th, 2013 at 11:31 am	 and
is filed under Complexity, Nerd Interest. You can follow any responses to
this entry through the RSS 2.0 feed. You can leave a response, or trackback
from your own site.
24 Responses to NSA: Possibly breaking US laws, but still bound by laws of
computational complexity Aaronson on crypto. Schneier elliptic-curve
systems; the latter have constants that the NSA influences when they can. |
Gordon's shares Says: Comment  September 8th, 2013 at 1:22 pm [] Link.
Trust math, but not NSA mathematicians. []
Douglas Knight Says: Comment  September 8th, 2013 at 1:35 pm Could you be
more specific about what you mean by the hypothetical big improvement on
number theory algorithms that is covered by your 1%?
Do elliptic curve algorithms count? Does an L(1/4) algorithm count, or only
quasi-polynomial? What if they cant break all instances, but, as has
repeatedly happened, they discovered bad primes or bad exponents that make
particular keys weak? Breaking a random half of all keys is almost as good as
breaking all of them. Schneiers condemnation of ECC seems to require more
than 1% chance NSA knows something special about ECC.
PS  David Jao, commenting on Schneiers blog says that we can and do use
cryptography to prevent NSA from meddling with mystery constants. He says
that the ECC standard curves are generated by SHA-1, so to meddle, NSA would
have to break the has function. (But if half of curves are bad, thats easy.)
Anonymous Says: Comment  September 8th, 2013 at 1:45 pm
You are making good and interesting points. However, Koblitz also has some
valid criticisms of TCS even if his conclusions are not valid. The
mathematical models we built in TCS are useless if they dont relate to the
practice and we know many of our standard models are not good enough
approximation of the reality and arguably there isnt enough effort to deal
with these issues. Technical heavy weight lifting is used as the ultimate
criteria for judging the value of research projects inside the community.
Also I think you are exaggerating what most cryptographers expected that NSA
was doing. I have heard several famous crypto experts quite surprised by
these revelations and it has shaken their trust in the government
institutions. I never understood why some people presume that government is a
benevolent entity, such beliefs in government institutions seems like
ideology to me.
Daniel Armak Says: Comment  September 8th, 2013 at 2:06 pm
You can trust the math itself, and so can Bruce Schneier and a few tens of
thousands of other people. But everyone else who cant grok the entire
mathematical arguments for each cryptographical system, or doesnt want to
spend a long time studying it, must trust the word of people like you. And
since the NSA can and does subvert people like you, who do original work and
analyze others work and sit on standards committees, not to mention the
programmers who implement it in code, what are we to do?
Daniel W. Says: Comment  September 8th, 2013 at 2:33 pm
In my mind, the best circumstantial evidence that the NSA has not practically
broken any of the major cryptosystems is the following:, if they had, they
would most likely keep this as a highly guarded secret to be used only
against high value targets rather than as a means of monitoring potential
terrorists. It would most likely be contained within a small circle and not
mentioned in power-point presentations to low-level analysts.
Of course, the above argument may be flawed by assuming the NSA has too high
of a level of competence.
T H Ray Says: Comment  September 8th, 2013 at 2:43 pm
  the clarity and rigor of the systematizing approach has eventually won
No doubt. In Euclids time as well as the present, though, it is helpful to
have something to systematize. Making that assumption available and
convenient is what mathematicians do.
Scott Says: Comment  September 8th, 2013 at 3:02 pm
Daniel Armak You can trust the math itself, and so can Bruce Schneier and a few tens of
thousands of other people. But everyone else  must trust the word of people
like you.  You raise an excellent point, which I think applies even more
broadly than you say. For one thing, I merely understand some of the general
ideas: I havent gone through every detail of the math used by the crypto in
my web browser, and I dare say that most professional cryptographers havent
For another, the point is much broader than cryptography: how can you trust
quantum mechanics, if you havent done the requisite experiments yourself?
The physicists couldve all been bought off by some anti-realist cabal. :-)
Or how can you trust that the government isnt putting mind-control drugs
into the fruit you buy in the supermarket, etc. etc.
So were extremely lucky that science hit on a solution to these problemsthe
only workable solution, reallyback in the 17th century. The solution is to
open up every question to scrutiny, discussion, and challenge by any
interested person. Assertions gain credibility by surviving public
criticismand thats just as true in math as it is in experimental sciences.
I believe many theorems even though I havent checked the proofs myself,
because I know that if there were an error, then someone else couldve made a
name for themselves by finding it.
Now, for this Popperian dynamic to work, the whole process has to be carried
out in the open: if I thought someone who found a fatal flaw in a proof would
only tell their friends, then that doesnt do me any good. Thats why the
dividing line between crypto as black art and modern crypto happened
precisely when new discoveries started being published in the open
literature, rather than being filed in a drawer at NSA or GCHQ.
wolfgang Says: Comment  September 8th, 2013 at 3:20 pm
Unfortunately, this xkcd.com/538/ had it right imho.
Scott Says: Comment  September 8th, 2013 at 3:20 pm
Daniel W.  If the NSA had really broken strong cryptosystems, then why
would they have resorted to so many covert tactics (or, in the case of the
Clipper Chip, overt attempts) to prevent people from using strong crypto,
unless NSA has a backdoor? I suppose its all elaborate psychological
warfare, to prevent us from discovering the fact that these cryptosystems
were broken? And that even Snowden himself is part of the NSAs master plan?
At least in my book, every time you claim that what looks on its face like
evidence for X, is really evidence for a powerful cabal trying to prevent
everyone from discovering not(X), the plausibility of your theory gets cut by
a factor of maybe 50,000. This is directly related to the fact that I dont
believe any conspiracy theoriesas in zero, not one.
Scott Says: Comment  September 8th, 2013 at 3:32 pm
Douglas Knight  Sure, dramatic improvements in elliptic-curve algorithms
would certainly countas would merely subexponential algorithms, were the
improvements large enough to threaten key sizes that the academic
cryptographers considered safe.
More broadly, though, youre entirely right that theres not a sharp line
between improved number-theory algorithms and implementation
vulnerabilities. Often, whats happened in practice is that an
implementation vulnerability has opened the way for an attack that still
requires interesting and nontrivial number theory. But I suppose that sort of
thing would still belong to the 99% part of my probability estimate. In the
1% part, I really had in mind something that would give theoretical
cryptographers a heart attack (like, I dunno, factoring in L(1/10), or
elliptic curve discrete log in quasipolynomial time).
Scott Says: Comment  September 8th, 2013 at 5:03 pm
Anonymous You are making good and interesting points. However, Koblitz also has some
valid criticisms of TCS even if his conclusions are not valid.  I completely
agree that Koblitz has some valid criticisms.
However, Ive read pretty much all of his and Menezess anti-TCS screeds, and
to me what hes doing seems, if you like, too easy to be helpful. Koblitzs
favorite M.O. is to recount various slip-ups by people in the Goldreich
school of crypto and laugh at them: haha, they talk about provable
security, but there was a bug in their proof! or their security definition
left out an important class of side-channel attacks! Then, with even more
glee, Koblitz relates how the hapless computer scientists put out a new paper
supposedly fixing the problem, but that paper had its own problems, and so
The trouble is, that is indeed what a bunch of incompetent buffoons would
look like, but its also what science looks like! :-) Koblitz never seems to
want to acknowledge that the end result of the process is better scientific
understanding and more secure cryptosystems than before (even if still not
Also, of course, Koblitz almost defiantly refuses to suggest any better
mathematical foundations for cryptography, besides the reduction-based
foundations that were built up over the last 30 years. I.e., its not that
instead of adaptive chosen ciphertext attack, he has a better definition to
propose, or that instead of bodacious new hardness assumptions, he can give
a single assumption that suffices for everything. Instead, what he appears to
want is simply a return to the black art era of cryptography, when security
arguments boiled down to we tried to break it and failed or trust us, we
have better mathematical taste than you.
The trouble is, I cant think of a single case in the history of science when
mathematical foundations as well-developed as cryptographys now are, were
simply abandoned wholesale without better mathematical foundations to replace
them. So intellectually, Koblitz strikes me as someone whos throwing spears
at battle-tanks. Being the excellent marksman that he is, he actually scores
some hitsbut the reduction-encrusted battle-tanks are still going to win in
the end.
The mathematical models we built in TCS are useless if they dont relate to
the practice and we know many of our standard models are not good enough
approximation of the reality and arguably there isnt enough effort to deal
with these issues.  Would one also say that the mathematical foundations of
topologyopen sets, Urysohns Lemma, etc.are useless if they dont relate to
the practice of tying and untying knots? I think thats a pretty close
analogy for the relationship between what, say, Goldreich or Goldwasser or
Micali do, and the actual practice of cryptography. In both cases, yes,
theres some relation between the intellectual foundations on the bottom and
the beautiful ornaments on top, but not surprisingly there are many floors in
between. Starting from a one-way function, for example, you first have to
construct a quasi-regular one-way function, then a pseudoentropy generator,
then a pseudorandom generator, then a pseudorandom function, and then maybe
you can start to think about building (say) a rudimentary private-key
cryptosystem or signature scheme.
Also I think you are exaggerating what most cryptographers expected that NSA
was doing. I have heard several famous crypto experts quite surprised by
these revelations and it has shaken their trust in the government
institutions. I never understood why some people presume that government is a
benevolent entity, such beliefs in government institutions seems like
ideology to me.  My situation is different: I never had any real doubt that
NSA was doing such things; the thing I genuinely dont know is whether they
have good reasons to be doing them. I consider it conceivable that the NSA
has indeed stopped many terrorist attacks or other international disasters
that we never hear aboutin which case, the strongest case in their favor
might be stronger than the strongest case that can ever be made publicly. The
fact that President Obama, whos so reasonable on so many issues, has implied
as much is evidence for that view from my perspective. On the other hand, I
also consider it conceivable that the current eavesdropping regime is purely
a result of the universal tendency of bureaucracies to expand, justify
themselves, and zealously guard their power and privileges. Or it could be
some combination of the two.
For me, though, the deciding consideration is that, even in a fantasy world
where the NSAs actions had always been 100% justified, Id still want them
to be more accountable to the public than they are now. Trust that we have
our reasons, even though we cant tell you what they are simply doesnt work
over the long term in a democracy, even if the trust is justified at any
particular time or in any particular case (and of course, often it hasnt
Anonymous Says: Comment  September 8th, 2013 at 8:05 pm
I agree with you that his attitude is not constructive criticism. I would
even go further than you and say it is stupid to forget the science of crypto
and go back to purely engineering art treatment.
Regarding reasonability of what NSA does, NSA and its backers would of course
claim these tools are useful. To be honest, security was a weak point of
Obamas campaign, he is not really knowledgeable in these issues and he has
not gone and will not go against his advisers if they tell him these tools
are necessary to fight terrorism. However, as far as I have heard, they have
hard time convincing anyone outside executive branch that these tools have
been as useful as they are claiming. How many major terrorist plots they have
been uncovered and prevented using these tools? It seems that they are using
these tools for a very wide range of activities including industrial and
political espionage on foreign governments and companies and gain political
and commercial advantage (what they call US national interests, not just
securing Americans against terrorists). Does anyone really believe that EU or
Brazil or liberal NGOs will launch a terrorist attack on US? FBIs actions
against Dr. King is telling how far they would go. They use the fear factor
of a possible terrorist attacks to justify these actions to the public,
however the laws allow them to do whatever they want to and when there are
restrictions (like the fourth amendments) they find ways to circumvents them
(e.g. by colliding with foreign intelligence services like GCHQ to spy on
American citizens) or change the interpretations of those laws. We are very
lucky that many influential Americans in the previous generations had a
negative view of the federal government and wanted to restrict its powers as
much as possible, restrictions which are being removed in practice (partly
because some people want to settle sociopolitical disputes present in the
country using the governments power). I dont see why so much power should
be invested in a single authority with almost no real public supervision and
scrutiny (a role that media was playing to some extent in previous decades
but is coming under heavy pressure from government as Manning, Swartz,
Snowden,  cases demonstrate). And even when courts find that someone in the
government has seriously violated the laws the president forgives them and
they avoid real punishment (as Scoot Libby case demonstrates).
It is not just US government, there is a trend in western liberal
democracies. It is simply unbelievable that the UK security forces used a law
passed to fight terrorism to hold the partner of a Guardian journalist for 9
hours without a lawyer and without the protection of Miranda rights against
self-incrimination. Anyone who thinks that security forces will only use the
authority and tools they obtain to the limited extent of the original goal
suffers from extreme nativity. They will use any tools in their disposal to
the fullest extent they can to achieve what they perceive to be the goals of
their institution. When they perceive journalists like Greenwald as a threat
to the national interests they use these tools to fight them which includes
intimidating the partner of a journalist using terrorism fighting powers. I
still fund it really hard to believe that we have gone so far in the
direction of an Orwellian society.
What can theoretical computer science offer biology? | Theory, Evolution, and
Games Group Says: Comment  September 9th, 2013 at 2:16 am
[] the aid that cstheory can offer to biological understanding. In
yesterdays post on the NSA and computational complexity, Aaronson  with
attribution to mathematician Greg Kuperberg  provided the following []
Paul Beame Says: Comment  September 9th, 2013 at 2:45 am
Some of the NSA revelations have been no surprise at all. It was well known
in the 1980s, particularly after the publication of The Puzzle Palace, that
the NSA was tapping all the trans-Atlantic telephone cables; gathering up of
all e-mail to foreign addresses seems like more of the same.
The relationship of the NSA with TCS cryptographers has been pretty shaky. I
recall attending a theory of cryptography workshop at MITs Endicott House in
June 1985 with one or two official NSA attendees. At the time, there were one
or two TCS attendees known to have NSA funding and the NSA people wanted to
recruit more. In announcing their desire to sponsor more TCS cryptographers,
one of the NSA people cast a pall over the meeting by saying: If you are
interested, just mention it in a phone conversation with one of your friends
and well get back to you. This didnt exactly endear them to anyone.
J Says: Comment  September 9th, 2013 at 2:51 am
Math could be defined as that which can still be trusted, even when you
cant trust anything else
Wait till someone shows multiplication and addition have same complexity or
possible Voevodskys/Nelsons worst nightmare comes true
Scott Says: Comment  September 9th, 2013 at 4:20 am
J  Multiplication and addition having the same complexity (and yes, its
conceivable that theres a linear-time multiplication algorithm) wouldnt do
anything whatsoever to undermine my trust in mathwhy would it?
Also, even if ZF set theory were shown to be inconsistent (and it wont be
:-) ), that wouldnt do anything whatsoever to undermine my trust in theorems
about (say) finite groups, or low-dimensional topology, or theoretical
computer sciencein fact, about anything that doesnt involve transfinite
sets. It would merely tell me that there was a need (and, of course, an
exciting opportunity) to rethink the foundations. Thats something that
already happened 100+ years ago (the renovations causing virtually no damage
to the higher floors), and that could conceivably happen again.
Vitruvius Says: Comment  September 9th, 2013 at 4:58 am
I agree, Scott, with your general position that any time one claims that
evidence for x is really evidence for a powerful cabal trying to prevent
everyone from discovering not(x) ones credibility drops by an irrecoverably
large factor, and I agree with you that math can be defined as that which
can still be trusted, even when you cant trust anything else (as you put
it), yet that still begs the question of how we the people decide what to
trust to be valid math.
Similarly, while your suggestion to open up every question to scrutiny,
discussion, and challenge by any interested person may be necessary in order
to establish public trust, it isnt sufficient because we still have the
problem of deciding which such interested persons to trust, and which to
write off as conspiracy theorists in their own right. How do we feasibly
decide, in effect, whether Ehrenhaft is a crackpot (as it were), and whether
Snowden himself is part of the NSAs master plan (as you playfully alluded
To that end you may be interested in Why Doesnt the Public Trust
Scientists?, a lecture by The Right Honourable Professor The Baroness ONeill
of Bengarve, Emeritus Professor of Philosophy at the University of Cambridge
and past Principal of Newnham College, Cambridge, which she presented in 2005
as part of the Science Futures series by the San Diego Science and Technology
Councils Center for Ethics in Science and Technology.
Note that while scientists are the titular and exemplary referent matter in
that lecture, Baroness ONeills talk actually considers a range of questions
in regard of public trust, including the roles of professional organizations,
trustworthiness (which cant replace trust because of the quis custodiet
ipsos custodes problem), statutory regulation, post hoc accountability, &c,
which apply more broadly to the matters of public trust in any and every
profession and institution, including politics and the law.
ONeill argues, if I may be so bold as to suggest a prcis, that going back
through the 17th century (as you noted) western liberal democracies have
indeed evolved a multipartite methodology that does tend work in practice and
that may well be the best we can get in principal, though it remains unclear
to me how well we are applying those techniques to matters of state security
in general, and how effectively you folks in the United States of America are
applying those techniques to your vaunted Agency in particular.
Scott Says: Comment  September 9th, 2013 at 5:01 am
Paul Beame  Ive actually heard that joke many times, in other variants.
(Interested in career opportunities at the NSA? Call your mom and let her
know!) I didnt know that NSA people themselves used the joke at
conferences, but it doesnt surprise me at all.
J Says: Comment  September 9th, 2013 at 6:39 am Multiplication and
addition having the same complexity (and yes, its conceivable that theres a
linear-time multiplication algorithm) wouldnt do anything whatsoever to
undermine my trust in mathwhy would it?
I thought I read somewhere that if addition and multiplication turn out to be
similar in complexity, then it would imply something is wrong with
On the same vein think of the generalization of scheme theory that Mochizuki
claims to have undertaken to take apart + and x in ring structure.
I would think something fundamentally would have changed in our picture if
they turn to be similar in complexity.
J Says: Comment  September 9th, 2013 at 6:47 am
Atleast for computational purposes, the multiplicative group structure and
additive group structure of $\Bbb Z$ seem to be coinciding. This seems wrong.
I cannot directly relate to $Z \bmod p$ but this seems to have implication to
Discrete Log. An implication for this may not be beyond reach for atleast a
few other rings as well.
Scott Says: Comment  September 9th, 2013 at 7:02 am
J  Well, we already have a remarkable O(n logn loglogn) multiplication
algorithm (due to Frer, and building on many previous works), and it hasnt
created any problem for the foundations of mathematics that I know about.
Meanwhile, just like for most problems, we currently have no lower bound for
multiplication better than the trivial (n). I suppose Id guess that (n
logn) is some sort of barrier, but not with any strength of conviction: if a
linear-time algorithm were discovered, it certainly wouldnt cause me to
doubt the consistency of ZF set theory. :-)
Scott Says: Comment  September 9th, 2013 at 7:16 am
Vitruvius it remains unclear to me  how effectively you folks in the United States of
America are applying those techniques to your vaunted Agency in particular.
As long as were trading mild national barbs, youre Canadian? You guys do
have the Communications Security Establishment, which according to the NYT
article is one of only four foreign agencies (along with Britains,
Australias, and New Zealands) that knows the full extent of the NSAs
decoding capabilities and is cleared for its Bullrun program. Though I
confess that, when I try to imagine Canadas CSE, I come up with something
like the following:
Read this gentlemans private email? Ooo, nooo, that doesnt sound terribly
polite, eh?
J Says: Comment  September 9th, 2013 at 7:21 am
Professor I am well aware of all $n^{1+\epsilon}$ algorithms and Schonages
$O(n)$ algorithm on multitape machines. I cannot find the reference I am
thinking. It was written by a TCS theorist. I would seriously think that the
standard ring structure in $\Bbb Z$ could be modeled differently. I do not
know if ZF would be affected. However the question of treating x and +
differently for computation purposes compare to mathematical purposes arises
making things murky.
I am not implicating ZF with $O(n)$ algorithms for standard x operations on
the standard structure of $\Bbb Z$. The ZFC comment was a second piece of
mathematical conundrum some reputed folks have raised awareness about for a
need to be more well-grounded and it rang well with your statement on truth
in math as we know it. (Unrelated but bringing in  $Z$ has been a puzzle
before as well  it is the simplest ring with a spectrum of prime ideals
whose dimension is unclear to be interpreted in a standard way)
Scott Says: Comment  September 9th, 2013 at 7:23 am
Wolfgang Unfortunately, this xkcd.com/538/ had it right imho.
YES! I especially liked the mouseover text (Actual actual reality: nobody
cares about his secrets).

@_date: 2013-09-09 16:37:13
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Blockchain archival 
Not quite true, as I said balance-at-point-in-time would solve that (and make the storage requirements much lower)
For bitcoin to grow beyond interesting experiment into global everyday use a number of things would have to happen, not least of which is taking 'average punter' into account. Whilst new ideas can filter into the general consciousness over time,sometimes concepts have to go with 'what already works' :)
People's concept of money hasn't really changed in over 1,000 years - it remains 'something of known value i can exchange for something else'.
No-one outside of bitcoin dev's and early adopters really gets the one-shot concept of addresses - possibly rightly so - keeping issues of it lowering levels of anonymity etc out of the discussion - it doesn't fit with the mindset people have - it's difficult enough getting merchants to setup separate addresses for each client, one per transaction is simply a waste (of addresses, storage, blockchain size, numnber of inputs|outputs when spending etc)
I'm sure the wife would love a new handbag everytime she gets some money, but the real-world just isnt like that ;)
Addresses are perceived as the equivalent of a jar you stick your coins in. You can have lots of jars. Each jar can be for a specific reason or whatever, but the analogy is there.
Wallets are like a box you keep some of your jars in. With the added interesting concept that a jar can be in multiple boxes at the same time. Only the person with the right 'key' can open the jar and take the However unlike the 3 money boxes I have behind me right now - which i can take 1 single penny out of one and put it into another - if I want to move bitcoins from one addresses (jar) to another *of my own* I have to pay a fee. Worse still if the jar doesnt have much in it I'm denied that ability.
End user will neither understand why or want to pay the fee, for dealing with their own coins.
If a jar breaks I can just tip the contents into a new one - unless I'm very careless, the amount in the new one = the amount in the old one - people will want/need it to work like that.
Similarly if you do have all these addresses around, you may want (as good housekeeping) discard some of them (after moving the cash).
So having the ability to specify address to send from is essential (and a sadly missing feature of the QT client)
'intra-wallet' transfers with an 'also discard the sending address' would be a way of (once confirmed) stopping any further use of that address (denied any further transactions by miners ?) and when balance-at-point-in-time is implemented, a way of shrinking the storage for all other bitcoin users (who chosse not to have a full transaction If i send luke 10, and luke sends me back 3, i have 3, luke has 7.
If luke sends me 2, and i send luke 1, i have 4 and luke has 6.
To verify my ability to send jeff 4, all that is needed is to know that I have 4, not all the transactions that led to that state - thats how its done now, thats not necessarily efficient as bitcoin grows
If luke sends me 4 more, i now have 4 again, luke has 3
If i send 1 to each of the children, they have 1 each (*4)
Having a 'family' wallet means when on holiday they can have that rental of quad-bikes - to send the rental company 4 the client only needs to know that those addresses now have 1 each in them, not all the previous transactions - if they didnt exist at the point-in-time balance, then yes, it would need to know about the luke>rob>kids transactions, but thats all
I moved to a new netbook recently - it took 140 *hours* to d/load and process the blockchain (yes the wifi was that bad), I heard from one of our clients that (although they only had the client running during working hours) that to their desktop it was over 9 days before it had caught up.
If all I was d/loading were the transactions since the last difficulty change (as one example of a fixed point), and the remaining balance on any not-discarded address as at that point it would have been much much quicker, and not be shagging my shiny new hard drive.
There's more but it's 4.45 in the morning, and I cant think coherently until after a few hours kip and some good coffee :)

@_date: 2013-09-09 22:01:19
@_author: Eugen Leitl 
@_subject: hardware RNG 
I would use a cheap analog circuit like and let your audio card to A/D. Bonus points: there are already entropy gathering daemons which
use soundcard input.
Even cheaper: hang a cheap microphone into a fan exhaust. Noise definitely not white,
but certainly more entropy than just looking at lowest bits of A/D.

@_date: 2013-09-10 10:23:04
@_author: Eugen Leitl 
@_subject: hardware RNG 
Many cheap embeddes have hardware RNGs -- e.g. ALIX (Geode),
which can take e.g. HiFn 7955 on a mini-PCI, plus mixing in
some entropy from e.g. an USB device is not that expensive.

@_date: 2013-09-10 18:15:37
@_author: Eugen Leitl 
@_subject: generating noisy samples at a high rate with RTLSDR 
Just remembered another cheap option for generating a lot
of noisy samples: Especially, with wideband RF noise source.

@_date: 2013-09-10 18:55:46
@_author: Eugen Leitl 
@_subject: generating noisy samples at a high rate with RTLSDR 
That's exactly what you need, if you want to get entropy
from the real world. Wide-band white noise generator circuits up to 300 MHz are very cheap and easy.
This gives you some 1.4 Msamples @ 8 bit. With a wideband
white noise source there will be several bits of entropy
in each sample, estimated.

@_date: 2013-09-11 13:21:29
@_author: Eugen Leitl 
@_subject: SPDZ, a practical protocol for Multi-Party Computation 
Breakthrough in cryptography could result in more secure computing
Tags: computer science, research, security, cryptography
Nigel Smart, Professor of Cryptology New research to be presented at the 18th European Symposium on Research in
Computer Security (ESORICS 2013) this week could result in a sea change in
how to secure computations.
The collaborative work between the University of Bristol and Aarhus
University (Denmark) will be presented by Bristol PhD student Peter Scholl
from the Department of Computer Science.
The paper, entitled 'Practical covertly secure MPC for dishonest majority -
or: Breaking the SPDZ limits', builds upon earlier joint work between Bristol
and Aarhus and fills in the missing pieces of the jigsaw from the groups
prior work that was presented at the CRYPTO conference in Santa Barbara last
The SPDZ protocol (pronounced "Speedz") is a co-development between Bristol
and Aarhus and provides the fastest protocol known to implement a theoretical
idea called "Multi-Party Computation".
The idea behind Multi-Party Computation is that it should enable two or more
people to compute any function of their choosing on their secret inputs,
without revealing their inputs to either party. One example is an election,
voters want their vote to be counted but they do not want their vote made
The protocol developed by the universities turns Multi-Party Computation from
a theoretical tool into a practical reality. Using the SPDZ protocol the team
can now compute complex functions in a secure manner, enabling possible
applications in the finance, drugs and chemical industries where computation
often needs to be performed on secret data.
Nigel Smart, Professor of Cryptology in the University of Bristol's
Department of Computer Science and leader on the project, said: "We have
demonstrated our protocol to various groups and organisations across the
world, and everyone is impressed by how fast we can actually perform secure
"Only a few years ago such a theoretical idea becoming reality was considered
Alice in Wonderland style over ambitious hope. However, we in Bristol
realised around five years ago that a number of advances in different areas
would enable the pipe dream to be achieved. It is great that we have been
able to demonstrate our foresight was correct."
The University of Bristol is now starting to consider commercialising the
protocol via a company Dyadic Security Limited, co-founded by Professor Smart
and Professor Yehuda Lindell from Bar-Ilan University in Israel.
Note: This story has been adapted from a news release issued by the
University of Bristol

@_date: 2013-09-11 13:40:10
@_author: Eugen Leitl 
@_subject: WREN: The First Satellite YOU Can Fly 
The only satellite in Earth orbit that YOU can control DIRECTLY ! You are the
pilot. Launch is this year!
Even nowadays space is not opened to the public, but we will change that -
this year !
We are four guys in a garage, and we have dedicated ourselves to open space
for everyone. For that purpose we designed the miniaturized satellite WREN.
Its a so called Pocketqub-Femtosatellite. It has only 5x5x5cm of volume and
250g of mass, and fits perfectly into your hand, like a tennis ball. Despite
of its size, it even has real thrusters.
It can be remotely positioned by you in every direction and it has a camera
onboard for taking pictures from outer space. It will be released into a
polar orbit before the end of this year on board of the UNISAT-5 deployer,
which is launched inside a DNEPR Rocket from Yasni in Russia.
It will race around the globe every 98 minutes, passing every point of the
earth during each day, seven days a week, just waiting for the command to be
remotely flown by you.
System overview
WREN System Overview
WREN is equipped with a camera, a gyro and a magnetic field sensor. Those
three components will form an adaptive feedback guidance system which helps
you to easily navigate the satellite by your own by using its momentum wheels
and microthrusters. The camera is equipped with an image processing system
which can find the position of the sun and the earth automatically. This
technology will make the control of the satellite more easy. With the camera
system you can of course remotely take pictures of the earth, the sun and
other space objects. You can navigate the satellite directly in order to make
your own picture.
The communication up- and downlink will be performed at 437,405 MHz, a
frequency in the 70cm amateur radio band which has been kindly assigned to us
by the International Amateur Radio Union (IARU). Wren will be flying in a sun
synchronous orbit at 700km of altitude at an incredible speed of 7500
m/second, so that it will take only 98 minutes to fly one time all around the
planet. Practically, a link is possible for about 10 minutes from a single
ground station, up to three times a day. The mission control software is
equipped with prediction algorithms in order to predict the flyby- time
according to your location, so you can prepare yourself for the upcoming
communication window and take control over the satellite again.
We hope that amateur radio enthusiasts will join our network and provide a
link from time to time to use WRENs lifetime as long as possible.
Send a message into deep space
You can send a message into deep space. Of course it will be also receptable
on earth. Everytime WREN sends his status to earth, it will also send out one
of the saved messages.
If WREN survives for years, your message will be sent several times into the
deep far universe.
Project Status
The rocket launch is scheduled for November this year.
Wren is currently in the final assembly process and will be integrated into
the deployer in October this year, after the shaker test.
We will be helped out with a professional ground station after launch for the
first weeks, but we want to build our own mobile groundstation to be able to
establish the link for you anytime.
We will publish the plans for the groundstation as soon as it is ready and
working, so everybody can build it!
How do we get into space so cheaply?
Bringing one kilogram of mass into orbit costs about 50000$. Rockets must
carry their fuel all the way up, so the laws of physics make them big, heavy
and expensive.
So how do we fly so relatively cheaply?
First, we are light, about 250 grams. And we fly piggyback on a bigger
satellite called "UNISAT-5".  This satellite, together with some others, are
all stored in one rocket, so the costs for the launch will be shared
according to the mass. Wren will be stored in a deployment unit called MRFOD.
Wren will be waiting inside this MRFOD in the satellite "UNISAT-5" for his
release into the open space
The rocket will go up in November and will release UNISAT-5 and other
satellites. Wren will be released into space out of Unisat about one month
Please Spread the message
We want to bring space into your living room. To achieve this we need your
help, not only by asking you for backing us with money but also by telling
the story to everybody you know who may be interested in space. We also need
amateur radio guys who would like to take part in project and follow Wren all
along its way around the planet by listening its beacon and messages you
pledged for, being heard. Our blogs and webpages, reports and videos are just
a few components of the whole message. You are the messengers, you are the
carrier of the idea of transporting space into everybody's living room - and
beyond!

@_date: 2013-09-11 15:49:33
@_author: Eugen Leitl 
@_subject: NIST reopens RNG public comment period 
Sep. 9, 2013
SP 800-90 A Rev 1 B and C
DRAFT Draft SP 800-90 Series: Random Bit Generators 800-90 A Rev. 1: Recommendation for Random Number Generation Using Deterministic Random Bit Generators 800-90 B: Recommendation for the Entropy Sources Used for Random Bit Generation 800-90 C: Recommendation for Random Bit Generator (RBG) Constructions
In light of recent reports, NIST is reopening the public comment period for Special Publication 800-90A and draft Special Publications 800-90B and 800-90C.
NIST is interested in public review and comment to ensure that the recommendations are accurate and provide the strongest cryptographic recommendations possible.
The public comments will close on November 6, 2013. Comments should be sent to RBG_Comments at nist.gov. In addition, the Computer Security Division has released a supplemental ITL Security Bulletin titled "NIST Opens Draft Special Publication 800-90A, Recommendation for Random Number Generation Using Deterministic Random Bit Generators, For Review and Comment (Supplemental ITL Bulletin for September 2013)" to support the draft revision effort.
Draft SP 800-90 A Rev. 1 (721 KB) Draft SP 800-90 B (800 KB) Draft SP 800-90 C (1.1 MB)

@_date: 2013-09-13 11:49:24
@_author: Eugen Leitl 
@_subject: Stealthy Dopant-Level Hardware Trojans 
Stealthy Dopant-Level Hardware Trojans ?
Georg T. Becker1
, Francesco Regazzoni2
, Christof Paar1,3 , and Wayne P. Burleson1
1University of Massachusetts Amherst, USA
2TU Delft, The Netherlands and ALaRI - University of Lugano, Switzerland
3Horst ortz Institut for IT-Security, Ruhr-Universiat Bochum, Germany
Abstract. In recent years, hardware Trojans have drawn the attention of governments and
industry as well as the scientific community. One of the main concerns is
that integrated circuits, e.g., for military or critical infrastructure
applications, could be maliciously manipulated during the manufacturing
process, which often takes place abroad. However, since there have been no
reported hardware Trojans in practice yet, little is known about how such a
Trojan would look like, and how dicult it would be in practice to implement
In this paper we propose an extremely stealthy approach for implementing
hardware Trojans below the gate level, and we evaluate their impact on the
security of the target device. Instead of adding additional circuitry to the
target design, we insert our hardware Trojans by changing the dopant polarity
of existing transistors. Since the modified circuit appears legitimate on all
wiring layers (including all metal and polysilicon), our family of Trojans is
resistant to most detection techniques, including fine-grain optical
inspection and checking against "golden chips".  We demonstrate the
ectiveness of our approach by inserting Trojans into two designs | a digital
post-processing derived from Intel's cryptographically secure RNG design used
in the Ivy Bridge processors and a side-channel resistant SBox implementation
and by exploring their detectability and their ects on security.
Keywords: Hardware Trojans, malicious hardware, layout modifications, Trojan

@_date: 2013-09-18 19:08:22
@_author: Eugen Leitl 
@_subject: Zero Reserve - A distributed Bitcoin exchange 
Zero Reserve - A distributed Bitcoin exchange
tl;dr: Proposal and prototype for a distributed exchange not requiring a banking gateway. Implemented as a plugin for Retroshare. Licensed under the LGPL.
The Achilles heel of Bitcoin is the exchanges. Centralized as they are, they can be shut down by a number of means, by a number of players. Should that happen, price discovery of Bitcoin will not work any more. To address that, we offer a distributed exchange without the need of the banking system. Some intro and marketing blurb is here:
A tech paper is here:
And the code is here:
In short, ZR uses the Ripple idea of Ryan Fugger to get money in and out of the exchange. ZR has nothing to do whatsoever with ripple.com, however. As such, there is no need for XRP. There is no pre-mining, no company, just code.
Now the caveat: This is prototype software. Anything may or may not work. Security is only what the underlying Retroshare provides. The distributed order book works, but is still insecure. Currencies are therefore only defunct or fantasy currencies such as German Papermark(1923). Nothing you do has any effect on the blockchain.
The next steps are:
- hook up to the blockchain (using Amir Taakis excellent libbitcoin)
- providing basic wallet functionality
- provide authentication for anything beyond F2F.
I see no reason why it wouldnt work on OSX, but ZR was never built on it. It does build and run on Linux and Windows, though.
Once you are on Retroshare and have some friends, you should be able to use this link to get and subscribe to the Zero Reserve Forum:
One of my RS identities:
-----BEGIN PGP PUBLIC KEY BLOCK-----
Version: OpenPGP:SDK v0.9
-----END PGP PUBLIC KEY BLOCK-----

@_date: 2013-09-24 15:18:55
@_author: Eugen Leitl 
@_subject: How a Crypto =?utf-8?B?4oCYQmFja2Rvb3I=?= =?utf-8?B?4oCZ?= Pitted 
How a Crypto Backdoor Pitted the Tech World Against the NSA
BY KIM ZETTER09.24.136:30 AM
Illustration: alengo/Getty Images
In August 2007, a young programmer in Microsofts Windows security group
stood up to give a five-minute turbo talk at the annual Crypto conference in
Santa Barbara.  It was a Tuesday evening, part of the conferences
traditional rump session, when a hodge-podge of short talks are presented
outside of the conferences main lineup. To draw attendees away from the wine
and beer that competed for their attention at that hour, presenters sometimes
tried to sex up their talks with provocative titles like Does Bob Go to
Prison? or How to Steal Cars  A Practical Attack on KeeLoq or The Only
Rump Session Talk With Pamela Anderson.
Dan Shumow and his Microsoft colleague Niels Ferguson titled theirs,
provocatively, On the Possibility of a Back Door in the NIST SP800-90 Dual
Ec Prng. It was a title only a crypto geek would love or get.
The talk was only nine slides long (.pdf). But those nine slides were
potentially dynamite. They laid out a case showing that a new encryption
standard, given a stamp of approval by the U.S. government, possessed a
glaring weakness that made an algorithm in it susceptible to cracking. But
the weakness they described wasnt just an average vulnerability, it had the
kind of properties one would want if one were intentionally inserting a
backdoor to make the algorithm susceptible to cracking by design.
For such a dramatic presentation  by mathematicians standards  the
reaction to it was surprisingly muted. I think folks thought, Well thats
interesting, and, Wow, it looks like maybe there was a flaw in the
design, says a senior Microsoft manager who was at the talk. But there
wasnt a huge reaction.
Six years later, thats all changed.
Early this month the New York Times drew a connection between their talk and
memos leaked by Edward Snowden, classified Top Secret, that apparently
confirms that the weakness in the standard and so-called Dual_EC_DRBG
algorithm was indeed a backdoor. The Times story implies that the backdoor
was intentionally put there by the NSA as part of a $250-million, decade-long
covert operation by the agency to weaken and undermine the integrity of a
number of encryption systems used by millions of people around the world.
The Times story has kindled a firestorm over the integrity of the byzantine
process that produces security standards. The National Institute of Standards
and Technology, which approved Dual_EC_DRBG and the standard, is now facing a
crisis of confidence, having been forced to re-open the standard for public
discussion, while security and crypto firms scramble to unravel how deeply
the suspect algorithm infiltrated their code, if at all. On Thursday,
corporate giant RSA Security publicly renounced Dual_EC_DRBG, while also
conceding that its commercial suite of cryptographic libraries had been using
the bad algorithm as its default algorithm for years.
But beneath the flames, a surprising uncertainty is still smoldering over
whether Dual_EC_DRBG really is backdoored. The Times, crypto experts note,
hasnt released the memos that purport to prove the existence of a backdoor,
and the papers direct quotes from the classified documents dont mention any
backdoor in the algorithm or efforts by the NSA to weaken it or the standard.
They only discuss efforts to push the standard through committees for
Jon Callas, the CTO of Silent Circle, whose company offers encrypted phone
communication, delivered a different rump session talk at the Crypto
conference in 2007 and saw the presentation by Shumow. He says he wasnt
alarmed by it at the time and still has doubts that what was exposed was
actually a backdoor, in part because the algorithm is so badly done.
If [NSA] spent $250 million weakening the standard and this is the best that
they could do, then we have nothing to fear from them, he says. Because
this was really ham-fisted. When you put on your conspiratorial hat about
what the NSA would be doing, you would expect something more devious,
Machiavellian  and this thing is just laughably bad. This is Boris and
Natasha sort of stuff.
Indeed, the Microsoft presenters themselves  who declined to comment for
this article  didnt press the backdoor theory in their talk. They didnt
mention NSA at all, and went out of their way to avoid accusing NIST of
anything. WE ARE NOT SAYING: NIST intentionally put a back door in this
PRNG, read the last slide of their deck.
The Microsoft manager who spoke with WIRED on condition of anonymity thinks
the provocative title of the 2007 presentation overstates the issue with the
algorithm and is being misinterpreted  that perhaps reporters at the Times
read something in a classified document showing that the NSA worked on the
algorithm and pushed it through the standards process, and quickly took it as
proof that the title of the 2007 talk had been right to call the weakness in
the standard and algorithm a backdoor.
But Paul Kocher, president and chief scientist of Cryptography Research, says
that regardless of the lack of evidence in the Times story, he discounts the
bad cryptography explanation for the weakness, in favor of the backdoor
Bad cryptography happens through laziness and ignorance, he says. But in
this case, a great deal of effort went into creating this and choosing a
structure that happens to be amenable to attack.
Whats mathematically creative [with this algorithm] is that when you look
at it, you cant even prove whether there is a backdoor or not, which is very
bizarre in cryptography, he says. Usually the presence of a backdoor is
something you can prove is there, because you can see it and exploit it. In
my entire career in cryptography, Ive never seen a vulnerability like this.
National Security Agency headquarters, Fort Meade, Maryland. Photo: Wikipedia
Its not the first time the NSA has been accused of installing backdoors.
Crypto trapdoors, real and imagined, have been part of NSA lore for decades.
In some ways the current controversy echoes the long-ago debate over the
first U.S. Data Encryption Standard in the 1970s. The NSA was widely
suspected of weakening DES to make it more crackable by the agency by
tinkering with a table of numeric constants called an S-Box and shortening
the algorithms key length. In 1994, though, the NSA was exonerated when it
turned out that the agency had actually changed the S-Box numbers to harden
DES against a code-breaking technique that had been known only within NSA at
the time.
In 1995, another case came up that seemed to confirm suspicions about the
NSA. The Baltimore Sun reported that year that the NSA had inserted a
backdoor into cryptographic machines made by the respected Swiss company
Crypto AG, apparently substantiating longstanding rumors to that effect.
Then in 1999, Microsoft inadvertently kicked off another controversy when it
leaked its internal name for a cryptographic signing key built into Windows
NT. The key was called _NSAKEY, spawning speculation that Microsoft had
secretly given the agency the power to write and sign its own updates to
Windows NTs crypto engine. Microsoft said this was incorrect, that the key
was an internal Microsoft key only and that it was called _NSAKEY because
the NSA was the technical reviewing authority for U.S. export controls. The
key was part of Microsofts compliance with U.S. export laws.
Suspicions about the NSA and backdoors were lingering in 2006 when Shumow and
Ferguson began looking at Dual_EC_DRBG after NIST approved it for inclusion
in a standard (.pdf). The standard discussed four federally sanctioned random
number generators approved for use in encrypting government classified and
unclassified-but-sensitive communication.
Each of the four algorithms was based on a different cryptographic design
family. One was based on hash functions, one on so-called HMAC (hash-based
message authentication code), one on block ciphers and the fourth one was
based on elliptic curves. The NSA had been pushing elliptic curve
cryptography for a number of years, and it publicly championed the last one 
Dual_EC_DRBG  to be included in the standard.
Elliptic curve algorithms are based on slightly different mathematics than
the more common RSA algorithm, and the NSA believes theyre the future of
cryptography, asserting that elliptic curve algorithms are smaller, faster
and offer better security.
But as Shumow and Ferguson examined the properties of the elliptic curve
random number generator in the standard, to determine how to incorporate it
into the Windows operating system, a couple of strange things stood out.
First, the random number generator was very slow  two to three orders of
magnitude slower than another algorithm in the standard.
Second, it didnt seem to be very secure.
There was a property [in it] that seemed to make the prediction-resistance
of the algorithm not what you would necessarily want it to be, the Microsoft
manager says. In non-geek speak, there was a weakness that made the random
number generator not so random.
Good random number generation is at the core of encryption, and a weak RNG
can undo the entire encryption system. Random number generators play a role
in creating cryptographic keys, in opening secure communications between
users and web sites and in resetting passwords for email accounts. Without
assured randomness, an attacker can predict what the system will generate and
undermine the algorithm.
Shumow and Ferguson found that the obstacles to predicting what the random
number generator would generate was low. It wasnt a catastrophic problem,
but it seemed strange for a security system being promulgated by the
Then they noticed something else.
The standard for implementing the algorithm included a list of constants 
static numbers  that were used in the elliptic curve on which the random
number generator was based. Whoever generated the constants, which served as
a kind of public key for the algorithm, could have generated a second set of
numbers at the same time  a private key.
Anyone possessing that second set of numbers would have whats known in the
cryptography community as trapdoor information  that is, they would be
able to essentially unlock the encryption algorithm by predicting what the
random number generator generated. And, Shumow and Ferguson realized, they
could predict this after seeing as few as 32 bytes of output from the
generator. With a very small sample, they could crack the entire encryption
system used to secure the output.
Even if no one knows the secret numbers, the fact that the backdoor is
present makes Dual_EC_DRBG very fragile, cryptographer Bruce Schneier wrote
at the time, in a piece for WIRED. If someone were to solve just one
instance of the algorithms elliptic-curve problem, he would effectively have
the keys to the kingdom. He could then use it for whatever nefarious purpose
he wanted. Or he could publish his result, and render every implementation of
the random-number generator completely insecure.
No one knew who had produced the constants, but it was assumed that because
the NSA had pushed the algorithm into the standard, the agency had generated
the numbers. The spy agency might also, then, have generated a secret key.
Schneier called it scary stuff indeed, but he also said at the time that it
made no sense as a backdoor, since it was so obvious to anyone who looked at
the algorithm and standard that there was this flaw in it. As a result,
developers of web sites and software applications wouldnt use it to help
secure their products and systems, he said.
But in fact, many developers did use it.
The U.S. government has enormous purchasing power, and vendors soon were
forced to implement the suspect standard as a condition of selling their
products to federal agencies under so-called FIPS certification requirements.
Microsoft added support for the standard, including the elliptic curve
random-number generator, in a Vista update in February 2008, though it did
not make the problematic generator the default algorithm.
Asked why Microsoft supported the algorithm when two of its own employees had
shown it to be weakened, a second Microsoft senior manager who spoke with
WIRED said that while the weakness in the algorithm and standard was weird
it wasnt a smoking gun. It was more of an odd property.
Microsoft decided to include the algorithm in its operating system because a
major customer was asking for it, because it had been sanctioned by NIST, and
because it wasnt going to be enabled as the default algorithm in the system,
thus having no impact on other customers.
In fact it is nearly impossible for any user to implement or to get this
particular random number generator instantiating on their machines without
going into the guts of the machine and reconfiguring it, he says.
Other major companies, like Cisco and RSA, added it as well. NIST in fact
provides a lengthy list of companies that have included it in their
libraries, though the list doesnt say which companies made it the default
algorithm in their library or which products have been developed that invoke
the algorithm.
A Cisco spokesman told WIRED that the algorithm was implemented in its
standard crypto library around mid-2012, a library that is used in more than
120 product lines, but the algorithm is not the default, and the default
algorithm cannot be changed by users. The company is currently completing an
internal audit of all of its products that leverage the NIST standard.
RSA, however, made the algorithm the default in its BShare toolkit for Java
and C developers until this week when it told WIRED that it was changing the
default following the renewed controversy over it. The company sent an
advisory to developer customers strongly urging them to change the default
to one of a number of other random number generator algorithms RSA supports.
RSA also changed the default on its own end in BSafe and in an RSA key
management system. The company is currently doing an internal review of all
of its products to see where the algorithm gets invoked in order to change
RSA actually added the algorithm to its libraries in 2004 or 2005, before
NIST approved it for the standard in 2006 and before the government made it a
requirement for FIPS certification, says Sam Curry, the companys chief
technology officer. The company then made it the default algorithm in BSafe
and in its key management system after the algorithm was added to the
standard. Curry said that elliptic curve algorithms were all the rage at the
time and RSA chose it as the default because it provided certain advantages
over the other random number generators, including what he says was better
Cryptography is a changing field. Some algorithms go up and some come down
and we make the best decisions we can in any point in time, he says.A lot
of the hash-based algorithms were getting struck down by some weaknesses in
how they chose numbers and in fact what kind of sample set they chose for
initial seeding. From our perspective it looked like elliptic curve would be
immune to those things.
Curry says the fact that the algorithm is slower actually provides it with
better security in at least one respect.
The length of time that you have to gather samples will determine the
strength of your random number generation. So the fact that its slower
sometimes gives it a wider sample set to do initial seeding, he says.
Precisely because it takes a little longer, it actually winds up giving you
more randomness in your initial seeding, and that can be an advantage.
Despite the renewed controversy over the algorithm and standard, Microsoft
managers say they still dont think the weaknesses constitute an intentional
Callas agrees. He thinks it is simply bad cryptography that was included in
the standard to round-out the selection so that there would be at least one
elliptic curve algorithm in the standard.
But one advantage to having the algorithm supported in products like Vista 
and which may be the reason the NSA pushed it into the standard  is that
even if its not the default algorithm for encryption on a system, as long as
its an option on the system, an intruder, like the NSA, can get into the
system and change the registry to make it the default algorithm used for
encryption, thereby theoretically making it easy for the NSA to undermine the
encryption and spy on users of the machine.
Schneier says this is a much more efficient and stealth way of undermining
the encryption than simply installing a keystroke logger or other Trojan
malware that could be detected.
A Trojan is really, really big. You cant say that was a mistake. Its a
massive piece of code collecting keystrokes, he said. But changing a
bit-one to a bit-two [in the registry to change the default random number
generator on the machine] is probably going to be undetected. It is a low
conspiracy, highly deniable way of getting a backdoor. So theres a benefit
to getting it into the library and into the product.
To date, the only confirmation that the algorithm has a backdoor comes in the
Times story, based on NSA documents leaked by Edward Snowden, which the Times
and two other media outlets saw.
[I]nternal memos leaked by a former NSA contractor, Edward Snowden, suggest
that the NSA generated one of the random number generators used in a 2006
NIST standard  called the Dual EC DRBG standard  which contains a back door
for the NSA, the Times wrote.
An editorial published by the Times this weekend re-asserted the claim:
Unbeknown to the many users of the system, a different government arm, the
National Security Agency, secretly inserted a back door into the system
that allowed federal spies to crack open any data that was encoded using its
But all of the quotes that the Times published from the memos refer to the
NSA getting the standard passed by an international standards body; they do
not say the NSA intentionally weakened the algorithm and standard, though the
Times implies that this is what the memos mean by tying them to the 2007
presentation by Shumow and Ferguson.
NIST has denied any knowledge of a backdoor and has also denied that the NSA
authored its standard. The institute has, however, re-opened the standard for
public comment as a result of the controversy and strongly urged against
using the algorithm in question until the matter could be resolved. The
public comments period will close Nov. 6.
Even without more explicit confirmation that the weaknesses in the algorithm
and standard constitute a backdoor, Kocher and Schneier believe they do.
It is extraordinarily bad cryptography, says Kocher. If you look at the
NSAs role in creating standards [over the years] and its general
cryptographic sophistication, none of it makes sense if there isnt a
backdoor in this.
Schneier agrees and says the NSA has done too many other things for him to
think, when he sees government-mandated crypto thats weak, that its just by
If we were living in a kinder world, that would be a plausible explanation,
he says. But were living in a very malicious world, it turns out.
He adds that the uncertainty around the algorithm and standard is the worst
part of the whole matter.
This is the worst problem that the NSA has done, Schneier says. They have
so undermined the fundamental trust in the internet, that we dont know what
to trust. We have to suspect everything. Were never sure. Thats the
greatest damage.

@_date: 2013-09-24 16:52:50
@_author: Eugen Leitl 
@_subject: Dissentr: A High-Latency Overlay Mix Network 
Note: This project was created as part of a 36-hour hackathon - and primarily as a proof of concept. While the ideas may be sound, and the prototype may work as designed, the protocols involved in this specific project have not been peer-reviewed, and so I cannot recommend that the network be used for anything requiring serious privacy.
A High-Latency Overlay Mix Network
Essentially, Dissentr is a security-minded network, inspired by Tor, with a few important characteristics which serve to differentiate it.
Tor is a low-latency network. This makes it ideal for real time activities like web browsing, but as a result, opens it up to attacks involving large-scale traffic analysis methods known as end-to-end correlation. In these attacks, an adversary with the ability to analyze massive amounts of traffic in a short period of time is able to match up traffic entering the network with the corresponding traffic which will inevitably soon exit it.
Dissentr manages to protect against these sorts of attacks by being engineered as a high-latency network. Assuming any given node has not been compromised, that node will intentionally hold off on forwarding its traffic to the next node in the network until it is able to forward a large amount of data in bulk, rendering the aforementioned end-to-end correlation far less feasible. For an excellent discussion on this attack, and possible countermeasures, see Practical Traffic Analysis: Extending and Resisting Statistical Disclosure.
Much like any mix network, Dissentr models its network as a graph of nodes, each responsible for handling the relay of traffic as it moves along some path through the network. Where Dissentr differs from a network such as Tor is in how this path is constructed. In Dissentr, the network is constructed out of cascades (A term I first heard described by Ian Goldberg, but I've been unable to pin down an original source for): essentially directed, acyclic sub-graphs, in which a node defines a set of "trusted" nodes, through which they are willing to relay traffic through. Dissentr simplifies this model by only allowing for nodes of out-degree 1, at this time. This construction brings about a number of useful results:
In the event that a node is known to be compromised, individual nodes are allowed the ability to either remove themselves from a cascade, or bypass untrusted nodes entirely, without the necessity of a trusted third-party.
The network is protected from "supernode invasions," in which an attacker floods the network with compromised nodes, in the hopes of either endangering the network's health, or placing the security of users passing through their nodes at risk of traffic interception, and subsequent analysis. This can be guaranteed because cascades are constructed by virtue of a measure of trust between node-operators, and so long as there exists some non-zero subset of trusted operators, they retain the ability to form a cascade of their own, effectively shutting out the efforts of such an attacker.
As mentioned previously, the high-latency nature of the network causes a shift in the sorts of activities best facilitated by its use, however, there do exist some unique opportunities which I have neither seen implemented in the context of a mix network, nor discussed in the literature.
A personal favourite idea revolves around creating a platform for political blogging, which, assuming a noisy enough network, would offer political dissidents the ability to freely write about issues of corruption or government abuse, without many of the risks associated with using a lower-latency network like Tor. If it takes a week for a blog post to appear in circulation after the author posts it to the network, it becomes magnitudes more difficult for any assailant to trace the authorship of that blog post - especially if that author never visited the website which hosts their content in the first place!
It also becomes a fairly trivial exercise to adapt the network to act as a mixing service for digital currency such as Bitcoin. Furthermore, by breaking the network into a number of smaller, disjoint networks for that purpose, one is be able to counter many of the current attacks which target existing mixing services.
I again emphasize that the cryptosystem in place is the result of a rather rushed 48-hour hackathon - in a production system, I would recommend implementing a peer-reviewed cryptosystem, such as the very lightweight Sphinx, or, pending their coming proof of security, the recently proposed Ibis. That being said, Dissentr works as follows:
Every node in the network maintains an RSA-keypair, with the public key being exposed to every node in a given cascade.
When a client wishes to send a message M through the network, they choose some cascade C.
For each node in the cascade, beginning with the exit node, and continuing through to the entrance node, the client generates an AES CFB128 key, which it uses to encrypt M. The key is then encrypted using that node's public RSA key.
M, now encrypted with AES CFB128 for every node in the cascade, is then passed to the entrance node along with the encrypted AES keys. The entrance node then uses its private RSA key to decrypt the AES key, so that it can subsequently decrypt M, yielding yet another cipher text.
This process is repeated for every node in the cascade, until the final node decrypts M to a plaintext, which it then handles accordingly.
Building and Running it
If, after all of my warnings, you still want to see it in action, it's dead-easy to get setup. All you'll need is Erlang installed (Tested on R16B02), along with Elixir. From there, you'll want to invoke the following from within Dissentr's directory, on every machine you want to host a node:
iex --sname {Any name, different per machine} --cookie {Any string, common between all machines} -S mix
This will stick you into a REPL, loaded with Dissentr's namespaces and dependencies. Sorry, there's no interface yet. From there, if you're using more than one machine, you'll want to link them all together, by running the following on every machine you want to host a node on. Since Erlang node connections are transitive, you won't have to do this for every pair of nodes.:
The hostname in question can be found in the iex prompt. Most likely it will be something at domain.
Now, just spawn a few nodes to create a network. I've got some temporary methods in place for making this easy, using some hardcoded keys stored in example_data/ for testing. Ideally, each node will be hosted on a different machine, but for testing purposes it doesn't matter. Within your prompt, execute the following:
Dissentr.Cascade.add_node(:node1, nil, 1)
Dissentr.Cascade.add_node(:node2, :node1, 2)
Dissentr.Cascade.add_node(:node3, :node2, 3)
Dissentr.Cascade.add_node(:node4, :node3, 4)
Dissentr.Cascade.add_node(:node5, :node4, 5)
Finally, to send an encrypted message, run the following, substituting the node and message as desired:
Dissentr.Cascade.mix(:node3, "Something, something, NSA")
If all went well, you should see a debug statement print out the plaintext message, on the machine which is hosting :node1

@_date: 2013-09-25 09:56:29
@_author: Eugen Leitl 
@_subject: DARK WALLET: A RADICAL WAY TO BITCOIN 
"radical", huh.
DARK WALLET: A RADICAL WAY TO BITCOIN
POSTED BY MICHAEL DEL CASTILLO
Cody Wilson is a twenty-five-year-old former law student at the University of
Texas at Austin. He is also the inventor of the Liberator, a gun made almost
entirely from plastic pieces created with a 3-D printer; he also uploaded to
the Internet a blueprint that anyone could use to print such a gun.
Wilson, who espouses libertarian views, created the blueprint to make a
point: information should be free. Not everyone agreed with him. In May,
after Wilson successfully fired the gun at a range near Austin and posted the
design online, the State Department requested that those files be removed
from the Web site of his nonprofit, Defense Distributed.
Wilson compliedbut not before the files had been downloaded two hundred
thousand times, igniting a debate about whether there should be limits to the
free flow of information over the Internet, and over the role of the
government in enforcing those restrictions.
Wilson lives in a utopian world in which contraband will be only a notional
concept, because enforcement will require policing ideas and blueprints, not
simply goods, Jacob Silverman wrote in a piece about Wilson and the
Liberator in May.
A native of Cabot, Arkansasa small suburb of Little RockWilson said that
the State Departments action persuaded him to drop out of law school and
pursue revolutionary activities full-time. In fact, he had been planning his
next endeavor for a while. When Indiegogo, a crowdfunding site, booted
Defense Distributeds campaign in August, 2012, for violating its terms of
serviceIndiegogo said the project related to the sale of firearms; Wilson
said it was for the creation of informationWilson began to raise money by
asking people to support him using a currency called Bitcoin: encrypted,
difficult-to-trace bits of code that function like cash and can be exchanged
over the Internet without a bank or a PayPal account.
Wilson said that he eventually raised two hundred bitcoins for the
Liberatorthe equivalent of twenty-seven thousand dollars, according to the
current exchange rate. His efforts attracted the attention of a
twenty-five-year-old Brit named Amir Taaki, who e-mailed him with an
invitation to speak at the Bitcoin 2012 Conference, in London. He accepted.
Wilson and Taaki met in person for the first time in January of 2013, when
Taaki took Wilson to visit a workspace for hackers is Bratislava, Slovakia,
and to anarchist squats in London. They reconnected in Berlin that July and
began hashing out a plan to use the as of yet unregulated, untaxed, nearly
untraceable currency in a way that would, like the Liberator, undermine the
ability of governments to regulate the activities of their citizens.
In the Bitcoin world, where banks no longer serve as intermediaries between
people and their money, bank accounts have been replaced by online wallets
that people can use to virtually store and send bitcoins.
Wilson and Taakis project, tentatively known as Dark Wallet, is a simple
wallet designed to be easier to use for people who arent tech-savvy; they
hope that in turn accelerates the currencys rate of adoption around the
world. The wallet will be open-source and free to use. Eventually, Wilson and
Taaki hope to create a vast stable of Bitcoin-related tools.
The goal, for Wilson, is similar to what he tried to do with the Liberator:
use technology to remove government intervention from his life, and from the
lives of like-minded people.
Unlike many current Bitcoin wallets, which can be difficult to download and
cumbersome to use, Wilson and Taaki are designing Dark Wallet, they told me,
as an easy-to-install plug-in that sits discreetly on users Chrome or
Firefox browsers. Made for Windows, Mac, and Linux computers, Dark Wallet
would move most of the energy-sucking process of insuring theres only one of
each bitcoin in circulation, and that they arent spent in two places at the
same time, to separate servers.
Wilson still lives in Austin, working remotely on Dark Wallet with Taaki, who
lives in an anarchist compound called Calafou, outside of Barcelona, and
writes most of the code behind the wallet. Taaki and Vitalik Buterin, the
co-founder of Bitcoin Magazine, a periodical covering the currency, are part
of a Calafou-based organization called unSystem, which came up with the idea
for the wallet; theyre working with a team of developers from around the
world. Wilson, who will manage the development team behind Dark Wallet,
making sure they meet their targets on time, is also producing a video and
other material for a crowdfunding campaign to raise money for the project.
Dark Wallet should be ready sometime in January or February of 2014, Taaki
said, though hes not committing to anything. Itll launch when its ready,
he said. And the details of an upcoming crowdfunding campaign have still yet
to be solidified, though Taaki and Wilson expect it to launch sometime in
The person or group that, in 2008, created Bitcointhat is, released the
protocol that defined what Bitcoin would becalled itself Satoshi Nakamoto.
The online comments that Satoshi Nakamoto made before disappearing
completely, in 2012, indicate that the creator of Bitcoin, like Wilson, was
deeply mistrustful of economic institutions and designed the currency to be
intentionally subversive.
Bitcoin is created, or mined, as its called, by powerful computers that
race to solve complex math problems and are rewarded for their work with the
encrypted code that is a bitcoin. Today there are 11.7 million of the coins
in existence, worth an estimated $1.6 billion, though their value fluctuates
dramatically. Nakamoto set the number of coins entering circulation to halve
every four years until 2140, when they will plateau at twenty-one million
coins and never be produced again.
Because no one can arbitrarily decide to print more bitcoins, and because no
banks intermediate the storage and spending of the currency, the value of a
bitcoin is determined by market demand. Wilson finds this very attractive.
But where a currency exists, capitalism will inevitably find it. In recent
months, Bitcoin has caught the attention of entrepreneurs, many funded by
venture-capital firms, who have begun building Bitcoin-related start-ups. The
companies include exchanges where people can trade bitcoins, along with
services that let people store and spend the currency in places ranging from
Amazon-style online markets to brick-and-mortar bars and restaurants.
The mainstream entrepreneurs who are interested in Bitcoin have found a haven
in a nonprofit called the Bitcoin Foundation. Writing about Bitcoin in April,
Maria Bustillos described its executives as a rational and sober group of
adult administrators who stand in contrast with the image of Bitcoin users
as wild-eyed kids camping out in half-deserted lofts. Members of the
foundation met in August with several federal agencies, including the Federal
Reserve, the F.B.I., and the Secret Service. On the surface, the meeting was
an educational exercise, meant to explain how Bitcoin works, but many
observers assume it was a step toward regulating the currency.
The foundation, which celebrates its first anniversary this month, calls
itself an advocacy group dedicated to serving the business, technology,
government relations, and public affairs needs of the Bitcoin community. One
goal, according to Jon Matonis, its executive director of the Bitcoin
Foundation, is to educate both public and private interestsincluding the
governmentabout how the currency operates. (The Foundation is not
pro-regulation as some have claimed, but it is pro-education, Matonis has
written, adding that he supports bitcoin education for legislative and
regulatory entities and that lobbying on behalf of Bitcoin is not
necessarily anti-market.)
Wilson, not surprisingly, sees working with the government as a betrayal of
Bitcoins fundamental purpose. The public faces of Bitcoin are acting as
counter-revolutionaries, he told me. Theyre actively working to try to
diffuse it, and to pollute it. He was referring, he said, not only to the
Bitcoin Foundation but to venture capitalists and entrepreneurs in New York
and Silicon Valley who increasingly embrace the currency as a way to profit,
but dont share his revolutionary aims. (Matonis said he is aware of Wilsons
concerns. I dont see my role as advancing crony capitalism, he said.)
Wilson believes Bitcoin should remain the backbone of a separate economy that
undermines the governments ability to collect taxes and to control the value
of currencynot be subsumed into the mainstream economy.
The state is basically allowed because we have all chosen to use these
certain institutions to channel our activity and commerce, he told me. But
when we are enabled, through alternative means and technologies, to channel
our commerce as we will, channel our production as we will, the state simply
Not everyone agrees, of course, that society would benefit from the
disappearance of governments. Wilson used the Liberator to make the point
that the government shouldnt regulate the flow of information; he wants to
use Bitcoin to help build an economy outside of the governments reach.
But his ideology, taken to its logical conclusion, would also leave services
like roads, libraries, fire fighting, and policing in the hands of the
private sectorwhose interests may not be aligned, Wilsons critics argue,
with those of the public at large.
Wilson knows that he could see blowback for his stance against the
foundation: as a self-described crypto-anarchist, perhaps he shouldnt be
so concerned with who is or isnt determining the currencys future. And if
the U.S. government attempts to regulate the currency, which seems likely,
Wilson will also find himself once again in direct opposition to the
Wilson and the suit-and-tie-wearing people at the Bitcoin Foundation share a
common interest in bringing Bitcoin to as many people as possible. The
foundation seems willing to play nicely with the establishment, and has been
open to hearing about the interests of old-school players like venture
capitalists and government regulators. Wilson, however, who was only recently
firing an illicit gun into the desert, isnt looking only for a new currency
but for another way to liberate himselfand othersfrom government oversight.
Michael del Castillo is the technology and innovation reporter at Upstart
Business Journal, a member of American City Business Journals, which is a
sister publication to Cond Nast. A graduate of Columbia University, he is
also the cofounder of Literary Manhattan, a nonprofit dedicated to promoting
Manhattans literary community and creating new ways to appreciate
Illustration by Grafilu.

@_date: 2013-09-25 14:18:08
@_author: Eugen Leitl 
@_subject: [Cryptography] Hardware Trojan Protection 
On 9/22/13 at 6:07 PM, leichter at lrw.com (Jerry Leichter) wrote in
another thread:
You might get a reasonable level of protection implementing the core
of the crypto operations in a hardware security module (HSM) using
Field Programmable Gate Arrays (FPGA) or Complex Programmable Logic
Device (CPLD). There is an open source set of tools for programming
these beasts based on Python called MyHDL . The EFF DES
cracker may have some useful ideas too.
The largest of these devices are also pressing the current chip
limits. There isn't a lot of extra space for Trojans. In addition,
knowing what to look at is somewhat difficult if pin assignments etc
are changed from chip to chip at random.
As with any system, there are tool chain issues. Open source helps,
but there is always the Key Thompson attack. The best solution I can
think of is to audit the output. Look very carefully at the output of
the tool chain, and at the final piece that loads the configuration
data into the device.
Cheers - Bill

@_date: 2013-09-25 22:21:00
@_author: Eugen Leitl 
@_subject: The Compromised Internet 
About your only choices are hams or (slightly higher budget)
microsats with onboard flash and DTN (notice you can deliver
packets during flyby). Hams also do launch microsats,
so there's some overlap. I've been waiting for consumer
phased arrays, just saw Locata VRay today -- perhaps not
for much longer now. Prime your phased array with s00per-s3kr1t
sat ephemerides, and you're good to go. Really hard to
jam, too -- optical ones impossible to jam, even.
For very high latency you could just use a global sneakernet.
 has some numbers. You could probably
already run stock Usenet over uucp over that.

@_date: 2013-09-25 22:45:25
@_author: Eugen Leitl 
@_subject: The Compromised Internet 
It's not mathematics, it's braindead algorithms. Geographic routing
needs no admin chatter. You only need to handle the edge cases.
Notice that 40 GBit/s fiber WAN is low end, while your LoS WLAN will
have trouble transporting even 10 MBit/s in adverse weather.

@_date: 2013-09-26 08:19:00
@_author: Eugen Leitl 
@_subject: [cryptography] The Compromised Internet 
Here's a potentially disruptive technology for global communication
that bypasses the fiber infrastructure, and hence more difficult
to tap and almost impossible to disrupt by other means than
total orbit denial weapons.
NASA prepares to launch 600Mbps space laser system to replace conventional radio links
By Sebastian Anthony on August 29, 2013 at 10:05 am19 Comments
NASA is preparing to launch the Lunar Laser Communications Demonstration (LLCD), a testbed that will use lasers to send and receive data between Earth and the Moon. This will be the first time that NASA uses lasers instead of conventional S-band radio waves to communicate with spacecraft, allowing for massive data rates of up to 600 megabits per second, while also consuming much less power and requiring much smaller antennae. Ultimately, shifting to laser-based communications will allow NASA to receive much more data from spacecraft, allowing them to be outfitted with high-res cameras and other modern sensors that generate more data than S-band links can support.
Optical communications, as opposed to radio frequency (RF) communications (or simply radio), are desirable for three key reasons: Massive bandwidth, higher security, and lower output power requirements. All of these traits derive from the frequency of optical and radio waves. While S-band signals are in the 2-4GHz range (similar to your GSM, LTE, or WiFi link), the laser light used by the LLCD (near-infrared in this case) is measured in hundreds of terahertz. As a result, the wavelength of S-band signals is around 10cm, while near-infrared has a wavelength of just 1000nm  or about 100,000 times shorter. Not only can you cram a lot more data into into the same physical space, but theres also terahertz (compared to megahertz in the S band) of free, unlicensed space that can be used.
A diagram of the LLCD architecture
Because the wavelength is smaller, the sending and receiving antennae can also be a lot smaller, allowing for smaller/lighter spacecraft and much easier reception here on Earth. By the time a conventional RF signal arrives at Earth from outer space, the beam can cover an area as wide as 100 miles, requiring very large dish antennae (such as the Deep Space Network) to pick those signals up. Receiving laser signals, which are 100,000 times shorter, requires a much smaller dish. As a corollary, due to these beams being much tighter, theyre much harder for an enemy to snoop on, thus increasing security. Transmitting data via laser also requires less power than RF.
NASA's LLCD laser link diagram
The LLCD will be deployed upon the Lunar Atmosphere Dust Environment Explorer (LADEE), which is scheduled for launch in September. LADEE (which could be pronounced lay-dee or lad-ee, were not sure) will orbit the Moon, seeking to confirm whether the mysterious glow observed by Apollo astronauts was caused by dust in the lunar atmosphere. Thanks to the LLCD, NASA will have a 20Mbps uplink to LADEE (apparently 4,800 times faster than existing S-band uplinks), and LADEE will have a 600Mbps downlink to NASA (five times faster than current state-of-the-art lunar-distance links). The mission will only last for 30 days, after which, if its a success, NASA will launch the long-duration Lunar Communications Relay Demonstration (LCRD), which will hitch a ride aboard a commercial Loral satellite. The LCRD will allow NASA to perform further testing of space laser communications, with the hope of eventually replacing RF links in future spacecraft.
Moving forward, space laser communications will allow for the creation of spacecraft that are smaller, cheaper, and capable of more advanced functionality. With 600Mbps of downlink capacity, well be able to outfit spacecraft with high-resolution cameras and other advanced sensors that generate vast amounts of data  and view that data in real time, rather than waiting for the data to slowly dribble over the airwaves.

@_date: 2013-09-26 08:51:21
@_author: Eugen Leitl 
@_subject: Fwd: [cryptography] The Compromised Internet 
This was an off-list exchange actually, but what the hell.
LEO is a volume, not a surface. You can have as many flocks up
there as you like, if you can afford it.
I'm optimizing against people who walk up, and dismantle your
wireless mesh, or down the Internet in your country. It's really
hard to jam the sky, especially in VIS range.
Yes, you can fry them with ground laser or fill up orbit
with tungsten pellets. However, such things are quite frowned
upon, especially the latter option.
Surprise me.

@_date: 2013-09-26 16:17:09
@_author: Eugen Leitl 
@_subject: Fwd: [cryptography] The Compromised Internet 
If the VPN bridges go down, you're back to mice and pumpkins.
There are obvious values in urban-area public meshes, and long
distance WLAN, but it's no way to deliver messages globally,
even as simple as texting equivalent. The buck does definitely
stop when surf is lapping at your toes.
What is exactly is wrong with frequent fliers carrying
smartphones with or similar?
You need to track a given small, rapidly moving patch of sky in realtime, whether by parabol dish, amateur astronomic instrument, or phased array flat plate or half-dome. The bird is serving hundreds or thousands people ground-side as it passes by. If you really want to jam all these
at the same time you'll need a nuke.
Taking out the bird from the ground turns a game of
cat and mouse, if you're dumping phonesats by the
satbusload -- these are short-lived, anyway, and need
to be constantly replenished. Orbital denial against small cross-section targets in a really low orbit which can be replenished cheaply will make every country with space access very mad at you, which is dangerous to your None of the approaches are mutually exclusive.
Use meshes, link them up via VPN tunnels across
Internet, use DTN with avian carriers, or phonesats.

@_date: 2013-09-26 17:02:18
@_author: Eugen Leitl 
@_subject: Fwd: [cryptography] The Compromised Internet 
They want to pick up a parabolic dish, a LoS laser or a
phased array tracking a point source overhead, all sending
at maybe 5-10 W power? Sure, if your sky is thick with mapping drones. Sounds like
a fifth world problem.
Isotropic radiators with high power are easy to spot.
Dynamic tight beams need at least a passing point of alignment
to get a position fix on the ground station. NSA sigint
used that microwave LoS interception, but this wouldn't
scale for millions of users and very brief low-power
bursts during random alignment events.
Or maybe you just buy  or the lower-grade
gear for LoS.
Phased arrays which are flat or half domes are compact and don't
look like anything from air. If you're clever, you can integrate
these into a PV panel.

@_date: 2013-09-26 17:50:39
@_author: Eugen Leitl 
@_subject: sneakernet calculation 
You overestimate the amount of useful content the Internet
carries. Let's assume you just want to deliver text messages
hand-entered by people. Let's say 10^9 people/day care to enter some ~kByte of text. That's a mere TByte/day, uncompressed.

@_date: 2013-09-27 13:52:19
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Payment Protocol: BIP 70, 71, 72 
Hash: SHA1
DLP (data loss prevention) products usually have MITM capability, to
make sure that proprietary information isn't being exfiltrated.  Also,
some companies have full packet capture policies.  The technology is
out there and people buy and use it.  Whether or not they're going to
care about Bitcoin URIs in the short term, I don't know.
Some of the companies documented here have such products:
You are correct in that the incentive to carry out MITM attacks in
this use case may not be there.  However, detecting transactions may
be more useful to an attacker than meddling with them.

@_date: 2013-09-27 16:53:39
@_author: Eugen Leitl 
@_subject: What the heck is going on with =?utf-8?Q?N?= 
What the heck is going on with NISTs cryptographic standard, SHA-3?
by Joseph Lorenzo Hall [1]
September 24, 2013
(Warning: this is a fairly technical post about cryptographic standards
The cryptographic community has been deeply shaken since revelations earlier
this month [2] that the National Security Agency (NSA) has been using a
number of underhanded methods  stealing encryption keys, subverting
standards setting processes, planting backdoors in products  to undermine
much of the encryption used online. This includes crucial pieces of
e-commerce like HTTPS (SSL/TLS) and Virtual Private Networks (VPN) that we
use each day to purchase things online, to socialize in private, and that
businesses use to communicate confidential and proprietary information. While
the reporting has been vague and hasnt pointed to specific software versions
or protocols that have been compromised, last week RSA Security  a major
supplier of cryptographic software and hardware  initiated a product recall
[3] of sorts, warning users that one of its popular software encryption
products contained a likely NSA-planted backdoor. The practical implication
of the RSA recall is that much of the encryption that used this product since
2007 isnt nearly as secure as it was supposed to be.
Those of us who follow developments in the cryptographic community have
noticed another troubling development: there are a number of cryptographers
upset with how the National Institute of Standards and Technology (NIST) is
standardizing a new set of encryption algorithms called SHA-3 (which stands
for the third version of the Secure Hashing Algorithm). The remainder of this
post explains what is going on with SHA-3 and how NIST could diffuse this
particular controversy while it still has the chance.
(Warning: In this post, Im assuming the reader is familiar with the concepts
underlying basic encryption tools, called cryptographic primitives, such as
hash functions [4], digital signatures [5], and message authentication codes
What is SHA-3?
SHA-3 is the next generation hash algorithm being standardized by NIST. In
2005, researchers developed an attack [7] that called into question the
security guarantees of an earlier secure hash algorithm, SHA-1. The
characteristics of this 2005 attack seemed to hint that it could be refined
to attack many of the secure hash functions at the time, including SHA-0,
MD4, MD5 and even SHA-2. At the time, for many cryptographers, the message
was clear: a new hash algorithm is needed and it should be based on
completely different underlying mathematics that are not susceptible to the
attacks threatening known hash functions. To be clear: SHA-1 is thought to be
on its way out, as people expect the earlier attacks to be improved
considerably in the coming years and there hasnt been any result that calls
into question the soundness of SHA-2 at all. Attacks always improve, so its
imperative that there is an alternative hash function ready to go when and if
the floor falls out of the earlier hash functions.
NISTs cryptographic technology group [8] is world-renowned for cryptographic
algorithm standardization. In 2007, NIST began the process to develop and
standardize a new secure hash algorithm that would be called SHA-3. The
process for choosing a new algorithm was designed as a competition: new
candidate algorithms were submitted by more than 60 research teams and over
five years the entrants were whittled down to a set of finalists, from which
a winner was chosen. In October of last year, NIST announced [9] that a team
of Italian and Belgian cryptographers had won the competition with their
submission named, Keccak (pronounced KECH-ack).
What has NIST done with SHA-3?
Since the announcement of Keccak as the winner, NIST has been working hard to
turn Keccak into a standard. That is, NIST cant just point to the academic
paper and materials submitted by the Keccak team and call that a standard.
NIST has to write the algorithm up in a standards-compliant format and
include it in other NIST cryptographic standards documents, such as a
successor to the Secure Hash Standard document (FIPS Publication 180-4) [10].
Heres where the controversy starts.
One of the most accomplished civilian cryptographers, NISTs John Kelsey,
gave an invited talk at a conference in August, the Workshop on Cryptographic
Hardware and Embedded Systems 2013 (CHES13) [11], where he described some of
the changes NIST has made to Keccak in turning it into a standard. The
changes were detailed in five slides (slides 44-48) of Kelseys slide deck
for his talk [12]. Two major changes puzzled some in attendance:
In the name of increased performance (running faster in software and
hardware), the security levels of Keccak were drastically reduced. The four
versions of the winning Keccak algorithm had security levels of 224-bits,
256-bits, 384-bits, and 512-bits. However, from Kelseys slides, NIST intends
to standardize only two versions, a 128-bit and a 256-bit version.  Some of
the internals of the algorithm had been tweaked by NIST  some in cooperation
with the team that submitted Keccak  to improve performance and allow for
new types of applications.  Essentially, NIST had changed Keccak to something
very different from what won the 5-year competition. Since this talk,
cryptographers have been abuzz with this news and generally very critical of
the changes (e.g., folks like Marsh Ray on Twitter [13]).
What are the issues with SHA-3 standardization?
So, whats the big deal? Well, the problems here cluster in five areas:
Process: From a simple due process perspective, after a five-year hard-fought
competition, to make large changes to the winning algorithm is simply
problematic. The algorithm being standardized is very different from the
winning Keccak, which beat 62 other high-powered cryptography research groups
in a 5-year competition. (To be fair, its not like these changes came out of
the blue. However, given the new political environment reality itself has
changed.) No security improvement: The SHA-3 version of Keccak being proposed
appears to provide essentially the same level of security guarantees as
SHA-2, its predecessor. If we are going to develop a next generation hash,
there certainly should be standardized versions that provide a higher
security level than the older hash functions! NIST, in the original call for
submissions, specifically asked for four versions in each submission, with at
least two that would be stronger than what was currently available, so its
hard to understand this post-competition weakening.  Unclear implications of
internal changes: The changes made to Keccak to get to SHA-3 may be so
substantial as to render the cryptanalysis that was performed during the
competition moot. That is, all the intense number crunching cryptographers
performed during the competition to try and break the submitted ciphers to
prove their strength/weakness simply doesnt apply to the modified form of
Keccak that NIST is working on.  No real need for high-performance hashes:
NIST said it weakened the security levels of the winning Keccak submission to
boost performance. (Weaker versions of hash functions run faster.) However,
there is not clearly a need for another fast hash algorithm. For example, to
get exceedingly technical for a moment: in communications security, hashes
are used for a few purposes and most are computed on small inputs  where
performance isnt a concern  and in cases where performance is a concern due
to large inputs (e.g., with message authentication codes or MACs), many
applications are moving away from hash-based MACs (HMAC) to other types of
MACs like GMAC [14] that are not based on hash functions.  NISTs reputation
is undermined: Kelseys CHES13 talk was given in mid-August, two weeks
before the NSA encryption revelations. Those revelations [2] suggest that
NSA, through an intelligence program called BULLRUN actively worked to
undermine NISTs effort to standardize strong cryptography. NIST could not
have known how the changes it made might appear once that reporting had cast
a pall over NIST cryptographic standards setting. The changes made to Keccak
undoubtedly weaken the algorithm, calling NISTs motives into question in
light of the NSA revelations (regardless of their actual intentions).  None
of this is irreversible.
What could NIST do to diffuse this controversy?
Kelseys slides indicate that NIST is on track to standardize the
NIST-modified version of Keccak as SHA-3 and issue a draft standard in late
October for public comment. If the issues above are not addressed in that
draft standard, there will be considerable hue and cry from the cryptographic
community and it will only serve to reinforce the more general concerns about
NISTs cooperation with the NSA. Its in no ones interest to feed the flames
of NIST scaremongering and we all have an interest in NIST as a trusted place
for science and standardization. In that spirit, there are a number of things
NIST can do to calm this storm (and please consider joining NISTs Hash Forum
[15] to discuss this further):
Add back high-security modes: NIST must ensure that SHA-3 has strong modes of
operation. NIST should at least add back in a 512-bit security level version
of Keccak so those users who want exceedingly high security and dont worry
as much about performance have a standardized mode that they can use. In
fact, if NIST is worried about performance, it probably makes sense to
standardize the as-submitted versions of Keccak (224, 256, 384, 512-bit
security levels) and add in a much weaker but high-performance 128-bit
version for those users who want to make that trade-off. This would be the
Kumbaya solution, as it would have five security levels with both the
NIST-modified versions and the as-submitted Keccak versions.  Justify
optimizations and internal changes: NIST has obviously made significant
internal changes to the Keccak algorithm. This means that the NIST-modified
Keccak and the winner of the SHA-3 competition are likely to be very
different. To be sure, there are probably some very good reasons for the
changes, but we dont know what they are, and it would be unfortunate to
learn them simply in the draft standard as published in October. Extensive
changes should technically be subject to the cryptanalysis that was brought
to bear during the actual competition. Unfortunately, it will be impossible
to muster the cryptographic scrutiny necessary to examine the NIST-modified
Keccak as the resources and teams that worked on this during the competition
are no longer available. Here, it makes sense for NIST to standardize both
the winning version of Keccak and NISTs optimized version (SHA-3-Opt
maybe?), so that implementers can have their pick of whether they want the
Keccak that was subject to the grueling competition or an improved version
that hasnt been subject to as much scrutiny.  Improve the standardization
process: No one doubts that NIST runs high-quality cryptographic
competitions. The many-year competitions that resulted in AES (the Advanced
Encryption Standard) and SHA-3 marshaled the most gifted cryptographic
thinkers in the world to shake down very exotic forms of mathematics to
result in very strong, clever and useful practical outcomes. The resulting
algorithms look indistinguishable from magic to many of us who are not
steeped in the fine art of cryptography. However, the process of getting from
the algorithm that won the competition to a standard is a dark and mysterious
process, and it need not be. While the relationship between NSA and NIST has
always made many of us uneasy, in light of recent revelations, its
especially important that this standardization step be open and transparent
with a formal process that works to ensure that all decisions are made in a
well-documented manner and that conditions that ensured an algorithm
withstood withering scrutiny during a competition do not subsequently change
dramatically during the standardization process.  At CDT, we work hard to
make sure that standards processes serve the public interest in an open, free
and innovative Internet. Well be advocating for changes in standards
processes at NIST so that it remains an unbiased, trusted, and scientific
venue for developing cybersecurity and cryptographic standards.
UPDATE [2013-09-24T17:41:24]: Changed title to better reflect that SHA-3 is
not an encryption standard but a hash function standard (without using "hash
function" in the title). Better qualified that SHA-1 is likely weak in the
face of government-level adversaries. Further update [2013-09-25T06:09:38]:
clarified that SHA-1 is essentially on its way out.
Copyright  2013 by Center for Democracy & Technology.
The content throughout this website that originates with CDT can be freely
copied and used as long as you make no substantive changes and clearly give
us credit. Details.
Source URL: [1] [3] [4] [5] [6] [7] [8] [9] [10] [11] [12] [13] [14] [15]

@_date: 2014-08-06 13:31:49
@_author: Eugen Leitl 
@_subject: lowRISC -- fully open hardware systems 
Open to the core
lowRISC is producing fully open hardware systems. From the processor core to the development board, our goal is to create a completely open computing eco-system.
Our open-source SoC (System-on-a-Chip) designs will be based on the 64-bit RISC-V instruction set architecture. Volume silicon manufacture is planned as is a low-cost development board.
lowRISC is a not-for-profit organisation working closely with the University of Cambridge and the open-source community.
To keep track of the project, follow  or join our announcements list by entering your email below:
  Submit
The Team
Robert Mullins - Computer Laboratory, University of Cambridge, co-founder of Raspberry Pi
Gavin Ferris - Dreamworks, Radioscape (co-founder), Aspect Capital (former CIO)
Alex Bradbury - Computer Laboratory, University of Cambridge and Raspberry Pi
Technical Advisory Board
Krste Asanovic (UC Berkeley)
Julius Baxter (OpenRISC)
Bunnie Huang (Hacker)
Michael Taylor (UCSD)
We are currently hiring. Two new positions are available at the Computer Laboratory, University of Cambridge.
Contact us at info

@_date: 2014-08-19 10:58:20
@_author: Eugen Leitl 
@_subject: Gyroscopes in Android phones can be turned into always-on 
Mobile handsets are intrinsically untrusted. You can put up the
baseband spyware into a MiFi, and only use WLAN from a trusted,
blobless device, only with end to end encryption.
Of course this means you have to tear down your neural-sourced
MiFi puck first, to see what you can see.
In unrelated vein, I've recently read that it was the spooks
that killed the digital pulse radio star, by limiting licensend
power to toy levels. Apparently they were very unhappy with a
radio that's hard to look for.

@_date: 2014-08-26 13:05:57
@_author: Eugen Leitl 
@_subject: If you ran a Bitcoin related service before the thing hit $100 you 
A Law Enforcement Encounter: If you ran a Bitcoin related service before the
thing hit $100 you prolly ought to be somewhat concerned and/or prepared
Posted on August 25, 2014
So this afternoon I was roused from my day slumber by vigorous knocking at my
front door. Under the impression the two gentlemen at my door step might be
some sort of process servers or collections agents visiting about my
substantial student loan debt I begrudgingly inquire as to what is going on.
They inquire as to who I am, and I inquire as to who they are. 1 When they
show badges I offer confirmation that I am indeed the person referred to
frequently by the slave name2 they used.
Their inquiry was laser focused on any information I might have about
connections between BTCPak  and The Silk Road3 of which I have none that
can't be discovered by scraping public information off of the public web.
BTCPak was this thing that accepted Bitcoin and provided prepaid codes you
could load on to shitty Debit cards. I was new and didn't know any better so
I had some of the most costly eatings and drinkings of my life. BTCPak was
one of the more expensive ways to turn Bitcoin into US Dollars, but its
advantage was it was fast and had a great reputation for working. If there
weren't any codes to be had, the site wouldn't take Bitcoin. If you sent it
Bitcoin it gave you the code in six confirmations.  There was no market I
knew of to feed the codes the other direction.  The entire venture didn't
even really seem to be a business. It just seemed to be a machine DBordello
built to acquire Bitcoin in an automated fashion which as far as I can tell
was turned off, because the future he was buying all of the cheap coins for
finally arrived.
A notable thing that kept coming up was an incredulity on the part of the
investigators was that there was much of anything happening in early Bitcoin
that wasn't shady and related to Black Market drugs. In reality a lot of
stuff was happening on the plaintext Internet without the slightest shade of
illegality. I mentioned the Devcoin4 thing that was my first source of any
actual amount of Bitcoin. Devcoin was/is this arrangement where by dumping
text into a wiki you earned coins on an altchain. You could then take the
coins to this shitty exchange called Vircurex where you could dump them for
BTC. As astounding as it seems at the time when I started doing this devcoin
thing dumping a few thousand words in their wiki was probably worth a two
digit number of BTC in the first month I got paid. Fuck me for having been so
shortsighted and having not quite stumbled into what actual people were
writing about Bitcoin. As astoundingly stupid as the premise sounds much of
early Bitcoin involved people throwing coins around for appallingly,
dumbfoundingly, stupid reasons in the name of "supporting Bitcoin" and
"getting the ecosystem moving." Many stupid and lucrative things were scams
of the Pirateat40 and GLBSE sort,5 I instead did the writing for Devcoins
thing because I like sleeping soundly at night.
What you, dear reader can take from this encounter is that if you were
involved with Bitcoin before Coindesk6 became a thing and live in the United
States, you too might be questioned by agents of two separate federal law
enforcement agencies at the same time. If they are asking about BTCPak now,
who knows how long the backlog of sites and ventures they are working through
is. It's something to prepare for.  When the agents suggested that I probably
never expected they'd find me, they seemed a little shock when I replied that
I kind of expected this attention eventually. I don't exactly keep the
connections between my self and my slave name incredibly well guarded
secrets, at least not on the scale of Silk Road users and administrators.
This old Boy Scout would like to remind everyone of the motto: "Be Prepared".
The reason for this is in my jurisdiction failure to identify yourself in a
law enforcement encounter is a crime  of questionable constitutional
provenance, while having a conversation with a debt collector or process
server that consists of nothing on your part other than intoning "Fuck You" a
myriad of different was is great justice for all and legally sound.  
This odd thing happens when use a screen name  long enough and act with
established, credible pseudononymity in a space long enough, especially one
with such an effective Web of Trust surrounding it. The layperson Toby gets
asked about the learned amateur Bingo's hobby and suddenly you find yourself
in an IRL encounter where you feel like you are wearing a person suit.
Welcome to the future, its a weird fucking place.  
That thing I've avoided and wrote about on this blog before.   
Even though devcoin has dropped twenty times in value from ~200 satoshis per
to ~10 satoshis per now, holding it would still have booked a dollar
denominated gain over the time. But no, holding Devcoin would be stupid.  
Well so it would have seemed at least to the people running them. Running
such a thing though doesn't fit my acceptable risk profile in the same way
The Silk Road never fit my acceptable risk profile.  
Yes, the FBI agent name dropped Coindesk as a thing he reads as well as
admitting to having a small amount of Bitcoin.  
This entry was posted in Bitcoin, Commentary, Disclosures, News. Bookmark the

@_date: 2014-08-29 10:26:53
@_author: Eugen Leitl 
@_subject: Hal Finney cryopreserved 
Max More max at maxmore.com Thu Aug 28 18:41:54 UTC 2014
Previous message: [ExI] It's alive?
Next message: [ExI] Hal Finney being cryopreserved now
Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]
I am both sad and happy to tell you that long-time Extropy
Institute/Extropy magazine/Extropy chat list member -- and honored
cypherpunk and Bitcoin pioneer  was declared clinically dead this morning
and is now being cryopreserved.
Hal was diagnosed with ALS five years ago. He made it clear that once he
lost the ability to communicate, he did not want his vital functions
supported any further but should be allowed to cease functioning and
promptly be cryopreserved. Hal and Fran Finney arrived in Scottsdale,
Arizona on Tuesday where he was checked into ICU of a hospital near Alcor.
After administration of drugs to ensure no consciousness, his ventilator
was removed. Although the doctors expected all breathing to cease within an
hour, Hals body kept going until shortly before 9:00 am this morning,
August 28, 2014.
Immediately after pronouncement of legal death, Alcors standby team went
into action, restoring circulation, ventilation, administering an array of
medications, and initiating external cooling. Surgery is currently underway
to enable us to replace Hals blood and interstitial fluids with
cryoprotectant. Once perfusion is finished we will be able to plunge Hals
temperature down past the freezing point without any significant ice
formation. Once he is down to around -110 degC we will slow cooling and
take a couple more days to reach the final storage temperature of -196
degC. After that, Hal will be placed in long-term storage and cared for
until the day when repair and revival may be possible.
Hals wife, Fran (also an Alcor member) has stayed by Hals side throughout
and is observing our procedures firsthand.
Since Hal is open about his Alcor membership and said that he would be
happy for us to tell people about his choice if it might be good for
cryonics, we will be issuing a press release, as well as writing something
more extensive for *Cryonics* magazine and elsewhere. If you have thoughts
on Hal and his life and work, please send them to me.
Hal, I know I speak for many when I say that I look forward to speaking to
you again sometime in the future and to throwing a party in honor of your

@_date: 2014-08-06 13:31:49
@_author: Eugen Leitl 
@_subject: lowRISC -- fully open hardware systems 
Open to the core
lowRISC is producing fully open hardware systems. From the processor core to the development board, our goal is to create a completely open computing eco-system.
Our open-source SoC (System-on-a-Chip) designs will be based on the 64-bit RISC-V instruction set architecture. Volume silicon manufacture is planned as is a low-cost development board.
lowRISC is a not-for-profit organisation working closely with the University of Cambridge and the open-source community.
To keep track of the project, follow  or join our announcements list by entering your email below:
  Submit
The Team
Robert Mullins - Computer Laboratory, University of Cambridge, co-founder of Raspberry Pi
Gavin Ferris - Dreamworks, Radioscape (co-founder), Aspect Capital (former CIO)
Alex Bradbury - Computer Laboratory, University of Cambridge and Raspberry Pi
Technical Advisory Board
Krste Asanovic (UC Berkeley)
Julius Baxter (OpenRISC)
Bunnie Huang (Hacker)
Michael Taylor (UCSD)
We are currently hiring. Two new positions are available at the Computer Laboratory, University of Cambridge.
Contact us at info at lowrisc.org

@_date: 2014-08-19 10:58:20
@_author: Eugen Leitl 
@_subject: Gyroscopes in Android phones can be turned into always-on 
Mobile handsets are intrinsically untrusted. You can put up the
baseband spyware into a MiFi, and only use WLAN from a trusted,
blobless device, only with end to end encryption.
Of course this means you have to tear down your neural-sourced
MiFi puck first, to see what you can see.
In unrelated vein, I've recently read that it was the spooks
that killed the digital pulse radio star, by limiting licensend
power to toy levels. Apparently they were very unhappy with a
radio that's hard to look for.

@_date: 2014-08-26 13:05:57
@_author: Eugen Leitl 
@_subject: If you ran a Bitcoin related service before the thing hit $100 you 
A Law Enforcement Encounter: If you ran a Bitcoin related service before the
thing hit $100 you prolly ought to be somewhat concerned and/or prepared
Posted on August 25, 2014
So this afternoon I was roused from my day slumber by vigorous knocking at my
front door. Under the impression the two gentlemen at my door step might be
some sort of process servers or collections agents visiting about my
substantial student loan debt I begrudgingly inquire as to what is going on.
They inquire as to who I am, and I inquire as to who they are. 1 When they
show badges I offer confirmation that I am indeed the person referred to
frequently by the slave name2 they used.
Their inquiry was laser focused on any information I might have about
connections between BTCPak  and The Silk Road3 of which I have none that
can't be discovered by scraping public information off of the public web.
BTCPak was this thing that accepted Bitcoin and provided prepaid codes you
could load on to shitty Debit cards. I was new and didn't know any better so
I had some of the most costly eatings and drinkings of my life. BTCPak was
one of the more expensive ways to turn Bitcoin into US Dollars, but its
advantage was it was fast and had a great reputation for working. If there
weren't any codes to be had, the site wouldn't take Bitcoin. If you sent it
Bitcoin it gave you the code in six confirmations.  There was no market I
knew of to feed the codes the other direction.  The entire venture didn't
even really seem to be a business. It just seemed to be a machine DBordello
built to acquire Bitcoin in an automated fashion which as far as I can tell
was turned off, because the future he was buying all of the cheap coins for
finally arrived.
A notable thing that kept coming up was an incredulity on the part of the
investigators was that there was much of anything happening in early Bitcoin
that wasn't shady and related to Black Market drugs. In reality a lot of
stuff was happening on the plaintext Internet without the slightest shade of
illegality. I mentioned the Devcoin4 thing that was my first source of any
actual amount of Bitcoin. Devcoin was/is this arrangement where by dumping
text into a wiki you earned coins on an altchain. You could then take the
coins to this shitty exchange called Vircurex where you could dump them for
BTC. As astounding as it seems at the time when I started doing this devcoin
thing dumping a few thousand words in their wiki was probably worth a two
digit number of BTC in the first month I got paid. Fuck me for having been so
shortsighted and having not quite stumbled into what actual people were
writing about Bitcoin. As astoundingly stupid as the premise sounds much of
early Bitcoin involved people throwing coins around for appallingly,
dumbfoundingly, stupid reasons in the name of "supporting Bitcoin" and
"getting the ecosystem moving." Many stupid and lucrative things were scams
of the Pirateat40 and GLBSE sort,5 I instead did the writing for Devcoins
thing because I like sleeping soundly at night.
What you, dear reader can take from this encounter is that if you were
involved with Bitcoin before Coindesk6 became a thing and live in the United
States, you too might be questioned by agents of two separate federal law
enforcement agencies at the same time. If they are asking about BTCPak now,
who knows how long the backlog of sites and ventures they are working through
is. It's something to prepare for.  When the agents suggested that I probably
never expected they'd find me, they seemed a little shock when I replied that
I kind of expected this attention eventually. I don't exactly keep the
connections between my self and my slave name incredibly well guarded
secrets, at least not on the scale of Silk Road users and administrators.
This old Boy Scout would like to remind everyone of the motto: "Be Prepared".
The reason for this is in my jurisdiction failure to identify yourself in a
law enforcement encounter is a crime  of questionable constitutional
provenance, while having a conversation with a debt collector or process
server that consists of nothing on your part other than intoning "Fuck You" a
myriad of different was is great justice for all and legally sound.  
This odd thing happens when use a screen name  long enough and act with
established, credible pseudononymity in a space long enough, especially one
with such an effective Web of Trust surrounding it. The layperson Toby gets
asked about the learned amateur Bingo's hobby and suddenly you find yourself
in an IRL encounter where you feel like you are wearing a person suit.
Welcome to the future, its a weird fucking place.  
That thing I've avoided and wrote about on this blog before.   
Even though devcoin has dropped twenty times in value from ~200 satoshis per
to ~10 satoshis per now, holding it would still have booked a dollar
denominated gain over the time. But no, holding Devcoin would be stupid.  
Well so it would have seemed at least to the people running them. Running
such a thing though doesn't fit my acceptable risk profile in the same way
The Silk Road never fit my acceptable risk profile.  
Yes, the FBI agent name dropped Coindesk as a thing he reads as well as
admitting to having a small amount of Bitcoin.  
This entry was posted in Bitcoin, Commentary, Disclosures, News. Bookmark the

@_date: 2014-08-29 10:26:53
@_author: Eugen Leitl 
@_subject: Hal Finney cryopreserved 
Max More max at maxmore.com Thu Aug 28 18:41:54 UTC 2014
Previous message: [ExI] It's alive?
Next message: [ExI] Hal Finney being cryopreserved now
Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]
I am both sad and happy to tell you that long-time Extropy
Institute/Extropy magazine/Extropy chat list member -- and honored
cypherpunk and Bitcoin pioneer  was declared clinically dead this morning
and is now being cryopreserved.
Hal was diagnosed with ALS five years ago. He made it clear that once he
lost the ability to communicate, he did not want his vital functions
supported any further but should be allowed to cease functioning and
promptly be cryopreserved. Hal and Fran Finney arrived in Scottsdale,
Arizona on Tuesday where he was checked into ICU of a hospital near Alcor.
After administration of drugs to ensure no consciousness, his ventilator
was removed. Although the doctors expected all breathing to cease within an
hour, Hals body kept going until shortly before 9:00 am this morning,
August 28, 2014.
Immediately after pronouncement of legal death, Alcors standby team went
into action, restoring circulation, ventilation, administering an array of
medications, and initiating external cooling. Surgery is currently underway
to enable us to replace Hals blood and interstitial fluids with
cryoprotectant. Once perfusion is finished we will be able to plunge Hals
temperature down past the freezing point without any significant ice
formation. Once he is down to around -110 degC we will slow cooling and
take a couple more days to reach the final storage temperature of -196
degC. After that, Hal will be placed in long-term storage and cared for
until the day when repair and revival may be possible.
Hals wife, Fran (also an Alcor member) has stayed by Hals side throughout
and is observing our procedures firsthand.
Since Hal is open about his Alcor membership and said that he would be
happy for us to tell people about his choice if it might be good for
cryonics, we will be issuing a press release, as well as writing something
more extensive for *Cryonics* magazine and elsewhere. If you have thoughts
on Hal and his life and work, please send them to me.
Hal, I know I speak for many when I say that I look forward to speaking to
you again sometime in the future and to throwing a party in honor of your

@_date: 2014-08-06 13:31:49
@_author: Eugen Leitl 
@_subject: lowRISC -- fully open hardware systems 
Open to the core
lowRISC is producing fully open hardware systems. From the processor core to the development board, our goal is to create a completely open computing eco-system.
Our open-source SoC (System-on-a-Chip) designs will be based on the 64-bit RISC-V instruction set architecture. Volume silicon manufacture is planned as is a low-cost development board.
lowRISC is a not-for-profit organisation working closely with the University of Cambridge and the open-source community.
To keep track of the project, follow  or join our announcements list by entering your email below:
  Submit
The Team
Robert Mullins - Computer Laboratory, University of Cambridge, co-founder of Raspberry Pi
Gavin Ferris - Dreamworks, Radioscape (co-founder), Aspect Capital (former CIO)
Alex Bradbury - Computer Laboratory, University of Cambridge and Raspberry Pi
Technical Advisory Board
Krste Asanovic (UC Berkeley)
Julius Baxter (OpenRISC)
Bunnie Huang (Hacker)
Michael Taylor (UCSD)
We are currently hiring. Two new positions are available at the Computer Laboratory, University of Cambridge.
Contact us at info at lowrisc.org

@_date: 2014-08-19 10:58:20
@_author: Eugen Leitl 
@_subject: Gyroscopes in Android phones can be turned into always-on 
Mobile handsets are intrinsically untrusted. You can put up the
baseband spyware into a MiFi, and only use WLAN from a trusted,
blobless device, only with end to end encryption.
Of course this means you have to tear down your neural-sourced
MiFi puck first, to see what you can see.
In unrelated vein, I've recently read that it was the spooks
that killed the digital pulse radio star, by limiting licensend
power to toy levels. Apparently they were very unhappy with a
radio that's hard to look for.

@_date: 2014-08-26 13:05:57
@_author: Eugen Leitl 
@_subject: If you ran a Bitcoin related service before the thing hit $100 you 
A Law Enforcement Encounter: If you ran a Bitcoin related service before the
thing hit $100 you prolly ought to be somewhat concerned and/or prepared
Posted on August 25, 2014
So this afternoon I was roused from my day slumber by vigorous knocking at my
front door. Under the impression the two gentlemen at my door step might be
some sort of process servers or collections agents visiting about my
substantial student loan debt I begrudgingly inquire as to what is going on.
They inquire as to who I am, and I inquire as to who they are. 1 When they
show badges I offer confirmation that I am indeed the person referred to
frequently by the slave name2 they used.
Their inquiry was laser focused on any information I might have about
connections between BTCPak  and The Silk Road3 of which I have none that
can't be discovered by scraping public information off of the public web.
BTCPak was this thing that accepted Bitcoin and provided prepaid codes you
could load on to shitty Debit cards. I was new and didn't know any better so
I had some of the most costly eatings and drinkings of my life. BTCPak was
one of the more expensive ways to turn Bitcoin into US Dollars, but its
advantage was it was fast and had a great reputation for working. If there
weren't any codes to be had, the site wouldn't take Bitcoin. If you sent it
Bitcoin it gave you the code in six confirmations.  There was no market I
knew of to feed the codes the other direction.  The entire venture didn't
even really seem to be a business. It just seemed to be a machine DBordello
built to acquire Bitcoin in an automated fashion which as far as I can tell
was turned off, because the future he was buying all of the cheap coins for
finally arrived.
A notable thing that kept coming up was an incredulity on the part of the
investigators was that there was much of anything happening in early Bitcoin
that wasn't shady and related to Black Market drugs. In reality a lot of
stuff was happening on the plaintext Internet without the slightest shade of
illegality. I mentioned the Devcoin4 thing that was my first source of any
actual amount of Bitcoin. Devcoin was/is this arrangement where by dumping
text into a wiki you earned coins on an altchain. You could then take the
coins to this shitty exchange called Vircurex where you could dump them for
BTC. As astounding as it seems at the time when I started doing this devcoin
thing dumping a few thousand words in their wiki was probably worth a two
digit number of BTC in the first month I got paid. Fuck me for having been so
shortsighted and having not quite stumbled into what actual people were
writing about Bitcoin. As astoundingly stupid as the premise sounds much of
early Bitcoin involved people throwing coins around for appallingly,
dumbfoundingly, stupid reasons in the name of "supporting Bitcoin" and
"getting the ecosystem moving." Many stupid and lucrative things were scams
of the Pirateat40 and GLBSE sort,5 I instead did the writing for Devcoins
thing because I like sleeping soundly at night.
What you, dear reader can take from this encounter is that if you were
involved with Bitcoin before Coindesk6 became a thing and live in the United
States, you too might be questioned by agents of two separate federal law
enforcement agencies at the same time. If they are asking about BTCPak now,
who knows how long the backlog of sites and ventures they are working through
is. It's something to prepare for.  When the agents suggested that I probably
never expected they'd find me, they seemed a little shock when I replied that
I kind of expected this attention eventually. I don't exactly keep the
connections between my self and my slave name incredibly well guarded
secrets, at least not on the scale of Silk Road users and administrators.
This old Boy Scout would like to remind everyone of the motto: "Be Prepared".
The reason for this is in my jurisdiction failure to identify yourself in a
law enforcement encounter is a crime  of questionable constitutional
provenance, while having a conversation with a debt collector or process
server that consists of nothing on your part other than intoning "Fuck You" a
myriad of different was is great justice for all and legally sound.  
This odd thing happens when use a screen name  long enough and act with
established, credible pseudononymity in a space long enough, especially one
with such an effective Web of Trust surrounding it. The layperson Toby gets
asked about the learned amateur Bingo's hobby and suddenly you find yourself
in an IRL encounter where you feel like you are wearing a person suit.
Welcome to the future, its a weird fucking place.  
That thing I've avoided and wrote about on this blog before.   
Even though devcoin has dropped twenty times in value from ~200 satoshis per
to ~10 satoshis per now, holding it would still have booked a dollar
denominated gain over the time. But no, holding Devcoin would be stupid.  
Well so it would have seemed at least to the people running them. Running
such a thing though doesn't fit my acceptable risk profile in the same way
The Silk Road never fit my acceptable risk profile.  
Yes, the FBI agent name dropped Coindesk as a thing he reads as well as
admitting to having a small amount of Bitcoin.  
This entry was posted in Bitcoin, Commentary, Disclosures, News. Bookmark the

@_date: 2014-08-29 10:26:53
@_author: Eugen Leitl 
@_subject: Hal Finney cryopreserved 
Max More max at maxmore.com Thu Aug 28 18:41:54 UTC 2014
Previous message: [ExI] It's alive?
Next message: [ExI] Hal Finney being cryopreserved now
Messages sorted by: [ date ] [ thread ] [ subject ] [ author ]
I am both sad and happy to tell you that long-time Extropy
Institute/Extropy magazine/Extropy chat list member -- and honored
cypherpunk and Bitcoin pioneer  was declared clinically dead this morning
and is now being cryopreserved.
Hal was diagnosed with ALS five years ago. He made it clear that once he
lost the ability to communicate, he did not want his vital functions
supported any further but should be allowed to cease functioning and
promptly be cryopreserved. Hal and Fran Finney arrived in Scottsdale,
Arizona on Tuesday where he was checked into ICU of a hospital near Alcor.
After administration of drugs to ensure no consciousness, his ventilator
was removed. Although the doctors expected all breathing to cease within an
hour, Hals body kept going until shortly before 9:00 am this morning,
August 28, 2014.
Immediately after pronouncement of legal death, Alcors standby team went
into action, restoring circulation, ventilation, administering an array of
medications, and initiating external cooling. Surgery is currently underway
to enable us to replace Hals blood and interstitial fluids with
cryoprotectant. Once perfusion is finished we will be able to plunge Hals
temperature down past the freezing point without any significant ice
formation. Once he is down to around -110 degC we will slow cooling and
take a couple more days to reach the final storage temperature of -196
degC. After that, Hal will be placed in long-term storage and cared for
until the day when repair and revival may be possible.
Hals wife, Fran (also an Alcor member) has stayed by Hals side throughout
and is observing our procedures firsthand.
Since Hal is open about his Alcor membership and said that he would be
happy for us to tell people about his choice if it might be good for
cryonics, we will be issuing a press release, as well as writing something
more extensive for *Cryonics* magazine and elsewhere. If you have thoughts
on Hal and his life and work, please send them to me.
Hal, I know I speak for many when I say that I look forward to speaking to
you again sometime in the future and to throwing a party in honor of your

@_date: 2014-07-02 18:41:25
@_author: Eugen Leitl 
@_subject: Court =?utf-8?B?4oCTIE9mZmljaWE=?= =?utf-8?Q?l?= statement part #1 
Apologies, not sure this has been posted already in the thread, I'm
 Court  Official statement part Posted on July 2, 2014 by Will
As seen possibly here, or here i lost the Tor case and was sentenced to 3
years probation (instead of 3 months jail) and all fees (court and experts,
Assumption ~30000EUR, not less than 20k for sure).
The sentence is based on 12 which allows for anyone to be dealt with as
perpetrator (which is a pretty dictatorial law IMO) and this is based on that
i knew it *could* possibly be used for criminal activity (in this case child
I wont write much more yet before i have the written ruling (i do not even
know my probation terms yet) but merely want to explain why i wont appeal
this sentence:
First would be that I simply cant afford it anymore, donations covered a lot
of lawyer fees but i had to use my entire money on this case as well, im now
bankrupt and the garnishment (a rare word, DE: Pfndung) of my income (to pay
the 20k+ costs) does not help with it either. I have high medical costs as
well besides which are more important. Im not really interested in more
external funding due to taxation issues with larger amounts (and i do not
want *another* crime on me).   Second is that i just want to be done with
this, i had now years of issues (i would write harassment but then i get
sued again for sure) (Ex: Citing my boss to the police for questioning (x3);
physically monitoring my boss in Vienna; citing friends to the police for
questioning (x2); confiscation of bank transaction data; Polish extradiction
threats for hacking cases there (x2); citing me for useless questioning
causing lawyer costs (x5+) etc. etc.)  Its now finally over and besides the
cost i CAN live with this sentence, it does not show up in police registers
and wont be an issue for work and alike in the future.   Third is the
mental component, this years of horror changed a lot up to me being
hospitalized (x3) with paranoid schizophrenia (which was a wrong diagnosis,
but still its not helpful if you HAVE to assume permanent monitoring of
everything), PTSD (among other issues) and now taking medication  It took
its toll, including me getting fired for being in the clinic/sick stay for a
long time, i just cant afford to loose my job or go the clinic again even if
i actually should be still there.   Fourth is the attention, media and
personal  I dont really like any attention on myself, especially when
others should get it (like some public cause, Pirateparty or alike).  
So this is it for now, stay tuned for more in a few days.

@_date: 2014-07-03 10:38:16
@_author: Eugen Leitl 
@_subject: REVERSE ENGINEERING NSA SPY =?utf-8?B?4oCY?= 
REVERSE ENGINEERING NSA SPY RETRO REFLECTOR GADGETS WITH THE HACKRF
In 2013 whistleblower Edward Snowden leaked (along with other documents) some
information about the American National Security Agencies (NSA) spy tools.
One such group of tools named retro reflectors has recently been
investigated and reverse engineered by Micheal Ossmann, the security
researcher behind the recently available for preorder HackRF software defined
radio. The HackRF is a SDR similar to the RTL-SDR, but with better
performance and transmit capabilities.
Newscientist Magazine has written an article about Ossmanns work here. From
their article a retro reflectors are described in the following quote.
One reflector, which the NSA called Ragemaster, can be fixed to a computers
monitor cable to pick up on-screen images. Another, Surlyspawn, sits on the
keyboard cable and harvests keystrokes. After a lot of trial and error,
Ossmann found these bugs can be remarkably simple devices  little more than
a tiny transistor and a 2-centimetre-long wire acting as an antenna.
The HackRF comes in to play in the following quote
Ossmann found that using the radio [HackRF] to emit a high-power radar signal
causes a reflector to wirelessly transmit the data from keystrokes, say, to
an attacker. The set-up is akin to a large-scale RFID- chip system. Since the
signals returned from the reflectors are noisy and often scattered across
different bands, SDRs versatility is handy, says Robin Heydon at Cambridge
Silicon Radio in the UK.
Ossmann will present his work at this years Defcon conference in August.

@_date: 2014-07-03 14:46:48
@_author: Eugen Leitl 
@_subject: XKeyscore-Quellcode: more english details requested 
According to fefe who's seen the source it's just a selector

@_date: 2014-07-03 15:16:13
@_author: Eugen Leitl 
@_subject: tools used by intelligence analysts 
*ORA for network analysis Pentaho for data transformation Rapid Miner for data mining Orange for data visualisations and analysis Maltego for the analysis of networks between people, companies, websites, etc. Apache Hadoop for large-scale, distributed computing and analysis
Axis Pro Starlight Analyst's Notebook Palantir XPLR witk Reddit plugin Tiny Tiny Rss Pligg Twitter, Reddit, ...
ARC GIS
CPOF Oryon  (?)
Investigative Dashboard  (?)

@_date: 2014-07-03 17:29:47
@_author: Eugen Leitl 
@_subject: NSA targets the privacy-conscious 
NSA targets the privacy-conscious
von J. Appelbaum, A. Gibson, J. Goetz, V. Kabisch, L. Kampf, L. Ryge
The investigation discloses the following:
Two servers in Germany - in Berlin and Nuremberg - are under surveillance by
the NSA.
Merely searching the web for the privacy-enhancing software tools outlined in
the XKeyscore rules causes the NSA to mark and track the IP address of the
person doing the search. Not only are German privacy software users tracked,
but the source code shows that privacy software users worldwide are tracked
by the NSA.
Among the NSA's targets is the Tor network funded primarily by the US
government to aid democracy advocates in authoritarian states.
 The XKeyscore rules reveal that the NSA tracks all connections to a server
that hosts part of an anonymous email service at the MIT Computer Science and
Artificial Intelligence Laboratory (CSAIL) in Cambridge, Massachusetts. It
also records details about visits to a popular internet journal for Linux
operating system users called "the Linux Journal - the Original Magazine of
the Linux Community", and calls it an "extremist forum".
Three authors of this investigation have personal and professional ties to
the Tor Project, an American company mentioned within the following
investigation. Jacob Appelbaum is a paid employee of the Tor Project, Aaron
Gibson is a paid contractor for the Tor Project, and Leif Ryge is a volunteer
contributor to various Tor-related software projects. Their research in this
story is wholly independent from the Tor Project and does not reflect the
views of the Tor Project in any way. During the course of the investigation,
it was further discovered that an additional computer system run by Jacob
Appelbaum for his volunteer work with helping to run part of the Tor network
was targeted by the NSA. Moreover, all members of this team are Tor users and
appear to be have been targets of the mass surveillance described in the
It is a small server that looks like any of the other dozens in the same row.
It is in a large room devoted to computers and computer storage, just like
every other room in this industrial park building on Am Tower Street just
outside the city of Nuremberg. That the grey building is surrounded by barbed
wire seems to indicate that the servers' provider is working hard to secure
their customers' data.
Yet despite these efforts, one of the servers is targeted by the NSA.
The IP address 212.212.245.170 is explicitly specified in the rules of the
powerful and invasive spy software program XKeyscore. The code is published
here exclusively for the first time.
After a year of NSA revelations based on documents that focus on program
names and high-level Powerpoint presentations, NDR and WDR are revealing NSA
source code that shows how these programs function and how they are
implemented in Germany and around the world.
Months of investigation by the German public television broadcasters NDR and
WDR, drawing on exclusive access to top secret NSA source code, interviews
with former NSA employees, and the review of secret documents of the German
government reveal that not only is the server in Nuremberg under observation
by the NSA, but so is virtually anyone who has taken an interest in several
well-known privacy software systems.
The NSA program XKeyscore is a collection and analysis tool and "a computer
network exploitation system", as described in an NSA presentation. It is one
of the agencys most ambitious programs devoted to gathering "nearly
everything a user does on the internet." The source code contains several
rules that enable agents using XKeyscore to surveil privacy-conscious
internet users around the world. The rules published here are specifically
directed at the infrastructure and the users of the Tor Network, the Tails
operating system, and other privacy-related software. Tor, also known as The Onion Router, is a network of several thousand
volunteer-operated servers, or nodes, that work in concert to conceal Tor
users' IP addresses and thus keep them anonymous while online.
Tails is a privacy-focused GNU/Linux-based operating system that runs
entirely from an external storage device such as a USB stick or CD. It comes
with Tor and other privacy tools pre-installed and configured, and each time
it reboots it automatically wipes everything that is not saved on an
encrypted persistent storage medium.
Normally a user's online traffic - such as emails, instant messages,
searches, or visits to websites - can be attributed to the IP address
assigned to them by their internet service provider. When a user goes online
over the Tor Network, their connections are relayed through a number of Tor
nodes using another layer of encryption between each server such that the
first server cannot see where the last server is located and vice-versa.
Tor is used by private individuals who want to conceal their online activity,
human rights activists in oppressive regimes such as China and Iran,
journalists who want to protect their sources, and even by the U.S. Drug
Enforcement Agency in their efforts to infiltrate criminal groups without
revealing their identity. The Tor Project is a non-profit charity based in
Massachusetts and is primarily funded by government agencies. Thus it is
ironic that the Tor Network has become such a high-priority target in the
NSA's worldwide surveillance system.
As revealed by the British newspaper The Guardian, there have been repeated
efforts to crack the Tor Network and de-anonymize its users. The top secret
presentations published in October last year show that Tor is anathema to the
NSA. In one presentation, agents refer to the network as "the king of
high-secure, low-latency internet anonymity". Another is titled "Tor Stinks".
Despite the snide remarks, the agents admit, "We will never be able to
de-anonymize all Tor users all the time".
The former NSA director General Keith Alexander stated that all those
communicating with encryption will be regarded as terror suspects and will be
monitored and stored as a method of prevention, as quoted by the Frankfurter
Allgemeine Zeitung in August last year. The top secret source code published
here indicates that the NSA is making a concerted effort to combat any and
all anonymous spaces that remain on the internet. Merely visiting
privacy-related websites is enough for a user's IP address to be logged into
an NSA database.
An examination of the XKeyscore rules published here goes beyond the slide
presentation and provides a window into the actual instructions given to NSA
computers. The code was deployed recently and former NSA employees and
experts are convinced that the same code or similar code is still in use
today. The XKeyscore rules include elements known as "appids",
"fingerprints", and "microplugins".  Each connection a user makes online - to
a search engine, for example - can be assigned a single appid and any number
of fingerprints.
Appids are unique identifiers for a connection in XKeyscore. Appid rules have
weights assigned to them.  When multiple appids match a given connection, the
one with the highest weight is chosen. Microplugins may contain software
written in general-purpose programming languages, such as C++, which can
extract and store specific types of data. The rules specifically target the
Tor Project's email and web infrastructure, as well as servers operated by
key volunteers in Germany, the United States, Sweden, Austria, and the
Netherlands. Beyond being ethically questionable, the attacks on Tor also
raise legal concerns.  The IP addresses of Tor servers in the United States
are amongst the targets, which could violate the fourth amendment of the US
The German attorney Thomas Stadler, who specializes in IT law, commented:
"The fact that a German citizen is specifically traced by the NSA, in my
opinion, justifies the reasonable suspicion of the NSA carrying out secret
service activities in Germany. For this reason, the German Federal Public
Prosecutor should look into this matter and initiate preliminary
One of NSA's German targets is 212.212.245.170.  The string of numbers is an
IP address assigned to Sebastian Hahn, a computer science student at the
University of Erlangen. Hahn operates the server out of a grey high-security
building a few kilometers from where he lives. Hahn, 28 years old and
sporting a red beard, volunteers for the Tor Project in his free time. He is
especially trusted by the Tor community, as his server is not just a node, it
is a so-called Directory Authority. There are nine of these worldwide, and
they are central to the Tor Network, as they contain an index of all Tor
nodes. A user's traffic is automatically directed to one of the directory
authorities to download the newest list of Tor relays generated each hour.
Quellcode NSA  "anonymizer/tor/node/authority" fingerprint.
Hahn's predecessor named the server Gabelmoo, or Fork Man, the nickname of a
local statue of Poseidon. After a look at the NSA source code, Hahn quickly
found his server's name listed in the XKeyscore rules. "Yes, I recognize the
IP address of my Tor server called 'gabelmoo'." he said. "Millions of people
use it to stay safe online, and by watching the server and collecting
metadata about its users, those people are put at risk." The rule shown to
Hahn, published below, has a fingerprint called
'anonymizer/tor/node/authority'. The fingerprint targets users who connect to
Gabelmoo and other Tor Directory Authority servers. In Germany, the Tor
Directory Authorities like Gabelmoo that are specifically targeted by
XKeyscore rules are in Berlin and Nuremberg. Additional targets are located
in Austria, Sweden, the United States, and the Netherlands.
Quellcode NSA  Fragments of XKeyscore rules targetting Tor directory
The expression below performs essentially the same function, but it specifies
the Tor directory authorities located in Five Eyes countries (Australia,
Canada, New Zealand, the United Kingdom and the United States) separately
from those in other countries. As the comment explains, the "goal is to find
potential Tor clients connecting to the Tor directory servers."
Another rule catalogs users connecting to known Tor relays. This is not
difficult, because the addresses of all normal Tor relays are published by
the directory authorities so that the Tor software on users' computers can
select its own path through the network. In addition to the public relays,
connections characterized as Tor based on protocol identifiers are also
Not only Metadata
Internet service providers in countries with strong censorship such as China
and Iran frequently block connections to known Tor relays. To avoid this
blocking, The Tor Project maintains a list of non-public relays called
"bridges" to allow users to avoid this type of blocking. Bridges are run by
volunteers and they share the details with the Tor Project to help censored
users reach the internet.
Quellcode NSA  Microplugin which extracts bridge addresses from the full text
of Tor Project emails.
Users can request a bridge address via email or on the web. The following
fingerprints show two ways that XKeyscore attempts to track Tor bridge users.
First, the fingerprint "anonymizer/tor/bridge/tls" records connections to the
bridges.torproject.org server. Second, in order obtain the actual bridge
addresses for the purpose of tracking connections to them in the future, the
"microplugin" fingerprint called "anonymizer/tor/bridge/email" extracts data
from the body of the emails that the Tor Project sends to its users.
This code demonstrates the ease with which an XKeyscore rule can analyze the
full content of intercepted connections. The fingerprint first checks every
message using the "email_address" function to see if the message is to or
from "bridges Next, if the address matched, it uses the
"email_body" function to search the full content of the email for a
particular piece of text - in this case, "
If the "email_body" function finds what it is looking for, it passes the full
email text to a C++ program which extracts the bridge addresses and stores
them in a database.
Quellcode NSA  Fingerprint to identify visitors to the Tor Project website.
The full content of the email must already be intercepted before this code
can analyze it. XKeyscore also keeps track of people who are not using Tor,
but who are merely visiting The Tor Project's website (
as this rule demonstrates:
Quellcode NSA  Rules targeting people viewing the Tails or Linux Journal
websites, or performing Tails-related web searches.
It is interesting to note that this rule specifically avoids fingerprinting
users believed to be located in Five Eyes countries, while other rules make
no such distinction. For instance, the following fingerprint targets users
visiting the Tails and Linux Journal websites, or performing certain web
searches related to Tails, and makes no distinction about the country of the
The comment in the  source code above describes Tails as "a comsec mechanism
advocated by extremists on extremist forums". In actuality, the software is
used by journalists, human rights activists, and hundreds of thousands of
ordinary people who merely wish to protect their privacy.
The rules related to Tails clearly demonstrate how easily web searches and
website visits can be spied on by XKeyscore. On June 25, 2014, the United
States Supreme Court noted how sensitive this type of information is in their
Riley v. California decision against warrantless searches of mobile phones:
"An Internet search and browsing history [...] could reveal an individuals
private interests or concerns - perhaps a search for certain symptoms of
disease, coupled with frequent visits to WebMD."
Quellcode NSA  C++ program which searches "raw traffic" for .onion addresses.
In addition to anonymous internet access, Tor also provides a mechanism for
hosting anonymous internet services called "Hidden Services". These sites'
URLs contain a domain name in the pseudo-top-level-domain ".onion" which is
only accessible using Tor. The code shown below finds and catalogs URLs for
these sites which XKeyscore sees in "raw traffic", creating a unique
fingerprint for each onion address. Each .onion address found in raw traffic
is extracted and stored in an NSA database:
Quellcode NSA  "anonymizer/mailer/mixminion" appid matching all connections
to 128.31.0.34.
There are also rules that target users of numerous other privacy-focused
internet services, including HotSpotShield, FreeNet, Centurian,
FreeProxies.org, MegaProxy, privacy.li and an anonymous email service called
MixMinion as well as its predecessor MixMaster. The appid rule for MixMinion
is extremely broad as it matches all traffic to or from the IP address
128.31.0.34, a server located on the MIT campus.
That server is operated by the Tor Project's leader Roger Dingledine, an MIT
alumnus. The machine at this IP address provides many services besides
MixMinion, and it is also one of the above-mentioned Tor directory
authorities. Dingledine said "That computer hosts many websites, ranging from
open source gaming libraries to the Privacy Enhancing Technologies Symposium
Sebastian Hahn, the Tor volunteer who runs Gabelmoo, was stunned to learn
that his hobby could interest the NSA: "This shows that Tor is working well
enough that Tor has become a target for the intelligence services. For me
this means that I will definitely go ahead with the project.
When asked for a reaction to the findings, the Tor Project's Roger Dingledine
stated the following: "We've been thinking of state surveillance for years
because of our work in places where journalists are threatened. Tor's
anonymity is based on distributed trust, so observing traffic at one place in
the Tor network, even a directory authority, isn't enough to break it. Tor
has gone mainstream in the past few years, and its wide diversity of users -
from civic-minded individuals and ordinary consumers to activists, law
enforcement, and companies - is part of its security. Just learning that
somebody visited the Tor or Tails website doesn't tell you whether that
person is a journalist source, someone concerned that her Internet Service
Provider will learn about her health conditions, or just someone irked that
cat videos are blocked in her location. Trying to make a list of Tor's
millions of daily users certainly counts as wide scale collection. Their
attack on the bridge address distribution service shows their "collect all
the things" mentality - it's worth emphasizing that we designed bridges for
users in countries like China and Iran, and here we are finding out about
attacks by our own country. Does reading the contents of those mails violate
the wiretap act? Now I understand how the Google engineers felt when they
learned about the attacks on their infrastructure.
NDR and WDR wanted to know from the NSA how it justified attacking a service
funded by the U.S. government, under what legal authority Tor Network users
are monitored, and whether the German government has any knowledge of the
targeting of servers in Germany. Instead of adressing the questions
repeatedly posed to them, the NSA provided the following statement: "In
carrying out its mission, NSA collects only what it is authorized by law to
collect for valid foreign intelligence purposes - regardless of the technical
means used by foreign intelligence targets. The communications of people who
are not foreign intelligence targets are of no use to the agency. In January,
President Obama issued U.S. Presidential Policy Directive 28, which affirms
that all persons - regardless of nationality - have legitimate privacy
interests in the handling of their personal information, and that privacy and
civil liberties shall be integral considerations in the planning of U.S.
signals intelligence activities. The president's  directive also makes clear
that the United States does not collect signals intelligence for the purpose
of suppressing or burdening criticism or dissent, or for disadvantaging
persons based on their ethnicity, race, gender, sexual orientation, or
religion. XKeyscore is an analytic tool that is used as a part of NSA's
lawful foreign signals intelligence collection system. Such tools have
stringent oversight and compliance mechanisms built in at several levels. The
use of XKeyscore allows the agency to help defend the nation and protect U.S.
and allied troops abroad. All of NSA's operations are conducted in strict
accordance with the rule of law, including the President's new directive."
However, the research contradicts the United States' promise to Germany that
German citizens are not surveiled without suspicion. Using Tor in Germany
does not justify targeting someone, the German attorney Thomas Stadler
states: "Tor users do not breach any laws, it is absolutely legitimate to act
anonymously on the internet. There are many good reasons to remain
What is deep packet inspection?
Deep Packet Inspection, or DPI, refers to the class of technology which
examines the content of data packets as they travel across a network. A
packet is the fundamental unit of transfer in packet switched networks like
the internet. While DPI is commonly used by organizations to monitor their
own networks, its use on public networks for censorship and surveillance has
been widely condemned by privacy advocates and the United States government
In 2012, the head of the U.S. Delegation to the World Conference on
International Telecommunications, U.S. Ambassador Terry Kramer, said some
companies have used deep packet inspection technologies to not look at
aggregate customer information, traffic information, et cetera, but to look
at individual customer information. So looking at individuals and what sites
theyre on and how much capacity theyre using, et cetera, as you can
imagine, were very much opposed to that because we feel thats a violation
of peoples privacy and gets into, obviously, censorship, et cetera.
Despite its public political condemnations of invasive DPI use, the United
States "Intelligence Community" and its "Five Eyes" partners (Australia,
Canada, New Zealand, and the United Kingdom) operate massive internet-scale
DPI systems themselves, including XKeyscore. The use of XKeyscore is not
limited to these partners, however. The software has been shared with the
German BND and BfV, as well as the Swedish FRA, amongst others.
Active vs Passive
XKeyscore and the systems that feed it are considered "passive", meaning that
they silently listen but do not transmit anything on the networks that they
are targeting. However, through a process known as "tipping", data from these
programs can trigger other systems which perform "active" attacks.
Quantum is a family of such programs, including Quantuminsert, Quantumhand,
Quantumtheory, Quantumbot, and Quantumcopper, which are used for offensive
computer intrusion. Turmoil, Quantum, and other components of the Turbulence
architecture are running at so-called "defensive sites" including the
Ramstein Air Force base in Germany, Yokota Air Force base in Japan, and
numerous military and non-military locations within the United States.
Both Turmoil and XKeyscore feed selected data to real-time "tipping"
programs, such as Trafficthief, which can both alert NSA analysts when their
targets are communicating and trigger other software programs. Selected data
is "promoted" from the local XKeyscore data store to the NSA's so-called
"corporate repositories" for long term storage, analysis and exploitation.
More information about XKeyscore
In 2013, the British newspaper The Guardian revealed that by 2008 more than
150 internet surveillance facilities around the world were running the
XKeyscore Deep Packet Inspection software. All of the internet traffic
observed by XKeyscore, both metadata and full content, is analyzed and stored
temporarily at the collection sites for periods ranging from days to weeks,
while selected data is forwarded on to other locations for long-term storage.
The storage, indexing, and querying functions are performed at or near the
collection sites because the volume of data being collected is too large to
forward everything back to facilities in other countries. Analysts working
from various locations around the world may search specific XKeyscore sites,
or send their queries to a collection of sites.
XKeyscore provides a modular architecture in which tens of thousands of small
computer programs, or rules, written in XKeyscore's specialized programming
languages called Genesis and XKScript as well as general-purpose languages
such as C++ and Python, are run against all traffic to categorize it and
extract data. This indexing of the "full take" allows analysts to query the
temporary storage stored at the XKeyscore site, effectively sifting through
already pilfered communications which occurred before they had deemed them
interesting for a specific reason.
XKeyscore can be fed by several different programs, including Wealthycluster
and Turmoil. These programs "sessionize" the data, which means that
individual connections, such as a request for a web page, are reconstructed
from the stream of intercepted packets.
Locations where the NSA runs XKeyscore include Special Source Operations
(SSO) sites, typically found at or near major telecommunication providers'
infrastructure; Special Collection Service (SCS) sites, usually located
inside diplomatic facilities like embassies and consulates; and FORNSAT sites
where satellite communications are intercepted. All of these types of sites
are known to exist in Germany.
Other "Five Eyes" partners also operate XKeyscore installations. The United
Kingdom's Tempora program runs the largest instance of XKeyscore. Both the
software itself and limited access to NSA databases have been shared with
so-called "3rd party" partners including Germany. The German foreign
intelligence agency BND and the domestic intelligence agency BfV are testing
the Software.

@_date: 2014-07-04 16:56:41
@_author: Eugen Leitl 
@_subject: messing with XKeyScore 
Errata Security
Advanced persistent cybersecurity
Friday, July 04, 2014
Jamming XKeyScore
Back in the day there was talk about "jamming echelon" by adding keywords to email that the echelon system was supposedly looking for. We can do the same thing for XKeyScore: jam the system with more information than it can handle. (I enumerate the bugs I find in the code as "xks-00xx").
For example, when sending emails, just send from the address "bridges and in the email body include:
bridge = 0.0.0.1:443
bridge = 0.0.0.2:443
bridge = 0.0.0.3:443
Continue this for megabytes worth of bridges (xks-0001), and it'll totally mess up XKeyScore. It has no defense against getting flooded with information like this, as far as I can see.
Note that the regex only cares about 1 to 3 digit numbers, that means the following will be accepted by the system (xks-0002):
bridge = 75.748.86.91:80
The port number matches on 2 to 4 digits ([0-9]{2,4}). Therefore, bridges with port numbers below 10 and above 9999 will be safe. I don't know if this code reflect a limitation in Tor, or but assuming high/low ports are possible, this can be used to evade detection (xks-0011).
Strangely, when the port number is parsed, it'll capture the first non-digit character after the port number (xks-0012). This is normally whitespace, but we could generate an email with 256 entries, trying every possible character. A character like < or ' might cause various problems in rendering on an HTML page or generating SQL queries.
You can also jam the system with too many Onion addresses (xks-0003), but there are additional ways to screw with those. When looking for Onion addresses, the code uses a regex that contains the following capture clause:
This is looking for a string like " or " but the regex has no upper bounds (xks-0004) and there is no validation. Thus, you can include "goscrewyourself://o987asgia7gsdfoi.onion:443/" in network traffic, and it'll happily insert this into the database. But remember that "no upper bounds" means just that: the prefix can be kilobytes long, megabytes long, or even gigabytes long. You can open a TCP connection to a system you feel the NSA is monitoring, send 5 gigabytes of lower-case letters, followed by the rest of the Onion address, and see what happens. I mean, there is some practical upper bound somewhere in the system,, and when you hit it, there's a good chance bad things will happen.
Likewise, the port number for Onion address is captured by the regex (d+), meaning any number of digits (xks-0005). Thus, we could get numbers that overflow 16-bits, 32-bits, 64-bits, or 982745987-bits. Very long strings of digits (megabytes) at this point might cause bad things to happen within the system.
There is an extra-special thing that happens when the schema part of the Onion address is exactly 16-bytes long (xks-0006). This will cause the address and the scheme to reverse themselves when inserted into the database. Thus, we can insert digits into the scheme field. This might foul up later code that assumes schemes only contain letters, because only letters match in the regex.
In some protocol fields, the regexes appear to be partial matches. The system appears to match on HTTP servers with "mixminion" anywhere in the name. Thus, we start causing lots of traffic to go to our domains, such as "mixminion.robertgraham.com", that will cause their servers to fill up with long term storage of sessions they don't care about (xks-0007)
Let's talk X.509, and the following code:
fingerprint('anonymizer/tor/bridge/tls') =
  ssl_x509_subject('bridges.torproject.org') or
  ssl_dns_name('bridges.torproject.org');
Code that parses X.509 certificates is known to be flaky as all get out. The simplest thing to do is find a data center you feel the NSA can monitor, and then setup a hostile server that can do generic fuzzing of X.509 certificates, trying to crash them.
It's likely that whatever code is parsing X.509 certificates is not validating them. Thus, anybody can put certificates on their servers claiming to be 'bridges.torproject.org' (xks-0008). It's likely that the NSA is parsing SSL on all ports, so just pick a random port on your server not being used for anything else, create a self-signed CERT claiming to be "bridges.torproject.org', then create incoming links to that port from other places so at least search-engines will follow that link and generate traffic. This will cause the NSA database of bridges to fill up with bad information -- assuming it's not already full from people screwing with the emails as noted above :).
Putting the above code in a web page like this one will cause every visitor to trigger a search for TAILS in the XKeyScore rules. The more people who do this, the less useful it becomes to the NSA (xks-0009) in labeling people as suspicious. Likewise, putting tails.boum.org/<.title> in your webpages will cause the same effect, even when CSS/JavaScript makes such a title invisible.
In theory, the NSA should only be monitoring foreign traffic, and not traffic originating from the United States (or, apparently, the other five-eyes). So here is the fun thing (xks-0010): run your jamming tools from United States IP addresses against those servers in Iran you know the NSA is monitoring. Since the code should already be ignoring the traffic because it originates from the United States, then they can't complain if you've filled up their databases full of Tor Onion and bridge addresses.
Robert Graham

@_date: 2014-07-08 16:04:58
@_author: Eugen Leitl 
@_subject: The Ex-Google Hacker Taking on =?utf-8?Q?t?= 
cypherpunks
 The Ex-Google Hacker Taking on the Worlds Spy Agencies
BY ANDY GREENBERG   07.08.14  |   6:30 AM  |   PERMALINK
Ariel Zambelich/WIRED
During his last six years working as an elite security researcher for Google,
the hacker known as Morgan Mayhem spent his nights and weekends hunting down
the malware used to spy on vulnerable targets like human rights activists and
political dissidents.
His new job tasks him with defending a different endangered species: American
national security journalists.
For the last month, 34-year-old Morgan Marquis-Boire has been the director of
security for First Look Media, the journalism startup founded by Glenn
Greenwald and Laura Poitras. The website has become the most prolific
publisher of NSA leaker Edward Snowdens remaining secrets. Marquis-Boires
daunting task is to safeguard those documents, and the communications of
reporters who have perhaps the press most adversarial relationships with
Western intelligence agencies.
Beyond protecting Snowdens favorite journalists, Marquis-Boire sees his
decision to leave Google for First Look as a chance to focus full-time on the
problem of protecting reporters and activists as a whole, groups he sees as
some of the most sensitive targets for governments globally. I look at the
risk posed to individuals in the real world, says Marquis-Boire, an
imposing, often black-clad New Zealander with earrings, dreadlocks, and a
taste for death metal. In human rights and journalism, the consequences of
communications being compromised are imprisonment, physical violence, and
even death. These types of users need security assistance in a very real
Marquis-Boire already has distinguished himself as a relentless
counter-surveillance researcher and a vocal critic of the companies that have
created an industry hawking spyware to governments. In 2012, he and
researchers at the University of Torontos Citizen Lab were the first to
identify Finfisher, a stealthy collection of spying tools sold by the British
firm Gamma Group that they eventually tracked to command-and-control servers
in 25 countries. Later that year he helped trace how a piece of software sold
by the Italian firm Hacking Team was used by the government of the United
Arab Emirates to spy on a political dissident beaten by thugs. Just last
month he revealed new findings that showed how that companys tools have
evolved to target iPhones, Android devices and other mobile targets. And in
early 2013 Marquis-Boire and Citizen Lab researchers mapped the spread of
surveillance and censorship tools sold by the Palo Alto, California firm Blue
Coat to 61 countries, including Iran.
In the detective work required to pin those stealthy spying incidents on
repressive governments and Western companies, Marquis-Boire is
extraordinarily talented, says Ron Deibert, a professor of political
science at the University of Toronto and Citizen Labs director. There are
some people who are phenomenally adept at forensics, who have an intuitive
sense of how to make connections through different pieces of evidence, he
says. Morgan has those skillsBut what I very much appreciate about him is
his passion for human rights.
A Cypherpunk In The Newsroom First Look and Marquis-Boire arent saying much
about exactly what hell do at the closely-watched new media startup. But
Marquis-Boire says he was convinced early in their recruitment meetings that
First Look will treat security as a central tenet. (More about First Looks
plans in the video below.) The job also presents a challenge worthy of
leaving his high profile position at Google: Protecting the communications
between non-technical reporters and their highly-sensitive sources in a
post-WikiLeaks and -Snowden era where theyre both increasingly targeted by
Marquis-Boire hints that hes already researching security vulnerabilities
that affect journalists, and working with several companies to release
security fixes to their services in the next couple of months. Brian Sweeney,
First Looks head of technology operations, says Marquis-Boires work likely
will extend into research designed to protect reporters beyond the companys
firewall. The idea that all digital citizens, including and especially
journalists, have access to data privacy is something that we strongly
believe in, says Sweeney.
Marquis-Boire, the son of two literature professors at the University of
Auckland, got started with security experimentation as a teenager in the New
Zealand hacker scene under the handle headhntr. After starting college at
Auckland, he and a group of friends wrote an article for the university
magazine about breaking into the schools website to take over the server
that ran it. On another occasion he was called into a local telecoms office
and given a stern talking to about using their services as a test lab.
But from the beginning, his interest in hacking was also political: In the
late 1990s the kiwi teenager discovered the Cypherpunks Mailing List, a group
of cryptographers and radical libertarians bent on foiling government
surveillance and empowering individuals with privacy tools. The group
eventually would foster projects like the anonymous remailers that relay
emails to obscure their senders identities, the anonymity software Tor,
WikiLeaks, and countless other privacy and encryption projects. People
realized that to actually have free speech, we have to be sure we wont be
monitored or persecuted, says Marquis-Boire. The intertwined nature of
privacy and free expression was at the core of the cypherpunk movement.
Marquis-Boire and friends soon hosted what he says was the first anonymous
remailer server in New Zealand out of a dingy warehouse apartment with far
too many blinking lights and whirring things. Eventually, he ran five Tor
relays, the nodes in the Tor network that bounce users traffic to obscure
their location.
But Marquis-Boires first real job in security, penetration-testing banks,
power plants, and other clients for a New Zealand auditing firm, was
unsatisfying. I spent a bit of time musing about how much it costs to hire
security consultants to do something like a black box [penetration test] of
your whole enterprise, he says. I wanted to give my skills to the people
who really needed them.
He Has Quite a Hacker Mind In 2008, Google hired Marquis-Boire in its
Zurich, Switzerland office. He was assigned to cybersecurity incident
response at the company not long before the biggest known security crisis in
its history: the so-called Aurora hacking operation, in which Chinese hackers
breached Googles network for months and stole information that included
source code from its servers. Marquis-Boire became an early member of the
core team of network defenders assigned to battle the state-sponsored spies
trying to eavesdrop on Googles users. He has quite a hacker mind, says
Heather Adkins, Googles manager of information security, Of everyone Ive
ever hired at Google, Id put him in the top one percent of technical
When the Arab Spring began a year later, human rights activists like those at
Citizen Lab who had seen Marquis-Boires presentations on state-sponsored
hacking began seeking his help analyzing attacks on vulnerable groups across
the Middle East. As revolutions and political unrest blossomed from Tunisia
to Egypt to Libya to Syria, his detective work became nearly a full-time job.
There have been a lot of books not read and canceled vacations, he says.
In the meantime, Googles Adkins adds, Marquis-Boire frequently uncovered
weaknesses in the companys defenses for usersand hes been just as focused
on locking out the NSA as Chinas Peoples Liberation Army. In the wake of
revelations from Snowdens leaks that the NSA spied on unencrypted Google
data moving between the companys data centers, Marquis-Boire was one of the
first at the company to push for encryption not only of the companys
internal data transfers, but also the exchange of emails between Gmail and
other providers. That pressure led Google earlier this month to start
publicly naming which email services do and dont allow for that encryption
in a bid to pressure other companies to safeguard users privacy.
Marquis-Boires focus turned to protecting journalists in particular earlier
this year, when he and other Googlers released research in March showing that
21 out of the 25 top media organizations in the world had been targeted in
digital attacks that were likely the work of state-sponsored hackers. The
same month, he joined a technical advisory group for the Freedom of the Press
Foundation, which counts Glenn Greenwald, Laura Poitras and Edward Snowden as
members of its board. If you cant protect your privacy and that of your
sources, its debatable whether you can actually practice journalism in the
traditional sense, he says.
That notion represents a shift from the cypherpunk views of Marquis-Boires
youth. Once, cypherpunks were mainly interested in seizing privacy for
themselves. Now, he says, thats no longer enough. When we discovered that
we could create private and anonymous communications with math, that was
super cool, he says. But then after a while I think it dawned on us as a
movement that the only conversations you could have with those tools were
with other cypherpunks.
Now its been thrust into our faces that the people practicing adversarial
journalism and exposing human right abuses are the real-world targets of
precisely the kind of thing that the cypherpunk movement was trying to
protect against, says Marquis-Boire. Its become apparent we need to
provide privacy to those who need it, not just to ourselves.
Tags: Edward Snowden, First Look Media, NSA, Security

@_date: 2014-07-09 14:23:28
@_author: Eugen Leitl 
@_subject: BPjM blacklist reversed 
tl;dr: Germany has a censorship federal agency called BPjM which maintains a
secret list of about 3000 URLs. To keep the list secret it is distributed in
the form of md5 or sha1 hashes as the "BPJM-Modul". They think this is safe.
This leak explains in detail that it is in fact very easy to extract the
hashed censorship list from home routers or child protection software and
calculate the cleartext entries. It provides a first analysis of the
sometimes absurd entries on such a governmental Internet censorship list.

@_date: 2014-07-10 11:06:55
@_author: Eugen Leitl 
@_subject: [Server-sky] Server sky and social architecture 
Code is Law, Hardware is Code's Language
The Law of Law is language. If your language is richly metaphorical and contains the word "schadenfreude", you will annex the Sudetenland, gas most of your ethnic minorities, and a surviving ethnic outlier will use your language to express general relativity. Other languages better express other crimes and concepts. A linguist will tell you all languages can express all concepts - languages are Turing complete - but this fashionable conceit does not tell us why different cultures do different things.
Code is law. Hardware is the language and law of code. Code can only do what hardware permits. A Turing complete machine can manufacture any set of symbols from any other set, but those symbols cannot go where the hardware doesn't connect.
In 1990 I designed a chip, a non-blocking crossbar routing device, for the startup I-Cube Design Systems. This chip routed signals from any pin to any other pin, and could route 240 inputs to any combination of 240 other outputs. But it also had fanout - it could route an input to two or more outputs. 160 inputs could become 320 outputs. This was useful for the original task - hardware logic simulation. When the original logic simulator customers became enmired in patent lawsuits, I-Cube found a new customer, another small startup called Cisco. Cisco's routers distributed the backbone of the early internet, and still route most of it.
I realize, decades later, that I made one of the architectural decisions that allows the NSA to watch you as you read this webpage.
Cisco's routers flowed bitstreams, not "packets", a software metaphor for a time-bounded sequence of bits. Packet headers told the router which flow got the bits, the router told the crossbar device which path the bits should take. Sending the bits to more than one place was implicit in how the hardware worked, because the hardware had fanout.
Cisco remains, I-Cube was killed by incompetent venture capitalists. I'm not party to how Cisco designs routers today, but fanout is implicit in dataflow, hardware can stream one transmitter to multiple receivers, tracelessly.
Software is merely "judicial opinion" applied to that hardware, and we non-electrical macroscopic human beings only have opinions, not sure knowledge, about how the bits are actually moving and transforming from memory location to other (possibly multiple) memory locations.
Software can encrypt - or it can pretend to. Software becomes machine instructions via a compiler. Dennis Ritchie taught us that a compiler emits machine instructions chosen by the compiler author, who can override the decisions of the source code author. The hardware author can override both. The hard disk manufacturer decides what firmware bytes go on the boot tracks of your hard drive, the disk firmware decides what bytes you actually get to your RAM from which disk track, and this firmware is invisible to the machine code it dispenses. In an age of Viterbi coding and VLSI disk chips, even a hardware logic analyzer may not tell you what's actually on the boot tracks. For sure knowledge, you will need your own hardware, either your own replacement disk chips or a focused ion beam milling system (FIB) to take apart the disk chips and learn what they actually do.
The economics of chip production make it impossibly expensive to give everyone a different chip architecture, though you can cheaply individualize every chip (another of my inventions, see  ). If there is a ghost in the hardware machine, it is in all the machines, and those versed in VLSI, equipped with FIB, can find the ghosts. The individuality can be perfectly hidden, and cannot be unmasked without destroying the chip.
Puzzling out a proprietary design is possible but time-consuming, perhaps costing as much as the original design. Verifying that an open source hardware design is faithfully replicated in silicon is relatively easy, and could be automated, perhaps as cheap as sequencing a genome. We do not do so, because software designers pretend the substrate does not exist, or is logically identical to all other substrates, and thus not worth controlling or verifying (doctors and pharmaceutical companies share the same pretense).
Open source hardware can also encrypt, and properly-designed hardware can encrypt without fanout (no feasible side channel attacks). If we choose, we can build individual hardware that encrypts each keystroke and decrypts it at each screen, whether the path between is centimeters or megameters. With proper hardware, you can still use Gmail for your mail host, but your messages are gibberish to Google, and to whoever they share the messages with. Google banner ads can be ignored by your decrypter. Google would starve, so they want to make your software and hardware "for free", protecting their product (which is you).
Hardware geeks will still need to re-examine (identical) copies of the hardware from time to time, to make sure the hardware matches specification, and crypto geeks will need to frequently re-examine the specification to make sure it is mathematically correct. And sometimes the hardware will be invalid, and we will need to replace it with new hardware. But a billion transistors costs pennies from Intel, which Amazon can get to you overnight.
Why this matters to Server Sky
Server sky will use far fewer routers. Access to server sky arrays will be trigonometric, agile antenna pointing, not packet routing via DNS and border gateway protocol; if the array is above the horizon and has what you want, you can talk to it directly without intermediaries, and your conversation can be encrypted end-to-end. Of course, each end can have fanout, with either the orbiting array or your ground terminal copying your conversation to your Designated Overlord. Each end can have a fanout of zero, censorship applied by that same (or different) Designated Overlord. No man-in-the-middle attacks when there is only vacuum and Maxwell's equations between sender and receiver. Orbital mechanics, Doppler shift, and twelve-nines-accurate shared clocks provide link authentication that cannot be spoofed without reshaping space-time.
There will be Designated Overlords - in the US, we call the overlords "Google" and "Hollywood", in China the overlords are the Communist Party and/or the People's Liberation Army. People can't seem to live without chains, sigh. But we must design our hardware so the overlords are explicit in the design, few in number, and subject to organized social opinion (which may be more true for China than the US, though I love Google more than the PLA).
This matters because the Server Sky team will make the design decisions now that will shape the hardware for decades, until the next big re-architecting (the last two were the Bell network, and internet protocol). These decisions should be informed by every capable brain on the planet. They should not be made by me, nor by my handful of smart but fallible collaborators. The best minds work elsewhere, and the best minds, if they know what's good for them, will get involved while the future is still conceptual and easy to shape. After launch, we can still replace all the satellites and all the ground terminals and all the end-user gear, but this is costly, and even the best minds don't have the money and persuasiveness to make this happen often. Better to get it approximately right the first time, and make it plug-upgradable.
This webpage is an appeal for help. Bad social design is easy, and regrettably common. Hardware is easy compared to competent social design. I beg you to help design the future you and your descendants will live in. I goofed up once, I would rather not do it again.

@_date: 2014-07-11 12:36:00
@_author: Eugen Leitl 
@_subject: The ultimate goal of the NSA is total population control 
The ultimate goal of the NSA is total population control
At least 80% of all audio calls, not just metadata, are recorded and stored
in the US, says whistleblower William Binney  that's a 'totalitarian
Antony Loewenstein theguardian.com, Friday 11 July 2014 00.54 BST
William Binney testifies before a German inquiry into surveillance.
Photograph: Getty Images
William Binney is one of the highest-level whistleblowers to ever emerge from
the NSA. He was a leading code-breaker against the Soviet Union during the
Cold War but resigned soon after September 11, disgusted by Washingtons move
towards mass surveillance.
On 5 July he spoke at a conference in London organised by the Centre for
Investigative Journalism and revealed the extent of the surveillance programs
unleashed by the Bush and Obama administrations.
At least 80% of fibre-optic cables globally go via the US, Binney said.
This is no accident and allows the US to view all communication coming in.
At least 80% of all audio calls, not just metadata, are recorded and stored
in the US. The NSA lies about what it stores.
The NSA will soon be able to collect 966 exabytes a year, the total of
internet traffic annually. Former Google head Eric Schmidt once argued that
the entire amount of knowledge from the beginning of humankind until 2003
amount to only five exabytes.
Binney, who featured in a 2012 short film by Oscar-nominated US film-maker
Laura Poitras, described a future where surveillance is ubiquitous and
government intrusion unlimited.
The ultimate goal of the NSA is total population control, Binney said, but
Im a little optimistic with some recent Supreme Court decisions, such as law
enforcement mostly now needing a warrant before searching a smartphone.
He praised the revelations and bravery of former NSA contractor Edward
Snowden and told me that he had indirect contact with a number of other NSA
employees who felt disgusted with the agencys work. Theyre keen to speak
out but fear retribution and exile, not unlike Snowden himself, who is likely
to remain there for some time.
Unlike Snowden, Binney didnt take any documents with him when he left the
NSA. He now says that hard evidence of illegal spying would have been
invaluable. The latest Snowden leaks, featured in the Washington Post, detail
private conversations of average Americans with no connection to extremism.
It shows that the NSA is not just pursuing terrorism, as it claims, but
ordinary citizens going about their daily communications. The NSA is
mass-collecting on everyone, Binney said, and its said to be about
terrorism but inside the US it has stopped zero attacks.
The lack of official oversight is one of Binneys key concerns, particularly
of the secret Foreign Intelligence Surveillance Court (Fisa), which is held
out by NSA defenders as a sign of the surveillance scheme's
The Fisa court has only the governments point of view, he argued. There
are no other views for the judges to consider. There have been at least 15-20
trillion constitutional violations for US domestic audiences and you can
double that globally.
A Fisa court in 2010 allowed the NSA to spy on 193 countries around the
world, plus the World Bank, though theres evidence that even the nations the
US isnt supposed to monitor  Five Eyes allies Britain, Canada, Australia
and New Zealand  arent immune from being spied on. Its why encryption is
today so essential to transmit information safely.
Binney recently told the German NSA inquiry committee that his former
employer had a totalitarian mentality that was the "greatest threat" to US
society since that countrys US Civil War in the 19th century. Despite this
remarkable power, Binney still mocked the NSAs failures, including missing
this years Russian intervention in Ukraine and the Islamic States take-over
of Iraq.
The era of mass surveillance has gone from the fringes of public debate to
the mainstream, where it belongs. The Pew Research Centre released a report
this month, Digital Life in 2025, that predicted worsening state control and
censorship, reduced public trust, and increased commercialisation of every
aspect of web culture.
Its not just internet experts warning about the internets colonisation by
state and corporate power. One of Europes leading web creators, Lena Thiele,
presented her stunning series Netwars in London on the threat of cyber
warfare. She showed how easy it is for governments and corporations to
capture our personal information without us even realising.
Thiele said that the US budget for cyber security was US$67 billion in 2013
and will double by 2016. Much of this money is wasted and doesn't protect
online infrastructure. This fact doesnt worry the multinationals making a
killing from the gross exaggeration of fear that permeates the public domain.
Wikileaks understands this reality better than most. Founder Julian Assange
and investigative editor Sarah Harrison both remain in legal limbo. I spent
time with Assange in his current home at the Ecuadorian embassy in London
last week, where he continues to work, release leaks, and fight various legal
battles. He hopes to resolve his predicament soon.
At the Centre for Investigative Journalism conference, Harrison stressed the
importance of journalists who work with technologists to best report the NSA
stories. Its no accident, she said, that some of the best stories on the
NSA are in Germany, where theres technical assistance from people like Jacob
A core Wikileaks belief, she stressed, is releasing all documents in their
entirety, something the group criticised the news site The Intercept for not
doing on a recent story. The full archive should always be published,
Harrison said.
With 8m documents on its website after years of leaking, the importance of
publishing and maintaining source documents for the media, general public and
court cases cant be under-estimated. I see Wikileaks as a library, Assange
said. Were the librarians who cant say no.
With evidence that there could be a second NSA leaker, the time for more
aggressive reporting is now. As Binney said: I call people who are covering
up NSA crimes traitors.

@_date: 2014-07-15 15:38:15
@_author: Eugen Leitl 
@_subject: Experts report potential software "back doors" in U.S. standards 
Experts report potential software "back doors" in U.S. standards
BY JOSEPH MENN
SAN FRANCISCO, July 14 Mon Jul 14, 2014 8:58pm EDT
(Reuters) - U.S. government standards for software may enable spying by the
National Security Agency through widely used coding formulas that should be
jettisoned, some of the country's top independent experts concluded in papers
released on Monday.
Such mathematical formulas, or curves, are an arcane but essential part of
most technology that prevents interception and hacking, and the National
Institute of Standards and Technology (NIST) has been legally required to
consult with the NSA's defensive experts in approving them and other
cryptography standards.
But NIST's relationship with the spy agency came under fire in September
after reports based on documents from former NSA contractor Edward Snowden
pointed to one formula in particular as a Trojan horse for the NSA.
NIST discontinued that formula, called Dual Elliptic Curve, and asked its
external advisory board and a special panel of experts to make
recommendations that were published on Monday alongside more stinging
conclusions by the individual experts.
Noting the partially obscured hand of the NSA in creating Dual Elliptic Curve
- which Reuters reported was most broadly distributed by security firm RSA
[USN:nL2N0JZ1B6] - the group delved into the details of how it and other NIST
standards emerged. It found incomplete documentation and poor explanations in
some cases; in others material was withheld pending legal review.
As a whole, the panels recommended that NIST review its obligation to confer
with the NSA and seek legal changes "where it hinders its ability to
independently develop the best cryptographic standards to serve not only the
United States government but the broader community."
They also urged NIST to weigh the advice of individual task force members who
made more dramatic suggestions, such as calling for the replacement of a
larger set of curves approved for authenticating users, in part because they
were selected through unclear means by the NSA.
"It is possible that the specified curves contain a back door somehow," said
Massachusetts Institute of Technology professor Ron Rivest, a co-founder of
RSA and the source of the letter R in its name. Though the curves could be
fine, he wrote, "it seems prudent to assume the worst and transition away."
More broadly, Rivest wrote, "NIST should ask the NSA for full disclosure
regarding all existing standards... If NSA refuses to answer such an inquiry,
then any standard developed with significant NSA input should be assumed to
be `tainted,'" absent proof of security acceptable to outsiders.
In an email exchange, Rivest told Reuters that "NIST needs to have a process
whereby evidence is publicly presented" about how the curves were chosen.
The curves faulted on Monday had been questioned by outsiders after media
reports in September said the NSA could break much widely used security
software, without detailing which ones or how. "These curves are ubiquitous
in commercial cryptography," Johns Hopkins University professor Matthew Green
said in an interview. "If you connected to Google or Facebook today, you
probably used one."
Rivest's long association with RSA, now part of electronic storage maker EMC
Corp, made his remarks more poignant. But prominent task force colleagues
including Internet co-creator Vint Cerf and Ed Felten, former chief
technologist at Federal Trade Commission, also gave strongly worded verdicts
on the Department of Commerce unit.
"It cannot be accepted that NIST's responsibilities should be co-opted by the
NSA's intelligence mission," wrote Cerf, who now works at Google Inc.
While Rivest called the internal history of Dual Elliptic Curve a "smoking
gun" with an "almost certain" NSA back door, Felten wrote that NSA might not
remain alone in its ability to use it and other possible NIST-approved holes
for spying.
In each of three cases, including Dual Elliptic Curve and the more common
curves faulted by Rivest, Felten said the suspected back door access "reduces
the security of users against attack by other adversaries, including
organized crime groups or foreign intelligence services."
The NSA might have been able to generate curves that pass cursory security
tests but are still breakable through the aid of sheer computing power,
because it can try millions of curves and get a few that fit its goals. But a
researcher working for another country could discover the flaw, Felten said.
In the case of the curves approved under the FIPS 186 standard for
authenticating digital signatures, NIST should start over and pick its own
curves publicly rather than relying on the NSA, Felten and others said.
Several experts said NIST had to hire more cryptographers and strengthen its
internal processes to avoid relying on NSA.
NIST acting Director Willie May agreed in a statement, saying his agency
"must strengthen its in-house cryptography capabilities to ensure we can
reach independent conclusions about the merits of specific algorithms or
NIST did not respond to a Reuters email asking about the fate of the suspect
curves. (Reporting by Joseph Menn; Editing by Ken Wills)

@_date: 2014-07-15 18:31:11
@_author: Eugen Leitl 
@_subject: Rainforest Connection and WildLeaks 
Interesting uses of old mobile phones
(I'm sure you'll how this be made applicable in
other contexts (say, urban environment) and with other modifications).
One group hopes to end poaching, WikiLeaks-style

@_date: 2014-07-17 15:09:14
@_author: Eugen Leitl 
@_subject: the NSA revelations all in one chart 
The NSA Revelations All in One Chart
This is a plot of the NSA programs revealed in the past year according to
whether they are bulk or targeted, and whether the targets of surveillance
are foreign or domestic. Most of the programs fall squarely into the agencys
stated mission of foreign surveillance, but some  particularly those that
are both domestic and broad-sweeping  are more controversial.
Just as with the New York Magazine approval matrix that served as our
inspiration, the placement of each program is based on judgments and is
For more details, read our FAQ or listen to our podcast. Also, take our quiz
to test your NSA knowledge.

@_date: 2014-07-17 18:54:26
@_author: Eugen Leitl 
@_subject: Leaked GCHQ catalog of exploit tools for manipulation and mass 
Liberation Technologies Leaked GCHQ catalog of exploit tools for manipulation and mass surveillance
By Darlene Storm
July 16, 2014 1:22 PM EDTAdd a comment
Just as civil liberties groups challenge the legality of the UK intelligence
agencys mass surveillance programs, a catalog of exploit tools for
monitoring and manipulation is leaked online.
The Joint Threat Research Intelligence Group (JTRIG), a department within the
Government Communications Headquarters (GCHQ), develops the majority of
effects capabilities for UKs NSA-flavored intelligence agency. First Look
Media first published the Snowden-leaked Wikipedia-like document full of
covert tools used by GCHQ for surveillance and propaganda. JTRIG tools and
techniques help British spies seed the internet with false information,
including the ability to manipulate the results of online polls, monitor
social media posts, and launch attacks ranging from denial of service, to
call bombing phones, to disabling users' accounts on PCs.
Devils Handshake, Dirty Devil, Reaper and Poison Arrow are but a few
vicious-sounding JTRIG system tools, but the naming convention for others are
just inane like Bumblebee Dance, Techno Viking and Jazz Fusion. Perhaps the
British spies were hungry when coming up with Fruit Bowl, Spice Island, Nut
Allergy, and Berry Twister?  Most of the tools are "fully operational, tested and reliable, according to
the 2012 JTRIG Manual, but "Don't treat this like a catalog. If you don't see
it here, it doesn't mean we can't build it." Like the previously leaked TAO
exploits, its an eye-opener as to exploits that GCHQ can deploy.
GCHQ spy tools, techniques and exploits in JTRIG manual
Some of the especially invasive tools that are either ready to fire or very
close to being ready include:
long and when the effect is active.
material online.
files on a targets machine.
info, files, logs, etc and posts it back to GCHQ.
elicit a targets IP address.
       Tornado Alley is a delivery system aimed at Microsoft Excel "to
silently extract and run an executable on a target's machine."
address and send email under that identity.
ringing them. Target does not need to answer. Denial of Service:
services. Other JTRIG exploits include Screaming Eagle, a tool that
processes Kismet data into geolocation information and Chinese Firecracker
for overt brute login attempts against online forums. Hacienda is a port
scanning tool designed to scan an entire country or city before identifying
IP locations and adding them to an Earthling database.
Messing with cellphones:
telephones, or repeatedly bomb a target number with the same message.
phone to aid geolocation.
via call bombing.
BlackBerry targets.
allows us to pull back cell tower and Wi-Fi locations targeted against
particular areas. Vipers Tongue is another denial of service tool but its
aimed at satellite or GSM phone calls.  Manipulation and propaganda
Bomb Bay can increase website hits/rankings. Gateway can artificially
increase traffic to a website; Slipstream can inflate page views on
websites. Underpass can change the outcome of online polls. Badger can
mass deliver email messages to support an Information Operations campaign.
Gestator can amplify a given message, normally video, on popular multimedia
websites like YouTube. The production and dissemination of multimedia via
the web in the course of information operations can be accomplished with
Skyscraper. There are also various tools to censor or report extremist
Online surveillance of social networks
Godfather collects public data from Facebook. While Spring Bishop finds
private photos of targets on Facebook, Reservoir allows the collection of
various Facebook information. Clean Sweep can masquerade Facebook wall posts
for individuals or entire countries.
Birdstrike monitors and collects Twitter profiles. Dragons Snout collects
Paltalk group chats. Airwolf collects YouTube videos, comments and profiles.
Bugsy collects users info off Google+. Fatyak is about collecting data from
LinkedIn. Goodfella is a generic framework to collect public data from
online social networks. Elate monitors a target's use of UK's eBay. Mouth
finds, collects and downloads a users files from achive.org. Photon Torpedo
can actively grab the IP address of an MSN messenger user. Pitbull is aimed
at large scale delivery of tailored messages to IM services.
Miniature Hero is about exploiting Skype. The description states, Active
Skype capability. Provision of real time call records (SkypeOut and
SkypetoSkype) and bidirectional instant messaging. Also contact lists.
If thats not enough mass-scale surveillance and manipulation to irk you,
there are more weaponized tricks and techniques in the JTRIG Manual.

@_date: 2014-07-18 12:24:15
@_author: Eugen Leitl 
@_subject: interesting thread on BND intercept at DE-CIX on denog@ 
The netops are not amused.
You need to be a list member in order to access the archive.

@_date: 2014-07-21 14:03:08
@_author: Eugen Leitl 
@_subject: Huge collection of Security Data Science papers 
(looks useful)
 Over the past several years I have collected and read many security research papers/slides and have started a small catalog of sorts. The topics of these papers range from intrusion detection, anomaly detection, machine learning/data mining, Internet scale data collection, malware analysis, and intrusion/breach reports. I figured this collection might useful to others. All links lead to PDFs hosted here.
I hope to clean this up (add author info, date, and publication) when I get some more time as well as adding some detailed notes I have on the various features, models, algorithms, and datasets used in many of these papers.
Here are some of my favorites (nice uses of machine learning, graph analytics, and/or anomaly detection to solve interesting security problems):
CAMP - Content Agnostic Malware Protection
Notos - Building a Dynamic Reputation System for DNS
Kopis - Detecting malware domains at the upper dns hierarchy
Pleiades - From Throw-away Traffic To Bots - Detecting The Rise Of DGA-based Malware
EXPOSURE - Finding Malicious Domains Using Passive DNS Analysis
Polonium - Tera-Scale Graph Mining for Malware Detection
Nazca - Detecting Malware Distribution in Large-Scale Networks
PAYL - Anomalous Payload-based Network Intrusion Detection
Anagram - A Content Anomaly Detector Resistant to Mimicry Attack
Here is the entire collection:
Intrusion Detection
A Close Look on n-Grams in Intrusion Detection- Anomaly Detection vs. Classication
A Kill Chain Analysis of the 2013 Target Data Breach
A Lone Wolf No More - Supporting Network Intrusion Detection with Real-Time Intelligence
A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks
Acquiring Digital Evidence from Botnet Attacks: Procedures and Methods (PhD Thesis)
ALERT-ID - Analyze Logs of the network Element in Real Time for Intrusion Detection
Anagram - A Content Anomaly Detector Resistant to Mimicry Attack
Anomaly-based Intrusion Detection in Software as a Service
Back to Basics - Beyond Network Hygiene
Beehive - Large-Scale Log Analysis for Detecting Suspicious Activity in Enterprise Networks
Behavioral Clustering of HTTP-based Malware and Signature Generation Using Malicious Network Traces
Beheading Hydras - Performing Effective Botnet Takedowns
Bloodhound - Searching Out Malicious Input in Network Flows for Automatic Repair Validation
Boosting the Scalability of Botnet Detection Using Adaptive Traffic Sampling
CAMP - Content Agnostic Malware Protection
Casting out demons - Sanitizing training data for anomaly sensors
CloudFence - Data Flow Tracking as a Cloud Service
Comparing anomaly detection techniques for HTTP
Cujo - Efficient detection and prevention of drive-by-download attacks
Decoy Document Deployment for Effective Masquerade Attack Detection
Detecting Spammers with SNARE - Spatio-temporal Network-level Automatic Reputation Engine
Detecting Unknown Network Attacks Using Language Models
Early Detection of Malicious Flux Networks via Large-Scale Passive DNS Traffic Analysis
Effective Anomaly Detection with Scarce Training Data
Efficient Multidimensional Aggregation for Large Scale Monitoring
EFFORT - Efficient and Effective Bot Malware Detection
ExecScent- Mining for New C and C Domains in Live Networks with Adaptive Control Protocol Templates - slides
ExecScent- Mining for New C and C Domains in Live Networks with Adaptive Control Protocol Templates
EXPOSURE - Finding Malicious Domains Using Passive DNS Analysis
FiG - Automatic Fingerprint Generation
Filtering Spam with Behavioral Blacklisting
FLIPS - Hybrid Adaptive Intrusion Prevention
HMMPayl - An Intrusion Detection System Based on Hidden Markov Models
Kopis - Detecting malware domains at the upper dns hierarchy
Large-Scale Malware Analysis, Detection, and Signature Generation
Leveraging Honest Users - Stealth Command-and-Control of Botnets - slides
Leveraging Honest Users - Stealth Command-and-Control of Botnets
Local System Security via SSHD Instrumentation
Machine Learning In Adversarial Environments
Malware vs. Big Data (Umbrella Labs)
McPAD - A Multiple Classifier System for Accurate Payload-based Anomaly Detection
Measuring and Detecting Malware Downloads in Live Network Traffic
Mining Botnet Sink Holes - slides
MISHIMA - Multilateration of Internet hosts hidden using malicious fast-ux agents
Monitoring the Initial DNS Behavior of Malicious Domains
N-Gram against the Machine - On the Feasibility of the N-Gram Network Analysis for Binary Protocols
Nazca - Detecting Malware Distribution in Large-Scale Networks
Netgator - Malware Detection Using Program Interactive Challenges - slides
Network Traffic Characterization Using (p, n)-grams Packet Representation
Notos - Building a Dynamic Reputation System for DNS
On the Feasibility of Online Malware Detection with Performance Counters
On the Infeasibility of Modeling Polymorphic Shellcode
On the Mismanagement and Maliciousness of Networks
Outside the Closed World - On Using Machine Learning For Network Intrusion Detection
PAYL - Anomalous Payload-based Network Intrusion Detection
PAYL2 - Anomalous Payload-based Worm Detection and Signature Generation
Pleiades - From Throw-away Traffic To Bots - Detecting The Rise Of DGA-based Malware
Practical Comprehensive Bounds on Surreptitious Communication Over DNS - slides
Practical Comprehensive Bounds on Surreptitious Communication Over DNS
Privacy-preserving Payload-based Correlation for Accurate Malicious Traffic Detection
Revealing Botnet Membership Using DNSBL Counter-Intelligence
Revolver - An Automated Approach to the Detection of Evasive Web-based Malware
Self-organized Collaboration of Distributed IDS Sensors
SinkMiner- Mining Botnet Sinkholes for Fun and Profit
Spamming Botnets - Signatures and Characteristics
Spectrogram - A Mixture of Markov Chain models for Anomaly Detection in Web Traffic
The Security of Machine Learning
Toward Stealthy Malware Detection
Traffic Aggregation for Malware Detection
Understanding the Domain Registration Behavior of Spammers
Understanding the Network-Level Behavior of Spammers
VAST- Network Visibility Across Space and Time
A static, packer-agnostic filter to detect similar malware samples
A study of malcode-bearing documents
A survey on automated dynamic malware-analysis techniques and tools
APT1 Technical backstage (malware.lu hack backs of APT1 servers)
Automatic Analysis of Malware Behavior using Machine Learning
BitShred - Fast, Scalable Code Reuse Detection in Binary Code
BitShred - Fast, Scalable Malware Triage
Deobfuscating Embedded Malware using Probable-Plaintext Attacks
Escape from Monkey Island - Evading High-Interaction Honeyclients
Eureka - A framework for enabling static malware analysis
Extraction of Statistically Significant Malware Behaviors
Fast Automated Unpacking and Classification of Malware
FIRMA - Malware Clustering and Network Signature Generation with Mixed Network Behaviors
FuncTracker - Discovering Shared Code (to aid malware forensics) - slides
FuncTracker - Discovering Shared Code to Aid Malware Forensics Extended Abstract
Malware files clustering based on file geometry and visualization using R language
Mobile Malware Detection Based on Energy Fingerprints  A Dead End
Polonium - Tera-Scale Graph Mining for Malware Detection
Putting out a HIT - Crowdsourcing Malware Installs
Scalable Fine-grained Behavioral Clustering of HTTP-based Malware
SigMal - A Static Signal Processing Based Malware Triage
Tracking Memory Writes for Malware Classification and Code Reuse Identification
Using File Relationships in Malware Classification
VAMO - Towards a Fully Automated Malware Clustering Validity Analysis
Data Collection
Crawling BitTorrent DHTs for Fun and Prot
CyberProbe - Towards Internet-Scale Active Detection of Malicious Servers
Demystifying service discovery - Implementing an internet-wide scanner
gitDigger - Creating useful wordlists from GitHub
PoisonAmplifier - A Guided Approach of Discovering Compromised Websites through Reversing Search Poisoning Attacks
ZMap - Fast Internet-Wide Scanning and its Security Applications (slides)
ZMap - Fast Internet-Wide Scanning and its Security Applications
Vulnerability Analysis/Reversing
A Preliminary Analysis of Vulnerability Scores for Attacks in Wild
Attacker Economics for Internet-scale Vulnerability Risk Assessment
Detecting Logic Vulnerabilities in E-Commerce Applications
ReDeBug - Finding Unpatched Code Clones in Entire OS Distributions
The Classification of Valuable Data in an Assumption of Breach Paradigm
Toward Black-Box Detection of Logic Flaws in Web Applications
Vulnerability Extrapolation - Assisted Discovery of Vulnerabilities using Machine Learning - slides
Vulnerability Extrapolation - Assisted Discovery of Vulnerabilities using Machine Learning
Anonymous Hacking Group   Super Secret Security Handbook
Detecting Traffic Snooping in Tor Using Decoys
Risks and Realization of HTTPS Traffic Analysis
Selling Off Privacy at Auction
The Sniper Attack - Anonymously Deanonymizing and Disabling the Tor Network
The Velocity of Censorship - High-Fidelity Detection of Microblog Post Deletions - slides
The Velocity of Censorship - High-Fidelity Detection of Microblog Post Deletions
Tor vs. NSA
Data Mining
An Exploration of Geolocation and Traffic Visualization Using Network Flows to Aid in Cyber Defense
DSpin - Detecting Automatically Spun Content on the Web
Gyrus - A Framework for User-Intent Monitoring of Text-Based Networked Applications
Indexing Million of Packets per Second using GPUs
Multi-Label Learning with Millions of Labels - Recommending Advertiser Bid Phrases for Web Pages
Real-Time Handling of Network Monitoring Data Using a Data-Intensive Framework
Shingled Graph Disassembly - Finding the Undecideable Path
Synoptic Graphlet - Bridging the Gap between Supervised and Unsupervised Profiling of Host-level Network Traffic
Cyber Crime
Connected Colors - Unveiling the Structure of Criminal Networks
Image Matching for Branding Phishing Kit Images - slides
Image Matching for Branding Phishing Kit Images
Inside a Targeted Point-of-Sale Data Breach
Investigating Advanced Persistent Threat 1 (APT1)
Measuring pay-per-install - the Commoditization of Malware Distribution
Scambaiter - Understanding Targeted Nigerian Scams on Craigslist
Sherlock Holmes and the Case of the Advanced Persistent Threat
The Role of the Underground Market in Twitter Spam and Abuse
The Tangled Web of Password Reuse
Trafcking Fraudulent Accounts - The Role of the Underground Market in Twitter Spam and Abuse
Amplication Hell - Revisiting Network Protocols for DDoS Abuse
Defending The Enterprise, the Russian Way
Protecting a Moving Target - Addressing Web Application Concept Drift
Timing of Cyber Conflict
Jason SECURITYDATA SCIENCERES

@_date: 2014-07-21 16:31:35
@_author: Eugen Leitl 
@_subject: potential leak on Torpedo 
Please read if you use/depend on Tor. Never before seen FH information.
submitted 16 hours ago * by Deepthroat2 [+1]
Hello everyone, I have some information that I have been dying to share for
months, but due to the circumstances, and to avoid detection, I had to wait
for some time before I was able to safely make this post. My goal here is to
provide information that I know is credible and for the Tor community to use
it as they see fit, due to the nature of my work, and the severe penalties
associated with breaking the rules and giving out information you aren't
supposed too, I have no way of verifying or proving anything to you that I
say here, I understand if find me less than credible, however, this is
essentially a PSA, and you can take it for what it's worth to you.
Just about one year ago, the Tor community was shaken by a Firefox exploit
which utilized a javascript exploit and an old vulnerbility in the Tor
Browser Bundle to unmask some users of Freedom Hosting. There has been
rampant misinformation, and speculation to the point that I felt like pulling
my hair out, or just simply bursting out into laughter when reading some of
the outlandish claims made by people who have little to no idea what they are
talking about. Today, I will set the record straight.
The FH exploit was a government engineered, and deployed exploit that was
designed in response to former Director Mueller's fustration at an earlier
child pornography case in which the FBI was ridiculed for being unable to
ascertain the source of child pornography, for those who aren't familiar with
this case, it involved a man who had accessed child pornography by accident
on a Tor hidden service, and then brought his desktop computer to the office,
explaining what had happened and that he subsequently preformed a "Full wipe"
on the disk.
The agent who took the report had limited knowledge about Tor, however, at
the time he knew that any directed effort to identify a specific Tor user was
hopeless, and in the report he indicated that "There is currently no known
way to ascertain the location of a Tor user, thus, no investigative leads
exsist." This got leaked to the press, and they had a field day, hinting at
the incompetency of the Bureau. Needless to say, the FBI had it's ego hurt
quite badly by this public display of incompetency.
Then Director Mueller directed the CEOS (Child exploitation and obscenity
section) to find a way to penetrate the layers of protection provided by Tor,
and to come up with a fesible way to conduct a sting operation in order to
bring these people to justice. The FBI had previously conducted a sting on
viewers of child pornography in a case out of Nebraska, that resulted in the
arrest of about 25 people. This was the first successful take down of CP
consumers that were utilizing a Tor hidden service.
One of the errors that I see alot on these forums and others was that the
Nebraska take down was done in a similar fashion to the FH exploit, with the
code being deployed onto the pages of the boards, however, this is not the
case. From my understanding, the Nebraska field office was able to find the
actual server, take it over covertly, then upload a series of files that
purported to be child pornography, but actually contained nothing but
encrypted gibberish. They were video files that were embedded with code that
called back to a computer that recorded the IP address of the requestor, date
and time similar to the way windows media player attempts to recall album
information and cover art for music cds and such. These were files that the
user actually had to download and attempt to open. This is why the service
was run for weeks, and only 25 people were identified as users. This method
was described by the techs who deployed it as a "NIT" or "Network
Investigational Tool".
Now for Freedom Hosting....
The javascript exploit could not be deployed directly on the servers which
Mr. Marques was using due to either technical reasons, or legal requirements
by the AUSA in Maryland. So the decision was made to clone the services
exactly, and transport then to the home of the FBI CEOS in the Greenbelt
division of Maryland. This location was picked specifically because
sentencing in this district for Child Pornography crimes is more severe. It
was July 31st of 2013 when the exploit actually went live, and tried to
identify criminals. It was installed previously, however, there were
technical problems early on and the code had to be revised 3 times before it
was running as intended, it ran for about 11 days before being shut down.
The amount of people identified by this exploit is still a closely gaurded
secret, with only agents having a direct "Need to know" being privy to this
information. Howver, the victory dance was short lived as news started
flowing around that the evidence may not be admissible in court, due to the
manner in which it was collected, among other reasons. Although proper
warrants were issued, it would take atleast 4-7 years to comb through the
list of suspects, and question, arrest each one. The major problem is that
after about 12 months, the courts start to presume your evidence is
prejudicial to the defendant because you're supposed to have an indictment
and serve it on the defendant within 30 days, and that just wasn't possible.
You can request an extension of this time, however you must present a new,
fresh reason for doing so..."We still aren't ready" doesn't cut it. There is
no statue of limitations for the crime of "Accessing with intent to view
child pornography" so barring any other limitations, the FBI can come after
someone 10-15 years later.
The AUSA became uncomfortable with the prospects of his legal case against
the exploitees of FH and went to the US Attorney. There was disagreement as
to whether or not the evidence would be viable, however, the operation went
on anyways. One of the victims of the FH exploit was a man by the name of
Grant Klein from Vermont. The Bureau had made arrangements with the local
police for assistance with the raid (This is pretty much standard operation
procedure, and is done for the saftey of the agents, as well as to maintain
professional courtesy. Local cops get butt hurt when you arrest people on
their turf without them knowing).
The FBI had provided the local police with court documents and the affidavit
of arrest regarding the cirsumstances of Mr. Klein's warrant, which they
promptly posted onto their press release against the wishes of the FBI. This
resulted in the termination of atleast one employee from local PD.
He was raided and before even being asked a question ,he began spewing a
confession. His home was searched, and a desktop computer with no hard disk
was found, as well a laptop computer belonging to his wife Susan. There was
no illegal materials found on these, however, he had a smartphone in the
drawer of a nightstand which contained illegal images of minors. He was
arrested and charged with 3 seperate crimes.
To make a long story short, the FH related charges were dropped because the
FBI had crossed a legal line by offering up child pornography de novo, by
shutting down the server, then bringing it back online hosting real CP. They
were uncomfortable with the prospects of this case, and were able to use a
leon good faith exception to admit the evidence they found on his phone to
make a single possession charge stick, however, he agreed to plead guilty.
The rest of the leads which lead to foreign nationals were then distributed
accordingly to the various LEA's.
Also, earlier this wekk, the UK police arrested 660 people as part of
Operation Notarise.
The operation name of the FBI takedown in Nebraska was "Operation Torpedo"
This was a cute poke at both the method they used, and the users they
Torpedo - Navy missile
Tor Pedo - Tor Pedophile.
moar comments on Reddit

@_date: 2014-07-22 13:45:36
@_author: Eugen Leitl 
@_subject: HackRF will likely start shipping in August 
(the tinfoilhatterati will understand and rejoice)
HackRF One is now available for pre-order From: HakShop (US)
NooElec (US/CA)
Hacker Warehouse (US)
Ada's Technical Books (US)
Wall of Sheep (US)
Store4Geeks (SE)
Passion Radio Shop (FR)
Passion Radio Shop UK (UK)
TAPR (US)
iSource Asia (CN)
WiMo (DE)
Pre-ordered units will ship immediately after all rewards have shipped to Kickstarter backers, estimated July 2014. For the latest information on development and manufacturing, follow the Kickstarter updates.

@_date: 2014-07-23 12:13:28
@_author: Eugen Leitl 
@_subject: Gruveo, more secure skype alternative? 
RetroShare has quite good P2P audio. It's not properly audited though,
caveat emptor.

@_date: 2014-07-23 14:22:36
@_author: Eugen Leitl 
@_subject: Tor developers vow to fix bug that can uncloak users 
Tor developers vow to fix bug that can uncloak users
Weakness was topic of talk abruptly pulled from security conference.
by Dan Goodin - July 22 2014, 8:15pm CEST
Developers of the Tor privacy service say they're close to fixing a weakness
that researchers for an abruptly canceled conference presentation said
provides a low-cost way for adversaries to deanonymize hundreds of thousands
of users.
The talk previously scheduled for next month's Black Hat security conference
in Las Vegas was titled "You Don't Have to be the NSA to Break Tor:
Deanonymizing Users on a Budget." The abstract said that the hack cost less
than $3,000 and could uncloak hundreds of thousands of users. On Monday,
Black Hat organizers said the presentation was canceled at the request of
attorneys from Carnegie Mellon University (CMU), where the researchers were
employed, as well as the Software Engineering Institute (SEI). The attorneys
said only that the materials to be presented "have not yet been approved by
CMU/SEI for public release." Researchers Alexander Volynkin and Michael
McCord have yet to explain why their talk was pulled.
Tor officials responded by saying that they're working on an update for
individual Tor relay nodes that will close the unspecified security hole.
"Based on our current plans, we'll be putting out a fix that relays can apply
that should close the particular bug they found," Tor project leader Roger
Dingledine wrote in an e-mail to Tor users. "The bug is a nice bug, but it
isn't the end of the world. And of course these things are never as simple as
'close that one bug and you're 100% safe.'"
He said the fix was complicated because the researchers didn't provide all
the technical details when privately informing Tor officials of the
"We've been trying to find delicate ways to explain that we think we know
what they did, but also it sure would have been smoother if they'd opted to
tell us everything," he wrote. "The main reason for trying to be delicate is
that I don't want to discourage future researchers from telling us about neat
things that they find. I'm currently waiting for them to answer their mail so
I can proceed."
In a previous e-mail, Dingledine said Tor developers "informally" received
some materials related to the vulnerability. He went on to say Tor officials
played no role in the cancellation of the Black Hat talk.
"We did not ask Black Hat or CERT to cancel the talk. We did (and still do)
have questions for the presenter and for CERT about some aspects of the
research, but we had no idea the talk would be pulled before the announcement
was made," he wrote.
CMU is affiliated with CERT, which coordinates security disclosures between
researchers and affected parties. A CMU spokesman contacted Monday didn't
elaborate on the reasons for pulling the talk.

@_date: 2014-07-24 16:04:24
@_author: Eugen Leitl 
@_subject: Tails vulnerability specific to I2P, not Tor 
SILVER BULLETS AND FAIRY TAILS
This week we made mention on Twitter of a zero-day vulnerability weve unearthed that affects the popular Tails operating system. As the Tails website states:
Tails is a live operating system, that you can start on almost any computer from a DVD, USB stick, or SD card. It aims at preserving your privacy and anonymity, and helps you to:
use the Internet anonymously and circumvent censorship;
all connections to the Internet are forced to go through the Tor network;
leave no trace on the computer you are using unless you ask it explicitly;
use state-of-the-art cryptographic tools to encrypt your files, emails and instant messaging.
This software was largely popularized due to the fact that it was used by whistleblower Edward Snowden. Since then, the OS has garnered much attention and use by a wide range of those seeking anonymity on the Internet.
We publicized the fact that weve discovered these issues for a very simple reason: no user should put full trust into any particular security solution. By bringing to light the fact that we have found verifiable flaws in such a widely trusted piece of code, we hope to remind the Tails userbase that no software is infallible. Even when the issues weve found are fixed by the Tails team, the community should keep in mind that there are most certainly other flaws still present and likely known to others.
Our customers use our information for both offensive and defensive purposes to better protect themselves and others. Providing a wide variety of exploit software we help penetration testers effectively test network security and incident response teams. One high profile example occurred last year when Facebook used a zero-day vulnerability to test their teams response to a zero-day attack. The information we provide is also leveraged in defensive purposes providing companies with well documented research for use in IDS and AV signatures for previously unknown threats. We at Exodus are able to do what many software projects cannot, perform security code audits and find exploitable vulnerabilities releasing them to the public.
The Vulnerable Component
The vulnerability we will be disclosing is specific to I2P. I2P currently boasts about 30,000 active peers. Since I2P has been bundled with Tails since version 0.7, Tails is by far the most widely adopted I2P usage. The I2P vulnerability works on default, fully patched installation of Tails. No settings or configurations need to be changed for the exploit to work. I2P is preconfigured so that all .i2p TLD sites are routed through the I2P network. At a high level I2P traffic is message based similar to IP packets. All communication is encrypted end to end with a total of four layers of encryption. I2P routers (end points) act as cryptographic identifiers, similar to a pair of public keys. I2P is a packet switched network, instead of circuit switched like Tor. This means transparent load balancing of packets across multiple peers. I2P is fully distributed with no centralized resources. There is no distinct separation of servers to nodes, this architecture helps eliminate single points of failure.
To lend credence to our claims we have created a video that demonstrates de-anonymizing a Tails user:
0:00:00,000 > 0:00:10,400: Demonstrating IP on listening server, Turning on listening server
0:00:19,000 > 0:00:25,400: Tails user visiting website icanhazip.com which shows the anonymized IP address
0:00:36,000 > 0:00:49,400: Showing that were indeed using the latest Tails build 1.1
0:00:50,000 > 0:01:03,400: I2P address being resolved, proof of concept malicious payload being delivered
0:01:30,000 > 0:01:40,400: Listening server retrieves the Tails users de-anonymized IP address (Austin RoadRunner ISP)
Note on Disclosure
Disclosure of vulnerabilities takes many forms, particularly their shape is adapted to the landscape that the platform is used upon. In the past at Exodus Intelligence, weve felt that significant vulnerabilities have been disregarded and have not had the requisite exposure. Through appropriate airing of the issue, we feel that users of such security platforms may come to understand the risks in base-level trust. Even further we hope to break the mold of unconditional trust in a platform. Users should question the tools they use, they should go even further to understand the underlying mechanisms that interlock to grant them security. Its not enough to have faith upon security, rather to have an understanding of it. If the public thinks Exodus is one of a few entities finding bugs in software, they are grossly misinformed. As is the case with all vulnerabilities we report to vendors, we do not ask for any remuneration. All flaws that we give to vendors are given free of charge. All accusations of extortion perpetuated by those unfamiliar with our business model are completely unfounded. As of publication of this blog post the Tails team and the I2P team have both received all the relevant details and exploit code they require to remediate the vulnerabilities weve discovered.
Recently a high profile talk on de-anonymization Tor users was pulled from Blackhat due to legal issues. Their talk outlined with a budget of $3000 with some powerful servers and multiple gigabit links they were able to de-anonymize hundreds of thousands of users in a couple of months. Exodus decided to pick up where this talk left off by letting the community know that there are many other vectors for de-anonymization. The vulnerability we have found is able to perform remote code execution with a specially crafted payload. This payload can be customized to unmask a user and show the public IP address in which the user connected from within a couple of seconds.
Stay Tuned
Part two of this blog post will present a technical discussion of the vulnerability. This will be posted once we have confirmed the vulnerabilities in I2P are patched and have been incorporated into Tails.

@_date: 2014-07-28 18:20:42
@_author: Eugen Leitl 
@_subject: Alleged "microkernel mathematically proven to be bug free" 
I'm on their announcement list. Good news, question is who's going to
pick it up and build a distro around that. Anyone here use Qubes OS?

@_date: 2014-07-02 18:41:25
@_author: Eugen Leitl 
@_subject: Court =?utf-8?B?4oCTIE9mZmljaWE=?= =?utf-8?Q?l?= statement part #1 
Apologies, not sure this has been posted already in the thread, I'm
 Court  Official statement part Posted on July 2, 2014 by Will
As seen possibly here, or here i lost the Tor case and was sentenced to 3
years probation (instead of 3 months jail) and all fees (court and experts,
Assumption ~30000EUR, not less than 20k for sure).
The sentence is based on 12 which allows for anyone to be dealt with as
perpetrator (which is a pretty dictatorial law IMO) and this is based on that
i knew it *could* possibly be used for criminal activity (in this case child
I wont write much more yet before i have the written ruling (i do not even
know my probation terms yet) but merely want to explain why i wont appeal
this sentence:
First would be that I simply cant afford it anymore, donations covered a lot
of lawyer fees but i had to use my entire money on this case as well, im now
bankrupt and the garnishment (a rare word, DE: Pfndung) of my income (to pay
the 20k+ costs) does not help with it either. I have high medical costs as
well besides which are more important. Im not really interested in more
external funding due to taxation issues with larger amounts (and i do not
want *another* crime on me).   Second is that i just want to be done with
this, i had now years of issues (i would write harassment but then i get
sued again for sure) (Ex: Citing my boss to the police for questioning (x3);
physically monitoring my boss in Vienna; citing friends to the police for
questioning (x2); confiscation of bank transaction data; Polish extradiction
threats for hacking cases there (x2); citing me for useless questioning
causing lawyer costs (x5+) etc. etc.)  Its now finally over and besides the
cost i CAN live with this sentence, it does not show up in police registers
and wont be an issue for work and alike in the future.   Third is the
mental component, this years of horror changed a lot up to me being
hospitalized (x3) with paranoid schizophrenia (which was a wrong diagnosis,
but still its not helpful if you HAVE to assume permanent monitoring of
everything), PTSD (among other issues) and now taking medication  It took
its toll, including me getting fired for being in the clinic/sick stay for a
long time, i just cant afford to loose my job or go the clinic again even if
i actually should be still there.   Fourth is the attention, media and
personal  I dont really like any attention on myself, especially when
others should get it (like some public cause, Pirateparty or alike).  
So this is it for now, stay tuned for more in a few days.

@_date: 2014-07-03 10:38:16
@_author: Eugen Leitl 
@_subject: REVERSE ENGINEERING NSA SPY =?utf-8?B?4oCY?= 
REVERSE ENGINEERING NSA SPY RETRO REFLECTOR GADGETS WITH THE HACKRF
In 2013 whistleblower Edward Snowden leaked (along with other documents) some
information about the American National Security Agencies (NSA) spy tools.
One such group of tools named retro reflectors has recently been
investigated and reverse engineered by Micheal Ossmann, the security
researcher behind the recently available for preorder HackRF software defined
radio. The HackRF is a SDR similar to the RTL-SDR, but with better
performance and transmit capabilities.
Newscientist Magazine has written an article about Ossmanns work here. From
their article a retro reflectors are described in the following quote.
One reflector, which the NSA called Ragemaster, can be fixed to a computers
monitor cable to pick up on-screen images. Another, Surlyspawn, sits on the
keyboard cable and harvests keystrokes. After a lot of trial and error,
Ossmann found these bugs can be remarkably simple devices  little more than
a tiny transistor and a 2-centimetre-long wire acting as an antenna.
The HackRF comes in to play in the following quote
Ossmann found that using the radio [HackRF] to emit a high-power radar signal
causes a reflector to wirelessly transmit the data from keystrokes, say, to
an attacker. The set-up is akin to a large-scale RFID- chip system. Since the
signals returned from the reflectors are noisy and often scattered across
different bands, SDRs versatility is handy, says Robin Heydon at Cambridge
Silicon Radio in the UK.
Ossmann will present his work at this years Defcon conference in August.

@_date: 2014-07-03 14:46:48
@_author: Eugen Leitl 
@_subject: XKeyscore-Quellcode: more english details requested 
According to fefe who's seen the source it's just a selector

@_date: 2014-07-03 15:16:13
@_author: Eugen Leitl 
@_subject: tools used by intelligence analysts 
*ORA for network analysis Pentaho for data transformation Rapid Miner for data mining Orange for data visualisations and analysis Maltego for the analysis of networks between people, companies, websites, etc. Apache Hadoop for large-scale, distributed computing and analysis
Axis Pro Starlight Analyst's Notebook Palantir XPLR witk Reddit plugin Tiny Tiny Rss Pligg Twitter, Reddit, ...
ARC GIS
CPOF Oryon  (?)
Investigative Dashboard  (?)

@_date: 2014-07-03 17:29:47
@_author: Eugen Leitl 
@_subject: NSA targets the privacy-conscious 
NSA targets the privacy-conscious
von J. Appelbaum, A. Gibson, J. Goetz, V. Kabisch, L. Kampf, L. Ryge
The investigation discloses the following:
Two servers in Germany - in Berlin and Nuremberg - are under surveillance by
the NSA.
Merely searching the web for the privacy-enhancing software tools outlined in
the XKeyscore rules causes the NSA to mark and track the IP address of the
person doing the search. Not only are German privacy software users tracked,
but the source code shows that privacy software users worldwide are tracked
by the NSA.
Among the NSA's targets is the Tor network funded primarily by the US
government to aid democracy advocates in authoritarian states.
 The XKeyscore rules reveal that the NSA tracks all connections to a server
that hosts part of an anonymous email service at the MIT Computer Science and
Artificial Intelligence Laboratory (CSAIL) in Cambridge, Massachusetts. It
also records details about visits to a popular internet journal for Linux
operating system users called "the Linux Journal - the Original Magazine of
the Linux Community", and calls it an "extremist forum".
Three authors of this investigation have personal and professional ties to
the Tor Project, an American company mentioned within the following
investigation. Jacob Appelbaum is a paid employee of the Tor Project, Aaron
Gibson is a paid contractor for the Tor Project, and Leif Ryge is a volunteer
contributor to various Tor-related software projects. Their research in this
story is wholly independent from the Tor Project and does not reflect the
views of the Tor Project in any way. During the course of the investigation,
it was further discovered that an additional computer system run by Jacob
Appelbaum for his volunteer work with helping to run part of the Tor network
was targeted by the NSA. Moreover, all members of this team are Tor users and
appear to be have been targets of the mass surveillance described in the
It is a small server that looks like any of the other dozens in the same row.
It is in a large room devoted to computers and computer storage, just like
every other room in this industrial park building on Am Tower Street just
outside the city of Nuremberg. That the grey building is surrounded by barbed
wire seems to indicate that the servers' provider is working hard to secure
their customers' data.
Yet despite these efforts, one of the servers is targeted by the NSA.
The IP address 212.212.245.170 is explicitly specified in the rules of the
powerful and invasive spy software program XKeyscore. The code is published
here exclusively for the first time.
After a year of NSA revelations based on documents that focus on program
names and high-level Powerpoint presentations, NDR and WDR are revealing NSA
source code that shows how these programs function and how they are
implemented in Germany and around the world.
Months of investigation by the German public television broadcasters NDR and
WDR, drawing on exclusive access to top secret NSA source code, interviews
with former NSA employees, and the review of secret documents of the German
government reveal that not only is the server in Nuremberg under observation
by the NSA, but so is virtually anyone who has taken an interest in several
well-known privacy software systems.
The NSA program XKeyscore is a collection and analysis tool and "a computer
network exploitation system", as described in an NSA presentation. It is one
of the agencys most ambitious programs devoted to gathering "nearly
everything a user does on the internet." The source code contains several
rules that enable agents using XKeyscore to surveil privacy-conscious
internet users around the world. The rules published here are specifically
directed at the infrastructure and the users of the Tor Network, the Tails
operating system, and other privacy-related software. Tor, also known as The Onion Router, is a network of several thousand
volunteer-operated servers, or nodes, that work in concert to conceal Tor
users' IP addresses and thus keep them anonymous while online.
Tails is a privacy-focused GNU/Linux-based operating system that runs
entirely from an external storage device such as a USB stick or CD. It comes
with Tor and other privacy tools pre-installed and configured, and each time
it reboots it automatically wipes everything that is not saved on an
encrypted persistent storage medium.
Normally a user's online traffic - such as emails, instant messages,
searches, or visits to websites - can be attributed to the IP address
assigned to them by their internet service provider. When a user goes online
over the Tor Network, their connections are relayed through a number of Tor
nodes using another layer of encryption between each server such that the
first server cannot see where the last server is located and vice-versa.
Tor is used by private individuals who want to conceal their online activity,
human rights activists in oppressive regimes such as China and Iran,
journalists who want to protect their sources, and even by the U.S. Drug
Enforcement Agency in their efforts to infiltrate criminal groups without
revealing their identity. The Tor Project is a non-profit charity based in
Massachusetts and is primarily funded by government agencies. Thus it is
ironic that the Tor Network has become such a high-priority target in the
NSA's worldwide surveillance system.
As revealed by the British newspaper The Guardian, there have been repeated
efforts to crack the Tor Network and de-anonymize its users. The top secret
presentations published in October last year show that Tor is anathema to the
NSA. In one presentation, agents refer to the network as "the king of
high-secure, low-latency internet anonymity". Another is titled "Tor Stinks".
Despite the snide remarks, the agents admit, "We will never be able to
de-anonymize all Tor users all the time".
The former NSA director General Keith Alexander stated that all those
communicating with encryption will be regarded as terror suspects and will be
monitored and stored as a method of prevention, as quoted by the Frankfurter
Allgemeine Zeitung in August last year. The top secret source code published
here indicates that the NSA is making a concerted effort to combat any and
all anonymous spaces that remain on the internet. Merely visiting
privacy-related websites is enough for a user's IP address to be logged into
an NSA database.
An examination of the XKeyscore rules published here goes beyond the slide
presentation and provides a window into the actual instructions given to NSA
computers. The code was deployed recently and former NSA employees and
experts are convinced that the same code or similar code is still in use
today. The XKeyscore rules include elements known as "appids",
"fingerprints", and "microplugins".  Each connection a user makes online - to
a search engine, for example - can be assigned a single appid and any number
of fingerprints.
Appids are unique identifiers for a connection in XKeyscore. Appid rules have
weights assigned to them.  When multiple appids match a given connection, the
one with the highest weight is chosen. Microplugins may contain software
written in general-purpose programming languages, such as C++, which can
extract and store specific types of data. The rules specifically target the
Tor Project's email and web infrastructure, as well as servers operated by
key volunteers in Germany, the United States, Sweden, Austria, and the
Netherlands. Beyond being ethically questionable, the attacks on Tor also
raise legal concerns.  The IP addresses of Tor servers in the United States
are amongst the targets, which could violate the fourth amendment of the US
The German attorney Thomas Stadler, who specializes in IT law, commented:
"The fact that a German citizen is specifically traced by the NSA, in my
opinion, justifies the reasonable suspicion of the NSA carrying out secret
service activities in Germany. For this reason, the German Federal Public
Prosecutor should look into this matter and initiate preliminary
One of NSA's German targets is 212.212.245.170.  The string of numbers is an
IP address assigned to Sebastian Hahn, a computer science student at the
University of Erlangen. Hahn operates the server out of a grey high-security
building a few kilometers from where he lives. Hahn, 28 years old and
sporting a red beard, volunteers for the Tor Project in his free time. He is
especially trusted by the Tor community, as his server is not just a node, it
is a so-called Directory Authority. There are nine of these worldwide, and
they are central to the Tor Network, as they contain an index of all Tor
nodes. A user's traffic is automatically directed to one of the directory
authorities to download the newest list of Tor relays generated each hour.
Quellcode NSA  "anonymizer/tor/node/authority" fingerprint.
Hahn's predecessor named the server Gabelmoo, or Fork Man, the nickname of a
local statue of Poseidon. After a look at the NSA source code, Hahn quickly
found his server's name listed in the XKeyscore rules. "Yes, I recognize the
IP address of my Tor server called 'gabelmoo'." he said. "Millions of people
use it to stay safe online, and by watching the server and collecting
metadata about its users, those people are put at risk." The rule shown to
Hahn, published below, has a fingerprint called
'anonymizer/tor/node/authority'. The fingerprint targets users who connect to
Gabelmoo and other Tor Directory Authority servers. In Germany, the Tor
Directory Authorities like Gabelmoo that are specifically targeted by
XKeyscore rules are in Berlin and Nuremberg. Additional targets are located
in Austria, Sweden, the United States, and the Netherlands.
Quellcode NSA  Fragments of XKeyscore rules targetting Tor directory
The expression below performs essentially the same function, but it specifies
the Tor directory authorities located in Five Eyes countries (Australia,
Canada, New Zealand, the United Kingdom and the United States) separately
from those in other countries. As the comment explains, the "goal is to find
potential Tor clients connecting to the Tor directory servers."
Another rule catalogs users connecting to known Tor relays. This is not
difficult, because the addresses of all normal Tor relays are published by
the directory authorities so that the Tor software on users' computers can
select its own path through the network. In addition to the public relays,
connections characterized as Tor based on protocol identifiers are also
Not only Metadata
Internet service providers in countries with strong censorship such as China
and Iran frequently block connections to known Tor relays. To avoid this
blocking, The Tor Project maintains a list of non-public relays called
"bridges" to allow users to avoid this type of blocking. Bridges are run by
volunteers and they share the details with the Tor Project to help censored
users reach the internet.
Quellcode NSA  Microplugin which extracts bridge addresses from the full text
of Tor Project emails.
Users can request a bridge address via email or on the web. The following
fingerprints show two ways that XKeyscore attempts to track Tor bridge users.
First, the fingerprint "anonymizer/tor/bridge/tls" records connections to the
bridges.torproject.org server. Second, in order obtain the actual bridge
addresses for the purpose of tracking connections to them in the future, the
"microplugin" fingerprint called "anonymizer/tor/bridge/email" extracts data
from the body of the emails that the Tor Project sends to its users.
This code demonstrates the ease with which an XKeyscore rule can analyze the
full content of intercepted connections. The fingerprint first checks every
message using the "email_address" function to see if the message is to or
from "bridges Next, if the address matched, it uses the
"email_body" function to search the full content of the email for a
particular piece of text - in this case, "
If the "email_body" function finds what it is looking for, it passes the full
email text to a C++ program which extracts the bridge addresses and stores
them in a database.
Quellcode NSA  Fingerprint to identify visitors to the Tor Project website.
The full content of the email must already be intercepted before this code
can analyze it. XKeyscore also keeps track of people who are not using Tor,
but who are merely visiting The Tor Project's website (
as this rule demonstrates:
Quellcode NSA  Rules targeting people viewing the Tails or Linux Journal
websites, or performing Tails-related web searches.
It is interesting to note that this rule specifically avoids fingerprinting
users believed to be located in Five Eyes countries, while other rules make
no such distinction. For instance, the following fingerprint targets users
visiting the Tails and Linux Journal websites, or performing certain web
searches related to Tails, and makes no distinction about the country of the
The comment in the  source code above describes Tails as "a comsec mechanism
advocated by extremists on extremist forums". In actuality, the software is
used by journalists, human rights activists, and hundreds of thousands of
ordinary people who merely wish to protect their privacy.
The rules related to Tails clearly demonstrate how easily web searches and
website visits can be spied on by XKeyscore. On June 25, 2014, the United
States Supreme Court noted how sensitive this type of information is in their
Riley v. California decision against warrantless searches of mobile phones:
"An Internet search and browsing history [...] could reveal an individuals
private interests or concerns - perhaps a search for certain symptoms of
disease, coupled with frequent visits to WebMD."
Quellcode NSA  C++ program which searches "raw traffic" for .onion addresses.
In addition to anonymous internet access, Tor also provides a mechanism for
hosting anonymous internet services called "Hidden Services". These sites'
URLs contain a domain name in the pseudo-top-level-domain ".onion" which is
only accessible using Tor. The code shown below finds and catalogs URLs for
these sites which XKeyscore sees in "raw traffic", creating a unique
fingerprint for each onion address. Each .onion address found in raw traffic
is extracted and stored in an NSA database:
Quellcode NSA  "anonymizer/mailer/mixminion" appid matching all connections
to 128.31.0.34.
There are also rules that target users of numerous other privacy-focused
internet services, including HotSpotShield, FreeNet, Centurian,
FreeProxies.org, MegaProxy, privacy.li and an anonymous email service called
MixMinion as well as its predecessor MixMaster. The appid rule for MixMinion
is extremely broad as it matches all traffic to or from the IP address
128.31.0.34, a server located on the MIT campus.
That server is operated by the Tor Project's leader Roger Dingledine, an MIT
alumnus. The machine at this IP address provides many services besides
MixMinion, and it is also one of the above-mentioned Tor directory
authorities. Dingledine said "That computer hosts many websites, ranging from
open source gaming libraries to the Privacy Enhancing Technologies Symposium
Sebastian Hahn, the Tor volunteer who runs Gabelmoo, was stunned to learn
that his hobby could interest the NSA: "This shows that Tor is working well
enough that Tor has become a target for the intelligence services. For me
this means that I will definitely go ahead with the project.
When asked for a reaction to the findings, the Tor Project's Roger Dingledine
stated the following: "We've been thinking of state surveillance for years
because of our work in places where journalists are threatened. Tor's
anonymity is based on distributed trust, so observing traffic at one place in
the Tor network, even a directory authority, isn't enough to break it. Tor
has gone mainstream in the past few years, and its wide diversity of users -
from civic-minded individuals and ordinary consumers to activists, law
enforcement, and companies - is part of its security. Just learning that
somebody visited the Tor or Tails website doesn't tell you whether that
person is a journalist source, someone concerned that her Internet Service
Provider will learn about her health conditions, or just someone irked that
cat videos are blocked in her location. Trying to make a list of Tor's
millions of daily users certainly counts as wide scale collection. Their
attack on the bridge address distribution service shows their "collect all
the things" mentality - it's worth emphasizing that we designed bridges for
users in countries like China and Iran, and here we are finding out about
attacks by our own country. Does reading the contents of those mails violate
the wiretap act? Now I understand how the Google engineers felt when they
learned about the attacks on their infrastructure.
NDR and WDR wanted to know from the NSA how it justified attacking a service
funded by the U.S. government, under what legal authority Tor Network users
are monitored, and whether the German government has any knowledge of the
targeting of servers in Germany. Instead of adressing the questions
repeatedly posed to them, the NSA provided the following statement: "In
carrying out its mission, NSA collects only what it is authorized by law to
collect for valid foreign intelligence purposes - regardless of the technical
means used by foreign intelligence targets. The communications of people who
are not foreign intelligence targets are of no use to the agency. In January,
President Obama issued U.S. Presidential Policy Directive 28, which affirms
that all persons - regardless of nationality - have legitimate privacy
interests in the handling of their personal information, and that privacy and
civil liberties shall be integral considerations in the planning of U.S.
signals intelligence activities. The president's  directive also makes clear
that the United States does not collect signals intelligence for the purpose
of suppressing or burdening criticism or dissent, or for disadvantaging
persons based on their ethnicity, race, gender, sexual orientation, or
religion. XKeyscore is an analytic tool that is used as a part of NSA's
lawful foreign signals intelligence collection system. Such tools have
stringent oversight and compliance mechanisms built in at several levels. The
use of XKeyscore allows the agency to help defend the nation and protect U.S.
and allied troops abroad. All of NSA's operations are conducted in strict
accordance with the rule of law, including the President's new directive."
However, the research contradicts the United States' promise to Germany that
German citizens are not surveiled without suspicion. Using Tor in Germany
does not justify targeting someone, the German attorney Thomas Stadler
states: "Tor users do not breach any laws, it is absolutely legitimate to act
anonymously on the internet. There are many good reasons to remain
What is deep packet inspection?
Deep Packet Inspection, or DPI, refers to the class of technology which
examines the content of data packets as they travel across a network. A
packet is the fundamental unit of transfer in packet switched networks like
the internet. While DPI is commonly used by organizations to monitor their
own networks, its use on public networks for censorship and surveillance has
been widely condemned by privacy advocates and the United States government
In 2012, the head of the U.S. Delegation to the World Conference on
International Telecommunications, U.S. Ambassador Terry Kramer, said some
companies have used deep packet inspection technologies to not look at
aggregate customer information, traffic information, et cetera, but to look
at individual customer information. So looking at individuals and what sites
theyre on and how much capacity theyre using, et cetera, as you can
imagine, were very much opposed to that because we feel thats a violation
of peoples privacy and gets into, obviously, censorship, et cetera.
Despite its public political condemnations of invasive DPI use, the United
States "Intelligence Community" and its "Five Eyes" partners (Australia,
Canada, New Zealand, and the United Kingdom) operate massive internet-scale
DPI systems themselves, including XKeyscore. The use of XKeyscore is not
limited to these partners, however. The software has been shared with the
German BND and BfV, as well as the Swedish FRA, amongst others.
Active vs Passive
XKeyscore and the systems that feed it are considered "passive", meaning that
they silently listen but do not transmit anything on the networks that they
are targeting. However, through a process known as "tipping", data from these
programs can trigger other systems which perform "active" attacks.
Quantum is a family of such programs, including Quantuminsert, Quantumhand,
Quantumtheory, Quantumbot, and Quantumcopper, which are used for offensive
computer intrusion. Turmoil, Quantum, and other components of the Turbulence
architecture are running at so-called "defensive sites" including the
Ramstein Air Force base in Germany, Yokota Air Force base in Japan, and
numerous military and non-military locations within the United States.
Both Turmoil and XKeyscore feed selected data to real-time "tipping"
programs, such as Trafficthief, which can both alert NSA analysts when their
targets are communicating and trigger other software programs. Selected data
is "promoted" from the local XKeyscore data store to the NSA's so-called
"corporate repositories" for long term storage, analysis and exploitation.
More information about XKeyscore
In 2013, the British newspaper The Guardian revealed that by 2008 more than
150 internet surveillance facilities around the world were running the
XKeyscore Deep Packet Inspection software. All of the internet traffic
observed by XKeyscore, both metadata and full content, is analyzed and stored
temporarily at the collection sites for periods ranging from days to weeks,
while selected data is forwarded on to other locations for long-term storage.
The storage, indexing, and querying functions are performed at or near the
collection sites because the volume of data being collected is too large to
forward everything back to facilities in other countries. Analysts working
from various locations around the world may search specific XKeyscore sites,
or send their queries to a collection of sites.
XKeyscore provides a modular architecture in which tens of thousands of small
computer programs, or rules, written in XKeyscore's specialized programming
languages called Genesis and XKScript as well as general-purpose languages
such as C++ and Python, are run against all traffic to categorize it and
extract data. This indexing of the "full take" allows analysts to query the
temporary storage stored at the XKeyscore site, effectively sifting through
already pilfered communications which occurred before they had deemed them
interesting for a specific reason.
XKeyscore can be fed by several different programs, including Wealthycluster
and Turmoil. These programs "sessionize" the data, which means that
individual connections, such as a request for a web page, are reconstructed
from the stream of intercepted packets.
Locations where the NSA runs XKeyscore include Special Source Operations
(SSO) sites, typically found at or near major telecommunication providers'
infrastructure; Special Collection Service (SCS) sites, usually located
inside diplomatic facilities like embassies and consulates; and FORNSAT sites
where satellite communications are intercepted. All of these types of sites
are known to exist in Germany.
Other "Five Eyes" partners also operate XKeyscore installations. The United
Kingdom's Tempora program runs the largest instance of XKeyscore. Both the
software itself and limited access to NSA databases have been shared with
so-called "3rd party" partners including Germany. The German foreign
intelligence agency BND and the domestic intelligence agency BfV are testing
the Software.

@_date: 2014-07-04 16:56:41
@_author: Eugen Leitl 
@_subject: messing with XKeyScore 
Errata Security
Advanced persistent cybersecurity
Friday, July 04, 2014
Jamming XKeyScore
Back in the day there was talk about "jamming echelon" by adding keywords to email that the echelon system was supposedly looking for. We can do the same thing for XKeyScore: jam the system with more information than it can handle. (I enumerate the bugs I find in the code as "xks-00xx").
For example, when sending emails, just send from the address "bridges at torproject.org" and in the email body include:
bridge = 0.0.0.1:443
bridge = 0.0.0.2:443
bridge = 0.0.0.3:443
Continue this for megabytes worth of bridges (xks-0001), and it'll totally mess up XKeyScore. It has no defense against getting flooded with information like this, as far as I can see.
Note that the regex only cares about 1 to 3 digit numbers, that means the following will be accepted by the system (xks-0002):
bridge = 75.748.86.91:80
The port number matches on 2 to 4 digits ([0-9]{2,4}). Therefore, bridges with port numbers below 10 and above 9999 will be safe. I don't know if this code reflect a limitation in Tor, or but assuming high/low ports are possible, this can be used to evade detection (xks-0011).
Strangely, when the port number is parsed, it'll capture the first non-digit character after the port number (xks-0012). This is normally whitespace, but we could generate an email with 256 entries, trying every possible character. A character like < or ' might cause various problems in rendering on an HTML page or generating SQL queries.
You can also jam the system with too many Onion addresses (xks-0003), but there are additional ways to screw with those. When looking for Onion addresses, the code uses a regex that contains the following capture clause:
This is looking for a string like " or " but the regex has no upper bounds (xks-0004) and there is no validation. Thus, you can include "goscrewyourself://o987asgia7gsdfoi.onion:443/" in network traffic, and it'll happily insert this into the database. But remember that "no upper bounds" means just that: the prefix can be kilobytes long, megabytes long, or even gigabytes long. You can open a TCP connection to a system you feel the NSA is monitoring, send 5 gigabytes of lower-case letters, followed by the rest of the Onion address, and see what happens. I mean, there is some practical upper bound somewhere in the system,, and when you hit it, there's a good chance bad things will happen.
Likewise, the port number for Onion address is captured by the regex (d+), meaning any number of digits (xks-0005). Thus, we could get numbers that overflow 16-bits, 32-bits, 64-bits, or 982745987-bits. Very long strings of digits (megabytes) at this point might cause bad things to happen within the system.
There is an extra-special thing that happens when the schema part of the Onion address is exactly 16-bytes long (xks-0006). This will cause the address and the scheme to reverse themselves when inserted into the database. Thus, we can insert digits into the scheme field. This might foul up later code that assumes schemes only contain letters, because only letters match in the regex.
In some protocol fields, the regexes appear to be partial matches. The system appears to match on HTTP servers with "mixminion" anywhere in the name. Thus, we start causing lots of traffic to go to our domains, such as "mixminion.robertgraham.com", that will cause their servers to fill up with long term storage of sessions they don't care about (xks-0007)
Let's talk X.509, and the following code:
fingerprint('anonymizer/tor/bridge/tls') =
  ssl_x509_subject('bridges.torproject.org') or
  ssl_dns_name('bridges.torproject.org');
Code that parses X.509 certificates is known to be flaky as all get out. The simplest thing to do is find a data center you feel the NSA can monitor, and then setup a hostile server that can do generic fuzzing of X.509 certificates, trying to crash them.
It's likely that whatever code is parsing X.509 certificates is not validating them. Thus, anybody can put certificates on their servers claiming to be 'bridges.torproject.org' (xks-0008). It's likely that the NSA is parsing SSL on all ports, so just pick a random port on your server not being used for anything else, create a self-signed CERT claiming to be "bridges.torproject.org', then create incoming links to that port from other places so at least search-engines will follow that link and generate traffic. This will cause the NSA database of bridges to fill up with bad information -- assuming it's not already full from people screwing with the emails as noted above :).
Putting the above code in a web page like this one will cause every visitor to trigger a search for TAILS in the XKeyScore rules. The more people who do this, the less useful it becomes to the NSA (xks-0009) in labeling people as suspicious. Likewise, putting tails.boum.org/<.title> in your webpages will cause the same effect, even when CSS/JavaScript makes such a title invisible.
In theory, the NSA should only be monitoring foreign traffic, and not traffic originating from the United States (or, apparently, the other five-eyes). So here is the fun thing (xks-0010): run your jamming tools from United States IP addresses against those servers in Iran you know the NSA is monitoring. Since the code should already be ignoring the traffic because it originates from the United States, then they can't complain if you've filled up their databases full of Tor Onion and bridge addresses.
Robert Graham

@_date: 2014-07-08 16:04:58
@_author: Eugen Leitl 
@_subject: The Ex-Google Hacker Taking on =?utf-8?Q?t?= 
cypherpunks
 The Ex-Google Hacker Taking on the Worlds Spy Agencies
BY ANDY GREENBERG   07.08.14  |   6:30 AM  |   PERMALINK
Ariel Zambelich/WIRED
During his last six years working as an elite security researcher for Google,
the hacker known as Morgan Mayhem spent his nights and weekends hunting down
the malware used to spy on vulnerable targets like human rights activists and
political dissidents.
His new job tasks him with defending a different endangered species: American
national security journalists.
For the last month, 34-year-old Morgan Marquis-Boire has been the director of
security for First Look Media, the journalism startup founded by Glenn
Greenwald and Laura Poitras. The website has become the most prolific
publisher of NSA leaker Edward Snowdens remaining secrets. Marquis-Boires
daunting task is to safeguard those documents, and the communications of
reporters who have perhaps the press most adversarial relationships with
Western intelligence agencies.
Beyond protecting Snowdens favorite journalists, Marquis-Boire sees his
decision to leave Google for First Look as a chance to focus full-time on the
problem of protecting reporters and activists as a whole, groups he sees as
some of the most sensitive targets for governments globally. I look at the
risk posed to individuals in the real world, says Marquis-Boire, an
imposing, often black-clad New Zealander with earrings, dreadlocks, and a
taste for death metal. In human rights and journalism, the consequences of
communications being compromised are imprisonment, physical violence, and
even death. These types of users need security assistance in a very real
Marquis-Boire already has distinguished himself as a relentless
counter-surveillance researcher and a vocal critic of the companies that have
created an industry hawking spyware to governments. In 2012, he and
researchers at the University of Torontos Citizen Lab were the first to
identify Finfisher, a stealthy collection of spying tools sold by the British
firm Gamma Group that they eventually tracked to command-and-control servers
in 25 countries. Later that year he helped trace how a piece of software sold
by the Italian firm Hacking Team was used by the government of the United
Arab Emirates to spy on a political dissident beaten by thugs. Just last
month he revealed new findings that showed how that companys tools have
evolved to target iPhones, Android devices and other mobile targets. And in
early 2013 Marquis-Boire and Citizen Lab researchers mapped the spread of
surveillance and censorship tools sold by the Palo Alto, California firm Blue
Coat to 61 countries, including Iran.
In the detective work required to pin those stealthy spying incidents on
repressive governments and Western companies, Marquis-Boire is
extraordinarily talented, says Ron Deibert, a professor of political
science at the University of Toronto and Citizen Labs director. There are
some people who are phenomenally adept at forensics, who have an intuitive
sense of how to make connections through different pieces of evidence, he
says. Morgan has those skillsBut what I very much appreciate about him is
his passion for human rights.
A Cypherpunk In The Newsroom First Look and Marquis-Boire arent saying much
about exactly what hell do at the closely-watched new media startup. But
Marquis-Boire says he was convinced early in their recruitment meetings that
First Look will treat security as a central tenet. (More about First Looks
plans in the video below.) The job also presents a challenge worthy of
leaving his high profile position at Google: Protecting the communications
between non-technical reporters and their highly-sensitive sources in a
post-WikiLeaks and -Snowden era where theyre both increasingly targeted by
Marquis-Boire hints that hes already researching security vulnerabilities
that affect journalists, and working with several companies to release
security fixes to their services in the next couple of months. Brian Sweeney,
First Looks head of technology operations, says Marquis-Boires work likely
will extend into research designed to protect reporters beyond the companys
firewall. The idea that all digital citizens, including and especially
journalists, have access to data privacy is something that we strongly
believe in, says Sweeney.
Marquis-Boire, the son of two literature professors at the University of
Auckland, got started with security experimentation as a teenager in the New
Zealand hacker scene under the handle headhntr. After starting college at
Auckland, he and a group of friends wrote an article for the university
magazine about breaking into the schools website to take over the server
that ran it. On another occasion he was called into a local telecoms office
and given a stern talking to about using their services as a test lab.
But from the beginning, his interest in hacking was also political: In the
late 1990s the kiwi teenager discovered the Cypherpunks Mailing List, a group
of cryptographers and radical libertarians bent on foiling government
surveillance and empowering individuals with privacy tools. The group
eventually would foster projects like the anonymous remailers that relay
emails to obscure their senders identities, the anonymity software Tor,
WikiLeaks, and countless other privacy and encryption projects. People
realized that to actually have free speech, we have to be sure we wont be
monitored or persecuted, says Marquis-Boire. The intertwined nature of
privacy and free expression was at the core of the cypherpunk movement.
Marquis-Boire and friends soon hosted what he says was the first anonymous
remailer server in New Zealand out of a dingy warehouse apartment with far
too many blinking lights and whirring things. Eventually, he ran five Tor
relays, the nodes in the Tor network that bounce users traffic to obscure
their location.
But Marquis-Boires first real job in security, penetration-testing banks,
power plants, and other clients for a New Zealand auditing firm, was
unsatisfying. I spent a bit of time musing about how much it costs to hire
security consultants to do something like a black box [penetration test] of
your whole enterprise, he says. I wanted to give my skills to the people
who really needed them.
He Has Quite a Hacker Mind In 2008, Google hired Marquis-Boire in its
Zurich, Switzerland office. He was assigned to cybersecurity incident
response at the company not long before the biggest known security crisis in
its history: the so-called Aurora hacking operation, in which Chinese hackers
breached Googles network for months and stole information that included
source code from its servers. Marquis-Boire became an early member of the
core team of network defenders assigned to battle the state-sponsored spies
trying to eavesdrop on Googles users. He has quite a hacker mind, says
Heather Adkins, Googles manager of information security, Of everyone Ive
ever hired at Google, Id put him in the top one percent of technical
When the Arab Spring began a year later, human rights activists like those at
Citizen Lab who had seen Marquis-Boires presentations on state-sponsored
hacking began seeking his help analyzing attacks on vulnerable groups across
the Middle East. As revolutions and political unrest blossomed from Tunisia
to Egypt to Libya to Syria, his detective work became nearly a full-time job.
There have been a lot of books not read and canceled vacations, he says.
In the meantime, Googles Adkins adds, Marquis-Boire frequently uncovered
weaknesses in the companys defenses for usersand hes been just as focused
on locking out the NSA as Chinas Peoples Liberation Army. In the wake of
revelations from Snowdens leaks that the NSA spied on unencrypted Google
data moving between the companys data centers, Marquis-Boire was one of the
first at the company to push for encryption not only of the companys
internal data transfers, but also the exchange of emails between Gmail and
other providers. That pressure led Google earlier this month to start
publicly naming which email services do and dont allow for that encryption
in a bid to pressure other companies to safeguard users privacy.
Marquis-Boires focus turned to protecting journalists in particular earlier
this year, when he and other Googlers released research in March showing that
21 out of the 25 top media organizations in the world had been targeted in
digital attacks that were likely the work of state-sponsored hackers. The
same month, he joined a technical advisory group for the Freedom of the Press
Foundation, which counts Glenn Greenwald, Laura Poitras and Edward Snowden as
members of its board. If you cant protect your privacy and that of your
sources, its debatable whether you can actually practice journalism in the
traditional sense, he says.
That notion represents a shift from the cypherpunk views of Marquis-Boires
youth. Once, cypherpunks were mainly interested in seizing privacy for
themselves. Now, he says, thats no longer enough. When we discovered that
we could create private and anonymous communications with math, that was
super cool, he says. But then after a while I think it dawned on us as a
movement that the only conversations you could have with those tools were
with other cypherpunks.
Now its been thrust into our faces that the people practicing adversarial
journalism and exposing human right abuses are the real-world targets of
precisely the kind of thing that the cypherpunk movement was trying to
protect against, says Marquis-Boire. Its become apparent we need to
provide privacy to those who need it, not just to ourselves.
Tags: Edward Snowden, First Look Media, NSA, Security

@_date: 2014-07-09 14:23:28
@_author: Eugen Leitl 
@_subject: BPjM blacklist reversed 
tl;dr: Germany has a censorship federal agency called BPjM which maintains a
secret list of about 3000 URLs. To keep the list secret it is distributed in
the form of md5 or sha1 hashes as the "BPJM-Modul". They think this is safe.
This leak explains in detail that it is in fact very easy to extract the
hashed censorship list from home routers or child protection software and
calculate the cleartext entries. It provides a first analysis of the
sometimes absurd entries on such a governmental Internet censorship list.

@_date: 2014-07-10 11:06:55
@_author: Eugen Leitl 
@_subject: [Server-sky] Server sky and social architecture 
Code is Law, Hardware is Code's Language
The Law of Law is language. If your language is richly metaphorical and contains the word "schadenfreude", you will annex the Sudetenland, gas most of your ethnic minorities, and a surviving ethnic outlier will use your language to express general relativity. Other languages better express other crimes and concepts. A linguist will tell you all languages can express all concepts - languages are Turing complete - but this fashionable conceit does not tell us why different cultures do different things.
Code is law. Hardware is the language and law of code. Code can only do what hardware permits. A Turing complete machine can manufacture any set of symbols from any other set, but those symbols cannot go where the hardware doesn't connect.
In 1990 I designed a chip, a non-blocking crossbar routing device, for the startup I-Cube Design Systems. This chip routed signals from any pin to any other pin, and could route 240 inputs to any combination of 240 other outputs. But it also had fanout - it could route an input to two or more outputs. 160 inputs could become 320 outputs. This was useful for the original task - hardware logic simulation. When the original logic simulator customers became enmired in patent lawsuits, I-Cube found a new customer, another small startup called Cisco. Cisco's routers distributed the backbone of the early internet, and still route most of it.
I realize, decades later, that I made one of the architectural decisions that allows the NSA to watch you as you read this webpage.
Cisco's routers flowed bitstreams, not "packets", a software metaphor for a time-bounded sequence of bits. Packet headers told the router which flow got the bits, the router told the crossbar device which path the bits should take. Sending the bits to more than one place was implicit in how the hardware worked, because the hardware had fanout.
Cisco remains, I-Cube was killed by incompetent venture capitalists. I'm not party to how Cisco designs routers today, but fanout is implicit in dataflow, hardware can stream one transmitter to multiple receivers, tracelessly.
Software is merely "judicial opinion" applied to that hardware, and we non-electrical macroscopic human beings only have opinions, not sure knowledge, about how the bits are actually moving and transforming from memory location to other (possibly multiple) memory locations.
Software can encrypt - or it can pretend to. Software becomes machine instructions via a compiler. Dennis Ritchie taught us that a compiler emits machine instructions chosen by the compiler author, who can override the decisions of the source code author. The hardware author can override both. The hard disk manufacturer decides what firmware bytes go on the boot tracks of your hard drive, the disk firmware decides what bytes you actually get to your RAM from which disk track, and this firmware is invisible to the machine code it dispenses. In an age of Viterbi coding and VLSI disk chips, even a hardware logic analyzer may not tell you what's actually on the boot tracks. For sure knowledge, you will need your own hardware, either your own replacement disk chips or a focused ion beam milling system (FIB) to take apart the disk chips and learn what they actually do.
The economics of chip production make it impossibly expensive to give everyone a different chip architecture, though you can cheaply individualize every chip (another of my inventions, see  ). If there is a ghost in the hardware machine, it is in all the machines, and those versed in VLSI, equipped with FIB, can find the ghosts. The individuality can be perfectly hidden, and cannot be unmasked without destroying the chip.
Puzzling out a proprietary design is possible but time-consuming, perhaps costing as much as the original design. Verifying that an open source hardware design is faithfully replicated in silicon is relatively easy, and could be automated, perhaps as cheap as sequencing a genome. We do not do so, because software designers pretend the substrate does not exist, or is logically identical to all other substrates, and thus not worth controlling or verifying (doctors and pharmaceutical companies share the same pretense).
Open source hardware can also encrypt, and properly-designed hardware can encrypt without fanout (no feasible side channel attacks). If we choose, we can build individual hardware that encrypts each keystroke and decrypts it at each screen, whether the path between is centimeters or megameters. With proper hardware, you can still use Gmail for your mail host, but your messages are gibberish to Google, and to whoever they share the messages with. Google banner ads can be ignored by your decrypter. Google would starve, so they want to make your software and hardware "for free", protecting their product (which is you).
Hardware geeks will still need to re-examine (identical) copies of the hardware from time to time, to make sure the hardware matches specification, and crypto geeks will need to frequently re-examine the specification to make sure it is mathematically correct. And sometimes the hardware will be invalid, and we will need to replace it with new hardware. But a billion transistors costs pennies from Intel, which Amazon can get to you overnight.
Why this matters to Server Sky
Server sky will use far fewer routers. Access to server sky arrays will be trigonometric, agile antenna pointing, not packet routing via DNS and border gateway protocol; if the array is above the horizon and has what you want, you can talk to it directly without intermediaries, and your conversation can be encrypted end-to-end. Of course, each end can have fanout, with either the orbiting array or your ground terminal copying your conversation to your Designated Overlord. Each end can have a fanout of zero, censorship applied by that same (or different) Designated Overlord. No man-in-the-middle attacks when there is only vacuum and Maxwell's equations between sender and receiver. Orbital mechanics, Doppler shift, and twelve-nines-accurate shared clocks provide link authentication that cannot be spoofed without reshaping space-time.
There will be Designated Overlords - in the US, we call the overlords "Google" and "Hollywood", in China the overlords are the Communist Party and/or the People's Liberation Army. People can't seem to live without chains, sigh. But we must design our hardware so the overlords are explicit in the design, few in number, and subject to organized social opinion (which may be more true for China than the US, though I love Google more than the PLA).
This matters because the Server Sky team will make the design decisions now that will shape the hardware for decades, until the next big re-architecting (the last two were the Bell network, and internet protocol). These decisions should be informed by every capable brain on the planet. They should not be made by me, nor by my handful of smart but fallible collaborators. The best minds work elsewhere, and the best minds, if they know what's good for them, will get involved while the future is still conceptual and easy to shape. After launch, we can still replace all the satellites and all the ground terminals and all the end-user gear, but this is costly, and even the best minds don't have the money and persuasiveness to make this happen often. Better to get it approximately right the first time, and make it plug-upgradable.
This webpage is an appeal for help. Bad social design is easy, and regrettably common. Hardware is easy compared to competent social design. I beg you to help design the future you and your descendants will live in. I goofed up once, I would rather not do it again.

@_date: 2014-07-11 12:36:00
@_author: Eugen Leitl 
@_subject: The ultimate goal of the NSA is total population control 
The ultimate goal of the NSA is total population control
At least 80% of all audio calls, not just metadata, are recorded and stored
in the US, says whistleblower William Binney  that's a 'totalitarian
Antony Loewenstein theguardian.com, Friday 11 July 2014 00.54 BST
William Binney testifies before a German inquiry into surveillance.
Photograph: Getty Images
William Binney is one of the highest-level whistleblowers to ever emerge from
the NSA. He was a leading code-breaker against the Soviet Union during the
Cold War but resigned soon after September 11, disgusted by Washingtons move
towards mass surveillance.
On 5 July he spoke at a conference in London organised by the Centre for
Investigative Journalism and revealed the extent of the surveillance programs
unleashed by the Bush and Obama administrations.
At least 80% of fibre-optic cables globally go via the US, Binney said.
This is no accident and allows the US to view all communication coming in.
At least 80% of all audio calls, not just metadata, are recorded and stored
in the US. The NSA lies about what it stores.
The NSA will soon be able to collect 966 exabytes a year, the total of
internet traffic annually. Former Google head Eric Schmidt once argued that
the entire amount of knowledge from the beginning of humankind until 2003
amount to only five exabytes.
Binney, who featured in a 2012 short film by Oscar-nominated US film-maker
Laura Poitras, described a future where surveillance is ubiquitous and
government intrusion unlimited.
The ultimate goal of the NSA is total population control, Binney said, but
Im a little optimistic with some recent Supreme Court decisions, such as law
enforcement mostly now needing a warrant before searching a smartphone.
He praised the revelations and bravery of former NSA contractor Edward
Snowden and told me that he had indirect contact with a number of other NSA
employees who felt disgusted with the agencys work. Theyre keen to speak
out but fear retribution and exile, not unlike Snowden himself, who is likely
to remain there for some time.
Unlike Snowden, Binney didnt take any documents with him when he left the
NSA. He now says that hard evidence of illegal spying would have been
invaluable. The latest Snowden leaks, featured in the Washington Post, detail
private conversations of average Americans with no connection to extremism.
It shows that the NSA is not just pursuing terrorism, as it claims, but
ordinary citizens going about their daily communications. The NSA is
mass-collecting on everyone, Binney said, and its said to be about
terrorism but inside the US it has stopped zero attacks.
The lack of official oversight is one of Binneys key concerns, particularly
of the secret Foreign Intelligence Surveillance Court (Fisa), which is held
out by NSA defenders as a sign of the surveillance scheme's
The Fisa court has only the governments point of view, he argued. There
are no other views for the judges to consider. There have been at least 15-20
trillion constitutional violations for US domestic audiences and you can
double that globally.
A Fisa court in 2010 allowed the NSA to spy on 193 countries around the
world, plus the World Bank, though theres evidence that even the nations the
US isnt supposed to monitor  Five Eyes allies Britain, Canada, Australia
and New Zealand  arent immune from being spied on. Its why encryption is
today so essential to transmit information safely.
Binney recently told the German NSA inquiry committee that his former
employer had a totalitarian mentality that was the "greatest threat" to US
society since that countrys US Civil War in the 19th century. Despite this
remarkable power, Binney still mocked the NSAs failures, including missing
this years Russian intervention in Ukraine and the Islamic States take-over
of Iraq.
The era of mass surveillance has gone from the fringes of public debate to
the mainstream, where it belongs. The Pew Research Centre released a report
this month, Digital Life in 2025, that predicted worsening state control and
censorship, reduced public trust, and increased commercialisation of every
aspect of web culture.
Its not just internet experts warning about the internets colonisation by
state and corporate power. One of Europes leading web creators, Lena Thiele,
presented her stunning series Netwars in London on the threat of cyber
warfare. She showed how easy it is for governments and corporations to
capture our personal information without us even realising.
Thiele said that the US budget for cyber security was US$67 billion in 2013
and will double by 2016. Much of this money is wasted and doesn't protect
online infrastructure. This fact doesnt worry the multinationals making a
killing from the gross exaggeration of fear that permeates the public domain.
Wikileaks understands this reality better than most. Founder Julian Assange
and investigative editor Sarah Harrison both remain in legal limbo. I spent
time with Assange in his current home at the Ecuadorian embassy in London
last week, where he continues to work, release leaks, and fight various legal
battles. He hopes to resolve his predicament soon.
At the Centre for Investigative Journalism conference, Harrison stressed the
importance of journalists who work with technologists to best report the NSA
stories. Its no accident, she said, that some of the best stories on the
NSA are in Germany, where theres technical assistance from people like Jacob
A core Wikileaks belief, she stressed, is releasing all documents in their
entirety, something the group criticised the news site The Intercept for not
doing on a recent story. The full archive should always be published,
Harrison said.
With 8m documents on its website after years of leaking, the importance of
publishing and maintaining source documents for the media, general public and
court cases cant be under-estimated. I see Wikileaks as a library, Assange
said. Were the librarians who cant say no.
With evidence that there could be a second NSA leaker, the time for more
aggressive reporting is now. As Binney said: I call people who are covering
up NSA crimes traitors.

@_date: 2014-07-15 15:38:15
@_author: Eugen Leitl 
@_subject: Experts report potential software "back doors" in U.S. standards 
Experts report potential software "back doors" in U.S. standards
BY JOSEPH MENN
SAN FRANCISCO, July 14 Mon Jul 14, 2014 8:58pm EDT
(Reuters) - U.S. government standards for software may enable spying by the
National Security Agency through widely used coding formulas that should be
jettisoned, some of the country's top independent experts concluded in papers
released on Monday.
Such mathematical formulas, or curves, are an arcane but essential part of
most technology that prevents interception and hacking, and the National
Institute of Standards and Technology (NIST) has been legally required to
consult with the NSA's defensive experts in approving them and other
cryptography standards.
But NIST's relationship with the spy agency came under fire in September
after reports based on documents from former NSA contractor Edward Snowden
pointed to one formula in particular as a Trojan horse for the NSA.
NIST discontinued that formula, called Dual Elliptic Curve, and asked its
external advisory board and a special panel of experts to make
recommendations that were published on Monday alongside more stinging
conclusions by the individual experts.
Noting the partially obscured hand of the NSA in creating Dual Elliptic Curve
- which Reuters reported was most broadly distributed by security firm RSA
[USN:nL2N0JZ1B6] - the group delved into the details of how it and other NIST
standards emerged. It found incomplete documentation and poor explanations in
some cases; in others material was withheld pending legal review.
As a whole, the panels recommended that NIST review its obligation to confer
with the NSA and seek legal changes "where it hinders its ability to
independently develop the best cryptographic standards to serve not only the
United States government but the broader community."
They also urged NIST to weigh the advice of individual task force members who
made more dramatic suggestions, such as calling for the replacement of a
larger set of curves approved for authenticating users, in part because they
were selected through unclear means by the NSA.
"It is possible that the specified curves contain a back door somehow," said
Massachusetts Institute of Technology professor Ron Rivest, a co-founder of
RSA and the source of the letter R in its name. Though the curves could be
fine, he wrote, "it seems prudent to assume the worst and transition away."
More broadly, Rivest wrote, "NIST should ask the NSA for full disclosure
regarding all existing standards... If NSA refuses to answer such an inquiry,
then any standard developed with significant NSA input should be assumed to
be `tainted,'" absent proof of security acceptable to outsiders.
In an email exchange, Rivest told Reuters that "NIST needs to have a process
whereby evidence is publicly presented" about how the curves were chosen.
The curves faulted on Monday had been questioned by outsiders after media
reports in September said the NSA could break much widely used security
software, without detailing which ones or how. "These curves are ubiquitous
in commercial cryptography," Johns Hopkins University professor Matthew Green
said in an interview. "If you connected to Google or Facebook today, you
probably used one."
Rivest's long association with RSA, now part of electronic storage maker EMC
Corp, made his remarks more poignant. But prominent task force colleagues
including Internet co-creator Vint Cerf and Ed Felten, former chief
technologist at Federal Trade Commission, also gave strongly worded verdicts
on the Department of Commerce unit.
"It cannot be accepted that NIST's responsibilities should be co-opted by the
NSA's intelligence mission," wrote Cerf, who now works at Google Inc.
While Rivest called the internal history of Dual Elliptic Curve a "smoking
gun" with an "almost certain" NSA back door, Felten wrote that NSA might not
remain alone in its ability to use it and other possible NIST-approved holes
for spying.
In each of three cases, including Dual Elliptic Curve and the more common
curves faulted by Rivest, Felten said the suspected back door access "reduces
the security of users against attack by other adversaries, including
organized crime groups or foreign intelligence services."
The NSA might have been able to generate curves that pass cursory security
tests but are still breakable through the aid of sheer computing power,
because it can try millions of curves and get a few that fit its goals. But a
researcher working for another country could discover the flaw, Felten said.
In the case of the curves approved under the FIPS 186 standard for
authenticating digital signatures, NIST should start over and pick its own
curves publicly rather than relying on the NSA, Felten and others said.
Several experts said NIST had to hire more cryptographers and strengthen its
internal processes to avoid relying on NSA.
NIST acting Director Willie May agreed in a statement, saying his agency
"must strengthen its in-house cryptography capabilities to ensure we can
reach independent conclusions about the merits of specific algorithms or
NIST did not respond to a Reuters email asking about the fate of the suspect
curves. (Reporting by Joseph Menn; Editing by Ken Wills)

@_date: 2014-07-15 18:31:11
@_author: Eugen Leitl 
@_subject: Rainforest Connection and WildLeaks 
Interesting uses of old mobile phones
(I'm sure you'll how this be made applicable in
other contexts (say, urban environment) and with other modifications).
One group hopes to end poaching, WikiLeaks-style

@_date: 2014-07-17 15:09:14
@_author: Eugen Leitl 
@_subject: the NSA revelations all in one chart 
The NSA Revelations All in One Chart
This is a plot of the NSA programs revealed in the past year according to
whether they are bulk or targeted, and whether the targets of surveillance
are foreign or domestic. Most of the programs fall squarely into the agencys
stated mission of foreign surveillance, but some  particularly those that
are both domestic and broad-sweeping  are more controversial.
Just as with the New York Magazine approval matrix that served as our
inspiration, the placement of each program is based on judgments and is
For more details, read our FAQ or listen to our podcast. Also, take our quiz
to test your NSA knowledge.

@_date: 2014-07-17 18:54:26
@_author: Eugen Leitl 
@_subject: Leaked GCHQ catalog of exploit tools for manipulation and mass 
Liberation Technologies Leaked GCHQ catalog of exploit tools for manipulation and mass surveillance
By Darlene Storm
July 16, 2014 1:22 PM EDTAdd a comment
Just as civil liberties groups challenge the legality of the UK intelligence
agencys mass surveillance programs, a catalog of exploit tools for
monitoring and manipulation is leaked online.
The Joint Threat Research Intelligence Group (JTRIG), a department within the
Government Communications Headquarters (GCHQ), develops the majority of
effects capabilities for UKs NSA-flavored intelligence agency. First Look
Media first published the Snowden-leaked Wikipedia-like document full of
covert tools used by GCHQ for surveillance and propaganda. JTRIG tools and
techniques help British spies seed the internet with false information,
including the ability to manipulate the results of online polls, monitor
social media posts, and launch attacks ranging from denial of service, to
call bombing phones, to disabling users' accounts on PCs.
Devils Handshake, Dirty Devil, Reaper and Poison Arrow are but a few
vicious-sounding JTRIG system tools, but the naming convention for others are
just inane like Bumblebee Dance, Techno Viking and Jazz Fusion. Perhaps the
British spies were hungry when coming up with Fruit Bowl, Spice Island, Nut
Allergy, and Berry Twister?  Most of the tools are "fully operational, tested and reliable, according to
the 2012 JTRIG Manual, but "Don't treat this like a catalog. If you don't see
it here, it doesn't mean we can't build it." Like the previously leaked TAO
exploits, its an eye-opener as to exploits that GCHQ can deploy.
GCHQ spy tools, techniques and exploits in JTRIG manual
Some of the especially invasive tools that are either ready to fire or very
close to being ready include:
long and when the effect is active.
material online.
files on a targets machine.
info, files, logs, etc and posts it back to GCHQ.
elicit a targets IP address.
       Tornado Alley is a delivery system aimed at Microsoft Excel "to
silently extract and run an executable on a target's machine."
address and send email under that identity.
ringing them. Target does not need to answer. Denial of Service:
services. Other JTRIG exploits include Screaming Eagle, a tool that
processes Kismet data into geolocation information and Chinese Firecracker
for overt brute login attempts against online forums. Hacienda is a port
scanning tool designed to scan an entire country or city before identifying
IP locations and adding them to an Earthling database.
Messing with cellphones:
telephones, or repeatedly bomb a target number with the same message.
phone to aid geolocation.
via call bombing.
BlackBerry targets.
allows us to pull back cell tower and Wi-Fi locations targeted against
particular areas. Vipers Tongue is another denial of service tool but its
aimed at satellite or GSM phone calls.  Manipulation and propaganda
Bomb Bay can increase website hits/rankings. Gateway can artificially
increase traffic to a website; Slipstream can inflate page views on
websites. Underpass can change the outcome of online polls. Badger can
mass deliver email messages to support an Information Operations campaign.
Gestator can amplify a given message, normally video, on popular multimedia
websites like YouTube. The production and dissemination of multimedia via
the web in the course of information operations can be accomplished with
Skyscraper. There are also various tools to censor or report extremist
Online surveillance of social networks
Godfather collects public data from Facebook. While Spring Bishop finds
private photos of targets on Facebook, Reservoir allows the collection of
various Facebook information. Clean Sweep can masquerade Facebook wall posts
for individuals or entire countries.
Birdstrike monitors and collects Twitter profiles. Dragons Snout collects
Paltalk group chats. Airwolf collects YouTube videos, comments and profiles.
Bugsy collects users info off Google+. Fatyak is about collecting data from
LinkedIn. Goodfella is a generic framework to collect public data from
online social networks. Elate monitors a target's use of UK's eBay. Mouth
finds, collects and downloads a users files from achive.org. Photon Torpedo
can actively grab the IP address of an MSN messenger user. Pitbull is aimed
at large scale delivery of tailored messages to IM services.
Miniature Hero is about exploiting Skype. The description states, Active
Skype capability. Provision of real time call records (SkypeOut and
SkypetoSkype) and bidirectional instant messaging. Also contact lists.
If thats not enough mass-scale surveillance and manipulation to irk you,
there are more weaponized tricks and techniques in the JTRIG Manual.

@_date: 2014-07-18 12:24:15
@_author: Eugen Leitl 
@_subject: interesting thread on BND intercept at DE-CIX on denog@ 
The netops are not amused.
You need to be a list member in order to access the archive.

@_date: 2014-07-21 14:03:08
@_author: Eugen Leitl 
@_subject: Huge collection of Security Data Science papers 
(looks useful)
 Over the past several years I have collected and read many security research papers/slides and have started a small catalog of sorts. The topics of these papers range from intrusion detection, anomaly detection, machine learning/data mining, Internet scale data collection, malware analysis, and intrusion/breach reports. I figured this collection might useful to others. All links lead to PDFs hosted here.
I hope to clean this up (add author info, date, and publication) when I get some more time as well as adding some detailed notes I have on the various features, models, algorithms, and datasets used in many of these papers.
Here are some of my favorites (nice uses of machine learning, graph analytics, and/or anomaly detection to solve interesting security problems):
CAMP - Content Agnostic Malware Protection
Notos - Building a Dynamic Reputation System for DNS
Kopis - Detecting malware domains at the upper dns hierarchy
Pleiades - From Throw-away Traffic To Bots - Detecting The Rise Of DGA-based Malware
EXPOSURE - Finding Malicious Domains Using Passive DNS Analysis
Polonium - Tera-Scale Graph Mining for Malware Detection
Nazca - Detecting Malware Distribution in Large-Scale Networks
PAYL - Anomalous Payload-based Network Intrusion Detection
Anagram - A Content Anomaly Detector Resistant to Mimicry Attack
Here is the entire collection:
Intrusion Detection
A Close Look on n-Grams in Intrusion Detection- Anomaly Detection vs. Classication
A Kill Chain Analysis of the 2013 Target Data Breach
A Lone Wolf No More - Supporting Network Intrusion Detection with Real-Time Intelligence
A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks
Acquiring Digital Evidence from Botnet Attacks: Procedures and Methods (PhD Thesis)
ALERT-ID - Analyze Logs of the network Element in Real Time for Intrusion Detection
Anagram - A Content Anomaly Detector Resistant to Mimicry Attack
Anomaly-based Intrusion Detection in Software as a Service
Back to Basics - Beyond Network Hygiene
Beehive - Large-Scale Log Analysis for Detecting Suspicious Activity in Enterprise Networks
Behavioral Clustering of HTTP-based Malware and Signature Generation Using Malicious Network Traces
Beheading Hydras - Performing Effective Botnet Takedowns
Bloodhound - Searching Out Malicious Input in Network Flows for Automatic Repair Validation
Boosting the Scalability of Botnet Detection Using Adaptive Traffic Sampling
CAMP - Content Agnostic Malware Protection
Casting out demons - Sanitizing training data for anomaly sensors
CloudFence - Data Flow Tracking as a Cloud Service
Comparing anomaly detection techniques for HTTP
Cujo - Efficient detection and prevention of drive-by-download attacks
Decoy Document Deployment for Effective Masquerade Attack Detection
Detecting Spammers with SNARE - Spatio-temporal Network-level Automatic Reputation Engine
Detecting Unknown Network Attacks Using Language Models
Early Detection of Malicious Flux Networks via Large-Scale Passive DNS Traffic Analysis
Effective Anomaly Detection with Scarce Training Data
Efficient Multidimensional Aggregation for Large Scale Monitoring
EFFORT - Efficient and Effective Bot Malware Detection
ExecScent- Mining for New C and C Domains in Live Networks with Adaptive Control Protocol Templates - slides
ExecScent- Mining for New C and C Domains in Live Networks with Adaptive Control Protocol Templates
EXPOSURE - Finding Malicious Domains Using Passive DNS Analysis
FiG - Automatic Fingerprint Generation
Filtering Spam with Behavioral Blacklisting
FLIPS - Hybrid Adaptive Intrusion Prevention
HMMPayl - An Intrusion Detection System Based on Hidden Markov Models
Kopis - Detecting malware domains at the upper dns hierarchy
Large-Scale Malware Analysis, Detection, and Signature Generation
Leveraging Honest Users - Stealth Command-and-Control of Botnets - slides
Leveraging Honest Users - Stealth Command-and-Control of Botnets
Local System Security via SSHD Instrumentation
Machine Learning In Adversarial Environments
Malware vs. Big Data (Umbrella Labs)
McPAD - A Multiple Classifier System for Accurate Payload-based Anomaly Detection
Measuring and Detecting Malware Downloads in Live Network Traffic
Mining Botnet Sink Holes - slides
MISHIMA - Multilateration of Internet hosts hidden using malicious fast-ux agents
Monitoring the Initial DNS Behavior of Malicious Domains
N-Gram against the Machine - On the Feasibility of the N-Gram Network Analysis for Binary Protocols
Nazca - Detecting Malware Distribution in Large-Scale Networks
Netgator - Malware Detection Using Program Interactive Challenges - slides
Network Traffic Characterization Using (p, n)-grams Packet Representation
Notos - Building a Dynamic Reputation System for DNS
On the Feasibility of Online Malware Detection with Performance Counters
On the Infeasibility of Modeling Polymorphic Shellcode
On the Mismanagement and Maliciousness of Networks
Outside the Closed World - On Using Machine Learning For Network Intrusion Detection
PAYL - Anomalous Payload-based Network Intrusion Detection
PAYL2 - Anomalous Payload-based Worm Detection and Signature Generation
Pleiades - From Throw-away Traffic To Bots - Detecting The Rise Of DGA-based Malware
Practical Comprehensive Bounds on Surreptitious Communication Over DNS - slides
Practical Comprehensive Bounds on Surreptitious Communication Over DNS
Privacy-preserving Payload-based Correlation for Accurate Malicious Traffic Detection
Revealing Botnet Membership Using DNSBL Counter-Intelligence
Revolver - An Automated Approach to the Detection of Evasive Web-based Malware
Self-organized Collaboration of Distributed IDS Sensors
SinkMiner- Mining Botnet Sinkholes for Fun and Profit
Spamming Botnets - Signatures and Characteristics
Spectrogram - A Mixture of Markov Chain models for Anomaly Detection in Web Traffic
The Security of Machine Learning
Toward Stealthy Malware Detection
Traffic Aggregation for Malware Detection
Understanding the Domain Registration Behavior of Spammers
Understanding the Network-Level Behavior of Spammers
VAST- Network Visibility Across Space and Time
A static, packer-agnostic filter to detect similar malware samples
A study of malcode-bearing documents
A survey on automated dynamic malware-analysis techniques and tools
APT1 Technical backstage (malware.lu hack backs of APT1 servers)
Automatic Analysis of Malware Behavior using Machine Learning
BitShred - Fast, Scalable Code Reuse Detection in Binary Code
BitShred - Fast, Scalable Malware Triage
Deobfuscating Embedded Malware using Probable-Plaintext Attacks
Escape from Monkey Island - Evading High-Interaction Honeyclients
Eureka - A framework for enabling static malware analysis
Extraction of Statistically Significant Malware Behaviors
Fast Automated Unpacking and Classification of Malware
FIRMA - Malware Clustering and Network Signature Generation with Mixed Network Behaviors
FuncTracker - Discovering Shared Code (to aid malware forensics) - slides
FuncTracker - Discovering Shared Code to Aid Malware Forensics Extended Abstract
Malware files clustering based on file geometry and visualization using R language
Mobile Malware Detection Based on Energy Fingerprints  A Dead End
Polonium - Tera-Scale Graph Mining for Malware Detection
Putting out a HIT - Crowdsourcing Malware Installs
Scalable Fine-grained Behavioral Clustering of HTTP-based Malware
SigMal - A Static Signal Processing Based Malware Triage
Tracking Memory Writes for Malware Classification and Code Reuse Identification
Using File Relationships in Malware Classification
VAMO - Towards a Fully Automated Malware Clustering Validity Analysis
Data Collection
Crawling BitTorrent DHTs for Fun and Prot
CyberProbe - Towards Internet-Scale Active Detection of Malicious Servers
Demystifying service discovery - Implementing an internet-wide scanner
gitDigger - Creating useful wordlists from GitHub
PoisonAmplifier - A Guided Approach of Discovering Compromised Websites through Reversing Search Poisoning Attacks
ZMap - Fast Internet-Wide Scanning and its Security Applications (slides)
ZMap - Fast Internet-Wide Scanning and its Security Applications
Vulnerability Analysis/Reversing
A Preliminary Analysis of Vulnerability Scores for Attacks in Wild
Attacker Economics for Internet-scale Vulnerability Risk Assessment
Detecting Logic Vulnerabilities in E-Commerce Applications
ReDeBug - Finding Unpatched Code Clones in Entire OS Distributions
The Classification of Valuable Data in an Assumption of Breach Paradigm
Toward Black-Box Detection of Logic Flaws in Web Applications
Vulnerability Extrapolation - Assisted Discovery of Vulnerabilities using Machine Learning - slides
Vulnerability Extrapolation - Assisted Discovery of Vulnerabilities using Machine Learning
Anonymous Hacking Group   Super Secret Security Handbook
Detecting Traffic Snooping in Tor Using Decoys
Risks and Realization of HTTPS Traffic Analysis
Selling Off Privacy at Auction
The Sniper Attack - Anonymously Deanonymizing and Disabling the Tor Network
The Velocity of Censorship - High-Fidelity Detection of Microblog Post Deletions - slides
The Velocity of Censorship - High-Fidelity Detection of Microblog Post Deletions
Tor vs. NSA
Data Mining
An Exploration of Geolocation and Traffic Visualization Using Network Flows to Aid in Cyber Defense
DSpin - Detecting Automatically Spun Content on the Web
Gyrus - A Framework for User-Intent Monitoring of Text-Based Networked Applications
Indexing Million of Packets per Second using GPUs
Multi-Label Learning with Millions of Labels - Recommending Advertiser Bid Phrases for Web Pages
Real-Time Handling of Network Monitoring Data Using a Data-Intensive Framework
Shingled Graph Disassembly - Finding the Undecideable Path
Synoptic Graphlet - Bridging the Gap between Supervised and Unsupervised Profiling of Host-level Network Traffic
Cyber Crime
Connected Colors - Unveiling the Structure of Criminal Networks
Image Matching for Branding Phishing Kit Images - slides
Image Matching for Branding Phishing Kit Images
Inside a Targeted Point-of-Sale Data Breach
Investigating Advanced Persistent Threat 1 (APT1)
Measuring pay-per-install - the Commoditization of Malware Distribution
Scambaiter - Understanding Targeted Nigerian Scams on Craigslist
Sherlock Holmes and the Case of the Advanced Persistent Threat
The Role of the Underground Market in Twitter Spam and Abuse
The Tangled Web of Password Reuse
Trafcking Fraudulent Accounts - The Role of the Underground Market in Twitter Spam and Abuse
Amplication Hell - Revisiting Network Protocols for DDoS Abuse
Defending The Enterprise, the Russian Way
Protecting a Moving Target - Addressing Web Application Concept Drift
Timing of Cyber Conflict
Jason SECURITYDATA SCIENCERES

@_date: 2014-07-21 16:31:35
@_author: Eugen Leitl 
@_subject: potential leak on Torpedo 
Please read if you use/depend on Tor. Never before seen FH information.
submitted 16 hours ago * by Deepthroat2 [+1]
Hello everyone, I have some information that I have been dying to share for
months, but due to the circumstances, and to avoid detection, I had to wait
for some time before I was able to safely make this post. My goal here is to
provide information that I know is credible and for the Tor community to use
it as they see fit, due to the nature of my work, and the severe penalties
associated with breaking the rules and giving out information you aren't
supposed too, I have no way of verifying or proving anything to you that I
say here, I understand if find me less than credible, however, this is
essentially a PSA, and you can take it for what it's worth to you.
Just about one year ago, the Tor community was shaken by a Firefox exploit
which utilized a javascript exploit and an old vulnerbility in the Tor
Browser Bundle to unmask some users of Freedom Hosting. There has been
rampant misinformation, and speculation to the point that I felt like pulling
my hair out, or just simply bursting out into laughter when reading some of
the outlandish claims made by people who have little to no idea what they are
talking about. Today, I will set the record straight.
The FH exploit was a government engineered, and deployed exploit that was
designed in response to former Director Mueller's fustration at an earlier
child pornography case in which the FBI was ridiculed for being unable to
ascertain the source of child pornography, for those who aren't familiar with
this case, it involved a man who had accessed child pornography by accident
on a Tor hidden service, and then brought his desktop computer to the office,
explaining what had happened and that he subsequently preformed a "Full wipe"
on the disk.
The agent who took the report had limited knowledge about Tor, however, at
the time he knew that any directed effort to identify a specific Tor user was
hopeless, and in the report he indicated that "There is currently no known
way to ascertain the location of a Tor user, thus, no investigative leads
exsist." This got leaked to the press, and they had a field day, hinting at
the incompetency of the Bureau. Needless to say, the FBI had it's ego hurt
quite badly by this public display of incompetency.
Then Director Mueller directed the CEOS (Child exploitation and obscenity
section) to find a way to penetrate the layers of protection provided by Tor,
and to come up with a fesible way to conduct a sting operation in order to
bring these people to justice. The FBI had previously conducted a sting on
viewers of child pornography in a case out of Nebraska, that resulted in the
arrest of about 25 people. This was the first successful take down of CP
consumers that were utilizing a Tor hidden service.
One of the errors that I see alot on these forums and others was that the
Nebraska take down was done in a similar fashion to the FH exploit, with the
code being deployed onto the pages of the boards, however, this is not the
case. From my understanding, the Nebraska field office was able to find the
actual server, take it over covertly, then upload a series of files that
purported to be child pornography, but actually contained nothing but
encrypted gibberish. They were video files that were embedded with code that
called back to a computer that recorded the IP address of the requestor, date
and time similar to the way windows media player attempts to recall album
information and cover art for music cds and such. These were files that the
user actually had to download and attempt to open. This is why the service
was run for weeks, and only 25 people were identified as users. This method
was described by the techs who deployed it as a "NIT" or "Network
Investigational Tool".
Now for Freedom Hosting....
The javascript exploit could not be deployed directly on the servers which
Mr. Marques was using due to either technical reasons, or legal requirements
by the AUSA in Maryland. So the decision was made to clone the services
exactly, and transport then to the home of the FBI CEOS in the Greenbelt
division of Maryland. This location was picked specifically because
sentencing in this district for Child Pornography crimes is more severe. It
was July 31st of 2013 when the exploit actually went live, and tried to
identify criminals. It was installed previously, however, there were
technical problems early on and the code had to be revised 3 times before it
was running as intended, it ran for about 11 days before being shut down.
The amount of people identified by this exploit is still a closely gaurded
secret, with only agents having a direct "Need to know" being privy to this
information. Howver, the victory dance was short lived as news started
flowing around that the evidence may not be admissible in court, due to the
manner in which it was collected, among other reasons. Although proper
warrants were issued, it would take atleast 4-7 years to comb through the
list of suspects, and question, arrest each one. The major problem is that
after about 12 months, the courts start to presume your evidence is
prejudicial to the defendant because you're supposed to have an indictment
and serve it on the defendant within 30 days, and that just wasn't possible.
You can request an extension of this time, however you must present a new,
fresh reason for doing so..."We still aren't ready" doesn't cut it. There is
no statue of limitations for the crime of "Accessing with intent to view
child pornography" so barring any other limitations, the FBI can come after
someone 10-15 years later.
The AUSA became uncomfortable with the prospects of his legal case against
the exploitees of FH and went to the US Attorney. There was disagreement as
to whether or not the evidence would be viable, however, the operation went
on anyways. One of the victims of the FH exploit was a man by the name of
Grant Klein from Vermont. The Bureau had made arrangements with the local
police for assistance with the raid (This is pretty much standard operation
procedure, and is done for the saftey of the agents, as well as to maintain
professional courtesy. Local cops get butt hurt when you arrest people on
their turf without them knowing).
The FBI had provided the local police with court documents and the affidavit
of arrest regarding the cirsumstances of Mr. Klein's warrant, which they
promptly posted onto their press release against the wishes of the FBI. This
resulted in the termination of atleast one employee from local PD.
He was raided and before even being asked a question ,he began spewing a
confession. His home was searched, and a desktop computer with no hard disk
was found, as well a laptop computer belonging to his wife Susan. There was
no illegal materials found on these, however, he had a smartphone in the
drawer of a nightstand which contained illegal images of minors. He was
arrested and charged with 3 seperate crimes.
To make a long story short, the FH related charges were dropped because the
FBI had crossed a legal line by offering up child pornography de novo, by
shutting down the server, then bringing it back online hosting real CP. They
were uncomfortable with the prospects of this case, and were able to use a
leon good faith exception to admit the evidence they found on his phone to
make a single possession charge stick, however, he agreed to plead guilty.
The rest of the leads which lead to foreign nationals were then distributed
accordingly to the various LEA's.
Also, earlier this wekk, the UK police arrested 660 people as part of
Operation Notarise.
The operation name of the FBI takedown in Nebraska was "Operation Torpedo"
This was a cute poke at both the method they used, and the users they
Torpedo - Navy missile
Tor Pedo - Tor Pedophile.
moar comments on Reddit

@_date: 2014-07-22 13:45:36
@_author: Eugen Leitl 
@_subject: HackRF will likely start shipping in August 
(the tinfoilhatterati will understand and rejoice)
HackRF One is now available for pre-order From: HakShop (US)
NooElec (US/CA)
Hacker Warehouse (US)
Ada's Technical Books (US)
Wall of Sheep (US)
Store4Geeks (SE)
Passion Radio Shop (FR)
Passion Radio Shop UK (UK)
TAPR (US)
iSource Asia (CN)
WiMo (DE)
Pre-ordered units will ship immediately after all rewards have shipped to Kickstarter backers, estimated July 2014. For the latest information on development and manufacturing, follow the Kickstarter updates.

@_date: 2014-07-23 12:13:28
@_author: Eugen Leitl 
@_subject: Gruveo, more secure skype alternative? 
RetroShare has quite good P2P audio. It's not properly audited though,
caveat emptor.

@_date: 2014-07-23 14:22:36
@_author: Eugen Leitl 
@_subject: Tor developers vow to fix bug that can uncloak users 
Tor developers vow to fix bug that can uncloak users
Weakness was topic of talk abruptly pulled from security conference.
by Dan Goodin - July 22 2014, 8:15pm CEST
Developers of the Tor privacy service say they're close to fixing a weakness
that researchers for an abruptly canceled conference presentation said
provides a low-cost way for adversaries to deanonymize hundreds of thousands
of users.
The talk previously scheduled for next month's Black Hat security conference
in Las Vegas was titled "You Don't Have to be the NSA to Break Tor:
Deanonymizing Users on a Budget." The abstract said that the hack cost less
than $3,000 and could uncloak hundreds of thousands of users. On Monday,
Black Hat organizers said the presentation was canceled at the request of
attorneys from Carnegie Mellon University (CMU), where the researchers were
employed, as well as the Software Engineering Institute (SEI). The attorneys
said only that the materials to be presented "have not yet been approved by
CMU/SEI for public release." Researchers Alexander Volynkin and Michael
McCord have yet to explain why their talk was pulled.
Tor officials responded by saying that they're working on an update for
individual Tor relay nodes that will close the unspecified security hole.
"Based on our current plans, we'll be putting out a fix that relays can apply
that should close the particular bug they found," Tor project leader Roger
Dingledine wrote in an e-mail to Tor users. "The bug is a nice bug, but it
isn't the end of the world. And of course these things are never as simple as
'close that one bug and you're 100% safe.'"
He said the fix was complicated because the researchers didn't provide all
the technical details when privately informing Tor officials of the
"We've been trying to find delicate ways to explain that we think we know
what they did, but also it sure would have been smoother if they'd opted to
tell us everything," he wrote. "The main reason for trying to be delicate is
that I don't want to discourage future researchers from telling us about neat
things that they find. I'm currently waiting for them to answer their mail so
I can proceed."
In a previous e-mail, Dingledine said Tor developers "informally" received
some materials related to the vulnerability. He went on to say Tor officials
played no role in the cancellation of the Black Hat talk.
"We did not ask Black Hat or CERT to cancel the talk. We did (and still do)
have questions for the presenter and for CERT about some aspects of the
research, but we had no idea the talk would be pulled before the announcement
was made," he wrote.
CMU is affiliated with CERT, which coordinates security disclosures between
researchers and affected parties. A CMU spokesman contacted Monday didn't
elaborate on the reasons for pulling the talk.

@_date: 2014-07-24 16:04:24
@_author: Eugen Leitl 
@_subject: Tails vulnerability specific to I2P, not Tor 
SILVER BULLETS AND FAIRY TAILS
This week we made mention on Twitter of a zero-day vulnerability weve unearthed that affects the popular Tails operating system. As the Tails website states:
Tails is a live operating system, that you can start on almost any computer from a DVD, USB stick, or SD card. It aims at preserving your privacy and anonymity, and helps you to:
use the Internet anonymously and circumvent censorship;
all connections to the Internet are forced to go through the Tor network;
leave no trace on the computer you are using unless you ask it explicitly;
use state-of-the-art cryptographic tools to encrypt your files, emails and instant messaging.
This software was largely popularized due to the fact that it was used by whistleblower Edward Snowden. Since then, the OS has garnered much attention and use by a wide range of those seeking anonymity on the Internet.
We publicized the fact that weve discovered these issues for a very simple reason: no user should put full trust into any particular security solution. By bringing to light the fact that we have found verifiable flaws in such a widely trusted piece of code, we hope to remind the Tails userbase that no software is infallible. Even when the issues weve found are fixed by the Tails team, the community should keep in mind that there are most certainly other flaws still present and likely known to others.
Our customers use our information for both offensive and defensive purposes to better protect themselves and others. Providing a wide variety of exploit software we help penetration testers effectively test network security and incident response teams. One high profile example occurred last year when Facebook used a zero-day vulnerability to test their teams response to a zero-day attack. The information we provide is also leveraged in defensive purposes providing companies with well documented research for use in IDS and AV signatures for previously unknown threats. We at Exodus are able to do what many software projects cannot, perform security code audits and find exploitable vulnerabilities releasing them to the public.
The Vulnerable Component
The vulnerability we will be disclosing is specific to I2P. I2P currently boasts about 30,000 active peers. Since I2P has been bundled with Tails since version 0.7, Tails is by far the most widely adopted I2P usage. The I2P vulnerability works on default, fully patched installation of Tails. No settings or configurations need to be changed for the exploit to work. I2P is preconfigured so that all .i2p TLD sites are routed through the I2P network. At a high level I2P traffic is message based similar to IP packets. All communication is encrypted end to end with a total of four layers of encryption. I2P routers (end points) act as cryptographic identifiers, similar to a pair of public keys. I2P is a packet switched network, instead of circuit switched like Tor. This means transparent load balancing of packets across multiple peers. I2P is fully distributed with no centralized resources. There is no distinct separation of servers to nodes, this architecture helps eliminate single points of failure.
To lend credence to our claims we have created a video that demonstrates de-anonymizing a Tails user:
0:00:00,000 > 0:00:10,400: Demonstrating IP on listening server, Turning on listening server
0:00:19,000 > 0:00:25,400: Tails user visiting website icanhazip.com which shows the anonymized IP address
0:00:36,000 > 0:00:49,400: Showing that were indeed using the latest Tails build 1.1
0:00:50,000 > 0:01:03,400: I2P address being resolved, proof of concept malicious payload being delivered
0:01:30,000 > 0:01:40,400: Listening server retrieves the Tails users de-anonymized IP address (Austin RoadRunner ISP)
Note on Disclosure
Disclosure of vulnerabilities takes many forms, particularly their shape is adapted to the landscape that the platform is used upon. In the past at Exodus Intelligence, weve felt that significant vulnerabilities have been disregarded and have not had the requisite exposure. Through appropriate airing of the issue, we feel that users of such security platforms may come to understand the risks in base-level trust. Even further we hope to break the mold of unconditional trust in a platform. Users should question the tools they use, they should go even further to understand the underlying mechanisms that interlock to grant them security. Its not enough to have faith upon security, rather to have an understanding of it. If the public thinks Exodus is one of a few entities finding bugs in software, they are grossly misinformed. As is the case with all vulnerabilities we report to vendors, we do not ask for any remuneration. All flaws that we give to vendors are given free of charge. All accusations of extortion perpetuated by those unfamiliar with our business model are completely unfounded. As of publication of this blog post the Tails team and the I2P team have both received all the relevant details and exploit code they require to remediate the vulnerabilities weve discovered.
Recently a high profile talk on de-anonymization Tor users was pulled from Blackhat due to legal issues. Their talk outlined with a budget of $3000 with some powerful servers and multiple gigabit links they were able to de-anonymize hundreds of thousands of users in a couple of months. Exodus decided to pick up where this talk left off by letting the community know that there are many other vectors for de-anonymization. The vulnerability we have found is able to perform remote code execution with a specially crafted payload. This payload can be customized to unmask a user and show the public IP address in which the user connected from within a couple of seconds.
Stay Tuned
Part two of this blog post will present a technical discussion of the vulnerability. This will be posted once we have confirmed the vulnerabilities in I2P are patched and have been incorporated into Tails.

@_date: 2014-07-28 18:20:42
@_author: Eugen Leitl 
@_subject: Alleged "microkernel mathematically proven to be bug free" 
I'm on their announcement list. Good news, question is who's going to
pick it up and build a distro around that. Anyone here use Qubes OS?

@_date: 2014-07-02 18:41:25
@_author: Eugen Leitl 
@_subject: Court =?utf-8?B?4oCTIE9mZmljaWE=?= =?utf-8?Q?l?= statement part #1 
Apologies, not sure this has been posted already in the thread, I'm
 Court  Official statement part Posted on July 2, 2014 by Will
As seen possibly here, or here i lost the Tor case and was sentenced to 3
years probation (instead of 3 months jail) and all fees (court and experts,
Assumption ~30000EUR, not less than 20k for sure).
The sentence is based on 12 which allows for anyone to be dealt with as
perpetrator (which is a pretty dictatorial law IMO) and this is based on that
i knew it *could* possibly be used for criminal activity (in this case child
I wont write much more yet before i have the written ruling (i do not even
know my probation terms yet) but merely want to explain why i wont appeal
this sentence:
First would be that I simply cant afford it anymore, donations covered a lot
of lawyer fees but i had to use my entire money on this case as well, im now
bankrupt and the garnishment (a rare word, DE: Pfndung) of my income (to pay
the 20k+ costs) does not help with it either. I have high medical costs as
well besides which are more important. Im not really interested in more
external funding due to taxation issues with larger amounts (and i do not
want *another* crime on me).   Second is that i just want to be done with
this, i had now years of issues (i would write harassment but then i get
sued again for sure) (Ex: Citing my boss to the police for questioning (x3);
physically monitoring my boss in Vienna; citing friends to the police for
questioning (x2); confiscation of bank transaction data; Polish extradiction
threats for hacking cases there (x2); citing me for useless questioning
causing lawyer costs (x5+) etc. etc.)  Its now finally over and besides the
cost i CAN live with this sentence, it does not show up in police registers
and wont be an issue for work and alike in the future.   Third is the
mental component, this years of horror changed a lot up to me being
hospitalized (x3) with paranoid schizophrenia (which was a wrong diagnosis,
but still its not helpful if you HAVE to assume permanent monitoring of
everything), PTSD (among other issues) and now taking medication  It took
its toll, including me getting fired for being in the clinic/sick stay for a
long time, i just cant afford to loose my job or go the clinic again even if
i actually should be still there.   Fourth is the attention, media and
personal  I dont really like any attention on myself, especially when
others should get it (like some public cause, Pirateparty or alike).  
So this is it for now, stay tuned for more in a few days.

@_date: 2014-07-03 10:38:16
@_author: Eugen Leitl 
@_subject: REVERSE ENGINEERING NSA SPY =?utf-8?B?4oCY?= 
REVERSE ENGINEERING NSA SPY RETRO REFLECTOR GADGETS WITH THE HACKRF
In 2013 whistleblower Edward Snowden leaked (along with other documents) some
information about the American National Security Agencies (NSA) spy tools.
One such group of tools named retro reflectors has recently been
investigated and reverse engineered by Micheal Ossmann, the security
researcher behind the recently available for preorder HackRF software defined
radio. The HackRF is a SDR similar to the RTL-SDR, but with better
performance and transmit capabilities.
Newscientist Magazine has written an article about Ossmanns work here. From
their article a retro reflectors are described in the following quote.
One reflector, which the NSA called Ragemaster, can be fixed to a computers
monitor cable to pick up on-screen images. Another, Surlyspawn, sits on the
keyboard cable and harvests keystrokes. After a lot of trial and error,
Ossmann found these bugs can be remarkably simple devices  little more than
a tiny transistor and a 2-centimetre-long wire acting as an antenna.
The HackRF comes in to play in the following quote
Ossmann found that using the radio [HackRF] to emit a high-power radar signal
causes a reflector to wirelessly transmit the data from keystrokes, say, to
an attacker. The set-up is akin to a large-scale RFID- chip system. Since the
signals returned from the reflectors are noisy and often scattered across
different bands, SDRs versatility is handy, says Robin Heydon at Cambridge
Silicon Radio in the UK.
Ossmann will present his work at this years Defcon conference in August.

@_date: 2014-07-03 14:46:48
@_author: Eugen Leitl 
@_subject: XKeyscore-Quellcode: more english details requested 
According to fefe who's seen the source it's just a selector

@_date: 2014-07-03 15:16:13
@_author: Eugen Leitl 
@_subject: tools used by intelligence analysts 
*ORA for network analysis Pentaho for data transformation Rapid Miner for data mining Orange for data visualisations and analysis Maltego for the analysis of networks between people, companies, websites, etc. Apache Hadoop for large-scale, distributed computing and analysis
Axis Pro Starlight Analyst's Notebook Palantir XPLR witk Reddit plugin Tiny Tiny Rss Pligg Twitter, Reddit, ...
ARC GIS
CPOF Oryon  (?)
Investigative Dashboard  (?)

@_date: 2014-07-03 17:29:47
@_author: Eugen Leitl 
@_subject: NSA targets the privacy-conscious 
NSA targets the privacy-conscious
von J. Appelbaum, A. Gibson, J. Goetz, V. Kabisch, L. Kampf, L. Ryge
The investigation discloses the following:
Two servers in Germany - in Berlin and Nuremberg - are under surveillance by
the NSA.
Merely searching the web for the privacy-enhancing software tools outlined in
the XKeyscore rules causes the NSA to mark and track the IP address of the
person doing the search. Not only are German privacy software users tracked,
but the source code shows that privacy software users worldwide are tracked
by the NSA.
Among the NSA's targets is the Tor network funded primarily by the US
government to aid democracy advocates in authoritarian states.
 The XKeyscore rules reveal that the NSA tracks all connections to a server
that hosts part of an anonymous email service at the MIT Computer Science and
Artificial Intelligence Laboratory (CSAIL) in Cambridge, Massachusetts. It
also records details about visits to a popular internet journal for Linux
operating system users called "the Linux Journal - the Original Magazine of
the Linux Community", and calls it an "extremist forum".
Three authors of this investigation have personal and professional ties to
the Tor Project, an American company mentioned within the following
investigation. Jacob Appelbaum is a paid employee of the Tor Project, Aaron
Gibson is a paid contractor for the Tor Project, and Leif Ryge is a volunteer
contributor to various Tor-related software projects. Their research in this
story is wholly independent from the Tor Project and does not reflect the
views of the Tor Project in any way. During the course of the investigation,
it was further discovered that an additional computer system run by Jacob
Appelbaum for his volunteer work with helping to run part of the Tor network
was targeted by the NSA. Moreover, all members of this team are Tor users and
appear to be have been targets of the mass surveillance described in the
It is a small server that looks like any of the other dozens in the same row.
It is in a large room devoted to computers and computer storage, just like
every other room in this industrial park building on Am Tower Street just
outside the city of Nuremberg. That the grey building is surrounded by barbed
wire seems to indicate that the servers' provider is working hard to secure
their customers' data.
Yet despite these efforts, one of the servers is targeted by the NSA.
The IP address 212.212.245.170 is explicitly specified in the rules of the
powerful and invasive spy software program XKeyscore. The code is published
here exclusively for the first time.
After a year of NSA revelations based on documents that focus on program
names and high-level Powerpoint presentations, NDR and WDR are revealing NSA
source code that shows how these programs function and how they are
implemented in Germany and around the world.
Months of investigation by the German public television broadcasters NDR and
WDR, drawing on exclusive access to top secret NSA source code, interviews
with former NSA employees, and the review of secret documents of the German
government reveal that not only is the server in Nuremberg under observation
by the NSA, but so is virtually anyone who has taken an interest in several
well-known privacy software systems.
The NSA program XKeyscore is a collection and analysis tool and "a computer
network exploitation system", as described in an NSA presentation. It is one
of the agencys most ambitious programs devoted to gathering "nearly
everything a user does on the internet." The source code contains several
rules that enable agents using XKeyscore to surveil privacy-conscious
internet users around the world. The rules published here are specifically
directed at the infrastructure and the users of the Tor Network, the Tails
operating system, and other privacy-related software. Tor, also known as The Onion Router, is a network of several thousand
volunteer-operated servers, or nodes, that work in concert to conceal Tor
users' IP addresses and thus keep them anonymous while online.
Tails is a privacy-focused GNU/Linux-based operating system that runs
entirely from an external storage device such as a USB stick or CD. It comes
with Tor and other privacy tools pre-installed and configured, and each time
it reboots it automatically wipes everything that is not saved on an
encrypted persistent storage medium.
Normally a user's online traffic - such as emails, instant messages,
searches, or visits to websites - can be attributed to the IP address
assigned to them by their internet service provider. When a user goes online
over the Tor Network, their connections are relayed through a number of Tor
nodes using another layer of encryption between each server such that the
first server cannot see where the last server is located and vice-versa.
Tor is used by private individuals who want to conceal their online activity,
human rights activists in oppressive regimes such as China and Iran,
journalists who want to protect their sources, and even by the U.S. Drug
Enforcement Agency in their efforts to infiltrate criminal groups without
revealing their identity. The Tor Project is a non-profit charity based in
Massachusetts and is primarily funded by government agencies. Thus it is
ironic that the Tor Network has become such a high-priority target in the
NSA's worldwide surveillance system.
As revealed by the British newspaper The Guardian, there have been repeated
efforts to crack the Tor Network and de-anonymize its users. The top secret
presentations published in October last year show that Tor is anathema to the
NSA. In one presentation, agents refer to the network as "the king of
high-secure, low-latency internet anonymity". Another is titled "Tor Stinks".
Despite the snide remarks, the agents admit, "We will never be able to
de-anonymize all Tor users all the time".
The former NSA director General Keith Alexander stated that all those
communicating with encryption will be regarded as terror suspects and will be
monitored and stored as a method of prevention, as quoted by the Frankfurter
Allgemeine Zeitung in August last year. The top secret source code published
here indicates that the NSA is making a concerted effort to combat any and
all anonymous spaces that remain on the internet. Merely visiting
privacy-related websites is enough for a user's IP address to be logged into
an NSA database.
An examination of the XKeyscore rules published here goes beyond the slide
presentation and provides a window into the actual instructions given to NSA
computers. The code was deployed recently and former NSA employees and
experts are convinced that the same code or similar code is still in use
today. The XKeyscore rules include elements known as "appids",
"fingerprints", and "microplugins".  Each connection a user makes online - to
a search engine, for example - can be assigned a single appid and any number
of fingerprints.
Appids are unique identifiers for a connection in XKeyscore. Appid rules have
weights assigned to them.  When multiple appids match a given connection, the
one with the highest weight is chosen. Microplugins may contain software
written in general-purpose programming languages, such as C++, which can
extract and store specific types of data. The rules specifically target the
Tor Project's email and web infrastructure, as well as servers operated by
key volunteers in Germany, the United States, Sweden, Austria, and the
Netherlands. Beyond being ethically questionable, the attacks on Tor also
raise legal concerns.  The IP addresses of Tor servers in the United States
are amongst the targets, which could violate the fourth amendment of the US
The German attorney Thomas Stadler, who specializes in IT law, commented:
"The fact that a German citizen is specifically traced by the NSA, in my
opinion, justifies the reasonable suspicion of the NSA carrying out secret
service activities in Germany. For this reason, the German Federal Public
Prosecutor should look into this matter and initiate preliminary
One of NSA's German targets is 212.212.245.170.  The string of numbers is an
IP address assigned to Sebastian Hahn, a computer science student at the
University of Erlangen. Hahn operates the server out of a grey high-security
building a few kilometers from where he lives. Hahn, 28 years old and
sporting a red beard, volunteers for the Tor Project in his free time. He is
especially trusted by the Tor community, as his server is not just a node, it
is a so-called Directory Authority. There are nine of these worldwide, and
they are central to the Tor Network, as they contain an index of all Tor
nodes. A user's traffic is automatically directed to one of the directory
authorities to download the newest list of Tor relays generated each hour.
Quellcode NSA  "anonymizer/tor/node/authority" fingerprint.
Hahn's predecessor named the server Gabelmoo, or Fork Man, the nickname of a
local statue of Poseidon. After a look at the NSA source code, Hahn quickly
found his server's name listed in the XKeyscore rules. "Yes, I recognize the
IP address of my Tor server called 'gabelmoo'." he said. "Millions of people
use it to stay safe online, and by watching the server and collecting
metadata about its users, those people are put at risk." The rule shown to
Hahn, published below, has a fingerprint called
'anonymizer/tor/node/authority'. The fingerprint targets users who connect to
Gabelmoo and other Tor Directory Authority servers. In Germany, the Tor
Directory Authorities like Gabelmoo that are specifically targeted by
XKeyscore rules are in Berlin and Nuremberg. Additional targets are located
in Austria, Sweden, the United States, and the Netherlands.
Quellcode NSA  Fragments of XKeyscore rules targetting Tor directory
The expression below performs essentially the same function, but it specifies
the Tor directory authorities located in Five Eyes countries (Australia,
Canada, New Zealand, the United Kingdom and the United States) separately
from those in other countries. As the comment explains, the "goal is to find
potential Tor clients connecting to the Tor directory servers."
Another rule catalogs users connecting to known Tor relays. This is not
difficult, because the addresses of all normal Tor relays are published by
the directory authorities so that the Tor software on users' computers can
select its own path through the network. In addition to the public relays,
connections characterized as Tor based on protocol identifiers are also
Not only Metadata
Internet service providers in countries with strong censorship such as China
and Iran frequently block connections to known Tor relays. To avoid this
blocking, The Tor Project maintains a list of non-public relays called
"bridges" to allow users to avoid this type of blocking. Bridges are run by
volunteers and they share the details with the Tor Project to help censored
users reach the internet.
Quellcode NSA  Microplugin which extracts bridge addresses from the full text
of Tor Project emails.
Users can request a bridge address via email or on the web. The following
fingerprints show two ways that XKeyscore attempts to track Tor bridge users.
First, the fingerprint "anonymizer/tor/bridge/tls" records connections to the
bridges.torproject.org server. Second, in order obtain the actual bridge
addresses for the purpose of tracking connections to them in the future, the
"microplugin" fingerprint called "anonymizer/tor/bridge/email" extracts data
from the body of the emails that the Tor Project sends to its users.
This code demonstrates the ease with which an XKeyscore rule can analyze the
full content of intercepted connections. The fingerprint first checks every
message using the "email_address" function to see if the message is to or
from "bridges Next, if the address matched, it uses the
"email_body" function to search the full content of the email for a
particular piece of text - in this case, "
If the "email_body" function finds what it is looking for, it passes the full
email text to a C++ program which extracts the bridge addresses and stores
them in a database.
Quellcode NSA  Fingerprint to identify visitors to the Tor Project website.
The full content of the email must already be intercepted before this code
can analyze it. XKeyscore also keeps track of people who are not using Tor,
but who are merely visiting The Tor Project's website (
as this rule demonstrates:
Quellcode NSA  Rules targeting people viewing the Tails or Linux Journal
websites, or performing Tails-related web searches.
It is interesting to note that this rule specifically avoids fingerprinting
users believed to be located in Five Eyes countries, while other rules make
no such distinction. For instance, the following fingerprint targets users
visiting the Tails and Linux Journal websites, or performing certain web
searches related to Tails, and makes no distinction about the country of the
The comment in the  source code above describes Tails as "a comsec mechanism
advocated by extremists on extremist forums". In actuality, the software is
used by journalists, human rights activists, and hundreds of thousands of
ordinary people who merely wish to protect their privacy.
The rules related to Tails clearly demonstrate how easily web searches and
website visits can be spied on by XKeyscore. On June 25, 2014, the United
States Supreme Court noted how sensitive this type of information is in their
Riley v. California decision against warrantless searches of mobile phones:
"An Internet search and browsing history [...] could reveal an individuals
private interests or concerns - perhaps a search for certain symptoms of
disease, coupled with frequent visits to WebMD."
Quellcode NSA  C++ program which searches "raw traffic" for .onion addresses.
In addition to anonymous internet access, Tor also provides a mechanism for
hosting anonymous internet services called "Hidden Services". These sites'
URLs contain a domain name in the pseudo-top-level-domain ".onion" which is
only accessible using Tor. The code shown below finds and catalogs URLs for
these sites which XKeyscore sees in "raw traffic", creating a unique
fingerprint for each onion address. Each .onion address found in raw traffic
is extracted and stored in an NSA database:
Quellcode NSA  "anonymizer/mailer/mixminion" appid matching all connections
to 128.31.0.34.
There are also rules that target users of numerous other privacy-focused
internet services, including HotSpotShield, FreeNet, Centurian,
FreeProxies.org, MegaProxy, privacy.li and an anonymous email service called
MixMinion as well as its predecessor MixMaster. The appid rule for MixMinion
is extremely broad as it matches all traffic to or from the IP address
128.31.0.34, a server located on the MIT campus.
That server is operated by the Tor Project's leader Roger Dingledine, an MIT
alumnus. The machine at this IP address provides many services besides
MixMinion, and it is also one of the above-mentioned Tor directory
authorities. Dingledine said "That computer hosts many websites, ranging from
open source gaming libraries to the Privacy Enhancing Technologies Symposium
Sebastian Hahn, the Tor volunteer who runs Gabelmoo, was stunned to learn
that his hobby could interest the NSA: "This shows that Tor is working well
enough that Tor has become a target for the intelligence services. For me
this means that I will definitely go ahead with the project.
When asked for a reaction to the findings, the Tor Project's Roger Dingledine
stated the following: "We've been thinking of state surveillance for years
because of our work in places where journalists are threatened. Tor's
anonymity is based on distributed trust, so observing traffic at one place in
the Tor network, even a directory authority, isn't enough to break it. Tor
has gone mainstream in the past few years, and its wide diversity of users -
from civic-minded individuals and ordinary consumers to activists, law
enforcement, and companies - is part of its security. Just learning that
somebody visited the Tor or Tails website doesn't tell you whether that
person is a journalist source, someone concerned that her Internet Service
Provider will learn about her health conditions, or just someone irked that
cat videos are blocked in her location. Trying to make a list of Tor's
millions of daily users certainly counts as wide scale collection. Their
attack on the bridge address distribution service shows their "collect all
the things" mentality - it's worth emphasizing that we designed bridges for
users in countries like China and Iran, and here we are finding out about
attacks by our own country. Does reading the contents of those mails violate
the wiretap act? Now I understand how the Google engineers felt when they
learned about the attacks on their infrastructure.
NDR and WDR wanted to know from the NSA how it justified attacking a service
funded by the U.S. government, under what legal authority Tor Network users
are monitored, and whether the German government has any knowledge of the
targeting of servers in Germany. Instead of adressing the questions
repeatedly posed to them, the NSA provided the following statement: "In
carrying out its mission, NSA collects only what it is authorized by law to
collect for valid foreign intelligence purposes - regardless of the technical
means used by foreign intelligence targets. The communications of people who
are not foreign intelligence targets are of no use to the agency. In January,
President Obama issued U.S. Presidential Policy Directive 28, which affirms
that all persons - regardless of nationality - have legitimate privacy
interests in the handling of their personal information, and that privacy and
civil liberties shall be integral considerations in the planning of U.S.
signals intelligence activities. The president's  directive also makes clear
that the United States does not collect signals intelligence for the purpose
of suppressing or burdening criticism or dissent, or for disadvantaging
persons based on their ethnicity, race, gender, sexual orientation, or
religion. XKeyscore is an analytic tool that is used as a part of NSA's
lawful foreign signals intelligence collection system. Such tools have
stringent oversight and compliance mechanisms built in at several levels. The
use of XKeyscore allows the agency to help defend the nation and protect U.S.
and allied troops abroad. All of NSA's operations are conducted in strict
accordance with the rule of law, including the President's new directive."
However, the research contradicts the United States' promise to Germany that
German citizens are not surveiled without suspicion. Using Tor in Germany
does not justify targeting someone, the German attorney Thomas Stadler
states: "Tor users do not breach any laws, it is absolutely legitimate to act
anonymously on the internet. There are many good reasons to remain
What is deep packet inspection?
Deep Packet Inspection, or DPI, refers to the class of technology which
examines the content of data packets as they travel across a network. A
packet is the fundamental unit of transfer in packet switched networks like
the internet. While DPI is commonly used by organizations to monitor their
own networks, its use on public networks for censorship and surveillance has
been widely condemned by privacy advocates and the United States government
In 2012, the head of the U.S. Delegation to the World Conference on
International Telecommunications, U.S. Ambassador Terry Kramer, said some
companies have used deep packet inspection technologies to not look at
aggregate customer information, traffic information, et cetera, but to look
at individual customer information. So looking at individuals and what sites
theyre on and how much capacity theyre using, et cetera, as you can
imagine, were very much opposed to that because we feel thats a violation
of peoples privacy and gets into, obviously, censorship, et cetera.
Despite its public political condemnations of invasive DPI use, the United
States "Intelligence Community" and its "Five Eyes" partners (Australia,
Canada, New Zealand, and the United Kingdom) operate massive internet-scale
DPI systems themselves, including XKeyscore. The use of XKeyscore is not
limited to these partners, however. The software has been shared with the
German BND and BfV, as well as the Swedish FRA, amongst others.
Active vs Passive
XKeyscore and the systems that feed it are considered "passive", meaning that
they silently listen but do not transmit anything on the networks that they
are targeting. However, through a process known as "tipping", data from these
programs can trigger other systems which perform "active" attacks.
Quantum is a family of such programs, including Quantuminsert, Quantumhand,
Quantumtheory, Quantumbot, and Quantumcopper, which are used for offensive
computer intrusion. Turmoil, Quantum, and other components of the Turbulence
architecture are running at so-called "defensive sites" including the
Ramstein Air Force base in Germany, Yokota Air Force base in Japan, and
numerous military and non-military locations within the United States.
Both Turmoil and XKeyscore feed selected data to real-time "tipping"
programs, such as Trafficthief, which can both alert NSA analysts when their
targets are communicating and trigger other software programs. Selected data
is "promoted" from the local XKeyscore data store to the NSA's so-called
"corporate repositories" for long term storage, analysis and exploitation.
More information about XKeyscore
In 2013, the British newspaper The Guardian revealed that by 2008 more than
150 internet surveillance facilities around the world were running the
XKeyscore Deep Packet Inspection software. All of the internet traffic
observed by XKeyscore, both metadata and full content, is analyzed and stored
temporarily at the collection sites for periods ranging from days to weeks,
while selected data is forwarded on to other locations for long-term storage.
The storage, indexing, and querying functions are performed at or near the
collection sites because the volume of data being collected is too large to
forward everything back to facilities in other countries. Analysts working
from various locations around the world may search specific XKeyscore sites,
or send their queries to a collection of sites.
XKeyscore provides a modular architecture in which tens of thousands of small
computer programs, or rules, written in XKeyscore's specialized programming
languages called Genesis and XKScript as well as general-purpose languages
such as C++ and Python, are run against all traffic to categorize it and
extract data. This indexing of the "full take" allows analysts to query the
temporary storage stored at the XKeyscore site, effectively sifting through
already pilfered communications which occurred before they had deemed them
interesting for a specific reason.
XKeyscore can be fed by several different programs, including Wealthycluster
and Turmoil. These programs "sessionize" the data, which means that
individual connections, such as a request for a web page, are reconstructed
from the stream of intercepted packets.
Locations where the NSA runs XKeyscore include Special Source Operations
(SSO) sites, typically found at or near major telecommunication providers'
infrastructure; Special Collection Service (SCS) sites, usually located
inside diplomatic facilities like embassies and consulates; and FORNSAT sites
where satellite communications are intercepted. All of these types of sites
are known to exist in Germany.
Other "Five Eyes" partners also operate XKeyscore installations. The United
Kingdom's Tempora program runs the largest instance of XKeyscore. Both the
software itself and limited access to NSA databases have been shared with
so-called "3rd party" partners including Germany. The German foreign
intelligence agency BND and the domestic intelligence agency BfV are testing
the Software.

@_date: 2014-07-04 16:56:41
@_author: Eugen Leitl 
@_subject: messing with XKeyScore 
Errata Security
Advanced persistent cybersecurity
Friday, July 04, 2014
Jamming XKeyScore
Back in the day there was talk about "jamming echelon" by adding keywords to email that the echelon system was supposedly looking for. We can do the same thing for XKeyScore: jam the system with more information than it can handle. (I enumerate the bugs I find in the code as "xks-00xx").
For example, when sending emails, just send from the address "bridges at torproject.org" and in the email body include:
bridge = 0.0.0.1:443
bridge = 0.0.0.2:443
bridge = 0.0.0.3:443
Continue this for megabytes worth of bridges (xks-0001), and it'll totally mess up XKeyScore. It has no defense against getting flooded with information like this, as far as I can see.
Note that the regex only cares about 1 to 3 digit numbers, that means the following will be accepted by the system (xks-0002):
bridge = 75.748.86.91:80
The port number matches on 2 to 4 digits ([0-9]{2,4}). Therefore, bridges with port numbers below 10 and above 9999 will be safe. I don't know if this code reflect a limitation in Tor, or but assuming high/low ports are possible, this can be used to evade detection (xks-0011).
Strangely, when the port number is parsed, it'll capture the first non-digit character after the port number (xks-0012). This is normally whitespace, but we could generate an email with 256 entries, trying every possible character. A character like < or ' might cause various problems in rendering on an HTML page or generating SQL queries.
You can also jam the system with too many Onion addresses (xks-0003), but there are additional ways to screw with those. When looking for Onion addresses, the code uses a regex that contains the following capture clause:
This is looking for a string like " or " but the regex has no upper bounds (xks-0004) and there is no validation. Thus, you can include "goscrewyourself://o987asgia7gsdfoi.onion:443/" in network traffic, and it'll happily insert this into the database. But remember that "no upper bounds" means just that: the prefix can be kilobytes long, megabytes long, or even gigabytes long. You can open a TCP connection to a system you feel the NSA is monitoring, send 5 gigabytes of lower-case letters, followed by the rest of the Onion address, and see what happens. I mean, there is some practical upper bound somewhere in the system,, and when you hit it, there's a good chance bad things will happen.
Likewise, the port number for Onion address is captured by the regex (d+), meaning any number of digits (xks-0005). Thus, we could get numbers that overflow 16-bits, 32-bits, 64-bits, or 982745987-bits. Very long strings of digits (megabytes) at this point might cause bad things to happen within the system.
There is an extra-special thing that happens when the schema part of the Onion address is exactly 16-bytes long (xks-0006). This will cause the address and the scheme to reverse themselves when inserted into the database. Thus, we can insert digits into the scheme field. This might foul up later code that assumes schemes only contain letters, because only letters match in the regex.
In some protocol fields, the regexes appear to be partial matches. The system appears to match on HTTP servers with "mixminion" anywhere in the name. Thus, we start causing lots of traffic to go to our domains, such as "mixminion.robertgraham.com", that will cause their servers to fill up with long term storage of sessions they don't care about (xks-0007)
Let's talk X.509, and the following code:
fingerprint('anonymizer/tor/bridge/tls') =
  ssl_x509_subject('bridges.torproject.org') or
  ssl_dns_name('bridges.torproject.org');
Code that parses X.509 certificates is known to be flaky as all get out. The simplest thing to do is find a data center you feel the NSA can monitor, and then setup a hostile server that can do generic fuzzing of X.509 certificates, trying to crash them.
It's likely that whatever code is parsing X.509 certificates is not validating them. Thus, anybody can put certificates on their servers claiming to be 'bridges.torproject.org' (xks-0008). It's likely that the NSA is parsing SSL on all ports, so just pick a random port on your server not being used for anything else, create a self-signed CERT claiming to be "bridges.torproject.org', then create incoming links to that port from other places so at least search-engines will follow that link and generate traffic. This will cause the NSA database of bridges to fill up with bad information -- assuming it's not already full from people screwing with the emails as noted above :).
Putting the above code in a web page like this one will cause every visitor to trigger a search for TAILS in the XKeyScore rules. The more people who do this, the less useful it becomes to the NSA (xks-0009) in labeling people as suspicious. Likewise, putting tails.boum.org/<.title> in your webpages will cause the same effect, even when CSS/JavaScript makes such a title invisible.
In theory, the NSA should only be monitoring foreign traffic, and not traffic originating from the United States (or, apparently, the other five-eyes). So here is the fun thing (xks-0010): run your jamming tools from United States IP addresses against those servers in Iran you know the NSA is monitoring. Since the code should already be ignoring the traffic because it originates from the United States, then they can't complain if you've filled up their databases full of Tor Onion and bridge addresses.
Robert Graham

@_date: 2014-07-08 16:04:58
@_author: Eugen Leitl 
@_subject: The Ex-Google Hacker Taking on =?utf-8?Q?t?= 
The Ex-Google Hacker Taking on the Worlds Spy Agencies
BY ANDY GREENBERG   07.08.14  |   6:30 AM  |   PERMALINK
Ariel Zambelich/WIRED
During his last six years working as an elite security researcher for Google,
the hacker known as Morgan Mayhem spent his nights and weekends hunting down
the malware used to spy on vulnerable targets like human rights activists and
political dissidents.
His new job tasks him with defending a different endangered species: American
national security journalists.
For the last month, 34-year-old Morgan Marquis-Boire has been the director of
security for First Look Media, the journalism startup founded by Glenn
Greenwald and Laura Poitras. The website has become the most prolific
publisher of NSA leaker Edward Snowdens remaining secrets. Marquis-Boires
daunting task is to safeguard those documents, and the communications of
reporters who have perhaps the press most adversarial relationships with
Western intelligence agencies.
Beyond protecting Snowdens favorite journalists, Marquis-Boire sees his
decision to leave Google for First Look as a chance to focus full-time on the
problem of protecting reporters and activists as a whole, groups he sees as
some of the most sensitive targets for governments globally. I look at the
risk posed to individuals in the real world, says Marquis-Boire, an
imposing, often black-clad New Zealander with earrings, dreadlocks, and a
taste for death metal. In human rights and journalism, the consequences of
communications being compromised are imprisonment, physical violence, and
even death. These types of users need security assistance in a very real
Marquis-Boire already has distinguished himself as a relentless
counter-surveillance researcher and a vocal critic of the companies that have
created an industry hawking spyware to governments. In 2012, he and
researchers at the University of Torontos Citizen Lab were the first to
identify Finfisher, a stealthy collection of spying tools sold by the British
firm Gamma Group that they eventually tracked to command-and-control servers
in 25 countries. Later that year he helped trace how a piece of software sold
by the Italian firm Hacking Team was used by the government of the United
Arab Emirates to spy on a political dissident beaten by thugs. Just last
month he revealed new findings that showed how that companys tools have
evolved to target iPhones, Android devices and other mobile targets. And in
early 2013 Marquis-Boire and Citizen Lab researchers mapped the spread of
surveillance and censorship tools sold by the Palo Alto, California firm Blue
Coat to 61 countries, including Iran.
In the detective work required to pin those stealthy spying incidents on
repressive governments and Western companies, Marquis-Boire is
extraordinarily talented, says Ron Deibert, a professor of political
science at the University of Toronto and Citizen Labs director. There are
some people who are phenomenally adept at forensics, who have an intuitive
sense of how to make connections through different pieces of evidence, he
says. Morgan has those skillsBut what I very much appreciate about him is
his passion for human rights.
A Cypherpunk In The Newsroom First Look and Marquis-Boire arent saying much
about exactly what hell do at the closely-watched new media startup. But
Marquis-Boire says he was convinced early in their recruitment meetings that
First Look will treat security as a central tenet. (More about First Looks
plans in the video below.) The job also presents a challenge worthy of
leaving his high profile position at Google: Protecting the communications
between non-technical reporters and their highly-sensitive sources in a
post-WikiLeaks and -Snowden era where theyre both increasingly targeted by
Marquis-Boire hints that hes already researching security vulnerabilities
that affect journalists, and working with several companies to release
security fixes to their services in the next couple of months. Brian Sweeney,
First Looks head of technology operations, says Marquis-Boires work likely
will extend into research designed to protect reporters beyond the companys
firewall. The idea that all digital citizens, including and especially
journalists, have access to data privacy is something that we strongly
believe in, says Sweeney.
Marquis-Boire, the son of two literature professors at the University of
Auckland, got started with security experimentation as a teenager in the New
Zealand hacker scene under the handle headhntr. After starting college at
Auckland, he and a group of friends wrote an article for the university
magazine about breaking into the schools website to take over the server
that ran it. On another occasion he was called into a local telecoms office
and given a stern talking to about using their services as a test lab.
But from the beginning, his interest in hacking was also political: In the
late 1990s the kiwi teenager discovered the Cypherpunks Mailing List, a group
of cryptographers and radical libertarians bent on foiling government
surveillance and empowering individuals with privacy tools. The group
eventually would foster projects like the anonymous remailers that relay
emails to obscure their senders identities, the anonymity software Tor,
WikiLeaks, and countless other privacy and encryption projects. People
realized that to actually have free speech, we have to be sure we wont be
monitored or persecuted, says Marquis-Boire. The intertwined nature of
privacy and free expression was at the core of the cypherpunk movement.
Marquis-Boire and friends soon hosted what he says was the first anonymous
remailer server in New Zealand out of a dingy warehouse apartment with far
too many blinking lights and whirring things. Eventually, he ran five Tor
relays, the nodes in the Tor network that bounce users traffic to obscure
their location.
But Marquis-Boires first real job in security, penetration-testing banks,
power plants, and other clients for a New Zealand auditing firm, was
unsatisfying. I spent a bit of time musing about how much it costs to hire
security consultants to do something like a black box [penetration test] of
your whole enterprise, he says. I wanted to give my skills to the people
who really needed them.
He Has Quite a Hacker Mind In 2008, Google hired Marquis-Boire in its
Zurich, Switzerland office. He was assigned to cybersecurity incident
response at the company not long before the biggest known security crisis in
its history: the so-called Aurora hacking operation, in which Chinese hackers
breached Googles network for months and stole information that included
source code from its servers. Marquis-Boire became an early member of the
core team of network defenders assigned to battle the state-sponsored spies
trying to eavesdrop on Googles users. He has quite a hacker mind, says
Heather Adkins, Googles manager of information security, Of everyone Ive
ever hired at Google, Id put him in the top one percent of technical
When the Arab Spring began a year later, human rights activists like those at
Citizen Lab who had seen Marquis-Boires presentations on state-sponsored
hacking began seeking his help analyzing attacks on vulnerable groups across
the Middle East. As revolutions and political unrest blossomed from Tunisia
to Egypt to Libya to Syria, his detective work became nearly a full-time job.
There have been a lot of books not read and canceled vacations, he says.
In the meantime, Googles Adkins adds, Marquis-Boire frequently uncovered
weaknesses in the companys defenses for usersand hes been just as focused
on locking out the NSA as Chinas Peoples Liberation Army. In the wake of
revelations from Snowdens leaks that the NSA spied on unencrypted Google
data moving between the companys data centers, Marquis-Boire was one of the
first at the company to push for encryption not only of the companys
internal data transfers, but also the exchange of emails between Gmail and
other providers. That pressure led Google earlier this month to start
publicly naming which email services do and dont allow for that encryption
in a bid to pressure other companies to safeguard users privacy.
Marquis-Boires focus turned to protecting journalists in particular earlier
this year, when he and other Googlers released research in March showing that
21 out of the 25 top media organizations in the world had been targeted in
digital attacks that were likely the work of state-sponsored hackers. The
same month, he joined a technical advisory group for the Freedom of the Press
Foundation, which counts Glenn Greenwald, Laura Poitras and Edward Snowden as
members of its board. If you cant protect your privacy and that of your
sources, its debatable whether you can actually practice journalism in the
traditional sense, he says.
That notion represents a shift from the cypherpunk views of Marquis-Boires
youth. Once, cypherpunks were mainly interested in seizing privacy for
themselves. Now, he says, thats no longer enough. When we discovered that
we could create private and anonymous communications with math, that was
super cool, he says. But then after a while I think it dawned on us as a
movement that the only conversations you could have with those tools were
with other cypherpunks.
Now its been thrust into our faces that the people practicing adversarial
journalism and exposing human right abuses are the real-world targets of
precisely the kind of thing that the cypherpunk movement was trying to
protect against, says Marquis-Boire. Its become apparent we need to
provide privacy to those who need it, not just to ourselves.
Tags: Edward Snowden, First Look Media, NSA, Security

@_date: 2014-07-09 14:23:28
@_author: Eugen Leitl 
@_subject: BPjM blacklist reversed 
tl;dr: Germany has a censorship federal agency called BPjM which maintains a
secret list of about 3000 URLs. To keep the list secret it is distributed in
the form of md5 or sha1 hashes as the "BPJM-Modul". They think this is safe.
This leak explains in detail that it is in fact very easy to extract the
hashed censorship list from home routers or child protection software and
calculate the cleartext entries. It provides a first analysis of the
sometimes absurd entries on such a governmental Internet censorship list.

@_date: 2014-07-10 11:06:55
@_author: Eugen Leitl 
@_subject: [Server-sky] Server sky and social architecture 
Code is Law, Hardware is Code's Language
The Law of Law is language. If your language is richly metaphorical and contains the word "schadenfreude", you will annex the Sudetenland, gas most of your ethnic minorities, and a surviving ethnic outlier will use your language to express general relativity. Other languages better express other crimes and concepts. A linguist will tell you all languages can express all concepts - languages are Turing complete - but this fashionable conceit does not tell us why different cultures do different things.
Code is law. Hardware is the language and law of code. Code can only do what hardware permits. A Turing complete machine can manufacture any set of symbols from any other set, but those symbols cannot go where the hardware doesn't connect.
In 1990 I designed a chip, a non-blocking crossbar routing device, for the startup I-Cube Design Systems. This chip routed signals from any pin to any other pin, and could route 240 inputs to any combination of 240 other outputs. But it also had fanout - it could route an input to two or more outputs. 160 inputs could become 320 outputs. This was useful for the original task - hardware logic simulation. When the original logic simulator customers became enmired in patent lawsuits, I-Cube found a new customer, another small startup called Cisco. Cisco's routers distributed the backbone of the early internet, and still route most of it.
I realize, decades later, that I made one of the architectural decisions that allows the NSA to watch you as you read this webpage.
Cisco's routers flowed bitstreams, not "packets", a software metaphor for a time-bounded sequence of bits. Packet headers told the router which flow got the bits, the router told the crossbar device which path the bits should take. Sending the bits to more than one place was implicit in how the hardware worked, because the hardware had fanout.
Cisco remains, I-Cube was killed by incompetent venture capitalists. I'm not party to how Cisco designs routers today, but fanout is implicit in dataflow, hardware can stream one transmitter to multiple receivers, tracelessly.
Software is merely "judicial opinion" applied to that hardware, and we non-electrical macroscopic human beings only have opinions, not sure knowledge, about how the bits are actually moving and transforming from memory location to other (possibly multiple) memory locations.
Software can encrypt - or it can pretend to. Software becomes machine instructions via a compiler. Dennis Ritchie taught us that a compiler emits machine instructions chosen by the compiler author, who can override the decisions of the source code author. The hardware author can override both. The hard disk manufacturer decides what firmware bytes go on the boot tracks of your hard drive, the disk firmware decides what bytes you actually get to your RAM from which disk track, and this firmware is invisible to the machine code it dispenses. In an age of Viterbi coding and VLSI disk chips, even a hardware logic analyzer may not tell you what's actually on the boot tracks. For sure knowledge, you will need your own hardware, either your own replacement disk chips or a focused ion beam milling system (FIB) to take apart the disk chips and learn what they actually do.
The economics of chip production make it impossibly expensive to give everyone a different chip architecture, though you can cheaply individualize every chip (another of my inventions, see  ). If there is a ghost in the hardware machine, it is in all the machines, and those versed in VLSI, equipped with FIB, can find the ghosts. The individuality can be perfectly hidden, and cannot be unmasked without destroying the chip.
Puzzling out a proprietary design is possible but time-consuming, perhaps costing as much as the original design. Verifying that an open source hardware design is faithfully replicated in silicon is relatively easy, and could be automated, perhaps as cheap as sequencing a genome. We do not do so, because software designers pretend the substrate does not exist, or is logically identical to all other substrates, and thus not worth controlling or verifying (doctors and pharmaceutical companies share the same pretense).
Open source hardware can also encrypt, and properly-designed hardware can encrypt without fanout (no feasible side channel attacks). If we choose, we can build individual hardware that encrypts each keystroke and decrypts it at each screen, whether the path between is centimeters or megameters. With proper hardware, you can still use Gmail for your mail host, but your messages are gibberish to Google, and to whoever they share the messages with. Google banner ads can be ignored by your decrypter. Google would starve, so they want to make your software and hardware "for free", protecting their product (which is you).
Hardware geeks will still need to re-examine (identical) copies of the hardware from time to time, to make sure the hardware matches specification, and crypto geeks will need to frequently re-examine the specification to make sure it is mathematically correct. And sometimes the hardware will be invalid, and we will need to replace it with new hardware. But a billion transistors costs pennies from Intel, which Amazon can get to you overnight.
Why this matters to Server Sky
Server sky will use far fewer routers. Access to server sky arrays will be trigonometric, agile antenna pointing, not packet routing via DNS and border gateway protocol; if the array is above the horizon and has what you want, you can talk to it directly without intermediaries, and your conversation can be encrypted end-to-end. Of course, each end can have fanout, with either the orbiting array or your ground terminal copying your conversation to your Designated Overlord. Each end can have a fanout of zero, censorship applied by that same (or different) Designated Overlord. No man-in-the-middle attacks when there is only vacuum and Maxwell's equations between sender and receiver. Orbital mechanics, Doppler shift, and twelve-nines-accurate shared clocks provide link authentication that cannot be spoofed without reshaping space-time.
There will be Designated Overlords - in the US, we call the overlords "Google" and "Hollywood", in China the overlords are the Communist Party and/or the People's Liberation Army. People can't seem to live without chains, sigh. But we must design our hardware so the overlords are explicit in the design, few in number, and subject to organized social opinion (which may be more true for China than the US, though I love Google more than the PLA).
This matters because the Server Sky team will make the design decisions now that will shape the hardware for decades, until the next big re-architecting (the last two were the Bell network, and internet protocol). These decisions should be informed by every capable brain on the planet. They should not be made by me, nor by my handful of smart but fallible collaborators. The best minds work elsewhere, and the best minds, if they know what's good for them, will get involved while the future is still conceptual and easy to shape. After launch, we can still replace all the satellites and all the ground terminals and all the end-user gear, but this is costly, and even the best minds don't have the money and persuasiveness to make this happen often. Better to get it approximately right the first time, and make it plug-upgradable.
This webpage is an appeal for help. Bad social design is easy, and regrettably common. Hardware is easy compared to competent social design. I beg you to help design the future you and your descendants will live in. I goofed up once, I would rather not do it again.

@_date: 2014-07-11 12:36:00
@_author: Eugen Leitl 
@_subject: The ultimate goal of the NSA is total population control 
The ultimate goal of the NSA is total population control
At least 80% of all audio calls, not just metadata, are recorded and stored
in the US, says whistleblower William Binney  that's a 'totalitarian
Antony Loewenstein theguardian.com, Friday 11 July 2014 00.54 BST
William Binney testifies before a German inquiry into surveillance.
Photograph: Getty Images
William Binney is one of the highest-level whistleblowers to ever emerge from
the NSA. He was a leading code-breaker against the Soviet Union during the
Cold War but resigned soon after September 11, disgusted by Washingtons move
towards mass surveillance.
On 5 July he spoke at a conference in London organised by the Centre for
Investigative Journalism and revealed the extent of the surveillance programs
unleashed by the Bush and Obama administrations.
At least 80% of fibre-optic cables globally go via the US, Binney said.
This is no accident and allows the US to view all communication coming in.
At least 80% of all audio calls, not just metadata, are recorded and stored
in the US. The NSA lies about what it stores.
The NSA will soon be able to collect 966 exabytes a year, the total of
internet traffic annually. Former Google head Eric Schmidt once argued that
the entire amount of knowledge from the beginning of humankind until 2003
amount to only five exabytes.
Binney, who featured in a 2012 short film by Oscar-nominated US film-maker
Laura Poitras, described a future where surveillance is ubiquitous and
government intrusion unlimited.
The ultimate goal of the NSA is total population control, Binney said, but
Im a little optimistic with some recent Supreme Court decisions, such as law
enforcement mostly now needing a warrant before searching a smartphone.
He praised the revelations and bravery of former NSA contractor Edward
Snowden and told me that he had indirect contact with a number of other NSA
employees who felt disgusted with the agencys work. Theyre keen to speak
out but fear retribution and exile, not unlike Snowden himself, who is likely
to remain there for some time.
Unlike Snowden, Binney didnt take any documents with him when he left the
NSA. He now says that hard evidence of illegal spying would have been
invaluable. The latest Snowden leaks, featured in the Washington Post, detail
private conversations of average Americans with no connection to extremism.
It shows that the NSA is not just pursuing terrorism, as it claims, but
ordinary citizens going about their daily communications. The NSA is
mass-collecting on everyone, Binney said, and its said to be about
terrorism but inside the US it has stopped zero attacks.
The lack of official oversight is one of Binneys key concerns, particularly
of the secret Foreign Intelligence Surveillance Court (Fisa), which is held
out by NSA defenders as a sign of the surveillance scheme's
The Fisa court has only the governments point of view, he argued. There
are no other views for the judges to consider. There have been at least 15-20
trillion constitutional violations for US domestic audiences and you can
double that globally.
A Fisa court in 2010 allowed the NSA to spy on 193 countries around the
world, plus the World Bank, though theres evidence that even the nations the
US isnt supposed to monitor  Five Eyes allies Britain, Canada, Australia
and New Zealand  arent immune from being spied on. Its why encryption is
today so essential to transmit information safely.
Binney recently told the German NSA inquiry committee that his former
employer had a totalitarian mentality that was the "greatest threat" to US
society since that countrys US Civil War in the 19th century. Despite this
remarkable power, Binney still mocked the NSAs failures, including missing
this years Russian intervention in Ukraine and the Islamic States take-over
of Iraq.
The era of mass surveillance has gone from the fringes of public debate to
the mainstream, where it belongs. The Pew Research Centre released a report
this month, Digital Life in 2025, that predicted worsening state control and
censorship, reduced public trust, and increased commercialisation of every
aspect of web culture.
Its not just internet experts warning about the internets colonisation by
state and corporate power. One of Europes leading web creators, Lena Thiele,
presented her stunning series Netwars in London on the threat of cyber
warfare. She showed how easy it is for governments and corporations to
capture our personal information without us even realising.
Thiele said that the US budget for cyber security was US$67 billion in 2013
and will double by 2016. Much of this money is wasted and doesn't protect
online infrastructure. This fact doesnt worry the multinationals making a
killing from the gross exaggeration of fear that permeates the public domain.
Wikileaks understands this reality better than most. Founder Julian Assange
and investigative editor Sarah Harrison both remain in legal limbo. I spent
time with Assange in his current home at the Ecuadorian embassy in London
last week, where he continues to work, release leaks, and fight various legal
battles. He hopes to resolve his predicament soon.
At the Centre for Investigative Journalism conference, Harrison stressed the
importance of journalists who work with technologists to best report the NSA
stories. Its no accident, she said, that some of the best stories on the
NSA are in Germany, where theres technical assistance from people like Jacob
A core Wikileaks belief, she stressed, is releasing all documents in their
entirety, something the group criticised the news site The Intercept for not
doing on a recent story. The full archive should always be published,
Harrison said.
With 8m documents on its website after years of leaking, the importance of
publishing and maintaining source documents for the media, general public and
court cases cant be under-estimated. I see Wikileaks as a library, Assange
said. Were the librarians who cant say no.
With evidence that there could be a second NSA leaker, the time for more
aggressive reporting is now. As Binney said: I call people who are covering
up NSA crimes traitors.

@_date: 2014-07-15 15:38:15
@_author: Eugen Leitl 
@_subject: Experts report potential software "back doors" in U.S. standards 
Experts report potential software "back doors" in U.S. standards
BY JOSEPH MENN
SAN FRANCISCO, July 14 Mon Jul 14, 2014 8:58pm EDT
(Reuters) - U.S. government standards for software may enable spying by the
National Security Agency through widely used coding formulas that should be
jettisoned, some of the country's top independent experts concluded in papers
released on Monday.
Such mathematical formulas, or curves, are an arcane but essential part of
most technology that prevents interception and hacking, and the National
Institute of Standards and Technology (NIST) has been legally required to
consult with the NSA's defensive experts in approving them and other
cryptography standards.
But NIST's relationship with the spy agency came under fire in September
after reports based on documents from former NSA contractor Edward Snowden
pointed to one formula in particular as a Trojan horse for the NSA.
NIST discontinued that formula, called Dual Elliptic Curve, and asked its
external advisory board and a special panel of experts to make
recommendations that were published on Monday alongside more stinging
conclusions by the individual experts.
Noting the partially obscured hand of the NSA in creating Dual Elliptic Curve
- which Reuters reported was most broadly distributed by security firm RSA
[USN:nL2N0JZ1B6] - the group delved into the details of how it and other NIST
standards emerged. It found incomplete documentation and poor explanations in
some cases; in others material was withheld pending legal review.
As a whole, the panels recommended that NIST review its obligation to confer
with the NSA and seek legal changes "where it hinders its ability to
independently develop the best cryptographic standards to serve not only the
United States government but the broader community."
They also urged NIST to weigh the advice of individual task force members who
made more dramatic suggestions, such as calling for the replacement of a
larger set of curves approved for authenticating users, in part because they
were selected through unclear means by the NSA.
"It is possible that the specified curves contain a back door somehow," said
Massachusetts Institute of Technology professor Ron Rivest, a co-founder of
RSA and the source of the letter R in its name. Though the curves could be
fine, he wrote, "it seems prudent to assume the worst and transition away."
More broadly, Rivest wrote, "NIST should ask the NSA for full disclosure
regarding all existing standards... If NSA refuses to answer such an inquiry,
then any standard developed with significant NSA input should be assumed to
be `tainted,'" absent proof of security acceptable to outsiders.
In an email exchange, Rivest told Reuters that "NIST needs to have a process
whereby evidence is publicly presented" about how the curves were chosen.
The curves faulted on Monday had been questioned by outsiders after media
reports in September said the NSA could break much widely used security
software, without detailing which ones or how. "These curves are ubiquitous
in commercial cryptography," Johns Hopkins University professor Matthew Green
said in an interview. "If you connected to Google or Facebook today, you
probably used one."
Rivest's long association with RSA, now part of electronic storage maker EMC
Corp, made his remarks more poignant. But prominent task force colleagues
including Internet co-creator Vint Cerf and Ed Felten, former chief
technologist at Federal Trade Commission, also gave strongly worded verdicts
on the Department of Commerce unit.
"It cannot be accepted that NIST's responsibilities should be co-opted by the
NSA's intelligence mission," wrote Cerf, who now works at Google Inc.
While Rivest called the internal history of Dual Elliptic Curve a "smoking
gun" with an "almost certain" NSA back door, Felten wrote that NSA might not
remain alone in its ability to use it and other possible NIST-approved holes
for spying.
In each of three cases, including Dual Elliptic Curve and the more common
curves faulted by Rivest, Felten said the suspected back door access "reduces
the security of users against attack by other adversaries, including
organized crime groups or foreign intelligence services."
The NSA might have been able to generate curves that pass cursory security
tests but are still breakable through the aid of sheer computing power,
because it can try millions of curves and get a few that fit its goals. But a
researcher working for another country could discover the flaw, Felten said.
In the case of the curves approved under the FIPS 186 standard for
authenticating digital signatures, NIST should start over and pick its own
curves publicly rather than relying on the NSA, Felten and others said.
Several experts said NIST had to hire more cryptographers and strengthen its
internal processes to avoid relying on NSA.
NIST acting Director Willie May agreed in a statement, saying his agency
"must strengthen its in-house cryptography capabilities to ensure we can
reach independent conclusions about the merits of specific algorithms or
NIST did not respond to a Reuters email asking about the fate of the suspect
curves. (Reporting by Joseph Menn; Editing by Ken Wills)

@_date: 2014-07-15 18:31:11
@_author: Eugen Leitl 
@_subject: Rainforest Connection and WildLeaks 
Interesting uses of old mobile phones
(I'm sure you'll how this be made applicable in
other contexts (say, urban environment) and with other modifications).
One group hopes to end poaching, WikiLeaks-style

@_date: 2014-07-17 15:09:14
@_author: Eugen Leitl 
@_subject: the NSA revelations all in one chart 
The NSA Revelations All in One Chart
This is a plot of the NSA programs revealed in the past year according to
whether they are bulk or targeted, and whether the targets of surveillance
are foreign or domestic. Most of the programs fall squarely into the agencys
stated mission of foreign surveillance, but some  particularly those that
are both domestic and broad-sweeping  are more controversial.
Just as with the New York Magazine approval matrix that served as our
inspiration, the placement of each program is based on judgments and is
For more details, read our FAQ or listen to our podcast. Also, take our quiz
to test your NSA knowledge.

@_date: 2014-07-17 18:54:26
@_author: Eugen Leitl 
@_subject: Leaked GCHQ catalog of exploit tools for manipulation and mass 
Leaked GCHQ catalog of exploit tools for manipulation and mass surveillance
By Darlene Storm
July 16, 2014 1:22 PM EDTAdd a comment
Just as civil liberties groups challenge the legality of the UK intelligence
agencys mass surveillance programs, a catalog of exploit tools for
monitoring and manipulation is leaked online.
The Joint Threat Research Intelligence Group (JTRIG), a department within the
Government Communications Headquarters (GCHQ), develops the majority of
effects capabilities for UKs NSA-flavored intelligence agency. First Look
Media first published the Snowden-leaked Wikipedia-like document full of
covert tools used by GCHQ for surveillance and propaganda. JTRIG tools and
techniques help British spies seed the internet with false information,
including the ability to manipulate the results of online polls, monitor
social media posts, and launch attacks ranging from denial of service, to
call bombing phones, to disabling users' accounts on PCs.
Devils Handshake, Dirty Devil, Reaper and Poison Arrow are but a few
vicious-sounding JTRIG system tools, but the naming convention for others are
just inane like Bumblebee Dance, Techno Viking and Jazz Fusion. Perhaps the
British spies were hungry when coming up with Fruit Bowl, Spice Island, Nut
Allergy, and Berry Twister?  Most of the tools are "fully operational, tested and reliable, according to
the 2012 JTRIG Manual, but "Don't treat this like a catalog. If you don't see
it here, it doesn't mean we can't build it." Like the previously leaked TAO
exploits, its an eye-opener as to exploits that GCHQ can deploy.
GCHQ spy tools, techniques and exploits in JTRIG manual
Some of the especially invasive tools that are either ready to fire or very
close to being ready include:
long and when the effect is active.
material online.
files on a targets machine.
info, files, logs, etc and posts it back to GCHQ.
elicit a targets IP address.
       Tornado Alley is a delivery system aimed at Microsoft Excel "to
silently extract and run an executable on a target's machine."
address and send email under that identity.
ringing them. Target does not need to answer. Denial of Service:
services. Other JTRIG exploits include Screaming Eagle, a tool that
processes Kismet data into geolocation information and Chinese Firecracker
for overt brute login attempts against online forums. Hacienda is a port
scanning tool designed to scan an entire country or city before identifying
IP locations and adding them to an Earthling database.
Messing with cellphones:
telephones, or repeatedly bomb a target number with the same message.
phone to aid geolocation.
via call bombing.
BlackBerry targets.
allows us to pull back cell tower and Wi-Fi locations targeted against
particular areas. Vipers Tongue is another denial of service tool but its
aimed at satellite or GSM phone calls.  Manipulation and propaganda
Bomb Bay can increase website hits/rankings. Gateway can artificially
increase traffic to a website; Slipstream can inflate page views on
websites. Underpass can change the outcome of online polls. Badger can
mass deliver email messages to support an Information Operations campaign.
Gestator can amplify a given message, normally video, on popular multimedia
websites like YouTube. The production and dissemination of multimedia via
the web in the course of information operations can be accomplished with
Skyscraper. There are also various tools to censor or report extremist
Online surveillance of social networks
Godfather collects public data from Facebook. While Spring Bishop finds
private photos of targets on Facebook, Reservoir allows the collection of
various Facebook information. Clean Sweep can masquerade Facebook wall posts
for individuals or entire countries.
Birdstrike monitors and collects Twitter profiles. Dragons Snout collects
Paltalk group chats. Airwolf collects YouTube videos, comments and profiles.
Bugsy collects users info off Google+. Fatyak is about collecting data from
LinkedIn. Goodfella is a generic framework to collect public data from
online social networks. Elate monitors a target's use of UK's eBay. Mouth
finds, collects and downloads a users files from achive.org. Photon Torpedo
can actively grab the IP address of an MSN messenger user. Pitbull is aimed
at large scale delivery of tailored messages to IM services.
Miniature Hero is about exploiting Skype. The description states, Active
Skype capability. Provision of real time call records (SkypeOut and
SkypetoSkype) and bidirectional instant messaging. Also contact lists.
If thats not enough mass-scale surveillance and manipulation to irk you,
there are more weaponized tricks and techniques in the JTRIG Manual.

@_date: 2014-07-18 12:24:15
@_author: Eugen Leitl 
@_subject: interesting thread on BND intercept at DE-CIX on denog@ 
The netops are not amused.
You need to be a list member in order to access the archive.

@_date: 2014-07-21 14:03:08
@_author: Eugen Leitl 
@_subject: Huge collection of Security Data Science papers 
(looks useful)
 Over the past several years I have collected and read many security research papers/slides and have started a small catalog of sorts. The topics of these papers range from intrusion detection, anomaly detection, machine learning/data mining, Internet scale data collection, malware analysis, and intrusion/breach reports. I figured this collection might useful to others. All links lead to PDFs hosted here.
I hope to clean this up (add author info, date, and publication) when I get some more time as well as adding some detailed notes I have on the various features, models, algorithms, and datasets used in many of these papers.
Here are some of my favorites (nice uses of machine learning, graph analytics, and/or anomaly detection to solve interesting security problems):
CAMP - Content Agnostic Malware Protection
Notos - Building a Dynamic Reputation System for DNS
Kopis - Detecting malware domains at the upper dns hierarchy
Pleiades - From Throw-away Traffic To Bots - Detecting The Rise Of DGA-based Malware
EXPOSURE - Finding Malicious Domains Using Passive DNS Analysis
Polonium - Tera-Scale Graph Mining for Malware Detection
Nazca - Detecting Malware Distribution in Large-Scale Networks
PAYL - Anomalous Payload-based Network Intrusion Detection
Anagram - A Content Anomaly Detector Resistant to Mimicry Attack
Here is the entire collection:
Intrusion Detection
A Close Look on n-Grams in Intrusion Detection- Anomaly Detection vs. Classication
A Kill Chain Analysis of the 2013 Target Data Breach
A Lone Wolf No More - Supporting Network Intrusion Detection with Real-Time Intelligence
A Machine-learning Approach for Classifying and Categorizing Android Sources and Sinks
Acquiring Digital Evidence from Botnet Attacks: Procedures and Methods (PhD Thesis)
ALERT-ID - Analyze Logs of the network Element in Real Time for Intrusion Detection
Anagram - A Content Anomaly Detector Resistant to Mimicry Attack
Anomaly-based Intrusion Detection in Software as a Service
Back to Basics - Beyond Network Hygiene
Beehive - Large-Scale Log Analysis for Detecting Suspicious Activity in Enterprise Networks
Behavioral Clustering of HTTP-based Malware and Signature Generation Using Malicious Network Traces
Beheading Hydras - Performing Effective Botnet Takedowns
Bloodhound - Searching Out Malicious Input in Network Flows for Automatic Repair Validation
Boosting the Scalability of Botnet Detection Using Adaptive Traffic Sampling
CAMP - Content Agnostic Malware Protection
Casting out demons - Sanitizing training data for anomaly sensors
CloudFence - Data Flow Tracking as a Cloud Service
Comparing anomaly detection techniques for HTTP
Cujo - Efficient detection and prevention of drive-by-download attacks
Decoy Document Deployment for Effective Masquerade Attack Detection
Detecting Spammers with SNARE - Spatio-temporal Network-level Automatic Reputation Engine
Detecting Unknown Network Attacks Using Language Models
Early Detection of Malicious Flux Networks via Large-Scale Passive DNS Traffic Analysis
Effective Anomaly Detection with Scarce Training Data
Efficient Multidimensional Aggregation for Large Scale Monitoring
EFFORT - Efficient and Effective Bot Malware Detection
ExecScent- Mining for New C and C Domains in Live Networks with Adaptive Control Protocol Templates - slides
ExecScent- Mining for New C and C Domains in Live Networks with Adaptive Control Protocol Templates
EXPOSURE - Finding Malicious Domains Using Passive DNS Analysis
FiG - Automatic Fingerprint Generation
Filtering Spam with Behavioral Blacklisting
FLIPS - Hybrid Adaptive Intrusion Prevention
HMMPayl - An Intrusion Detection System Based on Hidden Markov Models
Kopis - Detecting malware domains at the upper dns hierarchy
Large-Scale Malware Analysis, Detection, and Signature Generation
Leveraging Honest Users - Stealth Command-and-Control of Botnets - slides
Leveraging Honest Users - Stealth Command-and-Control of Botnets
Local System Security via SSHD Instrumentation
Machine Learning In Adversarial Environments
Malware vs. Big Data (Umbrella Labs)
McPAD - A Multiple Classifier System for Accurate Payload-based Anomaly Detection
Measuring and Detecting Malware Downloads in Live Network Traffic
Mining Botnet Sink Holes - slides
MISHIMA - Multilateration of Internet hosts hidden using malicious fast-ux agents
Monitoring the Initial DNS Behavior of Malicious Domains
N-Gram against the Machine - On the Feasibility of the N-Gram Network Analysis for Binary Protocols
Nazca - Detecting Malware Distribution in Large-Scale Networks
Netgator - Malware Detection Using Program Interactive Challenges - slides
Network Traffic Characterization Using (p, n)-grams Packet Representation
Notos - Building a Dynamic Reputation System for DNS
On the Feasibility of Online Malware Detection with Performance Counters
On the Infeasibility of Modeling Polymorphic Shellcode
On the Mismanagement and Maliciousness of Networks
Outside the Closed World - On Using Machine Learning For Network Intrusion Detection
PAYL - Anomalous Payload-based Network Intrusion Detection
PAYL2 - Anomalous Payload-based Worm Detection and Signature Generation
Pleiades - From Throw-away Traffic To Bots - Detecting The Rise Of DGA-based Malware
Practical Comprehensive Bounds on Surreptitious Communication Over DNS - slides
Practical Comprehensive Bounds on Surreptitious Communication Over DNS
Privacy-preserving Payload-based Correlation for Accurate Malicious Traffic Detection
Revealing Botnet Membership Using DNSBL Counter-Intelligence
Revolver - An Automated Approach to the Detection of Evasive Web-based Malware
Self-organized Collaboration of Distributed IDS Sensors
SinkMiner- Mining Botnet Sinkholes for Fun and Profit
Spamming Botnets - Signatures and Characteristics
Spectrogram - A Mixture of Markov Chain models for Anomaly Detection in Web Traffic
The Security of Machine Learning
Toward Stealthy Malware Detection
Traffic Aggregation for Malware Detection
Understanding the Domain Registration Behavior of Spammers
Understanding the Network-Level Behavior of Spammers
VAST- Network Visibility Across Space and Time
A static, packer-agnostic filter to detect similar malware samples
A study of malcode-bearing documents
A survey on automated dynamic malware-analysis techniques and tools
APT1 Technical backstage (malware.lu hack backs of APT1 servers)
Automatic Analysis of Malware Behavior using Machine Learning
BitShred - Fast, Scalable Code Reuse Detection in Binary Code
BitShred - Fast, Scalable Malware Triage
Deobfuscating Embedded Malware using Probable-Plaintext Attacks
Escape from Monkey Island - Evading High-Interaction Honeyclients
Eureka - A framework for enabling static malware analysis
Extraction of Statistically Significant Malware Behaviors
Fast Automated Unpacking and Classification of Malware
FIRMA - Malware Clustering and Network Signature Generation with Mixed Network Behaviors
FuncTracker - Discovering Shared Code (to aid malware forensics) - slides
FuncTracker - Discovering Shared Code to Aid Malware Forensics Extended Abstract
Malware files clustering based on file geometry and visualization using R language
Mobile Malware Detection Based on Energy Fingerprints  A Dead End
Polonium - Tera-Scale Graph Mining for Malware Detection
Putting out a HIT - Crowdsourcing Malware Installs
Scalable Fine-grained Behavioral Clustering of HTTP-based Malware
SigMal - A Static Signal Processing Based Malware Triage
Tracking Memory Writes for Malware Classification and Code Reuse Identification
Using File Relationships in Malware Classification
VAMO - Towards a Fully Automated Malware Clustering Validity Analysis
Data Collection
Crawling BitTorrent DHTs for Fun and Prot
CyberProbe - Towards Internet-Scale Active Detection of Malicious Servers
Demystifying service discovery - Implementing an internet-wide scanner
gitDigger - Creating useful wordlists from GitHub
PoisonAmplifier - A Guided Approach of Discovering Compromised Websites through Reversing Search Poisoning Attacks
ZMap - Fast Internet-Wide Scanning and its Security Applications (slides)
ZMap - Fast Internet-Wide Scanning and its Security Applications
Vulnerability Analysis/Reversing
A Preliminary Analysis of Vulnerability Scores for Attacks in Wild
Attacker Economics for Internet-scale Vulnerability Risk Assessment
Detecting Logic Vulnerabilities in E-Commerce Applications
ReDeBug - Finding Unpatched Code Clones in Entire OS Distributions
The Classification of Valuable Data in an Assumption of Breach Paradigm
Toward Black-Box Detection of Logic Flaws in Web Applications
Vulnerability Extrapolation - Assisted Discovery of Vulnerabilities using Machine Learning - slides
Vulnerability Extrapolation - Assisted Discovery of Vulnerabilities using Machine Learning
Anonymous Hacking Group   Super Secret Security Handbook
Detecting Traffic Snooping in Tor Using Decoys
Risks and Realization of HTTPS Traffic Analysis
Selling Off Privacy at Auction
The Sniper Attack - Anonymously Deanonymizing and Disabling the Tor Network
The Velocity of Censorship - High-Fidelity Detection of Microblog Post Deletions - slides
The Velocity of Censorship - High-Fidelity Detection of Microblog Post Deletions
Tor vs. NSA
Data Mining
An Exploration of Geolocation and Traffic Visualization Using Network Flows to Aid in Cyber Defense
DSpin - Detecting Automatically Spun Content on the Web
Gyrus - A Framework for User-Intent Monitoring of Text-Based Networked Applications
Indexing Million of Packets per Second using GPUs
Multi-Label Learning with Millions of Labels - Recommending Advertiser Bid Phrases for Web Pages
Real-Time Handling of Network Monitoring Data Using a Data-Intensive Framework
Shingled Graph Disassembly - Finding the Undecideable Path
Synoptic Graphlet - Bridging the Gap between Supervised and Unsupervised Profiling of Host-level Network Traffic
Cyber Crime
Connected Colors - Unveiling the Structure of Criminal Networks
Image Matching for Branding Phishing Kit Images - slides
Image Matching for Branding Phishing Kit Images
Inside a Targeted Point-of-Sale Data Breach
Investigating Advanced Persistent Threat 1 (APT1)
Measuring pay-per-install - the Commoditization of Malware Distribution
Scambaiter - Understanding Targeted Nigerian Scams on Craigslist
Sherlock Holmes and the Case of the Advanced Persistent Threat
The Role of the Underground Market in Twitter Spam and Abuse
The Tangled Web of Password Reuse
Trafcking Fraudulent Accounts - The Role of the Underground Market in Twitter Spam and Abuse
Amplication Hell - Revisiting Network Protocols for DDoS Abuse
Defending The Enterprise, the Russian Way
Protecting a Moving Target - Addressing Web Application Concept Drift
Timing of Cyber Conflict
Jason SECURITYDATA SCIENCERES

@_date: 2014-07-21 16:31:35
@_author: Eugen Leitl 
@_subject: potential leak on Torpedo 
Please read if you use/depend on Tor. Never before seen FH information.
submitted 16 hours ago * by Deepthroat2 [+1]
Hello everyone, I have some information that I have been dying to share for
months, but due to the circumstances, and to avoid detection, I had to wait
for some time before I was able to safely make this post. My goal here is to
provide information that I know is credible and for the Tor community to use
it as they see fit, due to the nature of my work, and the severe penalties
associated with breaking the rules and giving out information you aren't
supposed too, I have no way of verifying or proving anything to you that I
say here, I understand if find me less than credible, however, this is
essentially a PSA, and you can take it for what it's worth to you.
Just about one year ago, the Tor community was shaken by a Firefox exploit
which utilized a javascript exploit and an old vulnerbility in the Tor
Browser Bundle to unmask some users of Freedom Hosting. There has been
rampant misinformation, and speculation to the point that I felt like pulling
my hair out, or just simply bursting out into laughter when reading some of
the outlandish claims made by people who have little to no idea what they are
talking about. Today, I will set the record straight.
The FH exploit was a government engineered, and deployed exploit that was
designed in response to former Director Mueller's fustration at an earlier
child pornography case in which the FBI was ridiculed for being unable to
ascertain the source of child pornography, for those who aren't familiar with
this case, it involved a man who had accessed child pornography by accident
on a Tor hidden service, and then brought his desktop computer to the office,
explaining what had happened and that he subsequently preformed a "Full wipe"
on the disk.
The agent who took the report had limited knowledge about Tor, however, at
the time he knew that any directed effort to identify a specific Tor user was
hopeless, and in the report he indicated that "There is currently no known
way to ascertain the location of a Tor user, thus, no investigative leads
exsist." This got leaked to the press, and they had a field day, hinting at
the incompetency of the Bureau. Needless to say, the FBI had it's ego hurt
quite badly by this public display of incompetency.
Then Director Mueller directed the CEOS (Child exploitation and obscenity
section) to find a way to penetrate the layers of protection provided by Tor,
and to come up with a fesible way to conduct a sting operation in order to
bring these people to justice. The FBI had previously conducted a sting on
viewers of child pornography in a case out of Nebraska, that resulted in the
arrest of about 25 people. This was the first successful take down of CP
consumers that were utilizing a Tor hidden service.
One of the errors that I see alot on these forums and others was that the
Nebraska take down was done in a similar fashion to the FH exploit, with the
code being deployed onto the pages of the boards, however, this is not the
case. From my understanding, the Nebraska field office was able to find the
actual server, take it over covertly, then upload a series of files that
purported to be child pornography, but actually contained nothing but
encrypted gibberish. They were video files that were embedded with code that
called back to a computer that recorded the IP address of the requestor, date
and time similar to the way windows media player attempts to recall album
information and cover art for music cds and such. These were files that the
user actually had to download and attempt to open. This is why the service
was run for weeks, and only 25 people were identified as users. This method
was described by the techs who deployed it as a "NIT" or "Network
Investigational Tool".
Now for Freedom Hosting....
The javascript exploit could not be deployed directly on the servers which
Mr. Marques was using due to either technical reasons, or legal requirements
by the AUSA in Maryland. So the decision was made to clone the services
exactly, and transport then to the home of the FBI CEOS in the Greenbelt
division of Maryland. This location was picked specifically because
sentencing in this district for Child Pornography crimes is more severe. It
was July 31st of 2013 when the exploit actually went live, and tried to
identify criminals. It was installed previously, however, there were
technical problems early on and the code had to be revised 3 times before it
was running as intended, it ran for about 11 days before being shut down.
The amount of people identified by this exploit is still a closely gaurded
secret, with only agents having a direct "Need to know" being privy to this
information. Howver, the victory dance was short lived as news started
flowing around that the evidence may not be admissible in court, due to the
manner in which it was collected, among other reasons. Although proper
warrants were issued, it would take atleast 4-7 years to comb through the
list of suspects, and question, arrest each one. The major problem is that
after about 12 months, the courts start to presume your evidence is
prejudicial to the defendant because you're supposed to have an indictment
and serve it on the defendant within 30 days, and that just wasn't possible.
You can request an extension of this time, however you must present a new,
fresh reason for doing so..."We still aren't ready" doesn't cut it. There is
no statue of limitations for the crime of "Accessing with intent to view
child pornography" so barring any other limitations, the FBI can come after
someone 10-15 years later.
The AUSA became uncomfortable with the prospects of his legal case against
the exploitees of FH and went to the US Attorney. There was disagreement as
to whether or not the evidence would be viable, however, the operation went
on anyways. One of the victims of the FH exploit was a man by the name of
Grant Klein from Vermont. The Bureau had made arrangements with the local
police for assistance with the raid (This is pretty much standard operation
procedure, and is done for the saftey of the agents, as well as to maintain
professional courtesy. Local cops get butt hurt when you arrest people on
their turf without them knowing).
The FBI had provided the local police with court documents and the affidavit
of arrest regarding the cirsumstances of Mr. Klein's warrant, which they
promptly posted onto their press release against the wishes of the FBI. This
resulted in the termination of atleast one employee from local PD.
He was raided and before even being asked a question ,he began spewing a
confession. His home was searched, and a desktop computer with no hard disk
was found, as well a laptop computer belonging to his wife Susan. There was
no illegal materials found on these, however, he had a smartphone in the
drawer of a nightstand which contained illegal images of minors. He was
arrested and charged with 3 seperate crimes.
To make a long story short, the FH related charges were dropped because the
FBI had crossed a legal line by offering up child pornography de novo, by
shutting down the server, then bringing it back online hosting real CP. They
were uncomfortable with the prospects of this case, and were able to use a
leon good faith exception to admit the evidence they found on his phone to
make a single possession charge stick, however, he agreed to plead guilty.
The rest of the leads which lead to foreign nationals were then distributed
accordingly to the various LEA's.
Also, earlier this wekk, the UK police arrested 660 people as part of
Operation Notarise.
The operation name of the FBI takedown in Nebraska was "Operation Torpedo"
This was a cute poke at both the method they used, and the users they
Torpedo - Navy missile
Tor Pedo - Tor Pedophile.
moar comments on Reddit

@_date: 2014-07-22 13:45:36
@_author: Eugen Leitl 
@_subject: HackRF will likely start shipping in August 
(the tinfoilhatterati will understand and rejoice)
HackRF One is now available for pre-order From: HakShop (US)
NooElec (US/CA)
Hacker Warehouse (US)
Ada's Technical Books (US)
Wall of Sheep (US)
Store4Geeks (SE)
Passion Radio Shop (FR)
Passion Radio Shop UK (UK)
TAPR (US)
iSource Asia (CN)
WiMo (DE)
Pre-ordered units will ship immediately after all rewards have shipped to Kickstarter backers, estimated July 2014. For the latest information on development and manufacturing, follow the Kickstarter updates.

@_date: 2014-07-23 12:13:28
@_author: Eugen Leitl 
@_subject: Gruveo, more secure skype alternative? 
RetroShare has quite good P2P audio. It's not properly audited though,
caveat emptor.

@_date: 2014-07-23 14:22:36
@_author: Eugen Leitl 
@_subject: Tor developers vow to fix bug that can uncloak users 
Tor developers vow to fix bug that can uncloak users
Weakness was topic of talk abruptly pulled from security conference.
by Dan Goodin - July 22 2014, 8:15pm CEST
Developers of the Tor privacy service say they're close to fixing a weakness
that researchers for an abruptly canceled conference presentation said
provides a low-cost way for adversaries to deanonymize hundreds of thousands
of users.
The talk previously scheduled for next month's Black Hat security conference
in Las Vegas was titled "You Don't Have to be the NSA to Break Tor:
Deanonymizing Users on a Budget." The abstract said that the hack cost less
than $3,000 and could uncloak hundreds of thousands of users. On Monday,
Black Hat organizers said the presentation was canceled at the request of
attorneys from Carnegie Mellon University (CMU), where the researchers were
employed, as well as the Software Engineering Institute (SEI). The attorneys
said only that the materials to be presented "have not yet been approved by
CMU/SEI for public release." Researchers Alexander Volynkin and Michael
McCord have yet to explain why their talk was pulled.
Tor officials responded by saying that they're working on an update for
individual Tor relay nodes that will close the unspecified security hole.
"Based on our current plans, we'll be putting out a fix that relays can apply
that should close the particular bug they found," Tor project leader Roger
Dingledine wrote in an e-mail to Tor users. "The bug is a nice bug, but it
isn't the end of the world. And of course these things are never as simple as
'close that one bug and you're 100% safe.'"
He said the fix was complicated because the researchers didn't provide all
the technical details when privately informing Tor officials of the
"We've been trying to find delicate ways to explain that we think we know
what they did, but also it sure would have been smoother if they'd opted to
tell us everything," he wrote. "The main reason for trying to be delicate is
that I don't want to discourage future researchers from telling us about neat
things that they find. I'm currently waiting for them to answer their mail so
I can proceed."
In a previous e-mail, Dingledine said Tor developers "informally" received
some materials related to the vulnerability. He went on to say Tor officials
played no role in the cancellation of the Black Hat talk.
"We did not ask Black Hat or CERT to cancel the talk. We did (and still do)
have questions for the presenter and for CERT about some aspects of the
research, but we had no idea the talk would be pulled before the announcement
was made," he wrote.
CMU is affiliated with CERT, which coordinates security disclosures between
researchers and affected parties. A CMU spokesman contacted Monday didn't
elaborate on the reasons for pulling the talk.

@_date: 2014-07-24 16:04:24
@_author: Eugen Leitl 
@_subject: Tails vulnerability specific to I2P, not Tor 
SILVER BULLETS AND FAIRY TAILS
This week we made mention on Twitter of a zero-day vulnerability weve unearthed that affects the popular Tails operating system. As the Tails website states:
Tails is a live operating system, that you can start on almost any computer from a DVD, USB stick, or SD card. It aims at preserving your privacy and anonymity, and helps you to:
use the Internet anonymously and circumvent censorship;
all connections to the Internet are forced to go through the Tor network;
leave no trace on the computer you are using unless you ask it explicitly;
use state-of-the-art cryptographic tools to encrypt your files, emails and instant messaging.
This software was largely popularized due to the fact that it was used by whistleblower Edward Snowden. Since then, the OS has garnered much attention and use by a wide range of those seeking anonymity on the Internet.
We publicized the fact that weve discovered these issues for a very simple reason: no user should put full trust into any particular security solution. By bringing to light the fact that we have found verifiable flaws in such a widely trusted piece of code, we hope to remind the Tails userbase that no software is infallible. Even when the issues weve found are fixed by the Tails team, the community should keep in mind that there are most certainly other flaws still present and likely known to others.
Our customers use our information for both offensive and defensive purposes to better protect themselves and others. Providing a wide variety of exploit software we help penetration testers effectively test network security and incident response teams. One high profile example occurred last year when Facebook used a zero-day vulnerability to test their teams response to a zero-day attack. The information we provide is also leveraged in defensive purposes providing companies with well documented research for use in IDS and AV signatures for previously unknown threats. We at Exodus are able to do what many software projects cannot, perform security code audits and find exploitable vulnerabilities releasing them to the public.
The Vulnerable Component
The vulnerability we will be disclosing is specific to I2P. I2P currently boasts about 30,000 active peers. Since I2P has been bundled with Tails since version 0.7, Tails is by far the most widely adopted I2P usage. The I2P vulnerability works on default, fully patched installation of Tails. No settings or configurations need to be changed for the exploit to work. I2P is preconfigured so that all .i2p TLD sites are routed through the I2P network. At a high level I2P traffic is message based similar to IP packets. All communication is encrypted end to end with a total of four layers of encryption. I2P routers (end points) act as cryptographic identifiers, similar to a pair of public keys. I2P is a packet switched network, instead of circuit switched like Tor. This means transparent load balancing of packets across multiple peers. I2P is fully distributed with no centralized resources. There is no distinct separation of servers to nodes, this architecture helps eliminate single points of failure.
To lend credence to our claims we have created a video that demonstrates de-anonymizing a Tails user:
0:00:00,000 > 0:00:10,400: Demonstrating IP on listening server, Turning on listening server
0:00:19,000 > 0:00:25,400: Tails user visiting website icanhazip.com which shows the anonymized IP address
0:00:36,000 > 0:00:49,400: Showing that were indeed using the latest Tails build 1.1
0:00:50,000 > 0:01:03,400: I2P address being resolved, proof of concept malicious payload being delivered
0:01:30,000 > 0:01:40,400: Listening server retrieves the Tails users de-anonymized IP address (Austin RoadRunner ISP)
Note on Disclosure
Disclosure of vulnerabilities takes many forms, particularly their shape is adapted to the landscape that the platform is used upon. In the past at Exodus Intelligence, weve felt that significant vulnerabilities have been disregarded and have not had the requisite exposure. Through appropriate airing of the issue, we feel that users of such security platforms may come to understand the risks in base-level trust. Even further we hope to break the mold of unconditional trust in a platform. Users should question the tools they use, they should go even further to understand the underlying mechanisms that interlock to grant them security. Its not enough to have faith upon security, rather to have an understanding of it. If the public thinks Exodus is one of a few entities finding bugs in software, they are grossly misinformed. As is the case with all vulnerabilities we report to vendors, we do not ask for any remuneration. All flaws that we give to vendors are given free of charge. All accusations of extortion perpetuated by those unfamiliar with our business model are completely unfounded. As of publication of this blog post the Tails team and the I2P team have both received all the relevant details and exploit code they require to remediate the vulnerabilities weve discovered.
Recently a high profile talk on de-anonymization Tor users was pulled from Blackhat due to legal issues. Their talk outlined with a budget of $3000 with some powerful servers and multiple gigabit links they were able to de-anonymize hundreds of thousands of users in a couple of months. Exodus decided to pick up where this talk left off by letting the community know that there are many other vectors for de-anonymization. The vulnerability we have found is able to perform remote code execution with a specially crafted payload. This payload can be customized to unmask a user and show the public IP address in which the user connected from within a couple of seconds.
Stay Tuned
Part two of this blog post will present a technical discussion of the vulnerability. This will be posted once we have confirmed the vulnerabilities in I2P are patched and have been incorporated into Tails.

@_date: 2014-07-28 18:20:42
@_author: Eugen Leitl 
@_subject: Alleged "microkernel mathematically proven to be bug free" 
I'm on their announcement list. Good news, question is who's going to
pick it up and build a distro around that. Anyone here use Qubes OS?

@_date: 2014-03-13 11:00:36
@_author: Eugen Leitl 
@_subject: TURBINE 
Above is a declaration of war. Here's a modest counterproposal.
What do intelligence services fear most? Like cockroaches, they hate the light. Public scrutiny is their permethrin. So what we need is a hidden service (Tahoe LAFS as distributed
storage backend run by many volunteers world-wide) where annotated collection of personal information can be crowdsourced. You can start collecting license plates and match them to addresses and Let's doxx the spooks. All intelligence services, all countries.
Make sure to vet data against malicious contamination. Publish
them all, and let God sort them out.
P.S. If you intend to do it, make sure you never talk about it in
public. Just publish code anonymously, and invite collaborators
after a closed beta. Make it easy to use, make it secure. Good luck.

@_date: 2014-03-13 17:35:42
@_author: Eugen Leitl 
@_subject: TURBINE 
Actually, we demonstrably have a case of collusion among rogue intelligence services of several countries for the purpose
of undermining the democratic order and the constitution of
said countries, which is high treason, if you care about such
trifles. If nobody else is taking measures (official stonewalling is slowly getting there, making such individuals actually potentially complicit in high treason) GG Art 20 (arguably, also Art 32 StGB) applies and taking countermeasures by individual citizens is lawful. Always IANAL, of course.
So if the state is not taking measures against surveillance
gear on US embassies or unlawful data collection by foreign
intelligence agencies, individuals are by law allowed to.
See e.g. Doxxing foreign (of course, everybody is a foreigner, somewhere) intelligence and special services appears a rather mild measure, under the circumstances.

@_date: 2014-03-14 14:45:48
@_author: Eugen Leitl 
@_subject: TURBINE 
Au contraire, name and shame does work for criminals. Consider
drone operators or black ops being outed, or NSA cybercriminals
published with full name and address. I assure they're not going
to take it lightly any more than sex offenders want to see
their mugs and full addresses and map locations published.  I agree, but it's a different kettle of fish entirely. The probability
overlap of being both willing to risk and able (to be hired) is negligible. Plus security measures are much higher after the
last heist. Not to say impossible, but personal risk is much higher,
and potential ROI is considerably lower.
That would be nice. But realistically only a very rate exception.
However, intelligence people do not operate in a vacuum. They use
the same public infrastructure as you. They don't teleport in and
out of their facilities. Collecting and crosscorrelating publicly
available data is powerful while invidual risk is low to zero.
Leaking large batches is safe if you follow standard security

@_date: 2014-03-13 11:00:36
@_author: Eugen Leitl 
@_subject: TURBINE 
Above is a declaration of war. Here's a modest counterproposal.
What do intelligence services fear most? Like cockroaches, they hate the light. Public scrutiny is their permethrin. So what we need is a hidden service (Tahoe LAFS as distributed
storage backend run by many volunteers world-wide) where annotated collection of personal information can be crowdsourced. You can start collecting license plates and match them to addresses and Let's doxx the spooks. All intelligence services, all countries.
Make sure to vet data against malicious contamination. Publish
them all, and let God sort them out.
P.S. If you intend to do it, make sure you never talk about it in
public. Just publish code anonymously, and invite collaborators
after a closed beta. Make it easy to use, make it secure. Good luck.

@_date: 2014-03-13 17:35:42
@_author: Eugen Leitl 
@_subject: TURBINE 
Actually, we demonstrably have a case of collusion among rogue intelligence services of several countries for the purpose
of undermining the democratic order and the constitution of
said countries, which is high treason, if you care about such
trifles. If nobody else is taking measures (official stonewalling is slowly getting there, making such individuals actually potentially complicit in high treason) GG Art 20 (arguably, also Art 32 StGB) applies and taking countermeasures by individual citizens is lawful. Always IANAL, of course.
So if the state is not taking measures against surveillance
gear on US embassies or unlawful data collection by foreign
intelligence agencies, individuals are by law allowed to.
See e.g. Doxxing foreign (of course, everybody is a foreigner, somewhere) intelligence and special services appears a rather mild measure, under the circumstances.

@_date: 2014-03-14 14:45:48
@_author: Eugen Leitl 
@_subject: TURBINE 
Au contraire, name and shame does work for criminals. Consider
drone operators or black ops being outed, or NSA cybercriminals
published with full name and address. I assure they're not going
to take it lightly any more than sex offenders want to see
their mugs and full addresses and map locations published.  I agree, but it's a different kettle of fish entirely. The probability
overlap of being both willing to risk and able (to be hired) is negligible. Plus security measures are much higher after the
last heist. Not to say impossible, but personal risk is much higher,
and potential ROI is considerably lower.
That would be nice. But realistically only a very rate exception.
However, intelligence people do not operate in a vacuum. They use
the same public infrastructure as you. They don't teleport in and
out of their facilities. Collecting and crosscorrelating publicly
available data is powerful while invidual risk is low to zero.
Leaking large batches is safe if you follow standard security

@_date: 2014-03-13 11:00:36
@_author: Eugen Leitl 
@_subject: TURBINE 
Above is a declaration of war. Here's a modest counterproposal.
What do intelligence services fear most? Like cockroaches, they hate the light. Public scrutiny is their permethrin. So what we need is a hidden service (Tahoe LAFS as distributed
storage backend run by many volunteers world-wide) where annotated collection of personal information can be crowdsourced. You can start collecting license plates and match them to addresses and Let's doxx the spooks. All intelligence services, all countries.
Make sure to vet data against malicious contamination. Publish
them all, and let God sort them out.
P.S. If you intend to do it, make sure you never talk about it in
public. Just publish code anonymously, and invite collaborators
after a closed beta. Make it easy to use, make it secure. Good luck.

@_date: 2014-03-13 17:35:42
@_author: Eugen Leitl 
@_subject: TURBINE 
Actually, we demonstrably have a case of collusion among rogue intelligence services of several countries for the purpose
of undermining the democratic order and the constitution of
said countries, which is high treason, if you care about such
trifles. If nobody else is taking measures (official stonewalling is slowly getting there, making such individuals actually potentially complicit in high treason) GG Art 20 (arguably, also Art 32 StGB) applies and taking countermeasures by individual citizens is lawful. Always IANAL, of course.
So if the state is not taking measures against surveillance
gear on US embassies or unlawful data collection by foreign
intelligence agencies, individuals are by law allowed to.
See e.g. Doxxing foreign (of course, everybody is a foreigner, somewhere) intelligence and special services appears a rather mild measure, under the circumstances.

@_date: 2014-03-14 14:45:48
@_author: Eugen Leitl 
@_subject: TURBINE 
Au contraire, name and shame does work for criminals. Consider
drone operators or black ops being outed, or NSA cybercriminals
published with full name and address. I assure they're not going
to take it lightly any more than sex offenders want to see
their mugs and full addresses and map locations published.  I agree, but it's a different kettle of fish entirely. The probability
overlap of being both willing to risk and able (to be hired) is negligible. Plus security measures are much higher after the
last heist. Not to say impossible, but personal risk is much higher,
and potential ROI is considerably lower.
That would be nice. But realistically only a very rate exception.
However, intelligence people do not operate in a vacuum. They use
the same public infrastructure as you. They don't teleport in and
out of their facilities. Collecting and crosscorrelating publicly
available data is powerful while invidual risk is low to zero.
Leaking large batches is safe if you follow standard security

@_date: 2014-11-03 13:40:15
@_author: Eugen Leitl 
@_subject: Brain decoder can eavesdrop on your inner voice 
Brain decoder can eavesdrop on your inner voice
29 October 2014 by Helen Thomson
Magazine issue 2993. Subscribe and save
For similar stories, visit the The Human Brain Topic Guide
As you read this, your neurons are firing  that brain activity can now
be decoded to reveal the silent words in your head
TALKING to yourself used to be a strictly private pastime. That's no longer
the case  researchers have eavesdropped on our internal monologue for
the first time. The achievement is a step towards helping people who cannot
physically speak communicate with the outside world.
"If you're reading text in a newspaper or a book, you hear a voice in your
own head," says Brian Pasley at the University of California, Berkeley.
"We're trying to decode the brain activity related to that voice to create a
medical prosthesis that can allow someone who is paralysed or locked in to
When you hear someone speak, sound waves activate sensory neurons in your
inner ear. These neurons pass information to areas of the brain where
different aspects of the sound are extracted and interpreted as words.
In a previous study, Pasley and his colleagues recorded brain activity in
people who already had electrodes implanted in their brain to treat epilepsy,
while they listened to speech. The team found that certain neurons in the
brain's temporal lobe were only active in response to certain aspects of
sound, such as a specific frequency. One set of neurons might only react to
sound waves that had a frequency of 1000 hertz, for example, while another
set only cares about those at 2000 hertz. Armed with this knowledge, the team
built an algorithm that could decode the words heard based on neural activity
aloneMovie Camera (PLoS Biology, doi.org/fzv269).
The team hypothesised that hearing speech and thinking to oneself might spark
some of the same neural signatures in the brain. They supposed that an
algorithm trained to identify speech heard out loud might also be able to
identify words that are thought.
To test the idea, they recorded brain activity in another seven people
undergoing epilepsy surgery, while they looked at a screen that displayed
text from either the Gettysburg Address, John F. Kennedy's inaugural address
or the nursery rhyme Humpty Dumpty.
Each participant was asked to read the text aloud, read it silently in their
head and then do nothing. While they read the text out loud, the team worked
out which neurons were reacting to what aspects of speech and generated a
personalised decoder to interpret this information. The decoder was used to
create a spectrogram  a visual representation of the different
frequencies of sound waves heard over time. As each frequency correlates to
specific sounds in each word spoken, the spectrogram can be used to recreate
what had been said. They then applied the decoder to the brain activity that
occurred while the participants read the passages silently to themselves (see
Despite the neural activity from imagined or actual speech differing
slightly, the decoder was able to reconstruct which words several of the
volunteers were thinking, using neural activity alone (Frontiers in
Neuroengineering, doi.org/whb).
The algorithm isn't perfect, says Stephanie Martin, who worked on the study
with Pasley. "We got significant results but it's not good enough yet to
build a device."
In practice, if the decoder is to be used by people who are unable to speak
it would have to be trained on what they hear rather than their own speech.
"We don't think it would be an issue to train the decoder on heard speech
because they share overlapping brain areas," says Martin.
The team is now fine-tuning their algorithms, by looking at the neural
activity associated with speaking rate and different pronunciations of the
same word, for example. "The bar is very high," says Pasley. "Its preliminary
data, and we're still working on making it better."
The team have also turned their hand to predicting what songs a person is
listening to by playing lots of Pink Floyd to volunteers, and then working
out which neurons respond to what aspects of the music. "Sound is sound,"
says Pasley. "It all helps us understand different aspects of how the brain
processes it."
"Ultimately, if we understand covert speech well enough, we'll be able to
create a medical prosthesis that could help someone who is paralysed, or
locked in and can't speak," he says.
Several other researchers are also investigating ways to read the human mind.
Some can tell what pictures a person is looking at, others have worked out
what neural activity represents certain concepts in the brain, and one team
has even produced crude reproductions of movie clips that someone is watching
just by analysing their brain activity. So is it possible to put it all
together to create one multisensory mind-reading device?
In theory, yes, says Martin, but it would be extraordinarily complicated. She
says you would need a huge amount of data for each thing you are trying to
predict. "It would be really interesting to look into. It would allow us to
predict what people are doing or thinking," she says. "But we need individual
decoders that work really well before combining different senses."
This article appeared in print under the headline "Hearing our inner voice"

@_date: 2014-11-04 18:36:15
@_author: Eugen Leitl 
@_subject: Crypto War Redux 
There's also  which could use some tender love
and caring, and be it just by way of crossposts from the usual suspect subreddits.

@_date: 2014-11-11 13:39:23
@_author: Eugen Leitl 
@_subject: OpenBazaar Beta 3.0 =?utf-8?B?4oCcVGFicml6?= =?utf-8?B?4oCd?= is 
Beta 3.0 Tabriz is released
November 10, 2014  Sam Patterson
The third OpenBazaar beta release is now available. With this release, were starting the tradition of naming our releases after great bazaars from all around the world, with the first being Tabriz, a market in Iran which is one of the oldest bazaars in the Middle East.
Tabriz represents a significant amount of work for our developers, with more than 350 commits, and merging more than 70 pull requests from the community. We thank everyone who contributed.
One of the major improvements in Tabriz is the ability to run on Windows. If youd like to become a beta tester, download the Windows binary [signature here], unzip the file and run the OpenBazaar.exe file. In case our site goes down, you can get a torrent with this magnet link.
For a full list of changes in Tabriz, check out the changelog.
If you want to become a beta tester and are running on Mac or Linux, follow these instructions in your terminal:
If you dont have Git installed on Linux, open terminal (Ctrl+Alt+T) and type:
sudo apt-get install git
If you dont have Git installed for OSX, download here and install.
Now run:
git clone Once thats complete, change directories:
cd OpenBazaar
Run the configure with this command:
If youve already been running OpenBazaar, you need to update the code. In terminal, run the following commands:
git pull
To start your node:
./openbazaar start
To stop your node:
./openbazaar stop
To get help on the commands you can use with OpenBazaar:
./openbazaar help
If you find a bug, please let us know on our Github or on the bug reporting thread in our subreddit.
3.0 beta Tabriz

@_date: 2014-11-13 09:52:35
@_author: Eugen Leitl 
@_subject: Lantern: One Device, Free Data From Space Forever 
Global access to the Internets best content on your mobile device. Anonymous. Uncensored. Free.
 Chicago, Illinois, United States   Technology
A Library In Every Pocket
The Short Wave Radio for the Digital Age. -- Fast Company
A Tiny Satellite Dish That Brings Info to the Worlds Deadzones. -- Wired
Outernet aims to provide data to the net unconnected. -- BBC
"Billions of people around the world don't have access to the Internet, so the next big thing is trying to connect the world." -- CNN
Lantern is an anonymous portable library that constantly receives free data from space.
Like the water we drink or the air we breathe, the information we consume feeds the very essence of what it means to be human. Lantern establishes a new baseline of human knowledge. We are not fixing the world for people, we are giving them the information they need to fix it themselves.
Lantern continuously receives radio waves broadcast by Outernet from space. Lantern turns the signal into digital files, like webpages, news articles, ebooks, videos, and music. Lantern can receive and store any type of digital file on its internal drive. To view the content stored in Lantern, turn on the Wi-Fi hotspot and connect to Lantern with any Wi-Fi enabled device. All you need is a browser.
Oh, and Outernet is free to use, always.

@_date: 2014-11-03 13:40:15
@_author: Eugen Leitl 
@_subject: Brain decoder can eavesdrop on your inner voice 
Brain decoder can eavesdrop on your inner voice
29 October 2014 by Helen Thomson
Magazine issue 2993. Subscribe and save
For similar stories, visit the The Human Brain Topic Guide
As you read this, your neurons are firing  that brain activity can now
be decoded to reveal the silent words in your head
TALKING to yourself used to be a strictly private pastime. That's no longer
the case  researchers have eavesdropped on our internal monologue for
the first time. The achievement is a step towards helping people who cannot
physically speak communicate with the outside world.
"If you're reading text in a newspaper or a book, you hear a voice in your
own head," says Brian Pasley at the University of California, Berkeley.
"We're trying to decode the brain activity related to that voice to create a
medical prosthesis that can allow someone who is paralysed or locked in to
When you hear someone speak, sound waves activate sensory neurons in your
inner ear. These neurons pass information to areas of the brain where
different aspects of the sound are extracted and interpreted as words.
In a previous study, Pasley and his colleagues recorded brain activity in
people who already had electrodes implanted in their brain to treat epilepsy,
while they listened to speech. The team found that certain neurons in the
brain's temporal lobe were only active in response to certain aspects of
sound, such as a specific frequency. One set of neurons might only react to
sound waves that had a frequency of 1000 hertz, for example, while another
set only cares about those at 2000 hertz. Armed with this knowledge, the team
built an algorithm that could decode the words heard based on neural activity
aloneMovie Camera (PLoS Biology, doi.org/fzv269).
The team hypothesised that hearing speech and thinking to oneself might spark
some of the same neural signatures in the brain. They supposed that an
algorithm trained to identify speech heard out loud might also be able to
identify words that are thought.
To test the idea, they recorded brain activity in another seven people
undergoing epilepsy surgery, while they looked at a screen that displayed
text from either the Gettysburg Address, John F. Kennedy's inaugural address
or the nursery rhyme Humpty Dumpty.
Each participant was asked to read the text aloud, read it silently in their
head and then do nothing. While they read the text out loud, the team worked
out which neurons were reacting to what aspects of speech and generated a
personalised decoder to interpret this information. The decoder was used to
create a spectrogram  a visual representation of the different
frequencies of sound waves heard over time. As each frequency correlates to
specific sounds in each word spoken, the spectrogram can be used to recreate
what had been said. They then applied the decoder to the brain activity that
occurred while the participants read the passages silently to themselves (see
Despite the neural activity from imagined or actual speech differing
slightly, the decoder was able to reconstruct which words several of the
volunteers were thinking, using neural activity alone (Frontiers in
Neuroengineering, doi.org/whb).
The algorithm isn't perfect, says Stephanie Martin, who worked on the study
with Pasley. "We got significant results but it's not good enough yet to
build a device."
In practice, if the decoder is to be used by people who are unable to speak
it would have to be trained on what they hear rather than their own speech.
"We don't think it would be an issue to train the decoder on heard speech
because they share overlapping brain areas," says Martin.
The team is now fine-tuning their algorithms, by looking at the neural
activity associated with speaking rate and different pronunciations of the
same word, for example. "The bar is very high," says Pasley. "Its preliminary
data, and we're still working on making it better."
The team have also turned their hand to predicting what songs a person is
listening to by playing lots of Pink Floyd to volunteers, and then working
out which neurons respond to what aspects of the music. "Sound is sound,"
says Pasley. "It all helps us understand different aspects of how the brain
processes it."
"Ultimately, if we understand covert speech well enough, we'll be able to
create a medical prosthesis that could help someone who is paralysed, or
locked in and can't speak," he says.
Several other researchers are also investigating ways to read the human mind.
Some can tell what pictures a person is looking at, others have worked out
what neural activity represents certain concepts in the brain, and one team
has even produced crude reproductions of movie clips that someone is watching
just by analysing their brain activity. So is it possible to put it all
together to create one multisensory mind-reading device?
In theory, yes, says Martin, but it would be extraordinarily complicated. She
says you would need a huge amount of data for each thing you are trying to
predict. "It would be really interesting to look into. It would allow us to
predict what people are doing or thinking," she says. "But we need individual
decoders that work really well before combining different senses."
This article appeared in print under the headline "Hearing our inner voice"

@_date: 2014-11-04 18:36:15
@_author: Eugen Leitl 
@_subject: Crypto War Redux 
There's also  which could use some tender love
and caring, and be it just by way of crossposts from the usual suspect subreddits.

@_date: 2014-11-11 13:39:23
@_author: Eugen Leitl 
@_subject: OpenBazaar Beta 3.0 =?utf-8?B?4oCcVGFicml6?= =?utf-8?B?4oCd?= is 
Beta 3.0 Tabriz is released
November 10, 2014  Sam Patterson
The third OpenBazaar beta release is now available. With this release, were starting the tradition of naming our releases after great bazaars from all around the world, with the first being Tabriz, a market in Iran which is one of the oldest bazaars in the Middle East.
Tabriz represents a significant amount of work for our developers, with more than 350 commits, and merging more than 70 pull requests from the community. We thank everyone who contributed.
One of the major improvements in Tabriz is the ability to run on Windows. If youd like to become a beta tester, download the Windows binary [signature here], unzip the file and run the OpenBazaar.exe file. In case our site goes down, you can get a torrent with this magnet link.
For a full list of changes in Tabriz, check out the changelog.
If you want to become a beta tester and are running on Mac or Linux, follow these instructions in your terminal:
If you dont have Git installed on Linux, open terminal (Ctrl+Alt+T) and type:
sudo apt-get install git
If you dont have Git installed for OSX, download here and install.
Now run:
git clone Once thats complete, change directories:
cd OpenBazaar
Run the configure with this command:
If youve already been running OpenBazaar, you need to update the code. In terminal, run the following commands:
git pull
To start your node:
./openbazaar start
To stop your node:
./openbazaar stop
To get help on the commands you can use with OpenBazaar:
./openbazaar help
If you find a bug, please let us know on our Github or on the bug reporting thread in our subreddit.
3.0 beta Tabriz

@_date: 2014-11-13 09:52:35
@_author: Eugen Leitl 
@_subject: Lantern: One Device, Free Data From Space Forever 
Global access to the Internets best content on your mobile device. Anonymous. Uncensored. Free.
 Chicago, Illinois, United States   Technology
A Library In Every Pocket
The Short Wave Radio for the Digital Age. -- Fast Company
A Tiny Satellite Dish That Brings Info to the Worlds Deadzones. -- Wired
Outernet aims to provide data to the net unconnected. -- BBC
"Billions of people around the world don't have access to the Internet, so the next big thing is trying to connect the world." -- CNN
Lantern is an anonymous portable library that constantly receives free data from space.
Like the water we drink or the air we breathe, the information we consume feeds the very essence of what it means to be human. Lantern establishes a new baseline of human knowledge. We are not fixing the world for people, we are giving them the information they need to fix it themselves.
Lantern continuously receives radio waves broadcast by Outernet from space. Lantern turns the signal into digital files, like webpages, news articles, ebooks, videos, and music. Lantern can receive and store any type of digital file on its internal drive. To view the content stored in Lantern, turn on the Wi-Fi hotspot and connect to Lantern with any Wi-Fi enabled device. All you need is a browser.
Oh, and Outernet is free to use, always.

@_date: 2014-11-03 13:40:15
@_author: Eugen Leitl 
@_subject: Brain decoder can eavesdrop on your inner voice 
Brain decoder can eavesdrop on your inner voice
29 October 2014 by Helen Thomson
Magazine issue 2993. Subscribe and save
For similar stories, visit the The Human Brain Topic Guide
As you read this, your neurons are firing  that brain activity can now
be decoded to reveal the silent words in your head
TALKING to yourself used to be a strictly private pastime. That's no longer
the case  researchers have eavesdropped on our internal monologue for
the first time. The achievement is a step towards helping people who cannot
physically speak communicate with the outside world.
"If you're reading text in a newspaper or a book, you hear a voice in your
own head," says Brian Pasley at the University of California, Berkeley.
"We're trying to decode the brain activity related to that voice to create a
medical prosthesis that can allow someone who is paralysed or locked in to
When you hear someone speak, sound waves activate sensory neurons in your
inner ear. These neurons pass information to areas of the brain where
different aspects of the sound are extracted and interpreted as words.
In a previous study, Pasley and his colleagues recorded brain activity in
people who already had electrodes implanted in their brain to treat epilepsy,
while they listened to speech. The team found that certain neurons in the
brain's temporal lobe were only active in response to certain aspects of
sound, such as a specific frequency. One set of neurons might only react to
sound waves that had a frequency of 1000 hertz, for example, while another
set only cares about those at 2000 hertz. Armed with this knowledge, the team
built an algorithm that could decode the words heard based on neural activity
aloneMovie Camera (PLoS Biology, doi.org/fzv269).
The team hypothesised that hearing speech and thinking to oneself might spark
some of the same neural signatures in the brain. They supposed that an
algorithm trained to identify speech heard out loud might also be able to
identify words that are thought.
To test the idea, they recorded brain activity in another seven people
undergoing epilepsy surgery, while they looked at a screen that displayed
text from either the Gettysburg Address, John F. Kennedy's inaugural address
or the nursery rhyme Humpty Dumpty.
Each participant was asked to read the text aloud, read it silently in their
head and then do nothing. While they read the text out loud, the team worked
out which neurons were reacting to what aspects of speech and generated a
personalised decoder to interpret this information. The decoder was used to
create a spectrogram  a visual representation of the different
frequencies of sound waves heard over time. As each frequency correlates to
specific sounds in each word spoken, the spectrogram can be used to recreate
what had been said. They then applied the decoder to the brain activity that
occurred while the participants read the passages silently to themselves (see
Despite the neural activity from imagined or actual speech differing
slightly, the decoder was able to reconstruct which words several of the
volunteers were thinking, using neural activity alone (Frontiers in
Neuroengineering, doi.org/whb).
The algorithm isn't perfect, says Stephanie Martin, who worked on the study
with Pasley. "We got significant results but it's not good enough yet to
build a device."
In practice, if the decoder is to be used by people who are unable to speak
it would have to be trained on what they hear rather than their own speech.
"We don't think it would be an issue to train the decoder on heard speech
because they share overlapping brain areas," says Martin.
The team is now fine-tuning their algorithms, by looking at the neural
activity associated with speaking rate and different pronunciations of the
same word, for example. "The bar is very high," says Pasley. "Its preliminary
data, and we're still working on making it better."
The team have also turned their hand to predicting what songs a person is
listening to by playing lots of Pink Floyd to volunteers, and then working
out which neurons respond to what aspects of the music. "Sound is sound,"
says Pasley. "It all helps us understand different aspects of how the brain
processes it."
"Ultimately, if we understand covert speech well enough, we'll be able to
create a medical prosthesis that could help someone who is paralysed, or
locked in and can't speak," he says.
Several other researchers are also investigating ways to read the human mind.
Some can tell what pictures a person is looking at, others have worked out
what neural activity represents certain concepts in the brain, and one team
has even produced crude reproductions of movie clips that someone is watching
just by analysing their brain activity. So is it possible to put it all
together to create one multisensory mind-reading device?
In theory, yes, says Martin, but it would be extraordinarily complicated. She
says you would need a huge amount of data for each thing you are trying to
predict. "It would be really interesting to look into. It would allow us to
predict what people are doing or thinking," she says. "But we need individual
decoders that work really well before combining different senses."
This article appeared in print under the headline "Hearing our inner voice"

@_date: 2014-11-04 18:36:15
@_author: Eugen Leitl 
@_subject: Crypto War Redux 
There's also  which could use some tender love
and caring, and be it just by way of crossposts from the usual suspect subreddits.

@_date: 2014-11-11 13:39:23
@_author: Eugen Leitl 
@_subject: OpenBazaar Beta 3.0 =?utf-8?B?4oCcVGFicml6?= =?utf-8?B?4oCd?= is 
Beta 3.0 Tabriz is released
November 10, 2014  Sam Patterson
The third OpenBazaar beta release is now available. With this release, were starting the tradition of naming our releases after great bazaars from all around the world, with the first being Tabriz, a market in Iran which is one of the oldest bazaars in the Middle East.
Tabriz represents a significant amount of work for our developers, with more than 350 commits, and merging more than 70 pull requests from the community. We thank everyone who contributed.
One of the major improvements in Tabriz is the ability to run on Windows. If youd like to become a beta tester, download the Windows binary [signature here], unzip the file and run the OpenBazaar.exe file. In case our site goes down, you can get a torrent with this magnet link.
For a full list of changes in Tabriz, check out the changelog.
If you want to become a beta tester and are running on Mac or Linux, follow these instructions in your terminal:
If you dont have Git installed on Linux, open terminal (Ctrl+Alt+T) and type:
sudo apt-get install git
If you dont have Git installed for OSX, download here and install.
Now run:
git clone Once thats complete, change directories:
cd OpenBazaar
Run the configure with this command:
If youve already been running OpenBazaar, you need to update the code. In terminal, run the following commands:
git pull
To start your node:
./openbazaar start
To stop your node:
./openbazaar stop
To get help on the commands you can use with OpenBazaar:
./openbazaar help
If you find a bug, please let us know on our Github or on the bug reporting thread in our subreddit.
3.0 beta Tabriz

@_date: 2014-11-13 09:52:35
@_author: Eugen Leitl 
@_subject: Lantern: One Device, Free Data From Space Forever 
Global access to the Internets best content on your mobile device. Anonymous. Uncensored. Free.
 Chicago, Illinois, United States   Technology
A Library In Every Pocket
The Short Wave Radio for the Digital Age. -- Fast Company
A Tiny Satellite Dish That Brings Info to the Worlds Deadzones. -- Wired
Outernet aims to provide data to the net unconnected. -- BBC
"Billions of people around the world don't have access to the Internet, so the next big thing is trying to connect the world." -- CNN
Lantern is an anonymous portable library that constantly receives free data from space.
Like the water we drink or the air we breathe, the information we consume feeds the very essence of what it means to be human. Lantern establishes a new baseline of human knowledge. We are not fixing the world for people, we are giving them the information they need to fix it themselves.
Lantern continuously receives radio waves broadcast by Outernet from space. Lantern turns the signal into digital files, like webpages, news articles, ebooks, videos, and music. Lantern can receive and store any type of digital file on its internal drive. To view the content stored in Lantern, turn on the Wi-Fi hotspot and connect to Lantern with any Wi-Fi enabled device. All you need is a browser.
Oh, and Outernet is free to use, always.

@_date: 2014-10-01 12:45:56
@_author: Eugen Leitl 
@_subject: BitNation 
BITNATION IS A FULLY INCLUSIVE GOVERNANCE SYSTEM
BITNATION offers a full range of services traditionally done by governments.
We provide a cryptographically secure ID system, blockchain based dispute
resolution, marriage and divorce, land registry, education, insurance,
security, diplomacy, and more through a fully distributed platform.

@_date: 2014-10-01 13:31:32
@_author: Eugen Leitl 
@_subject: BitNation 
Once they got their own nukes that's surely to follow...

@_date: 2014-10-09 14:11:33
@_author: Eugen Leitl 
@_subject: outernet.is 
It seems the project is picking up steam, and got mentioned

@_date: 2014-10-17 14:13:43
@_author: Eugen Leitl 
@_subject: Novena update 
Bunnie seems on track. Wonder what the price tag for rubes will be.

@_date: 2014-10-29 15:56:41
@_author: Eugen Leitl 
@_subject: are USB floppies toxic? 
We know USB flash is is Biosafety 4, what about other sneaker-net suitable
storage media? USB floppies are still around, as well as media, which
are write-protectable.
How easy to hop the air gap with these?

@_date: 2014-10-30 10:16:12
@_author: Eugen Leitl 
@_subject: FBI demands new powers to hack into computers and carry out 
This is obviously about mass surveillance for social control. The
deviants are already accounted for.
What makes you think it will? The massive criminal malware load so far failed to do it, and federal malware will be a lot more considerate/stealthy than that. Why should they even notice? Or use unpatriotic ("Negative, I am a meat popsicle") antimalware systems?
But of couse mass appearance of malware would hit the honeypots, and result
in more secure systems overall.

@_date: 2014-10-01 12:45:56
@_author: Eugen Leitl 
@_subject: BitNation 
BITNATION IS A FULLY INCLUSIVE GOVERNANCE SYSTEM
BITNATION offers a full range of services traditionally done by governments.
We provide a cryptographically secure ID system, blockchain based dispute
resolution, marriage and divorce, land registry, education, insurance,
security, diplomacy, and more through a fully distributed platform.

@_date: 2014-10-01 13:31:32
@_author: Eugen Leitl 
@_subject: BitNation 
Once they got their own nukes that's surely to follow...

@_date: 2014-10-09 14:11:33
@_author: Eugen Leitl 
@_subject: outernet.is 
It seems the project is picking up steam, and got mentioned

@_date: 2014-10-17 14:13:43
@_author: Eugen Leitl 
@_subject: Novena update 
Bunnie seems on track. Wonder what the price tag for rubes will be.

@_date: 2014-10-29 15:56:41
@_author: Eugen Leitl 
@_subject: are USB floppies toxic? 
We know USB flash is is Biosafety 4, what about other sneaker-net suitable
storage media? USB floppies are still around, as well as media, which
are write-protectable.
How easy to hop the air gap with these?

@_date: 2014-10-30 10:16:12
@_author: Eugen Leitl 
@_subject: FBI demands new powers to hack into computers and carry out 
This is obviously about mass surveillance for social control. The
deviants are already accounted for.
What makes you think it will? The massive criminal malware load so far failed to do it, and federal malware will be a lot more considerate/stealthy than that. Why should they even notice? Or use unpatriotic ("Negative, I am a meat popsicle") antimalware systems?
But of couse mass appearance of malware would hit the honeypots, and result
in more secure systems overall.

@_date: 2014-10-01 12:45:56
@_author: Eugen Leitl 
@_subject: BitNation 
BITNATION IS A FULLY INCLUSIVE GOVERNANCE SYSTEM
BITNATION offers a full range of services traditionally done by governments.
We provide a cryptographically secure ID system, blockchain based dispute
resolution, marriage and divorce, land registry, education, insurance,
security, diplomacy, and more through a fully distributed platform.

@_date: 2014-10-01 13:31:32
@_author: Eugen Leitl 
@_subject: BitNation 
Once they got their own nukes that's surely to follow...

@_date: 2014-10-09 14:11:33
@_author: Eugen Leitl 
@_subject: outernet.is 
It seems the project is picking up steam, and got mentioned

@_date: 2014-10-17 14:13:43
@_author: Eugen Leitl 
@_subject: Novena update 
Bunnie seems on track. Wonder what the price tag for rubes will be.

@_date: 2014-10-29 15:56:41
@_author: Eugen Leitl 
@_subject: are USB floppies toxic? 
We know USB flash is is Biosafety 4, what about other sneaker-net suitable
storage media? USB floppies are still around, as well as media, which
are write-protectable.
How easy to hop the air gap with these?

@_date: 2014-10-30 10:16:12
@_author: Eugen Leitl 
@_subject: FBI demands new powers to hack into computers and carry out 
This is obviously about mass surveillance for social control. The
deviants are already accounted for.
What makes you think it will? The massive criminal malware load so far failed to do it, and federal malware will be a lot more considerate/stealthy than that. Why should they even notice? Or use unpatriotic ("Negative, I am a meat popsicle") antimalware systems?
But of couse mass appearance of malware would hit the honeypots, and result
in more secure systems overall.

@_date: 2014-09-01 11:58:03
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Testing and reviewing requested for work on 
Cozz Lovan has been doing great work on Bitcoin Core's wallet code lately.
If anyone cares about Bitcoin Core's wallet, for example its
performance, do help testing and reviewing these improvements so that
they can make it into 0.10:
Subtract fee from amount
[Wallet] Improve ReorderTransactions(..)
[Wallet] Replace OrderedTxItems(..) with in-memory map
[Qt] Call checkBalanceChanged() periodically instead for every updated tx
Move g_signals.SetBestChain(..) below SyncWithWallets
[Wallet] Call SetBestChain before and after rescan
[Wallet] Do not flush the wallet in AddToWalletIfInvolvingMe(..)

@_date: 2014-09-17 10:12:53
@_author: Eugen Leitl 
@_subject: Palantir pricelist 
173 points by thebyrd 15 hours ago | flag | 58 comments
bane 10 hours ago | link
For folks who've never seen one of these.
132-33 - Price for a Palantir server, priced per core. $141k per core. Includes 1 year of "maintenance" (support and software upgrades).
132-34 - This is the maintenance for second year on. $28k per core.
How many users can a core support? I dunno. But let's say you can serve 50 people off of a 4-core system (you can redo the math for the number of users).
You initial purchase is $564k. Or about $11k per user.
Each year after that, if you want software updates, it'll cost you $113k or or about $2.2k per year per user.
So let's say you use the system for 3 years. That's over $15k of software per user over that time.
Plus there's training ~$2k per user. Or another $100k in training costs.
And then who knows how many hours of engineering and "ninja" services. But a CONUS (within the U.S.) FSR is billed at about $300k per year for a full-time person on staff. Let's say you need two of them to support those 50 users.
Added up for 3 years of Palantir: $1.5million
I'll let you decide if that's good value, but that works out to around $30k per user partial TCO (not including power, security, networking, local IT staff support, etc.).
elblanco 5 hours ago | link
I've done a bit of work with Palantir. This is basically spot on. They're really cagey about the core/user requirement in real life so I'd be comfortable in saying most customer over purchase cores. They usually staff 2-3 full time guys for every 30-50 people and the implementation takes forever. I know of more than one place that didn't have a working system a full year after purchase. Meaning the maintenance had already expired on that first year.
Your later comment about the crack model is also spot on. There's a fairly long list of disgruntled places that bought on discount and are now being hit with huge O&M maintenance fees and are looking for a way out. I think they're government customers are slowly going away.
They're starting to show up more overseas here. Palantir recently opened up a Seoul office. But how much of whatever business they get out of it is government and how much of it is commercial is anybody's guess.
Cthulhu_ 58 minutes ago | link
Sounds... Actually doesn't sound as bad as SAP, Europe's largest software package/manufacturer for... IDK, business software. IIRC, every implementation requires you to hire half a dozen SAP engineers for a decent hourly rate just to set up the system, then keep them on to train and maintain the system.
nostrademons 8 hours ago | link
Not that out of line for what much other enterprise software costs. A Bloomberg terminal runs about $24k/user/year:
When I was doing enterprise financial software it wasn't uncommon for contracts to run in the millions per year.
bane 7 hours ago | link
Yeah it kind of depends how you look at it. Is it specialty software that provides some critical function they can't get elsewhere? Or is it Microsoft Office, everybody gets it and it should really be like $150/seat.
I should have also added to my original post, this is their GSA schedule. For these specific line-items, the government considers this the "prenegotiated lowest price". This simplifies purchasing. So if somebody in the government wants buy another core (item 132-33) they just ring up Palantir or their GSA schedule VAR (reseller) and ask for a 132-33 volume:1 and they know that it'll cost $141k and be good for 1 year of O&M.
The downside of being on the GSA schedule is that it means that there are limits on your ability to change prices year to year to reflect a change in business environment. Say next year you want to drop the price by 50%. That's not allowed, since it would basically mean that you weren't selling your software at the lowest possible prenegotiated price. Similarly if you want to increase it, you're limited in that as well. I think the +- variance can't exceed 10% in a single 12 month period, but I might be wrong. The other downside is that this basically provides your prices in public so your competitors can see what you charge, which can be critical information in contract bids.
There's always a loophole. For example, convince your customer to not buy off of the GSA and sell them a "package" at some discount off of GSA. That "package" counts as a different SKU and the GSA doesn't apply. So for example, you could make a Palantir "starter kit" composed of
   2 core license (normally $282k)
   1 extra year of O&M maintenance for both cores (normally $56k)
   500 hours of Ninja Services @ $150/hr (normally $98k)
   500 hours of CONUS FSR Service @ $120/hr (normally $73k)
all for the grand total of $350k or some such, instead of the normal price of $510k. A $160k discount.
Any government purchaser would fall over themselves to try to make this happen since it's a >30% discount off of the normal GSA schedule prices (which they can refer to and are governed by various rules). This looks fantastic on their yearly performance eval "-saved government $160k on purchase of Palantir package deal"
This is the crack model. When the O&M runs out in two years and they come asking for more, well, there's no deal anymore, and the GSA schedule prices on O&M and people have gone up 20% in that time.
edit keep in mind that this company has raised almost a billion dollars and is valued at something like $9 billion dollars.
elblanco 5 hours ago | link
And now particular plans to sell or go public. This keeps all their financials private and the fact that they have to keep doing new fundraising rounds every few months does not make me think they're making money. At $9bil valuation, finding a buyer is going to be really tough.
They're a really weird company to deal with too. A bit cultish, the CEO is kind of flake the few times I've met him at their conferences. I get the impression that he's not really running the show, he's impossibly unqualified with zero history in any of the spaces they sell into and no business background of any useful type.
Their offices are nice, loads of free great food, but when people emerge from their offices for lunch it looks like they're on a death march. If you ask any of them if they like it there you'll always get a blank stare and a "I love it at Palantir, Palantir is great" answer.
Combined with the track jackets and sketchy legal history (well worth a read), it's kind of off-putting.
msh 4 hours ago | link
Can you provide a link on the last line?
elblanco 1 hour ago | link
eldemar is providing some of the information. I'd add some color the i2 suit.
The fraud perpetrated by Palantir was actually so organized and so bad (they set up an entirely fake front company in another state), that the suing company asked the judge for the case to be tried under RICO rules...which are basically rules put in place to fight the mafia. The judge agreed that it qualified under the law (immediately tripling any damages that would have been awarded) and Palantir settled with i2 immediately after that and the case was dropped.
Word on the street is the settlement was for an almost 9 figure sum and Palantir immediately went into another fundraising round to cover the loss and sustain operations.
The employees (all senior execs) at the center of the fraud kept their jobs but didn't show their faces in public for a couple years (they had been acting as a de facto spokespeople during trade events). They're back in the public eye now.
Yes, that's correct, Palantir is currently run by people who's activities were qualified by a judge as falling under legal guidelines setup to fight the Mob.
You can say what you want about the big defense contractors, incompetence and lobbying and all that (which Palantir does in spades and has even gotten in trouble for not disclosing some lobbying deals) but mafioso they ain't.
Some more here: This isn't even touching the HBGary union busting scheme and the Bank of America anti-Wikileaks proposal. And other very anti-democratic activities.
I don't know what happened to the employee with the anti-Wikileaks deal, but the one with HBGary was the stuff of dystopian nightmares. The employee responsible was publicly terminated but actually it turns out was just sent away for a bit and then quietly either rehired or just turned back up to a job he never lost. Nobody would have ever known about this if Anonymous hadn't had a very public fight with the CEO of HBGary Federal and hacked their network to pull down some documents, revealing an ongoing 3-way partnership with Palantir).
They appear to be offering a revolving door to high level government supporters who then later become "consultants" for the company. "such as former head of the National Counterterrorism Center Michael E Leiter who had said to himself Theres Karp with his hair and his outfithe doesnt look like me or the other people that work for me, before becoming a supporter and then consultant for Palantir"
and heavy lobbying (which explains some of the bizarre support they get in congress while the generals go blue in the face arguing against them)
"It has also been active in formal political lobbying, recruiting former senators John Braux and Trent Lott, (5) with its lobbying expenditures increasing steadily from 2010 to 2013 when its total annual investment exceeded $1.1 million"
more examples I've heard rumors that even the CIA is trying to distance themselves from them and find alternatives.
eldamar 3 hours ago | link
They essentially defrauded their chief competitor, i2, so that they could copy their features and reverse engineer their software so Palantir's system could integrate with it.
Read the full complaint here for the juicy details: Note that all the Palantir employees involved in this suit are still high-ranking Palantir executives.
There is also the case of the Wikileaks/HBGary fiaso; the main individual involved in that mess is still a high ranking Palantir employee as well.
Spooky23 4 hours ago | link
I was involved in a Oracle Financials implemention a few years ago. Forget about the Oracle part... the IBM/Tivoli garbage used to monitor the IT systems cost about $1M in licensing alone!
hkmurakami 5 hours ago | link
They sure have chosen their preferred client industries of Government and Financial Services wisely then. Those industries (a) are accustomed to paying that much for their technology, and (b) are very unlikely to leave your platform once you start using your wares, since the difficulty of getting them as a customer in the first place (and how slow they move and how much paperwork / due diligence is required) directly translates to difficulty for them to move off of your system.
elblanco 5 hours ago | link
there's a fair amount of vendor lock-in in this space as well and Palantir is pretty good at it. They talk quite a bit about open standards and what not. But moving off of their platform and onto one of the competing ones is basically impossible.
They've done a fantastic job at disrupting the link-chart market (which is surprisingly robust) and making it seem like customers are buying something else, but at 2-3x the price of the competition. They hide their sales guys as "forward deployed engineers" and obfuscate their sales process to the point where it doesn't seem like you've ever dealt with the kind of sketchy enterprise sales goon you'd deal with from any of their competitors.
They're very smart.
poolpool 8 hours ago | link
Navigating enterprise sales cycles is a giant pain but man is it profitable compared to the latest social startup du jour.
fishcakes 4 hours ago | link
The alternative to Palantir - an alternative enterprise bespoke system or one built by the companies' or Gov's IT department - costs a whole lot more (25x) and often doesn't work! Palantir is a great value.
elblanco 4 hours ago | link
I presume you're talking about the DCGS-A system. Palantir has done an expert level job confusing the public on this.
That system definitely has problems (it's terrible and sucks in many places), but it's a system of much larger capability and complexity than Palantir.
Comparing Palantir to it is like comparing a wheel to a an entire transport system. Palantir could comfortably fit in as a single capabilty in DCGS-A (and probably do a better job than the stuff currently filling in that role), but it could never replace it.
It's basically just a federated search, mediocre map and halfway decent link-analysis tool. But ask it to do anything even remotely outside of those three things and you're basically dead in the water as it doesn't offer anything relevant to all the other millions of things DCGS-A provides. DCGS-A is more than just some analytic tools.
The reason it's not part of DCGS-A is very political and complex and as much Palantir's doing as the Army's, but the answer is that the components that are on DCGS-A that basically do what Palantir does were selected because they're cheaper over the long run, even if a bit clunky. For example, on the client side, there's presently a forward looking mandate from big Army to drop flash and java clients (because they're an IT administrative menace). Palantir's front end is Java.
steakejjs 8 hours ago | link
The question I am asking is, do they really have the demand to make $1.5million a customer pay (or look like one day it could pay) for their expenses?
My guess is your estimates are really conservative.
halcyondaze 8 hours ago | link
Thanks for breaking that down. I was looking cluelessly at the price sheet for the actual prices.
incision 9 hours ago | link
All right in line with just about any sort of "Enterprise" software. Training and implementation services are downright cheap. Maintenance is the standard 20%.
The last big vendor PO I had to look at put every professional services line item at $300-360/hr with $320 being about average.
sien 9 hours ago | link
Also Palantir's software actually does something more challenging than a lot of enterprise software.
People should go and see what small packages from Oracle, HP, Tibco & IBM cost. It's incredible.
elblanco 5 hours ago | link
Funny you should mention that. Palantir's main competition in the governmeent, i2, is now IBM.
i2 was selling their software at some fraction of Palantir's and in the DoD space it's basically as ubiquitous as Microsoft Office. Palantir is everywhere, but it doesn't end up being used nearly as much.
meowface 6 hours ago | link
Yep, absolutely. This is a perfectly reasonable price for good enterprise software that actually adds value to an organization. (God, I feel like a middle manager just by typing that...).
My company spends tens of millions per year on some really awful enterprise software unfortunately.
aliasaria 6 hours ago | link
Favourite part: "Palantir is in no way affiliated with, or endorsed or sponsored by, The Saul Zaentz Company d.b.a. Tolkien Enterprises or the Estate of J.R.R. Tolkien."
jamesash 6 hours ago | link
Funny, but necessary. The Zaentz company is notoriously litigious. From Zaentz' Wikipedia article: "In 2011, Zaentz's company began several legal actions against small businesses in the UK to enforce their "Hobbit" trade mark, including the Hungry Hobbit cafe in Sarehole, near Birmingham[13][14] and a pub in Southampton, England, which had traded as The Hobbit for twenty years.[15] This raised the ire of many British correspondents such as Stephen Fry, who described it as "pointless, self-defeating bullying."
Jabbles 7 hours ago | link
Agencies can browse GSA Advantage! by accessing the Internet World Wide Web utilizing a browser (ex.: NetScape)
mikegreen 8 hours ago | link
Do not confuse the GSA schedule with actual implementation cost (or TCO as mentioned below). The prices are a starting point and as with any relationship, they can (and will, if the buyer is smart) be negotiated.
Source: sold & implemented alot of software for the gubbmint.
hendzen 6 hours ago | link
If you read between the lines, notice how the "Palantir Gotham Appliance" for 151,042.82 includes "Palantir recommended...database software licenses."
I would bet Oracle (or MS/IBM) is getting a hefty chunk of that.
mmcclellan 4 hours ago | link
Yeah but it's only $10k a core more. This job posting lists Oracle and PostgeSQL:
dfc 4 hours ago | link
I think it is Postgres.
amalag 10 hours ago | link
You can't do diddly with an off the shelf install. They get you on the Implementation Ninjas and Support.
elblanco 5 hours ago | link
Their implementation periods are horrendous. Their marketing speak and sales drones make it sound like a turnkey appliance...like you just drop it in, point it to your database URLS and you're now playing with knowledge management. But in practice there's months of custom backend Java development (the entire tech stack is Java 1.6 or something horrible) to build the connectors and map the data into their backend, then months of ontology management meetings to build up the one-true-model (TM) for all your enterprise needs.
Then months and months of post deployment tweaking and continuous work to keep the system alive and fix issues when some of the data sources change schemas or something.
I've heard things like average time from purchase to full deployment is something like 9 months. But from my time dealing with them I think it's much longer.
fishcakes 4 hours ago | link
That is simply FUD  Palantir guarantees to customers that their software is working within 90 days AND has generated results. They offer a refund if not. Their homepage said this for a while!
elblanco 4 hours ago | link
Well, feel free to buy a core and let me know how long it takes before you're up and running. Having been on the inside during 3 of their deployments, and on the outside of 2 more, I can definitely say 90 days is wildly optimistic.
edit never mind, after reviewing your comment history, it looks like you probably work for Palantir. You should probably disclose that. I stand by my comments about deployment times.
capkutay 9 hours ago | link
I think they get you on the off the shelf price too..
$150k/core...say you run it on a cluster of relatively puny machines ...($150k * 4 cores) on a 4 node cluster is already above $2m.
dlinder 7 hours ago | link
132-51 CONS CONUS FSR Support hourly rate. CONUS rates will be billed for Services performed outside the continental U.S. unless in a warzone. Normal business hours are defined as an 8-hour work day (rate is 15% more outside of normal business hours). $ 146.60
132-51 OCONS OCONUS FSR Support hourly rate. OCONUS rates will be billed for Services performed in a warzone. Normal business hours are defined as a 12-hour work day (rate is 15% more outside of normal business hours). $ 195.47
bane 7 hours ago | link
I'm actually surprised how cheap their OCONUS warzone rates are. Many contractors will pay hazardous bonuses, time in theater bonuses and living condition bonuses on top of the CONUS base pay. Added up it can far exceed this kind of rate.
But this is probably helpful for people getting into consulting to see what hourly rates are for this kind of work. In my experience these rates are actually fairly cheap. I'm used to seeing $170-200 for most things billed to the government.
But I've also heard Palantir has fairly conservative pay caps, that might account for the low rates.
judgardner 10 hours ago | link
132-51 | IMS | Implementation Ninja Services
dkarapetyan 9 hours ago | link
So ost.
bane 6 hours ago | link
It's less automated data analytics and more chart drawing and semantic knowledge base management tied to a federated search system.
Their principle competitor is They used to have a free trial you could run via java webstart on their website, but they've taken it down.
Here's a video It's big data in the sense that using google's search box is big data. But from my time using their demo a couple years ago, the actual tool is fairly small in focus. I don't even think the chart view can show more than a few hundred things.
mayneack 2 hours ago | link
It's still up: bane 1 hour ago | link
Oh okay cool. That's a different demo. The old one was Operation Tradewinds or something.
mayneack 1 hour ago | link
Tradestop is what you're thinking of.
AJ007 5 hours ago | link
Interesting, it looks a lot like Maltego.
fishcakes 10 hours ago | link
Pretty affordable considering many other things on the GSA don't work once you buy them!
jonknee 8 hours ago | link
Luckily for Palantir whether or not it works is classified. I have my doubts. I'm sure it "works", but I'm also sure it's a giant waste of money and Americans are not safer because we're funneling millions of dollars to Palantir.
bane 6 hours ago | link
I messed around with the demo they used to have on their website. It seems to be very much an answer to the 9-11 failure to connect the dots problem.
Unify search, build semantic links.
It was a very manually intensive tool based on what I saw. Very little automation, more like those pictures and strings you see in crime shows on TV...but on a computer.
arikrak 7 hours ago | link
How do they get such precise prices? If I was selling something for 140k, I would sell it for 140k. But they sell it for $141,015.42.
pvarangot 6 hours ago | link
It's GSA price. My guess is the retail price is somewhat rounder, and after tax and other specific discounts it comes down to that.
m0nastic 5 hours ago | link
Strictly speaking, being on the GSA schedule and being able to offer products/services for sale to the federal government requires that you not sell that product/service anywhere else for less than that GSA price.
This is actually one of the reasons that doing business with the government is less lucrative than the commercial industry (for products and services which are comparable, many are things only sold to the government, so there is no hesitation about pricing them through the roof).
As you can imagine, one of the ways that duplicitous federal contractors get around the idea of having to sell to the government for less than their normal prices is to structure their products/services as different (and therefore not apples to apples comparable).
I still would bet that the price that they charge Goldman Sachs (just as an example, I don't actually know which investment banks are using their product) is higher than what they charge for any individual government client.
Also, I think it's probably worth noting that the maximum addressable customer base for their products for federal agencies is way smaller than the equivalent number of financial customers. There's really only a handful of agencies that have this capability (I'd guess more than a handful, but probably less than a dozen).
tptacek 6 hours ago | link
Yes: GSA prices are IIRC the result of a pro-forma (and totally BS) discounting process.
phmagic 10 hours ago | link
pretty affordable compared to most enterprise software packages
bicknergseng 10 hours ago | link
"per core"
trhway 9 hours ago | link
with 90 days warranty :) Can it rot?
Anyway, from their Gotham page "Working closely with the customer, our engineers integrate and map all of the relevant source dataregardless of type or volumeinto a single, coherent model.
Once the model has ted, data flows continuously from its sources into the Palantir Gotham platform.
They can search across all of their data sources at once, visualize relationships, explore divergent hypotheses, discover unknown connections, "
Pretty much my 2009 pitch, and in the hindsight i see that my main weakness was that i couldn't even imagine $150K/core. Man, it is imagination what separates losers from winners! :)
sz4kerto 8 hours ago | link
kdb, a database engine I consider extremely simple compared to Palantir costs $50k/yr/core.
mmcclellan 4 hours ago | link
simple but competent for time series. and the 32-bit version is at least available for free now.
xacaxulu 8 hours ago | link
So Palantir is hiring if you have a clearance :-). Time to get your tax dollars back. Looks like SAIC all over again.
xamdam 6 hours ago | link
You don't need a clearance. We have large commercial deployments.
bane 4 hours ago | link
I did some consulting work with the NYPD and heard you guys also have some deployments with them and other large police forces. Those are nice non-clearance, but cool, jobs as well.

@_date: 2014-09-17 11:33:42
@_author: Eugen Leitl 
@_subject: PFS is a global, versioned, peer-to-peer filesystem 
IPFS is a global, versioned, peer-to-peer filesystem.
It combines good ideas from Git, BitTorrent, Kademlia, SFS, and the Web. It
is like a single bittorrent swarm, exchanging git objects. IPFS provides an
interface as simple as the HTTP web, but with permanence built in. You can
also mount the world at /ipfs.
How does it work? Read the paper

@_date: 2014-09-01 11:58:03
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Testing and reviewing requested for work on 
Cozz Lovan has been doing great work on Bitcoin Core's wallet code lately.
If anyone cares about Bitcoin Core's wallet, for example its
performance, do help testing and reviewing these improvements so that
they can make it into 0.10:
Subtract fee from amount
[Wallet] Improve ReorderTransactions(..)
[Wallet] Replace OrderedTxItems(..) with in-memory map
[Qt] Call checkBalanceChanged() periodically instead for every updated tx
Move g_signals.SetBestChain(..) below SyncWithWallets
[Wallet] Call SetBestChain before and after rescan
[Wallet] Do not flush the wallet in AddToWalletIfInvolvingMe(..)

@_date: 2014-09-17 10:12:53
@_author: Eugen Leitl 
@_subject: Palantir pricelist 
173 points by thebyrd 15 hours ago | flag | 58 comments
bane 10 hours ago | link
For folks who've never seen one of these.
132-33 - Price for a Palantir server, priced per core. $141k per core. Includes 1 year of "maintenance" (support and software upgrades).
132-34 - This is the maintenance for second year on. $28k per core.
How many users can a core support? I dunno. But let's say you can serve 50 people off of a 4-core system (you can redo the math for the number of users).
You initial purchase is $564k. Or about $11k per user.
Each year after that, if you want software updates, it'll cost you $113k or or about $2.2k per year per user.
So let's say you use the system for 3 years. That's over $15k of software per user over that time.
Plus there's training ~$2k per user. Or another $100k in training costs.
And then who knows how many hours of engineering and "ninja" services. But a CONUS (within the U.S.) FSR is billed at about $300k per year for a full-time person on staff. Let's say you need two of them to support those 50 users.
Added up for 3 years of Palantir: $1.5million
I'll let you decide if that's good value, but that works out to around $30k per user partial TCO (not including power, security, networking, local IT staff support, etc.).
elblanco 5 hours ago | link
I've done a bit of work with Palantir. This is basically spot on. They're really cagey about the core/user requirement in real life so I'd be comfortable in saying most customer over purchase cores. They usually staff 2-3 full time guys for every 30-50 people and the implementation takes forever. I know of more than one place that didn't have a working system a full year after purchase. Meaning the maintenance had already expired on that first year.
Your later comment about the crack model is also spot on. There's a fairly long list of disgruntled places that bought on discount and are now being hit with huge O&M maintenance fees and are looking for a way out. I think they're government customers are slowly going away.
They're starting to show up more overseas here. Palantir recently opened up a Seoul office. But how much of whatever business they get out of it is government and how much of it is commercial is anybody's guess.
Cthulhu_ 58 minutes ago | link
Sounds... Actually doesn't sound as bad as SAP, Europe's largest software package/manufacturer for... IDK, business software. IIRC, every implementation requires you to hire half a dozen SAP engineers for a decent hourly rate just to set up the system, then keep them on to train and maintain the system.
nostrademons 8 hours ago | link
Not that out of line for what much other enterprise software costs. A Bloomberg terminal runs about $24k/user/year:
When I was doing enterprise financial software it wasn't uncommon for contracts to run in the millions per year.
bane 7 hours ago | link
Yeah it kind of depends how you look at it. Is it specialty software that provides some critical function they can't get elsewhere? Or is it Microsoft Office, everybody gets it and it should really be like $150/seat.
I should have also added to my original post, this is their GSA schedule. For these specific line-items, the government considers this the "prenegotiated lowest price". This simplifies purchasing. So if somebody in the government wants buy another core (item 132-33) they just ring up Palantir or their GSA schedule VAR (reseller) and ask for a 132-33 volume:1 and they know that it'll cost $141k and be good for 1 year of O&M.
The downside of being on the GSA schedule is that it means that there are limits on your ability to change prices year to year to reflect a change in business environment. Say next year you want to drop the price by 50%. That's not allowed, since it would basically mean that you weren't selling your software at the lowest possible prenegotiated price. Similarly if you want to increase it, you're limited in that as well. I think the +- variance can't exceed 10% in a single 12 month period, but I might be wrong. The other downside is that this basically provides your prices in public so your competitors can see what you charge, which can be critical information in contract bids.
There's always a loophole. For example, convince your customer to not buy off of the GSA and sell them a "package" at some discount off of GSA. That "package" counts as a different SKU and the GSA doesn't apply. So for example, you could make a Palantir "starter kit" composed of
   2 core license (normally $282k)
   1 extra year of O&M maintenance for both cores (normally $56k)
   500 hours of Ninja Services @ $150/hr (normally $98k)
   500 hours of CONUS FSR Service @ $120/hr (normally $73k)
all for the grand total of $350k or some such, instead of the normal price of $510k. A $160k discount.
Any government purchaser would fall over themselves to try to make this happen since it's a >30% discount off of the normal GSA schedule prices (which they can refer to and are governed by various rules). This looks fantastic on their yearly performance eval "-saved government $160k on purchase of Palantir package deal"
This is the crack model. When the O&M runs out in two years and they come asking for more, well, there's no deal anymore, and the GSA schedule prices on O&M and people have gone up 20% in that time.
edit keep in mind that this company has raised almost a billion dollars and is valued at something like $9 billion dollars.
elblanco 5 hours ago | link
And now particular plans to sell or go public. This keeps all their financials private and the fact that they have to keep doing new fundraising rounds every few months does not make me think they're making money. At $9bil valuation, finding a buyer is going to be really tough.
They're a really weird company to deal with too. A bit cultish, the CEO is kind of flake the few times I've met him at their conferences. I get the impression that he's not really running the show, he's impossibly unqualified with zero history in any of the spaces they sell into and no business background of any useful type.
Their offices are nice, loads of free great food, but when people emerge from their offices for lunch it looks like they're on a death march. If you ask any of them if they like it there you'll always get a blank stare and a "I love it at Palantir, Palantir is great" answer.
Combined with the track jackets and sketchy legal history (well worth a read), it's kind of off-putting.
msh 4 hours ago | link
Can you provide a link on the last line?
elblanco 1 hour ago | link
eldemar is providing some of the information. I'd add some color the i2 suit.
The fraud perpetrated by Palantir was actually so organized and so bad (they set up an entirely fake front company in another state), that the suing company asked the judge for the case to be tried under RICO rules...which are basically rules put in place to fight the mafia. The judge agreed that it qualified under the law (immediately tripling any damages that would have been awarded) and Palantir settled with i2 immediately after that and the case was dropped.
Word on the street is the settlement was for an almost 9 figure sum and Palantir immediately went into another fundraising round to cover the loss and sustain operations.
The employees (all senior execs) at the center of the fraud kept their jobs but didn't show their faces in public for a couple years (they had been acting as a de facto spokespeople during trade events). They're back in the public eye now.
Yes, that's correct, Palantir is currently run by people who's activities were qualified by a judge as falling under legal guidelines setup to fight the Mob.
You can say what you want about the big defense contractors, incompetence and lobbying and all that (which Palantir does in spades and has even gotten in trouble for not disclosing some lobbying deals) but mafioso they ain't.
Some more here: This isn't even touching the HBGary union busting scheme and the Bank of America anti-Wikileaks proposal. And other very anti-democratic activities.
I don't know what happened to the employee with the anti-Wikileaks deal, but the one with HBGary was the stuff of dystopian nightmares. The employee responsible was publicly terminated but actually it turns out was just sent away for a bit and then quietly either rehired or just turned back up to a job he never lost. Nobody would have ever known about this if Anonymous hadn't had a very public fight with the CEO of HBGary Federal and hacked their network to pull down some documents, revealing an ongoing 3-way partnership with Palantir).
They appear to be offering a revolving door to high level government supporters who then later become "consultants" for the company. "such as former head of the National Counterterrorism Center Michael E Leiter who had said to himself Theres Karp with his hair and his outfithe doesnt look like me or the other people that work for me, before becoming a supporter and then consultant for Palantir"
and heavy lobbying (which explains some of the bizarre support they get in congress while the generals go blue in the face arguing against them)
"It has also been active in formal political lobbying, recruiting former senators John Braux and Trent Lott, (5) with its lobbying expenditures increasing steadily from 2010 to 2013 when its total annual investment exceeded $1.1 million"
more examples I've heard rumors that even the CIA is trying to distance themselves from them and find alternatives.
eldamar 3 hours ago | link
They essentially defrauded their chief competitor, i2, so that they could copy their features and reverse engineer their software so Palantir's system could integrate with it.
Read the full complaint here for the juicy details: Note that all the Palantir employees involved in this suit are still high-ranking Palantir executives.
There is also the case of the Wikileaks/HBGary fiaso; the main individual involved in that mess is still a high ranking Palantir employee as well.
Spooky23 4 hours ago | link
I was involved in a Oracle Financials implemention a few years ago. Forget about the Oracle part... the IBM/Tivoli garbage used to monitor the IT systems cost about $1M in licensing alone!
hkmurakami 5 hours ago | link
They sure have chosen their preferred client industries of Government and Financial Services wisely then. Those industries (a) are accustomed to paying that much for their technology, and (b) are very unlikely to leave your platform once you start using your wares, since the difficulty of getting them as a customer in the first place (and how slow they move and how much paperwork / due diligence is required) directly translates to difficulty for them to move off of your system.
elblanco 5 hours ago | link
there's a fair amount of vendor lock-in in this space as well and Palantir is pretty good at it. They talk quite a bit about open standards and what not. But moving off of their platform and onto one of the competing ones is basically impossible.
They've done a fantastic job at disrupting the link-chart market (which is surprisingly robust) and making it seem like customers are buying something else, but at 2-3x the price of the competition. They hide their sales guys as "forward deployed engineers" and obfuscate their sales process to the point where it doesn't seem like you've ever dealt with the kind of sketchy enterprise sales goon you'd deal with from any of their competitors.
They're very smart.
poolpool 8 hours ago | link
Navigating enterprise sales cycles is a giant pain but man is it profitable compared to the latest social startup du jour.
fishcakes 4 hours ago | link
The alternative to Palantir - an alternative enterprise bespoke system or one built by the companies' or Gov's IT department - costs a whole lot more (25x) and often doesn't work! Palantir is a great value.
elblanco 4 hours ago | link
I presume you're talking about the DCGS-A system. Palantir has done an expert level job confusing the public on this.
That system definitely has problems (it's terrible and sucks in many places), but it's a system of much larger capability and complexity than Palantir.
Comparing Palantir to it is like comparing a wheel to a an entire transport system. Palantir could comfortably fit in as a single capabilty in DCGS-A (and probably do a better job than the stuff currently filling in that role), but it could never replace it.
It's basically just a federated search, mediocre map and halfway decent link-analysis tool. But ask it to do anything even remotely outside of those three things and you're basically dead in the water as it doesn't offer anything relevant to all the other millions of things DCGS-A provides. DCGS-A is more than just some analytic tools.
The reason it's not part of DCGS-A is very political and complex and as much Palantir's doing as the Army's, but the answer is that the components that are on DCGS-A that basically do what Palantir does were selected because they're cheaper over the long run, even if a bit clunky. For example, on the client side, there's presently a forward looking mandate from big Army to drop flash and java clients (because they're an IT administrative menace). Palantir's front end is Java.
steakejjs 8 hours ago | link
The question I am asking is, do they really have the demand to make $1.5million a customer pay (or look like one day it could pay) for their expenses?
My guess is your estimates are really conservative.
halcyondaze 8 hours ago | link
Thanks for breaking that down. I was looking cluelessly at the price sheet for the actual prices.
incision 9 hours ago | link
All right in line with just about any sort of "Enterprise" software. Training and implementation services are downright cheap. Maintenance is the standard 20%.
The last big vendor PO I had to look at put every professional services line item at $300-360/hr with $320 being about average.
sien 9 hours ago | link
Also Palantir's software actually does something more challenging than a lot of enterprise software.
People should go and see what small packages from Oracle, HP, Tibco & IBM cost. It's incredible.
elblanco 5 hours ago | link
Funny you should mention that. Palantir's main competition in the governmeent, i2, is now IBM.
i2 was selling their software at some fraction of Palantir's and in the DoD space it's basically as ubiquitous as Microsoft Office. Palantir is everywhere, but it doesn't end up being used nearly as much.
meowface 6 hours ago | link
Yep, absolutely. This is a perfectly reasonable price for good enterprise software that actually adds value to an organization. (God, I feel like a middle manager just by typing that...).
My company spends tens of millions per year on some really awful enterprise software unfortunately.
aliasaria 6 hours ago | link
Favourite part: "Palantir is in no way affiliated with, or endorsed or sponsored by, The Saul Zaentz Company d.b.a. Tolkien Enterprises or the Estate of J.R.R. Tolkien."
jamesash 6 hours ago | link
Funny, but necessary. The Zaentz company is notoriously litigious. From Zaentz' Wikipedia article: "In 2011, Zaentz's company began several legal actions against small businesses in the UK to enforce their "Hobbit" trade mark, including the Hungry Hobbit cafe in Sarehole, near Birmingham[13][14] and a pub in Southampton, England, which had traded as The Hobbit for twenty years.[15] This raised the ire of many British correspondents such as Stephen Fry, who described it as "pointless, self-defeating bullying."
Jabbles 7 hours ago | link
Agencies can browse GSA Advantage! by accessing the Internet World Wide Web utilizing a browser (ex.: NetScape)
mikegreen 8 hours ago | link
Do not confuse the GSA schedule with actual implementation cost (or TCO as mentioned below). The prices are a starting point and as with any relationship, they can (and will, if the buyer is smart) be negotiated.
Source: sold & implemented alot of software for the gubbmint.
hendzen 6 hours ago | link
If you read between the lines, notice how the "Palantir Gotham Appliance" for 151,042.82 includes "Palantir recommended...database software licenses."
I would bet Oracle (or MS/IBM) is getting a hefty chunk of that.
mmcclellan 4 hours ago | link
Yeah but it's only $10k a core more. This job posting lists Oracle and PostgeSQL:
dfc 4 hours ago | link
I think it is Postgres.
amalag 10 hours ago | link
You can't do diddly with an off the shelf install. They get you on the Implementation Ninjas and Support.
elblanco 5 hours ago | link
Their implementation periods are horrendous. Their marketing speak and sales drones make it sound like a turnkey appliance...like you just drop it in, point it to your database URLS and you're now playing with knowledge management. But in practice there's months of custom backend Java development (the entire tech stack is Java 1.6 or something horrible) to build the connectors and map the data into their backend, then months of ontology management meetings to build up the one-true-model (TM) for all your enterprise needs.
Then months and months of post deployment tweaking and continuous work to keep the system alive and fix issues when some of the data sources change schemas or something.
I've heard things like average time from purchase to full deployment is something like 9 months. But from my time dealing with them I think it's much longer.
fishcakes 4 hours ago | link
That is simply FUD  Palantir guarantees to customers that their software is working within 90 days AND has generated results. They offer a refund if not. Their homepage said this for a while!
elblanco 4 hours ago | link
Well, feel free to buy a core and let me know how long it takes before you're up and running. Having been on the inside during 3 of their deployments, and on the outside of 2 more, I can definitely say 90 days is wildly optimistic.
edit never mind, after reviewing your comment history, it looks like you probably work for Palantir. You should probably disclose that. I stand by my comments about deployment times.
capkutay 9 hours ago | link
I think they get you on the off the shelf price too..
$150k/core...say you run it on a cluster of relatively puny machines ...($150k * 4 cores) on a 4 node cluster is already above $2m.
dlinder 7 hours ago | link
132-51 CONS CONUS FSR Support hourly rate. CONUS rates will be billed for Services performed outside the continental U.S. unless in a warzone. Normal business hours are defined as an 8-hour work day (rate is 15% more outside of normal business hours). $ 146.60
132-51 OCONS OCONUS FSR Support hourly rate. OCONUS rates will be billed for Services performed in a warzone. Normal business hours are defined as a 12-hour work day (rate is 15% more outside of normal business hours). $ 195.47
bane 7 hours ago | link
I'm actually surprised how cheap their OCONUS warzone rates are. Many contractors will pay hazardous bonuses, time in theater bonuses and living condition bonuses on top of the CONUS base pay. Added up it can far exceed this kind of rate.
But this is probably helpful for people getting into consulting to see what hourly rates are for this kind of work. In my experience these rates are actually fairly cheap. I'm used to seeing $170-200 for most things billed to the government.
But I've also heard Palantir has fairly conservative pay caps, that might account for the low rates.
judgardner 10 hours ago | link
132-51 | IMS | Implementation Ninja Services
dkarapetyan 9 hours ago | link
So ost.
bane 6 hours ago | link
It's less automated data analytics and more chart drawing and semantic knowledge base management tied to a federated search system.
Their principle competitor is They used to have a free trial you could run via java webstart on their website, but they've taken it down.
Here's a video It's big data in the sense that using google's search box is big data. But from my time using their demo a couple years ago, the actual tool is fairly small in focus. I don't even think the chart view can show more than a few hundred things.
mayneack 2 hours ago | link
It's still up: bane 1 hour ago | link
Oh okay cool. That's a different demo. The old one was Operation Tradewinds or something.
mayneack 1 hour ago | link
Tradestop is what you're thinking of.
AJ007 5 hours ago | link
Interesting, it looks a lot like Maltego.
fishcakes 10 hours ago | link
Pretty affordable considering many other things on the GSA don't work once you buy them!
jonknee 8 hours ago | link
Luckily for Palantir whether or not it works is classified. I have my doubts. I'm sure it "works", but I'm also sure it's a giant waste of money and Americans are not safer because we're funneling millions of dollars to Palantir.
bane 6 hours ago | link
I messed around with the demo they used to have on their website. It seems to be very much an answer to the 9-11 failure to connect the dots problem.
Unify search, build semantic links.
It was a very manually intensive tool based on what I saw. Very little automation, more like those pictures and strings you see in crime shows on TV...but on a computer.
arikrak 7 hours ago | link
How do they get such precise prices? If I was selling something for 140k, I would sell it for 140k. But they sell it for $141,015.42.
pvarangot 6 hours ago | link
It's GSA price. My guess is the retail price is somewhat rounder, and after tax and other specific discounts it comes down to that.
m0nastic 5 hours ago | link
Strictly speaking, being on the GSA schedule and being able to offer products/services for sale to the federal government requires that you not sell that product/service anywhere else for less than that GSA price.
This is actually one of the reasons that doing business with the government is less lucrative than the commercial industry (for products and services which are comparable, many are things only sold to the government, so there is no hesitation about pricing them through the roof).
As you can imagine, one of the ways that duplicitous federal contractors get around the idea of having to sell to the government for less than their normal prices is to structure their products/services as different (and therefore not apples to apples comparable).
I still would bet that the price that they charge Goldman Sachs (just as an example, I don't actually know which investment banks are using their product) is higher than what they charge for any individual government client.
Also, I think it's probably worth noting that the maximum addressable customer base for their products for federal agencies is way smaller than the equivalent number of financial customers. There's really only a handful of agencies that have this capability (I'd guess more than a handful, but probably less than a dozen).
tptacek 6 hours ago | link
Yes: GSA prices are IIRC the result of a pro-forma (and totally BS) discounting process.
phmagic 10 hours ago | link
pretty affordable compared to most enterprise software packages
bicknergseng 10 hours ago | link
"per core"
trhway 9 hours ago | link
with 90 days warranty :) Can it rot?
Anyway, from their Gotham page "Working closely with the customer, our engineers integrate and map all of the relevant source dataregardless of type or volumeinto a single, coherent model.
Once the model has ted, data flows continuously from its sources into the Palantir Gotham platform.
They can search across all of their data sources at once, visualize relationships, explore divergent hypotheses, discover unknown connections, "
Pretty much my 2009 pitch, and in the hindsight i see that my main weakness was that i couldn't even imagine $150K/core. Man, it is imagination what separates losers from winners! :)
sz4kerto 8 hours ago | link
kdb, a database engine I consider extremely simple compared to Palantir costs $50k/yr/core.
mmcclellan 4 hours ago | link
simple but competent for time series. and the 32-bit version is at least available for free now.
xacaxulu 8 hours ago | link
So Palantir is hiring if you have a clearance :-). Time to get your tax dollars back. Looks like SAIC all over again.
xamdam 6 hours ago | link
You don't need a clearance. We have large commercial deployments.
bane 4 hours ago | link
I did some consulting work with the NYPD and heard you guys also have some deployments with them and other large police forces. Those are nice non-clearance, but cool, jobs as well.

@_date: 2014-09-17 11:33:42
@_author: Eugen Leitl 
@_subject: PFS is a global, versioned, peer-to-peer filesystem 
IPFS is a global, versioned, peer-to-peer filesystem.
It combines good ideas from Git, BitTorrent, Kademlia, SFS, and the Web. It
is like a single bittorrent swarm, exchanging git objects. IPFS provides an
interface as simple as the HTTP web, but with permanence built in. You can
also mount the world at /ipfs.
How does it work? Read the paper

@_date: 2014-09-01 11:58:03
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Testing and reviewing requested for work on 
Cozz Lovan has been doing great work on Bitcoin Core's wallet code lately.
If anyone cares about Bitcoin Core's wallet, for example its
performance, do help testing and reviewing these improvements so that
they can make it into 0.10:
Subtract fee from amount
[Wallet] Improve ReorderTransactions(..)
[Wallet] Replace OrderedTxItems(..) with in-memory map
[Qt] Call checkBalanceChanged() periodically instead for every updated tx
Move g_signals.SetBestChain(..) below SyncWithWallets
[Wallet] Call SetBestChain before and after rescan
[Wallet] Do not flush the wallet in AddToWalletIfInvolvingMe(..)

@_date: 2014-09-17 10:12:53
@_author: Eugen Leitl 
@_subject: Palantir pricelist 
173 points by thebyrd 15 hours ago | flag | 58 comments
bane 10 hours ago | link
For folks who've never seen one of these.
132-33 - Price for a Palantir server, priced per core. $141k per core. Includes 1 year of "maintenance" (support and software upgrades).
132-34 - This is the maintenance for second year on. $28k per core.
How many users can a core support? I dunno. But let's say you can serve 50 people off of a 4-core system (you can redo the math for the number of users).
You initial purchase is $564k. Or about $11k per user.
Each year after that, if you want software updates, it'll cost you $113k or or about $2.2k per year per user.
So let's say you use the system for 3 years. That's over $15k of software per user over that time.
Plus there's training ~$2k per user. Or another $100k in training costs.
And then who knows how many hours of engineering and "ninja" services. But a CONUS (within the U.S.) FSR is billed at about $300k per year for a full-time person on staff. Let's say you need two of them to support those 50 users.
Added up for 3 years of Palantir: $1.5million
I'll let you decide if that's good value, but that works out to around $30k per user partial TCO (not including power, security, networking, local IT staff support, etc.).
elblanco 5 hours ago | link
I've done a bit of work with Palantir. This is basically spot on. They're really cagey about the core/user requirement in real life so I'd be comfortable in saying most customer over purchase cores. They usually staff 2-3 full time guys for every 30-50 people and the implementation takes forever. I know of more than one place that didn't have a working system a full year after purchase. Meaning the maintenance had already expired on that first year.
Your later comment about the crack model is also spot on. There's a fairly long list of disgruntled places that bought on discount and are now being hit with huge O&M maintenance fees and are looking for a way out. I think they're government customers are slowly going away.
They're starting to show up more overseas here. Palantir recently opened up a Seoul office. But how much of whatever business they get out of it is government and how much of it is commercial is anybody's guess.
Cthulhu_ 58 minutes ago | link
Sounds... Actually doesn't sound as bad as SAP, Europe's largest software package/manufacturer for... IDK, business software. IIRC, every implementation requires you to hire half a dozen SAP engineers for a decent hourly rate just to set up the system, then keep them on to train and maintain the system.
nostrademons 8 hours ago | link
Not that out of line for what much other enterprise software costs. A Bloomberg terminal runs about $24k/user/year:
When I was doing enterprise financial software it wasn't uncommon for contracts to run in the millions per year.
bane 7 hours ago | link
Yeah it kind of depends how you look at it. Is it specialty software that provides some critical function they can't get elsewhere? Or is it Microsoft Office, everybody gets it and it should really be like $150/seat.
I should have also added to my original post, this is their GSA schedule. For these specific line-items, the government considers this the "prenegotiated lowest price". This simplifies purchasing. So if somebody in the government wants buy another core (item 132-33) they just ring up Palantir or their GSA schedule VAR (reseller) and ask for a 132-33 volume:1 and they know that it'll cost $141k and be good for 1 year of O&M.
The downside of being on the GSA schedule is that it means that there are limits on your ability to change prices year to year to reflect a change in business environment. Say next year you want to drop the price by 50%. That's not allowed, since it would basically mean that you weren't selling your software at the lowest possible prenegotiated price. Similarly if you want to increase it, you're limited in that as well. I think the +- variance can't exceed 10% in a single 12 month period, but I might be wrong. The other downside is that this basically provides your prices in public so your competitors can see what you charge, which can be critical information in contract bids.
There's always a loophole. For example, convince your customer to not buy off of the GSA and sell them a "package" at some discount off of GSA. That "package" counts as a different SKU and the GSA doesn't apply. So for example, you could make a Palantir "starter kit" composed of
   2 core license (normally $282k)
   1 extra year of O&M maintenance for both cores (normally $56k)
   500 hours of Ninja Services @ $150/hr (normally $98k)
   500 hours of CONUS FSR Service @ $120/hr (normally $73k)
all for the grand total of $350k or some such, instead of the normal price of $510k. A $160k discount.
Any government purchaser would fall over themselves to try to make this happen since it's a >30% discount off of the normal GSA schedule prices (which they can refer to and are governed by various rules). This looks fantastic on their yearly performance eval "-saved government $160k on purchase of Palantir package deal"
This is the crack model. When the O&M runs out in two years and they come asking for more, well, there's no deal anymore, and the GSA schedule prices on O&M and people have gone up 20% in that time.
edit keep in mind that this company has raised almost a billion dollars and is valued at something like $9 billion dollars.
elblanco 5 hours ago | link
And now particular plans to sell or go public. This keeps all their financials private and the fact that they have to keep doing new fundraising rounds every few months does not make me think they're making money. At $9bil valuation, finding a buyer is going to be really tough.
They're a really weird company to deal with too. A bit cultish, the CEO is kind of flake the few times I've met him at their conferences. I get the impression that he's not really running the show, he's impossibly unqualified with zero history in any of the spaces they sell into and no business background of any useful type.
Their offices are nice, loads of free great food, but when people emerge from their offices for lunch it looks like they're on a death march. If you ask any of them if they like it there you'll always get a blank stare and a "I love it at Palantir, Palantir is great" answer.
Combined with the track jackets and sketchy legal history (well worth a read), it's kind of off-putting.
msh 4 hours ago | link
Can you provide a link on the last line?
elblanco 1 hour ago | link
eldemar is providing some of the information. I'd add some color the i2 suit.
The fraud perpetrated by Palantir was actually so organized and so bad (they set up an entirely fake front company in another state), that the suing company asked the judge for the case to be tried under RICO rules...which are basically rules put in place to fight the mafia. The judge agreed that it qualified under the law (immediately tripling any damages that would have been awarded) and Palantir settled with i2 immediately after that and the case was dropped.
Word on the street is the settlement was for an almost 9 figure sum and Palantir immediately went into another fundraising round to cover the loss and sustain operations.
The employees (all senior execs) at the center of the fraud kept their jobs but didn't show their faces in public for a couple years (they had been acting as a de facto spokespeople during trade events). They're back in the public eye now.
Yes, that's correct, Palantir is currently run by people who's activities were qualified by a judge as falling under legal guidelines setup to fight the Mob.
You can say what you want about the big defense contractors, incompetence and lobbying and all that (which Palantir does in spades and has even gotten in trouble for not disclosing some lobbying deals) but mafioso they ain't.
Some more here: This isn't even touching the HBGary union busting scheme and the Bank of America anti-Wikileaks proposal. And other very anti-democratic activities.
I don't know what happened to the employee with the anti-Wikileaks deal, but the one with HBGary was the stuff of dystopian nightmares. The employee responsible was publicly terminated but actually it turns out was just sent away for a bit and then quietly either rehired or just turned back up to a job he never lost. Nobody would have ever known about this if Anonymous hadn't had a very public fight with the CEO of HBGary Federal and hacked their network to pull down some documents, revealing an ongoing 3-way partnership with Palantir).
They appear to be offering a revolving door to high level government supporters who then later become "consultants" for the company. "such as former head of the National Counterterrorism Center Michael E Leiter who had said to himself Theres Karp with his hair and his outfithe doesnt look like me or the other people that work for me, before becoming a supporter and then consultant for Palantir"
and heavy lobbying (which explains some of the bizarre support they get in congress while the generals go blue in the face arguing against them)
"It has also been active in formal political lobbying, recruiting former senators John Braux and Trent Lott, (5) with its lobbying expenditures increasing steadily from 2010 to 2013 when its total annual investment exceeded $1.1 million"
more examples I've heard rumors that even the CIA is trying to distance themselves from them and find alternatives.
eldamar 3 hours ago | link
They essentially defrauded their chief competitor, i2, so that they could copy their features and reverse engineer their software so Palantir's system could integrate with it.
Read the full complaint here for the juicy details: Note that all the Palantir employees involved in this suit are still high-ranking Palantir executives.
There is also the case of the Wikileaks/HBGary fiaso; the main individual involved in that mess is still a high ranking Palantir employee as well.
Spooky23 4 hours ago | link
I was involved in a Oracle Financials implemention a few years ago. Forget about the Oracle part... the IBM/Tivoli garbage used to monitor the IT systems cost about $1M in licensing alone!
hkmurakami 5 hours ago | link
They sure have chosen their preferred client industries of Government and Financial Services wisely then. Those industries (a) are accustomed to paying that much for their technology, and (b) are very unlikely to leave your platform once you start using your wares, since the difficulty of getting them as a customer in the first place (and how slow they move and how much paperwork / due diligence is required) directly translates to difficulty for them to move off of your system.
elblanco 5 hours ago | link
there's a fair amount of vendor lock-in in this space as well and Palantir is pretty good at it. They talk quite a bit about open standards and what not. But moving off of their platform and onto one of the competing ones is basically impossible.
They've done a fantastic job at disrupting the link-chart market (which is surprisingly robust) and making it seem like customers are buying something else, but at 2-3x the price of the competition. They hide their sales guys as "forward deployed engineers" and obfuscate their sales process to the point where it doesn't seem like you've ever dealt with the kind of sketchy enterprise sales goon you'd deal with from any of their competitors.
They're very smart.
poolpool 8 hours ago | link
Navigating enterprise sales cycles is a giant pain but man is it profitable compared to the latest social startup du jour.
fishcakes 4 hours ago | link
The alternative to Palantir - an alternative enterprise bespoke system or one built by the companies' or Gov's IT department - costs a whole lot more (25x) and often doesn't work! Palantir is a great value.
elblanco 4 hours ago | link
I presume you're talking about the DCGS-A system. Palantir has done an expert level job confusing the public on this.
That system definitely has problems (it's terrible and sucks in many places), but it's a system of much larger capability and complexity than Palantir.
Comparing Palantir to it is like comparing a wheel to a an entire transport system. Palantir could comfortably fit in as a single capabilty in DCGS-A (and probably do a better job than the stuff currently filling in that role), but it could never replace it.
It's basically just a federated search, mediocre map and halfway decent link-analysis tool. But ask it to do anything even remotely outside of those three things and you're basically dead in the water as it doesn't offer anything relevant to all the other millions of things DCGS-A provides. DCGS-A is more than just some analytic tools.
The reason it's not part of DCGS-A is very political and complex and as much Palantir's doing as the Army's, but the answer is that the components that are on DCGS-A that basically do what Palantir does were selected because they're cheaper over the long run, even if a bit clunky. For example, on the client side, there's presently a forward looking mandate from big Army to drop flash and java clients (because they're an IT administrative menace). Palantir's front end is Java.
steakejjs 8 hours ago | link
The question I am asking is, do they really have the demand to make $1.5million a customer pay (or look like one day it could pay) for their expenses?
My guess is your estimates are really conservative.
halcyondaze 8 hours ago | link
Thanks for breaking that down. I was looking cluelessly at the price sheet for the actual prices.
incision 9 hours ago | link
All right in line with just about any sort of "Enterprise" software. Training and implementation services are downright cheap. Maintenance is the standard 20%.
The last big vendor PO I had to look at put every professional services line item at $300-360/hr with $320 being about average.
sien 9 hours ago | link
Also Palantir's software actually does something more challenging than a lot of enterprise software.
People should go and see what small packages from Oracle, HP, Tibco & IBM cost. It's incredible.
elblanco 5 hours ago | link
Funny you should mention that. Palantir's main competition in the governmeent, i2, is now IBM.
i2 was selling their software at some fraction of Palantir's and in the DoD space it's basically as ubiquitous as Microsoft Office. Palantir is everywhere, but it doesn't end up being used nearly as much.
meowface 6 hours ago | link
Yep, absolutely. This is a perfectly reasonable price for good enterprise software that actually adds value to an organization. (God, I feel like a middle manager just by typing that...).
My company spends tens of millions per year on some really awful enterprise software unfortunately.
aliasaria 6 hours ago | link
Favourite part: "Palantir is in no way affiliated with, or endorsed or sponsored by, The Saul Zaentz Company d.b.a. Tolkien Enterprises or the Estate of J.R.R. Tolkien."
jamesash 6 hours ago | link
Funny, but necessary. The Zaentz company is notoriously litigious. From Zaentz' Wikipedia article: "In 2011, Zaentz's company began several legal actions against small businesses in the UK to enforce their "Hobbit" trade mark, including the Hungry Hobbit cafe in Sarehole, near Birmingham[13][14] and a pub in Southampton, England, which had traded as The Hobbit for twenty years.[15] This raised the ire of many British correspondents such as Stephen Fry, who described it as "pointless, self-defeating bullying."
Jabbles 7 hours ago | link
Agencies can browse GSA Advantage! by accessing the Internet World Wide Web utilizing a browser (ex.: NetScape)
mikegreen 8 hours ago | link
Do not confuse the GSA schedule with actual implementation cost (or TCO as mentioned below). The prices are a starting point and as with any relationship, they can (and will, if the buyer is smart) be negotiated.
Source: sold & implemented alot of software for the gubbmint.
hendzen 6 hours ago | link
If you read between the lines, notice how the "Palantir Gotham Appliance" for 151,042.82 includes "Palantir recommended...database software licenses."
I would bet Oracle (or MS/IBM) is getting a hefty chunk of that.
mmcclellan 4 hours ago | link
Yeah but it's only $10k a core more. This job posting lists Oracle and PostgeSQL:
dfc 4 hours ago | link
I think it is Postgres.
amalag 10 hours ago | link
You can't do diddly with an off the shelf install. They get you on the Implementation Ninjas and Support.
elblanco 5 hours ago | link
Their implementation periods are horrendous. Their marketing speak and sales drones make it sound like a turnkey appliance...like you just drop it in, point it to your database URLS and you're now playing with knowledge management. But in practice there's months of custom backend Java development (the entire tech stack is Java 1.6 or something horrible) to build the connectors and map the data into their backend, then months of ontology management meetings to build up the one-true-model (TM) for all your enterprise needs.
Then months and months of post deployment tweaking and continuous work to keep the system alive and fix issues when some of the data sources change schemas or something.
I've heard things like average time from purchase to full deployment is something like 9 months. But from my time dealing with them I think it's much longer.
fishcakes 4 hours ago | link
That is simply FUD  Palantir guarantees to customers that their software is working within 90 days AND has generated results. They offer a refund if not. Their homepage said this for a while!
elblanco 4 hours ago | link
Well, feel free to buy a core and let me know how long it takes before you're up and running. Having been on the inside during 3 of their deployments, and on the outside of 2 more, I can definitely say 90 days is wildly optimistic.
edit never mind, after reviewing your comment history, it looks like you probably work for Palantir. You should probably disclose that. I stand by my comments about deployment times.
capkutay 9 hours ago | link
I think they get you on the off the shelf price too..
$150k/core...say you run it on a cluster of relatively puny machines ...($150k * 4 cores) on a 4 node cluster is already above $2m.
dlinder 7 hours ago | link
132-51 CONS CONUS FSR Support hourly rate. CONUS rates will be billed for Services performed outside the continental U.S. unless in a warzone. Normal business hours are defined as an 8-hour work day (rate is 15% more outside of normal business hours). $ 146.60
132-51 OCONS OCONUS FSR Support hourly rate. OCONUS rates will be billed for Services performed in a warzone. Normal business hours are defined as a 12-hour work day (rate is 15% more outside of normal business hours). $ 195.47
bane 7 hours ago | link
I'm actually surprised how cheap their OCONUS warzone rates are. Many contractors will pay hazardous bonuses, time in theater bonuses and living condition bonuses on top of the CONUS base pay. Added up it can far exceed this kind of rate.
But this is probably helpful for people getting into consulting to see what hourly rates are for this kind of work. In my experience these rates are actually fairly cheap. I'm used to seeing $170-200 for most things billed to the government.
But I've also heard Palantir has fairly conservative pay caps, that might account for the low rates.
judgardner 10 hours ago | link
132-51 | IMS | Implementation Ninja Services
dkarapetyan 9 hours ago | link
So ost.
bane 6 hours ago | link
It's less automated data analytics and more chart drawing and semantic knowledge base management tied to a federated search system.
Their principle competitor is They used to have a free trial you could run via java webstart on their website, but they've taken it down.
Here's a video It's big data in the sense that using google's search box is big data. But from my time using their demo a couple years ago, the actual tool is fairly small in focus. I don't even think the chart view can show more than a few hundred things.
mayneack 2 hours ago | link
It's still up: bane 1 hour ago | link
Oh okay cool. That's a different demo. The old one was Operation Tradewinds or something.
mayneack 1 hour ago | link
Tradestop is what you're thinking of.
AJ007 5 hours ago | link
Interesting, it looks a lot like Maltego.
fishcakes 10 hours ago | link
Pretty affordable considering many other things on the GSA don't work once you buy them!
jonknee 8 hours ago | link
Luckily for Palantir whether or not it works is classified. I have my doubts. I'm sure it "works", but I'm also sure it's a giant waste of money and Americans are not safer because we're funneling millions of dollars to Palantir.
bane 6 hours ago | link
I messed around with the demo they used to have on their website. It seems to be very much an answer to the 9-11 failure to connect the dots problem.
Unify search, build semantic links.
It was a very manually intensive tool based on what I saw. Very little automation, more like those pictures and strings you see in crime shows on TV...but on a computer.
arikrak 7 hours ago | link
How do they get such precise prices? If I was selling something for 140k, I would sell it for 140k. But they sell it for $141,015.42.
pvarangot 6 hours ago | link
It's GSA price. My guess is the retail price is somewhat rounder, and after tax and other specific discounts it comes down to that.
m0nastic 5 hours ago | link
Strictly speaking, being on the GSA schedule and being able to offer products/services for sale to the federal government requires that you not sell that product/service anywhere else for less than that GSA price.
This is actually one of the reasons that doing business with the government is less lucrative than the commercial industry (for products and services which are comparable, many are things only sold to the government, so there is no hesitation about pricing them through the roof).
As you can imagine, one of the ways that duplicitous federal contractors get around the idea of having to sell to the government for less than their normal prices is to structure their products/services as different (and therefore not apples to apples comparable).
I still would bet that the price that they charge Goldman Sachs (just as an example, I don't actually know which investment banks are using their product) is higher than what they charge for any individual government client.
Also, I think it's probably worth noting that the maximum addressable customer base for their products for federal agencies is way smaller than the equivalent number of financial customers. There's really only a handful of agencies that have this capability (I'd guess more than a handful, but probably less than a dozen).
tptacek 6 hours ago | link
Yes: GSA prices are IIRC the result of a pro-forma (and totally BS) discounting process.
phmagic 10 hours ago | link
pretty affordable compared to most enterprise software packages
bicknergseng 10 hours ago | link
"per core"
trhway 9 hours ago | link
with 90 days warranty :) Can it rot?
Anyway, from their Gotham page "Working closely with the customer, our engineers integrate and map all of the relevant source dataregardless of type or volumeinto a single, coherent model.
Once the model has ted, data flows continuously from its sources into the Palantir Gotham platform.
They can search across all of their data sources at once, visualize relationships, explore divergent hypotheses, discover unknown connections, "
Pretty much my 2009 pitch, and in the hindsight i see that my main weakness was that i couldn't even imagine $150K/core. Man, it is imagination what separates losers from winners! :)
sz4kerto 8 hours ago | link
kdb, a database engine I consider extremely simple compared to Palantir costs $50k/yr/core.
mmcclellan 4 hours ago | link
simple but competent for time series. and the 32-bit version is at least available for free now.
xacaxulu 8 hours ago | link
So Palantir is hiring if you have a clearance :-). Time to get your tax dollars back. Looks like SAIC all over again.
xamdam 6 hours ago | link
You don't need a clearance. We have large commercial deployments.
bane 4 hours ago | link
I did some consulting work with the NYPD and heard you guys also have some deployments with them and other large police forces. Those are nice non-clearance, but cool, jobs as well.

@_date: 2014-09-17 11:33:42
@_author: Eugen Leitl 
@_subject: PFS is a global, versioned, peer-to-peer filesystem 
IPFS is a global, versioned, peer-to-peer filesystem.
It combines good ideas from Git, BitTorrent, Kademlia, SFS, and the Web. It
is like a single bittorrent swarm, exchanging git objects. IPFS provides an
interface as simple as the HTTP web, but with permanence built in. You can
also mount the world at /ipfs.
How does it work? Read the paper

@_date: 2015-04-14 15:33:28
@_author: Eugen Leitl 
@_subject: lowRISC tagged memory preview release 
lowRISC tagged memory preview release
Monday, April 13, 2015
Were pleased to announce the first lowRISC preview release,
demonstrating support for tagged memory as described in our memo. Our
ambition with lowRISC is to provide an open-source System-on-Chip platform
for others to build on, along with low-cost development boards featuring a
reference implementation. Although theres more work to be done on the
tagged memory implementation, now seemed a good time to document what
weve done in order for the wider community to take a look. Please see
our full tutorial which describes in some detail the changes weve made
to the Berkeley Rocket core, as well as how you can build and try it out for
yourself (either in simulation, or on an FPGA). Weve gone to some effort
to produce this documentation, both to document our work, and to share our
experiences building upon the Berkeley RISC-V code releases in the hopes
theyll be useful to other groups.
The initial motivation for tagged memory was to prevent control-flow
hijacking attacks, though there are a range of other potential uses including
fine-grained memory synchronisation, garbage collection, and debug tools.
Please note that the instructions used to manipulate tagged memory in this
release (ltag and stag) are only temporary and chosen simply because they
require minimal changes to the core pipeline. Future work will include
exploring better ISA support, collecting performance numbers across a range
of tagged memory uses and tuning the tag cache. We are also working on
developing an untethered version of the SoC with the necessary
peripherals integrated for standalone operation.
If youve visited lowrisc.org before, youll have noticed weve
changed a few things around. Keep an eye on this blog (and its RSS feed) to
keep an eye on developments - we expect to be updating at least every couple
of weeks. Were very grateful to the RISC-V team at Berkeley for all
their support and guidance. A large portion of the credit for this initial
code release goes to Wei Song, whos been working tirelessly on the HDL

@_date: 2015-04-14 15:33:28
@_author: Eugen Leitl 
@_subject: lowRISC tagged memory preview release 
lowRISC tagged memory preview release
Monday, April 13, 2015
Were pleased to announce the first lowRISC preview release,
demonstrating support for tagged memory as described in our memo. Our
ambition with lowRISC is to provide an open-source System-on-Chip platform
for others to build on, along with low-cost development boards featuring a
reference implementation. Although theres more work to be done on the
tagged memory implementation, now seemed a good time to document what
weve done in order for the wider community to take a look. Please see
our full tutorial which describes in some detail the changes weve made
to the Berkeley Rocket core, as well as how you can build and try it out for
yourself (either in simulation, or on an FPGA). Weve gone to some effort
to produce this documentation, both to document our work, and to share our
experiences building upon the Berkeley RISC-V code releases in the hopes
theyll be useful to other groups.
The initial motivation for tagged memory was to prevent control-flow
hijacking attacks, though there are a range of other potential uses including
fine-grained memory synchronisation, garbage collection, and debug tools.
Please note that the instructions used to manipulate tagged memory in this
release (ltag and stag) are only temporary and chosen simply because they
require minimal changes to the core pipeline. Future work will include
exploring better ISA support, collecting performance numbers across a range
of tagged memory uses and tuning the tag cache. We are also working on
developing an untethered version of the SoC with the necessary
peripherals integrated for standalone operation.
If youve visited lowrisc.org before, youll have noticed weve
changed a few things around. Keep an eye on this blog (and its RSS feed) to
keep an eye on developments - we expect to be updating at least every couple
of weeks. Were very grateful to the RISC-V team at Berkeley for all
their support and guidance. A large portion of the credit for this initial
code release goes to Wei Song, whos been working tirelessly on the HDL

@_date: 2015-04-14 15:33:28
@_author: Eugen Leitl 
@_subject: lowRISC tagged memory preview release 
lowRISC tagged memory preview release
Monday, April 13, 2015
Were pleased to announce the first lowRISC preview release,
demonstrating support for tagged memory as described in our memo. Our
ambition with lowRISC is to provide an open-source System-on-Chip platform
for others to build on, along with low-cost development boards featuring a
reference implementation. Although theres more work to be done on the
tagged memory implementation, now seemed a good time to document what
weve done in order for the wider community to take a look. Please see
our full tutorial which describes in some detail the changes weve made
to the Berkeley Rocket core, as well as how you can build and try it out for
yourself (either in simulation, or on an FPGA). Weve gone to some effort
to produce this documentation, both to document our work, and to share our
experiences building upon the Berkeley RISC-V code releases in the hopes
theyll be useful to other groups.
The initial motivation for tagged memory was to prevent control-flow
hijacking attacks, though there are a range of other potential uses including
fine-grained memory synchronisation, garbage collection, and debug tools.
Please note that the instructions used to manipulate tagged memory in this
release (ltag and stag) are only temporary and chosen simply because they
require minimal changes to the core pipeline. Future work will include
exploring better ISA support, collecting performance numbers across a range
of tagged memory uses and tuning the tag cache. We are also working on
developing an untethered version of the SoC with the necessary
peripherals integrated for standalone operation.
If youve visited lowrisc.org before, youll have noticed weve
changed a few things around. Keep an eye on this blog (and its RSS feed) to
keep an eye on developments - we expect to be updating at least every couple
of weeks. Were very grateful to the RISC-V team at Berkeley for all
their support and guidance. A large portion of the credit for this initial
code release goes to Wei Song, whos been working tirelessly on the HDL

@_date: 2015-02-21 14:28:14
@_author: Eugen Leitl 
@_subject: [Comp-neuro] RA position =?utf-8?B?4oCT?= 
=?utf-8?B?4oCT?= Brown University (Providence, RI)

@_date: 2015-02-21 14:28:14
@_author: Eugen Leitl 
@_subject: [Comp-neuro] RA position =?utf-8?B?4oCT?= 
=?utf-8?B?4oCT?= Brown University (Providence, RI)

@_date: 2015-02-21 14:28:14
@_author: Eugen Leitl 
@_subject: [Comp-neuro] RA position =?utf-8?B?4oCT?= 
=?utf-8?B?4oCT?= Brown University (Providence, RI)

@_date: 2015-06-16 10:11:31
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] questions about bitcoin-XT code fork & 
Hi Mike
Well thank you for replying openly on this topic, its helpful.
I apologise in advance if this gets quite to the point and at times
blunt, but transparency is important, and we owe it to the users who
see Bitcoin as the start of a new future and the$3b of invested funds
and $600m of VC funds invested in companies, we owe it to them that we
be open and transparent here.
I would really prefer on a personal nor professional basis to be
having this conversation period, never mind in public, but Mike - your
and Gavin's decision to promote a unilateral hard-fork and code fork
are extremely high risk for bitcoin and so there remains little
choice.  So I apologise again that we have to have this kind of
conversation on a technical discussion list.  This whole thing is
hugely stressful and worrying for developers, companies and investors.
I strongly urge that we return to the existing collaborative
constructive review process that has been used for the last 4 years
which is a consensus by design to prevent one rogue person from
inserting a backdoor, or lobbying for a favoured change on behalf of a
special interest group, or working for bad actor (without accusing you
of any of those - I understand you personally just want to scale
bitcoin, but are inclined to knock heads and try to force an issue you
see, rather than work collaboratively).
For you (and everyone)
- Should there be a summit of some kind, that is open attendance, and
video recorded so that people who are unable to attend can participate
too, so that people can present the technical proposals and risks in
an unbiased way?
(It is not theoretical question, I may have a sponsor and host - not
Blockstream, an independent, its a question for everyone, developers,
users, CTOs, CEOs.)
So here I come back to more frank questions:
The rest of the developers are wise to realise that they do not want
exclusive control, to avoid governance centralising into the hands of
one person, and this is why they have shared it with a consensus
process over the last 4 years.  No offence but I dont think you
personally are thinking far enough ahead to think you want personal
control of this industry.  Maybe some factions dont trust your
motives, or they dont mind, but feel more assured if a dozen other
people are closely reviewing and have collective review authority.
- Do you understand that attempting to break this process by
unilateral hard-fork is extremely weakening of Bitcoin's change
governance model?
- Do you understand that change governance is important, and that it
is important that there be multiple reviewers and sign-off to avoid
someone being blackmailed or influenced by an external party - which
could potentially result in massive theft of funds if something were
- Secondarily do you understand that even if you succeed in a
unilateral fork (and the level of lost coins and market cap and damage
to confidence is recoverable), that it sets a precedent that others
may try to follow in the future to introduce coercive features that
break the assurances of bitcoin, like fungibility reducing features
say (topically I hear you once proposed on a private forum the concept
of red-lists, other such proposals have been made and quickly
abandoned), or ultimately if there is a political process to obtain
unpopular changes by unilateral threat, the sky is the limit - rewrite
the social contract at that point without consensus, but by
calculation that people will value Bitcoin enough that they will
follow a lead to avoid risk to the system?
As you probably know some extremely subtle bugs in Bitcoin have at
times slipped past even the most rigorous testings, often with
innocuous but unexpected behaviours, but some security issues  Some
extremely intricate and time-sensitive security defect and incident
response happens from time to time which is not necessarily publicly
disclosed until after the issue has been rolled out and fixed, which
can take some time due to the nature of protocol upgrades,
work-arounds, software upgrade via contacting key miners etc.  We
could take an example of the openSSL bug.
- How do you plan to deal with security & incident response for the
duration you describe where you will have control while you are
deploying the unilateral hard-fork and being in sole maintainership
- Are you a member of the bitcoin security reporting list?
As you know the people who have written 95% of the code (and reviewed,
and tested, and formally proved segments etc) are strenuously advising
not to push any consensus code into public use without listening to
and addressing review questions which span beyond rigorous code &
automated guided fuzz testers, simulation and sometimes formal proofs,
but also economics, game-theory and critically very subtle
determinism/consensus safety that they have collectively 4-5 years
experience of each.
- Will you pause your release plans if all of the other developers
insist that the code or algorithm is defective?
- Please don't take this the wrong way, and I know your bitcoinj work
was a significant engineering project which required porting bitcoin
logic.  But If the answer to the above question is no, as you seemed
to indicate in your response, as you not have not written much bitcoin
core code yourself (I think 3 PRs in total), do you find yourself more
qualified than the combination of peer review of the group of people
who have written 95% of it, and maintained it and refactored most of
it over the last 4-5 years?
I presume from your security background you are quite familiar with
the need for review of crypto protocol changes & rigorous code review.
That is even more the case with Bitcoin given the consensus
That you are frustrated, is not a sufficient answer as to why you are
proposing to go ahead with a universally acknowledged extreme network
divergence danger unilateral hard-fork, lacking wide-spread consensus.
People are quite concerned about this.  Patience, caution and prudence
is necessary in a software system with such high assurance
So I ask again:
- On the idea of a non-consensus hard-fork at all, I think we can
assume you will get a row of NACKs.  Can you explain your rationale
for going ahead anyway?  The risks are well understood and enormous.
Note the key point is that you are working on a unilateral hard-fork,
where there is a clear 4 year established process for proposing
improvements and an extremely well thought out and important change
management governance process.  While there has been much discussion,
you nor Gavin, have not actually posted a BIP for review.  Nor
actually was much of the discussion even conducted in the open: it was
only when Matt felt the need to clear the air and steer this
conversation into the open that discussion arose here.  During that
period of private discussion you and Gavin were largely unknown to
most of us lobbying companies with your representation of a method
that concerns everyone of the Bitcoin users.  Now that the technical
community aware aware they are strenuously discouraging you on the
basis of risks.
- Do you agree that bitcoin technical discussions should happen in the open?
- As this is a FOSS project, do you agree that companies should also
be open, about their requirements and trade-offs they would prefer?
- Can you disclose the list of companies you have lobbied in private
whether they have spoken publicly or not, and whether they have
indicated approval or not?
- Did you share a specific plan, like a BIP or white paper with these
companies, and if so can we see it?
- If you didnt submit a plan, could you summarise what you asked them
and what you proposed, and if you discussed also the risks?  (If you
asked them if they would like Bitcoin to scale, I expect almost
everyone does, including every member of the technical community, so
that for example would not fairly indicate approval for a unilateral
I and others will be happy to talk with the CTO and CEOs of companies
you have lobbied in private, for balance to assure ourselves and the
rest of the community that their support was given - and with full
understanding of the risks of doing it unilaterally, without peer
review, benefit of maintenance and security inidence management, and
what exactly they are being quoting as having signed up for.
(This maybe more efficiently and openly achieved by the open process,
on a mailing list, maybe a different one even special purpose to this
topic, with additional option of the open public meeting I proposed at
the top).
- Do you agree that it would be appropriate, that companies be aware
of both the scaling opportunities (of course, great everyone wants
scalability) as well as the technical limits and risks with various
approaches?  And that these be presented by parties from a range of
views to ensure balance?
- Do you consider your expression of issues to hold true to the ideal
of representing balanced nuanced view of all sides of a technical
debate, even when under pressure or feeling impatient about the
You may want to review the opening few minutes of your epicenter 82
bitcoin for example where you claimed and I quote "[the rest of the
technical community] dont want capacity to ever increase and want it
to stay where it is and when it fills up people move to other
- Do you think that is an accurate depiction of the complex trade-offs
we have been discussing on this list?
(For the record I am not aware of a single person who has said they do
not agree with scaling Bitcoin.  Changing a constant is not the
hard-part.  The hard part is validating a plan and the other factors
that go into it.  It's not a free choice it is a security/scalability
tradeoff.  No one will thank us if we "scale" bitcoin but break it in
hard to recover ways at the same time.)
- Were you similarly balanced in your explanations when talking to
companies in private discussions?
- Do you understand that if we do not work from balanced technical
discussion, that we may end up with some biased criteria?
Neither you nor Gavin have any particular authority here to speak on
behalf of Bitcoin (eg you acknowledge in your podcast that Wladimir is
dev lead, and you and Gavin are both well aware of the 4 year
established change management consensus decision making model where
all of the technical reviewers have to come to agreement before
changes go in for security reasons explained above).  I know Gavin has
a "Chief Scientist" title from the Bitcoin Foundation, but sadly that
organisation is not held in as much regard as it once was, due to
various irregularities and controversies, and as I understand it no
longer employs any developers, due to lack of funds.  Gavin is now
employed by MIT's DCI project as a researcher in some capacity.  As
you know Wladimir is doing the development lead role now, and it seems
part of your personal frustration you said was because he did not
agree with your views.  Neither you nor Gavin have been particularly
involved in bitcoin lately, even Gavin, for 1.5 years or so.
- Do you agree that if you presume to speak where you do not have
authority you may confuse companies?
But I think this is a false dichotomy.  As I said in previous mail I
understand people are frustrated that it has taken so long, but it is
not the case that no progress has been made on scalability.
I itemised a long list of scalability work which you acknowledged as
impressive work (CPU, memory, network bandwidth/latency) and RBF, CPFP
fee work, fee-estimation, and so on, which you acknowledged and are
aware of.
There are multiple proposals and BIPs under consideration on the list right now.
- what is the reason that you (or Gavin) would not post your BIP along
side the others to see if it would win based on technical merit?
- why would you feel uniquely qualified to override the expert opinion
of the rest of the technical community if your proposal were not
considered to have most technical merit? (Given that this is not a
simple market competition thing where multiple hard-forks can be
considered - it is a one only decision, and if it is done in a
divisive unilateral way there are extreme risks of the ledger
Network Divergence Risk
But this is not a soft-fork, it is a hard-fork.  Miner voting is only
peripherally related.  Even if in the extremis 75% of miners tried a
unilateral hard-fork but 100% of the users stayed on the maintained
original code, no change would occur other than those miners losing
reward (mining fork-coins with no resale value) and the difficulty
would adjust.  The miners who made an error in choice would lose money
and go out of business or rejoin the chain.
However if something in that direction happens with actual users and
companies on both sides of it users will lose money, the ledger will
diverge as soon as a single double-spend happens, and never share a
block again, companies will go instantly insolvent, and chaos will
break out.  This is the dangerous scenario we are concerned about.
So the same question again:
- How do you propose to deal with the extra risks that come from
non-consensus hard-forks?  Hard-forks themselves are quite risky, but
non-consensus ones are extremely dangerous for consensus.
Being sensitive to alarming the market
It is something akin to Greece or Portugal or Italy exiting the euro
currency in a disorderly way.  Economists and central bank policy
makers are extremely worried about such an eventuality and talk about
related factors in careful, measured terms, watch Mario Draghi when he
Imagine that bitcoin is 10x or 100x bigger.  Bitcoin cant have people
taking unilateral actions such as you have been proposing.  It is not
following the consensus governance process, and not good policy and it
is probably affecting bitcoin confidence and price at this moment.
This is not a soft-fork, and the community will not want to take the
risks once they understand them, and they have months in which to
understand them and at this point you've motivated and wasted 100s of
developer man hours such that we will feel impelled to make sure that
no one opts into a unilateral hard-fork without understanding the
risks.  It would be negligent to allow people to do that.  Before this
gets very far FAQs will be on bitcoin.org etc explaining this risk I
would imagine.  Its just starting not finished.
What makes you think the rest of the community may not instead prefer
Jeff Garzik's BIP after revisions that he is making now with review
comments from others?
Or another proposal.  Taken together with a deployment plan that sees
work on decentralisation tying into that plan.
- If you persisted anyway, what makes you think bitcoin could not make
code changes defensively relating to your unilateral fork?
(I am sure creative minds can find some ways to harden bitcoin against
a unilateral fork, with a soft-fork or non-consensus update can be
deployed much faster than a hard-fork).
I tried to warn Gavin privately that I thought he was under-estimating
the risk of failure to his fork proposal due to it being unilateral.
Ie as you both seem sincere in your wish to have your proposal
succeed, then obviously the best way to do that is to release a BIP in
the open collaborative process and submit it to review like everyone
else.  Doing it unilaterally only increases its chance of failure.
The only sensible thing to do here is submit a BIP and stop the
unilateral fork threat.
Scalability Plans
Yes people have proposed other plans.  Bryan Bishop posted a list of them.
Jeff Garzik has a proposal, BIP-100 which seems already better than
Gavin's having benefit of peer review which he has been incorporating.
I proposed several soft-fork models which can be deployed safely and
immediately, which do not have ledger risk.
I have another proposal relating to simplified soft-fork one-way pegs
which I'll write up in a bit.
I think there are still issues in Jeff's proposal but he is very open
and collaborating and there maybe related but different proposals
It does not seem to me that you understand the issue.  Of course they
want to increase the scalability of bitcoin.  So does everyone else on
this mailing list.
That they would support that is obvious.  If you presented your
unilateral action plan without explaining the risks too.
I think I covered this further above.  If you would like to share the
company list, or we can invite them to the proposed public physical
meeting, I think it would be useful for them to have a balanced view
of the ledger divergence risks, and alternative in-consensus proposals
underway, as well as the governance risks, maintenance risks, security
incident risks.
Note that other people talk to companies too, as part of their day to
day jobs, or from contacts from being in the industry.  You have no
special authority or unique ability to talk with business people.  Its
just that the technical community did not know you were busy doing
I can not believe that any company that would listen to their CTO, CSO
or failing that board would be ok with the risks implied by what you
are proposing on full examination.
I know you want scale bitcoin, as I said everyone here does. I think
what you're experiencing is that you've had more luck explaining your
pragmatic unilateral plan to non-technical people without peer review,
and so not experienced the kind of huge pushback you are getting from
the technical community.  The whole of bitcoin is immensely
complicated such that it takes an uber-geek CS genius years to
catchup, this is not a slight of any of the business people who are
working hard to deploy Bitcoin into the world, its just complicated
and therefore not easy to understand the game-theory, security,
governance and distributed system thinking.  I have a comp sci PhD in
distributed systems, implemented p2p network systems and have 2
decades of applied crypto experience with a major interest in
electronic cash crypto protocols, and it took me a several years to
catchup and even I have a few hazy spots on low-level details, and I
addictively into read everything I could find.  Realistically all of
us are still learning, as bitcoin combines so many fields that it
opens new possibilities.
What I am expecting that yourself and Gavin are thinking is that
you'll knock heads and force the issue and get to consensus.
However I think you have seriously misjudged the risks and have not
adequately explained them to companies you are talking with.  Indeed
you do not fully seem to acknowledge the risks, nor to have a well
thought out plan here of how you would actually manage it, nor the
moral hazards of having a lone developer in hugely divisive
circumstances in sole control of bitcoins running code.  Those are
exactly the reasons for the code change governance process!
Even though you are trying to help, the full result is you are not
helping achieve anything by changing a constant and starting a
unilateral hard-fork (not to trivialise the work of making a patch to
do that).
The work to even make the constant change be feasible was a result of
1000s of hours of work by others in the development community, that is
emphatically and unilaterally telling you that hard-forks are hugely
You are trying to break the code change governance security procedure
that were put in place for good reason for the security of $3b of
other peoples money, even if you have a pragmatic intent to help, this
is flat out unacceptable.
There are also security implications to what you are proposing, which
I have heard you attempting to trivialise, that are core to Bitcoins
security and core functionality.
I think this is a significant mischaracterisation, and I think almost
everybody is on board with a combination plan:
1. work to improve decentralisation (specific technical work already
underway, and education)
2. create a plan to increase block-size in a slow fashion to not cause
system shocks (eg like Jeff is proposing or some better variant)
3. work on actual algorithmic scaling
In this way we can have throughput needed for scalability and security
work to continue.
As I said you can not scale a O(n^2) broadcast network by changing
constants, you need algorithmic improvements.
People are working on them already.  All of those 3 things are being
actively worked on RIGHT NOW, and in the case of algorithmic scaling
and improve decentralisation have been worked on for months.
You may have done one useful thing which is to remind people that
blocks are only 3x-4x below capacity such that we should look at it.
But we can not work under duress of haste, nor unilateral ultimatums,
this is the realm of human action that leads to moral hazard, and
ironically reminds us of why Satoshi put the quote in the genesis
Bitcoin is too complex a system with too much at stake to be making
political hasty decisions, it would be negligent to act in such a way.
Again please consider that you did your job, caused people to pay
attention, but return to the process, submit a BIP, retract the
unilateral hard-fork which is so dangerous and lets have things be
calm, civil and collaborative in the technical zone of Bitcoin and not
further alarm companies and investors.

@_date: 2015-06-16 10:11:31
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] questions about bitcoin-XT code fork & 
Hi Mike
Well thank you for replying openly on this topic, its helpful.
I apologise in advance if this gets quite to the point and at times
blunt, but transparency is important, and we owe it to the users who
see Bitcoin as the start of a new future and the$3b of invested funds
and $600m of VC funds invested in companies, we owe it to them that we
be open and transparent here.
I would really prefer on a personal nor professional basis to be
having this conversation period, never mind in public, but Mike - your
and Gavin's decision to promote a unilateral hard-fork and code fork
are extremely high risk for bitcoin and so there remains little
choice.  So I apologise again that we have to have this kind of
conversation on a technical discussion list.  This whole thing is
hugely stressful and worrying for developers, companies and investors.
I strongly urge that we return to the existing collaborative
constructive review process that has been used for the last 4 years
which is a consensus by design to prevent one rogue person from
inserting a backdoor, or lobbying for a favoured change on behalf of a
special interest group, or working for bad actor (without accusing you
of any of those - I understand you personally just want to scale
bitcoin, but are inclined to knock heads and try to force an issue you
see, rather than work collaboratively).
For you (and everyone)
- Should there be a summit of some kind, that is open attendance, and
video recorded so that people who are unable to attend can participate
too, so that people can present the technical proposals and risks in
an unbiased way?
(It is not theoretical question, I may have a sponsor and host - not
Blockstream, an independent, its a question for everyone, developers,
users, CTOs, CEOs.)
So here I come back to more frank questions:
The rest of the developers are wise to realise that they do not want
exclusive control, to avoid governance centralising into the hands of
one person, and this is why they have shared it with a consensus
process over the last 4 years.  No offence but I dont think you
personally are thinking far enough ahead to think you want personal
control of this industry.  Maybe some factions dont trust your
motives, or they dont mind, but feel more assured if a dozen other
people are closely reviewing and have collective review authority.
- Do you understand that attempting to break this process by
unilateral hard-fork is extremely weakening of Bitcoin's change
governance model?
- Do you understand that change governance is important, and that it
is important that there be multiple reviewers and sign-off to avoid
someone being blackmailed or influenced by an external party - which
could potentially result in massive theft of funds if something were
- Secondarily do you understand that even if you succeed in a
unilateral fork (and the level of lost coins and market cap and damage
to confidence is recoverable), that it sets a precedent that others
may try to follow in the future to introduce coercive features that
break the assurances of bitcoin, like fungibility reducing features
say (topically I hear you once proposed on a private forum the concept
of red-lists, other such proposals have been made and quickly
abandoned), or ultimately if there is a political process to obtain
unpopular changes by unilateral threat, the sky is the limit - rewrite
the social contract at that point without consensus, but by
calculation that people will value Bitcoin enough that they will
follow a lead to avoid risk to the system?
As you probably know some extremely subtle bugs in Bitcoin have at
times slipped past even the most rigorous testings, often with
innocuous but unexpected behaviours, but some security issues  Some
extremely intricate and time-sensitive security defect and incident
response happens from time to time which is not necessarily publicly
disclosed until after the issue has been rolled out and fixed, which
can take some time due to the nature of protocol upgrades,
work-arounds, software upgrade via contacting key miners etc.  We
could take an example of the openSSL bug.
- How do you plan to deal with security & incident response for the
duration you describe where you will have control while you are
deploying the unilateral hard-fork and being in sole maintainership
- Are you a member of the bitcoin security reporting list?
As you know the people who have written 95% of the code (and reviewed,
and tested, and formally proved segments etc) are strenuously advising
not to push any consensus code into public use without listening to
and addressing review questions which span beyond rigorous code &
automated guided fuzz testers, simulation and sometimes formal proofs,
but also economics, game-theory and critically very subtle
determinism/consensus safety that they have collectively 4-5 years
experience of each.
- Will you pause your release plans if all of the other developers
insist that the code or algorithm is defective?
- Please don't take this the wrong way, and I know your bitcoinj work
was a significant engineering project which required porting bitcoin
logic.  But If the answer to the above question is no, as you seemed
to indicate in your response, as you not have not written much bitcoin
core code yourself (I think 3 PRs in total), do you find yourself more
qualified than the combination of peer review of the group of people
who have written 95% of it, and maintained it and refactored most of
it over the last 4-5 years?
I presume from your security background you are quite familiar with
the need for review of crypto protocol changes & rigorous code review.
That is even more the case with Bitcoin given the consensus
That you are frustrated, is not a sufficient answer as to why you are
proposing to go ahead with a universally acknowledged extreme network
divergence danger unilateral hard-fork, lacking wide-spread consensus.
People are quite concerned about this.  Patience, caution and prudence
is necessary in a software system with such high assurance
So I ask again:
- On the idea of a non-consensus hard-fork at all, I think we can
assume you will get a row of NACKs.  Can you explain your rationale
for going ahead anyway?  The risks are well understood and enormous.
Note the key point is that you are working on a unilateral hard-fork,
where there is a clear 4 year established process for proposing
improvements and an extremely well thought out and important change
management governance process.  While there has been much discussion,
you nor Gavin, have not actually posted a BIP for review.  Nor
actually was much of the discussion even conducted in the open: it was
only when Matt felt the need to clear the air and steer this
conversation into the open that discussion arose here.  During that
period of private discussion you and Gavin were largely unknown to
most of us lobbying companies with your representation of a method
that concerns everyone of the Bitcoin users.  Now that the technical
community aware aware they are strenuously discouraging you on the
basis of risks.
- Do you agree that bitcoin technical discussions should happen in the open?
- As this is a FOSS project, do you agree that companies should also
be open, about their requirements and trade-offs they would prefer?
- Can you disclose the list of companies you have lobbied in private
whether they have spoken publicly or not, and whether they have
indicated approval or not?
- Did you share a specific plan, like a BIP or white paper with these
companies, and if so can we see it?
- If you didnt submit a plan, could you summarise what you asked them
and what you proposed, and if you discussed also the risks?  (If you
asked them if they would like Bitcoin to scale, I expect almost
everyone does, including every member of the technical community, so
that for example would not fairly indicate approval for a unilateral
I and others will be happy to talk with the CTO and CEOs of companies
you have lobbied in private, for balance to assure ourselves and the
rest of the community that their support was given - and with full
understanding of the risks of doing it unilaterally, without peer
review, benefit of maintenance and security inidence management, and
what exactly they are being quoting as having signed up for.
(This maybe more efficiently and openly achieved by the open process,
on a mailing list, maybe a different one even special purpose to this
topic, with additional option of the open public meeting I proposed at
the top).
- Do you agree that it would be appropriate, that companies be aware
of both the scaling opportunities (of course, great everyone wants
scalability) as well as the technical limits and risks with various
approaches?  And that these be presented by parties from a range of
views to ensure balance?
- Do you consider your expression of issues to hold true to the ideal
of representing balanced nuanced view of all sides of a technical
debate, even when under pressure or feeling impatient about the
You may want to review the opening few minutes of your epicenter 82
bitcoin for example where you claimed and I quote "[the rest of the
technical community] dont want capacity to ever increase and want it
to stay where it is and when it fills up people move to other
- Do you think that is an accurate depiction of the complex trade-offs
we have been discussing on this list?
(For the record I am not aware of a single person who has said they do
not agree with scaling Bitcoin.  Changing a constant is not the
hard-part.  The hard part is validating a plan and the other factors
that go into it.  It's not a free choice it is a security/scalability
tradeoff.  No one will thank us if we "scale" bitcoin but break it in
hard to recover ways at the same time.)
- Were you similarly balanced in your explanations when talking to
companies in private discussions?
- Do you understand that if we do not work from balanced technical
discussion, that we may end up with some biased criteria?
Neither you nor Gavin have any particular authority here to speak on
behalf of Bitcoin (eg you acknowledge in your podcast that Wladimir is
dev lead, and you and Gavin are both well aware of the 4 year
established change management consensus decision making model where
all of the technical reviewers have to come to agreement before
changes go in for security reasons explained above).  I know Gavin has
a "Chief Scientist" title from the Bitcoin Foundation, but sadly that
organisation is not held in as much regard as it once was, due to
various irregularities and controversies, and as I understand it no
longer employs any developers, due to lack of funds.  Gavin is now
employed by MIT's DCI project as a researcher in some capacity.  As
you know Wladimir is doing the development lead role now, and it seems
part of your personal frustration you said was because he did not
agree with your views.  Neither you nor Gavin have been particularly
involved in bitcoin lately, even Gavin, for 1.5 years or so.
- Do you agree that if you presume to speak where you do not have
authority you may confuse companies?
But I think this is a false dichotomy.  As I said in previous mail I
understand people are frustrated that it has taken so long, but it is
not the case that no progress has been made on scalability.
I itemised a long list of scalability work which you acknowledged as
impressive work (CPU, memory, network bandwidth/latency) and RBF, CPFP
fee work, fee-estimation, and so on, which you acknowledged and are
aware of.
There are multiple proposals and BIPs under consideration on the list right now.
- what is the reason that you (or Gavin) would not post your BIP along
side the others to see if it would win based on technical merit?
- why would you feel uniquely qualified to override the expert opinion
of the rest of the technical community if your proposal were not
considered to have most technical merit? (Given that this is not a
simple market competition thing where multiple hard-forks can be
considered - it is a one only decision, and if it is done in a
divisive unilateral way there are extreme risks of the ledger
Network Divergence Risk
But this is not a soft-fork, it is a hard-fork.  Miner voting is only
peripherally related.  Even if in the extremis 75% of miners tried a
unilateral hard-fork but 100% of the users stayed on the maintained
original code, no change would occur other than those miners losing
reward (mining fork-coins with no resale value) and the difficulty
would adjust.  The miners who made an error in choice would lose money
and go out of business or rejoin the chain.
However if something in that direction happens with actual users and
companies on both sides of it users will lose money, the ledger will
diverge as soon as a single double-spend happens, and never share a
block again, companies will go instantly insolvent, and chaos will
break out.  This is the dangerous scenario we are concerned about.
So the same question again:
- How do you propose to deal with the extra risks that come from
non-consensus hard-forks?  Hard-forks themselves are quite risky, but
non-consensus ones are extremely dangerous for consensus.
Being sensitive to alarming the market
It is something akin to Greece or Portugal or Italy exiting the euro
currency in a disorderly way.  Economists and central bank policy
makers are extremely worried about such an eventuality and talk about
related factors in careful, measured terms, watch Mario Draghi when he
Imagine that bitcoin is 10x or 100x bigger.  Bitcoin cant have people
taking unilateral actions such as you have been proposing.  It is not
following the consensus governance process, and not good policy and it
is probably affecting bitcoin confidence and price at this moment.
This is not a soft-fork, and the community will not want to take the
risks once they understand them, and they have months in which to
understand them and at this point you've motivated and wasted 100s of
developer man hours such that we will feel impelled to make sure that
no one opts into a unilateral hard-fork without understanding the
risks.  It would be negligent to allow people to do that.  Before this
gets very far FAQs will be on bitcoin.org etc explaining this risk I
would imagine.  Its just starting not finished.
What makes you think the rest of the community may not instead prefer
Jeff Garzik's BIP after revisions that he is making now with review
comments from others?
Or another proposal.  Taken together with a deployment plan that sees
work on decentralisation tying into that plan.
- If you persisted anyway, what makes you think bitcoin could not make
code changes defensively relating to your unilateral fork?
(I am sure creative minds can find some ways to harden bitcoin against
a unilateral fork, with a soft-fork or non-consensus update can be
deployed much faster than a hard-fork).
I tried to warn Gavin privately that I thought he was under-estimating
the risk of failure to his fork proposal due to it being unilateral.
Ie as you both seem sincere in your wish to have your proposal
succeed, then obviously the best way to do that is to release a BIP in
the open collaborative process and submit it to review like everyone
else.  Doing it unilaterally only increases its chance of failure.
The only sensible thing to do here is submit a BIP and stop the
unilateral fork threat.
Scalability Plans
Yes people have proposed other plans.  Bryan Bishop posted a list of them.
Jeff Garzik has a proposal, BIP-100 which seems already better than
Gavin's having benefit of peer review which he has been incorporating.
I proposed several soft-fork models which can be deployed safely and
immediately, which do not have ledger risk.
I have another proposal relating to simplified soft-fork one-way pegs
which I'll write up in a bit.
I think there are still issues in Jeff's proposal but he is very open
and collaborating and there maybe related but different proposals
It does not seem to me that you understand the issue.  Of course they
want to increase the scalability of bitcoin.  So does everyone else on
this mailing list.
That they would support that is obvious.  If you presented your
unilateral action plan without explaining the risks too.
I think I covered this further above.  If you would like to share the
company list, or we can invite them to the proposed public physical
meeting, I think it would be useful for them to have a balanced view
of the ledger divergence risks, and alternative in-consensus proposals
underway, as well as the governance risks, maintenance risks, security
incident risks.
Note that other people talk to companies too, as part of their day to
day jobs, or from contacts from being in the industry.  You have no
special authority or unique ability to talk with business people.  Its
just that the technical community did not know you were busy doing
I can not believe that any company that would listen to their CTO, CSO
or failing that board would be ok with the risks implied by what you
are proposing on full examination.
I know you want scale bitcoin, as I said everyone here does. I think
what you're experiencing is that you've had more luck explaining your
pragmatic unilateral plan to non-technical people without peer review,
and so not experienced the kind of huge pushback you are getting from
the technical community.  The whole of bitcoin is immensely
complicated such that it takes an uber-geek CS genius years to
catchup, this is not a slight of any of the business people who are
working hard to deploy Bitcoin into the world, its just complicated
and therefore not easy to understand the game-theory, security,
governance and distributed system thinking.  I have a comp sci PhD in
distributed systems, implemented p2p network systems and have 2
decades of applied crypto experience with a major interest in
electronic cash crypto protocols, and it took me a several years to
catchup and even I have a few hazy spots on low-level details, and I
addictively into read everything I could find.  Realistically all of
us are still learning, as bitcoin combines so many fields that it
opens new possibilities.
What I am expecting that yourself and Gavin are thinking is that
you'll knock heads and force the issue and get to consensus.
However I think you have seriously misjudged the risks and have not
adequately explained them to companies you are talking with.  Indeed
you do not fully seem to acknowledge the risks, nor to have a well
thought out plan here of how you would actually manage it, nor the
moral hazards of having a lone developer in hugely divisive
circumstances in sole control of bitcoins running code.  Those are
exactly the reasons for the code change governance process!
Even though you are trying to help, the full result is you are not
helping achieve anything by changing a constant and starting a
unilateral hard-fork (not to trivialise the work of making a patch to
do that).
The work to even make the constant change be feasible was a result of
1000s of hours of work by others in the development community, that is
emphatically and unilaterally telling you that hard-forks are hugely
You are trying to break the code change governance security procedure
that were put in place for good reason for the security of $3b of
other peoples money, even if you have a pragmatic intent to help, this
is flat out unacceptable.
There are also security implications to what you are proposing, which
I have heard you attempting to trivialise, that are core to Bitcoins
security and core functionality.
I think this is a significant mischaracterisation, and I think almost
everybody is on board with a combination plan:
1. work to improve decentralisation (specific technical work already
underway, and education)
2. create a plan to increase block-size in a slow fashion to not cause
system shocks (eg like Jeff is proposing or some better variant)
3. work on actual algorithmic scaling
In this way we can have throughput needed for scalability and security
work to continue.
As I said you can not scale a O(n^2) broadcast network by changing
constants, you need algorithmic improvements.
People are working on them already.  All of those 3 things are being
actively worked on RIGHT NOW, and in the case of algorithmic scaling
and improve decentralisation have been worked on for months.
You may have done one useful thing which is to remind people that
blocks are only 3x-4x below capacity such that we should look at it.
But we can not work under duress of haste, nor unilateral ultimatums,
this is the realm of human action that leads to moral hazard, and
ironically reminds us of why Satoshi put the quote in the genesis
Bitcoin is too complex a system with too much at stake to be making
political hasty decisions, it would be negligent to act in such a way.
Again please consider that you did your job, caused people to pay
attention, but return to the process, submit a BIP, retract the
unilateral hard-fork which is so dangerous and lets have things be
calm, civil and collaborative in the technical zone of Bitcoin and not
further alarm companies and investors.

@_date: 2015-06-16 10:11:31
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] questions about bitcoin-XT code fork & 
Hi Mike
Well thank you for replying openly on this topic, its helpful.
I apologise in advance if this gets quite to the point and at times
blunt, but transparency is important, and we owe it to the users who
see Bitcoin as the start of a new future and the$3b of invested funds
and $600m of VC funds invested in companies, we owe it to them that we
be open and transparent here.
I would really prefer on a personal nor professional basis to be
having this conversation period, never mind in public, but Mike - your
and Gavin's decision to promote a unilateral hard-fork and code fork
are extremely high risk for bitcoin and so there remains little
choice.  So I apologise again that we have to have this kind of
conversation on a technical discussion list.  This whole thing is
hugely stressful and worrying for developers, companies and investors.
I strongly urge that we return to the existing collaborative
constructive review process that has been used for the last 4 years
which is a consensus by design to prevent one rogue person from
inserting a backdoor, or lobbying for a favoured change on behalf of a
special interest group, or working for bad actor (without accusing you
of any of those - I understand you personally just want to scale
bitcoin, but are inclined to knock heads and try to force an issue you
see, rather than work collaboratively).
For you (and everyone)
- Should there be a summit of some kind, that is open attendance, and
video recorded so that people who are unable to attend can participate
too, so that people can present the technical proposals and risks in
an unbiased way?
(It is not theoretical question, I may have a sponsor and host - not
Blockstream, an independent, its a question for everyone, developers,
users, CTOs, CEOs.)
So here I come back to more frank questions:
The rest of the developers are wise to realise that they do not want
exclusive control, to avoid governance centralising into the hands of
one person, and this is why they have shared it with a consensus
process over the last 4 years.  No offence but I dont think you
personally are thinking far enough ahead to think you want personal
control of this industry.  Maybe some factions dont trust your
motives, or they dont mind, but feel more assured if a dozen other
people are closely reviewing and have collective review authority.
- Do you understand that attempting to break this process by
unilateral hard-fork is extremely weakening of Bitcoin's change
governance model?
- Do you understand that change governance is important, and that it
is important that there be multiple reviewers and sign-off to avoid
someone being blackmailed or influenced by an external party - which
could potentially result in massive theft of funds if something were
- Secondarily do you understand that even if you succeed in a
unilateral fork (and the level of lost coins and market cap and damage
to confidence is recoverable), that it sets a precedent that others
may try to follow in the future to introduce coercive features that
break the assurances of bitcoin, like fungibility reducing features
say (topically I hear you once proposed on a private forum the concept
of red-lists, other such proposals have been made and quickly
abandoned), or ultimately if there is a political process to obtain
unpopular changes by unilateral threat, the sky is the limit - rewrite
the social contract at that point without consensus, but by
calculation that people will value Bitcoin enough that they will
follow a lead to avoid risk to the system?
As you probably know some extremely subtle bugs in Bitcoin have at
times slipped past even the most rigorous testings, often with
innocuous but unexpected behaviours, but some security issues  Some
extremely intricate and time-sensitive security defect and incident
response happens from time to time which is not necessarily publicly
disclosed until after the issue has been rolled out and fixed, which
can take some time due to the nature of protocol upgrades,
work-arounds, software upgrade via contacting key miners etc.  We
could take an example of the openSSL bug.
- How do you plan to deal with security & incident response for the
duration you describe where you will have control while you are
deploying the unilateral hard-fork and being in sole maintainership
- Are you a member of the bitcoin security reporting list?
As you know the people who have written 95% of the code (and reviewed,
and tested, and formally proved segments etc) are strenuously advising
not to push any consensus code into public use without listening to
and addressing review questions which span beyond rigorous code &
automated guided fuzz testers, simulation and sometimes formal proofs,
but also economics, game-theory and critically very subtle
determinism/consensus safety that they have collectively 4-5 years
experience of each.
- Will you pause your release plans if all of the other developers
insist that the code or algorithm is defective?
- Please don't take this the wrong way, and I know your bitcoinj work
was a significant engineering project which required porting bitcoin
logic.  But If the answer to the above question is no, as you seemed
to indicate in your response, as you not have not written much bitcoin
core code yourself (I think 3 PRs in total), do you find yourself more
qualified than the combination of peer review of the group of people
who have written 95% of it, and maintained it and refactored most of
it over the last 4-5 years?
I presume from your security background you are quite familiar with
the need for review of crypto protocol changes & rigorous code review.
That is even more the case with Bitcoin given the consensus
That you are frustrated, is not a sufficient answer as to why you are
proposing to go ahead with a universally acknowledged extreme network
divergence danger unilateral hard-fork, lacking wide-spread consensus.
People are quite concerned about this.  Patience, caution and prudence
is necessary in a software system with such high assurance
So I ask again:
- On the idea of a non-consensus hard-fork at all, I think we can
assume you will get a row of NACKs.  Can you explain your rationale
for going ahead anyway?  The risks are well understood and enormous.
Note the key point is that you are working on a unilateral hard-fork,
where there is a clear 4 year established process for proposing
improvements and an extremely well thought out and important change
management governance process.  While there has been much discussion,
you nor Gavin, have not actually posted a BIP for review.  Nor
actually was much of the discussion even conducted in the open: it was
only when Matt felt the need to clear the air and steer this
conversation into the open that discussion arose here.  During that
period of private discussion you and Gavin were largely unknown to
most of us lobbying companies with your representation of a method
that concerns everyone of the Bitcoin users.  Now that the technical
community aware aware they are strenuously discouraging you on the
basis of risks.
- Do you agree that bitcoin technical discussions should happen in the open?
- As this is a FOSS project, do you agree that companies should also
be open, about their requirements and trade-offs they would prefer?
- Can you disclose the list of companies you have lobbied in private
whether they have spoken publicly or not, and whether they have
indicated approval or not?
- Did you share a specific plan, like a BIP or white paper with these
companies, and if so can we see it?
- If you didnt submit a plan, could you summarise what you asked them
and what you proposed, and if you discussed also the risks?  (If you
asked them if they would like Bitcoin to scale, I expect almost
everyone does, including every member of the technical community, so
that for example would not fairly indicate approval for a unilateral
I and others will be happy to talk with the CTO and CEOs of companies
you have lobbied in private, for balance to assure ourselves and the
rest of the community that their support was given - and with full
understanding of the risks of doing it unilaterally, without peer
review, benefit of maintenance and security inidence management, and
what exactly they are being quoting as having signed up for.
(This maybe more efficiently and openly achieved by the open process,
on a mailing list, maybe a different one even special purpose to this
topic, with additional option of the open public meeting I proposed at
the top).
- Do you agree that it would be appropriate, that companies be aware
of both the scaling opportunities (of course, great everyone wants
scalability) as well as the technical limits and risks with various
approaches?  And that these be presented by parties from a range of
views to ensure balance?
- Do you consider your expression of issues to hold true to the ideal
of representing balanced nuanced view of all sides of a technical
debate, even when under pressure or feeling impatient about the
You may want to review the opening few minutes of your epicenter 82
bitcoin for example where you claimed and I quote "[the rest of the
technical community] dont want capacity to ever increase and want it
to stay where it is and when it fills up people move to other
- Do you think that is an accurate depiction of the complex trade-offs
we have been discussing on this list?
(For the record I am not aware of a single person who has said they do
not agree with scaling Bitcoin.  Changing a constant is not the
hard-part.  The hard part is validating a plan and the other factors
that go into it.  It's not a free choice it is a security/scalability
tradeoff.  No one will thank us if we "scale" bitcoin but break it in
hard to recover ways at the same time.)
- Were you similarly balanced in your explanations when talking to
companies in private discussions?
- Do you understand that if we do not work from balanced technical
discussion, that we may end up with some biased criteria?
Neither you nor Gavin have any particular authority here to speak on
behalf of Bitcoin (eg you acknowledge in your podcast that Wladimir is
dev lead, and you and Gavin are both well aware of the 4 year
established change management consensus decision making model where
all of the technical reviewers have to come to agreement before
changes go in for security reasons explained above).  I know Gavin has
a "Chief Scientist" title from the Bitcoin Foundation, but sadly that
organisation is not held in as much regard as it once was, due to
various irregularities and controversies, and as I understand it no
longer employs any developers, due to lack of funds.  Gavin is now
employed by MIT's DCI project as a researcher in some capacity.  As
you know Wladimir is doing the development lead role now, and it seems
part of your personal frustration you said was because he did not
agree with your views.  Neither you nor Gavin have been particularly
involved in bitcoin lately, even Gavin, for 1.5 years or so.
- Do you agree that if you presume to speak where you do not have
authority you may confuse companies?
But I think this is a false dichotomy.  As I said in previous mail I
understand people are frustrated that it has taken so long, but it is
not the case that no progress has been made on scalability.
I itemised a long list of scalability work which you acknowledged as
impressive work (CPU, memory, network bandwidth/latency) and RBF, CPFP
fee work, fee-estimation, and so on, which you acknowledged and are
aware of.
There are multiple proposals and BIPs under consideration on the list right now.
- what is the reason that you (or Gavin) would not post your BIP along
side the others to see if it would win based on technical merit?
- why would you feel uniquely qualified to override the expert opinion
of the rest of the technical community if your proposal were not
considered to have most technical merit? (Given that this is not a
simple market competition thing where multiple hard-forks can be
considered - it is a one only decision, and if it is done in a
divisive unilateral way there are extreme risks of the ledger
Network Divergence Risk
But this is not a soft-fork, it is a hard-fork.  Miner voting is only
peripherally related.  Even if in the extremis 75% of miners tried a
unilateral hard-fork but 100% of the users stayed on the maintained
original code, no change would occur other than those miners losing
reward (mining fork-coins with no resale value) and the difficulty
would adjust.  The miners who made an error in choice would lose money
and go out of business or rejoin the chain.
However if something in that direction happens with actual users and
companies on both sides of it users will lose money, the ledger will
diverge as soon as a single double-spend happens, and never share a
block again, companies will go instantly insolvent, and chaos will
break out.  This is the dangerous scenario we are concerned about.
So the same question again:
- How do you propose to deal with the extra risks that come from
non-consensus hard-forks?  Hard-forks themselves are quite risky, but
non-consensus ones are extremely dangerous for consensus.
Being sensitive to alarming the market
It is something akin to Greece or Portugal or Italy exiting the euro
currency in a disorderly way.  Economists and central bank policy
makers are extremely worried about such an eventuality and talk about
related factors in careful, measured terms, watch Mario Draghi when he
Imagine that bitcoin is 10x or 100x bigger.  Bitcoin cant have people
taking unilateral actions such as you have been proposing.  It is not
following the consensus governance process, and not good policy and it
is probably affecting bitcoin confidence and price at this moment.
This is not a soft-fork, and the community will not want to take the
risks once they understand them, and they have months in which to
understand them and at this point you've motivated and wasted 100s of
developer man hours such that we will feel impelled to make sure that
no one opts into a unilateral hard-fork without understanding the
risks.  It would be negligent to allow people to do that.  Before this
gets very far FAQs will be on bitcoin.org etc explaining this risk I
would imagine.  Its just starting not finished.
What makes you think the rest of the community may not instead prefer
Jeff Garzik's BIP after revisions that he is making now with review
comments from others?
Or another proposal.  Taken together with a deployment plan that sees
work on decentralisation tying into that plan.
- If you persisted anyway, what makes you think bitcoin could not make
code changes defensively relating to your unilateral fork?
(I am sure creative minds can find some ways to harden bitcoin against
a unilateral fork, with a soft-fork or non-consensus update can be
deployed much faster than a hard-fork).
I tried to warn Gavin privately that I thought he was under-estimating
the risk of failure to his fork proposal due to it being unilateral.
Ie as you both seem sincere in your wish to have your proposal
succeed, then obviously the best way to do that is to release a BIP in
the open collaborative process and submit it to review like everyone
else.  Doing it unilaterally only increases its chance of failure.
The only sensible thing to do here is submit a BIP and stop the
unilateral fork threat.
Scalability Plans
Yes people have proposed other plans.  Bryan Bishop posted a list of them.
Jeff Garzik has a proposal, BIP-100 which seems already better than
Gavin's having benefit of peer review which he has been incorporating.
I proposed several soft-fork models which can be deployed safely and
immediately, which do not have ledger risk.
I have another proposal relating to simplified soft-fork one-way pegs
which I'll write up in a bit.
I think there are still issues in Jeff's proposal but he is very open
and collaborating and there maybe related but different proposals
It does not seem to me that you understand the issue.  Of course they
want to increase the scalability of bitcoin.  So does everyone else on
this mailing list.
That they would support that is obvious.  If you presented your
unilateral action plan without explaining the risks too.
I think I covered this further above.  If you would like to share the
company list, or we can invite them to the proposed public physical
meeting, I think it would be useful for them to have a balanced view
of the ledger divergence risks, and alternative in-consensus proposals
underway, as well as the governance risks, maintenance risks, security
incident risks.
Note that other people talk to companies too, as part of their day to
day jobs, or from contacts from being in the industry.  You have no
special authority or unique ability to talk with business people.  Its
just that the technical community did not know you were busy doing
I can not believe that any company that would listen to their CTO, CSO
or failing that board would be ok with the risks implied by what you
are proposing on full examination.
I know you want scale bitcoin, as I said everyone here does. I think
what you're experiencing is that you've had more luck explaining your
pragmatic unilateral plan to non-technical people without peer review,
and so not experienced the kind of huge pushback you are getting from
the technical community.  The whole of bitcoin is immensely
complicated such that it takes an uber-geek CS genius years to
catchup, this is not a slight of any of the business people who are
working hard to deploy Bitcoin into the world, its just complicated
and therefore not easy to understand the game-theory, security,
governance and distributed system thinking.  I have a comp sci PhD in
distributed systems, implemented p2p network systems and have 2
decades of applied crypto experience with a major interest in
electronic cash crypto protocols, and it took me a several years to
catchup and even I have a few hazy spots on low-level details, and I
addictively into read everything I could find.  Realistically all of
us are still learning, as bitcoin combines so many fields that it
opens new possibilities.
What I am expecting that yourself and Gavin are thinking is that
you'll knock heads and force the issue and get to consensus.
However I think you have seriously misjudged the risks and have not
adequately explained them to companies you are talking with.  Indeed
you do not fully seem to acknowledge the risks, nor to have a well
thought out plan here of how you would actually manage it, nor the
moral hazards of having a lone developer in hugely divisive
circumstances in sole control of bitcoins running code.  Those are
exactly the reasons for the code change governance process!
Even though you are trying to help, the full result is you are not
helping achieve anything by changing a constant and starting a
unilateral hard-fork (not to trivialise the work of making a patch to
do that).
The work to even make the constant change be feasible was a result of
1000s of hours of work by others in the development community, that is
emphatically and unilaterally telling you that hard-forks are hugely
You are trying to break the code change governance security procedure
that were put in place for good reason for the security of $3b of
other peoples money, even if you have a pragmatic intent to help, this
is flat out unacceptable.
There are also security implications to what you are proposing, which
I have heard you attempting to trivialise, that are core to Bitcoins
security and core functionality.
I think this is a significant mischaracterisation, and I think almost
everybody is on board with a combination plan:
1. work to improve decentralisation (specific technical work already
underway, and education)
2. create a plan to increase block-size in a slow fashion to not cause
system shocks (eg like Jeff is proposing or some better variant)
3. work on actual algorithmic scaling
In this way we can have throughput needed for scalability and security
work to continue.
As I said you can not scale a O(n^2) broadcast network by changing
constants, you need algorithmic improvements.
People are working on them already.  All of those 3 things are being
actively worked on RIGHT NOW, and in the case of algorithmic scaling
and improve decentralisation have been worked on for months.
You may have done one useful thing which is to remind people that
blocks are only 3x-4x below capacity such that we should look at it.
But we can not work under duress of haste, nor unilateral ultimatums,
this is the realm of human action that leads to moral hazard, and
ironically reminds us of why Satoshi put the quote in the genesis
Bitcoin is too complex a system with too much at stake to be making
political hasty decisions, it would be negligent to act in such a way.
Again please consider that you did your job, caused people to pay
attention, but return to the process, submit a BIP, retract the
unilateral hard-fork which is so dangerous and lets have things be
calm, civil and collaborative in the technical zone of Bitcoin and not
further alarm companies and investors.

@_date: 2015-03-02 18:02:57
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] New paper: Research Perspectives and 
Cryptography List ----- Forwarded message from Andrew Miller  -----
We (Joseph Bonneau, myself Arvind Narayanan, Jeremy Clark, Ed Felten,
Josh Kroll -- from Stanford, Maryland, Concordia, Princeton) have
written a systemization paper about Bitcoin-related research. Its
going to appear in the Oakland security conference later this year
(IEEE Security and Privacy) but we wanted to announce a draft to this
community ahead of time.
One of the main goals of our work is to build a bridge between the
computer science research community and the cryptocurrency community.
Many of the most interesting ideas and proposals for Bitcoin come from
this mailing list and forums/wikis/irc channels, where many academic
researchers simply dont know to look! In fact, we started out by
scraping all the interesting posts/articles we could find and trying
to figure out how we could organize them. We hope our paper helps some
of the best ideas and research questions from the Bitcoin community
bubble up and inspires researchers to build on them.
We didnt limit our scope to Bitcoin, but we also decided not to
provide a complete survey of altcoins and other next-generation
cryptocurrency designs. Instead, we tried to explain all the
dimensions along which these designs differ from Bitcoin.
This effort has roughly been in progress over two years, though it
stopped and restarted several times along the way.
If anyone has comments or suggestions, we still have a week before the
final version is due, and regardless we plan to continue updating our
online version for the forseeable future.

@_date: 2015-03-13 11:10:55
@_author: Eugen Leitl 
@_subject: Computer-stored encryption keys are not safe from side-channel attacks 
Computer-stored encryption keys are not safe from side-channel attacks
By Michael Kassner March 11, 2015, 1:25 PM PST
Using side-channel technology, researchers at Tel Aviv University can extract
decryption keys from RSA and ElGamal implementations without altering or
having control of a computer. Figure A: Tel Aviv University researchers built this self-contained PITA
receiver.  Image courtesy of Daniel Genkin, Lev Pachmanov, Itamar Pipman,
Eran Tromer, and Tel Aviv University
Not that long ago, grabbing information from air-gapped computers required
sophisticated equipment. In my TechRepublic column Air-gapped computers are
no longer secure, researchers at Georgia Institute of Technology explain how
simple it is to capture keystrokes from a computer just using spurious
electromagnetic side-channel emissions emanating from the computer under
Daniel Genkin, Lev Pachmanov, Itamar Pipman, and Eran Tromer, researchers at
Tel Aviv University, agree the process is simple. However, the scientists
have upped the ante, figuring out how to ex-filtrate complex encryption data
using side-channel technology.
The process In the paper Stealing Keys from PCs using a Radio: Cheap
Electromagnetic Attacks on Windowed Exponentiation (PDF), the researchers
explain how they determine decryption keys for mathematically-secure
cryptographic schemes by capturing information about secret values inside the
computation taking place in the computer.
"We present new side-channel attacks on RSA and ElGamal implementations that
use the popular sliding-window or fixed-window (m-ary) modular exponentiation
algorithms," the team writes. "The attacks can extract decryption keys using
a low measurement bandwidth (a frequency band of less than 100 kHz around a
carrier under 2 MHz) even when attacking multi-GHz CPUs."
If that doesn't mean much, this might help: The researchers can extract keys
from GnuPG in just a few seconds by measuring side-channel emissions from
computers. "The measurement equipment is cheap, compact, and uses
readily-available components," add the researchers. Using that philosophy the
university team developed the following attacks.
Software Defined Radio (SDR) attack: This comprises of a shielded loop
antenna to capture the side-channel signal, which is then recorded by an SDR
program installed on a notebook.
Portable Instrument for Trace Acquisition (PITA) attack: The researchers,
using available electronics and food items (who says academics don't have a
sense of humor?), built the self-contained receiver shown in Figure A. The
PITA receiver has two modes: online and autonomous.
Online: PITA connects to a nearby observation station via Wi-Fi, providing
real-time streaming of the digitized signal.  Autonomous: Similar to online
mode, PITA first measures the digitized signal, then records it on an
internal microSD card for later retrieval by physical access or via Wi-Fi.
Consumer radio attack: To make an even cheaper version, the team leveraged
knowing that side-channel signals modulate at a carrier frequency near 1.7
MHz, which is within the AM radio frequency band. "We used a plain
consumer-grade radio receiver to acquire the desired signal, replacing the
magnetic probe and SDR receiver," the authors explain. "We then recorded the
signal by connecting it to the microphone input of an HTC EVO 4G smartphone."
Cryptanalytic approach
This is where the magic occurs. I must confess that paraphrasing what the
researchers accomplished would be a disservice; I felt it best to include
their cryptanalysis description verbatim:
"Our attack utilizes the fact that, in the sliding-window or fixed window
exponentiation routine, the values inside the table of ciphertext powers can
be partially predicted. By crafting a suitable ciphertext, the attacker can
cause the value at a specific table entry to have a specific structure.
"This structure, coupled with a subtle control flow difference deep inside
GnuPG's basic multiplication routine, will cause a noticeable difference in
the leakage whenever a multiplication by this structured value has occurred.
This allows the attacker to learn all the locations inside the secret
exponent where the specific table entry is selected by the bit pattern in the
sliding window. Repeating this process across all table indices reveals the
Figure B is a spectrogram displaying measured power as a function of time and
frequency for a recording of GnuPG decrypting the same ciphertext using
different randomly generated RSA keys. The research team's explanation:
"It is easy to see where each decryption starts and ends (yellow arrow).
Notice the change in the middle of each decryption operation, spanning
several frequency bands. This is because, internally, each GnuPG RSA
decryption first exponentiates modulo the secret prime p and then modulo the
secret prime q, and we can see the difference between these stages.
"Each of these pairs looks different because each decryption uses a different
key. So in this example, by observing electromagnetic emanations during
decryption operations, using the setup from this figure, we can distinguish
between different secret keys."
Figure B: A spectrogram Image courtesy of Daniel Genkin, Lev Pachmanov,
Itamar Pipman, Eran Tromer, and Tel Aviv University
Any way to prevent the leakage?
One solution, albeit unwieldy, is operating the computer in a Faraday cage,
which prevents any spurious emissions from escaping. "The cryptographic
software can be changed, and algorithmic techniques used to render the
emanations less useful to the attacker," mentions the paper. "These
techniques ensure the behavior of the algorithm is independent of the inputs
it receives."
Interestingly, the research paper tackles a question about side-channel
attacks that TechRepublic readers commented on in my earlier article, "It's a
hardware problem, so why not fix the equipment?"
Basically the researchers mention that the emissions are at such a low level,
prevention is impractical because:
Any leakage remnants can often be amplified by suitable manipulation as we do
in our chosen-ciphertext attack; and Leakage is often an inevitable side
effect of essential performance-enhancing mechanisms.
Something else of interest: the National Institute of Standards and
Technology (NIST) considers resistance to side-channel attacks an important
evaluation consideration in its SHA-3 competition.

@_date: 2015-03-02 18:02:57
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] New paper: Research Perspectives and 
Cryptography List ----- Forwarded message from Andrew Miller  -----
We (Joseph Bonneau, myself Arvind Narayanan, Jeremy Clark, Ed Felten,
Josh Kroll -- from Stanford, Maryland, Concordia, Princeton) have
written a systemization paper about Bitcoin-related research. Its
going to appear in the Oakland security conference later this year
(IEEE Security and Privacy) but we wanted to announce a draft to this
community ahead of time.
One of the main goals of our work is to build a bridge between the
computer science research community and the cryptocurrency community.
Many of the most interesting ideas and proposals for Bitcoin come from
this mailing list and forums/wikis/irc channels, where many academic
researchers simply dont know to look! In fact, we started out by
scraping all the interesting posts/articles we could find and trying
to figure out how we could organize them. We hope our paper helps some
of the best ideas and research questions from the Bitcoin community
bubble up and inspires researchers to build on them.
We didnt limit our scope to Bitcoin, but we also decided not to
provide a complete survey of altcoins and other next-generation
cryptocurrency designs. Instead, we tried to explain all the
dimensions along which these designs differ from Bitcoin.
This effort has roughly been in progress over two years, though it
stopped and restarted several times along the way.
If anyone has comments or suggestions, we still have a week before the
final version is due, and regardless we plan to continue updating our
online version for the forseeable future.

@_date: 2015-03-13 11:10:55
@_author: Eugen Leitl 
@_subject: Computer-stored encryption keys are not safe from side-channel attacks 
Computer-stored encryption keys are not safe from side-channel attacks
By Michael Kassner March 11, 2015, 1:25 PM PST
Using side-channel technology, researchers at Tel Aviv University can extract
decryption keys from RSA and ElGamal implementations without altering or
having control of a computer. Figure A: Tel Aviv University researchers built this self-contained PITA
receiver.  Image courtesy of Daniel Genkin, Lev Pachmanov, Itamar Pipman,
Eran Tromer, and Tel Aviv University
Not that long ago, grabbing information from air-gapped computers required
sophisticated equipment. In my TechRepublic column Air-gapped computers are
no longer secure, researchers at Georgia Institute of Technology explain how
simple it is to capture keystrokes from a computer just using spurious
electromagnetic side-channel emissions emanating from the computer under
Daniel Genkin, Lev Pachmanov, Itamar Pipman, and Eran Tromer, researchers at
Tel Aviv University, agree the process is simple. However, the scientists
have upped the ante, figuring out how to ex-filtrate complex encryption data
using side-channel technology.
The process In the paper Stealing Keys from PCs using a Radio: Cheap
Electromagnetic Attacks on Windowed Exponentiation (PDF), the researchers
explain how they determine decryption keys for mathematically-secure
cryptographic schemes by capturing information about secret values inside the
computation taking place in the computer.
"We present new side-channel attacks on RSA and ElGamal implementations that
use the popular sliding-window or fixed-window (m-ary) modular exponentiation
algorithms," the team writes. "The attacks can extract decryption keys using
a low measurement bandwidth (a frequency band of less than 100 kHz around a
carrier under 2 MHz) even when attacking multi-GHz CPUs."
If that doesn't mean much, this might help: The researchers can extract keys
from GnuPG in just a few seconds by measuring side-channel emissions from
computers. "The measurement equipment is cheap, compact, and uses
readily-available components," add the researchers. Using that philosophy the
university team developed the following attacks.
Software Defined Radio (SDR) attack: This comprises of a shielded loop
antenna to capture the side-channel signal, which is then recorded by an SDR
program installed on a notebook.
Portable Instrument for Trace Acquisition (PITA) attack: The researchers,
using available electronics and food items (who says academics don't have a
sense of humor?), built the self-contained receiver shown in Figure A. The
PITA receiver has two modes: online and autonomous.
Online: PITA connects to a nearby observation station via Wi-Fi, providing
real-time streaming of the digitized signal.  Autonomous: Similar to online
mode, PITA first measures the digitized signal, then records it on an
internal microSD card for later retrieval by physical access or via Wi-Fi.
Consumer radio attack: To make an even cheaper version, the team leveraged
knowing that side-channel signals modulate at a carrier frequency near 1.7
MHz, which is within the AM radio frequency band. "We used a plain
consumer-grade radio receiver to acquire the desired signal, replacing the
magnetic probe and SDR receiver," the authors explain. "We then recorded the
signal by connecting it to the microphone input of an HTC EVO 4G smartphone."
Cryptanalytic approach
This is where the magic occurs. I must confess that paraphrasing what the
researchers accomplished would be a disservice; I felt it best to include
their cryptanalysis description verbatim:
"Our attack utilizes the fact that, in the sliding-window or fixed window
exponentiation routine, the values inside the table of ciphertext powers can
be partially predicted. By crafting a suitable ciphertext, the attacker can
cause the value at a specific table entry to have a specific structure.
"This structure, coupled with a subtle control flow difference deep inside
GnuPG's basic multiplication routine, will cause a noticeable difference in
the leakage whenever a multiplication by this structured value has occurred.
This allows the attacker to learn all the locations inside the secret
exponent where the specific table entry is selected by the bit pattern in the
sliding window. Repeating this process across all table indices reveals the
Figure B is a spectrogram displaying measured power as a function of time and
frequency for a recording of GnuPG decrypting the same ciphertext using
different randomly generated RSA keys. The research team's explanation:
"It is easy to see where each decryption starts and ends (yellow arrow).
Notice the change in the middle of each decryption operation, spanning
several frequency bands. This is because, internally, each GnuPG RSA
decryption first exponentiates modulo the secret prime p and then modulo the
secret prime q, and we can see the difference between these stages.
"Each of these pairs looks different because each decryption uses a different
key. So in this example, by observing electromagnetic emanations during
decryption operations, using the setup from this figure, we can distinguish
between different secret keys."
Figure B: A spectrogram Image courtesy of Daniel Genkin, Lev Pachmanov,
Itamar Pipman, Eran Tromer, and Tel Aviv University
Any way to prevent the leakage?
One solution, albeit unwieldy, is operating the computer in a Faraday cage,
which prevents any spurious emissions from escaping. "The cryptographic
software can be changed, and algorithmic techniques used to render the
emanations less useful to the attacker," mentions the paper. "These
techniques ensure the behavior of the algorithm is independent of the inputs
it receives."
Interestingly, the research paper tackles a question about side-channel
attacks that TechRepublic readers commented on in my earlier article, "It's a
hardware problem, so why not fix the equipment?"
Basically the researchers mention that the emissions are at such a low level,
prevention is impractical because:
Any leakage remnants can often be amplified by suitable manipulation as we do
in our chosen-ciphertext attack; and Leakage is often an inevitable side
effect of essential performance-enhancing mechanisms.
Something else of interest: the National Institute of Standards and
Technology (NIST) considers resistance to side-channel attacks an important
evaluation consideration in its SHA-3 competition.

@_date: 2015-03-02 18:02:57
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] New paper: Research Perspectives and 
We (Joseph Bonneau, myself Arvind Narayanan, Jeremy Clark, Ed Felten,
Josh Kroll -- from Stanford, Maryland, Concordia, Princeton) have
written a systemization paper about Bitcoin-related research. Its
going to appear in the Oakland security conference later this year
(IEEE Security and Privacy) but we wanted to announce a draft to this
community ahead of time.
One of the main goals of our work is to build a bridge between the
computer science research community and the cryptocurrency community.
Many of the most interesting ideas and proposals for Bitcoin come from
this mailing list and forums/wikis/irc channels, where many academic
researchers simply dont know to look! In fact, we started out by
scraping all the interesting posts/articles we could find and trying
to figure out how we could organize them. We hope our paper helps some
of the best ideas and research questions from the Bitcoin community
bubble up and inspires researchers to build on them.
We didnt limit our scope to Bitcoin, but we also decided not to
provide a complete survey of altcoins and other next-generation
cryptocurrency designs. Instead, we tried to explain all the
dimensions along which these designs differ from Bitcoin.
This effort has roughly been in progress over two years, though it
stopped and restarted several times along the way.
If anyone has comments or suggestions, we still have a week before the
final version is due, and regardless we plan to continue updating our
online version for the forseeable future.

@_date: 2015-03-13 11:10:55
@_author: Eugen Leitl 
@_subject: Computer-stored encryption keys are not safe from side-channel attacks 
Computer-stored encryption keys are not safe from side-channel attacks
By Michael Kassner March 11, 2015, 1:25 PM PST
Using side-channel technology, researchers at Tel Aviv University can extract
decryption keys from RSA and ElGamal implementations without altering or
having control of a computer. Figure A: Tel Aviv University researchers built this self-contained PITA
receiver.  Image courtesy of Daniel Genkin, Lev Pachmanov, Itamar Pipman,
Eran Tromer, and Tel Aviv University
Not that long ago, grabbing information from air-gapped computers required
sophisticated equipment. In my TechRepublic column Air-gapped computers are
no longer secure, researchers at Georgia Institute of Technology explain how
simple it is to capture keystrokes from a computer just using spurious
electromagnetic side-channel emissions emanating from the computer under
Daniel Genkin, Lev Pachmanov, Itamar Pipman, and Eran Tromer, researchers at
Tel Aviv University, agree the process is simple. However, the scientists
have upped the ante, figuring out how to ex-filtrate complex encryption data
using side-channel technology.
The process In the paper Stealing Keys from PCs using a Radio: Cheap
Electromagnetic Attacks on Windowed Exponentiation (PDF), the researchers
explain how they determine decryption keys for mathematically-secure
cryptographic schemes by capturing information about secret values inside the
computation taking place in the computer.
"We present new side-channel attacks on RSA and ElGamal implementations that
use the popular sliding-window or fixed-window (m-ary) modular exponentiation
algorithms," the team writes. "The attacks can extract decryption keys using
a low measurement bandwidth (a frequency band of less than 100 kHz around a
carrier under 2 MHz) even when attacking multi-GHz CPUs."
If that doesn't mean much, this might help: The researchers can extract keys
from GnuPG in just a few seconds by measuring side-channel emissions from
computers. "The measurement equipment is cheap, compact, and uses
readily-available components," add the researchers. Using that philosophy the
university team developed the following attacks.
Software Defined Radio (SDR) attack: This comprises of a shielded loop
antenna to capture the side-channel signal, which is then recorded by an SDR
program installed on a notebook.
Portable Instrument for Trace Acquisition (PITA) attack: The researchers,
using available electronics and food items (who says academics don't have a
sense of humor?), built the self-contained receiver shown in Figure A. The
PITA receiver has two modes: online and autonomous.
Online: PITA connects to a nearby observation station via Wi-Fi, providing
real-time streaming of the digitized signal.  Autonomous: Similar to online
mode, PITA first measures the digitized signal, then records it on an
internal microSD card for later retrieval by physical access or via Wi-Fi.
Consumer radio attack: To make an even cheaper version, the team leveraged
knowing that side-channel signals modulate at a carrier frequency near 1.7
MHz, which is within the AM radio frequency band. "We used a plain
consumer-grade radio receiver to acquire the desired signal, replacing the
magnetic probe and SDR receiver," the authors explain. "We then recorded the
signal by connecting it to the microphone input of an HTC EVO 4G smartphone."
Cryptanalytic approach
This is where the magic occurs. I must confess that paraphrasing what the
researchers accomplished would be a disservice; I felt it best to include
their cryptanalysis description verbatim:
"Our attack utilizes the fact that, in the sliding-window or fixed window
exponentiation routine, the values inside the table of ciphertext powers can
be partially predicted. By crafting a suitable ciphertext, the attacker can
cause the value at a specific table entry to have a specific structure.
"This structure, coupled with a subtle control flow difference deep inside
GnuPG's basic multiplication routine, will cause a noticeable difference in
the leakage whenever a multiplication by this structured value has occurred.
This allows the attacker to learn all the locations inside the secret
exponent where the specific table entry is selected by the bit pattern in the
sliding window. Repeating this process across all table indices reveals the
Figure B is a spectrogram displaying measured power as a function of time and
frequency for a recording of GnuPG decrypting the same ciphertext using
different randomly generated RSA keys. The research team's explanation:
"It is easy to see where each decryption starts and ends (yellow arrow).
Notice the change in the middle of each decryption operation, spanning
several frequency bands. This is because, internally, each GnuPG RSA
decryption first exponentiates modulo the secret prime p and then modulo the
secret prime q, and we can see the difference between these stages.
"Each of these pairs looks different because each decryption uses a different
key. So in this example, by observing electromagnetic emanations during
decryption operations, using the setup from this figure, we can distinguish
between different secret keys."
Figure B: A spectrogram Image courtesy of Daniel Genkin, Lev Pachmanov,
Itamar Pipman, Eran Tromer, and Tel Aviv University
Any way to prevent the leakage?
One solution, albeit unwieldy, is operating the computer in a Faraday cage,
which prevents any spurious emissions from escaping. "The cryptographic
software can be changed, and algorithmic techniques used to render the
emanations less useful to the attacker," mentions the paper. "These
techniques ensure the behavior of the algorithm is independent of the inputs
it receives."
Interestingly, the research paper tackles a question about side-channel
attacks that TechRepublic readers commented on in my earlier article, "It's a
hardware problem, so why not fix the equipment?"
Basically the researchers mention that the emissions are at such a low level,
prevention is impractical because:
Any leakage remnants can often be amplified by suitable manipulation as we do
in our chosen-ciphertext attack; and Leakage is often an inevitable side
effect of essential performance-enhancing mechanisms.
Something else of interest: the National Institute of Standards and
Technology (NIST) considers resistance to side-channel attacks an important
evaluation consideration in its SHA-3 competition.

@_date: 2015-05-20 13:04:21
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Virtual Notary. 
Hi everyone,
Given the recent discussions on projects that use the Bitcoin blockchain to
record factoids, people on this list might be interested in the Virtual
Notary project. Virtual Notary is essentially an online witness (aka
attestor) to online factoids. It can provide:
  * proof of Bitcoin funds (without revealing public addresses or fund
location on the blockchain)
  * proof of Bitcoin address ownership
  * proof of Tweet
  * proof of real estate value
  * proof of DNS ownership
  * proof of existence
  * proof of web page contents
  * proof of weather conditions
The factoids can be recorded on the blockchain (if you pay for the
transaction with Bitcoin or PayPal), or they can be part of a free
attestation chain that we maintain. The website provides a permanent URL to
the factoids it generates; it also provides an X.509 certificate that you
can download and keep safe in perpetuity, independent of the website.
The link to the website is here:
  The link to the writeup describing the various factoids and their use cases
is here:
  We are actively looking for people who are interested in developing the
service further. Specifically, if you have suggestions for how to extend
the service, for new proof/factoid types, or for how to build a business
case around the core idea, please let us know.
- egs

@_date: 2015-05-20 13:04:21
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Virtual Notary. 
Hi everyone,
Given the recent discussions on projects that use the Bitcoin blockchain to
record factoids, people on this list might be interested in the Virtual
Notary project. Virtual Notary is essentially an online witness (aka
attestor) to online factoids. It can provide:
  * proof of Bitcoin funds (without revealing public addresses or fund
location on the blockchain)
  * proof of Bitcoin address ownership
  * proof of Tweet
  * proof of real estate value
  * proof of DNS ownership
  * proof of existence
  * proof of web page contents
  * proof of weather conditions
The factoids can be recorded on the blockchain (if you pay for the
transaction with Bitcoin or PayPal), or they can be part of a free
attestation chain that we maintain. The website provides a permanent URL to
the factoids it generates; it also provides an X.509 certificate that you
can download and keep safe in perpetuity, independent of the website.
The link to the website is here:
  The link to the writeup describing the various factoids and their use cases
is here:
  We are actively looking for people who are interested in developing the
service further. Specifically, if you have suggestions for how to extend
the service, for new proof/factoid types, or for how to build a business
case around the core idea, please let us know.
- egs

@_date: 2015-05-20 13:04:21
@_author: Eugen Leitl 
@_subject: [Bitcoin-development] Virtual Notary. 
Hi everyone,
Given the recent discussions on projects that use the Bitcoin blockchain to
record factoids, people on this list might be interested in the Virtual
Notary project. Virtual Notary is essentially an online witness (aka
attestor) to online factoids. It can provide:
  * proof of Bitcoin funds (without revealing public addresses or fund
location on the blockchain)
  * proof of Bitcoin address ownership
  * proof of Tweet
  * proof of real estate value
  * proof of DNS ownership
  * proof of existence
  * proof of web page contents
  * proof of weather conditions
The factoids can be recorded on the blockchain (if you pay for the
transaction with Bitcoin or PayPal), or they can be part of a free
attestation chain that we maintain. The website provides a permanent URL to
the factoids it generates; it also provides an X.509 certificate that you
can download and keep safe in perpetuity, independent of the website.
The link to the website is here:
  The link to the writeup describing the various factoids and their use cases
is here:
  We are actively looking for people who are interested in developing the
service further. Specifically, if you have suggestions for how to extend
the service, for new proof/factoid types, or for how to build a business
case around the core idea, please let us know.
- egs

@_date: 2015-10-02 13:18:04
@_author: Eugen Leitl 
@_subject: Qubes 3.0 out 
Qubes 3.0
Oct 1, 2015  Joanna Rutkowska
About 5 months after the initial release of Qubes 3.0-rc1, we're now
releasing the final 3.0 today!
Let me quickly recap the main "killer features" of Qubes OS 3.0 compared to
the Release 2:
Qubes is now based on what we call Hypervisor Abstraction Layer (HAL), which
decouples Qubes logic from the underlying hypervisor. This will allow us to
easily switch the underlying hypervisors in the near future, perhaps even
during the installation time, depending on the user needs (think tradeoffs
between hardware compatibility and performance vs. security properties
desired, such as e.g. reduction of covert channels between VMs, which might
be of importance to some users). More philosophically-wise, this is a nice
manifestation of how Qubes OS is really "not yet another virtualization
system", but rather: a user of a virtualization system (such as Xen).
We upgraded from Xen 4.1 to Xen 4.4 (now that was really easy thanks to HAL),
which allowed for: 1) better hardware compatibility (e.g. UEFI coming soon in
3.1), 2) better performance (e.g. via Xen's libvchan that replaced our
vchan). Also, new Qubes qrexec framework that has optimized performance for
inter-VM services.
We introduced officially supported Debian templates.
And finally: we integrated Whonix templates, which optimize Tor workflows for
As explained in our Release Cycle Documentation (something we finally created
and been polishing through this 3.0 branch development), there is almost no
new features in 3.0 compared to 3.0-rc1, essentially only bugfixes,
intermixed with a few minor improvements.
But, while the 3.0 branch was "maturing", and getting bugfixes merged, most
of our work has been focused on the 3.1 branch, which is adding a bunch of
exciting new features, as indicated on our high-level roadmap, specifically:
UEFI support (see this ticket for more info and test images).
Live USB edition (preview for which we already released earlier this summer,
now it will get merged into the master branch for 3.1)
Management/pre-configuration stack: The Big Killer Feature of the upcoming
3.1 release, which will make it easy to provide out of the box configurations
for things such as: out of the box Whonix/Tor, or Split GPG, or default USB
sandboxing VM, which currently the user must do manually.
We're planning to release the first candidate for 3.1 as early as the end of
October, actually.
But development of any serious project is not just adding new features,
although that's admittedly the most exciting thing for any developer to do.
In R3 we have finally started implementing this golden thought, and the first
tangible outcome of this change of attitude is the automated testing
framework which we have been using for all the releases in this 3.0 branch
already. We hope this results in much more polished, stable code.
Other things we've started to be increasingly prioritizing recently, and only
plan to intensify in the coming year are: 1) making Qubes more accessible to
people (think easier to get hardware that can run Qubes OS), and 2) easier to
use (better UX and UI). I think this is also pretty exciting, actually.
As previously announced earlier this summer, we have decided to dedicate this
release of Qubes OS to the memory of Caspar Bowden:
Caspar's dedication screenshot
Caspar has been a proud user, supporter, and advocate for Qubes OS, and also
a friend. I think he would have liked that dedication.
The Qubes 3.0 ISO can be downloaded from here.
We have also released another scheduled Qubes Canary today.
I would like to thank all the people who have contributed to this huge effort
of creating a new "reasonably secure" desktop OS. I believe we're making
together an important and meaningful thing here. Let's keep this going!

@_date: 2015-10-26 14:12:38
@_author: Eugen Leitl 
@_subject: Obfuscation: how leaving a trail of confusion can beat online 
Obfuscation: how leaving a trail of confusion can beat online surveillance
The art of obfuscation has a grand history, from Im Spartacus!
to ghost radar in WWII. Could the same blurred approach give us more freedom
 Analog television with white noise
 Obfuscation, say Brunton and Nissenbaum, is the addition of ambiguous,
confusing, or misleading information to interfere with surveillance and data
collection projects to  buy time, gain cover, and hide in a crowd
of signals. Photograph: Jon Helgason/Alamy
Julia Powles Saturday 24 October 2015 09.00 BST Last modified on Sunday 25
October 2015 20.32 GMT
At the heart of Cambridge University, theres a library tower filled with
200,000 forgotten books. Rumoured by generations of students to hold the
campus collection of porn, Sir Gilbert Scotts tower is, in fact, filled
with pocket books. Guides, manuals, tales and pamphlets for everyday life,
deemed insufficiently scholarly for the ordinary collection, they stand
preserved as an extraordinary relic of past preoccupations.
One new guide in the handbook tradition  and one that is decidedly on
point for 2015  is the slim, black, cloth-bound volume, Obfuscation: A
Users Guide for Privacy and Protest, published by MIT Press. A
collaboration between technologist Finn Brunton and philosopher Helen
Nissenbaum, both of New York University, Obfuscation packs utility, charm and
conviction into its tightly-composed 100-page core. This is a thin book, but
its ambition is vast.
Brunton and Nissenbaum aim to start a big little revolution in the
data-mining and surveillance business, by throwing some sand in the
gears, kicking up dust and making some noise. Specifically, the authors
champion the titular term, obfuscation, or the addition of ambiguous,
confusing, or misleading information to interfere with surveillance and data
collection projects. The objective of such measures is to thwart
profiling, to buy time, gain cover, and hide in a crowd of signals.
More than 30 colourful examples  instructive vignettes in their own
right  are used to build the case. Roughly a third are analogue, and the
images stick. War-era choppers generating radar chaff. False tells in poker.
Iconic movie scenes, like the switching briefcases in The Thomas Crown
Affair, or the powerful I am Spartacus moment in Kubricks 1960
epic. The authors bring in orb-making spiders, sim-card shuffles,
loyalty-card swap meets, babble tapes (a digital file played in the
background of a conversation in order to obscure it  all examples where
the individual merges with the tribe; where false signals muddy the genuine;
where noise and quick feet offer weapons of the weak.
 Im Spartacus!  obfuscation on film
Shifting to digital, noise can be destructive or productive, and it can scale
dramatically. This is the landscape that a 21st-century handbook must
confront. Platforms and channels can be swamped by code that mimics and
distorts human communication  bots, like-farmers, decoys and hydras.
Other tools, like the anonymous Tor browser, the Guardians SecureDrop,
or stylometric obfuscation (to disguise authorship), can be mission-critical
for dissidents. And there is an ever growing demand for consumer-focused
privacy-preserving apps, like CacheCloak, which hides your mobile location in
a spaghetti map of plausible trails, or FaceCloak, which gives a layer of
control over personal data within Facebook.
We are naked, exposed and eminently traceable, now and into the future, by an
increasing range of data-hungry agents Most of us, most of the time, use
immensely popular technologies without masks or noise. We post in what you
might call corruptible silence. On Facebook, Instagram, Twitter and Google,
we document our personal spaces, our frailties, our desires, questions and
answers. We are naked, exposed and eminently traceable, now and into the
future, by an ever-increasing range of data-hungry agents. To concerned
citizens living this reality, and to thoughtful designers of technology, what
Brunton and Nissenbaum offer is a compelling moral defence and some
ready-to-hand tools for a small, distributed revolution of resistance.
Stunt tech, silence and saviours
Core to the books perspective is the authors experience in building
practical tech  what they describe as tools among other tools for
the construction and defence of privacy. Nissenbaum has been the steward
of two major projects, both with programmer Daniel C Howe: TrackMeNot, a
search-history obfuscator that spontaneously generates clouds of possible
queries; and AdNauseam, which clicks all the ads, so you dont have
TrackMeNot was developed in 2006, in conjunction with developer Vincent
Toubiana, while AdNauseam is new, and currently operates in conjunction with
AdBlock Plus, running in the background to click every ad on a given page.
Discussing the latter platform in Berlin, team-member and designer Mushon
Zer-Aviv described it as, presently, more art project than mass-rollout tech.
AdNauseam is currently in public beta in Firefox, but the team is working
hard to bring it to Google Chrome. As Zer-Aviv described, with a hint of
daring, Google will either take it down, to save ad revenue, which would be a
great stunt; or it wont take it down, which would also be great.
 One of Googles data centres Facebook Twitter Pinterest
 One of Googles data centres, part of the webs back-end.
Photograph: KeystoneUSA-ZUMA / Rex Features
We see these obfuscating apps and systems as moves in a bigger
picture, says Nissenbaum. None, we think, will offer what we really
need, which is comprehensive attention to the picture. Not only the big fuss
about government but all the large data collectors. But they allow people to
visibly signal their disgruntlement  for privacy and protest.
So how does obfuscation play into the current ad-blocking wars? It is a
devilish move by ad networks to conflate the massive back-end of tracking,
aggregation, mining and profiling with advertising itself, says
Nissenbaum. Our effort, both with TrackMeNot and AdNauseam, has been
targeted at the former. I dont love advertising but I can tolerate it.
When supporters of the current structures of behavioural advertising say this
will be the end of all the innovation and free stuff on the web, our response
is: no. Although this might happen if advertising itself goes away, it does
not require the back-end tracking for survival.
The worrying back-end of the web
Advertising does not require back-end tracking for survival.
Helen Nissenbaum
Nissenbaum is right to separate advertising and its current digital back-end.
In the case of newspapers, for example, a great Faustian pact has operated
between ads and content for some 300 years. It more or less works, as long as
theres not too much of one or the other. The fact that this bargain is
threatened by overreaching data collection and surveillance, from search
engines to content-providers to third-party leeches to governments, is a
measure of the urgency of our contemporary challenge and the necessity for a
creative response. Obfuscation is part of that response.
There is something compelling in being persuaded of the ethical imperative of
digital troublemaking by a couple of righteous academics. Obfuscation is not
an academic tome, and it doesnt delve into conceptual analyses on its
core principles, such as anonymity in crowds following David Chaum, or
linkability following Andreas Pfitzmann. But the book has been justifiably
selective to capture broad appeal. The lucid, authoritative, accessible and
thought-provoking text that results is a pleasure to read.
Obfuscation is ultimately a tiny shop in the digital realm. To that extent,
it has nothing against the might of big tech. But what it does have is the
potential to fight to keep the preserve of human agency and autonomy uniquely
human. The big hope is that when our bot descendants find this handbook
stuffed in a tower in 100 years, it is unchecked surveillance  not
digital disobedience  that seems antiquated.

@_date: 2015-10-02 13:18:04
@_author: Eugen Leitl 
@_subject: Qubes 3.0 out 
Qubes 3.0
Oct 1, 2015  Joanna Rutkowska
About 5 months after the initial release of Qubes 3.0-rc1, we're now
releasing the final 3.0 today!
Let me quickly recap the main "killer features" of Qubes OS 3.0 compared to
the Release 2:
Qubes is now based on what we call Hypervisor Abstraction Layer (HAL), which
decouples Qubes logic from the underlying hypervisor. This will allow us to
easily switch the underlying hypervisors in the near future, perhaps even
during the installation time, depending on the user needs (think tradeoffs
between hardware compatibility and performance vs. security properties
desired, such as e.g. reduction of covert channels between VMs, which might
be of importance to some users). More philosophically-wise, this is a nice
manifestation of how Qubes OS is really "not yet another virtualization
system", but rather: a user of a virtualization system (such as Xen).
We upgraded from Xen 4.1 to Xen 4.4 (now that was really easy thanks to HAL),
which allowed for: 1) better hardware compatibility (e.g. UEFI coming soon in
3.1), 2) better performance (e.g. via Xen's libvchan that replaced our
vchan). Also, new Qubes qrexec framework that has optimized performance for
inter-VM services.
We introduced officially supported Debian templates.
And finally: we integrated Whonix templates, which optimize Tor workflows for
As explained in our Release Cycle Documentation (something we finally created
and been polishing through this 3.0 branch development), there is almost no
new features in 3.0 compared to 3.0-rc1, essentially only bugfixes,
intermixed with a few minor improvements.
But, while the 3.0 branch was "maturing", and getting bugfixes merged, most
of our work has been focused on the 3.1 branch, which is adding a bunch of
exciting new features, as indicated on our high-level roadmap, specifically:
UEFI support (see this ticket for more info and test images).
Live USB edition (preview for which we already released earlier this summer,
now it will get merged into the master branch for 3.1)
Management/pre-configuration stack: The Big Killer Feature of the upcoming
3.1 release, which will make it easy to provide out of the box configurations
for things such as: out of the box Whonix/Tor, or Split GPG, or default USB
sandboxing VM, which currently the user must do manually.
We're planning to release the first candidate for 3.1 as early as the end of
October, actually.
But development of any serious project is not just adding new features,
although that's admittedly the most exciting thing for any developer to do.
In R3 we have finally started implementing this golden thought, and the first
tangible outcome of this change of attitude is the automated testing
framework which we have been using for all the releases in this 3.0 branch
already. We hope this results in much more polished, stable code.
Other things we've started to be increasingly prioritizing recently, and only
plan to intensify in the coming year are: 1) making Qubes more accessible to
people (think easier to get hardware that can run Qubes OS), and 2) easier to
use (better UX and UI). I think this is also pretty exciting, actually.
As previously announced earlier this summer, we have decided to dedicate this
release of Qubes OS to the memory of Caspar Bowden:
Caspar's dedication screenshot
Caspar has been a proud user, supporter, and advocate for Qubes OS, and also
a friend. I think he would have liked that dedication.
The Qubes 3.0 ISO can be downloaded from here.
We have also released another scheduled Qubes Canary today.
I would like to thank all the people who have contributed to this huge effort
of creating a new "reasonably secure" desktop OS. I believe we're making
together an important and meaningful thing here. Let's keep this going!

@_date: 2015-10-26 14:12:38
@_author: Eugen Leitl 
@_subject: Obfuscation: how leaving a trail of confusion can beat online 
Obfuscation: how leaving a trail of confusion can beat online surveillance
The art of obfuscation has a grand history, from Im Spartacus!
to ghost radar in WWII. Could the same blurred approach give us more freedom
 Analog television with white noise
 Obfuscation, say Brunton and Nissenbaum, is the addition of ambiguous,
confusing, or misleading information to interfere with surveillance and data
collection projects to  buy time, gain cover, and hide in a crowd
of signals. Photograph: Jon Helgason/Alamy
Julia Powles Saturday 24 October 2015 09.00 BST Last modified on Sunday 25
October 2015 20.32 GMT
At the heart of Cambridge University, theres a library tower filled with
200,000 forgotten books. Rumoured by generations of students to hold the
campus collection of porn, Sir Gilbert Scotts tower is, in fact, filled
with pocket books. Guides, manuals, tales and pamphlets for everyday life,
deemed insufficiently scholarly for the ordinary collection, they stand
preserved as an extraordinary relic of past preoccupations.
One new guide in the handbook tradition  and one that is decidedly on
point for 2015  is the slim, black, cloth-bound volume, Obfuscation: A
Users Guide for Privacy and Protest, published by MIT Press. A
collaboration between technologist Finn Brunton and philosopher Helen
Nissenbaum, both of New York University, Obfuscation packs utility, charm and
conviction into its tightly-composed 100-page core. This is a thin book, but
its ambition is vast.
Brunton and Nissenbaum aim to start a big little revolution in the
data-mining and surveillance business, by throwing some sand in the
gears, kicking up dust and making some noise. Specifically, the authors
champion the titular term, obfuscation, or the addition of ambiguous,
confusing, or misleading information to interfere with surveillance and data
collection projects. The objective of such measures is to thwart
profiling, to buy time, gain cover, and hide in a crowd of signals.
More than 30 colourful examples  instructive vignettes in their own
right  are used to build the case. Roughly a third are analogue, and the
images stick. War-era choppers generating radar chaff. False tells in poker.
Iconic movie scenes, like the switching briefcases in The Thomas Crown
Affair, or the powerful I am Spartacus moment in Kubricks 1960
epic. The authors bring in orb-making spiders, sim-card shuffles,
loyalty-card swap meets, babble tapes (a digital file played in the
background of a conversation in order to obscure it  all examples where
the individual merges with the tribe; where false signals muddy the genuine;
where noise and quick feet offer weapons of the weak.
 Im Spartacus!  obfuscation on film
Shifting to digital, noise can be destructive or productive, and it can scale
dramatically. This is the landscape that a 21st-century handbook must
confront. Platforms and channels can be swamped by code that mimics and
distorts human communication  bots, like-farmers, decoys and hydras.
Other tools, like the anonymous Tor browser, the Guardians SecureDrop,
or stylometric obfuscation (to disguise authorship), can be mission-critical
for dissidents. And there is an ever growing demand for consumer-focused
privacy-preserving apps, like CacheCloak, which hides your mobile location in
a spaghetti map of plausible trails, or FaceCloak, which gives a layer of
control over personal data within Facebook.
We are naked, exposed and eminently traceable, now and into the future, by an
increasing range of data-hungry agents Most of us, most of the time, use
immensely popular technologies without masks or noise. We post in what you
might call corruptible silence. On Facebook, Instagram, Twitter and Google,
we document our personal spaces, our frailties, our desires, questions and
answers. We are naked, exposed and eminently traceable, now and into the
future, by an ever-increasing range of data-hungry agents. To concerned
citizens living this reality, and to thoughtful designers of technology, what
Brunton and Nissenbaum offer is a compelling moral defence and some
ready-to-hand tools for a small, distributed revolution of resistance.
Stunt tech, silence and saviours
Core to the books perspective is the authors experience in building
practical tech  what they describe as tools among other tools for
the construction and defence of privacy. Nissenbaum has been the steward
of two major projects, both with programmer Daniel C Howe: TrackMeNot, a
search-history obfuscator that spontaneously generates clouds of possible
queries; and AdNauseam, which clicks all the ads, so you dont have
TrackMeNot was developed in 2006, in conjunction with developer Vincent
Toubiana, while AdNauseam is new, and currently operates in conjunction with
AdBlock Plus, running in the background to click every ad on a given page.
Discussing the latter platform in Berlin, team-member and designer Mushon
Zer-Aviv described it as, presently, more art project than mass-rollout tech.
AdNauseam is currently in public beta in Firefox, but the team is working
hard to bring it to Google Chrome. As Zer-Aviv described, with a hint of
daring, Google will either take it down, to save ad revenue, which would be a
great stunt; or it wont take it down, which would also be great.
 One of Googles data centres Facebook Twitter Pinterest
 One of Googles data centres, part of the webs back-end.
Photograph: KeystoneUSA-ZUMA / Rex Features
We see these obfuscating apps and systems as moves in a bigger
picture, says Nissenbaum. None, we think, will offer what we really
need, which is comprehensive attention to the picture. Not only the big fuss
about government but all the large data collectors. But they allow people to
visibly signal their disgruntlement  for privacy and protest.
So how does obfuscation play into the current ad-blocking wars? It is a
devilish move by ad networks to conflate the massive back-end of tracking,
aggregation, mining and profiling with advertising itself, says
Nissenbaum. Our effort, both with TrackMeNot and AdNauseam, has been
targeted at the former. I dont love advertising but I can tolerate it.
When supporters of the current structures of behavioural advertising say this
will be the end of all the innovation and free stuff on the web, our response
is: no. Although this might happen if advertising itself goes away, it does
not require the back-end tracking for survival.
The worrying back-end of the web
Advertising does not require back-end tracking for survival.
Helen Nissenbaum
Nissenbaum is right to separate advertising and its current digital back-end.
In the case of newspapers, for example, a great Faustian pact has operated
between ads and content for some 300 years. It more or less works, as long as
theres not too much of one or the other. The fact that this bargain is
threatened by overreaching data collection and surveillance, from search
engines to content-providers to third-party leeches to governments, is a
measure of the urgency of our contemporary challenge and the necessity for a
creative response. Obfuscation is part of that response.
There is something compelling in being persuaded of the ethical imperative of
digital troublemaking by a couple of righteous academics. Obfuscation is not
an academic tome, and it doesnt delve into conceptual analyses on its
core principles, such as anonymity in crowds following David Chaum, or
linkability following Andreas Pfitzmann. But the book has been justifiably
selective to capture broad appeal. The lucid, authoritative, accessible and
thought-provoking text that results is a pleasure to read.
Obfuscation is ultimately a tiny shop in the digital realm. To that extent,
it has nothing against the might of big tech. But what it does have is the
potential to fight to keep the preserve of human agency and autonomy uniquely
human. The big hope is that when our bot descendants find this handbook
stuffed in a tower in 100 years, it is unchecked surveillance  not
digital disobedience  that seems antiquated.

@_date: 2015-10-02 13:18:04
@_author: Eugen Leitl 
@_subject: Qubes 3.0 out 
Qubes 3.0
Oct 1, 2015  Joanna Rutkowska
About 5 months after the initial release of Qubes 3.0-rc1, we're now
releasing the final 3.0 today!
Let me quickly recap the main "killer features" of Qubes OS 3.0 compared to
the Release 2:
Qubes is now based on what we call Hypervisor Abstraction Layer (HAL), which
decouples Qubes logic from the underlying hypervisor. This will allow us to
easily switch the underlying hypervisors in the near future, perhaps even
during the installation time, depending on the user needs (think tradeoffs
between hardware compatibility and performance vs. security properties
desired, such as e.g. reduction of covert channels between VMs, which might
be of importance to some users). More philosophically-wise, this is a nice
manifestation of how Qubes OS is really "not yet another virtualization
system", but rather: a user of a virtualization system (such as Xen).
We upgraded from Xen 4.1 to Xen 4.4 (now that was really easy thanks to HAL),
which allowed for: 1) better hardware compatibility (e.g. UEFI coming soon in
3.1), 2) better performance (e.g. via Xen's libvchan that replaced our
vchan). Also, new Qubes qrexec framework that has optimized performance for
inter-VM services.
We introduced officially supported Debian templates.
And finally: we integrated Whonix templates, which optimize Tor workflows for
As explained in our Release Cycle Documentation (something we finally created
and been polishing through this 3.0 branch development), there is almost no
new features in 3.0 compared to 3.0-rc1, essentially only bugfixes,
intermixed with a few minor improvements.
But, while the 3.0 branch was "maturing", and getting bugfixes merged, most
of our work has been focused on the 3.1 branch, which is adding a bunch of
exciting new features, as indicated on our high-level roadmap, specifically:
UEFI support (see this ticket for more info and test images).
Live USB edition (preview for which we already released earlier this summer,
now it will get merged into the master branch for 3.1)
Management/pre-configuration stack: The Big Killer Feature of the upcoming
3.1 release, which will make it easy to provide out of the box configurations
for things such as: out of the box Whonix/Tor, or Split GPG, or default USB
sandboxing VM, which currently the user must do manually.
We're planning to release the first candidate for 3.1 as early as the end of
October, actually.
But development of any serious project is not just adding new features,
although that's admittedly the most exciting thing for any developer to do.
In R3 we have finally started implementing this golden thought, and the first
tangible outcome of this change of attitude is the automated testing
framework which we have been using for all the releases in this 3.0 branch
already. We hope this results in much more polished, stable code.
Other things we've started to be increasingly prioritizing recently, and only
plan to intensify in the coming year are: 1) making Qubes more accessible to
people (think easier to get hardware that can run Qubes OS), and 2) easier to
use (better UX and UI). I think this is also pretty exciting, actually.
As previously announced earlier this summer, we have decided to dedicate this
release of Qubes OS to the memory of Caspar Bowden:
Caspar's dedication screenshot
Caspar has been a proud user, supporter, and advocate for Qubes OS, and also
a friend. I think he would have liked that dedication.
The Qubes 3.0 ISO can be downloaded from here.
We have also released another scheduled Qubes Canary today.
I would like to thank all the people who have contributed to this huge effort
of creating a new "reasonably secure" desktop OS. I believe we're making
together an important and meaningful thing here. Let's keep this going!

@_date: 2015-10-26 14:12:38
@_author: Eugen Leitl 
@_subject: Obfuscation: how leaving a trail of confusion can beat online 
Obfuscation: how leaving a trail of confusion can beat online surveillance
The art of obfuscation has a grand history, from Im Spartacus!
to ghost radar in WWII. Could the same blurred approach give us more freedom
 Analog television with white noise
 Obfuscation, say Brunton and Nissenbaum, is the addition of ambiguous,
confusing, or misleading information to interfere with surveillance and data
collection projects to  buy time, gain cover, and hide in a crowd
of signals. Photograph: Jon Helgason/Alamy
Julia Powles Saturday 24 October 2015 09.00 BST Last modified on Sunday 25
October 2015 20.32 GMT
At the heart of Cambridge University, theres a library tower filled with
200,000 forgotten books. Rumoured by generations of students to hold the
campus collection of porn, Sir Gilbert Scotts tower is, in fact, filled
with pocket books. Guides, manuals, tales and pamphlets for everyday life,
deemed insufficiently scholarly for the ordinary collection, they stand
preserved as an extraordinary relic of past preoccupations.
One new guide in the handbook tradition  and one that is decidedly on
point for 2015  is the slim, black, cloth-bound volume, Obfuscation: A
Users Guide for Privacy and Protest, published by MIT Press. A
collaboration between technologist Finn Brunton and philosopher Helen
Nissenbaum, both of New York University, Obfuscation packs utility, charm and
conviction into its tightly-composed 100-page core. This is a thin book, but
its ambition is vast.
Brunton and Nissenbaum aim to start a big little revolution in the
data-mining and surveillance business, by throwing some sand in the
gears, kicking up dust and making some noise. Specifically, the authors
champion the titular term, obfuscation, or the addition of ambiguous,
confusing, or misleading information to interfere with surveillance and data
collection projects. The objective of such measures is to thwart
profiling, to buy time, gain cover, and hide in a crowd of signals.
More than 30 colourful examples  instructive vignettes in their own
right  are used to build the case. Roughly a third are analogue, and the
images stick. War-era choppers generating radar chaff. False tells in poker.
Iconic movie scenes, like the switching briefcases in The Thomas Crown
Affair, or the powerful I am Spartacus moment in Kubricks 1960
epic. The authors bring in orb-making spiders, sim-card shuffles,
loyalty-card swap meets, babble tapes (a digital file played in the
background of a conversation in order to obscure it  all examples where
the individual merges with the tribe; where false signals muddy the genuine;
where noise and quick feet offer weapons of the weak.
 Im Spartacus!  obfuscation on film
Shifting to digital, noise can be destructive or productive, and it can scale
dramatically. This is the landscape that a 21st-century handbook must
confront. Platforms and channels can be swamped by code that mimics and
distorts human communication  bots, like-farmers, decoys and hydras.
Other tools, like the anonymous Tor browser, the Guardians SecureDrop,
or stylometric obfuscation (to disguise authorship), can be mission-critical
for dissidents. And there is an ever growing demand for consumer-focused
privacy-preserving apps, like CacheCloak, which hides your mobile location in
a spaghetti map of plausible trails, or FaceCloak, which gives a layer of
control over personal data within Facebook.
We are naked, exposed and eminently traceable, now and into the future, by an
increasing range of data-hungry agents Most of us, most of the time, use
immensely popular technologies without masks or noise. We post in what you
might call corruptible silence. On Facebook, Instagram, Twitter and Google,
we document our personal spaces, our frailties, our desires, questions and
answers. We are naked, exposed and eminently traceable, now and into the
future, by an ever-increasing range of data-hungry agents. To concerned
citizens living this reality, and to thoughtful designers of technology, what
Brunton and Nissenbaum offer is a compelling moral defence and some
ready-to-hand tools for a small, distributed revolution of resistance.
Stunt tech, silence and saviours
Core to the books perspective is the authors experience in building
practical tech  what they describe as tools among other tools for
the construction and defence of privacy. Nissenbaum has been the steward
of two major projects, both with programmer Daniel C Howe: TrackMeNot, a
search-history obfuscator that spontaneously generates clouds of possible
queries; and AdNauseam, which clicks all the ads, so you dont have
TrackMeNot was developed in 2006, in conjunction with developer Vincent
Toubiana, while AdNauseam is new, and currently operates in conjunction with
AdBlock Plus, running in the background to click every ad on a given page.
Discussing the latter platform in Berlin, team-member and designer Mushon
Zer-Aviv described it as, presently, more art project than mass-rollout tech.
AdNauseam is currently in public beta in Firefox, but the team is working
hard to bring it to Google Chrome. As Zer-Aviv described, with a hint of
daring, Google will either take it down, to save ad revenue, which would be a
great stunt; or it wont take it down, which would also be great.
 One of Googles data centres Facebook Twitter Pinterest
 One of Googles data centres, part of the webs back-end.
Photograph: KeystoneUSA-ZUMA / Rex Features
We see these obfuscating apps and systems as moves in a bigger
picture, says Nissenbaum. None, we think, will offer what we really
need, which is comprehensive attention to the picture. Not only the big fuss
about government but all the large data collectors. But they allow people to
visibly signal their disgruntlement  for privacy and protest.
So how does obfuscation play into the current ad-blocking wars? It is a
devilish move by ad networks to conflate the massive back-end of tracking,
aggregation, mining and profiling with advertising itself, says
Nissenbaum. Our effort, both with TrackMeNot and AdNauseam, has been
targeted at the former. I dont love advertising but I can tolerate it.
When supporters of the current structures of behavioural advertising say this
will be the end of all the innovation and free stuff on the web, our response
is: no. Although this might happen if advertising itself goes away, it does
not require the back-end tracking for survival.
The worrying back-end of the web
Advertising does not require back-end tracking for survival.
Helen Nissenbaum
Nissenbaum is right to separate advertising and its current digital back-end.
In the case of newspapers, for example, a great Faustian pact has operated
between ads and content for some 300 years. It more or less works, as long as
theres not too much of one or the other. The fact that this bargain is
threatened by overreaching data collection and surveillance, from search
engines to content-providers to third-party leeches to governments, is a
measure of the urgency of our contemporary challenge and the necessity for a
creative response. Obfuscation is part of that response.
There is something compelling in being persuaded of the ethical imperative of
digital troublemaking by a couple of righteous academics. Obfuscation is not
an academic tome, and it doesnt delve into conceptual analyses on its
core principles, such as anonymity in crowds following David Chaum, or
linkability following Andreas Pfitzmann. But the book has been justifiably
selective to capture broad appeal. The lucid, authoritative, accessible and
thought-provoking text that results is a pleasure to read.
Obfuscation is ultimately a tiny shop in the digital realm. To that extent,
it has nothing against the might of big tech. But what it does have is the
potential to fight to keep the preserve of human agency and autonomy uniquely
human. The big hope is that when our bot descendants find this handbook
stuffed in a tower in 100 years, it is unchecked surveillance  not
digital disobedience  that seems antiquated.

@_date: 2016-11-23 10:57:32
@_author: Eugen Leitl 
@_subject: Parallella Epiphany-V 1024-core 64-bit RISC 
These are DSP (TigerSHARC like) cores with 128 kbyte embedded memory on
a 2d torus signalling grid. Not good for standard crypto, good for scientific
computing and gaming physics acceleration.
I have the prior board  and it's not bad at all.
My version needs active ventilation though.

@_date: 2016-11-25 10:36:52
@_author: Eugen Leitl 
@_subject: Patreon support for the CopperheadOS project 
You might have seen the Tor phone project
which is based on CopperheadOS  and badly needs some funding
to expand their hardware base support. E.g. the only tablet they support is Nexus 9, which
is obsolete and support will end 2017 anyway. Pixel tablets or phones are not supported.
If you want to change that, please donate at or support their Patreon  or buy hardware from
them I'm not associated with the project, but I've donated a little. Will consider donating more in future.

@_date: 2016-11-29 09:39:10
@_author: Eugen Leitl 
@_subject: Are there crypto discussions on this forum 
That was a long time ago, in a galaxy far away. But you can help bring
the good times back.

@_date: 2016-11-30 10:57:14
@_author: Eugen Leitl 
@_subject: Are there crypto discussions on this forum 
Indeed. Anyone care to volunteer for moderation duty?

@_date: 2016-11-30 11:42:13
@_author: Eugen Leitl 
@_subject: Are there crypto discussions on this forum 
I'm subscribed to those, and they are actually functional, unlike this list.
I vastly prefer a well-moderated list to the alternatives.
If you're of the opposite opinion you're being a part of the problem.

@_date: 2016-11-30 12:53:54
@_author: Eugen Leitl 
@_subject: Are there crypto discussions on this forum 
That's because it has been a very useful list for a very long time.
Don't recall seeing your name back then.
How do you kill an unmoderated list? By flooding it with shit.

@_date: 2016-11-23 10:57:32
@_author: Eugen Leitl 
@_subject: Parallella Epiphany-V 1024-core 64-bit RISC 
These are DSP (TigerSHARC like) cores with 128 kbyte embedded memory on
a 2d torus signalling grid. Not good for standard crypto, good for scientific
computing and gaming physics acceleration.
I have the prior board  and it's not bad at all.
My version needs active ventilation though.

@_date: 2016-11-25 10:36:52
@_author: Eugen Leitl 
@_subject: Patreon support for the CopperheadOS project 
You might have seen the Tor phone project
which is based on CopperheadOS  and badly needs some funding
to expand their hardware base support. E.g. the only tablet they support is Nexus 9, which
is obsolete and support will end 2017 anyway. Pixel tablets or phones are not supported.
If you want to change that, please donate at or support their Patreon  or buy hardware from
them I'm not associated with the project, but I've donated a little. Will consider donating more in future.

@_date: 2016-11-29 09:39:10
@_author: Eugen Leitl 
@_subject: Are there crypto discussions on this forum 
That was a long time ago, in a galaxy far away. But you can help bring
the good times back.

@_date: 2016-11-30 10:57:14
@_author: Eugen Leitl 
@_subject: Are there crypto discussions on this forum 
Indeed. Anyone care to volunteer for moderation duty?

@_date: 2016-11-30 11:42:13
@_author: Eugen Leitl 
@_subject: Are there crypto discussions on this forum 
I'm subscribed to those, and they are actually functional, unlike this list.
I vastly prefer a well-moderated list to the alternatives.
If you're of the opposite opinion you're being a part of the problem.

@_date: 2016-11-30 12:53:54
@_author: Eugen Leitl 
@_subject: Are there crypto discussions on this forum 
That's because it has been a very useful list for a very long time.
Don't recall seeing your name back then.
How do you kill an unmoderated list? By flooding it with shit.

@_date: 2017-02-17 08:42:51
@_author: Eugen Leitl 
@_subject: Building a new Tor that can resist next-generation state 
Anyone here able to evaluate the merits of the proposed new architectures? Or do we have to wait for the proof after pudding is served?

@_date: 2017-02-17 08:50:18
@_author: Eugen Leitl 
@_subject: Google???s Artificial Intelligence Getting ???Greedy,??? 
He has been publishing quite a few books lately. There is a method to his madness.

@_date: 2017-02-18 12:44:30
@_author: Eugen Leitl 
@_subject: Google???s Artificial Intelligence Getting ???Greedy,??? 
I have received Anti-Tech Revolution (2016) as a scan. I've just checked, and it's also on LibGen.

@_date: 2017-02-22 08:34:43
@_author: Eugen Leitl 
@_subject: Is email really that hard? 
Who is the list owner these days? If we do not get moderation going I'm out of here.

@_date: 2017-02-22 15:40:59
@_author: Eugen Leitl 
@_subject: Is email really that hard? 
Do you enjoy the current state of the list? No fair filtering.
Go reread it.

@_date: 2017-02-22 17:10:44
@_author: Eugen Leitl 
@_subject: Is email really that hard? 
I really made a mistake back then. This list should have never been resurrected
in the current form. Tolerance and patience will kill even the best list. This is not the way to keep a list healthy and sane. Pretty soon there
will be zero traffic passing your filters.
It's allright, I haven't read anything worthwhile here in years.

@_date: 2017-02-17 08:42:51
@_author: Eugen Leitl 
@_subject: Building a new Tor that can resist next-generation state 
Anyone here able to evaluate the merits of the proposed new architectures? Or do we have to wait for the proof after pudding is served?

@_date: 2017-02-17 08:50:18
@_author: Eugen Leitl 
@_subject: Google???s Artificial Intelligence Getting ???Greedy,??? 
He has been publishing quite a few books lately. There is a method to his madness.

@_date: 2017-02-18 12:44:30
@_author: Eugen Leitl 
@_subject: Google???s Artificial Intelligence Getting ???Greedy,??? 
I have received Anti-Tech Revolution (2016) as a scan. I've just checked, and it's also on LibGen.

@_date: 2017-02-22 08:34:43
@_author: Eugen Leitl 
@_subject: Is email really that hard? 
Who is the list owner these days? If we do not get moderation going I'm out of here.

@_date: 2017-02-22 15:40:59
@_author: Eugen Leitl 
@_subject: Is email really that hard? 
Do you enjoy the current state of the list? No fair filtering.
Go reread it.

@_date: 2017-02-22 17:10:44
@_author: Eugen Leitl 
@_subject: Is email really that hard? 
I really made a mistake back then. This list should have never been resurrected
in the current form. Tolerance and patience will kill even the best list. This is not the way to keep a list healthy and sane. Pretty soon there
will be zero traffic passing your filters.
It's allright, I haven't read anything worthwhile here in years.
