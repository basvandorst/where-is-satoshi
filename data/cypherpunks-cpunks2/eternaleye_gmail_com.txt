
@_date: 2013-10-30 00:08:24
@_author: Alex Elsayed 
@_subject: [Cryptography] /dev/random is not robust 
One thing I wonder is if entropy collection could be separated from pool
mixing - if entropy collection went to a ringbuffer or some other fast data
structure; on excess entropy we could potentially let it drop some or xor
new samples over the old that would be 'dropped'.
Due to the round-robin nature of Fortuna's pool mixing, it could be
parallelized, possibly allowing high-throughput implementations of mixing
and low-latency implementations of submission. That could also help prevent
dropped entropy.
The cryptography mailing list

@_date: 2013-10-30 00:08:24
@_author: Alex Elsayed 
@_subject: [Cryptography] /dev/random is not robust 
One thing I wonder is if entropy collection could be separated from pool
mixing - if entropy collection went to a ringbuffer or some other fast data
structure; on excess entropy we could potentially let it drop some or xor
new samples over the old that would be 'dropped'.
Due to the round-robin nature of Fortuna's pool mixing, it could be
parallelized, possibly allowing high-throughput implementations of mixing
and low-latency implementations of submission. That could also help prevent
dropped entropy.
The cryptography mailing list
cryptography at metzdowd.com

@_date: 2013-10-30 00:08:24
@_author: Alex Elsayed 
@_subject: [Cryptography] /dev/random is not robust 
One thing I wonder is if entropy collection could be separated from pool
mixing - if entropy collection went to a ringbuffer or some other fast data
structure; on excess entropy we could potentially let it drop some or xor
new samples over the old that would be 'dropped'.
Due to the round-robin nature of Fortuna's pool mixing, it could be
parallelized, possibly allowing high-throughput implementations of mixing
and low-latency implementations of submission. That could also help prevent
dropped entropy.
The cryptography mailing list
cryptography at metzdowd.com
